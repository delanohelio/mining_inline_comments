{"pr_number": 3366, "pr_title": "[STORM-3388] Launch workers inside container using runc runtime", "pr_createdAt": "2020-12-21T22:03:00Z", "pr_url": "https://github.com/apache/storm/pull/3366", "timeline": [{"oid": "183b02dccbee3c4e62a388123b936690d44302bd", "url": "https://github.com/apache/storm/commit/183b02dccbee3c4e62a388123b936690d44302bd", "message": "[STORM-3388] Launch workers inside container using runc runtime", "committedDate": "2020-12-21T22:08:36Z", "type": "forcePushed"}, {"oid": "9861143465230cacb31cf67442e69815e5c10805", "url": "https://github.com/apache/storm/commit/9861143465230cacb31cf67442e69815e5c10805", "message": "[STORM-3388] Launch workers inside container using runc runtime", "committedDate": "2020-12-21T22:13:39Z", "type": "forcePushed"}, {"oid": "e3c37eaf1bfb77932bdf15c0631d5e8768410ebc", "url": "https://github.com/apache/storm/commit/e3c37eaf1bfb77932bdf15c0631d5e8768410ebc", "message": "[STORM-3388] Launch workers inside container using runc runtime", "committedDate": "2020-12-21T22:41:07Z", "type": "forcePushed"}, {"oid": "a92685ab214a332ce206c71e52878fc69a06019b", "url": "https://github.com/apache/storm/commit/a92685ab214a332ce206c71e52878fc69a06019b", "message": "cleanup and fixing travis build", "committedDate": "2020-12-22T04:36:32Z", "type": "forcePushed"}, {"oid": "690e02091244f33b32a1dc3c449413e6aff1d964", "url": "https://github.com/apache/storm/commit/690e02091244f33b32a1dc3c449413e6aff1d964", "message": "[STORM-3388] Launch workers inside container using runc runtime", "committedDate": "2020-12-22T18:55:02Z", "type": "commit"}, {"oid": "690e02091244f33b32a1dc3c449413e6aff1d964", "url": "https://github.com/apache/storm/commit/690e02091244f33b32a1dc3c449413e6aff1d964", "message": "[STORM-3388] Launch workers inside container using runc runtime", "committedDate": "2020-12-22T18:55:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MDk0NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547560944", "bodyText": "Parameter order here is counter-intuitive. It makes more sense if reversed.", "author": "bipinprasad", "createdAt": "2020-12-22T23:47:02Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTM4Nzk4Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r555387986", "bodyText": "It means appending src to src_list. I think this order makes sense", "author": "Ethanlm", "createdAt": "2021-01-11T22:44:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MDk0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2MzIyMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547563223", "bodyText": "I believe PEP8 style would be \"if out is not None:\"", "author": "bipinprasad", "createdAt": "2020-12-22T23:56:02Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NDk5Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547564993", "bodyText": "Indentation should be 4 spaces (PEP8)", "author": "bipinprasad", "createdAt": "2020-12-23T00:03:18Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NjYxNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547566616", "bodyText": "timer may not be initialized; need a timer = None at line 55", "author": "bipinprasad", "createdAt": "2020-12-23T00:09:59Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2NzkyNA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547567924", "bodyText": "Remove semicolon", "author": "bipinprasad", "createdAt": "2020-12-23T00:15:24Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODU3Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547568573", "bodyText": "Global vars HADOOP_PREFIX , MAX_IMAGE_LAYERS , MAX_IMAGE_SIZE is not defined in this module", "author": "bipinprasad", "createdAt": "2020-12-23T00:17:50Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)\n+          logging.debug(\"image tag exists for %s\", image)\n+        else:\n+          manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+        update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                       manifest_hash, image)\n+\n+      elif sub_command == \"remove-tag\":\n+        tags = image_and_tag_arg.split(\",\")\n+        image = None\n+        manifest = None\n+        manifest_hash = 0\n+        remove_from_dicts(hash_to_tags, tag_to_hash, tags)\n+      else:\n+        raise Exception(\"Invalid sub_command: %s\" % (sub_command))\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def copy_update(args):\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  src_root = args.src_root\n+  dest_root = args.dest_root\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  src_layers_dir = src_root + \"/layers\"\n+  src_config_dir = src_root + \"/config\"\n+  src_manifest_dir = src_root  + \"/manifests\"\n+  dest_layers_dir = dest_root + \"/layers\"\n+  dest_config_dir = dest_root + \"/config\"\n+  dest_manifest_dir = dest_root  + \"/manifests\"\n+\n+  if bootstrap:\n+    hdfs_dirs = [dest_root, dest_layers_dir, dest_config_dir, dest_manifest_dir]\n+    image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+    setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_src_image_tag_to_hash = os.path.join(working_dir, \"src-\"\n+                                               + os.path.basename(image_tag_to_hash))\n+    local_dest_image_tag_to_hash = os.path.join(working_dir, \"dest-\"\n+                                                + os.path.basename(image_tag_to_hash))\n+\n+    src_hash_to_tags, src_tag_to_hash, src_image_tag_to_hash_hash = populate_tag_dicts(src_root, image_tag_to_hash, local_src_image_tag_to_hash)\n+    dest_hash_to_tags, dest_tag_to_hash, dest_image_tag_to_hash_hash = populate_tag_dicts(dest_root, image_tag_to_hash, local_dest_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image:\n+        raise Exception(\"Positional parameter requires an image: \" + image_and_tag_arg)\n+      if not tags:\n+        logging.debug(\"Tag not given. Using image tag instead: %s\", image)\n+        tags = [image]\n+\n+      src_manifest_hash = src_tag_to_hash.get(image, None)\n+      if not src_manifest_hash:\n+        logging.info(\"Manifest not found for image %s. Skipping\", image)\n+        continue\n+\n+      src_manifest_path = src_manifest_dir + \"/\" + src_manifest_hash\n+      dest_manifest_path = dest_manifest_dir + \"/\" + src_manifest_hash\n+      src_manifest, src_manifest_hash = get_hdfs_manifest_from_path(src_manifest_path)\n+\n+      src_config_hash = get_config_hash_from_manifest(src_manifest)\n+      src_config_path = src_config_dir + \"/\" + src_config_hash\n+      dest_config_path = dest_config_dir + \"/\" + src_config_hash\n+\n+      src_layers = get_layer_hashes_from_manifest(src_manifest)\n+      dest_layers_paths = [dest_layers_dir + \"/\" + layer + \".sqsh\" for layer in src_layers]\n+\n+      logging.debug(\"Copying Manifest: %s\", str(src_manifest_path))\n+      logging.debug(\"Copying Layers: %s\", str(src_layers_paths))\n+      logging.debug(\"Copying Config: %s\", str(src_config_hash))\n+\n+      hdfs_cp(src_layers_paths, dest_layers_dir, force)\n+      hdfs_cp(src_config_path, dest_config_dir, force)\n+      hdfs_cp(src_manifest_path, dest_manifest_dir, force)\n+\n+      hdfs_setrep(replication, dest_layers_paths)\n+      hdfs_setrep(replication, dest_config_path)\n+      hdfs_setrep(replication, dest_manifest_path)\n+\n+      hdfs_chmod(\"444\", dest_layers_paths)\n+      hdfs_chmod(\"444\", dest_config_path)\n+      hdfs_chmod(\"444\", dest_manifest_path)\n+\n+      for tag in tags:\n+        new_tags_and_comments = src_hash_to_tags.get(src_manifest_hash, None)\n+        if new_tags_and_comments:\n+          comment = ', '.join(map(str, new_tags_and_comments[1]))\n+        if comment is None:\n+          comment = image\n+\n+        update_dicts(dest_hash_to_tags, dest_tag_to_hash, tag, src_manifest_hash, comment)\n+\n+      write_local_image_tag_to_hash(local_dest_image_tag_to_hash, dest_hash_to_tags)\n+      atomic_upload_mv_to_hdfs(local_dest_image_tag_to_hash, image_tag_to_hash,\n+                                       dest_root, replication,\n+                                       dest_image_tag_to_hash_hash)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def query_tag(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  tags = args.tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    for tag in tags:\n+      image_hash = tag_to_hash.get(tag, None)\n+      if not image_hash:\n+        logging.info(\"image hash mapping doesn't exist for tag %s\", tag)\n+        continue\n+\n+      manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+      if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+        logging.debug(\"image manifest for %s exists: %s\", tag, manifest_path)\n+      else:\n+        logging.info(\"Image manifest for %s doesn't exist: %s\", tag, manifest_path)\n+        continue\n+\n+      manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+      layers = get_layer_hashes_from_manifest(manifest, False)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+      config_path = hdfs_config_dir + \"/\" + config_hash\n+\n+      layers_paths = [hdfs_layers_dir + \"/\" + layer + \".sqsh\" for layer in layers]\n+\n+      logging.info(\"Image info for '%s'\", tag)\n+      logging.info(manifest_path)\n+      logging.info(config_path)\n+      for layer in layers_paths:\n+        logging.info(layer)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def list_tags(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+\n+  hdfs_image_tag_to_hash = hdfs_root + \"/\" + image_tag_to_hash\n+  if does_hdfs_entry_exist(hdfs_image_tag_to_hash, raise_on_error=False):\n+    hdfs_cat(hdfs_image_tag_to_hash, True, True, False)\n+  else:\n+    logging.error(\"image-tag-to-hash file doesn't exist: %s\", hdfs_image_tag_to_hash)\n+\n+def bootstrap_setup(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+  hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+  image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+  setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+\n+def create_parsers():\n+  parser = argparse.ArgumentParser()\n+  add_parser_default_arguments(parser)\n+\n+  subparsers = parser.add_subparsers(help='sub help', dest='sub_command')\n+\n+  parse_pull_build_push_update = subparsers.add_parser('pull-build-push-update',\n+                                                       help='Pull an image, build its squashfs'\n+                                                       + ' layers, push it to hdfs, and'\n+                                                       + ' atomically update the'\n+                                                       + ' image-tag-to-hash file')\n+  parse_pull_build_push_update.set_defaults(func=pull_build_push_update)\n+  add_parser_default_arguments(parse_pull_build_push_update)\n+  parse_pull_build_push_update.add_argument(\"images_and_tags\", nargs=\"+\",\n+                                            help=\"Image and tag argument (can specify multiple)\")\n+\n+  parse_pull_build = subparsers.add_parser('pull-build',\n+                                           help='Pull an image and build its  squashfs layers')\n+  parse_pull_build .set_defaults(func=pull_build)\n+  add_parser_default_arguments(parse_pull_build)\n+  parse_pull_build.add_argument(\"images_and_tags\", nargs=\"+\",\n+                                help=\"Image and tag argument (can specify multiple)\")\n+\n+  parse_push_update = subparsers.add_parser('push-update',\n+                                            help='Push the squashfs layers to hdfs and update'\n+                                            + ' the image-tag-to-hash file')\n+  parse_push_update.set_defaults(func=push_update)\n+  add_parser_default_arguments(parse_push_update)\n+  parse_push_update.add_argument(\"images_and_tags\", nargs=\"+\",\n+                                 help=\"Image and tag argument (can specify multiple)\")\n+\n+  parse_remove_image = subparsers.add_parser('remove-image',\n+                                             help='Remove an image (manifest, config, layers)'\n+                                             + ' from hdfs based on its tag or manifest hash')\n+  parse_remove_image.set_defaults(func=remove_image)\n+  add_parser_default_arguments(parse_remove_image)\n+  parse_remove_image.add_argument(\"images_or_tags\", nargs=\"+\",\n+                                  help=\"Image or tag argument (can specify multiple)\")\n+\n+  parse_remove_tag = subparsers.add_parser('remove-tag',\n+                                           help='Remove an image to tag mapping in the'\n+                                           + ' image-tag-to-hash file')\n+  parse_remove_tag.set_defaults(func=add_remove_tag)\n+  add_parser_default_arguments(parse_remove_tag)\n+  parse_remove_tag.add_argument(\"images_and_tags\", nargs=\"+\",\n+                                help=\"Image and tag argument (can specify multiple)\")\n+\n+  parse_add_tag = subparsers.add_parser('add-tag',\n+                                        help='Add an image to tag mapping in the'\n+                                        + ' image-tag-to-hash file')\n+  parse_add_tag.set_defaults(func=add_remove_tag)\n+  add_parser_default_arguments(parse_add_tag)\n+  parse_add_tag.add_argument(\"images_and_tags\", nargs=\"+\",\n+                             help=\"Image and tag argument (can specify multiple)\")\n+\n+  parse_copy_update = subparsers.add_parser('copy-update',\n+                                            help='Copy an image from hdfs in one cluster to'\n+                                            + ' another and then update the'\n+                                            + ' image-tag-to-hash file')\n+  parse_copy_update.set_defaults(func=copy_update)\n+  add_parser_default_arguments(parse_copy_update)\n+  parse_copy_update.add_argument(\"src_root\",\n+                                 help=\"HDFS path for source root directory\")\n+  parse_copy_update.add_argument(\"dest_root\",\n+                                 help=\"HDFS path for destination root directory\")\n+  parse_copy_update.add_argument(\"images_and_tags\", nargs=\"+\",\n+                                 help=\"Image and tag argument (can specify multiple)\")\n+\n+  parse_query_tag = subparsers.add_parser('query-tag',\n+                                          help='Get the manifest, config, and layers'\n+                                          + ' associated with a tag')\n+  parse_query_tag.set_defaults(func=query_tag)\n+  add_parser_default_arguments(parse_query_tag)\n+  parse_query_tag.add_argument(\"tags\", nargs=\"+\",\n+                               help=\"Image or tag argument (can specify multiple)\")\n+\n+  parse_list_tags = subparsers.add_parser('list-tags',\n+                                          help='List all tags in image-tag-to-hash file')\n+  parse_list_tags.set_defaults(func=list_tags)\n+  add_parser_default_arguments(parse_list_tags)\n+\n+  parse_bootstrap_setup= subparsers.add_parser('bootstrap',\n+                                          help='Bootstrap setup of required HDFS'\n+                                          + 'directories')\n+  parse_bootstrap_setup.set_defaults(func=bootstrap_setup)\n+  add_parser_default_arguments(parse_bootstrap_setup)\n+\n+  return parser\n+\n+def add_parser_default_arguments(parser):\n+  parser.add_argument(\"--working-dir\", type=str, dest='working_dir', default=\"dts-work-dir\",\n+                      help=\"Name of working directory\")\n+  parser.add_argument(\"--skopeo-format\", type=str, dest='skopeo_format',\n+                      default='dir', help=\"Output format for skopeo copy\")\n+  parser.add_argument(\"--pull-format\", type=str, dest='pull_format',\n+                      default='docker', help=\"Pull format for skopeo\")\n+  parser.add_argument(\"-l\", \"--log\", type=str, dest='LOG_LEVEL',\n+                      default=\"INFO\", help=\"Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\")\n+  parser.add_argument(\"--hdfs-root\", type=str, dest='hdfs_root',\n+                      default='/runc-root', help=\"The root directory in HDFS for all of the\"\n+                      + \"squashfs images\")\n+  parser.add_argument(\"--image-tag-to-hash\", type=str,\n+                      dest='image_tag_to_hash', default='image-tag-to-hash',\n+                      help=\"image-tag-to-hash filename in hdfs\")\n+  parser.add_argument(\"-r\", \"--replication\", type=int, dest='replication',\n+                      default=3, help=\"Replication factor for all files uploaded to HDFS\")\n+  parser.add_argument(\"--hadoop-prefix\", type=str, dest='hadoop_prefix',\n+                      default=os.environ.get('HADOOP_PREFIX'),\n+                      help=\"hadoop prefix value for environment\")\n+  parser.add_argument(\"-f\", \"--force\", dest='force',\n+                      action=\"store_true\", default=False, help=\"Force overwrites in HDFS\")\n+  parser.add_argument(\"--check-magic-file\", dest='check_magic_file',\n+                      action=\"store_true\", default=False, help=\"Check for a specific magic file\"\n+                      + \"in the image before uploading\")\n+  parser.add_argument(\"--magic-file\", type=str, dest='magic_file',\n+                      default='etc/dockerfile-version', help=\"The magic file to check for\"\n+                      + \"in the image\")\n+  parser.add_argument(\"--max-layers\", type=int, dest='MAX_IMAGE_LAYERS',\n+                      default=37, help=\"Maximum number of layers an image is allowed to have\")\n+  parser.add_argument(\"--max-size\", type=int, dest='MAX_IMAGE_SIZE',\n+                      default=10*1024*1024*1024, help=\"Maximum size an image is allowed to be\")\n+  parser.add_argument(\"-b\", \"--bootstrap\", dest='bootstrap',\n+                      action=\"store_true\", default=False, help=\"Bootstrap setup\"\n+                      + \" of required HDFS directories\")\n+  return parser\n+\n+def check_dependencies():\n+  global HADOOP_BIN_DIR\n+  try:\n+    command = [HADOOP_BIN_DIR + \"/hadoop\", \"version\"]\n+    shell_command(command, False, False, True)\n+  except:\n+    logging.error(\"Could not find hadoop. Make sure HADOOP_PREFIX \" +\n+                  \"is set correctly either in your environment or on the command line \" +\n+                  \"via --hadoop-prefix\")\n+    return 1\n+\n+  try:\n+    command = [\"skopeo\", \"-v\"]\n+    shell_command(command, False, False, True)\n+  except:\n+    logging.error(\"Could not find skopeo. Make sure it is installed and present \" +\n+                  \"on the PATH\")\n+    return 1\n+\n+  try:\n+    command = [\"/usr/sbin/mksquashfs\", \"-version\"]\n+    shell_command(command, False, False, True)\n+  except:\n+    logging.error(\"Could not find /usr/sbin/mksquashfs. Make sure squashfs-tools is installed \" +\n+                  \"and /usr/sbin/mksquashfs is present on the the PATH\")\n+    return 1\n+\n+  try:\n+    command = [\"tar\", \"--version\"]\n+    shell_command(command, False, False, True)\n+  except:\n+    logging.error(\"Could not find tar. Make sure it is installed and present \" +\n+                  \"on the PATH\")\n+    return 1\n+\n+  try:\n+    command = [\"setfattr\", \"--version\"]\n+    shell_command(command, False, False, True)\n+  except:\n+    logging.error(\"Could not find setfattr . Make sure it is installed and present \" +\n+                  \"on the PATH\")\n+    return 1\n+\n+  return 0\n+\n+def main():\n+  global LOG_LEVEL\n+  global HADOOP_PREFIX\n+  global HADOOP_BIN_DIR\n+  global MAX_IMAGE_LAYERS\n+  global MAX_IMAGE_SIZE", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTM5MjI0NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r555392245", "bodyText": "They are passed in from arguments", "author": "Ethanlm", "createdAt": "2021-01-11T22:55:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2ODU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU2OTgyNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547569826", "bodyText": "sp: Commmand -> Command", "author": "bipinprasad", "createdAt": "2020-12-23T00:23:07Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3MjU4OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547572588", "bodyText": "replace with\"else:\" or initialize jar_file = None before for loop", "author": "bipinprasad", "createdAt": "2020-12-23T00:32:58Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDAyMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547574023", "bodyText": "Unused - can be removed", "author": "bipinprasad", "createdAt": "2020-12-23T00:38:30Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)\n+          logging.debug(\"image tag exists for %s\", image)\n+        else:\n+          manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+        update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                       manifest_hash, image)\n+\n+      elif sub_command == \"remove-tag\":\n+        tags = image_and_tag_arg.split(\",\")\n+        image = None\n+        manifest = None\n+        manifest_hash = 0", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDQ0MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547574441", "bodyText": "unused manifest can be replaced with \"_\"", "author": "bipinprasad", "createdAt": "2020-12-23T00:39:56Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTM5NDU1Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r555394553", "bodyText": "I think keeping it a as a readable variable is easier to understand even though it is not used", "author": "Ethanlm", "createdAt": "2021-01-11T23:00:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDQ0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDQ3Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547574477", "bodyText": "unused manifest can be replaced with \"_\"", "author": "bipinprasad", "createdAt": "2020-12-23T00:40:06Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)\n+          logging.debug(\"image tag exists for %s\", image)\n+        else:\n+          manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTM5NDY0OQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r555394649", "bodyText": "I think keeping it as a readable variable is easier to understand even though it is not used", "author": "Ethanlm", "createdAt": "2021-01-11T23:00:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDQ3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NTQwOQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547575409", "bodyText": "replace with args.hdfs_root or assign hdfs_root = args.hdfs_root like in some methods before.", "author": "bipinprasad", "createdAt": "2020-12-23T00:44:16Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)\n+          logging.debug(\"image tag exists for %s\", image)\n+        else:\n+          manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+        update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                       manifest_hash, image)\n+\n+      elif sub_command == \"remove-tag\":\n+        tags = image_and_tag_arg.split(\",\")\n+        image = None\n+        manifest = None\n+        manifest_hash = 0\n+        remove_from_dicts(hash_to_tags, tag_to_hash, tags)\n+      else:\n+        raise Exception(\"Invalid sub_command: %s\" % (sub_command))\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def copy_update(args):\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  src_root = args.src_root\n+  dest_root = args.dest_root\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  src_layers_dir = src_root + \"/layers\"\n+  src_config_dir = src_root + \"/config\"\n+  src_manifest_dir = src_root  + \"/manifests\"\n+  dest_layers_dir = dest_root + \"/layers\"\n+  dest_config_dir = dest_root + \"/config\"\n+  dest_manifest_dir = dest_root  + \"/manifests\"\n+\n+  if bootstrap:\n+    hdfs_dirs = [dest_root, dest_layers_dir, dest_config_dir, dest_manifest_dir]\n+    image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzIxNjE3Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r667216172", "bodyText": "This should be dest_root. Fixed and tested copy_update method.", "author": "Ethanlm", "createdAt": "2021-07-09T21:18:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NTQwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NjM5NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547576395", "bodyText": "src_layers_paths is used here and on 1104, but is not defined/assigned anywhere.", "author": "bipinprasad", "createdAt": "2020-12-23T00:48:08Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)\n+          logging.debug(\"image tag exists for %s\", image)\n+        else:\n+          manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+        update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                       manifest_hash, image)\n+\n+      elif sub_command == \"remove-tag\":\n+        tags = image_and_tag_arg.split(\",\")\n+        image = None\n+        manifest = None\n+        manifest_hash = 0\n+        remove_from_dicts(hash_to_tags, tag_to_hash, tags)\n+      else:\n+        raise Exception(\"Invalid sub_command: %s\" % (sub_command))\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def copy_update(args):\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  src_root = args.src_root\n+  dest_root = args.dest_root\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  src_layers_dir = src_root + \"/layers\"\n+  src_config_dir = src_root + \"/config\"\n+  src_manifest_dir = src_root  + \"/manifests\"\n+  dest_layers_dir = dest_root + \"/layers\"\n+  dest_config_dir = dest_root + \"/config\"\n+  dest_manifest_dir = dest_root  + \"/manifests\"\n+\n+  if bootstrap:\n+    hdfs_dirs = [dest_root, dest_layers_dir, dest_config_dir, dest_manifest_dir]\n+    image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+    setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_src_image_tag_to_hash = os.path.join(working_dir, \"src-\"\n+                                               + os.path.basename(image_tag_to_hash))\n+    local_dest_image_tag_to_hash = os.path.join(working_dir, \"dest-\"\n+                                                + os.path.basename(image_tag_to_hash))\n+\n+    src_hash_to_tags, src_tag_to_hash, src_image_tag_to_hash_hash = populate_tag_dicts(src_root, image_tag_to_hash, local_src_image_tag_to_hash)\n+    dest_hash_to_tags, dest_tag_to_hash, dest_image_tag_to_hash_hash = populate_tag_dicts(dest_root, image_tag_to_hash, local_dest_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image:\n+        raise Exception(\"Positional parameter requires an image: \" + image_and_tag_arg)\n+      if not tags:\n+        logging.debug(\"Tag not given. Using image tag instead: %s\", image)\n+        tags = [image]\n+\n+      src_manifest_hash = src_tag_to_hash.get(image, None)\n+      if not src_manifest_hash:\n+        logging.info(\"Manifest not found for image %s. Skipping\", image)\n+        continue\n+\n+      src_manifest_path = src_manifest_dir + \"/\" + src_manifest_hash\n+      dest_manifest_path = dest_manifest_dir + \"/\" + src_manifest_hash\n+      src_manifest, src_manifest_hash = get_hdfs_manifest_from_path(src_manifest_path)\n+\n+      src_config_hash = get_config_hash_from_manifest(src_manifest)\n+      src_config_path = src_config_dir + \"/\" + src_config_hash\n+      dest_config_path = dest_config_dir + \"/\" + src_config_hash\n+\n+      src_layers = get_layer_hashes_from_manifest(src_manifest)\n+      dest_layers_paths = [dest_layers_dir + \"/\" + layer + \".sqsh\" for layer in src_layers]\n+\n+      logging.debug(\"Copying Manifest: %s\", str(src_manifest_path))\n+      logging.debug(\"Copying Layers: %s\", str(src_layers_paths))", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzIxNjM3OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r667216378", "bodyText": "missed\nsrc_layers_paths = [src_layers_dir + \"/\" + layer + \".sqsh\" for layer in src_layers]\n\nFixed and tested copy_update", "author": "Ethanlm", "createdAt": "2021-07-09T21:18:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NjM5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3Njk5OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547576998", "bodyText": "change this to \"else:\" or define comment = None before the line 1118 (otherwise comment can be undefined)", "author": "bipinprasad", "createdAt": "2020-12-23T00:50:39Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"\n+    for file in glob.glob(jar_path):\n+      jar_file = file\n+\n+    if not jar_file:\n+      raise Exception(\"SymlinkTool Jar doesn't exist: %s\" % (jar_path))\n+\n+    logging.debug(\"jar_file: \" + jar_file)\n+\n+    shell_command([\"hadoop\", \"jar\", jar_file, \"org.apache.hadoop.tools.SymlinkTool\",\n+                   \"mvlink\", \"-f\", hdfs_tmp_path, hdfs_file_path], False, False, True)\n+\n+  except:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    raise Exception(\"image tag to hash file upload failed\")\n+\n+def docker_to_squash(layer_dir, layer, working_dir):\n+  tmp_dir = os.path.join(working_dir, \"expand_archive_\" + layer)\n+  layer_path = os.path.join(layer_dir, layer)\n+  squash_path = layer_path + \".sqsh\"\n+\n+  if os.path.isdir(tmp_dir):\n+    raise Exception(\"tmp_dir already exists. Please delete and try again \" +\n+                    \"Directory: \" + tmp_dir)\n+  os.makedirs(tmp_dir)\n+\n+  try:\n+    untar_layer(tmp_dir, layer_path)\n+    convert_oci_whiteouts(tmp_dir)\n+    dir_to_squashfs(tmp_dir, squash_path)\n+  finally:\n+    os.remove(layer_path)\n+    shell_command([\"rm\", \"-rf\", tmp_dir],\n+                  False, True, True)\n+\n+\n+def check_image_for_magic_file(magic_file, skopeo_dir, layers):\n+  magic_file_absolute = magic_file.strip(\"/\")\n+  logging.debug(\"Searching for magic file %s\", magic_file_absolute)\n+  for layer in layers:\n+    ret = tar_file_search(os.path.join(skopeo_dir, layer), magic_file_absolute)\n+    if ret:\n+      logging.debug(\"Found magic file %s in layer %s\", magic_file_absolute, layer)\n+      logging.debug(\"Magic file %s has contents:\\n%s\", magic_file_absolute, ret)\n+      return ret\n+  raise Exception(\"Magic file %s doesn't exist in any layer\" %\n+                  (magic_file_absolute))\n+\n+def pull_build_push_update(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying and uploading layer: %s\", layer)\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shell_command([\"rm\", \"-rf\", working_dir],\n+                      False, True, True)\n+\n+def pull_build(args):\n+  skopeo_format = args.skopeo_format\n+  pull_format = args.pull_format\n+  images_and_tags = args.images_and_tags\n+  check_magic_file = args.check_magic_file\n+  magic_file = args.magic_file\n+\n+  for image_and_tag_arg in images_and_tags:\n+    image, tags = split_image_and_tag(image_and_tag_arg)\n+    if not image or not tags:\n+      raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                      + image_and_tag_arg)\n+\n+    logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+    layers = get_layer_hashes_from_manifest(manifest)\n+    config_hash = get_config_hash_from_manifest(manifest)\n+\n+    logging.debug(\"Layers: %s\", str(layers))\n+    logging.debug(\"Config: %s\", str(config_hash))\n+\n+\n+    try:\n+      working_dir = get_working_dir(args.working_dir)\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      logging.debug(\"skopeo_dir: %s\", skopeo_dir)\n+      skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir)\n+\n+      if check_magic_file:\n+        check_image_for_magic_file(magic_file, skopeo_dir, layers)\n+\n+      for layer in layers:\n+        logging.info(\"Squashifying layer: %s\", layer)\n+        docker_to_squash(skopeo_dir, layer, working_dir)\n+\n+    except:\n+      if os.path.isdir(skopeo_dir):\n+        shutil.rmtree(skopeo_dir)\n+      raise\n+\n+def push_update(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  hdfs_layers_dir = hdfs_root + \"/layers\"\n+  hdfs_config_dir = hdfs_root + \"/config\"\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  local_image_tag_to_hash = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    if bootstrap:\n+      hdfs_dirs = [hdfs_root, hdfs_layers_dir, hdfs_config_dir, hdfs_manifest_dir]\n+      image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+      setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image or not tags:\n+        raise Exception(\"Positional parameter requires an image and at least 1 tag: \"\n+                        + image_and_tag_arg)\n+\n+      logging.info(\"Working on image %s with tags %s\", image, str(tags))\n+      skopeo_dir = os.path.join(working_dir, image.split(\"/\")[-1])\n+      if not os.path.exists(skopeo_dir):\n+        raise Exception(\"skopeo_dir doesn't exists: %s\" % (skopeo_dir))\n+      manifest, manifest_hash = get_local_manifest_from_path(skopeo_dir + \"/manifest.json\")\n+\n+      layers = get_layer_hashes_from_manifest(manifest)\n+      config_hash = get_config_hash_from_manifest(manifest)\n+\n+      logging.debug(\"Layers: %s\", str(layers))\n+      logging.debug(\"Config: %s\", str(config_hash))\n+\n+      update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                     manifest_hash, image)\n+\n+      all_layers_exist = True\n+\n+      if not does_hdfs_entry_exist(hdfs_manifest_dir + \"/\" + manifest_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      if not does_hdfs_entry_exist(hdfs_config_dir + \"/\" + config_hash,\n+                                   raise_on_error=False):\n+        all_layers_exist = False\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if not does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          all_layers_exist = False\n+          break\n+\n+      if all_layers_exist:\n+        if not force:\n+          logging.info(\"All layers exist in HDFS, skipping this image\")\n+          continue\n+        logging.info(\"All layers exist in HDFS, but force option set, so overwriting image\")\n+\n+      for layer in layers:\n+        hdfs_squash_path = hdfs_layers_dir + \"/\" + layer + \".sqsh\"\n+        if does_hdfs_entry_exist(hdfs_squash_path, raise_on_error=False):\n+          if force:\n+            logging.info(\"Layer already exists, but overwriting due to force\"\n+                         + \"option: %s\", layer)\n+          else:\n+            logging.info(\"Layer exists. Skipping and not squashifying or\"\n+                         + \"uploading: %s\", layer)\n+            continue\n+\n+        squash_path = os.path.join(skopeo_dir, layer + \".sqsh\")\n+        squash_name = os.path.basename(squash_path)\n+        upload_to_hdfs(squash_path, squash_name, hdfs_layers_dir, replication, \"444\", force)\n+\n+\n+      config_local_path = os.path.join(skopeo_dir, config_hash)\n+      upload_to_hdfs(config_local_path,\n+                     os.path.basename(config_local_path),\n+                     hdfs_config_dir, replication, \"444\", force)\n+\n+      manifest_local_path = os.path.join(skopeo_dir, \"manifest.json\")\n+      upload_to_hdfs(manifest_local_path, manifest_hash,\n+                     hdfs_manifest_dir, replication, \"444\", force)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if local_image_tag_to_hash:\n+      if os.path.isfile(local_image_tag_to_hash):\n+        os.remove(local_image_tag_to_hash)\n+\n+\n+def remove_image(args):\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  images_or_tags = args.images_or_tags\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+    logging.debug(\"tag_to_hash: %s\", str(tag_to_hash))\n+\n+    hdfs_layers_dir = hdfs_root + \"/layers\"\n+    hdfs_config_dir = hdfs_root + \"/config\"\n+    hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+\n+    delete_list = []\n+\n+    known_images, err, returncode = hdfs_ls(hdfs_manifest_dir, \"-C\", False, False, False)\n+    known_images = known_images.split()\n+\n+    logging.debug(\"known_images:\\n%s\", known_images)\n+\n+    layers_to_keep = []\n+\n+    images_and_tags_to_remove = []\n+    images_to_remove = []\n+    for image_or_tag_arg in images_or_tags:\n+      images_and_tags_to_remove.extend(image_or_tag_arg.split(\",\"))\n+\n+    logging.debug(\"images_and_tags_to_remove:\\n%s\", images_and_tags_to_remove)\n+\n+    if isinstance(images_and_tags_to_remove, Iterable):\n+      for image in images_and_tags_to_remove:\n+        if is_sha256_hash(image):\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+        if image_hash:\n+          images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+    else:\n+      image = images_and_tags_to_remove[0]\n+      if is_sha256_hash(image):\n+        image_hash = image\n+      else:\n+        image_hash = tag_to_hash.get(image, None)\n+      if image_hash:\n+        images_to_remove.append(hdfs_manifest_dir + \"/\" + image_hash)\n+\n+    logging.debug(\"images_to_remove:\\n%s\", images_to_remove)\n+    if not images_to_remove:\n+      logging.warn(\"No images to remove\")\n+      return\n+\n+    for image in known_images:\n+      if image not in images_to_remove:\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(image)\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_to_keep.extend(layers)\n+\n+    logging.debug(\"layers_to_keep:\\n%s\", layers_to_keep)\n+\n+    for image_or_tag_arg in images_or_tags:\n+      images = image_or_tag_arg.split(\",\")\n+      for image in images:\n+        logging.info(\"removing image: %s\", image)\n+        if is_sha256_hash(image):\n+          logging.debug(\"image is sha256\")\n+          image_hash = image\n+        else:\n+          image_hash = tag_to_hash.get(image, None)\n+          if image_hash:\n+            logging.debug(\"image tag exists for %s\", image)\n+          else:\n+            logging.info(\"Not removing %s. Image tag doesn't exist\", image)\n+            continue\n+        manifest_path = hdfs_manifest_dir + \"/\" + image_hash\n+        if does_hdfs_entry_exist(manifest_path, raise_on_error=False):\n+          logging.debug(\"image manifest for %s exists: %s\", image, manifest_path)\n+        else:\n+          logging.info(\"Not removing %s. Image manifest doesn't exist: %s\", image, manifest_path)\n+          continue\n+\n+        delete_list.append(manifest_path)\n+\n+        manifest, manifest_hash = get_hdfs_manifest_from_path(manifest_path)\n+\n+        config_hash = get_config_hash_from_manifest(manifest)\n+        logging.debug(\"config_hash: %s\", config_hash)\n+\n+        delete_list.append(hdfs_config_dir + \"/\" + config_hash)\n+\n+        layers = get_layer_hashes_from_manifest(manifest, False)\n+        layers_paths = []\n+        for layer in layers:\n+          if layer not in layers_to_keep:\n+            layers_paths.append(hdfs_layers_dir + \"/\" + layer + \".sqsh\")\n+        delete_list.extend(layers_paths)\n+\n+        logging.debug(\"delete_list: %s\", delete_list)\n+\n+        remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash)\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+\n+    hdfs_rm(delete_list)\n+\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def add_remove_tag(args):\n+  pull_format = args.pull_format\n+  hdfs_root = args.hdfs_root\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  sub_command = args.sub_command\n+  images_and_tags = args.images_and_tags\n+\n+  hdfs_manifest_dir = hdfs_root + \"/manifests\"\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_image_tag_to_hash = os.path.join(working_dir, os.path.basename(image_tag_to_hash))\n+    hash_to_tags, tag_to_hash, image_tag_to_hash_hash = populate_tag_dicts(hdfs_root,\n+                                                                           image_tag_to_hash,\n+                                                                           local_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      if sub_command == \"add-tag\":\n+        image, tags = split_image_and_tag(image_and_tag_arg)\n+        if is_sha256_hash(image):\n+          manifest_hash = image\n+        else:\n+          manifest_hash = tag_to_hash.get(image, None)\n+\n+        if manifest_hash:\n+          manifest_path = hdfs_manifest_dir + \"/\" + manifest_hash\n+          out, err, returncode = hdfs_cat(manifest_path)\n+          manifest = json.loads(out)\n+          logging.debug(\"image tag exists for %s\", image)\n+        else:\n+          manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image)\n+\n+        update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                       manifest_hash, image)\n+\n+      elif sub_command == \"remove-tag\":\n+        tags = image_and_tag_arg.split(\",\")\n+        image = None\n+        manifest = None\n+        manifest_hash = 0\n+        remove_from_dicts(hash_to_tags, tag_to_hash, tags)\n+      else:\n+        raise Exception(\"Invalid sub_command: %s\" % (sub_command))\n+\n+    write_local_image_tag_to_hash(local_image_tag_to_hash, hash_to_tags)\n+    atomic_upload_mv_to_hdfs(local_image_tag_to_hash, image_tag_to_hash,\n+                                     hdfs_root, replication,\n+                                     image_tag_to_hash_hash)\n+  finally:\n+    if working_dir:\n+      if os.path.isdir(working_dir):\n+        shutil.rmtree(working_dir)\n+\n+def copy_update(args):\n+  image_tag_to_hash = args.image_tag_to_hash\n+  replication = args.replication\n+  force = args.force\n+  src_root = args.src_root\n+  dest_root = args.dest_root\n+  images_and_tags = args.images_and_tags\n+  bootstrap = args.bootstrap\n+\n+  src_layers_dir = src_root + \"/layers\"\n+  src_config_dir = src_root + \"/config\"\n+  src_manifest_dir = src_root  + \"/manifests\"\n+  dest_layers_dir = dest_root + \"/layers\"\n+  dest_config_dir = dest_root + \"/config\"\n+  dest_manifest_dir = dest_root  + \"/manifests\"\n+\n+  if bootstrap:\n+    hdfs_dirs = [dest_root, dest_layers_dir, dest_config_dir, dest_manifest_dir]\n+    image_tag_to_hash_path = hdfs_root + \"/\" + image_tag_to_hash\n+    setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path)\n+  working_dir = None\n+\n+  try:\n+    working_dir = get_working_dir(args.working_dir)\n+    local_src_image_tag_to_hash = os.path.join(working_dir, \"src-\"\n+                                               + os.path.basename(image_tag_to_hash))\n+    local_dest_image_tag_to_hash = os.path.join(working_dir, \"dest-\"\n+                                                + os.path.basename(image_tag_to_hash))\n+\n+    src_hash_to_tags, src_tag_to_hash, src_image_tag_to_hash_hash = populate_tag_dicts(src_root, image_tag_to_hash, local_src_image_tag_to_hash)\n+    dest_hash_to_tags, dest_tag_to_hash, dest_image_tag_to_hash_hash = populate_tag_dicts(dest_root, image_tag_to_hash, local_dest_image_tag_to_hash)\n+\n+    for image_and_tag_arg in images_and_tags:\n+      image, tags = split_image_and_tag(image_and_tag_arg)\n+      if not image:\n+        raise Exception(\"Positional parameter requires an image: \" + image_and_tag_arg)\n+      if not tags:\n+        logging.debug(\"Tag not given. Using image tag instead: %s\", image)\n+        tags = [image]\n+\n+      src_manifest_hash = src_tag_to_hash.get(image, None)\n+      if not src_manifest_hash:\n+        logging.info(\"Manifest not found for image %s. Skipping\", image)\n+        continue\n+\n+      src_manifest_path = src_manifest_dir + \"/\" + src_manifest_hash\n+      dest_manifest_path = dest_manifest_dir + \"/\" + src_manifest_hash\n+      src_manifest, src_manifest_hash = get_hdfs_manifest_from_path(src_manifest_path)\n+\n+      src_config_hash = get_config_hash_from_manifest(src_manifest)\n+      src_config_path = src_config_dir + \"/\" + src_config_hash\n+      dest_config_path = dest_config_dir + \"/\" + src_config_hash\n+\n+      src_layers = get_layer_hashes_from_manifest(src_manifest)\n+      dest_layers_paths = [dest_layers_dir + \"/\" + layer + \".sqsh\" for layer in src_layers]\n+\n+      logging.debug(\"Copying Manifest: %s\", str(src_manifest_path))\n+      logging.debug(\"Copying Layers: %s\", str(src_layers_paths))\n+      logging.debug(\"Copying Config: %s\", str(src_config_hash))\n+\n+      hdfs_cp(src_layers_paths, dest_layers_dir, force)\n+      hdfs_cp(src_config_path, dest_config_dir, force)\n+      hdfs_cp(src_manifest_path, dest_manifest_dir, force)\n+\n+      hdfs_setrep(replication, dest_layers_paths)\n+      hdfs_setrep(replication, dest_config_path)\n+      hdfs_setrep(replication, dest_manifest_path)\n+\n+      hdfs_chmod(\"444\", dest_layers_paths)\n+      hdfs_chmod(\"444\", dest_config_path)\n+      hdfs_chmod(\"444\", dest_manifest_path)\n+\n+      for tag in tags:\n+        new_tags_and_comments = src_hash_to_tags.get(src_manifest_hash, None)\n+        if new_tags_and_comments:\n+          comment = ', '.join(map(str, new_tags_and_comments[1]))\n+        if comment is None:", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY0NzA5Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547647096", "bodyText": "Is this supposed to be part of javadoc on parsing logic?", "author": "bipinprasad", "createdAt": "2020-12-23T05:09:58Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"cache.refresh.interval.secs\";\n+\n+    /**\n+     * The number of manifests to cache.\n+     */\n+    private static String OCI_NUM_MANIFESTS_TO_CACHE = LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"num.manifests.to.cache\";\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";\n+\n+    @Override\n+    public void init(Map<String, Object> conf) throws IOException {\n+        this.conf = conf;\n+\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        localImageTagToHashFile = (String) conf.get(LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Failed to load local oci-image-to-hash file. Config not set\");\n+        }\n+        hdfsImageToHashFile = (String) conf.get(HDFS_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Failed to load HDFS oci-image-to-hash file. Config not set\");\n+        }\n+        if (hdfsImageToHashFile == null && localImageTagToHashFile == null) {\n+            throw new IllegalArgumentException(\"No valid image-tag-to-hash files\");\n+        }\n+        manifestDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR)) + \"/manifests/\";\n+        int numManifestsToCache = ObjectReader.getInt(conf.get(OCI_NUM_MANIFESTS_TO_CACHE), 10);\n+        this.objMapper = new ObjectMapper();\n+        this.manifestCache = new LruCache(numManifestsToCache, 0.75f);\n+        ociCacheRefreshIntervalSecs = ObjectReader.getInt(conf.get(OCI_CACHE_REFRESH_INTERVAL), 60);\n+    }\n+\n+    private boolean loadImageToHashFiles() throws IOException {\n+        boolean ret = false;\n+        try (BufferedReader localBr = getLocalImageToHashReader()) {\n+            Map<String, String> localImageToHash = readImageToHashFile(localBr);\n+            if (localImageToHash != null && !localImageToHash.equals(localImageToHashCache)) {\n+                localImageToHashCache = localImageToHash;\n+                LOG.info(\"Reloaded local image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+\n+        try (BufferedReader hdfsBr = getHdfsImageToHashReader()) {\n+            Map<String, String> hdfsImageToHash = readImageToHashFile(hdfsBr);\n+            if (hdfsImageToHash != null && !hdfsImageToHash.equals(hdfsImageToHashCache)) {\n+                hdfsImageToHashCache = hdfsImageToHash;\n+                LOG.info(\"Reloaded hdfs image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    private BufferedReader getLocalImageToHashReader() throws IOException {\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Did not load local image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        File imageTagToHashFile = new File(localImageTagToHashFile);\n+        if (!imageTagToHashFile.exists()) {\n+            LOG.warn(\"Did not load local image to hash file, file doesn't exist\");\n+            return null;\n+        }\n+\n+        long newLocalModTime = imageTagToHashFile.lastModified();\n+        if (newLocalModTime == localModTime) {\n+            LOG.debug(\"Did not load local image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        localModTime = newLocalModTime;\n+\n+        return new BufferedReader(new FileReader(imageTagToHashFile));\n+    }\n+\n+    private BufferedReader getHdfsImageToHashReader() throws IOException {\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        Path imageToHash = new Path(hdfsImageToHashFile);\n+        FileSystem fs = imageToHash.getFileSystem(new Configuration());\n+        if (!fs.exists(imageToHash)) {\n+            String message = \"Could not load hdfs image to hash file, \" + hdfsImageToHashFile + \" doesn't exist\";\n+            LOG.error(message);\n+            throw new IOException(message);\n+        }\n+\n+        long newHdfsModTime = fs.getFileStatus(imageToHash).getModificationTime();\n+        if (newHdfsModTime == hdfsModTime) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        hdfsModTime = newHdfsModTime;\n+\n+        return new BufferedReader(new InputStreamReader(fs.open(imageToHash)));\n+    }\n+\n+    // You may specify multiple tags per hash all on the same line.\n+    // Comments are allowed using #. Anything after this character will not\n+    // be read\n+    // Example file:\n+    // foo/bar:current,fizz/gig:latest:123456789\n+    // #this/line:wont,be:parsed:2378590895\n+    //\n+    // This will map both foo/bar:current and fizz/gig:latest to 123456789", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzIyMjMzNw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r667222337", "bodyText": "will convert this to javadoc", "author": "Ethanlm", "createdAt": "2021-07-09T21:35:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY0NzA5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY1MTg3NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547651875", "bodyText": "It will be good to know which file or hdfs url this error is in. Same comment for line 214.", "author": "bipinprasad", "createdAt": "2020-12-23T05:16:22Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"cache.refresh.interval.secs\";\n+\n+    /**\n+     * The number of manifests to cache.\n+     */\n+    private static String OCI_NUM_MANIFESTS_TO_CACHE = LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"num.manifests.to.cache\";\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";\n+\n+    @Override\n+    public void init(Map<String, Object> conf) throws IOException {\n+        this.conf = conf;\n+\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        localImageTagToHashFile = (String) conf.get(LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Failed to load local oci-image-to-hash file. Config not set\");\n+        }\n+        hdfsImageToHashFile = (String) conf.get(HDFS_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Failed to load HDFS oci-image-to-hash file. Config not set\");\n+        }\n+        if (hdfsImageToHashFile == null && localImageTagToHashFile == null) {\n+            throw new IllegalArgumentException(\"No valid image-tag-to-hash files\");\n+        }\n+        manifestDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR)) + \"/manifests/\";\n+        int numManifestsToCache = ObjectReader.getInt(conf.get(OCI_NUM_MANIFESTS_TO_CACHE), 10);\n+        this.objMapper = new ObjectMapper();\n+        this.manifestCache = new LruCache(numManifestsToCache, 0.75f);\n+        ociCacheRefreshIntervalSecs = ObjectReader.getInt(conf.get(OCI_CACHE_REFRESH_INTERVAL), 60);\n+    }\n+\n+    private boolean loadImageToHashFiles() throws IOException {\n+        boolean ret = false;\n+        try (BufferedReader localBr = getLocalImageToHashReader()) {\n+            Map<String, String> localImageToHash = readImageToHashFile(localBr);\n+            if (localImageToHash != null && !localImageToHash.equals(localImageToHashCache)) {\n+                localImageToHashCache = localImageToHash;\n+                LOG.info(\"Reloaded local image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+\n+        try (BufferedReader hdfsBr = getHdfsImageToHashReader()) {\n+            Map<String, String> hdfsImageToHash = readImageToHashFile(hdfsBr);\n+            if (hdfsImageToHash != null && !hdfsImageToHash.equals(hdfsImageToHashCache)) {\n+                hdfsImageToHashCache = hdfsImageToHash;\n+                LOG.info(\"Reloaded hdfs image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    private BufferedReader getLocalImageToHashReader() throws IOException {\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Did not load local image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        File imageTagToHashFile = new File(localImageTagToHashFile);\n+        if (!imageTagToHashFile.exists()) {\n+            LOG.warn(\"Did not load local image to hash file, file doesn't exist\");\n+            return null;\n+        }\n+\n+        long newLocalModTime = imageTagToHashFile.lastModified();\n+        if (newLocalModTime == localModTime) {\n+            LOG.debug(\"Did not load local image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        localModTime = newLocalModTime;\n+\n+        return new BufferedReader(new FileReader(imageTagToHashFile));\n+    }\n+\n+    private BufferedReader getHdfsImageToHashReader() throws IOException {\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        Path imageToHash = new Path(hdfsImageToHashFile);\n+        FileSystem fs = imageToHash.getFileSystem(new Configuration());\n+        if (!fs.exists(imageToHash)) {\n+            String message = \"Could not load hdfs image to hash file, \" + hdfsImageToHashFile + \" doesn't exist\";\n+            LOG.error(message);\n+            throw new IOException(message);\n+        }\n+\n+        long newHdfsModTime = fs.getFileStatus(imageToHash).getModificationTime();\n+        if (newHdfsModTime == hdfsModTime) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        hdfsModTime = newHdfsModTime;\n+\n+        return new BufferedReader(new InputStreamReader(fs.open(imageToHash)));\n+    }\n+\n+    // You may specify multiple tags per hash all on the same line.\n+    // Comments are allowed using #. Anything after this character will not\n+    // be read\n+    // Example file:\n+    // foo/bar:current,fizz/gig:latest:123456789\n+    // #this/line:wont,be:parsed:2378590895\n+    //\n+    // This will map both foo/bar:current and fizz/gig:latest to 123456789\n+    private static Map<String, String> readImageToHashFile(BufferedReader br) throws IOException {\n+        if (br == null) {\n+            return null;\n+        }\n+\n+        String line;\n+        Map<String, String> imageToHashCache = new HashMap<>();\n+        while ((line = br.readLine()) != null) {\n+            int index;\n+            index = line.indexOf(\"#\");\n+            if (index == 0) {\n+                continue;\n+            } else if (index != -1) {\n+                line = line.substring(0, index);\n+            }\n+\n+            index = line.lastIndexOf(\":\");\n+            if (index == -1) {\n+                LOG.warn(\"Malformed imageTagToManifest entry: \" + line);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY1NTMyOA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547655328", "bodyText": "The manifestPath seems to be a local file not HDFS.", "author": "bipinprasad", "createdAt": "2020-12-23T05:21:16Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"cache.refresh.interval.secs\";\n+\n+    /**\n+     * The number of manifests to cache.\n+     */\n+    private static String OCI_NUM_MANIFESTS_TO_CACHE = LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"num.manifests.to.cache\";\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";\n+\n+    @Override\n+    public void init(Map<String, Object> conf) throws IOException {\n+        this.conf = conf;\n+\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        localImageTagToHashFile = (String) conf.get(LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Failed to load local oci-image-to-hash file. Config not set\");\n+        }\n+        hdfsImageToHashFile = (String) conf.get(HDFS_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Failed to load HDFS oci-image-to-hash file. Config not set\");\n+        }\n+        if (hdfsImageToHashFile == null && localImageTagToHashFile == null) {\n+            throw new IllegalArgumentException(\"No valid image-tag-to-hash files\");\n+        }\n+        manifestDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR)) + \"/manifests/\";\n+        int numManifestsToCache = ObjectReader.getInt(conf.get(OCI_NUM_MANIFESTS_TO_CACHE), 10);\n+        this.objMapper = new ObjectMapper();\n+        this.manifestCache = new LruCache(numManifestsToCache, 0.75f);\n+        ociCacheRefreshIntervalSecs = ObjectReader.getInt(conf.get(OCI_CACHE_REFRESH_INTERVAL), 60);\n+    }\n+\n+    private boolean loadImageToHashFiles() throws IOException {\n+        boolean ret = false;\n+        try (BufferedReader localBr = getLocalImageToHashReader()) {\n+            Map<String, String> localImageToHash = readImageToHashFile(localBr);\n+            if (localImageToHash != null && !localImageToHash.equals(localImageToHashCache)) {\n+                localImageToHashCache = localImageToHash;\n+                LOG.info(\"Reloaded local image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+\n+        try (BufferedReader hdfsBr = getHdfsImageToHashReader()) {\n+            Map<String, String> hdfsImageToHash = readImageToHashFile(hdfsBr);\n+            if (hdfsImageToHash != null && !hdfsImageToHash.equals(hdfsImageToHashCache)) {\n+                hdfsImageToHashCache = hdfsImageToHash;\n+                LOG.info(\"Reloaded hdfs image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    private BufferedReader getLocalImageToHashReader() throws IOException {\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Did not load local image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        File imageTagToHashFile = new File(localImageTagToHashFile);\n+        if (!imageTagToHashFile.exists()) {\n+            LOG.warn(\"Did not load local image to hash file, file doesn't exist\");\n+            return null;\n+        }\n+\n+        long newLocalModTime = imageTagToHashFile.lastModified();\n+        if (newLocalModTime == localModTime) {\n+            LOG.debug(\"Did not load local image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        localModTime = newLocalModTime;\n+\n+        return new BufferedReader(new FileReader(imageTagToHashFile));\n+    }\n+\n+    private BufferedReader getHdfsImageToHashReader() throws IOException {\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        Path imageToHash = new Path(hdfsImageToHashFile);\n+        FileSystem fs = imageToHash.getFileSystem(new Configuration());\n+        if (!fs.exists(imageToHash)) {\n+            String message = \"Could not load hdfs image to hash file, \" + hdfsImageToHashFile + \" doesn't exist\";\n+            LOG.error(message);\n+            throw new IOException(message);\n+        }\n+\n+        long newHdfsModTime = fs.getFileStatus(imageToHash).getModificationTime();\n+        if (newHdfsModTime == hdfsModTime) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        hdfsModTime = newHdfsModTime;\n+\n+        return new BufferedReader(new InputStreamReader(fs.open(imageToHash)));\n+    }\n+\n+    // You may specify multiple tags per hash all on the same line.\n+    // Comments are allowed using #. Anything after this character will not\n+    // be read\n+    // Example file:\n+    // foo/bar:current,fizz/gig:latest:123456789\n+    // #this/line:wont,be:parsed:2378590895\n+    //\n+    // This will map both foo/bar:current and fizz/gig:latest to 123456789\n+    private static Map<String, String> readImageToHashFile(BufferedReader br) throws IOException {\n+        if (br == null) {\n+            return null;\n+        }\n+\n+        String line;\n+        Map<String, String> imageToHashCache = new HashMap<>();\n+        while ((line = br.readLine()) != null) {\n+            int index;\n+            index = line.indexOf(\"#\");\n+            if (index == 0) {\n+                continue;\n+            } else if (index != -1) {\n+                line = line.substring(0, index);\n+            }\n+\n+            index = line.lastIndexOf(\":\");\n+            if (index == -1) {\n+                LOG.warn(\"Malformed imageTagToManifest entry: \" + line);\n+                continue;\n+            }\n+            String imageTags = line.substring(0, index);\n+            String[] imageTagArray = imageTags.split(\",\");\n+            String hash = line.substring(index + 1);\n+\n+            if (!hash.matches(ALPHA_NUMERIC) || hash.length() != SHA256_HASH_LENGTH) {\n+                LOG.warn(\"Malformed image hash: \" + hash);\n+                continue;\n+            }\n+\n+            for (String imageTag : imageTagArray) {\n+                imageToHashCache.put(imageTag, hash);\n+            }\n+        }\n+        return imageToHashCache;\n+    }\n+\n+\n+    @Override\n+    public synchronized ImageManifest getManifestFromImageTag(String imageTag) throws IOException {\n+        String hash = getHashFromImageTag(imageTag);\n+        ImageManifest manifest = manifestCache.get(hash);\n+        if (manifest != null) {\n+            return manifest;\n+        }\n+        Path manifestPath = new Path(manifestDir + hash);\n+        FileSystem fs = manifestPath.getFileSystem(new Configuration());\n+        FSDataInputStream input;\n+        try {\n+            input = fs.open(manifestPath);\n+        } catch (IllegalArgumentException iae) {\n+            throw new IOException(\"Manifest file is not a valid HDFS file: \"\n+                + manifestPath.toString(), iae);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzIyMzEyNw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r667223127", "bodyText": "This is on HDFS.\nsee\nmanifestDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR)) + \"/manifests/\";", "author": "Ethanlm", "createdAt": "2021-07-09T21:37:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY1NTMyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY2Mzc4Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r547663782", "bodyText": "does this \"final\" do anything here?", "author": "bipinprasad", "createdAt": "2020-12-23T05:32:55Z", "path": "storm-client/src/jvm/org/apache/storm/daemon/supervisor/ClientSupervisorUtils.java", "diffHunk": "@@ -61,10 +61,15 @@ static boolean doRequiredTopoFilesExist(Map<String, Object> conf, String stormId\n     }\n \n     public static int processLauncherAndWait(Map<String, Object> conf, String user, List<String> args,\n-                                             final Map<String, String> environment, final String logPreFix)\n+                                             final Map<String, String> environment, final String logPreFix) throws IOException {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzIyMzg1MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r667223851", "bodyText": "I think it prevents the variable to be changed inside the method. Don't think it is very important so just left it as it is", "author": "Ethanlm", "createdAt": "2021-07-09T21:39:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzY2Mzc4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5NTg4OQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548495889", "bodyText": "Code duplicated in getConfigResource(). Should this be a method?", "author": "bipinprasad", "createdAt": "2020-12-24T11:09:23Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/HdfsManifestToResourcesPlugin.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nonnull;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+\n+public class HdfsManifestToResourcesPlugin implements OciManifestToResourcesPluginInterface {\n+\n+    private String layersDir;\n+    private String configDir;\n+    private FileSystem fs;\n+    private LoadingCache<Path, FileStatus> statCache;\n+\n+    private static String CONFIG_MEDIA_TYPE = \"application/vnd.docker.container.image.v1+json\";\n+\n+    private static String LAYER_TAR_GZIP_MEDIA_TYPE = \"application/vnd.docker.image.rootfs.diff.tar.gzip\";\n+\n+    private static String SHA_256 = \"sha256\";\n+\n+    private static String CONFIG_HASH_ALGORITHM = SHA_256;\n+\n+    private static String LAYER_HASH_ALGORITHM = SHA_256;\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";\n+\n+    @Override\n+    public void init(Map<String, Object> conf) throws IOException {\n+\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        String topLevelDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR));\n+\n+        this.layersDir = topLevelDir + \"/layers/\";\n+        this.configDir = topLevelDir + \"/config/\";\n+\n+        this.fs = new Path(topLevelDir).getFileSystem(new Configuration());\n+\n+        CacheLoader<Path, FileStatus> cacheLoader =\n+            new CacheLoader<Path, FileStatus>() {\n+                @Override\n+                public FileStatus load(@Nonnull Path path) throws Exception {\n+                    return statBlob(path);\n+                }\n+            };\n+        this.statCache = CacheBuilder.newBuilder().maximumSize(30)\n+            .refreshAfterWrite(60, TimeUnit.MINUTES).build(cacheLoader);\n+    }\n+\n+    @Override\n+    public List<OciResource> getLayerResources(ImageManifest manifest) throws IOException {\n+        List<OciResource> ociResources = new ArrayList<>();\n+        for (ImageManifest.Blob blob : manifest.getLayers()) {\n+            String mediaType = blob.getMediaType();\n+            if (!mediaType.equals(LAYER_TAR_GZIP_MEDIA_TYPE)) {\n+                throw new IOException(\"Invalid config mediaType: \" + mediaType);\n+            }\n+\n+            String[] layerDigest = blob.getDigest().split(\":\", 2);\n+            String algorithm = layerDigest[0];\n+            if (!algorithm.equals(LAYER_HASH_ALGORITHM)) {\n+                throw new IOException(\"Invalid config digest algorithm: \" + algorithm);\n+            }\n+\n+            String hash = layerDigest[1];\n+            if (!hash.matches(ALPHA_NUMERIC) || hash.length() != SHA256_HASH_LENGTH) {\n+                throw new IOException(\"Malformed layer digest: \" + hash);\n+            }\n+", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTkyMjYyMQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671922621", "bodyText": "There are many variables involved. using one method is fine but might explore it as a follow-up", "author": "Ethanlm", "createdAt": "2021-07-19T00:29:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5NTg4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5NjQxMA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548496410", "bodyText": "These can be final", "author": "bipinprasad", "createdAt": "2020-12-24T11:11:41Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/HdfsManifestToResourcesPlugin.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.google.common.cache.CacheBuilder;\n+import com.google.common.cache.CacheLoader;\n+import com.google.common.cache.LoadingCache;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nonnull;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+\n+public class HdfsManifestToResourcesPlugin implements OciManifestToResourcesPluginInterface {\n+\n+    private String layersDir;\n+    private String configDir;\n+    private FileSystem fs;\n+    private LoadingCache<Path, FileStatus> statCache;\n+\n+    private static String CONFIG_MEDIA_TYPE = \"application/vnd.docker.container.image.v1+json\";\n+\n+    private static String LAYER_TAR_GZIP_MEDIA_TYPE = \"application/vnd.docker.image.rootfs.diff.tar.gzip\";\n+\n+    private static String SHA_256 = \"sha256\";\n+\n+    private static String CONFIG_HASH_ALGORITHM = SHA_256;\n+\n+    private static String LAYER_HASH_ALGORITHM = SHA_256;\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5NzM4MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548497381", "bodyText": "nit: return value is not checked for failure", "author": "bipinprasad", "createdAt": "2020-12-24T11:15:16Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/HdfsOciResourcesLocalizer.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import org.apache.commons.io.FileDeleteStrategy;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class HdfsOciResourcesLocalizer implements OciResourcesLocalizerInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(HdfsOciResourcesLocalizer.class);\n+    private static final int LOCALIZE_MAX_RETRY = 5;\n+    private String layersLocalDir;\n+    private String configLocalDir;\n+    private FileSystem fs;\n+\n+    /**\n+     * Initialization.\n+     * @param conf the storm conf.\n+     * @throws IOException on I/O exception\n+     */\n+    public void init(Map<String, Object> conf) throws IOException {\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        String resourcesLocalDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCAL_DIR),\n+            ConfigUtils.supervisorLocalDir(conf) + \"/oci-resources\");\n+        FileUtils.forceMkdir(new File(resourcesLocalDir));\n+        this.layersLocalDir = resourcesLocalDir + \"/layers/\";\n+        this.configLocalDir = resourcesLocalDir + \"/config/\";\n+        String topLevelDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR));\n+        this.fs = new Path(topLevelDir).getFileSystem(new Configuration());\n+    }\n+\n+    /**\n+     * Download the resources from HDFS to local dir.\n+     * @param ociResource The oci resource to download\n+     * @return the destination of the oci resource\n+     * @throws IOException on I/O exception\n+     */\n+    public synchronized String localize(OciResource ociResource) throws IOException {\n+        if (ociResource == null) {\n+            return null;\n+        }\n+        File dst;\n+        switch (ociResource.getType()) {\n+            case CONFIG:\n+                dst = new File(this.configLocalDir, ociResource.getFileName());\n+                break;\n+            case LAYER:\n+                dst = new File(layersLocalDir, ociResource.getFileName());\n+                break;\n+            default:\n+                throw new IOException(\"unknown OciResourceType \" + ociResource.getType());\n+        }\n+\n+        if (dst.exists()) {\n+            LOG.info(\"{} already exists. Skip\", dst);\n+        } else {\n+            // create working dir, copy file here, and set readable, then move to final location.\n+            // this allows the operation to be atomic in case the supervisor dies.\n+            File workingDir = new File(dst.getParent() + \"/working\");\n+            workingDir.mkdir();", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5NzQyNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548497425", "bodyText": "nit: return value is not checked for failure", "author": "bipinprasad", "createdAt": "2020-12-24T11:15:28Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/HdfsOciResourcesLocalizer.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Map;\n+\n+import org.apache.commons.io.FileDeleteStrategy;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class HdfsOciResourcesLocalizer implements OciResourcesLocalizerInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(HdfsOciResourcesLocalizer.class);\n+    private static final int LOCALIZE_MAX_RETRY = 5;\n+    private String layersLocalDir;\n+    private String configLocalDir;\n+    private FileSystem fs;\n+\n+    /**\n+     * Initialization.\n+     * @param conf the storm conf.\n+     * @throws IOException on I/O exception\n+     */\n+    public void init(Map<String, Object> conf) throws IOException {\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        String resourcesLocalDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCAL_DIR),\n+            ConfigUtils.supervisorLocalDir(conf) + \"/oci-resources\");\n+        FileUtils.forceMkdir(new File(resourcesLocalDir));\n+        this.layersLocalDir = resourcesLocalDir + \"/layers/\";\n+        this.configLocalDir = resourcesLocalDir + \"/config/\";\n+        String topLevelDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR));\n+        this.fs = new Path(topLevelDir).getFileSystem(new Configuration());\n+    }\n+\n+    /**\n+     * Download the resources from HDFS to local dir.\n+     * @param ociResource The oci resource to download\n+     * @return the destination of the oci resource\n+     * @throws IOException on I/O exception\n+     */\n+    public synchronized String localize(OciResource ociResource) throws IOException {\n+        if (ociResource == null) {\n+            return null;\n+        }\n+        File dst;\n+        switch (ociResource.getType()) {\n+            case CONFIG:\n+                dst = new File(this.configLocalDir, ociResource.getFileName());\n+                break;\n+            case LAYER:\n+                dst = new File(layersLocalDir, ociResource.getFileName());\n+                break;\n+            default:\n+                throw new IOException(\"unknown OciResourceType \" + ociResource.getType());\n+        }\n+\n+        if (dst.exists()) {\n+            LOG.info(\"{} already exists. Skip\", dst);\n+        } else {\n+            // create working dir, copy file here, and set readable, then move to final location.\n+            // this allows the operation to be atomic in case the supervisor dies.\n+            File workingDir = new File(dst.getParent() + \"/working\");\n+            workingDir.mkdir();\n+            File workingDst = new File(workingDir.getPath() + \"/\" + dst.getName());\n+\n+            LOG.info(\"Starting to copy {} from hdfs to {}\", ociResource.getPath(), workingDst.toString());\n+            copyFileLocallyWithRetry(ociResource, workingDst);\n+            LOG.info(\"Successfully finished copying {} from hdfs to {}\", ociResource.getPath(), workingDst.toString());\n+\n+            //set to readable by anyone\n+            boolean setReadable = workingDst.setReadable(true, false);\n+            if (!setReadable) {\n+                throw new IOException(\"Couldn't set \" + workingDst + \" to be world-readable\");\n+            }\n+            workingDst.renameTo(dst);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5ODcxOQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548498719", "bodyText": "Can be final", "author": "bipinprasad", "createdAt": "2020-12-24T11:19:37Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"cache.refresh.interval.secs\";\n+\n+    /**\n+     * The number of manifests to cache.\n+     */\n+    private static String OCI_NUM_MANIFESTS_TO_CACHE = LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"num.manifests.to.cache\";\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODQ5OTA0NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548499045", "bodyText": "Class can be static", "author": "bipinprasad", "createdAt": "2020-12-24T11:20:46Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"cache.refresh.interval.secs\";\n+\n+    /**\n+     * The number of manifests to cache.\n+     */\n+    private static String OCI_NUM_MANIFESTS_TO_CACHE = LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"num.manifests.to.cache\";\n+\n+    private static int SHA256_HASH_LENGTH = 64;\n+\n+    private static String ALPHA_NUMERIC = \"[a-zA-Z0-9]+\";\n+\n+    @Override\n+    public void init(Map<String, Object> conf) throws IOException {\n+        this.conf = conf;\n+\n+        //login to hdfs\n+        HadoopLoginUtil.loginHadoop(conf);\n+\n+        localImageTagToHashFile = (String) conf.get(LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Failed to load local oci-image-to-hash file. Config not set\");\n+        }\n+        hdfsImageToHashFile = (String) conf.get(HDFS_OCI_IMAGE_TAG_TO_HASH_FILE);\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Failed to load HDFS oci-image-to-hash file. Config not set\");\n+        }\n+        if (hdfsImageToHashFile == null && localImageTagToHashFile == null) {\n+            throw new IllegalArgumentException(\"No valid image-tag-to-hash files\");\n+        }\n+        manifestDir = ObjectReader.getString(conf.get(DaemonConfig.STORM_OCI_IMAGE_HDFS_TOPLEVEL_DIR)) + \"/manifests/\";\n+        int numManifestsToCache = ObjectReader.getInt(conf.get(OCI_NUM_MANIFESTS_TO_CACHE), 10);\n+        this.objMapper = new ObjectMapper();\n+        this.manifestCache = new LruCache(numManifestsToCache, 0.75f);\n+        ociCacheRefreshIntervalSecs = ObjectReader.getInt(conf.get(OCI_CACHE_REFRESH_INTERVAL), 60);\n+    }\n+\n+    private boolean loadImageToHashFiles() throws IOException {\n+        boolean ret = false;\n+        try (BufferedReader localBr = getLocalImageToHashReader()) {\n+            Map<String, String> localImageToHash = readImageToHashFile(localBr);\n+            if (localImageToHash != null && !localImageToHash.equals(localImageToHashCache)) {\n+                localImageToHashCache = localImageToHash;\n+                LOG.info(\"Reloaded local image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+\n+        try (BufferedReader hdfsBr = getHdfsImageToHashReader()) {\n+            Map<String, String> hdfsImageToHash = readImageToHashFile(hdfsBr);\n+            if (hdfsImageToHash != null && !hdfsImageToHash.equals(hdfsImageToHashCache)) {\n+                hdfsImageToHashCache = hdfsImageToHash;\n+                LOG.info(\"Reloaded hdfs image tag to hash cache\");\n+                ret = true;\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    private BufferedReader getLocalImageToHashReader() throws IOException {\n+        if (localImageTagToHashFile == null) {\n+            LOG.debug(\"Did not load local image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        File imageTagToHashFile = new File(localImageTagToHashFile);\n+        if (!imageTagToHashFile.exists()) {\n+            LOG.warn(\"Did not load local image to hash file, file doesn't exist\");\n+            return null;\n+        }\n+\n+        long newLocalModTime = imageTagToHashFile.lastModified();\n+        if (newLocalModTime == localModTime) {\n+            LOG.debug(\"Did not load local image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        localModTime = newLocalModTime;\n+\n+        return new BufferedReader(new FileReader(imageTagToHashFile));\n+    }\n+\n+    private BufferedReader getHdfsImageToHashReader() throws IOException {\n+        if (hdfsImageToHashFile == null) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is null\");\n+            return null;\n+        }\n+\n+        Path imageToHash = new Path(hdfsImageToHashFile);\n+        FileSystem fs = imageToHash.getFileSystem(new Configuration());\n+        if (!fs.exists(imageToHash)) {\n+            String message = \"Could not load hdfs image to hash file, \" + hdfsImageToHashFile + \" doesn't exist\";\n+            LOG.error(message);\n+            throw new IOException(message);\n+        }\n+\n+        long newHdfsModTime = fs.getFileStatus(imageToHash).getModificationTime();\n+        if (newHdfsModTime == hdfsModTime) {\n+            LOG.debug(\"Did not load hdfs image to hash file, file is unmodified\");\n+            return null;\n+        }\n+        hdfsModTime = newHdfsModTime;\n+\n+        return new BufferedReader(new InputStreamReader(fs.open(imageToHash)));\n+    }\n+\n+    // You may specify multiple tags per hash all on the same line.\n+    // Comments are allowed using #. Anything after this character will not\n+    // be read\n+    // Example file:\n+    // foo/bar:current,fizz/gig:latest:123456789\n+    // #this/line:wont,be:parsed:2378590895\n+    //\n+    // This will map both foo/bar:current and fizz/gig:latest to 123456789\n+    private static Map<String, String> readImageToHashFile(BufferedReader br) throws IOException {\n+        if (br == null) {\n+            return null;\n+        }\n+\n+        String line;\n+        Map<String, String> imageToHashCache = new HashMap<>();\n+        while ((line = br.readLine()) != null) {\n+            int index;\n+            index = line.indexOf(\"#\");\n+            if (index == 0) {\n+                continue;\n+            } else if (index != -1) {\n+                line = line.substring(0, index);\n+            }\n+\n+            index = line.lastIndexOf(\":\");\n+            if (index == -1) {\n+                LOG.warn(\"Malformed imageTagToManifest entry: \" + line);\n+                continue;\n+            }\n+            String imageTags = line.substring(0, index);\n+            String[] imageTagArray = imageTags.split(\",\");\n+            String hash = line.substring(index + 1);\n+\n+            if (!hash.matches(ALPHA_NUMERIC) || hash.length() != SHA256_HASH_LENGTH) {\n+                LOG.warn(\"Malformed image hash: \" + hash);\n+                continue;\n+            }\n+\n+            for (String imageTag : imageTagArray) {\n+                imageToHashCache.put(imageTag, hash);\n+            }\n+        }\n+        return imageToHashCache;\n+    }\n+\n+\n+    @Override\n+    public synchronized ImageManifest getManifestFromImageTag(String imageTag) throws IOException {\n+        String hash = getHashFromImageTag(imageTag);\n+        ImageManifest manifest = manifestCache.get(hash);\n+        if (manifest != null) {\n+            return manifest;\n+        }\n+        Path manifestPath = new Path(manifestDir + hash);\n+        FileSystem fs = manifestPath.getFileSystem(new Configuration());\n+        FSDataInputStream input;\n+        try {\n+            input = fs.open(manifestPath);\n+        } catch (IllegalArgumentException iae) {\n+            throw new IOException(\"Manifest file is not a valid HDFS file: \"\n+                + manifestPath.toString(), iae);\n+        }\n+\n+        byte[] bytes = IOUtils.toByteArray(input);\n+        manifest = objMapper.readValue(bytes, ImageManifest.class);\n+\n+        manifestCache.put(hash, manifest);\n+        return manifest;\n+    }\n+\n+    @Override\n+    public synchronized String getHashFromImageTag(String imageTag) {\n+        String hash;\n+\n+        long currentTime = System.currentTimeMillis();\n+        if (currentTime - lastRefreshTime > Time.secsToMillis(ociCacheRefreshIntervalSecs)) {\n+            LOG.debug(\"Refreshing local and hdfs image-tag-to-hash cache\");\n+            try {\n+                boolean loaded = loadImageToHashFiles();\n+                //If this is the first time trying to load the files and yet it failed\n+                if (!loaded && lastRefreshTime == 0) {\n+                    throw new RuntimeException(\"Couldn't load any image-tag-to-hash-files\");\n+                }\n+                lastRefreshTime = currentTime;\n+            } catch (IOException e) {\n+                throw new RuntimeException(\"Couldn't load any image-tag-to-hash-files\", e);\n+            }\n+        }\n+\n+        // 1) Go to local file\n+        // 2) Go to HDFS\n+        // 3) Use tag as is/Assume tag is the hash\n+        if ((hash = localImageToHashCache.get(imageTag)) != null) {\n+            return hash;\n+        } else if ((hash = hdfsImageToHashCache.get(imageTag)) != null) {\n+            return hash;\n+        } else {\n+            return imageTag;\n+        }\n+    }\n+\n+    private class LruCache extends LinkedHashMap<String, ImageManifest> {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwMTU4Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548501586", "bodyText": "nit: consistent indent size of 4 spaces (or two as used here mostly)\nnit: stylewise, c code if expressions do not need a != 0 or != NULL part,\ni.e. \"if (file_stat.st_uid)\" instead of \"if (file_stat.st_uid != 0)\"", "author": "bipinprasad", "createdAt": "2020-12-24T11:29:55Z", "path": "storm-core/src/native/worker-launcher/impl/configuration.c", "diffHunk": "@@ -74,17 +74,17 @@ void free_configurations() {\n static int is_only_root_writable(const char *file) {\n   struct stat file_stat;\n   if (stat(file, &file_stat) != 0) {\n-    fprintf(ERRORFILE, \"Can't stat file %s - %s\\n\", file, strerror(errno));\n+    fprintf(ERRORFILE, \"ERROR: Can't stat file %s - %s\\n\", file, strerror(errno));", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwNDQ3NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548504474", "bodyText": "nit: why not the standard strcmp()?", "author": "bipinprasad", "createdAt": "2020-12-24T11:41:37Z", "path": "storm-core/src/native/worker-launcher/impl/main.c", "diffHunk": "@@ -269,6 +274,45 @@ int main(int argc, char **argv) {\n       return INVALID_ARGUMENT_NUMBER;\n     }\n     exit_code = signal_container_as_user(user_detail->pw_name, container_pid, signal);\n+  } else if (strcasecmp(\"run-oci-container\", command) == 0) {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA1NDU4Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669054586", "bodyText": "I don't have strong opinion on making it case-sensitive. But we have been using case-insensitive in other commands here, didn't think of changing it. case-insensitive is fine with me.", "author": "Ethanlm", "createdAt": "2021-07-13T19:36:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwNDQ3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwNTc2Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548505766", "bodyText": "nit: log and error files are closed before return for most cases. set exit_code here also?", "author": "bipinprasad", "createdAt": "2020-12-24T11:46:39Z", "path": "storm-core/src/native/worker-launcher/impl/main.c", "diffHunk": "@@ -269,6 +274,45 @@ int main(int argc, char **argv) {\n       return INVALID_ARGUMENT_NUMBER;\n     }\n     exit_code = signal_container_as_user(user_detail->pw_name, container_pid, signal);\n+  } else if (strcasecmp(\"run-oci-container\", command) == 0) {\n+    if (argc != 6) {\n+      fprintf(ERRORFILE, \"Incorrect number of arguments (%d vs 6) for run-oci-container\\n\", argc);\n+      fflush(ERRORFILE);\n+      return INVALID_ARGUMENT_NUMBER;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA1NjE5OQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669056199", "bodyText": "I don't understand the question. Can you please elaborate?", "author": "Ethanlm", "createdAt": "2021-07-13T19:39:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwNTc2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MDAxMDA5Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r670010097", "bodyText": "Set the exit code to non-zero so that it is returned at the end of this function (where it properly closes open files). Although I don't think it is critical, since open files will be closed by the system on program exit.", "author": "bipinprasad", "createdAt": "2021-07-14T23:03:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwNTc2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTg5OTgwNA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671899804", "bodyText": "got it. Thanks", "author": "Ethanlm", "createdAt": "2021-07-18T21:26:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUwNTc2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUxNDEzMQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548514131", "bodyText": "This JSON validation function is not implemented. Can it be similar to is_valid_oci_config_linux() ?", "author": "bipinprasad", "createdAt": "2020-12-24T12:20:12Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_launch_cmd.c", "diffHunk": "@@ -0,0 +1,544 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <stdbool.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+#include \"utils/string-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"oci_launch_cmd.h\"\n+\n+#define SQUASHFS_MEDIA_TYPE     \"application/vnd.squashfs\"\n+\n+static void free_olc_layers(olc_layer_spec* layers, unsigned int num_layers) {\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    free(layers[i].media_type);\n+    free(layers[i].path);\n+  }\n+  free(layers);\n+}\n+\n+/**\n+ * Free an OCI launch command structure and all memory associated with it.\n+ */\n+void free_oci_launch_cmd(oci_launch_cmd* olc) {\n+  if (olc != NULL) {\n+    free(olc->username);\n+    free(olc->container_id);\n+    free(olc->pid_file);\n+    free(olc->script_path);\n+    free_olc_layers(olc->layers, olc->num_layers);\n+    cJSON_Delete(olc->config.hostname);\n+    cJSON_Delete(olc->config.linux_config);\n+    cJSON_Delete(olc->config.mounts);\n+    cJSON_Delete(olc->config.process.args);\n+    cJSON_Delete(olc->config.process.cwd);\n+    cJSON_Delete(olc->config.process.env);\n+    free(olc);\n+  }\n+}\n+\n+static cJSON* parse_json_file(const char* filename) {\n+  char* data = read_file_to_string_as_wl_user(filename);\n+  if (data == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot read command file %s\\n\", filename);\n+    return NULL;\n+  }\n+\n+  const char* parse_error_location = NULL;\n+  cJSON* json = cJSON_ParseWithOpts(data, &parse_error_location, 1);\n+  if (json == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Error parsing command file %s at byte offset %ld\\n\",\n+        filename, parse_error_location - data);\n+  }\n+\n+  free(data);\n+  return json;\n+}\n+\n+static bool parse_oci_launch_cmd_layer(olc_layer_spec* layer_out,\n+    const cJSON* layer_json) {\n+  if (!cJSON_IsObject(layer_json)) {\n+    fputs(\"ERROR: OCI launch command layer is not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* media_type_json = cJSON_GetObjectItemCaseSensitive(layer_json,\n+      \"mediaType\");\n+  if (!cJSON_IsString(media_type_json)) {\n+    fputs(\"ERROR: Bad/Missing media type for OCI launch command layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* path_json = cJSON_GetObjectItemCaseSensitive(layer_json, \"path\");\n+  if (!cJSON_IsString(path_json)) {\n+    fputs(\"ERROR: Bad/Missing path for OCI launch command layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  layer_out->media_type = strdup(media_type_json->valuestring);\n+  layer_out->path = strdup(path_json->valuestring);\n+  return true;\n+}\n+\n+static olc_layer_spec* parse_oci_launch_cmd_layers(unsigned int* num_layers_out,\n+    const cJSON* layers_json) {\n+  if (!cJSON_IsArray(layers_json)) {\n+    fputs(\"ERROR: Bad/Missing OCI launch command layers\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+\n+  unsigned int num_layers = (unsigned int) cJSON_GetArraySize(layers_json);\n+  if (num_layers <= 0) {\n+    return NULL;\n+  }\n+\n+  olc_layer_spec* layers = calloc(num_layers, sizeof(*layers));\n+  if (layers == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot allocate memory for %d layers\\n\",\n+        num_layers + 1);\n+    return NULL;\n+  }\n+\n+  unsigned int layer_index = 0;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, layers_json) {\n+    if (layer_index >= num_layers) {\n+      fputs(\"ERROR: Iterating past end of layer array\\n\", ERRORFILE);\n+      free_olc_layers(layers, layer_index);\n+      return NULL;\n+    }\n+\n+    if (!parse_oci_launch_cmd_layer(&layers[layer_index], e)) {\n+      free_olc_layers(layers, layer_index);\n+      return NULL;\n+    }\n+\n+    ++layer_index;\n+  }\n+\n+  *num_layers_out = layer_index;\n+  return layers;\n+}\n+\n+static int parse_reap_layers_keep(cJSON* json) {\n+  if (!cJSON_IsNumber(json)) {\n+    fputs(\"ERROR: Bad/Missing OCI reap layer keep number\\n\", ERRORFILE);\n+    return -1;\n+  }\n+  return json->valueint;\n+}\n+\n+static void parse_oci_launch_cmd_oci_config(oci_config* oc, cJSON* oc_json) {\n+  if (!cJSON_IsObject(oc_json)) {\n+    fputs(\"ERROR: Bad/Missing OCI runtime config in launch command\\n\", ERRORFILE);\n+    return;\n+  }\n+  oc->hostname = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"hostname\");\n+  oc->linux_config = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"linux\");\n+  oc->mounts = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"mounts\");\n+\n+  cJSON* process_json = cJSON_GetObjectItemCaseSensitive(oc_json, \"process\");\n+  if (!cJSON_IsObject(process_json)) {\n+    fputs(\"ERROR: Bad/Missing process section in OCI config\\n\", ERRORFILE);\n+    return;\n+  }\n+  oc->process.args = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"args\");\n+  oc->process.cwd = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"cwd\");\n+  oc->process.env = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"env\");\n+}\n+\n+static bool is_valid_layer_media_type(char* media_type) {\n+  if (media_type == NULL) {\n+    return false;\n+  }\n+\n+  if (strcmp(SQUASHFS_MEDIA_TYPE, media_type)) {\n+    fprintf(ERRORFILE, \"ERROR: Unrecognized layer media type: %s\\n\", media_type);\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_launch_cmd_layers(olc_layer_spec* layers,\n+    unsigned int num_layers) {\n+  if (layers == NULL) {\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!is_valid_layer_media_type(layers[i].media_type)) {\n+      return false;\n+    }\n+    if (layers[i].path == NULL) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_linux_resources(const cJSON* oclr) {\n+  if (!cJSON_IsObject(oclr)) {\n+    fputs(\"ERROR: OCI config linux resources missing or not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool all_sections_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, oclr) {\n+    if (strcmp(\"blockIO\", e->string) == 0) {\n+      // block I/O settings allowed\n+    } else if (strcmp(\"cpu\", e->string) == 0) {\n+      // cpu settings allowed\n+    } else if (strcmp(\"memory\", e->string) == 0) {\n+      // memory settings allowed. (added for storm. hadoop doesn't allow this)\n+    } else {\n+      fprintf(ERRORFILE,\n+          \"ERROR: Unrecognized OCI config linux resources element: %s\\n\", e->string);\n+      all_sections_ok = false;\n+    }\n+  }\n+\n+  return all_sections_ok;\n+}\n+\n+static bool is_valid_oci_config_linux_seccomp(const cJSON* ocls) {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA1Njk5MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669056990", "bodyText": "validating secomp file is a little more involved so leaving it for future.", "author": "Ethanlm", "createdAt": "2021-07-13T19:40:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUxNDEzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUyMjczOA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548522738", "bodyText": "nit: why is the method named storm_user_info(). Same question for storm_user_info.c and storm_user_info.h. They seem to be generic user_info query functions and nothing storm specific.", "author": "bipinprasad", "createdAt": "2020-12-24T12:55:05Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_write_config.c", "diffHunk": "@@ -0,0 +1,464 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/utsname.h>\n+#include <stdarg.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+#include \"utils/storm_user_info.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_write_config.h\"\n+\n+#define RUNC_CONFIG_FILENAME    \"config.json\"\n+#define STARTING_JSON_BUFFER_SIZE  (128*1024)\n+\n+\n+static cJSON* build_runc_config_root(const char* rootfs_path) {\n+  cJSON* root = cJSON_CreateObject();\n+  if (cJSON_AddStringToObject(root, \"path\", rootfs_path) == NULL) {\n+    goto fail;\n+  }\n+  if (cJSON_AddTrueToObject(root, \"readonly\") == NULL) {\n+    goto fail;\n+  }\n+  return root;\n+\n+fail:\n+  cJSON_Delete(root);\n+  return NULL;\n+}\n+\n+static cJSON* build_runc_config_process_user(const char* username) {\n+  cJSON* user_json = cJSON_CreateObject();\n+  struct storm_user_info* sui = storm_user_info_alloc();\n+  if (sui == NULL) {\n+    return NULL;\n+  }\n+\n+  int rc = storm_user_info_fetch(sui, username);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTkyMzIzOA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671923238", "bodyText": "will make it generic", "author": "Ethanlm", "createdAt": "2021-07-19T00:33:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUyMjczOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUyNjkxOQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548526919", "bodyText": "when is this supposed to happen?", "author": "bipinprasad", "createdAt": "2020-12-24T13:13:09Z", "path": "storm-core/src/native/worker-launcher/impl/utils/file-utils.c", "diffHunk": "@@ -0,0 +1,182 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#define FILE_BUFFER_INCREMENT (128*1024)\n+\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"file-utils.h\"\n+\n+/**\n+ * Read the contents of the specified file into an allocated buffer and return\n+ * the contents as a NUL-terminated string. NOTE: The file contents must not\n+ * contain a NUL character or the result will appear to be truncated.\n+ *\n+ * Returns a pointer to the allocated, NUL-terminated string or NULL on error.\n+ */\n+char* read_file_to_string(const char* filename) {\n+  char* buff = NULL;\n+  int rc = -1;\n+  int fd = open(filename, O_RDONLY);\n+  if (fd < 0) {\n+    fprintf(ERRORFILE, \"Error opening %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  struct stat filestat;\n+  if (fstat(fd, &filestat) != 0) {\n+    fprintf(ERRORFILE, \"Error examining %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  size_t buff_size = FILE_BUFFER_INCREMENT;\n+  if (S_ISREG(filestat.st_mode)) {\n+    buff_size = filestat.st_size + 1;  // +1 for terminating NUL\n+  }\n+  buff = malloc(buff_size);\n+  if (buff == NULL) {\n+    fprintf(ERRORFILE, \"Unable to allocate %ld bytes\\n\", buff_size);\n+    goto cleanup;\n+  }\n+\n+  int bytes_left = buff_size;\n+  char* cp = buff;\n+  int bytes_read;\n+  while ((bytes_read = read(fd, cp, bytes_left)) > 0) {\n+    cp += bytes_read;\n+    bytes_left -= bytes_read;\n+    if (bytes_left == 0) {\n+      buff_size += FILE_BUFFER_INCREMENT;\n+      bytes_left += FILE_BUFFER_INCREMENT;\n+      buff = realloc(buff, buff_size);\n+      if (buff == NULL) {\n+        fprintf(ERRORFILE, \"Unable to allocate %ld bytes\\n\", buff_size);\n+        goto cleanup;\n+      }\n+    }\n+  }\n+  if (bytes_left < 0) {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA4MDU3NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669080574", "bodyText": "I think this is not needed as bytes_left will always be not less than bytes_read. will remove", "author": "Ethanlm", "createdAt": "2021-07-13T20:19:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUyNjkxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUyODk0MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548528941", "bodyText": "Add info about exiting, like: \"ERROR:EXITING process: failed to allocate.....\" because of the next exit() call.", "author": "bipinprasad", "createdAt": "2020-12-24T13:21:14Z", "path": "storm-core/src/native/worker-launcher/impl/utils/file-utils.c", "diffHunk": "@@ -0,0 +1,182 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#define FILE_BUFFER_INCREMENT (128*1024)\n+\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"file-utils.h\"\n+\n+/**\n+ * Read the contents of the specified file into an allocated buffer and return\n+ * the contents as a NUL-terminated string. NOTE: The file contents must not\n+ * contain a NUL character or the result will appear to be truncated.\n+ *\n+ * Returns a pointer to the allocated, NUL-terminated string or NULL on error.\n+ */\n+char* read_file_to_string(const char* filename) {\n+  char* buff = NULL;\n+  int rc = -1;\n+  int fd = open(filename, O_RDONLY);\n+  if (fd < 0) {\n+    fprintf(ERRORFILE, \"Error opening %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  struct stat filestat;\n+  if (fstat(fd, &filestat) != 0) {\n+    fprintf(ERRORFILE, \"Error examining %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  size_t buff_size = FILE_BUFFER_INCREMENT;\n+  if (S_ISREG(filestat.st_mode)) {\n+    buff_size = filestat.st_size + 1;  // +1 for terminating NUL\n+  }\n+  buff = malloc(buff_size);\n+  if (buff == NULL) {\n+    fprintf(ERRORFILE, \"Unable to allocate %ld bytes\\n\", buff_size);\n+    goto cleanup;\n+  }\n+\n+  int bytes_left = buff_size;\n+  char* cp = buff;\n+  int bytes_read;\n+  while ((bytes_read = read(fd, cp, bytes_left)) > 0) {\n+    cp += bytes_read;\n+    bytes_left -= bytes_read;\n+    if (bytes_left == 0) {\n+      buff_size += FILE_BUFFER_INCREMENT;\n+      bytes_left += FILE_BUFFER_INCREMENT;\n+      buff = realloc(buff, buff_size);\n+      if (buff == NULL) {\n+        fprintf(ERRORFILE, \"Unable to allocate %ld bytes\\n\", buff_size);\n+        goto cleanup;\n+      }\n+    }\n+  }\n+  if (bytes_left < 0) {\n+    fprintf(ERRORFILE, \"Error reading %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  *cp = '\\0';\n+  rc = 0;\n+\n+cleanup:\n+  if (fd != -1) {\n+    close(fd);\n+  }\n+  if (rc != 0) {\n+    free(buff);\n+    buff = NULL;\n+  }\n+  return buff;\n+}\n+\n+/**\n+ * Read a file to a string as the worker-launcher user and returns the\n+ * result as a string. See read_file_to_string for more details.\n+ *\n+ * Returns a pointer to the allocated, NUL-terminated string or NULL on error.\n+ */\n+char* read_file_to_string_as_wl_user(const char* filename) {\n+  uid_t user = geteuid();\n+  gid_t group = getegid();\n+  if (change_effective_user_to_wl() != 0) {\n+    fputs(\"Cannot change to worker-launcher user\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+\n+  char* buff = read_file_to_string(filename);\n+  if (change_effective_user(user, group) != 0) {\n+    fputs(\"Cannot revert to previous user\\n\", ERRORFILE);\n+    free(buff);\n+    return NULL;\n+  }\n+  return buff;\n+}\n+\n+/**\n+ * Write a sequence of bytes to a new file as the worker-launcher user.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+bool write_file_as_wl(const char* path, const void* data, size_t count) {\n+   bool result = false;\n+  int fd = -1;\n+  uid_t orig_user = geteuid();\n+  gid_t orig_group = getegid();\n+  if (change_effective_user_to_wl() != 0) {\n+    fputs(\"Error changing to worker-launcher user and group\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  fd = open(path, O_CREAT | O_EXCL | O_WRONLY, S_IRUSR | S_IWUSR);\n+  if (fd == -1) {\n+    fprintf(ERRORFILE, \"Error creating %s : %s\\n\", path, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  const uint8_t* bp = (const uint8_t*)data;\n+  while (count > 0) {\n+    ssize_t bytes_written = write(fd, bp, count);\n+    if (bytes_written == -1) {\n+      fprintf(ERRORFILE, \"Error writing to %s : %s\\n\", path, strerror(errno));\n+      goto cleanup;\n+    }\n+    bp += bytes_written;\n+    count -= bytes_written;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  if (fd != -1) {\n+    if (close(fd) == -1) {\n+      fprintf(ERRORFILE, \"Error writing to %s : %s\\n\", path, strerror(errno));\n+      result = false;\n+    }\n+  }\n+\n+  if (change_effective_user(orig_user, orig_group) != 0) {\n+    fputs(\"Cannot restore original user/group\\n\", ERRORFILE);\n+    result = false;\n+  }\n+\n+  return result;\n+}\n+\n+char *get_full_path(const char *dir, const char* file) {\n+  char *ret;\n+  int bytesPrinted = asprintf(&ret, \"%s/%s\", dir, file);\n+  if (bytesPrinted == -1) {\n+    fprintf(ERRORFILE, \"ERROR: failed to allocate file path\\n\");", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUzMDA4OQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548530089", "bodyText": "nit: change to all \"All negative return codes except -1 is considered as error\"", "author": "bipinprasad", "createdAt": "2020-12-24T13:25:58Z", "path": "storm-core/src/native/worker-launcher/impl/utils/storm_user_info.c", "diffHunk": "@@ -0,0 +1,275 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#include \"storm_user_info.h\"\n+\n+#include <errno.h>\n+#include <grp.h>\n+#include <pthread.h>\n+#include <pwd.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#define INITIAL_GIDS_SIZE 32\n+// 1KB buffer should be large enough to store a passwd record in most\n+// cases, but it can get bigger if each field is maximally used. The\n+// max is defined to avoid buggy libraries making us run out of memory.\n+#define MAX_USER_BUFFER_SIZE (32*1024)\n+\n+struct storm_user_info *storm_user_info_alloc(void)\n+{\n+  struct storm_user_info *uinfo;\n+  long buf_sz;\n+  char *buf;\n+\n+  uinfo = calloc(1, sizeof(struct storm_user_info));\n+  buf_sz = sysconf(_SC_GETPW_R_SIZE_MAX);\n+  if (buf_sz < 1024) {\n+    buf_sz = 1024;\n+  }\n+  buf = malloc(buf_sz);\n+  if (!buf) {\n+    free(uinfo);\n+    return NULL;\n+  }\n+  uinfo->buf_sz = buf_sz;\n+  uinfo->buf = buf;\n+  return uinfo;\n+}\n+\n+static void storm_user_info_clear(struct storm_user_info *uinfo)\n+{\n+  struct passwd *pwd = &uinfo->pwd;\n+\n+  pwd->pw_name = NULL;\n+  pwd->pw_uid = 0;\n+  pwd->pw_gid = 0;\n+  pwd->pw_passwd = NULL;\n+  pwd->pw_gecos = NULL;\n+  pwd->pw_dir = NULL;\n+  pwd->pw_shell = NULL;\n+  free(uinfo->gids);\n+  uinfo->gids = 0;\n+  uinfo->num_gids = 0;\n+  uinfo->gids_size = 0;\n+}\n+\n+void storm_user_info_free(struct storm_user_info *uinfo)\n+{\n+  free(uinfo->buf);\n+  storm_user_info_clear(uinfo);\n+  free(uinfo);\n+}\n+\n+/**\n+ * Different platforms use different error codes to represent \"user not found.\"\n+ * So whitelist the errors which do _not_ mean \"user not found.\"\n+ *\n+ * @param err           The errno\n+ *\n+ * @return              The error code to use\n+ */\n+static int getpwnam_error_translate(int err)\n+{\n+  if ((err == EIO) || (err == EMFILE) || (err == ENFILE) ||\n+      (err == ENOMEM) || (err == ERANGE)) {\n+    return err;\n+  }\n+  return ENOENT;\n+}\n+\n+int storm_user_info_fetch(struct storm_user_info *uinfo,\n+                           const char *username)\n+{\n+  struct passwd *pwd;\n+  int ret;\n+  size_t buf_sz;\n+  char *nbuf;\n+\n+  storm_user_info_clear(uinfo);\n+  for (;;) {\n+    // On success, the following call returns 0 and pwd is set to non-NULL.\n+    pwd = NULL;\n+    ret = getpwnam_r(username, &uinfo->pwd, uinfo->buf,\n+                         uinfo->buf_sz, &pwd);\n+    switch(ret) {\n+      case 0:\n+        if (!pwd) {\n+          // Not found.\n+          return ENOENT;\n+        }\n+        // Found.\n+        return 0;\n+      case EINTR:\n+        // EINTR: a signal was handled and this thread was allowed to continue.\n+        break;\n+      case ERANGE:\n+        // ERANGE: the buffer was not big enough.\n+        if (uinfo->buf_sz == MAX_USER_BUFFER_SIZE) {\n+          // Already tried with the max size.\n+          return ENOMEM;\n+        }\n+        buf_sz = uinfo->buf_sz * 2;\n+        if (buf_sz > MAX_USER_BUFFER_SIZE) {\n+          buf_sz = MAX_USER_BUFFER_SIZE;\n+        }\n+        nbuf = realloc(uinfo->buf, buf_sz);\n+        if (!nbuf) {\n+          return ENOMEM;\n+        }\n+        uinfo->buf = nbuf;\n+        uinfo->buf_sz = buf_sz;\n+        break;\n+      default:\n+        // Lookup failed.\n+        return getpwnam_error_translate(ret);\n+    }\n+  }\n+}\n+\n+static int put_primary_gid_first(struct storm_user_info *uinfo)\n+{\n+  int i, num_gids = uinfo->num_gids;\n+  gid_t first_gid;\n+  gid_t gid;\n+  gid_t primary = uinfo->pwd.pw_gid;\n+\n+  if (num_gids < 1) {\n+    // There are no gids, but we expected at least one.\n+    return EINVAL;\n+  }\n+  first_gid = uinfo->gids[0];\n+  if (first_gid == primary) {\n+    // First gid is already the primary.\n+    return 0;\n+  }\n+  for (i = 1; i < num_gids; i++) {\n+    gid = uinfo->gids[i];\n+    if (gid == primary) {\n+      // swap first gid and this gid.\n+      uinfo->gids[0] = gid;\n+      uinfo->gids[i] = first_gid;\n+      return 0;\n+    }\n+  }\n+  // Did not find the primary gid in the list.\n+  return EINVAL;\n+}\n+\n+int storm_user_info_getgroups(struct storm_user_info *uinfo)\n+{\n+  int ret, ngroups;\n+  gid_t *ngids;\n+\n+  if (!uinfo->pwd.pw_name) {\n+    // invalid user info\n+    return EINVAL;\n+  }\n+  uinfo->num_gids = 0;\n+  if (!uinfo->gids) {\n+    uinfo->gids = malloc(sizeof(uinfo->gids[0]) * INITIAL_GIDS_SIZE);\n+    if (!uinfo->gids) {\n+      return ENOMEM;\n+    }\n+    uinfo->gids_size = INITIAL_GIDS_SIZE;\n+  }\n+  ngroups = uinfo->gids_size;\n+  ret = getgrouplist(uinfo->pwd.pw_name, uinfo->pwd.pw_gid, \n+                         uinfo->gids, &ngroups);\n+  // Return value is different on Linux vs. FreeBSD.  Linux: the number of groups\n+  // or -1 on error.  FreeBSD: 0 on success or -1 on error.  Unfortunately, we\n+  // can't accept a 0 return on Linux, because buggy implementations have been\n+  // observed to return 0 but leave the other out parameters in an indeterminate\n+  // state.  This deviates from the man page, but it has been observed in\n+  // practice.  See issue HADOOP-10989 for details.\n+#ifdef __linux__\n+  if (ret > 0) {\n+#else\n+  if (ret >= 0) {\n+#endif\n+    uinfo->num_gids = ngroups;\n+    ret = put_primary_gid_first(uinfo);\n+    if (ret) {\n+      return ret;\n+    }\n+    return 0;\n+  } else if (ret != -1) {\n+    // Any return code that is not -1 is considered as error.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA5Mzc4OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669093788", "bodyText": "when it is on linux, we have\nif (ret > 0) {\n} else if (ret != -1) {\n    //ret could be zero\n}\n\nI will avoid causing confusion here. The original statement look fine to me.", "author": "Ethanlm", "createdAt": "2021-07-13T20:39:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUzMDA4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUzMDU3Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548530577", "bodyText": "nit: Is line break formatting based on 60 character line? Should be 80-120 for readability", "author": "bipinprasad", "createdAt": "2020-12-24T13:28:06Z", "path": "storm-core/src/native/worker-launcher/impl/utils/storm_user_info.c", "diffHunk": "@@ -0,0 +1,275 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#include \"storm_user_info.h\"\n+\n+#include <errno.h>\n+#include <grp.h>\n+#include <pthread.h>\n+#include <pwd.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#define INITIAL_GIDS_SIZE 32\n+// 1KB buffer should be large enough to store a passwd record in most\n+// cases, but it can get bigger if each field is maximally used. The\n+// max is defined to avoid buggy libraries making us run out of memory.\n+#define MAX_USER_BUFFER_SIZE (32*1024)\n+\n+struct storm_user_info *storm_user_info_alloc(void)\n+{\n+  struct storm_user_info *uinfo;\n+  long buf_sz;\n+  char *buf;\n+\n+  uinfo = calloc(1, sizeof(struct storm_user_info));\n+  buf_sz = sysconf(_SC_GETPW_R_SIZE_MAX);\n+  if (buf_sz < 1024) {\n+    buf_sz = 1024;\n+  }\n+  buf = malloc(buf_sz);\n+  if (!buf) {\n+    free(uinfo);\n+    return NULL;\n+  }\n+  uinfo->buf_sz = buf_sz;\n+  uinfo->buf = buf;\n+  return uinfo;\n+}\n+\n+static void storm_user_info_clear(struct storm_user_info *uinfo)\n+{\n+  struct passwd *pwd = &uinfo->pwd;\n+\n+  pwd->pw_name = NULL;\n+  pwd->pw_uid = 0;\n+  pwd->pw_gid = 0;\n+  pwd->pw_passwd = NULL;\n+  pwd->pw_gecos = NULL;\n+  pwd->pw_dir = NULL;\n+  pwd->pw_shell = NULL;\n+  free(uinfo->gids);\n+  uinfo->gids = 0;\n+  uinfo->num_gids = 0;\n+  uinfo->gids_size = 0;\n+}\n+\n+void storm_user_info_free(struct storm_user_info *uinfo)\n+{\n+  free(uinfo->buf);\n+  storm_user_info_clear(uinfo);\n+  free(uinfo);\n+}\n+\n+/**\n+ * Different platforms use different error codes to represent \"user not found.\"\n+ * So whitelist the errors which do _not_ mean \"user not found.\"\n+ *\n+ * @param err           The errno\n+ *\n+ * @return              The error code to use\n+ */\n+static int getpwnam_error_translate(int err)\n+{\n+  if ((err == EIO) || (err == EMFILE) || (err == ENFILE) ||\n+      (err == ENOMEM) || (err == ERANGE)) {\n+    return err;\n+  }\n+  return ENOENT;\n+}\n+\n+int storm_user_info_fetch(struct storm_user_info *uinfo,\n+                           const char *username)\n+{\n+  struct passwd *pwd;\n+  int ret;\n+  size_t buf_sz;\n+  char *nbuf;\n+\n+  storm_user_info_clear(uinfo);\n+  for (;;) {\n+    // On success, the following call returns 0 and pwd is set to non-NULL.\n+    pwd = NULL;\n+    ret = getpwnam_r(username, &uinfo->pwd, uinfo->buf,\n+                         uinfo->buf_sz, &pwd);\n+    switch(ret) {\n+      case 0:\n+        if (!pwd) {\n+          // Not found.\n+          return ENOENT;\n+        }\n+        // Found.\n+        return 0;\n+      case EINTR:\n+        // EINTR: a signal was handled and this thread was allowed to continue.\n+        break;\n+      case ERANGE:\n+        // ERANGE: the buffer was not big enough.\n+        if (uinfo->buf_sz == MAX_USER_BUFFER_SIZE) {\n+          // Already tried with the max size.\n+          return ENOMEM;\n+        }\n+        buf_sz = uinfo->buf_sz * 2;\n+        if (buf_sz > MAX_USER_BUFFER_SIZE) {\n+          buf_sz = MAX_USER_BUFFER_SIZE;\n+        }\n+        nbuf = realloc(uinfo->buf, buf_sz);\n+        if (!nbuf) {\n+          return ENOMEM;\n+        }\n+        uinfo->buf = nbuf;\n+        uinfo->buf_sz = buf_sz;\n+        break;\n+      default:\n+        // Lookup failed.\n+        return getpwnam_error_translate(ret);\n+    }\n+  }\n+}\n+\n+static int put_primary_gid_first(struct storm_user_info *uinfo)\n+{\n+  int i, num_gids = uinfo->num_gids;\n+  gid_t first_gid;\n+  gid_t gid;\n+  gid_t primary = uinfo->pwd.pw_gid;\n+\n+  if (num_gids < 1) {\n+    // There are no gids, but we expected at least one.\n+    return EINVAL;\n+  }\n+  first_gid = uinfo->gids[0];\n+  if (first_gid == primary) {\n+    // First gid is already the primary.\n+    return 0;\n+  }\n+  for (i = 1; i < num_gids; i++) {\n+    gid = uinfo->gids[i];\n+    if (gid == primary) {\n+      // swap first gid and this gid.\n+      uinfo->gids[0] = gid;\n+      uinfo->gids[i] = first_gid;\n+      return 0;\n+    }\n+  }\n+  // Did not find the primary gid in the list.\n+  return EINVAL;\n+}\n+\n+int storm_user_info_getgroups(struct storm_user_info *uinfo)\n+{\n+  int ret, ngroups;\n+  gid_t *ngids;\n+\n+  if (!uinfo->pwd.pw_name) {\n+    // invalid user info\n+    return EINVAL;\n+  }\n+  uinfo->num_gids = 0;\n+  if (!uinfo->gids) {\n+    uinfo->gids = malloc(sizeof(uinfo->gids[0]) * INITIAL_GIDS_SIZE);\n+    if (!uinfo->gids) {\n+      return ENOMEM;\n+    }\n+    uinfo->gids_size = INITIAL_GIDS_SIZE;\n+  }\n+  ngroups = uinfo->gids_size;\n+  ret = getgrouplist(uinfo->pwd.pw_name, uinfo->pwd.pw_gid, \n+                         uinfo->gids, &ngroups);\n+  // Return value is different on Linux vs. FreeBSD.  Linux: the number of groups\n+  // or -1 on error.  FreeBSD: 0 on success or -1 on error.  Unfortunately, we\n+  // can't accept a 0 return on Linux, because buggy implementations have been\n+  // observed to return 0 but leave the other out parameters in an indeterminate\n+  // state.  This deviates from the man page, but it has been observed in\n+  // practice.  See issue HADOOP-10989 for details.\n+#ifdef __linux__\n+  if (ret > 0) {\n+#else\n+  if (ret >= 0) {\n+#endif\n+    uinfo->num_gids = ngroups;\n+    ret = put_primary_gid_first(uinfo);\n+    if (ret) {\n+      return ret;\n+    }\n+    return 0;\n+  } else if (ret != -1) {\n+    // Any return code that is not -1 is considered as error.\n+    // Since the user lookup was successful, there should be at least one\n+    // group for this user.\n+    return EIO;\n+  }\n+  ngids = realloc(uinfo->gids, sizeof(uinfo->gids[0]) * ngroups);\n+  if (!ngids) {\n+    return ENOMEM;\n+  }\n+  uinfo->gids = ngids;\n+  uinfo->gids_size = ngroups;\n+  ret = getgrouplist(uinfo->pwd.pw_name, uinfo->pwd.pw_gid, \n+                         uinfo->gids, &ngroups);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUzNjkxNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548536915", "bodyText": "Is this check needed here: if (filestat.st_mode & S_IGUID) == 0) ?", "author": "bipinprasad", "createdAt": "2020-12-24T13:55:17Z", "path": "storm-core/src/native/worker-launcher/impl/worker-launcher.c", "diffHunk": "@@ -93,41 +109,41 @@ char* get_executable() {\n \n int check_executor_permissions(char *executable_file) {\n   errno = 0;\n-  char * resolved_path = realpath(executable_file, NULL);\n+  char* resolved_path = realpath(executable_file, NULL);\n   if (resolved_path == NULL) {\n     fprintf(ERRORFILE,\n-        \"Error resolving the canonical name for the executable : %s!\",\n-        strerror(errno));\n+            \"ERROR: Error resolving the canonical name for the executable : %s!\",\n+            strerror(errno));\n     return -1;\n   }\n \n   struct stat filestat;\n   errno = 0;\n   if (stat(resolved_path, &filestat) != 0) {\n-    fprintf(ERRORFILE, \n-            \"Could not stat the executable : %s!.\\n\", strerror(errno));\n+    fprintf(ERRORFILE,\n+            \"ERROR: Could not stat the executable : %s!.\\n\", strerror(errno));\n     return -1;\n   }\n \n   uid_t binary_euid = filestat.st_uid; // Binary's user owner\n-  gid_t binary_gid = filestat.st_gid; // Binary's group owner\n+  gid_t binary_gid = filestat.st_gid;  // Binary's group owner\n \n   // Effective uid should be root\n   if (binary_euid != 0) {\n-    fprintf(LOGFILE,\n-        \"The worker-launcher binary should be user-owned by root.\\n\");\n+    fprintf(LOGFILE, \"The worker-launcher binary should be user-owned by root.\\n\");\n     return -1;\n   }\n \n   if (binary_gid != getgid()) {\n     fprintf(LOGFILE, \"ERROR: The configured worker-launcher group %d is different from\"\n-            \" the group of the executable %d\\n\", getgid(), binary_gid);\n+                     \" the group of the executable %d\\n\",", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA5ODU1OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669098558", "bodyText": "yes the worker-launcher binary needs to have setuid set.", "author": "Ethanlm", "createdAt": "2021-07-13T20:47:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODUzNjkxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODU0MTAxNw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548541017", "bodyText": "containerCredentialsPath, localDirs and logDirs are unused vars.\nOther unused methods appear to be getPidFile(), getContainerScriptPath(), getReapLayerKeepCount(), getOciRuntimeConfig()", "author": "bipinprasad", "createdAt": "2020-12-24T14:12:17Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/OciContainerExecutorConfig.java", "diffHunk": "@@ -0,0 +1,1309 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.annotation.JsonInclude;\n+import com.fasterxml.jackson.annotation.JsonRawValue;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+@JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+public class OciContainerExecutorConfig {\n+    private final String version;\n+    private final String username;\n+    private final String containerId;\n+    private final String pidFile;\n+    private final String containerScriptPath;\n+    private final List<OciLayer> layers;\n+    private final int reapLayerKeepCount;\n+    private final OciRuntimeConfig ociRuntimeConfig;\n+\n+    public OciContainerExecutorConfig() {\n+        this(null, null, null, null, null, null, 0, null);\n+    }\n+\n+    public OciContainerExecutorConfig(String username,\n+                                      String containerId,\n+                                      String pidFile, String containerScriptPath, String containerCredentialsPath,\n+                                      List<String> localDirs,\n+                                      List<String> logDirs, List<OciLayer> layers, int reapLayerKeepCount,", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODU0MTg2MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548541861", "bodyText": "Unused constructor.", "author": "bipinprasad", "createdAt": "2020-12-24T14:16:03Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/OciContainerExecutorConfig.java", "diffHunk": "@@ -0,0 +1,1309 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.annotation.JsonInclude;\n+import com.fasterxml.jackson.annotation.JsonRawValue;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+@JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+public class OciContainerExecutorConfig {\n+    private final String version;\n+    private final String username;\n+    private final String containerId;\n+    private final String pidFile;\n+    private final String containerScriptPath;\n+    private final List<OciLayer> layers;\n+    private final int reapLayerKeepCount;\n+    private final OciRuntimeConfig ociRuntimeConfig;\n+\n+    public OciContainerExecutorConfig() {\n+        this(null, null, null, null, null, null, 0, null);\n+    }\n+\n+    public OciContainerExecutorConfig(String username,\n+                                      String containerId,\n+                                      String pidFile, String containerScriptPath, String containerCredentialsPath,\n+                                      List<String> localDirs,\n+                                      List<String> logDirs, List<OciLayer> layers, int reapLayerKeepCount,\n+                                      OciRuntimeConfig ociRuntimeConfig) {\n+        this(\"0.1\", username, containerId, pidFile,\n+            containerScriptPath, layers, reapLayerKeepCount, ociRuntimeConfig);\n+    }\n+\n+    public OciContainerExecutorConfig(String version, String username,\n+                                      String containerId,\n+                                      String pidFile, String containerScriptPath,\n+                                      List<OciLayer> layers, int reapLayerKeepCount,\n+                                      OciRuntimeConfig ociRuntimeConfig) {\n+        this.version = version;\n+        this.username = username;\n+        this.containerId = containerId;\n+        this.pidFile = pidFile;\n+        this.containerScriptPath = containerScriptPath;\n+        this.layers = layers;\n+        this.reapLayerKeepCount = reapLayerKeepCount;\n+        this.ociRuntimeConfig = ociRuntimeConfig;\n+    }\n+\n+    public String getVersion() {\n+        return version;\n+    }\n+\n+    public String getUsername() {\n+        return username;\n+    }\n+\n+    public String getContainerId() {\n+        return containerId;\n+    }\n+\n+    public String getPidFile() {\n+        return pidFile;\n+    }\n+\n+    public String getContainerScriptPath() {\n+        return containerScriptPath;\n+    }\n+\n+    public List<OciLayer> getLayers() {\n+        return layers;\n+    }\n+\n+    public int getReapLayerKeepCount() {\n+        return reapLayerKeepCount;\n+    }\n+\n+    public OciRuntimeConfig getOciRuntimeConfig() {\n+        return ociRuntimeConfig;\n+    }\n+\n+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+    public static class OciLayer {\n+        private final String mediaType;\n+        private final String path;\n+\n+        public OciLayer(String mediaType, String path) {\n+            this.mediaType = mediaType;\n+            this.path = path;\n+        }\n+\n+        public OciLayer() {\n+            this(null, null);\n+        }\n+\n+        public String getMediaType() {\n+            return mediaType;\n+        }\n+\n+        public String getPath() {\n+            return path;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"OciLayer{\"\n+                + \"mediaType='\" + mediaType + '\\''\n+                + \", path='\" + path + '\\''\n+                + '}';\n+        }\n+    }\n+\n+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+    public static class OciRuntimeConfig {\n+        private final OciRootConfig root;\n+        private final List<OciMount> mounts;\n+        private final OciProcessConfig process;\n+        private final OciHooksConfig hooks;\n+        private final OciAnnotationsConfig annotations;\n+        private final OciLinuxConfig linux;\n+        private final String hostname;\n+\n+        public OciRuntimeConfig() {\n+            this(null, null, null, null, null, null, null);\n+        }\n+\n+        public OciRuntimeConfig(OciRootConfig root, List<OciMount> mounts,\n+                                OciProcessConfig process, String hostname, OciHooksConfig hooks, OciAnnotationsConfig annotations,\n+                                OciLinuxConfig linux) {\n+            this.root = root;\n+            this.mounts = mounts;\n+            this.process = process;\n+            this.hostname = hostname;\n+            this.hooks = hooks;\n+            this.annotations = annotations;\n+            this.linux = linux;\n+        }\n+\n+        public OciRootConfig getRoot() {\n+            return root;\n+        }\n+\n+        public List<OciMount> getMounts() {\n+            return mounts;\n+        }\n+\n+        public OciProcessConfig getProcess() {\n+            return process;\n+        }\n+\n+        public String getHostname() {\n+            return hostname;\n+        }\n+\n+        public OciHooksConfig getHooks() {\n+            return hooks;\n+        }\n+\n+        public OciAnnotationsConfig getAnnotations() {\n+            return annotations;\n+        }\n+\n+        public OciLinuxConfig getLinux() {\n+            return linux;\n+        }\n+\n+        @JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+        static class OciRootConfig {\n+            private final String path;\n+            private final boolean readonly;\n+\n+            OciRootConfig(String path, boolean readonly) {\n+                this.path = path;\n+                this.readonly = readonly;\n+            }\n+\n+            OciRootConfig() {\n+                this(null, false);\n+            }\n+\n+            public String getPath() {\n+                return path;\n+            }\n+\n+            public boolean isReadonly() {\n+                return readonly;\n+            }\n+        }\n+\n+        @JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+        static class OciMount {\n+            private final String destination;\n+            private final String type;\n+            private final String source;\n+            private final List<String> options;\n+\n+            OciMount(String destination, String type, String source, List<String> options) {\n+                this.destination = destination;\n+                this.type = type;\n+                this.source = source;\n+                this.options = options;\n+            }\n+\n+            OciMount(String destination, String source, List<String> options) {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODU0MjU1MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548542551", "bodyText": "Can these be final?", "author": "bipinprasad", "createdAt": "2020-12-24T14:18:44Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODU0NzEyMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r548547123", "bodyText": "Could this multiplication on the right side cause an overflow - int * int * long  when the first two integers are being multiplied.", "author": "bipinprasad", "createdAt": "2020-12-24T14:36:56Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();\n+    private StormTimer checkContainerAliveTimer;\n+\n+    @Override\n+    public void prepare(Map<String, Object> conf) throws IOException {\n+        super.prepare(conf);\n+\n+        imageTagToManifestPlugin = chooseImageTagToManifestPlugin();\n+        imageTagToManifestPlugin.init(conf);\n+\n+        manifestToResourcesPlugin = chooseManifestToResourcesPlugin();\n+        manifestToResourcesPlugin.init(conf);\n+\n+        ociResourcesLocalizer = chooseOciResourcesLocalizer();\n+        ociResourcesLocalizer.init(conf);\n+\n+        layersToKeep = ObjectReader.getInt(\n+                conf.get(DaemonConfig.STORM_OCI_LAYER_MOUNTS_TO_KEEP),\n+                100\n+        );\n+\n+        mapper = new ObjectMapper();\n+\n+        if (seccompJsonFile != null) {\n+            seccomp = new String(Files.readAllBytes(Paths.get(seccompJsonFile)));\n+        }\n+\n+        if (checkContainerAliveTimer == null) {\n+            checkContainerAliveTimer =\n+                new StormTimer(\"CheckRuncContainerAlive\", Utils.createDefaultUncaughtExceptionHandler());\n+            checkContainerAliveTimer\n+                .scheduleRecurring(0, (Integer) conf.get(DaemonConfig.SUPERVISOR_MONITOR_FREQUENCY_SECS), () -> {\n+                    try {\n+                        checkContainersAlive();\n+                    } catch (Exception e) {\n+                        //Ignore\n+                        LOG.debug(\"The CheckRuncContainerAlive thread has exception. Ignored\", e);\n+                    }\n+                });\n+        }\n+    }\n+\n+    private OciImageTagToManifestPluginInterface chooseImageTagToManifestPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_IMAGE_TAG_TO_MANIFEST_PLUGIN)\n+        );\n+        LOG.info(\"imageTag-to-manifest Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciManifestToResourcesPluginInterface chooseManifestToResourcesPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_MANIFEST_TO_RESOURCES_PLUGIN)\n+        );\n+        LOG.info(\"manifest to resource Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciResourcesLocalizerInterface chooseOciResourcesLocalizer()\n+        throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCALIZER)\n+        );\n+        LOG.info(\"oci resource localizer is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    //the container process ID in the process namespace of the host.\n+    private String containerPidFile(String workerId) {\n+        return ConfigUtils.workerArtifactsSymlink(conf, workerId) + FILE_SEPARATOR + \"container-\" + workerId + \".pid\";\n+    }\n+\n+    @Override\n+    public void launchWorkerProcess(String user, String topologyId,  Map<String, Object> topoConf,\n+                                    int port, String workerId,\n+                                    List<String> command, Map<String, String> env, String logPrefix,\n+                                    ExitCodeCallback processExitCallback, File targetDir) throws IOException {\n+\n+        String imageName = getImageName(topoConf);\n+        if (imageName == null) {\n+            LOG.error(\"Image name for {} is not configured properly; will not continue to launch the worker\", topologyId);\n+            return;\n+        }\n+\n+        //set container ID to port + worker ID\n+        String containerId = getContainerId(workerId, port);\n+\n+        //get manifest\n+        ImageManifest manifest = imageTagToManifestPlugin.getManifestFromImageTag(imageName);\n+        LOG.debug(\"workerId {}: Got manifest: {}\", workerId, manifest.toString());\n+\n+        //get layers metadata\n+        OciResource configResource = manifestToResourcesPlugin.getConfigResource(manifest);\n+        LOG.info(\"workerId {}: Got config metadata: {}\", workerId, configResource.toString());\n+\n+        saveRuncYaml(topologyId, port, containerId, imageName, configResource);\n+\n+        List<OciResource> layersResource = manifestToResourcesPlugin.getLayerResources(manifest);\n+        LOG.info(\"workerId {}: Got layers metadata: {}\", workerId, layersResource.toString());\n+\n+        //localize resource\n+        String configLocalPath = ociResourcesLocalizer.localize(configResource);\n+\n+        List<String> ociEnv = new ArrayList<>();\n+        List<String> args = new ArrayList<>();\n+\n+        ArrayList<OciLayer> layers = new ArrayList<>();\n+\n+        File file = new File(configLocalPath);\n+        //extract env\n+        List<String> imageEnv = extractImageEnv(file);\n+        if (imageEnv != null && !imageEnv.isEmpty()) {\n+            ociEnv.addAll(imageEnv);\n+        }\n+        for (Map.Entry<String, String> entry : env.entrySet()) {\n+            ociEnv.add(entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        LOG.debug(\"workerId {}: ociEnv: {}\", workerId, ociEnv);\n+\n+        //extract entrypoint\n+        List<String> entrypoint = extractImageEntrypoint(file);\n+        if (entrypoint != null && !entrypoint.isEmpty()) {\n+            args.addAll(entrypoint);\n+        }\n+        LOG.debug(\"workerId {}: args: {}\", workerId, args);\n+\n+        //localize layers\n+        List<String> layersLocalPath = ociResourcesLocalizer.localize((layersResource));\n+        //compose layers\n+        for (String layerLocalPath : layersLocalPath) {\n+            OciLayer layer = new OciLayer(SQUASHFS_MEDIA_TYPE, layerLocalPath);\n+            layers.add(layer);\n+        }\n+        LOG.debug(\"workerId {}: layers: {}\", workerId, layers);\n+        ArrayList<OciMount> mounts = new ArrayList<>();\n+        setContainerMounts(mounts, topologyId, workerId, port);\n+        LOG.debug(\"workerId {}: mounts: {}\", workerId, mounts);\n+\n+        //calculate the cpusQuotas based on CPU_CFS_PERIOD and assigned CPU\n+        Long cpusQuotas = null;\n+        if (workerToCpu.containsKey(workerId)) {\n+            cpusQuotas = workerToCpu.get(workerId) * CPU_CFS_PERIOD_US / 100;\n+        }\n+\n+        Long memoryInBytes = null;\n+        if (workerToMemoryMb.containsKey(workerId)) {\n+            memoryInBytes = workerToMemoryMb.get(workerId) * 1024 * 1024L;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTkwMDU3MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671900571", "bodyText": "nice catch.", "author": "Ethanlm", "createdAt": "2021-07-18T21:32:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODU0NzEyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3Mzk3MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549473970", "bodyText": "what is this line for?", "author": "agresch", "createdAt": "2020-12-28T20:14:28Z", "path": ".travis.yml", "diffHunk": "@@ -51,6 +51,7 @@ before_install:\n   - nvm install 8.9.3\n   - nvm use 8.9.3\n   - sudo apt-get update\n+  - sudo apt-get install libssl-dev", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTA5OTcxMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669099713", "bodyText": "oci.c needs <openssl/evp.h>", "author": "Ethanlm", "createdAt": "2021-07-13T20:48:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3Mzk3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3NzcyNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549477726", "bodyText": "can we add this information to the begining of the docker-to-squash.py script?", "author": "agresch", "createdAt": "2020-12-28T20:29:29Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTg5NDI2OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669894268", "bodyText": "yes it is already there.", "author": "Ethanlm", "createdAt": "2021-07-14T19:30:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3NzcyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3OTY5Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549479692", "bodyText": "This script has a lot of code.  Some comments as to what these methods are doing could be helpful.", "author": "agresch", "createdAt": "2020-12-28T20:37:33Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3OTk1Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549479953", "bodyText": "is this a standard hadoop install directory?", "author": "agresch", "createdAt": "2020-12-28T20:38:41Z", "path": "bin/docker-to-squash.py", "diffHunk": "@@ -0,0 +1,1430 @@\n+#!/usr/bin/env python\n+\n+\"\"\"\n+Licensed to the Apache Software Foundation (ASF) under one\n+or more contributor license agreements.  See the NOTICE file\n+distributed with this work for additional information\n+regarding copyright ownership.  The ASF licenses this file\n+to you under the Apache License, Version 2.0 (the\n+\"License\"); you may not use this file except in compliance\n+with the License.  You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+\n+docker_to_squash.py is a tool to facilitate the process of converting\n+Docker images into squashFS layers, manifests, and configs.\n+\n+Tool dependencies: skopeo, squashfs-tools, tar, setfattr\n+\"\"\"\n+\n+import argparse\n+from collections import Iterable\n+import glob\n+import hashlib\n+import json\n+import logging\n+import os\n+import re\n+import shutil\n+import subprocess\n+from threading import Timer\n+\n+LOG_LEVEL = None\n+HADOOP_BIN_DIR = None\n+\n+def shell_command(command, print_stdout, print_stderr, raise_on_error,\n+                  timeout_sec=600):\n+  global LOG_LEVEL\n+  stdout_val = subprocess.PIPE\n+  stderr_val = subprocess.PIPE\n+\n+  logging.debug(\"command: %s\", command)\n+\n+  if print_stdout:\n+    stdout_val = None\n+\n+  if print_stderr or LOG_LEVEL == \"DEBUG\":\n+    stderr_val = None\n+\n+  process = None\n+  try:\n+    process = subprocess.Popen(command, stdout=stdout_val,\n+                               stderr=stderr_val)\n+    timer = Timer(timeout_sec, process_timeout, [process])\n+\n+    timer.start()\n+    out, err = process.communicate()\n+\n+    if raise_on_error and process.returncode is not 0:\n+      exception_string = (\"Commmand: \" + str(command)\n+                          + \" failed with returncode: \"\n+                          + str(process.returncode))\n+      if out != None:\n+        exception_string = exception_string + \"\\nstdout: \" + str(out)\n+      if err != None:\n+        exception_string = exception_string + \"\\nstderr: \" + str(err)\n+      raise Exception(exception_string)\n+\n+  except:\n+    if process and process.poll() is None:\n+      process.kill()\n+    raise Exception(\"Popen failure\")\n+  finally:\n+    if timer:\n+      timer.cancel()\n+\n+  return out, err, process.returncode\n+\n+def process_timeout(process):\n+  process.kill()\n+  logging.error(\"Process killed due to timeout\")\n+\n+def does_hdfs_entry_exist(entry, raise_on_error=True):\n+  out, err, returncode = hdfs_ls(entry, raise_on_error=raise_on_error)\n+  if returncode is not 0:\n+    return False\n+  return True\n+\n+def setup_hdfs_dirs(dirs):\n+  if does_hdfs_entry_exist(dirs, raise_on_error=False):\n+    return\n+\n+  hdfs_mkdir(dirs, create_parents=True)\n+  chmod_dirs = []\n+  for dir_entry in dirs:\n+    directories = dir_entry.split(\"/\")[1:]\n+    dir_path = \"\"\n+    for directory in directories:\n+      dir_path = dir_path + \"/\" +  directory\n+      logging.info(\"dir_path: %s\", str(dir_path))\n+      chmod_dirs.append(dir_path)\n+  hdfs_chmod(\"755\", chmod_dirs)\n+\n+def append_or_extend_to_list(src, src_list):\n+  if isinstance(src, list):\n+    src_list.extend(src)\n+  else:\n+    src_list.append(src)\n+\n+def hdfs_get(src, dest, print_stdout=False, print_stderr=False, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-get\"]\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_ls(file_path, options=\"\", print_stdout=False, print_stderr=False,\n+            raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-ls\"]\n+  if options:\n+    append_or_extend_to_list(options, command)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cat(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-cat\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_mkdir(file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               create_parents=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-mkdir\"]\n+  if create_parents:\n+    command.append(\"-p\")\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_rm(file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-rm\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_put(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-put\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_chmod(mode, file_path, print_stdout=False, print_stderr=True, raise_on_error=True,\n+               recursive=False):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-chmod\"]\n+  if recursive:\n+    command.append(\"-R\")\n+  command.append(mode)\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_setrep(replication, file_path, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-setrep\", str(replication)]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+def hdfs_cp(src, dest, force=False, print_stdout=False, print_stderr=True, raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR +  \"/hadoop\", \"fs\", \"-cp\"]\n+  if force:\n+    command.append(\"-f\")\n+  append_or_extend_to_list(src, command)\n+  command.append(dest)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr,\n+                                       raise_on_error, 60)\n+  return out, err, returncode\n+\n+def hdfs_touchz(file_path, print_stdout=False, print_stderr=True,\n+                raise_on_error=True):\n+  global HADOOP_BIN_DIR\n+  command = [HADOOP_BIN_DIR + \"/hadoop\", \"fs\", \"-touchz\"]\n+  append_or_extend_to_list(file_path, command)\n+  out, err, returncode = shell_command(command, print_stdout, print_stderr, raise_on_error)\n+  return out, err, returncode\n+\n+\n+def get_working_dir(directory):\n+  try:\n+    if os.path.isdir(directory):\n+      working_dir = os.path.join(directory, \"docker-to-squash\")\n+    else:\n+      working_dir = directory\n+    os.makedirs(working_dir)\n+  except:\n+    raise Exception(\"Could not create working_dir: \" + working_dir)\n+  return working_dir\n+\n+def is_sha256_hash(string):\n+  if not re.findall(r\"^[a-fA-F\\d]{64,64}$\", string):\n+    return False\n+  return True\n+\n+def calculate_file_hash(filename):\n+  sha = hashlib.sha256()\n+  with open(filename, 'rb') as file_pointer:\n+    while True:\n+      data = file_pointer.read(65536)\n+      if not data:\n+        break\n+      sha.update(data)\n+  hexdigest = sha.hexdigest()\n+  if hexdigest == 0:\n+    raise Exception(\"Hex digest for file: \" + hexdigest + \"returned 0\")\n+  return hexdigest\n+\n+def calculate_string_hash(string):\n+  sha = hashlib.sha256()\n+  sha.update(string)\n+  return sha.hexdigest()\n+\n+def get_local_manifest_from_path(manifest_path):\n+  with open(manifest_path, \"rb\") as file_pointer:\n+    out = file_pointer.read()\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_hdfs_manifest_from_path(manifest_path):\n+  out, err, returncode = hdfs_cat(manifest_path)\n+  manifest_hash = calculate_string_hash(str(out))\n+  manifest = json.loads(out)\n+  return manifest, manifest_hash\n+\n+def get_config_hash_from_manifest(manifest):\n+  config_hash = manifest['config']['digest'].split(\":\", 1)[1]\n+  return config_hash\n+\n+def check_total_layer_number(layers):\n+    global MAX_IMAGE_LAYERS\n+    if len(layers) > MAX_IMAGE_LAYERS:\n+      logging.error(\"layers: \" + str(layers))\n+      raise Exception(\"Image has \" + str(len(layers)) +\n+                      \" layers, which is more than the maximum \" + str(MAX_IMAGE_LAYERS) +\n+                      \" layers. Failing out\")\n+\n+def check_total_layer_size(manifest, size):\n+    global MAX_IMAGE_SIZE\n+    if size > MAX_IMAGE_SIZE:\n+      for layer in manifest['layers']:\n+        logging.error(\"layer \" + layer['digest'] + \" has size \" + str(layer['size']))\n+      raise Exception(\"Image has total size \" + str(size) +\n+                      \" B. which is more than the maximum size \" + str(MAX_IMAGE_SIZE) + \" B. Failing out\")\n+\n+def get_layer_hashes_from_manifest(manifest, error_on_size_check=True):\n+  layers = []\n+  size = 0;\n+\n+  for layer in manifest['layers']:\n+    layers.append(layer['digest'].split(\":\", 1)[1])\n+    size += layer['size']\n+\n+  if error_on_size_check:\n+    check_total_layer_number(layers)\n+    check_total_layer_size(manifest, size)\n+\n+  return layers\n+\n+def get_pull_fmt_string(pull_format):\n+  pull_fmt_string = pull_format + \":\"\n+  if pull_format == \"docker\":\n+    pull_fmt_string = pull_fmt_string + \"//\"\n+  return pull_fmt_string\n+\n+def get_manifest_from_docker_image(pull_format, image):\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  out, err, returncode = shell_command([\"skopeo\", \"inspect\", \"--raw\", pull_fmt_string + image],\n+                                       False, True, True, 60)\n+  manifest = json.loads(out)\n+  if 'manifests' in manifest:\n+    logging.debug(\"skopeo inspect --raw returned a list of manifests\")\n+    manifests_dict = manifest['manifests']\n+    sha = None\n+    for mfest in manifests_dict:\n+      if(mfest['platform']['architecture'] == \"amd64\"):\n+        sha = mfest['digest']\n+        break\n+    if not sha:\n+      raise Exception(\"Could not find amd64 manifest for\" + image)\n+\n+    image_without_tag = image.split(\"/\", 1)[-1].split(\":\", 1)[0]\n+    image_and_sha = image_without_tag + \"@\" + sha\n+\n+    logging.debug(\"amd64 manifest sha is: %s\", sha)\n+\n+    manifest, manifest_hash = get_manifest_from_docker_image(pull_format, image_and_sha)\n+  else:\n+    manifest_hash = calculate_string_hash(str(out))\n+\n+  logging.debug(\"manifest: %s\", str(manifest))\n+  return manifest, manifest_hash\n+\n+def split_image_and_tag(image_and_tag):\n+  split = image_and_tag.split(\",\")\n+  image = split[0]\n+  tags = split[1:]\n+  return image, tags\n+\n+def read_image_tag_to_hash(image_tag_to_hash):\n+  hash_to_tags = dict()\n+  tag_to_hash = dict()\n+  with open(image_tag_to_hash, 'rb') as file_pointer:\n+    while True:\n+      line = file_pointer.readline()\n+      if not line:\n+        break\n+      line = line.rstrip()\n+\n+      if not line:\n+        continue\n+\n+      comment_split_line = line.split(\"#\", 1)\n+      line = comment_split_line[0]\n+      comment = comment_split_line[1:]\n+\n+      split_line = line.rsplit(\":\", 1)\n+      manifest_hash = split_line[-1]\n+      tags_list = ' '.join(split_line[:-1]).split(\",\")\n+\n+      if not is_sha256_hash(manifest_hash) or not tags_list:\n+        logging.warn(\"image-tag-to-hash file malformed. Skipping entry %s\", line)\n+        continue\n+\n+      tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+      if tags_and_comments is None:\n+        known_tags = tags_list\n+        known_comment = comment\n+      else:\n+        known_tags = tags_and_comments[0]\n+        for tag in tags_list:\n+          if tag not in known_tags:\n+            known_tags.append(tag)\n+        known_comment = tags_and_comments[1]\n+        known_comment.extend(comment)\n+\n+      hash_to_tags[manifest_hash] = (known_tags, known_comment)\n+\n+      for tag in tags_list:\n+        cur_manifest = tag_to_hash.get(tag, None)\n+        if cur_manifest is not None:\n+          logging.warn(\"tag_to_hash already has manifest %s defined for tag %s.\"\n+                       + \"This entry will be overwritten\", cur_manifest, tag)\n+        tag_to_hash[tag] = manifest_hash\n+  return hash_to_tags, tag_to_hash\n+\n+def remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing tag %s\", tag)\n+    return\n+\n+  prev_hash = tag_to_hash.get(tag, None)\n+\n+  if prev_hash is not None:\n+    del tag_to_hash[tag]\n+    prev_tags, prev_comment = hash_to_tags.get(prev_hash, (None, None))\n+    prev_tags.remove(tag)\n+    if prev_tags == 0:\n+      del hash_to_tags[prev_hash]\n+    else:\n+      hash_to_tags[prev_hash] = (prev_tags, prev_comment)\n+  else:\n+    logging.debug(\"Tag not found. Not removing tag: %s\", tag)\n+\n+def remove_image_hash_from_dicts(hash_to_tags, tag_to_hash, image_hash):\n+  if not hash_to_tags:\n+    logging.debug(\"hash_to_tags is null. Not removing image_hash %s\", image_hash)\n+    return\n+  logging.debug(\"hash_to_tags: %s\", str(hash_to_tags))\n+  logging.debug(\"Removing image_hash from dicts: %s\", image_hash)\n+  prev_tags, prev_comments = hash_to_tags.get(image_hash, None)\n+\n+  if prev_tags is not None:\n+    hash_to_tags.pop(image_hash)\n+    for tag in prev_tags:\n+      del tag_to_hash[tag]\n+\n+def add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  tag_to_hash[tag] = manifest_hash\n+  new_tags_and_comments = hash_to_tags.get(manifest_hash, None)\n+  if new_tags_and_comments is None:\n+    new_tags = [tag]\n+    new_comment = [comment]\n+  else:\n+    new_tags = new_tags_and_comments[0]\n+    new_comment = new_tags_and_comments[1]\n+    if tag not in new_tags:\n+      new_tags.append(tag)\n+    if comment and comment not in new_comment:\n+      new_comment.append(comment)\n+  hash_to_tags[manifest_hash] = (new_tags, new_comment)\n+\n+def write_local_image_tag_to_hash(image_tag_to_hash, hash_to_tags):\n+  file_contents = []\n+  for key, value in hash_to_tags.iteritems():\n+    manifest_hash = key\n+    tags = ','.join(map(str, value[0]))\n+    if tags:\n+      comment = ', '.join(map(str, value[1]))\n+      if comment > 0:\n+        comment = \"#\" + comment\n+      file_contents.append(tags + \":\" + manifest_hash + comment + \"\\n\")\n+\n+  file_contents.sort()\n+  with open(image_tag_to_hash, 'w') as file_pointer:\n+    for val in file_contents:\n+      file_pointer.write(val)\n+\n+def update_dicts_for_multiple_tags(hash_to_tags, tag_to_hash, tags,\n+                                   manifest_hash, comment):\n+  for tag in tags:\n+    update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def update_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment):\n+  remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+  add_tag_to_dicts(hash_to_tags, tag_to_hash, tag, manifest_hash, comment)\n+\n+def remove_from_dicts(hash_to_tags, tag_to_hash, tags):\n+  for tag in tags:\n+    logging.debug(\"removing tag: %s\", tag)\n+    remove_tag_from_dicts(hash_to_tags, tag_to_hash, tag)\n+\n+def populate_tag_dicts(hdfs_root, image_tag_to_hash, local_image_tag_to_hash):\n+\n+  if does_hdfs_entry_exist(hdfs_root + \"/\" + image_tag_to_hash):\n+    hdfs_get(hdfs_root + \"/\" + image_tag_to_hash, local_image_tag_to_hash)\n+    image_tag_to_hash_hash = calculate_file_hash(local_image_tag_to_hash)\n+  else:\n+    image_tag_to_hash_hash = 0\n+\n+  if image_tag_to_hash_hash != 0:\n+    hash_to_tags, tag_to_hash = read_image_tag_to_hash(local_image_tag_to_hash)\n+  else:\n+    hash_to_tags = {}\n+    tag_to_hash = {}\n+  return hash_to_tags, tag_to_hash, image_tag_to_hash_hash\n+\n+\n+def setup_squashfs_hdfs_dirs(hdfs_dirs, image_tag_to_hash_path):\n+  logging.debug(\"Setting up squashfs hdfs_dirs: %s\", str(hdfs_dirs))\n+  setup_hdfs_dirs(hdfs_dirs)\n+  if not does_hdfs_entry_exist(image_tag_to_hash_path, raise_on_error=False):\n+    hdfs_touchz(image_tag_to_hash_path)\n+    hdfs_chmod(\"755\", image_tag_to_hash_path)\n+\n+def skopeo_copy_image(pull_format, image, skopeo_format, skopeo_dir):\n+  logging.info(\"Pulling image: %s\", image)\n+  if os.path.isdir(skopeo_dir):\n+    raise Exception(\"Skopeo output directory already exists. \"\n+                    + \"Please delete and try again \"\n+                    + \"Directory: \" + skopeo_dir)\n+  pull_fmt_string = get_pull_fmt_string(pull_format)\n+  shell_command([\"skopeo\", \"copy\", pull_fmt_string + image,\n+                 skopeo_format + \":\" + skopeo_dir], False, True, True, 600)\n+\n+def untar_layer(tmp_dir, layer_path):\n+  shell_command([\"tar\", \"-C\", tmp_dir, \"--xattrs\",\n+                 \"--xattrs-include='*'\", \"-xf\", layer_path],\n+                False, True, True, 600)\n+\n+def tar_file_search(archive, target):\n+  out, err, returncode = shell_command([\"tar\", \"-xf\", archive, target, \"-O\"],\n+                                       False, False, False, 600)\n+  return out\n+\n+def set_fattr(directory):\n+  shell_command([\"setfattr\", \"-n\", \"trusted.overlay.opaque\",\n+                 \"-v\", \"y\", directory], False, True, True)\n+\n+def make_whiteout_block_device(file_path, whiteout):\n+  shell_command([\"mknod\", \"-m\", \"000\", file_path,\n+                 \"c\", \"0\", \"0\"], False, True, True)\n+\n+  out, err, returncode = shell_command([\"stat\", \"-c\", \"%U:%G\", whiteout], False, True, True)\n+  perms = str(out).strip()\n+\n+  shell_command([\"chown\", perms, file_path], False, True, True)\n+\n+def convert_oci_whiteouts(tmp_dir):\n+  out, err, returncode = shell_command([\"find\", tmp_dir, \"-name\", \".wh.*\"],\n+                                       False, False, True, 60)\n+  whiteouts = str(out).splitlines()\n+  for whiteout in whiteouts:\n+    if whiteout == 0:\n+      continue\n+    basename = os.path.basename(whiteout)\n+    directory = os.path.dirname(whiteout)\n+    if basename == \".wh..wh..opq\":\n+      set_fattr(directory)\n+    else:\n+      whiteout_string = \".wh.\"\n+      idx = basename.rfind(whiteout_string)\n+      bname = basename[idx+len(whiteout_string):]\n+      file_path = os.path.join(directory, bname)\n+      make_whiteout_block_device(file_path, whiteout)\n+    shell_command([\"rm\", whiteout], False, True, True)\n+\n+def dir_to_squashfs(tmp_dir, squash_path):\n+  shell_command([\"/usr/sbin/mksquashfs\", tmp_dir, squash_path, \"-write-queue\", \"4096\",\n+                 \"-read-queue\", \"4096\", \"-fragment-queue\", \"4096\"],\n+                False, True, True, 600)\n+\n+def upload_to_hdfs(file_path, file_name, hdfs_dir, replication, mode, force=False):\n+  dest = hdfs_dir + \"/\" + file_name\n+\n+  if does_hdfs_entry_exist(dest, raise_on_error=False):\n+    if not force:\n+      logging.warn(\"Not uploading to HDFS. File already exists: %s\", dest)\n+      return\n+    logging.info(\"File already exists, but overwriting due to force option: %s\", dest)\n+\n+  hdfs_put(file_path, dest, force)\n+  hdfs_setrep(replication, dest)\n+  hdfs_chmod(mode, dest)\n+  logging.info(\"Uploaded file %s with replication %d and permissions %s\",\n+               dest, replication, mode)\n+\n+def atomic_upload_mv_to_hdfs(file_path, file_name, hdfs_dir, replication, image_tag_to_hash_file_hash):\n+  global HADOOP_PREFIX\n+  local_hash = calculate_file_hash(file_path)\n+  if local_hash == image_tag_to_hash_file_hash:\n+    logging.info(\"image_tag_to_hash file unchanged. Not uploading\")\n+    return\n+\n+  tmp_file_name = file_name + \".tmp\"\n+  hdfs_tmp_path = hdfs_dir + \"/\" + tmp_file_name\n+  hdfs_file_path = hdfs_dir + \"/\" + file_name\n+  try:\n+    if does_hdfs_entry_exist(hdfs_tmp_path, raise_on_error=False):\n+      hdfs_rm(hdfs_tmp_path)\n+    hdfs_put(file_path, hdfs_tmp_path)\n+    hdfs_setrep(replication, hdfs_tmp_path)\n+    hdfs_chmod(\"444\", hdfs_tmp_path)\n+\n+    jar_path = HADOOP_PREFIX + \"/share/hadoop/tools/lib/hadoop-extras-*.jar\"", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzIxNzQ2Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r667217467", "bodyText": "yes. HADOOP_PREFIX is where hadoop is installed. The rest is standard.\nIt is looking for the hadoop-extras jar, e.g.:\nshare/hadoop/tools/lib/hadoop-extras-2.10.1.19.2106161351.jar", "author": "Ethanlm", "createdAt": "2021-07-09T21:22:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3OTk1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MDQ2MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549480460", "bodyText": "OCI/Squashfs Runtime for workers running in containers or something might help to grab attention better.", "author": "agresch", "createdAt": "2020-12-28T20:40:53Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MTc0NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549481744", "bodyText": "belong -> belonging\nsquashfs file -> squashfs files", "author": "agresch", "createdAt": "2020-12-28T20:45:26Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; ", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MjE1Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549482153", "bodyText": "From reading this, I'm not clear what ./layers and ./manifests are relative to.\nLater it looks like this is under the containers/ HDFS dir.  I would mention this here.", "author": "agresch", "createdAt": "2020-12-28T20:46:50Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; ", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MjUzNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549482536", "bodyText": "is it required to put the data in /containers?  Is this the same as storm.oci.image.hdfs.toplevel.dir?", "author": "agresch", "createdAt": "2020-12-28T20:48:29Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MzgwNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549483805", "bodyText": "Do we need to do anything with regards to licenses when using external tools?", "author": "agresch", "createdAt": "2020-12-28T20:53:59Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkwMjYyNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669902625", "bodyText": "We are only referring to it and assuming they are available for use before running docker-to-squash.py. I think it should be fine.", "author": "Ethanlm", "createdAt": "2021-07-14T19:43:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MzgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NDU0Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549484546", "bodyText": "allowlist over whitelist", "author": "agresch", "createdAt": "2020-12-28T20:56:47Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NTE1MjQ4OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r675152488", "bodyText": "can we update this config description to allowlist?", "author": "agresch", "createdAt": "2021-07-22T20:49:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NDU0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NTEwNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549485105", "bodyText": "allowlist again", "author": "agresch", "createdAt": "2020-12-28T20:58:59Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.\n+| `storm.oci.image`                      | The default docker image to be used if user doesn't specify which image to use. And it must belong to the `storm.oci.allowed.images` \n+| `topology.oci.image`                   | Topologies can specify which image to use. It must belong to the `storm.oci.allowed.images` |\n+| `storm.oci.cgroup.root`                | The root path of cgroup for docker to use. On RHEL7, it should be \"/sys/fs/cgroup\".\n+| `storm.oci.cgroup.parent`              | --cgroup-parent config for docker command. It must follow the constraints of docker commands. The path will be made as absolute path if it's a relative path because we saw some weird bugs ((the cgroup memory directory disappears after a while) when a relative path is used.\n+| `storm.oci.readonly.bindmounts`        | A list of read only bind mounted directories.\n+| `storm.oci.readwrite.bindmounts`       | A list of read-write bind mounted directories.\n+| `storm.oci.nscd.dir`                   | The directory of nscd (name service cache daemon), e.g. \"/var/run/nscd/\". nscd must be running so that profiling can work properly.\n+| `storm.oci.seccomp.profile`            | White listed syscalls seccomp Json file to be used as a seccomp filter", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NjEyNA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549486124", "bodyText": "The config says localorhdfs, but the decription just mentions hdfs.  Can we be consistent or clarify the meaning?", "author": "agresch", "createdAt": "2020-12-28T21:03:28Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.\n+| `storm.oci.image`                      | The default docker image to be used if user doesn't specify which image to use. And it must belong to the `storm.oci.allowed.images` \n+| `topology.oci.image`                   | Topologies can specify which image to use. It must belong to the `storm.oci.allowed.images` |\n+| `storm.oci.cgroup.root`                | The root path of cgroup for docker to use. On RHEL7, it should be \"/sys/fs/cgroup\".\n+| `storm.oci.cgroup.parent`              | --cgroup-parent config for docker command. It must follow the constraints of docker commands. The path will be made as absolute path if it's a relative path because we saw some weird bugs ((the cgroup memory directory disappears after a while) when a relative path is used.\n+| `storm.oci.readonly.bindmounts`        | A list of read only bind mounted directories.\n+| `storm.oci.readwrite.bindmounts`       | A list of read-write bind mounted directories.\n+| `storm.oci.nscd.dir`                   | The directory of nscd (name service cache daemon), e.g. \"/var/run/nscd/\". nscd must be running so that profiling can work properly.\n+| `storm.oci.seccomp.profile`            | White listed syscalls seccomp Json file to be used as a seccomp filter\n+| `supervisor.worker.launcher`              | Full path to the worker-launcher executable.\n+| `storm.oci.image.hdfs.toplevel.dir`      |  The HDFS location under which the oci image manifests, layers and configs directories exist.\n+| `storm.oci.image.tag.to.manifest.plugin` |  The plugin to be used to get the image-tag to manifest mappings.\n+| `storm.oci.localorhdfs.image.tag.to.manifest.plugin.hdfs.hash.file`   |   The hdfs location of image-tag to manifest mapping file. You need to set it if `org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin` is used as `storm.oci.image.tag.to.manifest.plugin`.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NjgwMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549486803", "bodyText": "I assume there are default plugins for these last three?  Can we list them here?", "author": "agresch", "createdAt": "2020-12-28T21:06:13Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.\n+| `storm.oci.image`                      | The default docker image to be used if user doesn't specify which image to use. And it must belong to the `storm.oci.allowed.images` \n+| `topology.oci.image`                   | Topologies can specify which image to use. It must belong to the `storm.oci.allowed.images` |\n+| `storm.oci.cgroup.root`                | The root path of cgroup for docker to use. On RHEL7, it should be \"/sys/fs/cgroup\".\n+| `storm.oci.cgroup.parent`              | --cgroup-parent config for docker command. It must follow the constraints of docker commands. The path will be made as absolute path if it's a relative path because we saw some weird bugs ((the cgroup memory directory disappears after a while) when a relative path is used.\n+| `storm.oci.readonly.bindmounts`        | A list of read only bind mounted directories.\n+| `storm.oci.readwrite.bindmounts`       | A list of read-write bind mounted directories.\n+| `storm.oci.nscd.dir`                   | The directory of nscd (name service cache daemon), e.g. \"/var/run/nscd/\". nscd must be running so that profiling can work properly.\n+| `storm.oci.seccomp.profile`            | White listed syscalls seccomp Json file to be used as a seccomp filter\n+| `supervisor.worker.launcher`              | Full path to the worker-launcher executable.\n+| `storm.oci.image.hdfs.toplevel.dir`      |  The HDFS location under which the oci image manifests, layers and configs directories exist.\n+| `storm.oci.image.tag.to.manifest.plugin` |  The plugin to be used to get the image-tag to manifest mappings.\n+| `storm.oci.localorhdfs.image.tag.to.manifest.plugin.hdfs.hash.file`   |   The hdfs location of image-tag to manifest mapping file. You need to set it if `org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin` is used as `storm.oci.image.tag.to.manifest.plugin`.\n+| `storm.oci.manifest.to.resources.plugin` | The plugin to be used to get oci resource according to the manifest.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkxNTc4NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669915785", "bodyText": "storm.oci.manifest.to.resources.plugin and storm.oci.resources.localizer has no default value. We only have HDFS related plugins as of now, and we don't include storm-hdfs-oci in the package distribution by default\nAs for storm.oci.resources.local.dir, it is a little hard to describe the default value as it changes based on other configs.. not sure how to make it less confusing", "author": "Ethanlm", "createdAt": "2021-07-14T20:04:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NjgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4NzQxMA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549487410", "bodyText": "\"to the extlib-daemon\"", "author": "agresch", "createdAt": "2020-12-28T21:08:29Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.\n+| `storm.oci.image`                      | The default docker image to be used if user doesn't specify which image to use. And it must belong to the `storm.oci.allowed.images` \n+| `topology.oci.image`                   | Topologies can specify which image to use. It must belong to the `storm.oci.allowed.images` |\n+| `storm.oci.cgroup.root`                | The root path of cgroup for docker to use. On RHEL7, it should be \"/sys/fs/cgroup\".\n+| `storm.oci.cgroup.parent`              | --cgroup-parent config for docker command. It must follow the constraints of docker commands. The path will be made as absolute path if it's a relative path because we saw some weird bugs ((the cgroup memory directory disappears after a while) when a relative path is used.\n+| `storm.oci.readonly.bindmounts`        | A list of read only bind mounted directories.\n+| `storm.oci.readwrite.bindmounts`       | A list of read-write bind mounted directories.\n+| `storm.oci.nscd.dir`                   | The directory of nscd (name service cache daemon), e.g. \"/var/run/nscd/\". nscd must be running so that profiling can work properly.\n+| `storm.oci.seccomp.profile`            | White listed syscalls seccomp Json file to be used as a seccomp filter\n+| `supervisor.worker.launcher`              | Full path to the worker-launcher executable.\n+| `storm.oci.image.hdfs.toplevel.dir`      |  The HDFS location under which the oci image manifests, layers and configs directories exist.\n+| `storm.oci.image.tag.to.manifest.plugin` |  The plugin to be used to get the image-tag to manifest mappings.\n+| `storm.oci.localorhdfs.image.tag.to.manifest.plugin.hdfs.hash.file`   |   The hdfs location of image-tag to manifest mapping file. You need to set it if `org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin` is used as `storm.oci.image.tag.to.manifest.plugin`.\n+| `storm.oci.manifest.to.resources.plugin` | The plugin to be used to get oci resource according to the manifest.\n+| `storm.oci.resources.localizer`   | The plugin to use for oci resources localization. |\n+| `storm.oci.resources.local.dir` | The local directory for localized oci resources. |\n+\n+For example, \n+```bash\n+storm.resource.isolation.plugin: \"org.apache.storm.container.oci.RuncLibContainerManager\"\n+\n+storm.oci.allowed.images:\n+    - \"storm/rhel7:dev_current\"\n+    - \"storm/rhel7:dev_previous\"\n+    - \"storm/rhel7:dev_test\"\n+storm.oci.image: \"storm/rhel7:dev_current\"\n+\n+storm.oci.cgroup.parent: \"/storm\"\n+storm.oci.cgroup.root: \"/sys/fs/cgroup\"\n+storm.oci.image.hdfs.toplevel.dir: \"hdfs://host:port/containers/\"\n+storm.oci.image.tag.to.manifest.plugin: \"org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin\"\n+storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.hdfs.hash.file: \"hdfs://host:port/containers/image-tag-to-hash\"\n+storm.oci.manifest.to.resources.plugin: \"org.apache.storm.container.oci.HdfsManifestToResourcesPlugin\"\n+storm.oci.readonly.bindmounts:\n+    - \"/home/y/lib64/storm\"\n+    - \"/etc/krb5.conf\"\n+\n+storm.oci.resources.localizer: \"org.apache.storm.container.oci.HdfsOciResourcesLocalizer\"\n+storm.oci.seccomp.profile: \"/home/y/conf/storm/seccomp.json\"\n+```\n+\n+To use built-in plugins from `external/storm-hdfs-oci`, you need to build `external/storm-hdfs-oci` and copy `storm-hdfs-oci.jar` and its dependencies to `extlib-daemon` directory.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4Nzg1NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549487855", "bodyText": "invokes", "author": "agresch", "createdAt": "2020-12-28T21:10:21Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.\n+| `storm.oci.image`                      | The default docker image to be used if user doesn't specify which image to use. And it must belong to the `storm.oci.allowed.images` \n+| `topology.oci.image`                   | Topologies can specify which image to use. It must belong to the `storm.oci.allowed.images` |\n+| `storm.oci.cgroup.root`                | The root path of cgroup for docker to use. On RHEL7, it should be \"/sys/fs/cgroup\".\n+| `storm.oci.cgroup.parent`              | --cgroup-parent config for docker command. It must follow the constraints of docker commands. The path will be made as absolute path if it's a relative path because we saw some weird bugs ((the cgroup memory directory disappears after a while) when a relative path is used.\n+| `storm.oci.readonly.bindmounts`        | A list of read only bind mounted directories.\n+| `storm.oci.readwrite.bindmounts`       | A list of read-write bind mounted directories.\n+| `storm.oci.nscd.dir`                   | The directory of nscd (name service cache daemon), e.g. \"/var/run/nscd/\". nscd must be running so that profiling can work properly.\n+| `storm.oci.seccomp.profile`            | White listed syscalls seccomp Json file to be used as a seccomp filter\n+| `supervisor.worker.launcher`              | Full path to the worker-launcher executable.\n+| `storm.oci.image.hdfs.toplevel.dir`      |  The HDFS location under which the oci image manifests, layers and configs directories exist.\n+| `storm.oci.image.tag.to.manifest.plugin` |  The plugin to be used to get the image-tag to manifest mappings.\n+| `storm.oci.localorhdfs.image.tag.to.manifest.plugin.hdfs.hash.file`   |   The hdfs location of image-tag to manifest mapping file. You need to set it if `org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin` is used as `storm.oci.image.tag.to.manifest.plugin`.\n+| `storm.oci.manifest.to.resources.plugin` | The plugin to be used to get oci resource according to the manifest.\n+| `storm.oci.resources.localizer`   | The plugin to use for oci resources localization. |\n+| `storm.oci.resources.local.dir` | The local directory for localized oci resources. |\n+\n+For example, \n+```bash\n+storm.resource.isolation.plugin: \"org.apache.storm.container.oci.RuncLibContainerManager\"\n+\n+storm.oci.allowed.images:\n+    - \"storm/rhel7:dev_current\"\n+    - \"storm/rhel7:dev_previous\"\n+    - \"storm/rhel7:dev_test\"\n+storm.oci.image: \"storm/rhel7:dev_current\"\n+\n+storm.oci.cgroup.parent: \"/storm\"\n+storm.oci.cgroup.root: \"/sys/fs/cgroup\"\n+storm.oci.image.hdfs.toplevel.dir: \"hdfs://host:port/containers/\"\n+storm.oci.image.tag.to.manifest.plugin: \"org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin\"\n+storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.hdfs.hash.file: \"hdfs://host:port/containers/image-tag-to-hash\"\n+storm.oci.manifest.to.resources.plugin: \"org.apache.storm.container.oci.HdfsManifestToResourcesPlugin\"\n+storm.oci.readonly.bindmounts:\n+    - \"/home/y/lib64/storm\"\n+    - \"/etc/krb5.conf\"\n+\n+storm.oci.resources.localizer: \"org.apache.storm.container.oci.HdfsOciResourcesLocalizer\"\n+storm.oci.seccomp.profile: \"/home/y/conf/storm/seccomp.json\"\n+```\n+\n+To use built-in plugins from `external/storm-hdfs-oci`, you need to build `external/storm-hdfs-oci` and copy `storm-hdfs-oci.jar` and its dependencies to `extlib-daemon` directory.\n+\n+Additionally, if you want to access to secure hdfs, you also need to set the following configs.  \n+```\n+storm.hdfs.login.keytab\n+storm.hdfs.login.principal\n+```\n+\n+For example,\n+```\n+storm.hdfs.login.keytab: /etc/keytab\n+storm.hdfs.login.principal: primary/instance@REALM\n+```\n+\n+## Implementation\n+\n+##### Launch a container\n+\n+The supervisor calls RuncLibContainerManager to launch the container and the worker inside the container. It will first call the `storm.oci.image.tag.to.manifest.plugin`\n+to fetch the mapping of image tag to manifest. Then it calls `storm.oci.manifest.to.resources.plugin` to get the list of resources to be downloaded and invokes \n+`storm.oci.resources.localizer` to download the config of the image and the layers of the image to a local directory. It then composes a `oci-config.json` (see example in Appendix) and \n+invoke worker-launcher to launch the container.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5MDMyMQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549490321", "bodyText": "I think it would be nice to duplicate this info in cgroups_in_storm.md even if specific to runc.", "author": "agresch", "createdAt": "2020-12-28T21:20:20Z", "path": "docs/OCI-support.md", "diffHunk": "@@ -0,0 +1,1704 @@\n+---\n+title: OCI/Squashfs Runtime\n+layout: documentation\n+documentation: true\n+---\n+\n+# OCI/Squashfs Runtime\n+\n+OCI/Squashfs is a container runtime that allows topologies to run inside docker containers. However, unlike the existing\n+Docker runtime, the images are fetched from HDFS rather than from the Docker registry or requiring images to be pre-loaded\n+into Docker on each node. Docker does not need to be installed on the nodes in order for this runtime to work.\n+\n+Note: This has only been tested on RHEL7.\n+\n+## Motivation\n+\n+#### Docker runtime drawbacks\n+Using the current Docker runtime (see [Docker-support.md](Docker-support.md#Docker-Support) ) has some drawbacks:\n+\n+##### Docker Daemons Dependency\n+\n+The Docker daemons `dockerd` and `containerd` must be running on the system in order for the Docker runtime to function. \n+And these daemons can get out of sync which could cause nontrivial issues to the containers.\n+\n+##### Docker Registry Issues at Scale\n+\n+Using the Docker runtime on a large scale Storm cluster can overwhelm the Docker registry. In practice this requires\n+admins to pre-load a Docker image on all the cluster nodes in a controlled fashion before a large job requesting \n+the image can run.\n+\n+##### Image Costs in Time and Space\n+\n+Docker stores each image layer as a tar.gz archive. In order to use the layer, the compressed archive must be unpacked\n+into the node's filesystem. This can consume significant disk space, especially when the reliable image store location\n+capacity is relatively small. In addition, unpacking an image layer takes time, especially when the layer is large or \n+contains thousands of files. This additional time for unpacking delays container launch beyond the time needed to transfer\n+the layer data over the network.\n+\n+#### OCI/Squashfs Runtime advantages\n+\n+The OCI/Squashfs runtime avoids the drawback listed above in the following ways.\n+\n+##### No Docker dependencies on The Node\n+\n+Docker does not need to be installed on each node, nor is there a dependency on a daemon or service that needs to be started\n+by an admin before containers can be launched. All that is required to be present on each node is an OCI-compatible runtime like\n+`runc`.\n+\n+##### Leverages Distributed File Sytems For Scale\n+\n+Image can be fetched via HDFS or other distributed file systems instead of the Docker registry. This prevents a large cluster from\n+overwhelming a Docker registry when a big topology causes all of the nodes to request an image at once. This also allows large clusters\n+to run topologies more dynamically, as images would not need to be pre-loaded by admins on each node to prevent a large Docker registry\n+image request storm.\n+\n+##### Smaller, Faster images on The Node\n+\n+The new runtime handles layer localization directly, so layer formats other than tar archive can be supported. For example, each image layer\n+can be converted to squashfs images as part of copying the layers to HDFS. squashfs is a file system optimized for running directly on a\n+compressed image. With squashfs layers the layer data can remain compressed on the node saving disk space. Container launch after layer\n+localization is also faster, as the layers no longer need to be unpacked into a directory to become usable.\n+\n+\n+## Prerequisite \n+\n+First you need to use the`docker-to-squash.py` script to download docker images and configs, convert layers to squashfs files and put them to a directory in HDFS, for example\n+\n+```bash\n+python docker-to-squash.py pull-build-push-update --hdfs-root hdfs://hostname:port/containers \\\n+                      docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133,storm/rhel7:dev_current --log DEBUG --bootstrap\n+```\n+\n+With this command, all the layers belong to this image will be converted to squashfs file and be placed under `./layers` directory; \n+the manifest of this image will be placed under `./manifests` directory with the name as the sha256 value of the manifest content;\n+the config of this image will be placed under `./config` directory with the name as the sha256 value of the config content;\n+the mapping from the image tag to the sha256 value of the manifest  will be written to the \"./image-tag-to-manifest-file\".\n+\n+##### Example\n+\n+For example, the directory structure is like this:\n+\n+```bash\n+-bash-4.2$ hdfs dfs -ls /containers/*\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       7877 2020-12-04 14:29 /containers/config/ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\n+-r--r--r--   3 hdfsqa hadoop        160 2020-12-04 14:30 /containers/image-tag-to-hash\n+Found 7 items\n+-r--r--r--   3 hdfsqa hadoop   84697088 2020-12-04 14:28 /containers/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\n+-r--r--r--   3 hdfsqa hadoop  545267712 2020-12-04 14:28 /containers/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\n+-r--r--r--   3 hdfsqa hadoop   12906496 2020-10-06 15:24 /containers/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\n+-r--r--r--   3 hdfsqa hadoop   26091520 2020-10-06 15:22 /containers/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\n+-r--r--r--   3 hdfsqa hadoop       4096 2020-12-04 14:29 /containers/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\n+-r--r--r--   3 hdfsqa hadoop  121122816 2020-10-06 15:23 /containers/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\n+Found 1 items\n+-r--r--r--   3 hdfsqa hadoop       1793 2020-12-04 14:29 /containers/manifests/26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585\n+```\n+\n+The `image-tag-to-manifest-file`:\n+```bash\n+-bash-4.2$ hdfs dfs -cat /containers/image-tag-to-hash\n+storm/rhel7:dev_current:26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585#docker.xxx.com:4443/hadoop-user-images/storm/rhel7:20201202-232133\n+```\n+\n+The manifest file `26fd443859325d5911f3be5c5e231dddca88ee0d526456c0c92dd794148d8585`:\n+```json\n+{\n+  \"schemaVersion\": 2,\n+  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n+  \"config\": {\n+    \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n+    \"size\": 7877,\n+    \"digest\": \"sha256:ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e\"\n+  },\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 26858854,\n+      \"digest\": \"sha256:3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 123300113,\n+      \"digest\": \"sha256:ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 12927624,\n+      \"digest\": \"sha256:1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 567401434,\n+      \"digest\": \"sha256:18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 85748864,\n+      \"digest\": \"sha256:152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 186,\n+      \"digest\": \"sha256:344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n+      \"size\": 156,\n+      \"digest\": \"sha256:8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e\"\n+    }\n+  ]\n+}\n+```\n+\n+And the config file `ef1ff2c7167a1a6cd01e106f51b84a4d400611ba971c53cbc28de7919515ca4e` (some of the content is omitted):\n+```json\n+{\n+  \"architecture\": \"amd64\",\n+  \"config\": {\n+    \"Hostname\": \"\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/bash\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"container\": \"344ff1084dea3e0501a0d426e52c43cd589d6b29f33ab0915b7be8906b9aec41\",\n+  \"container_config\": {\n+    \"Hostname\": \"344ff1084dea\",\n+    \"Domainname\": \"\",\n+    \"User\": \"root\",\n+    \"AttachStdin\": false,\n+    \"AttachStdout\": false,\n+    \"AttachStderr\": false,\n+    \"Tty\": false,\n+    \"OpenStdin\": false,\n+    \"StdinOnce\": false,\n+    \"Env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\"\n+    ],\n+    \"Cmd\": [\n+      \"/bin/sh\",\n+      \"-c\"\n+    ],\n+    \"Image\": \"sha256:6977cd0735c96d14248e834f775373e40230c134b70f10163c05ce6c6c8873ca\",\n+    \"Volumes\": null,\n+    \"WorkingDir\": \"\",\n+    \"Entrypoint\": null,\n+    \"OnBuild\": null,\n+    \"Labels\": {\n+      \"name\": \"xxxxx\"\n+    }\n+  },\n+  \"created\": \"2020-12-02T23:25:47.354704574Z\",\n+  \"docker_version\": \"19.03.8\",\n+  \"history\": [\n+    {\n+      \"created\": \"2020-02-18T21:43:36.934503462Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:45:05.729764427Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-02-18T21:46:36.638896031Z\",\n+      \"created_by\": \"/bin/sh\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:21:54.595662813Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  USER root\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:45.822235539Z\",\n+      \"created_by\": \"/bin/sh -c /opt/python/bin/pip3.6 install --no-cache-dir numpy scipy pandas requests setuptools scikit-learn matplotlib\"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.708884538Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.770226108Z\",\n+      \"created_by\": \"/bin/sh -c #(nop)  ENV PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"empty_layer\": true\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:46.837263533Z\",\n+      \"created_by\": \"/bin/sh -c #(nop) COPY file:33283617fbd796b25e53eaf4d26012eea1f610ff9acc0706f11281e86be440dc in /etc/krb5.conf \"\n+    },\n+    {\n+      \"created\": \"2020-12-02T23:25:47.237515768Z\",\n+      \"created_by\": \"/bin/sh -c echo '7.7.4' \\u003e /etc/hadoop-dockerfile-version\"\n+    }\n+  ],\n+  \"os\": \"linux\",\n+  \"rootfs\": {\n+    \"type\": \"layers\",\n+    \"diff_ids\": [\n+      \"sha256:9f627fdb0292afbe5e2eb96edc1b3a5d3a8f468e3acf1d29f1509509285c7341\",\n+      \"sha256:83d2667f9458eaf719588a96bb63f2520bd377d29d52f6dbd4ff13c819c08037\",\n+      \"sha256:fcba5f49eef4f3d77d3e73e499a1a4e1914b3f20d903625d27c0aa3ab82f41a3\",\n+      \"sha256:3bd4567d0726f5d6560b548bc0c0400e868f6a27067887a36edd7e8ceafff96c\",\n+      \"sha256:ad56900a1f10e6ef96f17c7e8019384540ab1b34ccce6bda06675473b08d787e\",\n+      \"sha256:ac0a645609f957ab9c4a8a62f8646e99f09a74ada54ed2eaca204c6e183c9ae8\",\n+      \"sha256:9bf10102fc145156f4081c2cacdbadab5816dce4f88eb02881ab739239d316e6\"\n+    ]\n+  }\n+}\n+```\n+\n+Note: To use the `docker-to-squash.py`, you need to install [skopeo](https://github.com/containers/skopeo), [jq](https://stedolan.github.io/jq/) and squashfs-tools.\n+\n+\n+## Configurations\n+\n+Then you need to set up storm with the following configs:\n+\n+| Setting                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n+|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n+| `storm.resource.isolation.plugin.enable`  | set to `true` to enable isolation plugin. `storm.resource.isolation.plugin` determines which plugin to use. If this is set to `false`, `org.apache.storm.container.DefaultResourceIsolationManager` will be used.                                                                                                                                                                                                                                           |\n+| `storm.resource.isolation.plugin`         | set to `\"org.apache.storm.container.oci.RuncLibContainerManager\"` to enable OCI/Squash runtime support                                                                                                                                                                                                                                                                                                                                                                                                                              |\n+| `storm.oci.allowed.images`             | A whitelist of docker images that can be used. Users can only choose a docker image from the list.\n+| `storm.oci.image`                      | The default docker image to be used if user doesn't specify which image to use. And it must belong to the `storm.oci.allowed.images` \n+| `topology.oci.image`                   | Topologies can specify which image to use. It must belong to the `storm.oci.allowed.images` |\n+| `storm.oci.cgroup.root`                | The root path of cgroup for docker to use. On RHEL7, it should be \"/sys/fs/cgroup\".\n+| `storm.oci.cgroup.parent`              | --cgroup-parent config for docker command. It must follow the constraints of docker commands. The path will be made as absolute path if it's a relative path because we saw some weird bugs ((the cgroup memory directory disappears after a while) when a relative path is used.\n+| `storm.oci.readonly.bindmounts`        | A list of read only bind mounted directories.\n+| `storm.oci.readwrite.bindmounts`       | A list of read-write bind mounted directories.\n+| `storm.oci.nscd.dir`                   | The directory of nscd (name service cache daemon), e.g. \"/var/run/nscd/\". nscd must be running so that profiling can work properly.\n+| `storm.oci.seccomp.profile`            | White listed syscalls seccomp Json file to be used as a seccomp filter\n+| `supervisor.worker.launcher`              | Full path to the worker-launcher executable.\n+| `storm.oci.image.hdfs.toplevel.dir`      |  The HDFS location under which the oci image manifests, layers and configs directories exist.\n+| `storm.oci.image.tag.to.manifest.plugin` |  The plugin to be used to get the image-tag to manifest mappings.\n+| `storm.oci.localorhdfs.image.tag.to.manifest.plugin.hdfs.hash.file`   |   The hdfs location of image-tag to manifest mapping file. You need to set it if `org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin` is used as `storm.oci.image.tag.to.manifest.plugin`.\n+| `storm.oci.manifest.to.resources.plugin` | The plugin to be used to get oci resource according to the manifest.\n+| `storm.oci.resources.localizer`   | The plugin to use for oci resources localization. |\n+| `storm.oci.resources.local.dir` | The local directory for localized oci resources. |\n+\n+For example, \n+```bash\n+storm.resource.isolation.plugin: \"org.apache.storm.container.oci.RuncLibContainerManager\"\n+\n+storm.oci.allowed.images:\n+    - \"storm/rhel7:dev_current\"\n+    - \"storm/rhel7:dev_previous\"\n+    - \"storm/rhel7:dev_test\"\n+storm.oci.image: \"storm/rhel7:dev_current\"\n+\n+storm.oci.cgroup.parent: \"/storm\"\n+storm.oci.cgroup.root: \"/sys/fs/cgroup\"\n+storm.oci.image.hdfs.toplevel.dir: \"hdfs://host:port/containers/\"\n+storm.oci.image.tag.to.manifest.plugin: \"org.apache.storm.container.oci.LocalOrHdfsImageTagToManifestPlugin\"\n+storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.hdfs.hash.file: \"hdfs://host:port/containers/image-tag-to-hash\"\n+storm.oci.manifest.to.resources.plugin: \"org.apache.storm.container.oci.HdfsManifestToResourcesPlugin\"\n+storm.oci.readonly.bindmounts:\n+    - \"/home/y/lib64/storm\"\n+    - \"/etc/krb5.conf\"\n+\n+storm.oci.resources.localizer: \"org.apache.storm.container.oci.HdfsOciResourcesLocalizer\"\n+storm.oci.seccomp.profile: \"/home/y/conf/storm/seccomp.json\"\n+```\n+\n+To use built-in plugins from `external/storm-hdfs-oci`, you need to build `external/storm-hdfs-oci` and copy `storm-hdfs-oci.jar` and its dependencies to `extlib-daemon` directory.\n+\n+Additionally, if you want to access to secure hdfs, you also need to set the following configs.  \n+```\n+storm.hdfs.login.keytab\n+storm.hdfs.login.principal\n+```\n+\n+For example,\n+```\n+storm.hdfs.login.keytab: /etc/keytab\n+storm.hdfs.login.principal: primary/instance@REALM\n+```\n+\n+## Implementation\n+\n+##### Launch a container\n+\n+The supervisor calls RuncLibContainerManager to launch the container and the worker inside the container. It will first call the `storm.oci.image.tag.to.manifest.plugin`\n+to fetch the mapping of image tag to manifest. Then it calls `storm.oci.manifest.to.resources.plugin` to get the list of resources to be downloaded and invokes \n+`storm.oci.resources.localizer` to download the config of the image and the layers of the image to a local directory. It then composes a `oci-config.json` (see example in Appendix) and \n+invoke worker-launcher to launch the container.\n+\n+The worker-launcher parses the `oci-config.json` file and do some necessary initialization and set up. It then creates /run/worker-launcher/layers/xxx/mnt directories \n+and associate them with loopback devices, for example:\n+\n+```bash\n+-bash-4.2$ cat /proc/mounts\n+...\n+/dev/loop3 /run/worker-launcher/layers/f7452c2657900c53da1a4f7e430485a267b89c7717466ee61ffefba85f690226/mnt squashfs ro,relatime 0 0\n+/dev/loop4 /run/worker-launcher/layers/8156da43228752c7364b71dabba6aef6bd1cc081e9ea59cf92ea0f79fd8a50b6/mnt squashfs ro,relatime 0 0\n+/dev/loop5 /run/worker-launcher/layers/c7c9b1d6df043edf307c49d75c7d2bc3df72f8dcaf7d17b733c97022387902e6/mnt squashfs ro,relatime 0 0\n+/dev/loop6 /run/worker-launcher/layers/f0d08d5707855b02def8ac622a6c60203b380e31c6c237e5b691f5856594a3e7/mnt squashfs ro,relatime 0 0\n+/dev/loop11 /run/worker-launcher/layers/34b0bc9c446a9be565fb50b04db1e9d1c1c4d14a22a885a7aba6981748b6635e/mnt squashfs ro,relatime 0 0\n+/dev/loop12 /run/worker-launcher/layers/0ba001c025aa172a7d630914c75c1772228606f622e2c9d46a8fedf10774623e/mnt squashfs ro,relatime 0 0\n+/dev/loop13 /run/worker-launcher/layers/a5e4e615565081e04eaf4c5ab5b20d37de271db704fc781c7b1e07c5dcdf96e5/mnt squashfs ro,relatime 0 0\n+...\n+\n+```\n+\n+Then it mounts the layers, for example:\n+```bash\n+-bash-4.2$ mount\n+...\n+/home/y/var/storm/supervisor/oci-resources/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh on /run/worker-launcher/layers/f7452c2657900c53da1a4f7e430485a267b89c7717466ee61ffefba85f690226/mnt type squashfs (ro,relatime)\n+/home/y/var/storm/supervisor/oci-resources/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh on /run/worker-launcher/layers/8156da43228752c7364b71dabba6aef6bd1cc081e9ea59cf92ea0f79fd8a50b6/mnt type squashfs (ro,relatime)\n+/home/y/var/storm/supervisor/oci-resources/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh on /run/worker-launcher/layers/c7c9b1d6df043edf307c49d75c7d2bc3df72f8dcaf7d17b733c97022387902e6/mnt type squashfs (ro,relatime)\n+/home/y/var/storm/supervisor/oci-resources/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh on /run/worker-launcher/layers/f0d08d5707855b02def8ac622a6c60203b380e31c6c237e5b691f5856594a3e7/mnt type squashfs (ro,relatime)\n+/home/y/var/storm/supervisor/oci-resources/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh on /run/worker-launcher/layers/34b0bc9c446a9be565fb50b04db1e9d1c1c4d14a22a885a7aba6981748b6635e/mnt type squashfs (ro,relatime)\n+/home/y/var/storm/supervisor/oci-resources/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh on /run/worker-launcher/layers/0ba001c025aa172a7d630914c75c1772228606f622e2c9d46a8fedf10774623e/mnt type squashfs (ro,relatime)\n+/home/y/var/storm/supervisor/oci-resources/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh on /run/worker-launcher/layers/a5e4e615565081e04eaf4c5ab5b20d37de271db704fc781c7b1e07c5dcdf96e5/mnt type squashfs (ro,relatime)\n+...\n+```\n+\n+It creates the rootfs and mount the overlay filesystem (with lowerdir,upperdir,workdir) for the worker with the command \n+```bash\n+mount -t overlay overlay -o lowerdir=/lower1:/lower2:/lower3,upperdir=/upper,workdir=/work /merged\n+```\n+\n+```bash\n+-bash-4.2$ mount\n+...\n+overlay on /run/worker-launcher/6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/rootfs type overlay (rw,relatime,lowerdir=/run/worker-launcher/layers/a5e4e615565081e04eaf4c5ab5b20d37de271db704fc781c7b1e07c5dcdf96e5/mnt:/run/worker-launcher/layers/0ba001c025aa172a7d630914c75c1772228606f622e2c9d46a8fedf10774623e/mnt:/run/worker-launcher/layers/34b0bc9c446a9be565fb50b04db1e9d1c1c4d14a22a885a7aba6981748b6635e/mnt:/run/worker-launcher/layers/f0d08d5707855b02def8ac622a6c60203b380e31c6c237e5b691f5856594a3e7/mnt:/run/worker-launcher/layers/c7c9b1d6df043edf307c49d75c7d2bc3df72f8dcaf7d17b733c97022387902e6/mnt:/run/worker-launcher/layers/8156da43228752c7364b71dabba6aef6bd1cc081e9ea59cf92ea0f79fd8a50b6/mnt:/run/worker-launcher/layers/f7452c2657900c53da1a4f7e430485a267b89c7717466ee61ffefba85f690226/mnt,upperdir=/run/worker-launcher/6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/upper,workdir=/run/worker-launcher/6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/work)\n+...\n+```\n+\n+It then produce a `config.json` (see example at Appendix) under `/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb` directory and launch the container with\n+the command\n+```bash\n+/usr/bin/runc run -d \\\n+              --pid-file /home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/artifacts/container-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb.pid \\\n+              -b /home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb \\\n+              6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\n+```\n+\n+##### Kill a container\n+\n+To kill a container, `RuncLibContainerManager` sends the `SIGTERM` or `SIGKILL` signal to the container process. It then invokes worker-launcher to to umount the mounts and clean up the directories. \n+The worker-launcher will invoke `runc delete container-id` to delete the container at the end.\n+\n+\n+## Profile the processes inside the container\n+If you have sudo permission, you can also run `sudo nsenter --target <container-pid> --pid --mount --setuid <uid> --setgid <gid>` to enter the container. \n+Then you can run `jstack`, `jmap` etc inside the container. `<container-pid>` is the pid of the container process on the host.\n+`<container-pid>` can be obtained by running `runc list` command.\n+\n+## Seccomp security profiles\n+\n+You can set `storm.oci.seccomp.profile` to restrict the actions available within the container. If it's not set, the container runs without\n+restrictions. You can use `conf/seccomp.json.example` provided or you can specify our own `seccomp.json` file. \n+\n+\n+## Appendix\n+\n+##### Example oci-config.json file\n+```json\n+{\n+  \"version\": \"0.1\",\n+  \"username\": \"username1\",\n+  \"containerId\": \"6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+  \"pidFile\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/artifacts/container-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb.pid\",\n+  \"containerScriptPath\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/storm-worker-script.sh\",\n+  \"layers\": [\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/3692c3483ef6516fba685b316448e8aaf0fc10bb66818116edc8e5e6800076c7.sqsh\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/ea067172a7138f035d89a5c378db6d66c1581d98b0497b21f256e04c3d2b5303.sqsh\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/1b73e9433ecca0a6bb152bd7525f2b7c233484d51c24f8a6ba483d5cfd3035dc.sqsh\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/18ee671016a1bf3ecab07395d93c2cbecd352d59c497a1551e2074d64e1098d9.sqsh\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/152ee1d2cccea9dfe6393d2bdf9d077b67616b2b417b25eb74fc5ffaadcb96f5.sqsh\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/344224962010c03c9ca1f11a9bff0dfcc296ac46d0a55e4ff30a0ad13b9817af.sqsh\"\n+    },\n+    {\n+      \"mediaType\": \"application/vnd.squashfs\",\n+      \"path\": \"/home/y/var/storm/supervisor/oci-resources/layers/8710a3d72f75b45c48ab6b9b67eb6d77caea3dac91a0c30e0831f591cba4887e.sqsh\"\n+    }\n+  ],\n+  \"reapLayerKeepCount\": 100,\n+  \"ociRuntimeConfig\": {\n+    \"mounts\": [\n+      {\n+        \"destination\": \"/home/y/lib64/storm\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/lib64/storm\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/etc/krb5.conf\",\n+        \"type\": \"bind\",\n+        \"source\": \"/etc/krb5.conf\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/etc/resolv.conf\",\n+        \"type\": \"bind\",\n+        \"source\": \"/etc/resolv.conf\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/etc/hostname\",\n+        \"type\": \"bind\",\n+        \"source\": \"/etc/hostname\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/etc/hosts\",\n+        \"type\": \"bind\",\n+        \"source\": \"/etc/hosts\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/var/run/nscd\",\n+        \"type\": \"bind\",\n+        \"source\": \"/var/run/nscd\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/sys/fs/cgroup\",\n+        \"type\": \"bind\",\n+        \"source\": \"/sys/fs/cgroup\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/home/y/var/storm/supervisor\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/var/storm/supervisor\",\n+        \"options\": [\n+          \"ro\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+        \"options\": [\n+          \"rw\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/home/y/var/storm/workers-artifacts/wc1-2-1608581491/6703\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/var/storm/workers-artifacts/wc1-2-1608581491/6703\",\n+        \"options\": [\n+          \"rw\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/home/y/var/storm/workers-users/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/var/storm/workers-users/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+        \"options\": [\n+          \"rw\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/shared_by_topology\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/shared_by_topology\",\n+        \"options\": [\n+          \"rw\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      },\n+      {\n+        \"destination\": \"/tmp\",\n+        \"type\": \"bind\",\n+        \"source\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/tmp\",\n+        \"options\": [\n+          \"rw\",\n+          \"rbind\",\n+          \"rprivate\"\n+        ]\n+      }\n+    ],\n+    \"process\": {\n+      \"cwd\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+      \"env\": [\n+        \"X_SCLS=rh-git218\",\n+        \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+        \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+        \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+        \"LANG=en_US.UTF-8\",\n+        \"LANGUAGE=en_US:en\",\n+        \"LC_ALL=en_US.UTF-8\",\n+        \"JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+        \"LD_LIBRARY_PATH=/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/resources/Linux-amd64:/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/resources:/home/y/lib64:/usr/local/lib64:/usr/lib64:/lib64:\"\n+      ],\n+      \"args\": [\n+        \"bash\",\n+        \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/storm-worker-script.sh\"\n+      ]\n+    },\n+    \"linux\": {\n+      \"cgroupsPath\": \"/storm/6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+      \"resources\": {\n+        \"cpu\": {\n+          \"quota\": 140000,\n+          \"period\": 100000\n+        }\n+      },\n+      \"seccomp\": {\n+        \"defaultAction\": \"SCMP_ACT_ERRNO\",\n+        \"syscalls\": [\n+          {\n+            \"names\": [\n+              \"accept\",\n+              \"accept4\",\n+              \"access\",\n+              \"alarm\",\n+              \"alarm\",\n+              \"bind\",\n+              \"brk\",\n+              \"capget\",\n+              \"capset\",\n+              \"chdir\",\n+              \"chmod\",\n+              \"chown\",\n+              \"chown32\",\n+              \"clock_getres\",\n+              \"clock_gettime\",\n+              \"clock_nanosleep\",\n+              \"close\",\n+              \"connect\",\n+              \"copy_file_range\",\n+              \"creat\",\n+              \"dup\",\n+              \"dup2\",\n+              \"dup3\",\n+              \"epoll_create\",\n+              \"epoll_create1\",\n+              \"epoll_ctl\",\n+              \"epoll_ctl_old\",\n+              \"epoll_pwait\",\n+              \"epoll_wait\",\n+              \"epoll_wait_old\",\n+              \"eventfd\",\n+              \"eventfd2\",\n+              \"execve\",\n+              \"execveat\",\n+              \"exit\",\n+              \"exit_group\",\n+              \"faccessat\",\n+              \"fadvise64\",\n+              \"fadvise64_64\",\n+              \"fallocate\",\n+              \"fanotify_mark\",\n+              \"fchdir\",\n+              \"fchmod\",\n+              \"fchmodat\",\n+              \"fchown\",\n+              \"fchown32\",\n+              \"fchownat\",\n+              \"fcntl\",\n+              \"fcntl64\",\n+              \"fdatasync\",\n+              \"fgetxattr\",\n+              \"flistxattr\",\n+              \"flock\",\n+              \"fork\",\n+              \"fremovexattr\",\n+              \"fsetxattr\",\n+              \"fstat\",\n+              \"fstat64\",\n+              \"fstatat64\",\n+              \"fstatfs\",\n+              \"fstatfs64\",\n+              \"fsync\",\n+              \"ftruncate\",\n+              \"ftruncate64\",\n+              \"futex\",\n+              \"futimesat\",\n+              \"getcpu\",\n+              \"getcwd\",\n+              \"getdents\",\n+              \"getdents64\",\n+              \"getegid\",\n+              \"getegid32\",\n+              \"geteuid\",\n+              \"geteuid32\",\n+              \"getgid\",\n+              \"getgid32\",\n+              \"getgroups\",\n+              \"getgroups32\",\n+              \"getitimer\",\n+              \"getpeername\",\n+              \"getpgid\",\n+              \"getpgrp\",\n+              \"getpid\",\n+              \"getppid\",\n+              \"getpriority\",\n+              \"getrandom\",\n+              \"getresgid\",\n+              \"getresgid32\",\n+              \"getresuid\",\n+              \"getresuid32\",\n+              \"getrlimit\",\n+              \"get_robust_list\",\n+              \"getrusage\",\n+              \"getsid\",\n+              \"getsockname\",\n+              \"getsockopt\",\n+              \"get_thread_area\",\n+              \"gettid\",\n+              \"gettimeofday\",\n+              \"getuid\",\n+              \"getuid32\",\n+              \"getxattr\",\n+              \"inotify_add_watch\",\n+              \"inotify_init\",\n+              \"inotify_init1\",\n+              \"inotify_rm_watch\",\n+              \"io_cancel\",\n+              \"ioctl\",\n+              \"io_destroy\",\n+              \"io_getevents\",\n+              \"ioprio_get\",\n+              \"ioprio_set\",\n+              \"io_setup\",\n+              \"io_submit\",\n+              \"ipc\",\n+              \"kill\",\n+              \"lchown\",\n+              \"lchown32\",\n+              \"lgetxattr\",\n+              \"link\",\n+              \"linkat\",\n+              \"listen\",\n+              \"listxattr\",\n+              \"llistxattr\",\n+              \"_llseek\",\n+              \"lremovexattr\",\n+              \"lseek\",\n+              \"lsetxattr\",\n+              \"lstat\",\n+              \"lstat64\",\n+              \"madvise\",\n+              \"mbind\",\n+              \"memfd_create\",\n+              \"mincore\",\n+              \"mkdir\",\n+              \"mkdirat\",\n+              \"mknod\",\n+              \"mknodat\",\n+              \"mlock\",\n+              \"mlock2\",\n+              \"mlockall\",\n+              \"mmap\",\n+              \"mmap2\",\n+              \"mprotect\",\n+              \"mq_getsetattr\",\n+              \"mq_notify\",\n+              \"mq_open\",\n+              \"mq_timedreceive\",\n+              \"mq_timedsend\",\n+              \"mq_unlink\",\n+              \"mremap\",\n+              \"msgctl\",\n+              \"msgget\",\n+              \"msgrcv\",\n+              \"msgsnd\",\n+              \"msync\",\n+              \"munlock\",\n+              \"munlockall\",\n+              \"munmap\",\n+              \"nanosleep\",\n+              \"newfstatat\",\n+              \"_newselect\",\n+              \"open\",\n+              \"openat\",\n+              \"pause\",\n+              \"pipe\",\n+              \"pipe2\",\n+              \"poll\",\n+              \"ppoll\",\n+              \"prctl\",\n+              \"pread64\",\n+              \"preadv\",\n+              \"prlimit64\",\n+              \"pselect6\",\n+              \"pwrite64\",\n+              \"pwritev\",\n+              \"read\",\n+              \"readahead\",\n+              \"readlink\",\n+              \"readlinkat\",\n+              \"readv\",\n+              \"recv\",\n+              \"recvfrom\",\n+              \"recvmmsg\",\n+              \"recvmsg\",\n+              \"remap_file_pages\",\n+              \"removexattr\",\n+              \"rename\",\n+              \"renameat\",\n+              \"renameat2\",\n+              \"restart_syscall\",\n+              \"rmdir\",\n+              \"rt_sigaction\",\n+              \"rt_sigpending\",\n+              \"rt_sigprocmask\",\n+              \"rt_sigqueueinfo\",\n+              \"rt_sigreturn\",\n+              \"rt_sigsuspend\",\n+              \"rt_sigtimedwait\",\n+              \"rt_tgsigqueueinfo\",\n+              \"sched_getaffinity\",\n+              \"sched_getattr\",\n+              \"sched_getparam\",\n+              \"sched_get_priority_max\",\n+              \"sched_get_priority_min\",\n+              \"sched_getscheduler\",\n+              \"sched_rr_get_interval\",\n+              \"sched_setaffinity\",\n+              \"sched_setattr\",\n+              \"sched_setparam\",\n+              \"sched_setscheduler\",\n+              \"sched_yield\",\n+              \"seccomp\",\n+              \"select\",\n+              \"semctl\",\n+              \"semget\",\n+              \"semop\",\n+              \"semtimedop\",\n+              \"send\",\n+              \"sendfile\",\n+              \"sendfile64\",\n+              \"sendmmsg\",\n+              \"sendmsg\",\n+              \"sendto\",\n+              \"setfsgid\",\n+              \"setfsgid32\",\n+              \"setfsuid\",\n+              \"setfsuid32\",\n+              \"setgid\",\n+              \"setgid32\",\n+              \"setgroups\",\n+              \"setgroups32\",\n+              \"setitimer\",\n+              \"setpgid\",\n+              \"setpriority\",\n+              \"setregid\",\n+              \"setregid32\",\n+              \"setresgid\",\n+              \"setresgid32\",\n+              \"setresuid\",\n+              \"setresuid32\",\n+              \"setreuid\",\n+              \"setreuid32\",\n+              \"setrlimit\",\n+              \"set_robust_list\",\n+              \"setsid\",\n+              \"setsockopt\",\n+              \"set_thread_area\",\n+              \"set_tid_address\",\n+              \"setuid\",\n+              \"setuid32\",\n+              \"setxattr\",\n+              \"shmat\",\n+              \"shmctl\",\n+              \"shmdt\",\n+              \"shmget\",\n+              \"shutdown\",\n+              \"sigaltstack\",\n+              \"signalfd\",\n+              \"signalfd4\",\n+              \"sigreturn\",\n+              \"socket\",\n+              \"socketcall\",\n+              \"socketpair\",\n+              \"splice\",\n+              \"stat\",\n+              \"stat64\",\n+              \"statfs\",\n+              \"statfs64\",\n+              \"symlink\",\n+              \"symlinkat\",\n+              \"sync\",\n+              \"sync_file_range\",\n+              \"syncfs\",\n+              \"sysinfo\",\n+              \"syslog\",\n+              \"tee\",\n+              \"tgkill\",\n+              \"time\",\n+              \"timer_create\",\n+              \"timer_delete\",\n+              \"timerfd_create\",\n+              \"timerfd_gettime\",\n+              \"timerfd_settime\",\n+              \"timer_getoverrun\",\n+              \"timer_gettime\",\n+              \"timer_settime\",\n+              \"times\",\n+              \"tkill\",\n+              \"truncate\",\n+              \"truncate64\",\n+              \"ugetrlimit\",\n+              \"umask\",\n+              \"uname\",\n+              \"unlink\",\n+              \"unlinkat\",\n+              \"utime\",\n+              \"utimensat\",\n+              \"utimes\",\n+              \"vfork\",\n+              \"vmsplice\",\n+              \"wait4\",\n+              \"waitid\",\n+              \"waitpid\",\n+              \"write\",\n+              \"writev\",\n+              \"mount\",\n+              \"umount2\",\n+              \"reboot\",\n+              \"name_to_handle_at\",\n+              \"unshare\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\"\n+          },\n+          {\n+            \"names\": [\n+              \"personality\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\",\n+            \"args\": [\n+              {\n+                \"index\": 0,\n+                \"value\": 0,\n+                \"valueTwo\": 0,\n+                \"op\": \"SCMP_CMP_EQ\"\n+              }\n+            ]\n+          },\n+          {\n+            \"names\": [\n+              \"personality\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\",\n+            \"args\": [\n+              {\n+                \"index\": 0,\n+                \"value\": 8,\n+                \"valueTwo\": 0,\n+                \"op\": \"SCMP_CMP_EQ\"\n+              }\n+            ]\n+          },\n+          {\n+            \"names\": [\n+              \"personality\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\",\n+            \"args\": [\n+              {\n+                \"index\": 0,\n+                \"value\": 4294967295,\n+                \"valueTwo\": 0,\n+                \"op\": \"SCMP_CMP_EQ\"\n+              }\n+            ]\n+          },\n+          {\n+            \"names\": [\n+              \"arch_prctl\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\"\n+          },\n+          {\n+            \"names\": [\n+              \"modify_ldt\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\"\n+          },\n+          {\n+            \"names\": [\n+              \"clone\"\n+            ],\n+            \"action\": \"SCMP_ACT_ALLOW\",\n+            \"args\": [\n+              {\n+                \"index\": 0,\n+                \"value\": 2080505856,\n+                \"valueTwo\": 0,\n+                \"op\": \"SCMP_CMP_MASKED_EQ\"\n+              }\n+            ]\n+          }\n+        ]\n+      }\n+    }\n+  }\n+}\n+```\n+\n+##### Example config.json file\n+```json\n+{\n+  \"ociVersion\": \"1.0.0\",\n+  \"hostname\": \"hostname1\",\n+  \"root\": {\n+    \"path\": \"/run/worker-launcher/6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/rootfs\",\n+    \"readonly\": true\n+  },\n+  \"process\": {\n+    \"args\": [\n+      \"bash\",\n+      \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/storm-worker-script.sh\"\n+    ],\n+    \"cwd\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+    \"env\": [\n+      \"X_SCLS=rh-git218\",\n+      \"LD_LIBRARY_PATH=/opt/rh/httpd24/root/usr/lib64\",\n+      \"PATH=/opt/rh/rh-git218/root/usr/bin:/home/y/bin64:/home/y/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/y/share/yjava_jdk/java/bin\",\n+      \"PERL5LIB=/opt/rh/rh-git218/root/usr/share/perl5/vendor_perl\",\n+      \"LANG=en_US.UTF-8\",\n+      \"LANGUAGE=en_US:en\",\n+      \"LC_ALL=en_US.UTF-8\",\n+      \"JAVA_HOME=/home/y/share/yjava_jdk/java\",\n+      \"LD_LIBRARY_PATH=/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/resources/Linux-amd64:/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/resources:/home/y/lib64:/usr/local/lib64:/usr/lib64:/lib64:\"\n+    ],\n+    \"noNewPrivileges\": true,\n+    \"user\": {\n+      \"uid\": 31315,\n+      \"gid\": 100,\n+      \"additionalGids\": [\n+        5548\n+      ]\n+    }\n+  },\n+  \"mounts\": [\n+    {\n+      \"source\": \"proc\",\n+      \"destination\": \"/proc\",\n+      \"type\": \"proc\"\n+    },\n+    {\n+      \"source\": \"tmpfs\",\n+      \"destination\": \"/dev\",\n+      \"type\": \"tmpfs\",\n+      \"options\": [\n+        \"nosuid\",\n+        \"strictatime\",\n+        \"mode=755\",\n+        \"size=65536k\"\n+      ]\n+    },\n+    {\n+      \"source\": \"devpts\",\n+      \"destination\": \"/dev/pts\",\n+      \"type\": \"devpts\",\n+      \"options\": [\n+        \"nosuid\",\n+        \"noexec\",\n+        \"newinstance\",\n+        \"ptmxmode=0666\",\n+        \"mode=0620\",\n+        \"gid=5\"\n+      ]\n+    },\n+    {\n+      \"source\": \"shm\",\n+      \"destination\": \"/dev/shm\",\n+      \"type\": \"tmpfs\",\n+      \"options\": [\n+        \"nosuid\",\n+        \"noexec\",\n+        \"nodev\",\n+        \"mode=1777\",\n+        \"size=65536k\"\n+      ]\n+    },\n+    {\n+      \"source\": \"mqueue\",\n+      \"destination\": \"/dev/mqueue\",\n+      \"type\": \"mqueue\",\n+      \"options\": [\n+        \"nosuid\",\n+        \"noexec\",\n+        \"nodev\"\n+      ]\n+    },\n+    {\n+      \"source\": \"sysfs\",\n+      \"destination\": \"/sys\",\n+      \"type\": \"sysfs\",\n+      \"options\": [\n+        \"nosuid\",\n+        \"noexec\",\n+        \"nodev\",\n+        \"ro\"\n+      ]\n+    },\n+    {\n+      \"source\": \"cgroup\",\n+      \"destination\": \"/sys/fs/cgroup\",\n+      \"type\": \"cgroup\",\n+      \"options\": [\n+        \"nosuid\",\n+        \"noexec\",\n+        \"nodev\",\n+        \"relatime\",\n+        \"ro\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/home/y/lib64/storm\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/lib64/storm\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/etc/krb5.conf\",\n+      \"type\": \"bind\",\n+      \"source\": \"/etc/krb5.conf\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/etc/resolv.conf\",\n+      \"type\": \"bind\",\n+      \"source\": \"/etc/resolv.conf\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/etc/hostname\",\n+      \"type\": \"bind\",\n+      \"source\": \"/etc/hostname\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/etc/hosts\",\n+      \"type\": \"bind\",\n+      \"source\": \"/etc/hosts\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/var/run/nscd\",\n+      \"type\": \"bind\",\n+      \"source\": \"/var/run/nscd\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    \n+    {\n+      \"destination\": \"/sys/fs/cgroup\",\n+      \"type\": \"bind\",\n+      \"source\": \"/sys/fs/cgroup\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/home/y/var/storm/supervisor\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/var/storm/supervisor\",\n+      \"options\": [\n+        \"ro\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+      \"options\": [\n+        \"rw\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/home/y/var/storm/workers-artifacts/wc1-2-1608581491/6703\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/var/storm/workers-artifacts/wc1-2-1608581491/6703\",\n+      \"options\": [\n+        \"rw\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/home/y/var/storm/workers-users/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/var/storm/workers-users/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+      \"options\": [\n+        \"rw\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/shared_by_topology\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/var/storm/supervisor/stormdist/wc1-2-1608581491/shared_by_topology\",\n+      \"options\": [\n+        \"rw\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    },\n+    {\n+      \"destination\": \"/tmp\",\n+      \"type\": \"bind\",\n+      \"source\": \"/home/y/var/storm/workers/1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb/tmp\",\n+      \"options\": [\n+        \"rw\",\n+        \"rbind\",\n+        \"rprivate\"\n+      ]\n+    }\n+  ],\n+  \"linux\": {\n+    \"cgroupsPath\": \"/storm/6703-1a23ca4b-6062-4d08-8ac3-b09e7d35e7cb\",\n+    \"resources\": {\n+      \"devices\": [\n+        {\n+          \"access\": \"rwm\",\n+          \"allow\": false\n+        }\n+      ],\n+      \"cpu\": {\n+        \"quota\": 140000,\n+        \"period\": 100000\n+      }\n+    },\n+    \"namespaces\": [\n+      {\n+        \"type\": \"pid\"\n+      },\n+      {\n+        \"type\": \"ipc\"\n+      },\n+      {\n+        \"type\": \"uts\"\n+      },\n+      {\n+        \"type\": \"mount\"\n+      }\n+    ],\n+    \"maskedPaths\": [\n+      \"/proc/kcore\",\n+      \"/proc/latency_stats\",\n+      \"/proc/timer_list\",\n+      \"/proc/timer_stats\",\n+      \"/proc/sched_debug\",\n+      \"/proc/scsi\",\n+      \"/sys/firmware\"\n+    ],\n+    \"readonlyPaths\": [\n+      \"/proc/asound\",\n+      \"/proc/bus\",\n+      \"/proc/fs\",\n+      \"/proc/irq\",\n+      \"/proc/sys\",\n+      \"/proc/sysrq-trigger\"\n+    ],\n+    \"seccomp\": {\n+      \"defaultAction\": \"SCMP_ACT_ERRNO\",\n+      \"syscalls\": [\n+        {\n+          \"names\": [\n+            \"accept\",\n+            \"accept4\",\n+            \"access\",\n+            \"alarm\",\n+            \"alarm\",\n+            \"bind\",\n+            \"brk\",\n+            \"capget\",\n+            \"capset\",\n+            \"chdir\",\n+            \"chmod\",\n+            \"chown\",\n+            \"chown32\",\n+            \"clock_getres\",\n+            \"clock_gettime\",\n+            \"clock_nanosleep\",\n+            \"close\",\n+            \"connect\",\n+            \"copy_file_range\",\n+            \"creat\",\n+            \"dup\",\n+            \"dup2\",\n+            \"dup3\",\n+            \"epoll_create\",\n+            \"epoll_create1\",\n+            \"epoll_ctl\",\n+            \"epoll_ctl_old\",\n+            \"epoll_pwait\",\n+            \"epoll_wait\",\n+            \"epoll_wait_old\",\n+            \"eventfd\",\n+            \"eventfd2\",\n+            \"execve\",\n+            \"execveat\",\n+            \"exit\",\n+            \"exit_group\",\n+            \"faccessat\",\n+            \"fadvise64\",\n+            \"fadvise64_64\",\n+            \"fallocate\",\n+            \"fanotify_mark\",\n+            \"fchdir\",\n+            \"fchmod\",\n+            \"fchmodat\",\n+            \"fchown\",\n+            \"fchown32\",\n+            \"fchownat\",\n+            \"fcntl\",\n+            \"fcntl64\",\n+            \"fdatasync\",\n+            \"fgetxattr\",\n+            \"flistxattr\",\n+            \"flock\",\n+            \"fork\",\n+            \"fremovexattr\",\n+            \"fsetxattr\",\n+            \"fstat\",\n+            \"fstat64\",\n+            \"fstatat64\",\n+            \"fstatfs\",\n+            \"fstatfs64\",\n+            \"fsync\",\n+            \"ftruncate\",\n+            \"ftruncate64\",\n+            \"futex\",\n+            \"futimesat\",\n+            \"getcpu\",\n+            \"getcwd\",\n+            \"getdents\",\n+            \"getdents64\",\n+            \"getegid\",\n+            \"getegid32\",\n+            \"geteuid\",\n+            \"geteuid32\",\n+            \"getgid\",\n+            \"getgid32\",\n+            \"getgroups\",\n+            \"getgroups32\",\n+            \"getitimer\",\n+            \"getpeername\",\n+            \"getpgid\",\n+            \"getpgrp\",\n+            \"getpid\",\n+            \"getppid\",\n+            \"getpriority\",\n+            \"getrandom\",\n+            \"getresgid\",\n+            \"getresgid32\",\n+            \"getresuid\",\n+            \"getresuid32\",\n+            \"getrlimit\",\n+            \"get_robust_list\",\n+            \"getrusage\",\n+            \"getsid\",\n+            \"getsockname\",\n+            \"getsockopt\",\n+            \"get_thread_area\",\n+            \"gettid\",\n+            \"gettimeofday\",\n+            \"getuid\",\n+            \"getuid32\",\n+            \"getxattr\",\n+            \"inotify_add_watch\",\n+            \"inotify_init\",\n+            \"inotify_init1\",\n+            \"inotify_rm_watch\",\n+            \"io_cancel\",\n+            \"ioctl\",\n+            \"io_destroy\",\n+            \"io_getevents\",\n+            \"ioprio_get\",\n+            \"ioprio_set\",\n+            \"io_setup\",\n+            \"io_submit\",\n+            \"ipc\",\n+            \"kill\",\n+            \"lchown\",\n+            \"lchown32\",\n+            \"lgetxattr\",\n+            \"link\",\n+            \"linkat\",\n+            \"listen\",\n+            \"listxattr\",\n+            \"llistxattr\",\n+            \"_llseek\",\n+            \"lremovexattr\",\n+            \"lseek\",\n+            \"lsetxattr\",\n+            \"lstat\",\n+            \"lstat64\",\n+            \"madvise\",\n+            \"mbind\",\n+            \"memfd_create\",\n+            \"mincore\",\n+            \"mkdir\",\n+            \"mkdirat\",\n+            \"mknod\",\n+            \"mknodat\",\n+            \"mlock\",\n+            \"mlock2\",\n+            \"mlockall\",\n+            \"mmap\",\n+            \"mmap2\",\n+            \"mprotect\",\n+            \"mq_getsetattr\",\n+            \"mq_notify\",\n+            \"mq_open\",\n+            \"mq_timedreceive\",\n+            \"mq_timedsend\",\n+            \"mq_unlink\",\n+            \"mremap\",\n+            \"msgctl\",\n+            \"msgget\",\n+            \"msgrcv\",\n+            \"msgsnd\",\n+            \"msync\",\n+            \"munlock\",\n+            \"munlockall\",\n+            \"munmap\",\n+            \"nanosleep\",\n+            \"newfstatat\",\n+            \"_newselect\",\n+            \"open\",\n+            \"openat\",\n+            \"pause\",\n+            \"pipe\",\n+            \"pipe2\",\n+            \"poll\",\n+            \"ppoll\",\n+            \"prctl\",\n+            \"pread64\",\n+            \"preadv\",\n+            \"prlimit64\",\n+            \"pselect6\",\n+            \"pwrite64\",\n+            \"pwritev\",\n+            \"read\",\n+            \"readahead\",\n+            \"readlink\",\n+            \"readlinkat\",\n+            \"readv\",\n+            \"recv\",\n+            \"recvfrom\",\n+            \"recvmmsg\",\n+            \"recvmsg\",\n+            \"remap_file_pages\",\n+            \"removexattr\",\n+            \"rename\",\n+            \"renameat\",\n+            \"renameat2\",\n+            \"restart_syscall\",\n+            \"rmdir\",\n+            \"rt_sigaction\",\n+            \"rt_sigpending\",\n+            \"rt_sigprocmask\",\n+            \"rt_sigqueueinfo\",\n+            \"rt_sigreturn\",\n+            \"rt_sigsuspend\",\n+            \"rt_sigtimedwait\",\n+            \"rt_tgsigqueueinfo\",\n+            \"sched_getaffinity\",\n+            \"sched_getattr\",\n+            \"sched_getparam\",\n+            \"sched_get_priority_max\",\n+            \"sched_get_priority_min\",\n+            \"sched_getscheduler\",\n+            \"sched_rr_get_interval\",\n+            \"sched_setaffinity\",\n+            \"sched_setattr\",\n+            \"sched_setparam\",\n+            \"sched_setscheduler\",\n+            \"sched_yield\",\n+            \"seccomp\",\n+            \"select\",\n+            \"semctl\",\n+            \"semget\",\n+            \"semop\",\n+            \"semtimedop\",\n+            \"send\",\n+            \"sendfile\",\n+            \"sendfile64\",\n+            \"sendmmsg\",\n+            \"sendmsg\",\n+            \"sendto\",\n+            \"setfsgid\",\n+            \"setfsgid32\",\n+            \"setfsuid\",\n+            \"setfsuid32\",\n+            \"setgid\",\n+            \"setgid32\",\n+            \"setgroups\",\n+            \"setgroups32\",\n+            \"setitimer\",\n+            \"setpgid\",\n+            \"setpriority\",\n+            \"setregid\",\n+            \"setregid32\",\n+            \"setresgid\",\n+            \"setresgid32\",\n+            \"setresuid\",\n+            \"setresuid32\",\n+            \"setreuid\",\n+            \"setreuid32\",\n+            \"setrlimit\",\n+            \"set_robust_list\",\n+            \"setsid\",\n+            \"setsockopt\",\n+            \"set_thread_area\",\n+            \"set_tid_address\",\n+            \"setuid\",\n+            \"setuid32\",\n+            \"setxattr\",\n+            \"shmat\",\n+            \"shmctl\",\n+            \"shmdt\",\n+            \"shmget\",\n+            \"shutdown\",\n+            \"sigaltstack\",\n+            \"signalfd\",\n+            \"signalfd4\",\n+            \"sigreturn\",\n+            \"socket\",\n+            \"socketcall\",\n+            \"socketpair\",\n+            \"splice\",\n+            \"stat\",\n+            \"stat64\",\n+            \"statfs\",\n+            \"statfs64\",\n+            \"symlink\",\n+            \"symlinkat\",\n+            \"sync\",\n+            \"sync_file_range\",\n+            \"syncfs\",\n+            \"sysinfo\",\n+            \"syslog\",\n+            \"tee\",\n+            \"tgkill\",\n+            \"time\",\n+            \"timer_create\",\n+            \"timer_delete\",\n+            \"timerfd_create\",\n+            \"timerfd_gettime\",\n+            \"timerfd_settime\",\n+            \"timer_getoverrun\",\n+            \"timer_gettime\",\n+            \"timer_settime\",\n+            \"times\",\n+            \"tkill\",\n+            \"truncate\",\n+            \"truncate64\",\n+            \"ugetrlimit\",\n+            \"umask\",\n+            \"uname\",\n+            \"unlink\",\n+            \"unlinkat\",\n+            \"utime\",\n+            \"utimensat\",\n+            \"utimes\",\n+            \"vfork\",\n+            \"vmsplice\",\n+            \"wait4\",\n+            \"waitid\",\n+            \"waitpid\",\n+            \"write\",\n+            \"writev\",\n+            \"mount\",\n+            \"umount2\",\n+            \"reboot\",\n+            \"name_to_handle_at\",\n+            \"unshare\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\"\n+        },\n+        {\n+          \"names\": [\n+            \"personality\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\",\n+          \"args\": [\n+            {\n+              \"index\": 0,\n+              \"value\": 0,\n+              \"valueTwo\": 0,\n+              \"op\": \"SCMP_CMP_EQ\"\n+            }\n+          ]\n+        },\n+        {\n+          \"names\": [\n+            \"personality\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\",\n+          \"args\": [\n+            {\n+              \"index\": 0,\n+              \"value\": 8,\n+              \"valueTwo\": 0,\n+              \"op\": \"SCMP_CMP_EQ\"\n+            }\n+          ]\n+        },\n+        {\n+          \"names\": [\n+            \"personality\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\",\n+          \"args\": [\n+            {\n+              \"index\": 0,\n+              \"value\": 4294967295,\n+              \"valueTwo\": 0,\n+              \"op\": \"SCMP_CMP_EQ\"\n+            }\n+          ]\n+        },\n+        {\n+          \"names\": [\n+            \"arch_prctl\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\"\n+        },\n+        {\n+          \"names\": [\n+            \"modify_ldt\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\"\n+        },\n+        {\n+          \"names\": [\n+            \"clone\"\n+          ],\n+          \"action\": \"SCMP_ACT_ALLOW\",\n+          \"args\": [\n+            {\n+              \"index\": 0,\n+              \"value\": 2080505856,\n+              \"valueTwo\": 0,\n+              \"op\": \"SCMP_CMP_MASKED_EQ\"\n+            }\n+          ]\n+        }\n+      ]\n+    }\n+  }\n+}\n+```\n+\n+## CGroup Metrics\n+\n+Runc internally uses cgroups to control resources for containers. The CGroup Metrics described at [cgroups_in_storm.md](cgroups_in_storm.md#CGroup-Metrics) still apply except CGroupCpuGuarantee. To get CGroup cpu guarantee, use CGroupCpuGuaranteeByCfsQuota instead.", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5MzkwNA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549493904", "bodyText": "I did not find this referenced in the runc documentation.", "author": "agresch", "createdAt": "2020-12-28T21:35:37Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5Mzk1MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549493950", "bodyText": "I did not find this referenced in the runc documentation.", "author": "agresch", "createdAt": "2020-12-28T21:35:46Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NDE2Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549494166", "bodyText": "I did not find this referenced in the runc documentation.", "author": "agresch", "createdAt": "2020-12-28T21:36:31Z", "path": "external/storm-hdfs-oci/src/main/java/org/apache/storm/container/oci/LocalOrHdfsImageTagToManifestPlugin.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.BufferedReader;\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.utils.HadoopLoginUtil;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class LocalOrHdfsImageTagToManifestPlugin implements OciImageTagToManifestPluginInterface {\n+    private static final Logger LOG = LoggerFactory.getLogger(LocalOrHdfsImageTagToManifestPlugin.class);\n+\n+    private Map<String, ImageManifest> manifestCache;\n+    private ObjectMapper objMapper;\n+    private Map<String, String> localImageToHashCache = new HashMap<>();\n+    private Map<String, String> hdfsImageToHashCache = new HashMap<>();\n+    private Map<String, Object> conf;\n+    private long hdfsModTime;\n+    private long localModTime;\n+    private String hdfsImageToHashFile;\n+    private String manifestDir;\n+    private String localImageTagToHashFile;\n+    private int ociCacheRefreshIntervalSecs;\n+    private long lastRefreshTime;\n+\n+    private static String LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX = \"storm.oci.local.or.hdfs.image.tag.to.manifest.plugin.\";\n+\n+    /**\n+     * The HDFS location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String HDFS_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"hdfs.hash.file\";\n+\n+    /**\n+     * The local file system location where the oci image-tag-to-hash file exists.\n+     */\n+    private static String LOCAL_OCI_IMAGE_TAG_TO_HASH_FILE =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"local.hash.file\";\n+\n+    /**\n+     * The interval in seconds between refreshing the oci image-Tag-to-hash cache.\n+     */\n+    private static String OCI_CACHE_REFRESH_INTERVAL =\n+        LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"cache.refresh.interval.secs\";\n+\n+    /**\n+     * The number of manifests to cache.\n+     */\n+    private static String OCI_NUM_MANIFESTS_TO_CACHE = LOCAL_OR_HDFS_IMAGE_TAG_TO_MANIFEST_PLUGIN_PREFIX + \"num.manifests.to.cache\";", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NjU0MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549496540", "bodyText": "Is this added due to the hash calculations?", "author": "agresch", "createdAt": "2020-12-28T21:46:47Z", "path": "storm-core/src/native/worker-launcher/Makefile.am", "diffHunk": "@@ -16,14 +16,16 @@\n \n AM_CFLAGS=-I$(srcdir)/impl -Wall -g -Werror\n \n+LIBS=-lcrypto", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkyNDI1MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669924250", "bodyText": "yes", "author": "Ethanlm", "createdAt": "2021-07-14T20:18:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NjU0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NzI4MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549497281", "bodyText": "what if setup_dir_permissions is non-zero?", "author": "agresch", "createdAt": "2020-12-28T21:49:15Z", "path": "storm-core/src/native/worker-launcher/impl/main.c", "diffHunk": "@@ -269,6 +274,45 @@ int main(int argc, char **argv) {\n       return INVALID_ARGUMENT_NUMBER;\n     }\n     exit_code = signal_container_as_user(user_detail->pw_name, container_pid, signal);\n+  } else if (strcasecmp(\"run-oci-container\", command) == 0) {\n+    if (argc != 6) {\n+      fprintf(ERRORFILE, \"Incorrect number of arguments (%d vs 6) for run-oci-container\\n\", argc);\n+      fflush(ERRORFILE);\n+      return INVALID_ARGUMENT_NUMBER;\n+    }\n+    working_dir = argv[optind++];\n+    const char* command_file = argv[optind++];\n+    const char* worker_artifacts_dir = argv[optind];\n+    exit_code = setup_dir_permissions(working_dir, 1, TRUE);\n+    if (exit_code == 0) {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkyNzMxNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669927316", "bodyText": "it goes to the end of main.c and return the exit code.", "author": "Ethanlm", "createdAt": "2021-07-14T20:23:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NzI4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NzQxNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549497416", "bodyText": "what if setup_worker_tmp_permissions is non-zero", "author": "agresch", "createdAt": "2020-12-28T21:49:45Z", "path": "storm-core/src/native/worker-launcher/impl/main.c", "diffHunk": "@@ -269,6 +274,45 @@ int main(int argc, char **argv) {\n       return INVALID_ARGUMENT_NUMBER;\n     }\n     exit_code = signal_container_as_user(user_detail->pw_name, container_pid, signal);\n+  } else if (strcasecmp(\"run-oci-container\", command) == 0) {\n+    if (argc != 6) {\n+      fprintf(ERRORFILE, \"Incorrect number of arguments (%d vs 6) for run-oci-container\\n\", argc);\n+      fflush(ERRORFILE);\n+      return INVALID_ARGUMENT_NUMBER;\n+    }\n+    working_dir = argv[optind++];\n+    const char* command_file = argv[optind++];\n+    const char* worker_artifacts_dir = argv[optind];\n+    exit_code = setup_dir_permissions(working_dir, 1, TRUE);\n+    if (exit_code == 0) {\n+      exit_code = setup_worker_tmp_permissions(working_dir);\n+      if (exit_code == 0) {", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkyNzQwNw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669927407", "bodyText": "it goes to the end of main.c and return the exit code.", "author": "Ethanlm", "createdAt": "2021-07-14T20:23:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ5NzQxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwMzcyOQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549503729", "bodyText": "What is the implication of this using this specific value?", "author": "agresch", "createdAt": "2020-12-28T22:16:54Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkzMzc2MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669933760", "bodyText": "see https://man7.org/linux/man-pages/man4/loop.4.html\n       LOOP_CTL_GET_FREE\n              Allocate or find a free loop device for use.  On success,\n              the device number is returned as the result of the call.\n              This operation takes no argument.\n\nAdding this definition, if not set already, is to make sure it can still compile on older version of linux kernel.", "author": "Ethanlm", "createdAt": "2021-07-14T20:33:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwMzcyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNDk2MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549504961", "bodyText": "add an error message?", "author": "agresch", "createdAt": "2020-12-28T22:23:24Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_base_ctx.c", "diffHunk": "@@ -0,0 +1,301 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdlib.h>\n+#include <stdio.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"utils/file-utils.h\"\n+\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+\n+#define LAYER_MOUNT_SUFFIX      \"/mnt\"\n+#define LAYER_MOUNT_SUFFIX_LEN  (sizeof(LAYER_MOUNT_SUFFIX) -1)\n+\n+/**\n+ * Get the path to the runtime layers directory.\n+ *\n+ * Returns the heap-allocated path to the layers directory or NULL on error.\n+ */\n+char* get_oci_layers_path(const char* run_root) {\n+  return get_full_path(run_root, \"layers\");\n+}\n+\n+/**\n+ * Get the path to a layer directory.\n+ *\n+ * Returns the heap-allocated path to the layer directory or NULL on error.\n+ */\n+char* get_oci_layer_path(const char* run_root, const char* layer_name) {\n+  char* layer_path = NULL;\n+  if (asprintf(&layer_path, \"%s/layers/%s\", run_root, layer_name) == -1) {\n+    layer_path = NULL;\n+  }\n+  return layer_path;\n+}\n+\n+/**\n+ * Get the path to a layer's mountpoint.\n+ *\n+ * Returns the heap-allocated path to the layer's mountpoint or NULL on error.\n+ */\n+char* get_oci_layer_mount_path(const char* layer_path) {\n+  char* mount_path = NULL;\n+  if (asprintf(&mount_path, \"%s\" LAYER_MOUNT_SUFFIX, layer_path) == -1) {\n+    mount_path = NULL;\n+  }\n+  return mount_path;\n+}\n+\n+/**\n+ * Get the layer path from a layer's mountpoint.\n+ *\n+ * Returns the heap-allocated path to the layer directory or NULL on error.\n+ */\n+char* get_oci_layer_path_from_mount_path(const char* mount_path) {\n+  size_t mount_path_len = strlen(mount_path);\n+  if (mount_path_len <= LAYER_MOUNT_SUFFIX_LEN) {\n+    return NULL;\n+  }\n+  size_t layer_path_len = mount_path_len - LAYER_MOUNT_SUFFIX_LEN;\n+  const char* suffix = mount_path + layer_path_len;\n+  if (strcmp(suffix, LAYER_MOUNT_SUFFIX)) {\n+    return NULL;\n+  }\n+  return strndup(mount_path, layer_path_len);\n+}\n+\n+/**\n+ * Creates the run root directory and layers directory structure\n+ * underneath if necessary.\n+ * Returns the malloc'd run root path or NULL if there was an error.\n+ */\n+static char* setup_oci_run_root_directories() {\n+  char* layers_path = NULL;\n+  char* run_root = get_value(OCI_RUN_ROOT_CONFIG_KEY);\n+  if (run_root == NULL) {\n+    run_root = strdup(DEFAULT_OCI_RUN_ROOT);\n+    if (run_root == NULL) {\n+      goto mem_fail;\n+    }\n+  }\n+  \n+  if (mkdir(run_root, S_IRWXU) != 0 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating OCI run root at %s : %s\\n\", run_root,\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_path = get_oci_layers_path(run_root);\n+  if (layers_path == NULL) {\n+    goto mem_fail;\n+  }\n+\n+  if (mkdir(layers_path, S_IRWXU) != 0 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating layers directory at %s : %s\\n\",\n+        layers_path, strerror(errno));\n+    goto fail;\n+  }\n+\n+  free(layers_path);\n+  return run_root;\n+\n+fail:\n+  free(layers_path);\n+  free(run_root);\n+  return NULL;\n+\n+mem_fail:\n+  fputs(\"ERROR: Cannot allocate memory in setup_oci_run_root_directories\\n\", ERRORFILE);\n+  goto fail;\n+}\n+\n+/**\n+ * Initialize an uninitialized OCI base context.\n+ */\n+void init_oci_base_ctx(oci_base_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->layers_lock_fd = -1;\n+  ctx->layers_lock_state = F_UNLCK;\n+}\n+\n+/**\n+ * Releases the resources underneath an OCI base context but does NOT free the\n+ * structure itself. This is particularly useful for stack-allocated contexts\n+ * or structures that embed the context.\n+ * free_oci_base_ctx should be used for heap-allocated contexts.\n+ */\n+void destroy_oci_base_ctx(oci_base_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->run_root);\n+    if (ctx->layers_lock_fd != -1) {\n+      close(ctx->layers_lock_fd);\n+    }\n+  }\n+}\n+\n+/**\n+ * Allocates and initializes an OCI base context.\n+ *\n+ * Returns a pointer to the allocated and initialized context or NULL on error.\n+ */\n+oci_base_ctx* alloc_oci_base_ctx() {\n+  oci_base_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_base_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+/**\n+ * Free an OCI base context and all memory associated with it.\n+ */\n+void free_oci_base_ctx(oci_base_ctx* ctx) {\n+  destroy_oci_base_ctx(ctx);\n+  free(ctx);\n+}\n+\n+/**\n+ * Opens the base context for use. This will create the container runtime\n+ * root directory and layer lock files, if necessary.\n+ *\n+ * Returns true on success or false if there was an error.\n+ */\n+bool open_oci_base_ctx(oci_base_ctx* ctx) {\n+  ctx->run_root = setup_oci_run_root_directories();\n+  if (ctx->run_root == NULL) {\n+    return false;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTkzNTkwMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669935903", "bodyText": "setup_oci_run_root_directories has sufficient log inside the method", "author": "Ethanlm", "createdAt": "2021-07-14T20:36:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNDk2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNjE4MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549506181", "bodyText": "I don't know what this is about, but do we need a follow on JIRA?", "author": "agresch", "createdAt": "2020-12-28T22:29:05Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNjUyMQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549506521", "bodyText": "it seems like we should check for null here for each of these?  I saw that in initializing a ctx, it could exit early without initializing all pointers.", "author": "agresch", "createdAt": "2020-12-28T22:31:04Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTk0MDU0NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r669940544", "bodyText": "free(null) is okay.", "author": "Ethanlm", "createdAt": "2021-07-14T20:44:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNjUyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNzE4Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549507183", "bodyText": "init_layer_mount_ctx does not have an error message for all paths.  Should we have one here?", "author": "agresch", "createdAt": "2020-12-28T22:34:29Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,\n+    const char* run_root) {\n+  char* hash = compute_layer_hash(spec->path);\n+  if (hash == NULL) {\n+    return false;\n+  }\n+\n+  ctx->layer_path = get_oci_layer_path(run_root, hash);\n+  free(hash);\n+  if (ctx->layer_path == NULL) {\n+    return false;\n+  }\n+\n+  ctx->mount_path = get_oci_layer_mount_path(ctx->layer_path);\n+  if (ctx->mount_path == NULL) {\n+    return false;\n+  }\n+  #ifdef DEBUG  \n+  print_res_uid_gid(\"right before open layer image\");\n+  #endif\n+\n+  ctx->fd = open(spec->path, O_RDONLY | O_CLOEXEC);\n+  if (ctx->fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening layer image at %s : %s\\n\", spec->path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  ctx->src_path = strdup(spec->path);\n+  return ctx->src_path != NULL;\n+}\n+\n+/**\n+ * Initialize the layers mount contexts and open each layer image as the user\n+ * to validate the user should be allowed to access the image composed of\n+ * these layers.\n+ */\n+static bool init_layer_mount_ctxs(oci_launch_cmd_ctx* ctx,\n+    const olc_layer_spec* layer_specs, unsigned int num_layers) {\n+  ctx->layers = malloc(num_layers * sizeof(*ctx->layers));\n+  if (ctx->layers == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in init_layer_mount_ctxs\\n\", ERRORFILE);\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    init_oci_mount_ctx(&ctx->layers[i]);\n+  }\n+  ctx->num_layers = num_layers;\n+\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!init_layer_mount_ctx(&ctx->layers[i], &layer_specs[i],\n+        ctx->base_ctx.run_root)) {\n+      return false;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNzMyMA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549507320", "bodyText": "should this have error messages for all false paths?", "author": "agresch", "createdAt": "2020-12-28T22:35:13Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwNzk5Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549507997", "bodyText": "comment implies this should be a WARN instead of ERROR?  What action should be taken if this occurs?", "author": "agresch", "createdAt": "2020-12-28T22:38:23Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,\n+    const char* run_root) {\n+  char* hash = compute_layer_hash(spec->path);\n+  if (hash == NULL) {\n+    return false;\n+  }\n+\n+  ctx->layer_path = get_oci_layer_path(run_root, hash);\n+  free(hash);\n+  if (ctx->layer_path == NULL) {\n+    return false;\n+  }\n+\n+  ctx->mount_path = get_oci_layer_mount_path(ctx->layer_path);\n+  if (ctx->mount_path == NULL) {\n+    return false;\n+  }\n+  #ifdef DEBUG  \n+  print_res_uid_gid(\"right before open layer image\");\n+  #endif\n+\n+  ctx->fd = open(spec->path, O_RDONLY | O_CLOEXEC);\n+  if (ctx->fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening layer image at %s : %s\\n\", spec->path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  ctx->src_path = strdup(spec->path);\n+  return ctx->src_path != NULL;\n+}\n+\n+/**\n+ * Initialize the layers mount contexts and open each layer image as the user\n+ * to validate the user should be allowed to access the image composed of\n+ * these layers.\n+ */\n+static bool init_layer_mount_ctxs(oci_launch_cmd_ctx* ctx,\n+    const olc_layer_spec* layer_specs, unsigned int num_layers) {\n+  ctx->layers = malloc(num_layers * sizeof(*ctx->layers));\n+  if (ctx->layers == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in init_layer_mount_ctxs\\n\", ERRORFILE);\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    init_oci_mount_ctx(&ctx->layers[i]);\n+  }\n+  ctx->num_layers = num_layers;\n+\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!init_layer_mount_ctx(&ctx->layers[i], &layer_specs[i],\n+        ctx->base_ctx.run_root)) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+/**\n+ * Allocate a loop device and associate it with a file descriptor.\n+ * Returns the file descriptor of the opened loop device or -1 on error.\n+ */\n+static int allocate_and_open_loop_device(char** loopdev_name_out, int src_fd) {\n+  *loopdev_name_out = NULL;\n+  int loopctl = open(\"/dev/loop-control\", O_RDWR);\n+  if (loopctl == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening /dev/loop-control : %s\\n\",\n+        strerror(errno));\n+    return -1;\n+  }\n+\n+  char* loopdev_name = NULL;\n+  int loop_fd = -1;\n+  while (true) {\n+    int loop_num = ioctl(loopctl, LOOP_CTL_GET_FREE);\n+    if (loop_num < 0) {\n+      fprintf(ERRORFILE, \"ERROR: Error allocating a new loop device: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (asprintf(&loopdev_name, \"/dev/loop%d\", loop_num) == -1) {\n+      fputs(\"ERROR: Unable to allocate memory in allocate_and_open_loop_device\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+    loop_fd = open(loopdev_name, O_RDWR | O_CLOEXEC);\n+    if (loop_fd == -1) {\n+      fprintf(ERRORFILE, \"ERROR: Unable to open loop device at %s : %s\\n\",\n+          loopdev_name, strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (ioctl(loop_fd, LOOP_SET_FD, src_fd) != -1) {\n+      break;\n+    }\n+\n+    // EBUSY indicates another process stole this loop device\n+    if (errno != EBUSY) {\n+      fprintf(ERRORFILE, \"ERROR: Error setting loop source file: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    close(loop_fd);\n+    loop_fd = -1;\n+    free(loopdev_name);\n+    loopdev_name = NULL;\n+  }\n+\n+  struct loop_info64 loop_info;\n+  memset(&loop_info, 0, sizeof(loop_info));\n+  loop_info.lo_flags = LO_FLAGS_READ_ONLY | LO_FLAGS_AUTOCLEAR;\n+  if (ioctl(loop_fd, LOOP_SET_STATUS64, &loop_info) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error setting loop flags: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  close(loopctl);\n+  *loopdev_name_out = loopdev_name;\n+  return loop_fd;\n+\n+fail:\n+  if (loop_fd != -1) {\n+    close(loop_fd);\n+  }\n+  close(loopctl);\n+  free(loopdev_name);\n+  return -1;\n+}\n+\n+/**\n+ * Mount a filesystem with the specified arguments, see the mount(2) manpage.\n+ * If the mount fails an error message is printed to ERRORFILE.\n+ * Returns true for success or false on failure.\n+ */\n+static bool do_mount(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mount(src, target, fs_type, mount_flags, mount_options) == -1) {\n+    const char* nullstr = \"NULL\";\n+    src = (src != NULL) ? src : nullstr;\n+    fs_type = (fs_type != NULL) ? fs_type : nullstr;\n+    mount_options = (mount_options != NULL) ? mount_options : nullstr;\n+    fprintf(ERRORFILE, \"ERROR: Error mounting %s at %s type %s with options %s : %s\\n\",\n+        src, target, fs_type, mount_options, strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+/**\n+ * Mount a filesystem and return a file descriptor opened to the mount point.\n+ * The mount point directory will be created if necessary.\n+ * Returns a file descriptor to the mount point or -1 if there was an error.\n+ */\n+static int mount_and_open(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mkdir(target, S_IRWXU) == -1 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating mountpoint directory at %s : %s\\n\",\n+        target, strerror(errno));\n+    return -1;\n+  }\n+\n+  if (!do_mount(src, target, fs_type, mount_flags, mount_options)) {\n+    return -1;\n+  }\n+\n+  return open_mountpoint(target);\n+}\n+\n+static int mount_layer_and_open(const oci_mount_ctx* layer) {\n+  if (mkdir(layer->layer_path, S_IRWXU) == -1) {\n+    if (errno != EEXIST) {\n+      fprintf(ERRORFILE, \"ERROR: Error creating layer directory at %s : %s\\n\",\n+          layer->layer_path, strerror(errno));\n+      return -1;\n+    }\n+  }\n+\n+  char *loopdev_name = NULL;\n+  int loopfd = allocate_and_open_loop_device(&loopdev_name, layer->fd);\n+  if (loopfd == -1) {\n+    return -1;\n+  }\n+\n+  int mount_fd = mount_and_open(loopdev_name, layer->mount_path, \"squashfs\",\n+    MS_RDONLY, NULL);\n+\n+  // If the mount worked then the mount holds the loop device open. If the mount\n+  // failed then the loop device is no longer needed, so close it either way.\n+  close(loopfd);\n+\n+  free(loopdev_name);\n+  return mount_fd;\n+}\n+\n+static bool do_mount_layers_with_lock(oci_launch_cmd_ctx* ctx) {\n+  bool have_write_lock = false;\n+  unsigned int i;\n+  for (i = 0; i < ctx->num_layers; ++i) {\n+    int layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+    if (layer_mount_fd != -1) {\n+      // Touch layer directory to show this existing layer was recently used.\n+      if (utimes(ctx->layers[i].layer_path, NULL) == -1) {\n+        // Error is not critical to container launch so just print a warning.\n+        fprintf(ERRORFILE, \"ERROR: Error updating timestamps of %s : %s\\n\",", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwODIyNg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549508226", "bodyText": "should this have an error message?", "author": "agresch", "createdAt": "2020-12-28T22:39:34Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,\n+    const char* run_root) {\n+  char* hash = compute_layer_hash(spec->path);\n+  if (hash == NULL) {\n+    return false;\n+  }\n+\n+  ctx->layer_path = get_oci_layer_path(run_root, hash);\n+  free(hash);\n+  if (ctx->layer_path == NULL) {\n+    return false;\n+  }\n+\n+  ctx->mount_path = get_oci_layer_mount_path(ctx->layer_path);\n+  if (ctx->mount_path == NULL) {\n+    return false;\n+  }\n+  #ifdef DEBUG  \n+  print_res_uid_gid(\"right before open layer image\");\n+  #endif\n+\n+  ctx->fd = open(spec->path, O_RDONLY | O_CLOEXEC);\n+  if (ctx->fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening layer image at %s : %s\\n\", spec->path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  ctx->src_path = strdup(spec->path);\n+  return ctx->src_path != NULL;\n+}\n+\n+/**\n+ * Initialize the layers mount contexts and open each layer image as the user\n+ * to validate the user should be allowed to access the image composed of\n+ * these layers.\n+ */\n+static bool init_layer_mount_ctxs(oci_launch_cmd_ctx* ctx,\n+    const olc_layer_spec* layer_specs, unsigned int num_layers) {\n+  ctx->layers = malloc(num_layers * sizeof(*ctx->layers));\n+  if (ctx->layers == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in init_layer_mount_ctxs\\n\", ERRORFILE);\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    init_oci_mount_ctx(&ctx->layers[i]);\n+  }\n+  ctx->num_layers = num_layers;\n+\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!init_layer_mount_ctx(&ctx->layers[i], &layer_specs[i],\n+        ctx->base_ctx.run_root)) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+/**\n+ * Allocate a loop device and associate it with a file descriptor.\n+ * Returns the file descriptor of the opened loop device or -1 on error.\n+ */\n+static int allocate_and_open_loop_device(char** loopdev_name_out, int src_fd) {\n+  *loopdev_name_out = NULL;\n+  int loopctl = open(\"/dev/loop-control\", O_RDWR);\n+  if (loopctl == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening /dev/loop-control : %s\\n\",\n+        strerror(errno));\n+    return -1;\n+  }\n+\n+  char* loopdev_name = NULL;\n+  int loop_fd = -1;\n+  while (true) {\n+    int loop_num = ioctl(loopctl, LOOP_CTL_GET_FREE);\n+    if (loop_num < 0) {\n+      fprintf(ERRORFILE, \"ERROR: Error allocating a new loop device: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (asprintf(&loopdev_name, \"/dev/loop%d\", loop_num) == -1) {\n+      fputs(\"ERROR: Unable to allocate memory in allocate_and_open_loop_device\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+    loop_fd = open(loopdev_name, O_RDWR | O_CLOEXEC);\n+    if (loop_fd == -1) {\n+      fprintf(ERRORFILE, \"ERROR: Unable to open loop device at %s : %s\\n\",\n+          loopdev_name, strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (ioctl(loop_fd, LOOP_SET_FD, src_fd) != -1) {\n+      break;\n+    }\n+\n+    // EBUSY indicates another process stole this loop device\n+    if (errno != EBUSY) {\n+      fprintf(ERRORFILE, \"ERROR: Error setting loop source file: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    close(loop_fd);\n+    loop_fd = -1;\n+    free(loopdev_name);\n+    loopdev_name = NULL;\n+  }\n+\n+  struct loop_info64 loop_info;\n+  memset(&loop_info, 0, sizeof(loop_info));\n+  loop_info.lo_flags = LO_FLAGS_READ_ONLY | LO_FLAGS_AUTOCLEAR;\n+  if (ioctl(loop_fd, LOOP_SET_STATUS64, &loop_info) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error setting loop flags: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  close(loopctl);\n+  *loopdev_name_out = loopdev_name;\n+  return loop_fd;\n+\n+fail:\n+  if (loop_fd != -1) {\n+    close(loop_fd);\n+  }\n+  close(loopctl);\n+  free(loopdev_name);\n+  return -1;\n+}\n+\n+/**\n+ * Mount a filesystem with the specified arguments, see the mount(2) manpage.\n+ * If the mount fails an error message is printed to ERRORFILE.\n+ * Returns true for success or false on failure.\n+ */\n+static bool do_mount(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mount(src, target, fs_type, mount_flags, mount_options) == -1) {\n+    const char* nullstr = \"NULL\";\n+    src = (src != NULL) ? src : nullstr;\n+    fs_type = (fs_type != NULL) ? fs_type : nullstr;\n+    mount_options = (mount_options != NULL) ? mount_options : nullstr;\n+    fprintf(ERRORFILE, \"ERROR: Error mounting %s at %s type %s with options %s : %s\\n\",\n+        src, target, fs_type, mount_options, strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+/**\n+ * Mount a filesystem and return a file descriptor opened to the mount point.\n+ * The mount point directory will be created if necessary.\n+ * Returns a file descriptor to the mount point or -1 if there was an error.\n+ */\n+static int mount_and_open(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mkdir(target, S_IRWXU) == -1 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating mountpoint directory at %s : %s\\n\",\n+        target, strerror(errno));\n+    return -1;\n+  }\n+\n+  if (!do_mount(src, target, fs_type, mount_flags, mount_options)) {\n+    return -1;\n+  }\n+\n+  return open_mountpoint(target);\n+}\n+\n+static int mount_layer_and_open(const oci_mount_ctx* layer) {\n+  if (mkdir(layer->layer_path, S_IRWXU) == -1) {\n+    if (errno != EEXIST) {\n+      fprintf(ERRORFILE, \"ERROR: Error creating layer directory at %s : %s\\n\",\n+          layer->layer_path, strerror(errno));\n+      return -1;\n+    }\n+  }\n+\n+  char *loopdev_name = NULL;\n+  int loopfd = allocate_and_open_loop_device(&loopdev_name, layer->fd);\n+  if (loopfd == -1) {\n+    return -1;\n+  }\n+\n+  int mount_fd = mount_and_open(loopdev_name, layer->mount_path, \"squashfs\",\n+    MS_RDONLY, NULL);\n+\n+  // If the mount worked then the mount holds the loop device open. If the mount\n+  // failed then the loop device is no longer needed, so close it either way.\n+  close(loopfd);\n+\n+  free(loopdev_name);\n+  return mount_fd;\n+}\n+\n+static bool do_mount_layers_with_lock(oci_launch_cmd_ctx* ctx) {\n+  bool have_write_lock = false;\n+  unsigned int i;\n+  for (i = 0; i < ctx->num_layers; ++i) {\n+    int layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+    if (layer_mount_fd != -1) {\n+      // Touch layer directory to show this existing layer was recently used.\n+      if (utimes(ctx->layers[i].layer_path, NULL) == -1) {\n+        // Error is not critical to container launch so just print a warning.\n+        fprintf(ERRORFILE, \"ERROR: Error updating timestamps of %s : %s\\n\",\n+            ctx->layers[i].layer_path, strerror(errno));\n+      }\n+    } else {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(&ctx->base_ctx)) {\n+          return false;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwODM2NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549508364", "bodyText": "error message?", "author": "agresch", "createdAt": "2020-12-28T22:40:23Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,\n+    const char* run_root) {\n+  char* hash = compute_layer_hash(spec->path);\n+  if (hash == NULL) {\n+    return false;\n+  }\n+\n+  ctx->layer_path = get_oci_layer_path(run_root, hash);\n+  free(hash);\n+  if (ctx->layer_path == NULL) {\n+    return false;\n+  }\n+\n+  ctx->mount_path = get_oci_layer_mount_path(ctx->layer_path);\n+  if (ctx->mount_path == NULL) {\n+    return false;\n+  }\n+  #ifdef DEBUG  \n+  print_res_uid_gid(\"right before open layer image\");\n+  #endif\n+\n+  ctx->fd = open(spec->path, O_RDONLY | O_CLOEXEC);\n+  if (ctx->fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening layer image at %s : %s\\n\", spec->path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  ctx->src_path = strdup(spec->path);\n+  return ctx->src_path != NULL;\n+}\n+\n+/**\n+ * Initialize the layers mount contexts and open each layer image as the user\n+ * to validate the user should be allowed to access the image composed of\n+ * these layers.\n+ */\n+static bool init_layer_mount_ctxs(oci_launch_cmd_ctx* ctx,\n+    const olc_layer_spec* layer_specs, unsigned int num_layers) {\n+  ctx->layers = malloc(num_layers * sizeof(*ctx->layers));\n+  if (ctx->layers == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in init_layer_mount_ctxs\\n\", ERRORFILE);\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    init_oci_mount_ctx(&ctx->layers[i]);\n+  }\n+  ctx->num_layers = num_layers;\n+\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!init_layer_mount_ctx(&ctx->layers[i], &layer_specs[i],\n+        ctx->base_ctx.run_root)) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+/**\n+ * Allocate a loop device and associate it with a file descriptor.\n+ * Returns the file descriptor of the opened loop device or -1 on error.\n+ */\n+static int allocate_and_open_loop_device(char** loopdev_name_out, int src_fd) {\n+  *loopdev_name_out = NULL;\n+  int loopctl = open(\"/dev/loop-control\", O_RDWR);\n+  if (loopctl == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening /dev/loop-control : %s\\n\",\n+        strerror(errno));\n+    return -1;\n+  }\n+\n+  char* loopdev_name = NULL;\n+  int loop_fd = -1;\n+  while (true) {\n+    int loop_num = ioctl(loopctl, LOOP_CTL_GET_FREE);\n+    if (loop_num < 0) {\n+      fprintf(ERRORFILE, \"ERROR: Error allocating a new loop device: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (asprintf(&loopdev_name, \"/dev/loop%d\", loop_num) == -1) {\n+      fputs(\"ERROR: Unable to allocate memory in allocate_and_open_loop_device\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+    loop_fd = open(loopdev_name, O_RDWR | O_CLOEXEC);\n+    if (loop_fd == -1) {\n+      fprintf(ERRORFILE, \"ERROR: Unable to open loop device at %s : %s\\n\",\n+          loopdev_name, strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (ioctl(loop_fd, LOOP_SET_FD, src_fd) != -1) {\n+      break;\n+    }\n+\n+    // EBUSY indicates another process stole this loop device\n+    if (errno != EBUSY) {\n+      fprintf(ERRORFILE, \"ERROR: Error setting loop source file: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    close(loop_fd);\n+    loop_fd = -1;\n+    free(loopdev_name);\n+    loopdev_name = NULL;\n+  }\n+\n+  struct loop_info64 loop_info;\n+  memset(&loop_info, 0, sizeof(loop_info));\n+  loop_info.lo_flags = LO_FLAGS_READ_ONLY | LO_FLAGS_AUTOCLEAR;\n+  if (ioctl(loop_fd, LOOP_SET_STATUS64, &loop_info) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error setting loop flags: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  close(loopctl);\n+  *loopdev_name_out = loopdev_name;\n+  return loop_fd;\n+\n+fail:\n+  if (loop_fd != -1) {\n+    close(loop_fd);\n+  }\n+  close(loopctl);\n+  free(loopdev_name);\n+  return -1;\n+}\n+\n+/**\n+ * Mount a filesystem with the specified arguments, see the mount(2) manpage.\n+ * If the mount fails an error message is printed to ERRORFILE.\n+ * Returns true for success or false on failure.\n+ */\n+static bool do_mount(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mount(src, target, fs_type, mount_flags, mount_options) == -1) {\n+    const char* nullstr = \"NULL\";\n+    src = (src != NULL) ? src : nullstr;\n+    fs_type = (fs_type != NULL) ? fs_type : nullstr;\n+    mount_options = (mount_options != NULL) ? mount_options : nullstr;\n+    fprintf(ERRORFILE, \"ERROR: Error mounting %s at %s type %s with options %s : %s\\n\",\n+        src, target, fs_type, mount_options, strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+/**\n+ * Mount a filesystem and return a file descriptor opened to the mount point.\n+ * The mount point directory will be created if necessary.\n+ * Returns a file descriptor to the mount point or -1 if there was an error.\n+ */\n+static int mount_and_open(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mkdir(target, S_IRWXU) == -1 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating mountpoint directory at %s : %s\\n\",\n+        target, strerror(errno));\n+    return -1;\n+  }\n+\n+  if (!do_mount(src, target, fs_type, mount_flags, mount_options)) {\n+    return -1;\n+  }\n+\n+  return open_mountpoint(target);\n+}\n+\n+static int mount_layer_and_open(const oci_mount_ctx* layer) {\n+  if (mkdir(layer->layer_path, S_IRWXU) == -1) {\n+    if (errno != EEXIST) {\n+      fprintf(ERRORFILE, \"ERROR: Error creating layer directory at %s : %s\\n\",\n+          layer->layer_path, strerror(errno));\n+      return -1;\n+    }\n+  }\n+\n+  char *loopdev_name = NULL;\n+  int loopfd = allocate_and_open_loop_device(&loopdev_name, layer->fd);\n+  if (loopfd == -1) {\n+    return -1;\n+  }\n+\n+  int mount_fd = mount_and_open(loopdev_name, layer->mount_path, \"squashfs\",\n+    MS_RDONLY, NULL);\n+\n+  // If the mount worked then the mount holds the loop device open. If the mount\n+  // failed then the loop device is no longer needed, so close it either way.\n+  close(loopfd);\n+\n+  free(loopdev_name);\n+  return mount_fd;\n+}\n+\n+static bool do_mount_layers_with_lock(oci_launch_cmd_ctx* ctx) {\n+  bool have_write_lock = false;\n+  unsigned int i;\n+  for (i = 0; i < ctx->num_layers; ++i) {\n+    int layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+    if (layer_mount_fd != -1) {\n+      // Touch layer directory to show this existing layer was recently used.\n+      if (utimes(ctx->layers[i].layer_path, NULL) == -1) {\n+        // Error is not critical to container launch so just print a warning.\n+        fprintf(ERRORFILE, \"ERROR: Error updating timestamps of %s : %s\\n\",\n+            ctx->layers[i].layer_path, strerror(errno));\n+      }\n+    } else {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(&ctx->base_ctx)) {\n+          return false;\n+        }\n+        have_write_lock = true;\n+        // Try to open the mount point again in case another process created it\n+        // while we were waiting for the write lock.\n+        layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+      }\n+\n+      if (layer_mount_fd == -1) {\n+        layer_mount_fd = mount_layer_and_open(&ctx->layers[i]);\n+\n+        if (layer_mount_fd == -1) {\n+          fprintf(ERRORFILE, \"ERROR: Unable to mount layer data from %s\\n\",\n+              ctx->layers[i].src_path);\n+          return false;\n+        }\n+      }\n+    }\n+\n+    // Now that the layer is mounted we can start tracking the open mount point\n+    // for the layer rather than the descriptor to the layer image.\n+    // The mount point references the underlying image, so we no longer need\n+    // a direct reference to the layer image.\n+    close(ctx->layers[i].fd);\n+    ctx->layers[i].fd = layer_mount_fd;\n+  }\n+\n+  return true;\n+}\n+\n+static bool mount_layers(oci_launch_cmd_ctx* ctx) {\n+  if (!acquire_oci_layers_read_lock(&ctx->base_ctx)) {\n+    return false;\n+  }\n+\n+  bool result = do_mount_layers_with_lock(ctx);\n+\n+  if (!release_oci_layers_lock(&ctx->base_ctx)) {\n+    return false;\n+  }\n+\n+  return result;\n+}\n+\n+static char* build_overlay_options(oci_mount_ctx* layers,\n+    unsigned int num_layers, const oci_overlay_desc* upper) {\n+  char* result = NULL;\n+  const int sb_incr = 16*1024;\n+  strbuf sb;\n+  if (!strbuf_init(&sb, sb_incr)) {\n+    fputs(\"ERROR: Unable to allocate memory in build_overlay_options\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!strbuf_append_fmt(&sb, sb_incr, \"upperdir=%s,workdir=%s,lowerdir=\",\n+      upper->upper_path, upper->work_path)) {\n+    goto cleanup;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwODQyMg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549508422", "bodyText": "error message?", "author": "agresch", "createdAt": "2020-12-28T22:40:47Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,\n+    const char* run_root) {\n+  char* hash = compute_layer_hash(spec->path);\n+  if (hash == NULL) {\n+    return false;\n+  }\n+\n+  ctx->layer_path = get_oci_layer_path(run_root, hash);\n+  free(hash);\n+  if (ctx->layer_path == NULL) {\n+    return false;\n+  }\n+\n+  ctx->mount_path = get_oci_layer_mount_path(ctx->layer_path);\n+  if (ctx->mount_path == NULL) {\n+    return false;\n+  }\n+  #ifdef DEBUG  \n+  print_res_uid_gid(\"right before open layer image\");\n+  #endif\n+\n+  ctx->fd = open(spec->path, O_RDONLY | O_CLOEXEC);\n+  if (ctx->fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening layer image at %s : %s\\n\", spec->path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  ctx->src_path = strdup(spec->path);\n+  return ctx->src_path != NULL;\n+}\n+\n+/**\n+ * Initialize the layers mount contexts and open each layer image as the user\n+ * to validate the user should be allowed to access the image composed of\n+ * these layers.\n+ */\n+static bool init_layer_mount_ctxs(oci_launch_cmd_ctx* ctx,\n+    const olc_layer_spec* layer_specs, unsigned int num_layers) {\n+  ctx->layers = malloc(num_layers * sizeof(*ctx->layers));\n+  if (ctx->layers == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in init_layer_mount_ctxs\\n\", ERRORFILE);\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    init_oci_mount_ctx(&ctx->layers[i]);\n+  }\n+  ctx->num_layers = num_layers;\n+\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!init_layer_mount_ctx(&ctx->layers[i], &layer_specs[i],\n+        ctx->base_ctx.run_root)) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+/**\n+ * Allocate a loop device and associate it with a file descriptor.\n+ * Returns the file descriptor of the opened loop device or -1 on error.\n+ */\n+static int allocate_and_open_loop_device(char** loopdev_name_out, int src_fd) {\n+  *loopdev_name_out = NULL;\n+  int loopctl = open(\"/dev/loop-control\", O_RDWR);\n+  if (loopctl == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening /dev/loop-control : %s\\n\",\n+        strerror(errno));\n+    return -1;\n+  }\n+\n+  char* loopdev_name = NULL;\n+  int loop_fd = -1;\n+  while (true) {\n+    int loop_num = ioctl(loopctl, LOOP_CTL_GET_FREE);\n+    if (loop_num < 0) {\n+      fprintf(ERRORFILE, \"ERROR: Error allocating a new loop device: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (asprintf(&loopdev_name, \"/dev/loop%d\", loop_num) == -1) {\n+      fputs(\"ERROR: Unable to allocate memory in allocate_and_open_loop_device\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+    loop_fd = open(loopdev_name, O_RDWR | O_CLOEXEC);\n+    if (loop_fd == -1) {\n+      fprintf(ERRORFILE, \"ERROR: Unable to open loop device at %s : %s\\n\",\n+          loopdev_name, strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (ioctl(loop_fd, LOOP_SET_FD, src_fd) != -1) {\n+      break;\n+    }\n+\n+    // EBUSY indicates another process stole this loop device\n+    if (errno != EBUSY) {\n+      fprintf(ERRORFILE, \"ERROR: Error setting loop source file: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    close(loop_fd);\n+    loop_fd = -1;\n+    free(loopdev_name);\n+    loopdev_name = NULL;\n+  }\n+\n+  struct loop_info64 loop_info;\n+  memset(&loop_info, 0, sizeof(loop_info));\n+  loop_info.lo_flags = LO_FLAGS_READ_ONLY | LO_FLAGS_AUTOCLEAR;\n+  if (ioctl(loop_fd, LOOP_SET_STATUS64, &loop_info) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error setting loop flags: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  close(loopctl);\n+  *loopdev_name_out = loopdev_name;\n+  return loop_fd;\n+\n+fail:\n+  if (loop_fd != -1) {\n+    close(loop_fd);\n+  }\n+  close(loopctl);\n+  free(loopdev_name);\n+  return -1;\n+}\n+\n+/**\n+ * Mount a filesystem with the specified arguments, see the mount(2) manpage.\n+ * If the mount fails an error message is printed to ERRORFILE.\n+ * Returns true for success or false on failure.\n+ */\n+static bool do_mount(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mount(src, target, fs_type, mount_flags, mount_options) == -1) {\n+    const char* nullstr = \"NULL\";\n+    src = (src != NULL) ? src : nullstr;\n+    fs_type = (fs_type != NULL) ? fs_type : nullstr;\n+    mount_options = (mount_options != NULL) ? mount_options : nullstr;\n+    fprintf(ERRORFILE, \"ERROR: Error mounting %s at %s type %s with options %s : %s\\n\",\n+        src, target, fs_type, mount_options, strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+/**\n+ * Mount a filesystem and return a file descriptor opened to the mount point.\n+ * The mount point directory will be created if necessary.\n+ * Returns a file descriptor to the mount point or -1 if there was an error.\n+ */\n+static int mount_and_open(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mkdir(target, S_IRWXU) == -1 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating mountpoint directory at %s : %s\\n\",\n+        target, strerror(errno));\n+    return -1;\n+  }\n+\n+  if (!do_mount(src, target, fs_type, mount_flags, mount_options)) {\n+    return -1;\n+  }\n+\n+  return open_mountpoint(target);\n+}\n+\n+static int mount_layer_and_open(const oci_mount_ctx* layer) {\n+  if (mkdir(layer->layer_path, S_IRWXU) == -1) {\n+    if (errno != EEXIST) {\n+      fprintf(ERRORFILE, \"ERROR: Error creating layer directory at %s : %s\\n\",\n+          layer->layer_path, strerror(errno));\n+      return -1;\n+    }\n+  }\n+\n+  char *loopdev_name = NULL;\n+  int loopfd = allocate_and_open_loop_device(&loopdev_name, layer->fd);\n+  if (loopfd == -1) {\n+    return -1;\n+  }\n+\n+  int mount_fd = mount_and_open(loopdev_name, layer->mount_path, \"squashfs\",\n+    MS_RDONLY, NULL);\n+\n+  // If the mount worked then the mount holds the loop device open. If the mount\n+  // failed then the loop device is no longer needed, so close it either way.\n+  close(loopfd);\n+\n+  free(loopdev_name);\n+  return mount_fd;\n+}\n+\n+static bool do_mount_layers_with_lock(oci_launch_cmd_ctx* ctx) {\n+  bool have_write_lock = false;\n+  unsigned int i;\n+  for (i = 0; i < ctx->num_layers; ++i) {\n+    int layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+    if (layer_mount_fd != -1) {\n+      // Touch layer directory to show this existing layer was recently used.\n+      if (utimes(ctx->layers[i].layer_path, NULL) == -1) {\n+        // Error is not critical to container launch so just print a warning.\n+        fprintf(ERRORFILE, \"ERROR: Error updating timestamps of %s : %s\\n\",\n+            ctx->layers[i].layer_path, strerror(errno));\n+      }\n+    } else {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(&ctx->base_ctx)) {\n+          return false;\n+        }\n+        have_write_lock = true;\n+        // Try to open the mount point again in case another process created it\n+        // while we were waiting for the write lock.\n+        layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+      }\n+\n+      if (layer_mount_fd == -1) {\n+        layer_mount_fd = mount_layer_and_open(&ctx->layers[i]);\n+\n+        if (layer_mount_fd == -1) {\n+          fprintf(ERRORFILE, \"ERROR: Unable to mount layer data from %s\\n\",\n+              ctx->layers[i].src_path);\n+          return false;\n+        }\n+      }\n+    }\n+\n+    // Now that the layer is mounted we can start tracking the open mount point\n+    // for the layer rather than the descriptor to the layer image.\n+    // The mount point references the underlying image, so we no longer need\n+    // a direct reference to the layer image.\n+    close(ctx->layers[i].fd);\n+    ctx->layers[i].fd = layer_mount_fd;\n+  }\n+\n+  return true;\n+}\n+\n+static bool mount_layers(oci_launch_cmd_ctx* ctx) {\n+  if (!acquire_oci_layers_read_lock(&ctx->base_ctx)) {\n+    return false;\n+  }\n+\n+  bool result = do_mount_layers_with_lock(ctx);\n+\n+  if (!release_oci_layers_lock(&ctx->base_ctx)) {\n+    return false;\n+  }\n+\n+  return result;\n+}\n+\n+static char* build_overlay_options(oci_mount_ctx* layers,\n+    unsigned int num_layers, const oci_overlay_desc* upper) {\n+  char* result = NULL;\n+  const int sb_incr = 16*1024;\n+  strbuf sb;\n+  if (!strbuf_init(&sb, sb_incr)) {\n+    fputs(\"ERROR: Unable to allocate memory in build_overlay_options\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!strbuf_append_fmt(&sb, sb_incr, \"upperdir=%s,workdir=%s,lowerdir=\",\n+      upper->upper_path, upper->work_path)) {\n+    goto cleanup;\n+  }\n+\n+  // Overlay expects the base layer to be the last layer listed, but the\n+  // OCI image manifest specifies the base layer first.\n+  bool need_separator = false;\n+  int i;\n+  for (i = num_layers - 1; i >= 0; --i) {\n+    char* fmt = need_separator ? \":%s\" : \"%s\";\n+    if (!strbuf_append_fmt(&sb, sb_incr, fmt, layers[i].mount_path)) {\n+      goto cleanup;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUwODc4Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r549508783", "bodyText": "error message?", "author": "agresch", "createdAt": "2020-12-28T22:42:44Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci.c", "diffHunk": "@@ -0,0 +1,881 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <linux/loop.h>\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <sys/time.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+#include <openssl/evp.h>\n+\n+// LOOP_CTL_GET_FREE ioctl is supported since linux kernel 3.1\n+//Add this so it can compile on older version of linux kernel,\n+//but certain runc related functionalities will not work during runtime.\n+#ifndef LOOP_CTL_GET_FREE\n+#define LOOP_CTL_GET_FREE  0x4C82\n+#endif\n+\n+#include \"utils/string-utils.h\"\n+#include \"configuration.h\"\n+#include \"worker-launcher.h\"\n+\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_config.h\"\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_write_config.h\"\n+\n+\n+\n+// NOTE: Update init_oci_mount_context and destroy_oci_mount_context\n+//       when this is changed.\n+typedef struct oci_mount_context_struct {\n+  char* src_path;             // path to raw layer data\n+  char* layer_path;           // path under layer database for this layer\n+  char* mount_path;           // mount point of filesystem under layer_path\n+  int fd;                     // opened file descriptor or -1\n+} oci_mount_ctx;\n+\n+// NOTE: Update init_oci_launch_cmd_ctx and destroy_oci_launch_cmd_ctx\n+//       when this is changed.\n+typedef struct oci_launch_cmd_context_struct {\n+  oci_base_ctx base_ctx;      // run root and layer lock\n+  oci_overlay_desc upper;     // writable upper layer descriptor\n+  oci_mount_ctx* layers;      // layer mount info\n+  unsigned int num_layers;    // number of layer mount contexts\n+} oci_launch_cmd_ctx;\n+\n+void init_oci_overlay_desc(oci_overlay_desc* desc) {\n+  memset(desc, 0, sizeof(oci_overlay_desc));\n+}\n+\n+void destroy_oci_overlay_desc(oci_overlay_desc* desc) {\n+  if (desc != NULL) {\n+    free(desc->top_path);\n+    free(desc->mount_path);\n+    free(desc->upper_path);\n+    free(desc->work_path);\n+  }\n+}\n+\n+static void init_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  ctx->fd = -1;\n+}\n+\n+static void destroy_oci_mount_ctx(oci_mount_ctx* ctx) {\n+  if (ctx != NULL) {\n+    free(ctx->src_path);\n+    free(ctx->layer_path);\n+    free(ctx->mount_path);\n+    if (ctx->fd != -1) {\n+      close(ctx->fd);\n+    }\n+  }\n+}\n+\n+static void init_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  memset(ctx, 0, sizeof(*ctx));\n+  init_oci_base_ctx(&ctx->base_ctx);\n+  init_oci_overlay_desc(&ctx->upper);\n+}\n+\n+static void destroy_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    if (ctx->layers != NULL) {\n+      unsigned int i;\n+      for (i = 0; i < ctx->num_layers; ++i) {\n+        destroy_oci_mount_ctx(&ctx->layers[i]);\n+      }\n+      free(ctx->layers);\n+    }\n+    destroy_oci_overlay_desc(&ctx->upper);\n+    destroy_oci_base_ctx(&ctx->base_ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* alloc_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = malloc(sizeof(*ctx));\n+  if (ctx != NULL) {\n+    init_oci_launch_cmd_ctx(ctx);\n+  }\n+  return ctx;\n+}\n+\n+static void free_oci_launch_cmd_ctx(oci_launch_cmd_ctx* ctx) {\n+  if (ctx != NULL) {\n+    destroy_oci_launch_cmd_ctx(ctx);\n+    free(ctx);\n+  }\n+}\n+\n+static oci_launch_cmd_ctx* setup_oci_launch_cmd_ctx() {\n+  oci_launch_cmd_ctx* ctx = alloc_oci_launch_cmd_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Cannot allocate memory in oci_launch_cmd_ctx\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+  \n+  if (!open_oci_base_ctx(&ctx->base_ctx)) {\n+    free_oci_launch_cmd_ctx(ctx);\n+    return NULL;\n+  }\n+\n+  return ctx;\n+}\n+\n+/**\n+ * Compute a digest of a layer based on the layer's pathname.\n+ * Returns the malloc'd digest hexstring or NULL if there was an error.\n+ */\n+static char* compute_layer_hash(const char* path) {\n+  char* digest = NULL;\n+  EVP_MD_CTX* mdctx = EVP_MD_CTX_create();\n+  if (mdctx == NULL) {\n+    fputs(\"ERROR: Unable to create EVP MD context\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestInit_ex(mdctx, EVP_sha256(), NULL)) {\n+    fputs(\"ERROR: Unable to initialize SHA256 digester\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!EVP_DigestUpdate(mdctx, path, strlen(path))) {\n+    fputs(\"ERROR: Unable to compute layer path digest\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  unsigned char raw_digest[EVP_MAX_MD_SIZE];\n+  unsigned int raw_digest_len = 0;\n+  if (!EVP_DigestFinal_ex(mdctx, raw_digest, &raw_digest_len)) {\n+    fputs(\"ERROR: Unable to compute layer path digest in compute_layer_hash\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  digest = to_hexstring(raw_digest, raw_digest_len);\n+\n+cleanup:\n+  if (mdctx != NULL) {\n+    EVP_MD_CTX_destroy(mdctx);\n+  }\n+  return digest;\n+}\n+\n+/**\n+ * Open the specified path which is expected to be a mount point.\n+ *\n+ * Returns an valid file descriptor when the path exists and is a mount point\n+ * or -1 if the path does not exist or is not a mount point.\n+ *\n+ * NOTE: The corresponding read lock must be acquired.\n+ */\n+static int open_mountpoint(const char* path) {\n+  int fd = open(path, O_RDONLY | O_CLOEXEC);\n+  if (fd == -1) {\n+    if (errno != ENOENT) {\n+      fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at open\\n\", path,\n+          strerror(errno));\n+    }\n+    return fd;\n+  }\n+\n+  struct stat mstat, pstat;\n+  if (fstat(fd, &mstat) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point at %s : %s at fstat\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+  if (!S_ISDIR(mstat.st_mode)) {\n+    fprintf(ERRORFILE, \"ERROR: Mount point %s is not a directory\\n\", path);\n+    goto close_fail;\n+  }\n+\n+  if (fstatat(fd, \"..\", &pstat, 0) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing mount point parent of %s : %s\\n\", path,\n+        strerror(errno));\n+    goto close_fail;\n+  }\n+\n+  // If the parent directory's device matches the child directory's device\n+  // then we didn't cross a device boundary in the filesystem and therefore\n+  // this is likely not a mount point.\n+  // TODO: This assumption works for loopback mounts but would not work for\n+  //       bind mounts or some other situations. Worst case would need to\n+  //       walk the mount table and otherwise replicate the mountpoint(1) cmd.\n+  if (mstat.st_dev == pstat.st_dev) {\n+    goto close_fail;\n+  }\n+\n+  return fd;\n+\n+close_fail:\n+  close(fd);\n+  return -1;\n+}\n+\n+bool init_overlay_descriptor(oci_overlay_desc* desc,\n+    const char* run_root, const char* container_id) {\n+  if (asprintf(&desc->top_path, \"%s/%s\", run_root, container_id) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->mount_path, \"%s/rootfs\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->upper_path, \"%s/upper\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  if (asprintf(&desc->work_path, \"%s/work\", desc->top_path) == -1) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool init_layer_mount_ctx(oci_mount_ctx* ctx, const olc_layer_spec* spec,\n+    const char* run_root) {\n+  char* hash = compute_layer_hash(spec->path);\n+  if (hash == NULL) {\n+    return false;\n+  }\n+\n+  ctx->layer_path = get_oci_layer_path(run_root, hash);\n+  free(hash);\n+  if (ctx->layer_path == NULL) {\n+    return false;\n+  }\n+\n+  ctx->mount_path = get_oci_layer_mount_path(ctx->layer_path);\n+  if (ctx->mount_path == NULL) {\n+    return false;\n+  }\n+  #ifdef DEBUG  \n+  print_res_uid_gid(\"right before open layer image\");\n+  #endif\n+\n+  ctx->fd = open(spec->path, O_RDONLY | O_CLOEXEC);\n+  if (ctx->fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening layer image at %s : %s\\n\", spec->path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  ctx->src_path = strdup(spec->path);\n+  return ctx->src_path != NULL;\n+}\n+\n+/**\n+ * Initialize the layers mount contexts and open each layer image as the user\n+ * to validate the user should be allowed to access the image composed of\n+ * these layers.\n+ */\n+static bool init_layer_mount_ctxs(oci_launch_cmd_ctx* ctx,\n+    const olc_layer_spec* layer_specs, unsigned int num_layers) {\n+  ctx->layers = malloc(num_layers * sizeof(*ctx->layers));\n+  if (ctx->layers == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in init_layer_mount_ctxs\\n\", ERRORFILE);\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    init_oci_mount_ctx(&ctx->layers[i]);\n+  }\n+  ctx->num_layers = num_layers;\n+\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!init_layer_mount_ctx(&ctx->layers[i], &layer_specs[i],\n+        ctx->base_ctx.run_root)) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+/**\n+ * Allocate a loop device and associate it with a file descriptor.\n+ * Returns the file descriptor of the opened loop device or -1 on error.\n+ */\n+static int allocate_and_open_loop_device(char** loopdev_name_out, int src_fd) {\n+  *loopdev_name_out = NULL;\n+  int loopctl = open(\"/dev/loop-control\", O_RDWR);\n+  if (loopctl == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error opening /dev/loop-control : %s\\n\",\n+        strerror(errno));\n+    return -1;\n+  }\n+\n+  char* loopdev_name = NULL;\n+  int loop_fd = -1;\n+  while (true) {\n+    int loop_num = ioctl(loopctl, LOOP_CTL_GET_FREE);\n+    if (loop_num < 0) {\n+      fprintf(ERRORFILE, \"ERROR: Error allocating a new loop device: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (asprintf(&loopdev_name, \"/dev/loop%d\", loop_num) == -1) {\n+      fputs(\"ERROR: Unable to allocate memory in allocate_and_open_loop_device\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+    loop_fd = open(loopdev_name, O_RDWR | O_CLOEXEC);\n+    if (loop_fd == -1) {\n+      fprintf(ERRORFILE, \"ERROR: Unable to open loop device at %s : %s\\n\",\n+          loopdev_name, strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (ioctl(loop_fd, LOOP_SET_FD, src_fd) != -1) {\n+      break;\n+    }\n+\n+    // EBUSY indicates another process stole this loop device\n+    if (errno != EBUSY) {\n+      fprintf(ERRORFILE, \"ERROR: Error setting loop source file: %s\\n\",\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    close(loop_fd);\n+    loop_fd = -1;\n+    free(loopdev_name);\n+    loopdev_name = NULL;\n+  }\n+\n+  struct loop_info64 loop_info;\n+  memset(&loop_info, 0, sizeof(loop_info));\n+  loop_info.lo_flags = LO_FLAGS_READ_ONLY | LO_FLAGS_AUTOCLEAR;\n+  if (ioctl(loop_fd, LOOP_SET_STATUS64, &loop_info) == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Error setting loop flags: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  close(loopctl);\n+  *loopdev_name_out = loopdev_name;\n+  return loop_fd;\n+\n+fail:\n+  if (loop_fd != -1) {\n+    close(loop_fd);\n+  }\n+  close(loopctl);\n+  free(loopdev_name);\n+  return -1;\n+}\n+\n+/**\n+ * Mount a filesystem with the specified arguments, see the mount(2) manpage.\n+ * If the mount fails an error message is printed to ERRORFILE.\n+ * Returns true for success or false on failure.\n+ */\n+static bool do_mount(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mount(src, target, fs_type, mount_flags, mount_options) == -1) {\n+    const char* nullstr = \"NULL\";\n+    src = (src != NULL) ? src : nullstr;\n+    fs_type = (fs_type != NULL) ? fs_type : nullstr;\n+    mount_options = (mount_options != NULL) ? mount_options : nullstr;\n+    fprintf(ERRORFILE, \"ERROR: Error mounting %s at %s type %s with options %s : %s\\n\",\n+        src, target, fs_type, mount_options, strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+/**\n+ * Mount a filesystem and return a file descriptor opened to the mount point.\n+ * The mount point directory will be created if necessary.\n+ * Returns a file descriptor to the mount point or -1 if there was an error.\n+ */\n+static int mount_and_open(const char* src, const char* target,\n+    const char* fs_type, unsigned long mount_flags, const char* mount_options) {\n+  if (mkdir(target, S_IRWXU) == -1 && errno != EEXIST) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating mountpoint directory at %s : %s\\n\",\n+        target, strerror(errno));\n+    return -1;\n+  }\n+\n+  if (!do_mount(src, target, fs_type, mount_flags, mount_options)) {\n+    return -1;\n+  }\n+\n+  return open_mountpoint(target);\n+}\n+\n+static int mount_layer_and_open(const oci_mount_ctx* layer) {\n+  if (mkdir(layer->layer_path, S_IRWXU) == -1) {\n+    if (errno != EEXIST) {\n+      fprintf(ERRORFILE, \"ERROR: Error creating layer directory at %s : %s\\n\",\n+          layer->layer_path, strerror(errno));\n+      return -1;\n+    }\n+  }\n+\n+  char *loopdev_name = NULL;\n+  int loopfd = allocate_and_open_loop_device(&loopdev_name, layer->fd);\n+  if (loopfd == -1) {\n+    return -1;\n+  }\n+\n+  int mount_fd = mount_and_open(loopdev_name, layer->mount_path, \"squashfs\",\n+    MS_RDONLY, NULL);\n+\n+  // If the mount worked then the mount holds the loop device open. If the mount\n+  // failed then the loop device is no longer needed, so close it either way.\n+  close(loopfd);\n+\n+  free(loopdev_name);\n+  return mount_fd;\n+}\n+\n+static bool do_mount_layers_with_lock(oci_launch_cmd_ctx* ctx) {\n+  bool have_write_lock = false;\n+  unsigned int i;\n+  for (i = 0; i < ctx->num_layers; ++i) {\n+    int layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+    if (layer_mount_fd != -1) {\n+      // Touch layer directory to show this existing layer was recently used.\n+      if (utimes(ctx->layers[i].layer_path, NULL) == -1) {\n+        // Error is not critical to container launch so just print a warning.\n+        fprintf(ERRORFILE, \"ERROR: Error updating timestamps of %s : %s\\n\",\n+            ctx->layers[i].layer_path, strerror(errno));\n+      }\n+    } else {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(&ctx->base_ctx)) {\n+          return false;\n+        }\n+        have_write_lock = true;\n+        // Try to open the mount point again in case another process created it\n+        // while we were waiting for the write lock.\n+        layer_mount_fd = open_mountpoint(ctx->layers[i].mount_path);\n+      }\n+\n+      if (layer_mount_fd == -1) {\n+        layer_mount_fd = mount_layer_and_open(&ctx->layers[i]);\n+\n+        if (layer_mount_fd == -1) {\n+          fprintf(ERRORFILE, \"ERROR: Unable to mount layer data from %s\\n\",\n+              ctx->layers[i].src_path);\n+          return false;\n+        }\n+      }\n+    }\n+\n+    // Now that the layer is mounted we can start tracking the open mount point\n+    // for the layer rather than the descriptor to the layer image.\n+    // The mount point references the underlying image, so we no longer need\n+    // a direct reference to the layer image.\n+    close(ctx->layers[i].fd);\n+    ctx->layers[i].fd = layer_mount_fd;\n+  }\n+\n+  return true;\n+}\n+\n+static bool mount_layers(oci_launch_cmd_ctx* ctx) {\n+  if (!acquire_oci_layers_read_lock(&ctx->base_ctx)) {\n+    return false;\n+  }\n+\n+  bool result = do_mount_layers_with_lock(ctx);\n+\n+  if (!release_oci_layers_lock(&ctx->base_ctx)) {\n+    return false;\n+  }\n+\n+  return result;\n+}\n+\n+static char* build_overlay_options(oci_mount_ctx* layers,\n+    unsigned int num_layers, const oci_overlay_desc* upper) {\n+  char* result = NULL;\n+  const int sb_incr = 16*1024;\n+  strbuf sb;\n+  if (!strbuf_init(&sb, sb_incr)) {\n+    fputs(\"ERROR: Unable to allocate memory in build_overlay_options\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  if (!strbuf_append_fmt(&sb, sb_incr, \"upperdir=%s,workdir=%s,lowerdir=\",\n+      upper->upper_path, upper->work_path)) {\n+    goto cleanup;\n+  }\n+\n+  // Overlay expects the base layer to be the last layer listed, but the\n+  // OCI image manifest specifies the base layer first.\n+  bool need_separator = false;\n+  int i;\n+  for (i = num_layers - 1; i >= 0; --i) {\n+    char* fmt = need_separator ? \":%s\" : \"%s\";\n+    if (!strbuf_append_fmt(&sb, sb_incr, fmt, layers[i].mount_path)) {\n+      goto cleanup;\n+    }\n+    need_separator = true;\n+  }\n+\n+  result = strbuf_detach_buffer(&sb);\n+\n+cleanup:\n+  strbuf_destroy(&sb);\n+  return result;\n+}\n+\n+static bool create_overlay_dirs(oci_overlay_desc* od) {\n+  if (mkdir(od->top_path, S_IRWXU) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating top_path %s : %s\\n\", od->top_path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  if (mkdir(od->mount_path, S_IRWXU) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating mount_path %s : %s\\n\", od->mount_path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  mode_t upper_mode = S_IRWXU | S_IRGRP | S_IXGRP | S_IROTH | S_IXOTH;\n+  if (mkdir(od->upper_path, upper_mode) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating upper_path %s : %s\\n\", od->upper_path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  if (mkdir(od->work_path, S_IRWXU) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Error creating work_path %s : %s\\n\", od->work_path,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool mount_container_rootfs(oci_launch_cmd_ctx* ctx) {\n+  if (!create_overlay_dirs(&ctx->upper)) {\n+    return false;\n+  }\n+\n+  if (!mount_layers(ctx)) {\n+    return false;\n+  }\n+\n+  char* overlay_opts = build_overlay_options(ctx->layers, ctx->num_layers,\n+      &ctx->upper);\n+  if (overlay_opts == NULL) {\n+    return false;\n+  }\n+\n+  bool mount_ok = do_mount(\"overlay\", ctx->upper.mount_path, \"overlay\", 0,\n+      overlay_opts);\n+  free(overlay_opts);\n+  if (!mount_ok) {\n+    return false;\n+  }\n+\n+  // It would be tempting to close the layer file descriptors here since the\n+  // overlay should also be holding references to all the layers.  However\n+  // overlay somehow does NOT hold a hard reference to underlying filesystems,\n+  // so the layer file descriptors need to be kept open in order to prevent\n+  // other containers from unmounting shared layers when they cleanup.\n+\n+  return true;\n+}\n+\n+static bool rmdir_recursive_fd(int fd) {\n+  int dirfd = dup(fd);\n+  if (dirfd == -1) {\n+    fputs(\"Unable to duplicate file descriptor\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  DIR* dir = fdopendir(dirfd);\n+  if (dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Error deleting directory: %s\\n\", strerror(errno));\n+    return false;\n+  }\n+\n+  bool result = false;\n+  struct dirent* de;\n+  while ((de = readdir(dir)) != NULL) {\n+    if (strcmp(\".\", de->d_name) == 0 || strcmp(\"..\", de->d_name) == 0) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(dirfd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error accessing %s : %s in rmdir_recursive_fd\\n\", de->d_name,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+\n+    int rmflags = 0;\n+    if (S_ISDIR(statbuf.st_mode)) {\n+      rmflags = AT_REMOVEDIR;\n+      int de_fd = openat(dirfd, de->d_name, O_RDONLY | O_NOFOLLOW);\n+      if (de_fd == -1) {\n+        if (errno == ENOENT) {\n+          continue;\n+        }\n+        fprintf(ERRORFILE, \"ERROR: Error opening %s for delete: %s in rmdir_recursive_fd\\n\", de->d_name,\n+            strerror(errno));\n+        goto cleanup;\n+      }\n+      bool ok = rmdir_recursive_fd(de_fd);\n+      close(de_fd);\n+      if (!ok) {\n+        goto cleanup;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDUyOTk0NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550529944", "bodyText": "should we first check if layers is null to be safe?", "author": "agresch", "createdAt": "2020-12-31T16:23:00Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_launch_cmd.c", "diffHunk": "@@ -0,0 +1,544 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <stdbool.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+#include \"utils/string-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"oci_launch_cmd.h\"\n+\n+#define SQUASHFS_MEDIA_TYPE     \"application/vnd.squashfs\"\n+\n+static void free_olc_layers(olc_layer_spec* layers, unsigned int num_layers) {\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    free(layers[i].media_type);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MDU5MzY5Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r670593692", "bodyText": "the size layers array matches with num_layers, so we don't need to check null here.", "author": "Ethanlm", "createdAt": "2021-07-15T15:54:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDUyOTk0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDUzNzQ1Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550537452", "bodyText": "No error message for this case", "author": "agresch", "createdAt": "2020-12-31T16:32:45Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_launch_cmd.c", "diffHunk": "@@ -0,0 +1,544 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <stdbool.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+#include \"utils/string-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"oci_launch_cmd.h\"\n+\n+#define SQUASHFS_MEDIA_TYPE     \"application/vnd.squashfs\"\n+\n+static void free_olc_layers(olc_layer_spec* layers, unsigned int num_layers) {\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    free(layers[i].media_type);\n+    free(layers[i].path);\n+  }\n+  free(layers);\n+}\n+\n+/**\n+ * Free an OCI launch command structure and all memory associated with it.\n+ */\n+void free_oci_launch_cmd(oci_launch_cmd* olc) {\n+  if (olc != NULL) {\n+    free(olc->username);\n+    free(olc->container_id);\n+    free(olc->pid_file);\n+    free(olc->script_path);\n+    free_olc_layers(olc->layers, olc->num_layers);\n+    cJSON_Delete(olc->config.hostname);\n+    cJSON_Delete(olc->config.linux_config);\n+    cJSON_Delete(olc->config.mounts);\n+    cJSON_Delete(olc->config.process.args);\n+    cJSON_Delete(olc->config.process.cwd);\n+    cJSON_Delete(olc->config.process.env);\n+    free(olc);\n+  }\n+}\n+\n+static cJSON* parse_json_file(const char* filename) {\n+  char* data = read_file_to_string_as_wl_user(filename);\n+  if (data == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot read command file %s\\n\", filename);\n+    return NULL;\n+  }\n+\n+  const char* parse_error_location = NULL;\n+  cJSON* json = cJSON_ParseWithOpts(data, &parse_error_location, 1);\n+  if (json == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Error parsing command file %s at byte offset %ld\\n\",\n+        filename, parse_error_location - data);\n+  }\n+\n+  free(data);\n+  return json;\n+}\n+\n+static bool parse_oci_launch_cmd_layer(olc_layer_spec* layer_out,\n+    const cJSON* layer_json) {\n+  if (!cJSON_IsObject(layer_json)) {\n+    fputs(\"ERROR: OCI launch command layer is not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* media_type_json = cJSON_GetObjectItemCaseSensitive(layer_json,\n+      \"mediaType\");\n+  if (!cJSON_IsString(media_type_json)) {\n+    fputs(\"ERROR: Bad/Missing media type for OCI launch command layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* path_json = cJSON_GetObjectItemCaseSensitive(layer_json, \"path\");\n+  if (!cJSON_IsString(path_json)) {\n+    fputs(\"ERROR: Bad/Missing path for OCI launch command layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  layer_out->media_type = strdup(media_type_json->valuestring);\n+  layer_out->path = strdup(path_json->valuestring);\n+  return true;\n+}\n+\n+static olc_layer_spec* parse_oci_launch_cmd_layers(unsigned int* num_layers_out,\n+    const cJSON* layers_json) {\n+  if (!cJSON_IsArray(layers_json)) {\n+    fputs(\"ERROR: Bad/Missing OCI launch command layers\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+\n+  unsigned int num_layers = (unsigned int) cJSON_GetArraySize(layers_json);\n+  if (num_layers <= 0) {\n+    return NULL;\n+  }\n+\n+  olc_layer_spec* layers = calloc(num_layers, sizeof(*layers));\n+  if (layers == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot allocate memory for %d layers\\n\",\n+        num_layers + 1);\n+    return NULL;\n+  }\n+\n+  unsigned int layer_index = 0;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, layers_json) {\n+    if (layer_index >= num_layers) {\n+      fputs(\"ERROR: Iterating past end of layer array\\n\", ERRORFILE);\n+      free_olc_layers(layers, layer_index);\n+      return NULL;\n+    }\n+\n+    if (!parse_oci_launch_cmd_layer(&layers[layer_index], e)) {\n+      free_olc_layers(layers, layer_index);\n+      return NULL;\n+    }\n+\n+    ++layer_index;\n+  }\n+\n+  *num_layers_out = layer_index;\n+  return layers;\n+}\n+\n+static int parse_reap_layers_keep(cJSON* json) {\n+  if (!cJSON_IsNumber(json)) {\n+    fputs(\"ERROR: Bad/Missing OCI reap layer keep number\\n\", ERRORFILE);\n+    return -1;\n+  }\n+  return json->valueint;\n+}\n+\n+static void parse_oci_launch_cmd_oci_config(oci_config* oc, cJSON* oc_json) {\n+  if (!cJSON_IsObject(oc_json)) {\n+    fputs(\"ERROR: Bad/Missing OCI runtime config in launch command\\n\", ERRORFILE);\n+    return;\n+  }\n+  oc->hostname = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"hostname\");\n+  oc->linux_config = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"linux\");\n+  oc->mounts = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"mounts\");\n+\n+  cJSON* process_json = cJSON_GetObjectItemCaseSensitive(oc_json, \"process\");\n+  if (!cJSON_IsObject(process_json)) {\n+    fputs(\"ERROR: Bad/Missing process section in OCI config\\n\", ERRORFILE);\n+    return;\n+  }\n+  oc->process.args = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"args\");\n+  oc->process.cwd = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"cwd\");\n+  oc->process.env = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"env\");\n+}\n+\n+static bool is_valid_layer_media_type(char* media_type) {\n+  if (media_type == NULL) {\n+    return false;\n+  }\n+\n+  if (strcmp(SQUASHFS_MEDIA_TYPE, media_type)) {\n+    fprintf(ERRORFILE, \"ERROR: Unrecognized layer media type: %s\\n\", media_type);\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_launch_cmd_layers(olc_layer_spec* layers,\n+    unsigned int num_layers) {\n+  if (layers == NULL) {\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!is_valid_layer_media_type(layers[i].media_type)) {\n+      return false;\n+    }\n+    if (layers[i].path == NULL) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_linux_resources(const cJSON* oclr) {\n+  if (!cJSON_IsObject(oclr)) {\n+    fputs(\"ERROR: OCI config linux resources missing or not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool all_sections_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, oclr) {\n+    if (strcmp(\"blockIO\", e->string) == 0) {\n+      // block I/O settings allowed\n+    } else if (strcmp(\"cpu\", e->string) == 0) {\n+      // cpu settings allowed\n+    } else if (strcmp(\"memory\", e->string) == 0) {\n+      // memory settings allowed. (added for storm. hadoop doesn't allow this)\n+    } else {\n+      fprintf(ERRORFILE,\n+          \"ERROR: Unrecognized OCI config linux resources element: %s\\n\", e->string);\n+      all_sections_ok = false;\n+    }\n+  }\n+\n+  return all_sections_ok;\n+}\n+\n+static bool is_valid_oci_config_linux_seccomp(const cJSON* ocls) {\n+  // TODO: seccomp validation\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_linux(const cJSON* ocl) {\n+  if (!cJSON_IsObject(ocl)) {\n+    fputs(\"ERROR: OCI config linux section missing or not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool has_cgroup_path = false;\n+  bool all_sections_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, ocl) {\n+    if (strcmp(\"cgroupsPath\", e->string) == 0) {\n+      has_cgroup_path = true;\n+      if (!cJSON_IsString(e)) {\n+        all_sections_ok = false;\n+      }\n+    } else if (strcmp(\"resources\", e->string) == 0) {\n+      all_sections_ok &= is_valid_oci_config_linux_resources(e);\n+    } else if (strcmp(\"seccomp\", e->string) == 0) {\n+      all_sections_ok &= is_valid_oci_config_linux_seccomp(e);\n+    } else {\n+      fprintf(ERRORFILE, \"ERROR: Unrecognized OCI config linux element: %s\\n\",\n+          e->string);\n+      all_sections_ok = false;\n+    }\n+  }\n+\n+  return has_cgroup_path && all_sections_ok;\n+}\n+\n+static bool is_valid_mount_options(const cJSON* mo) {\n+  if (!cJSON_IsArray(mo)) {\n+    fputs(\"ERROR: OCI config mount options not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool has_rbind = false;\n+  bool has_rprivate = false;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, mo) {\n+    if (!cJSON_IsString(e)) {\n+      fputs(\"ERROR: OCI config mount option is not a string\\n\", ERRORFILE);\n+      return false;\n+    }\n+    if (strcmp(\"rbind\", e->valuestring) == 0) {\n+      has_rbind = true;\n+    } else if (strcmp(\"rprivate\", e->valuestring) == 0) {\n+      has_rprivate = true;\n+    }\n+  }\n+\n+  if (!has_rbind) {\n+    fputs(\"ERROR: OCI config mount options missing rbind\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (!has_rprivate) {\n+    fputs(\"ERROR: OCI config mount options missing rprivate\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_mount(const cJSON* mount) {\n+  if (!cJSON_IsObject(mount)) {\n+    fputs(\"ERROR: OCI config mount entry is not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool has_type = false;\n+  bool has_options = false;\n+  char* source = NULL;\n+  char* destination = NULL;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, mount) {\n+    if (strcmp(\"type\", e->string) == 0) {\n+      if (!cJSON_IsString(e) || strcmp(\"bind\", e->valuestring)) {\n+        fputs(\"ERROR: OCI config mount is not bind type\\n\", ERRORFILE);\n+        return false;\n+      }\n+      has_type = true;\n+    } else if (strcmp(\"source\", e->string) == 0) {\n+      if (!cJSON_IsString(e)) {\n+        fputs(\"ERROR: OCI config mount source is not a string\\n\", ERRORFILE);\n+        return false;\n+      }\n+      source = e->valuestring;\n+    } else if (strcmp(\"destination\", e->string) == 0) {\n+      if (!cJSON_IsString(e)) {\n+        fputs(\"ERROR: OCI config mount destination is not a string\\n\", ERRORFILE);\n+        return false;\n+      }\n+      destination = e->valuestring;\n+    } else if (strcmp(\"options\", e->string) == 0) {\n+      if (!is_valid_mount_options(e)) {\n+        return false;\n+      }\n+      has_options = true;\n+    } else {\n+      fprintf(ERRORFILE, \"ERROR: Unrecognized OCI config mount parameter: %s\\n\",\n+          e->string);\n+      return false;\n+    }\n+  }\n+\n+  if (!has_type) {\n+    fputs(\"ERROR: OCI config mount missing mount type\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (!has_options) {\n+    fputs(\"ERROR: OCI config mount missing mount options\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (source == NULL) {\n+    fputs(\"ERROR: OCI config mount missing source\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (destination == NULL) {\n+    fputs(\"ERROR: OCI config mount missing destination\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  // TODO: Need to add mount source/dest whitelist checking here.\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_mounts(const cJSON* ocm) {\n+  if (ocm == NULL) {\n+    return true;  // OK to have no extra mounts\n+  }\n+  if (!cJSON_IsArray(ocm)) {\n+    fputs(\"ERROR: OCI config mounts is not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool all_mounts_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, ocm) {\n+    all_mounts_ok &= is_valid_mount(e);\n+  }\n+\n+  return all_mounts_ok;\n+}\n+\n+static bool is_valid_oci_config_process(const oci_config_process* ocp) {\n+  if (ocp == NULL) {\n+    return false;\n+  }\n+\n+  if (!cJSON_IsArray(ocp->args)) {\n+    fputs(\"ERROR: OCI config process args is missing or not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, ocp->args) {\n+    if (!cJSON_IsString(e)) {\n+      fputs(\"ERROR: OCI config process args has a non-string in array\\n\", ERRORFILE);\n+      return false;\n+    }\n+  }\n+\n+  if (!cJSON_IsString(ocp->cwd)) {\n+    fputs(\"ERROR: Bad/Missing OCI config process cwd\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (!cJSON_IsArray(ocp->env)) {\n+    fputs(\"ERROR: OCI config process env is missing or not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+  cJSON_ArrayForEach(e, ocp->env) {\n+    if (!cJSON_IsString(e)) {\n+      fputs(\"ERROR: OCI config process env has a non-string in array\\n\", ERRORFILE);\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config(const oci_config* oc) {\n+  bool is_valid = true;\n+  if (oc->hostname != NULL && !cJSON_IsString(oc->hostname)) {\n+    fputs(\"ERROR: OCI config hostname is not a string\\n\", ERRORFILE);\n+    is_valid = false;\n+  }\n+  is_valid &= is_valid_oci_config_linux(oc->linux_config);\n+  is_valid &= is_valid_oci_config_mounts(oc->mounts);\n+  is_valid &= is_valid_oci_config_process(&oc->process);\n+  return is_valid;\n+}\n+\n+static bool is_valid_oci_launch_cmd(const oci_launch_cmd* olc) {\n+  if (olc == NULL) {\n+    return false;\n+  }\n+\n+  if (olc->username == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing username\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (olc->container_id == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing container ID\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (!validate_container_id(olc->container_id)) {\n+    fprintf(ERRORFILE, \"ERROR: Bad container id in OCI command: %s\\n\",\n+        olc->container_id);\n+    return false;\n+  }\n+\n+  if (olc->pid_file == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing pid file\\n\", ERRORFILE);\n+    return false;\n+  }\n+  struct stat statbuf;\n+  if (stat(olc->pid_file, &statbuf) == 0) {\n+    fprintf(ERRORFILE, \"ERROR: pid file already exists: %s\\n\", olc->pid_file);\n+    return false;\n+  }\n+  if (errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing %s : %s in is_valid_oci_launch_cmd\\n\", olc->pid_file,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  if (olc->script_path == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing container script path\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (!is_valid_oci_launch_cmd_layers(olc->layers, olc->num_layers)) {\n+    return false;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDUzNzY4Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550537682", "bodyText": "error message", "author": "agresch", "createdAt": "2020-12-31T16:33:05Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_launch_cmd.c", "diffHunk": "@@ -0,0 +1,544 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <stdbool.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+#include \"utils/string-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"oci_launch_cmd.h\"\n+\n+#define SQUASHFS_MEDIA_TYPE     \"application/vnd.squashfs\"\n+\n+static void free_olc_layers(olc_layer_spec* layers, unsigned int num_layers) {\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    free(layers[i].media_type);\n+    free(layers[i].path);\n+  }\n+  free(layers);\n+}\n+\n+/**\n+ * Free an OCI launch command structure and all memory associated with it.\n+ */\n+void free_oci_launch_cmd(oci_launch_cmd* olc) {\n+  if (olc != NULL) {\n+    free(olc->username);\n+    free(olc->container_id);\n+    free(olc->pid_file);\n+    free(olc->script_path);\n+    free_olc_layers(olc->layers, olc->num_layers);\n+    cJSON_Delete(olc->config.hostname);\n+    cJSON_Delete(olc->config.linux_config);\n+    cJSON_Delete(olc->config.mounts);\n+    cJSON_Delete(olc->config.process.args);\n+    cJSON_Delete(olc->config.process.cwd);\n+    cJSON_Delete(olc->config.process.env);\n+    free(olc);\n+  }\n+}\n+\n+static cJSON* parse_json_file(const char* filename) {\n+  char* data = read_file_to_string_as_wl_user(filename);\n+  if (data == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot read command file %s\\n\", filename);\n+    return NULL;\n+  }\n+\n+  const char* parse_error_location = NULL;\n+  cJSON* json = cJSON_ParseWithOpts(data, &parse_error_location, 1);\n+  if (json == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Error parsing command file %s at byte offset %ld\\n\",\n+        filename, parse_error_location - data);\n+  }\n+\n+  free(data);\n+  return json;\n+}\n+\n+static bool parse_oci_launch_cmd_layer(olc_layer_spec* layer_out,\n+    const cJSON* layer_json) {\n+  if (!cJSON_IsObject(layer_json)) {\n+    fputs(\"ERROR: OCI launch command layer is not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* media_type_json = cJSON_GetObjectItemCaseSensitive(layer_json,\n+      \"mediaType\");\n+  if (!cJSON_IsString(media_type_json)) {\n+    fputs(\"ERROR: Bad/Missing media type for OCI launch command layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* path_json = cJSON_GetObjectItemCaseSensitive(layer_json, \"path\");\n+  if (!cJSON_IsString(path_json)) {\n+    fputs(\"ERROR: Bad/Missing path for OCI launch command layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  layer_out->media_type = strdup(media_type_json->valuestring);\n+  layer_out->path = strdup(path_json->valuestring);\n+  return true;\n+}\n+\n+static olc_layer_spec* parse_oci_launch_cmd_layers(unsigned int* num_layers_out,\n+    const cJSON* layers_json) {\n+  if (!cJSON_IsArray(layers_json)) {\n+    fputs(\"ERROR: Bad/Missing OCI launch command layers\\n\", ERRORFILE);\n+    return NULL;\n+  }\n+\n+  unsigned int num_layers = (unsigned int) cJSON_GetArraySize(layers_json);\n+  if (num_layers <= 0) {\n+    return NULL;\n+  }\n+\n+  olc_layer_spec* layers = calloc(num_layers, sizeof(*layers));\n+  if (layers == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot allocate memory for %d layers\\n\",\n+        num_layers + 1);\n+    return NULL;\n+  }\n+\n+  unsigned int layer_index = 0;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, layers_json) {\n+    if (layer_index >= num_layers) {\n+      fputs(\"ERROR: Iterating past end of layer array\\n\", ERRORFILE);\n+      free_olc_layers(layers, layer_index);\n+      return NULL;\n+    }\n+\n+    if (!parse_oci_launch_cmd_layer(&layers[layer_index], e)) {\n+      free_olc_layers(layers, layer_index);\n+      return NULL;\n+    }\n+\n+    ++layer_index;\n+  }\n+\n+  *num_layers_out = layer_index;\n+  return layers;\n+}\n+\n+static int parse_reap_layers_keep(cJSON* json) {\n+  if (!cJSON_IsNumber(json)) {\n+    fputs(\"ERROR: Bad/Missing OCI reap layer keep number\\n\", ERRORFILE);\n+    return -1;\n+  }\n+  return json->valueint;\n+}\n+\n+static void parse_oci_launch_cmd_oci_config(oci_config* oc, cJSON* oc_json) {\n+  if (!cJSON_IsObject(oc_json)) {\n+    fputs(\"ERROR: Bad/Missing OCI runtime config in launch command\\n\", ERRORFILE);\n+    return;\n+  }\n+  oc->hostname = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"hostname\");\n+  oc->linux_config = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"linux\");\n+  oc->mounts = cJSON_DetachItemFromObjectCaseSensitive(oc_json, \"mounts\");\n+\n+  cJSON* process_json = cJSON_GetObjectItemCaseSensitive(oc_json, \"process\");\n+  if (!cJSON_IsObject(process_json)) {\n+    fputs(\"ERROR: Bad/Missing process section in OCI config\\n\", ERRORFILE);\n+    return;\n+  }\n+  oc->process.args = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"args\");\n+  oc->process.cwd = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"cwd\");\n+  oc->process.env = cJSON_DetachItemFromObjectCaseSensitive(\n+      process_json, \"env\");\n+}\n+\n+static bool is_valid_layer_media_type(char* media_type) {\n+  if (media_type == NULL) {\n+    return false;\n+  }\n+\n+  if (strcmp(SQUASHFS_MEDIA_TYPE, media_type)) {\n+    fprintf(ERRORFILE, \"ERROR: Unrecognized layer media type: %s\\n\", media_type);\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_launch_cmd_layers(olc_layer_spec* layers,\n+    unsigned int num_layers) {\n+  if (layers == NULL) {\n+    return false;\n+  }\n+  unsigned int i;\n+  for (i = 0; i < num_layers; ++i) {\n+    if (!is_valid_layer_media_type(layers[i].media_type)) {\n+      return false;\n+    }\n+    if (layers[i].path == NULL) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_linux_resources(const cJSON* oclr) {\n+  if (!cJSON_IsObject(oclr)) {\n+    fputs(\"ERROR: OCI config linux resources missing or not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool all_sections_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, oclr) {\n+    if (strcmp(\"blockIO\", e->string) == 0) {\n+      // block I/O settings allowed\n+    } else if (strcmp(\"cpu\", e->string) == 0) {\n+      // cpu settings allowed\n+    } else if (strcmp(\"memory\", e->string) == 0) {\n+      // memory settings allowed. (added for storm. hadoop doesn't allow this)\n+    } else {\n+      fprintf(ERRORFILE,\n+          \"ERROR: Unrecognized OCI config linux resources element: %s\\n\", e->string);\n+      all_sections_ok = false;\n+    }\n+  }\n+\n+  return all_sections_ok;\n+}\n+\n+static bool is_valid_oci_config_linux_seccomp(const cJSON* ocls) {\n+  // TODO: seccomp validation\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_linux(const cJSON* ocl) {\n+  if (!cJSON_IsObject(ocl)) {\n+    fputs(\"ERROR: OCI config linux section missing or not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool has_cgroup_path = false;\n+  bool all_sections_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, ocl) {\n+    if (strcmp(\"cgroupsPath\", e->string) == 0) {\n+      has_cgroup_path = true;\n+      if (!cJSON_IsString(e)) {\n+        all_sections_ok = false;\n+      }\n+    } else if (strcmp(\"resources\", e->string) == 0) {\n+      all_sections_ok &= is_valid_oci_config_linux_resources(e);\n+    } else if (strcmp(\"seccomp\", e->string) == 0) {\n+      all_sections_ok &= is_valid_oci_config_linux_seccomp(e);\n+    } else {\n+      fprintf(ERRORFILE, \"ERROR: Unrecognized OCI config linux element: %s\\n\",\n+          e->string);\n+      all_sections_ok = false;\n+    }\n+  }\n+\n+  return has_cgroup_path && all_sections_ok;\n+}\n+\n+static bool is_valid_mount_options(const cJSON* mo) {\n+  if (!cJSON_IsArray(mo)) {\n+    fputs(\"ERROR: OCI config mount options not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool has_rbind = false;\n+  bool has_rprivate = false;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, mo) {\n+    if (!cJSON_IsString(e)) {\n+      fputs(\"ERROR: OCI config mount option is not a string\\n\", ERRORFILE);\n+      return false;\n+    }\n+    if (strcmp(\"rbind\", e->valuestring) == 0) {\n+      has_rbind = true;\n+    } else if (strcmp(\"rprivate\", e->valuestring) == 0) {\n+      has_rprivate = true;\n+    }\n+  }\n+\n+  if (!has_rbind) {\n+    fputs(\"ERROR: OCI config mount options missing rbind\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (!has_rprivate) {\n+    fputs(\"ERROR: OCI config mount options missing rprivate\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_mount(const cJSON* mount) {\n+  if (!cJSON_IsObject(mount)) {\n+    fputs(\"ERROR: OCI config mount entry is not an object\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool has_type = false;\n+  bool has_options = false;\n+  char* source = NULL;\n+  char* destination = NULL;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, mount) {\n+    if (strcmp(\"type\", e->string) == 0) {\n+      if (!cJSON_IsString(e) || strcmp(\"bind\", e->valuestring)) {\n+        fputs(\"ERROR: OCI config mount is not bind type\\n\", ERRORFILE);\n+        return false;\n+      }\n+      has_type = true;\n+    } else if (strcmp(\"source\", e->string) == 0) {\n+      if (!cJSON_IsString(e)) {\n+        fputs(\"ERROR: OCI config mount source is not a string\\n\", ERRORFILE);\n+        return false;\n+      }\n+      source = e->valuestring;\n+    } else if (strcmp(\"destination\", e->string) == 0) {\n+      if (!cJSON_IsString(e)) {\n+        fputs(\"ERROR: OCI config mount destination is not a string\\n\", ERRORFILE);\n+        return false;\n+      }\n+      destination = e->valuestring;\n+    } else if (strcmp(\"options\", e->string) == 0) {\n+      if (!is_valid_mount_options(e)) {\n+        return false;\n+      }\n+      has_options = true;\n+    } else {\n+      fprintf(ERRORFILE, \"ERROR: Unrecognized OCI config mount parameter: %s\\n\",\n+          e->string);\n+      return false;\n+    }\n+  }\n+\n+  if (!has_type) {\n+    fputs(\"ERROR: OCI config mount missing mount type\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (!has_options) {\n+    fputs(\"ERROR: OCI config mount missing mount options\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (source == NULL) {\n+    fputs(\"ERROR: OCI config mount missing source\\n\", ERRORFILE);\n+    return false;\n+  }\n+  if (destination == NULL) {\n+    fputs(\"ERROR: OCI config mount missing destination\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  // TODO: Need to add mount source/dest whitelist checking here.\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config_mounts(const cJSON* ocm) {\n+  if (ocm == NULL) {\n+    return true;  // OK to have no extra mounts\n+  }\n+  if (!cJSON_IsArray(ocm)) {\n+    fputs(\"ERROR: OCI config mounts is not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool all_mounts_ok = true;\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, ocm) {\n+    all_mounts_ok &= is_valid_mount(e);\n+  }\n+\n+  return all_mounts_ok;\n+}\n+\n+static bool is_valid_oci_config_process(const oci_config_process* ocp) {\n+  if (ocp == NULL) {\n+    return false;\n+  }\n+\n+  if (!cJSON_IsArray(ocp->args)) {\n+    fputs(\"ERROR: OCI config process args is missing or not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  const cJSON* e;\n+  cJSON_ArrayForEach(e, ocp->args) {\n+    if (!cJSON_IsString(e)) {\n+      fputs(\"ERROR: OCI config process args has a non-string in array\\n\", ERRORFILE);\n+      return false;\n+    }\n+  }\n+\n+  if (!cJSON_IsString(ocp->cwd)) {\n+    fputs(\"ERROR: Bad/Missing OCI config process cwd\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (!cJSON_IsArray(ocp->env)) {\n+    fputs(\"ERROR: OCI config process env is missing or not an array\\n\", ERRORFILE);\n+    return false;\n+  }\n+  cJSON_ArrayForEach(e, ocp->env) {\n+    if (!cJSON_IsString(e)) {\n+      fputs(\"ERROR: OCI config process env has a non-string in array\\n\", ERRORFILE);\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+static bool is_valid_oci_config(const oci_config* oc) {\n+  bool is_valid = true;\n+  if (oc->hostname != NULL && !cJSON_IsString(oc->hostname)) {\n+    fputs(\"ERROR: OCI config hostname is not a string\\n\", ERRORFILE);\n+    is_valid = false;\n+  }\n+  is_valid &= is_valid_oci_config_linux(oc->linux_config);\n+  is_valid &= is_valid_oci_config_mounts(oc->mounts);\n+  is_valid &= is_valid_oci_config_process(&oc->process);\n+  return is_valid;\n+}\n+\n+static bool is_valid_oci_launch_cmd(const oci_launch_cmd* olc) {\n+  if (olc == NULL) {\n+    return false;\n+  }\n+\n+  if (olc->username == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing username\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (olc->container_id == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing container ID\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (!validate_container_id(olc->container_id)) {\n+    fprintf(ERRORFILE, \"ERROR: Bad container id in OCI command: %s\\n\",\n+        olc->container_id);\n+    return false;\n+  }\n+\n+  if (olc->pid_file == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing pid file\\n\", ERRORFILE);\n+    return false;\n+  }\n+  struct stat statbuf;\n+  if (stat(olc->pid_file, &statbuf) == 0) {\n+    fprintf(ERRORFILE, \"ERROR: pid file already exists: %s\\n\", olc->pid_file);\n+    return false;\n+  }\n+  if (errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error accessing %s : %s in is_valid_oci_launch_cmd\\n\", olc->pid_file,\n+        strerror(errno));\n+    return false;\n+  }\n+\n+  if (olc->script_path == NULL) {\n+    fputs(\"ERROR: OCI command has bad/missing container script path\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  if (!is_valid_oci_launch_cmd_layers(olc->layers, olc->num_layers)) {\n+    return false;\n+  }\n+\n+  if (olc->num_reap_layers_keep < 0) {\n+    fprintf(ERRORFILE, \"ERROR: Bad number of layers to preserve: %d\\n\",\n+        olc->num_reap_layers_keep);\n+    return false;\n+  }\n+\n+  return is_valid_oci_config(&olc->config);\n+}\n+\n+/**\n+ * Read, parse, and validate an OCI container launch command.\n+ *\n+ * Returns a pointer to the launch command or NULL on error.\n+ */\n+oci_launch_cmd* parse_oci_launch_cmd(const char* command_filename) {\n+  oci_launch_cmd* olc = NULL;\n+  cJSON* olc_json = NULL;\n+\n+  olc_json = parse_json_file(command_filename);\n+  if (olc_json == NULL) {\n+    goto cleanup;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU0NTYyOA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550545628", "bodyText": "error message", "author": "agresch", "createdAt": "2020-12-31T16:43:16Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU0Njk2NA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550546964", "bodyText": "error message", "author": "agresch", "createdAt": "2020-12-31T16:44:57Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU0Nzg4Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550547883", "bodyText": "error message", "author": "agresch", "createdAt": "2020-12-31T16:46:02Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1MDg1OQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550550859", "bodyText": "should this have an error message?", "author": "agresch", "createdAt": "2020-12-31T16:49:46Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;\n+  }\n+\n+  qsort(&dsa->stats[0], dsa->length, sizeof(*dsa->stats),\n+      compare_dent_stats_mtime);\n+\n+  bool result = false;\n+  size_t num_remain = dsa->length;\n+  if (num_remain <= num_preserve) {\n+    result = true;\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_write_lock(ctx)) {\n+    fputs(\"ERROR: Unable to acquire layer write lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+  size_t i;\n+  for (i = 0; i < dsa->length && num_remain > num_preserve; ++i) {\n+    char* layer_dir_path = get_oci_layer_path(ctx->run_root,\n+        dsa->stats[i].basename);\n+    if (layer_dir_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in do_reap_layer_mounts_with_lock\\n\", ERRORFILE);\n+      goto cleanup;\n+    }\n+    if (unmount_layer(layer_dir_path)) {\n+      --num_remain;\n+      printf(\"Unmounted layer %s\\n\", dsa->stats[i].basename);\n+    }\n+    free(layer_dir_path);\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_dent_stats(dsa);\n+  return result;\n+}\n+\n+/**\n+ * Determine if the specified loopback device is associated with a file that\n+ * has been deleted.\n+ *\n+ * Returns true if the loopback file is deleted or false otherwise or on error.\n+ */\n+bool is_loop_file_deleted(const char* loopdev) {\n+  bool result = false;\n+  FILE* f = NULL;\n+  char* path = NULL;\n+  char* linebuf = NULL;\n+\n+  // locate the numeric part of the loop device\n+  const char* loop_num_str = loopdev + DEV_LOOP_PREFIX_LEN;\n+\n+  if (asprintf(&path, \"/sys/devices/virtual/block/loop%s/loop/backing_file\",\n+      loop_num_str) == -1) {\n+    return false;\n+  }\n+\n+  f = fopen(path, \"r\");\n+  if (f == NULL) {\n+    goto cleanup;\n+  }\n+\n+  size_t linebuf_len = 0;\n+  ssize_t len = getline(&linebuf, &linebuf_len, f);\n+  if (len <= DELETED_SUFFIX_LEN) {\n+    goto cleanup;\n+  }\n+\n+  result = !strcmp(DELETED_SUFFIX, linebuf + len - DELETED_SUFFIX_LEN);\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(linebuf);\n+  free(path);\n+  return result;\n+}\n+\n+static bool copy_mntent(struct mntent* dest, const struct mntent* src) {\n+  memset(dest, 0, sizeof(*dest));\n+  if (src->mnt_fsname != NULL) {\n+    dest->mnt_fsname = strdup(src->mnt_fsname);\n+    if (dest->mnt_fsname == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_dir != NULL) {\n+    dest->mnt_dir = strdup(src->mnt_dir);\n+    if (dest->mnt_dir == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_type != NULL) {\n+    dest->mnt_type = strdup(src->mnt_type);\n+    if (dest->mnt_type == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_opts != NULL) {\n+    dest->mnt_opts = strdup(src->mnt_opts);\n+    if (dest->mnt_opts == NULL) {\n+      return false;\n+    }\n+  }\n+  dest->mnt_freq = src->mnt_freq;\n+  dest->mnt_passno = src->mnt_passno;\n+  return true;\n+}\n+\n+static void free_mntent_array(struct mntent* entries, size_t num_entries) {\n+  if (entries != NULL) {\n+    size_t i;\n+    for (i = 0; i < num_entries; ++i) {\n+      struct mntent* me = entries + i;\n+      free(me->mnt_fsname);\n+      free(me->mnt_dir);\n+      free(me->mnt_type);\n+      free(me->mnt_opts);\n+    }\n+    free(entries);\n+  }\n+}\n+\n+/**\n+ * Get the array of mount table entries that are layer mounts.\n+ *\n+ * Returns the heap-allocated array of mount entries or NULL on error.\n+ * The num_entries argument is updated to the number of elements in the array.\n+ */\n+static struct mntent* get_layer_mounts(size_t* num_entries_out,\n+    const char* layers_path) {\n+  const size_t layers_path_len = strlen(layers_path);\n+  char* read_buffer = NULL;\n+  FILE* f = NULL;\n+  const size_t num_entries_per_alloc = 8192;\n+  size_t num_entries = 0;\n+  size_t entries_capacity = num_entries_per_alloc;\n+  struct mntent* entries = malloc(sizeof(*entries) * entries_capacity);\n+  if (entries == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - malloc\\n\", ERRORFILE);\n+    goto fail;\n+  }\n+\n+  read_buffer = malloc(MOUNT_TABLE_BUFFER_SIZE);\n+  if (read_buffer == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to allocate read buffer of %d bytes\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  f = fopen(\"/proc/mounts\", \"r\");\n+  if (f == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open /proc/mounts : %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  if (setvbuf(f, read_buffer, _IOFBF, MOUNT_TABLE_BUFFER_SIZE) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to set mount table buffer to %d\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  struct mntent* me;\n+  while ((me = getmntent(f)) != NULL) {\n+    // Skip mounts that are not loopback mounts\n+    if (strncmp(me->mnt_fsname, DEV_LOOP_PREFIX, DEV_LOOP_PREFIX_LEN)) {\n+      continue;\n+    }\n+\n+    // skip destinations that are not under the layers mount area\n+    if (strncmp(layers_path, me->mnt_dir, layers_path_len)) {\n+      continue;\n+    }\n+\n+    if (num_entries == entries_capacity) {\n+      entries_capacity += num_entries_per_alloc;\n+      entries = realloc(entries, sizeof(*entries) * entries_capacity);\n+      if (entries == NULL) {\n+        fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - realloc\\n\", ERRORFILE);\n+        goto fail;\n+      }\n+    }\n+\n+    if (!copy_mntent(entries + num_entries, me)) {\n+      fputs(\"ERROR: Failed to copy_mntent\", ERRORFILE);\n+      goto fail;\n+    }\n+    ++num_entries;\n+  }\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(read_buffer);\n+  *num_entries_out = num_entries;\n+  return entries;\n+\n+fail:\n+  free_mntent_array(entries, num_entries);\n+  entries = NULL;\n+  num_entries = 0;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Search for layer mounts that correspond with deleted files and unmount them.\n+ */\n+static bool reap_deleted_mounts_with_lock(oci_base_ctx* ctx) {\n+  const char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_deleted_mounts_with_lock\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  size_t num_mnt_entries = 0;\n+  struct mntent* mnt_entries = get_layer_mounts(&num_mnt_entries, layers_path);\n+  if (mnt_entries == NULL) {\n+    fputs(\"ERROR: Error parsing mount table\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool have_write_lock = false;\n+  size_t i;\n+  for (i = 0; i < num_mnt_entries; ++i) {\n+    const struct mntent* me = mnt_entries + i;\n+    if (is_loop_file_deleted(me->mnt_fsname)) {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(ctx)) {\n+          goto cleanup;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1MTU5NQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550551595", "bodyText": "should we have error message if rc != 0?", "author": "agresch", "createdAt": "2020-12-31T16:50:39Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;\n+  }\n+\n+  qsort(&dsa->stats[0], dsa->length, sizeof(*dsa->stats),\n+      compare_dent_stats_mtime);\n+\n+  bool result = false;\n+  size_t num_remain = dsa->length;\n+  if (num_remain <= num_preserve) {\n+    result = true;\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_write_lock(ctx)) {\n+    fputs(\"ERROR: Unable to acquire layer write lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+  size_t i;\n+  for (i = 0; i < dsa->length && num_remain > num_preserve; ++i) {\n+    char* layer_dir_path = get_oci_layer_path(ctx->run_root,\n+        dsa->stats[i].basename);\n+    if (layer_dir_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in do_reap_layer_mounts_with_lock\\n\", ERRORFILE);\n+      goto cleanup;\n+    }\n+    if (unmount_layer(layer_dir_path)) {\n+      --num_remain;\n+      printf(\"Unmounted layer %s\\n\", dsa->stats[i].basename);\n+    }\n+    free(layer_dir_path);\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_dent_stats(dsa);\n+  return result;\n+}\n+\n+/**\n+ * Determine if the specified loopback device is associated with a file that\n+ * has been deleted.\n+ *\n+ * Returns true if the loopback file is deleted or false otherwise or on error.\n+ */\n+bool is_loop_file_deleted(const char* loopdev) {\n+  bool result = false;\n+  FILE* f = NULL;\n+  char* path = NULL;\n+  char* linebuf = NULL;\n+\n+  // locate the numeric part of the loop device\n+  const char* loop_num_str = loopdev + DEV_LOOP_PREFIX_LEN;\n+\n+  if (asprintf(&path, \"/sys/devices/virtual/block/loop%s/loop/backing_file\",\n+      loop_num_str) == -1) {\n+    return false;\n+  }\n+\n+  f = fopen(path, \"r\");\n+  if (f == NULL) {\n+    goto cleanup;\n+  }\n+\n+  size_t linebuf_len = 0;\n+  ssize_t len = getline(&linebuf, &linebuf_len, f);\n+  if (len <= DELETED_SUFFIX_LEN) {\n+    goto cleanup;\n+  }\n+\n+  result = !strcmp(DELETED_SUFFIX, linebuf + len - DELETED_SUFFIX_LEN);\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(linebuf);\n+  free(path);\n+  return result;\n+}\n+\n+static bool copy_mntent(struct mntent* dest, const struct mntent* src) {\n+  memset(dest, 0, sizeof(*dest));\n+  if (src->mnt_fsname != NULL) {\n+    dest->mnt_fsname = strdup(src->mnt_fsname);\n+    if (dest->mnt_fsname == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_dir != NULL) {\n+    dest->mnt_dir = strdup(src->mnt_dir);\n+    if (dest->mnt_dir == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_type != NULL) {\n+    dest->mnt_type = strdup(src->mnt_type);\n+    if (dest->mnt_type == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_opts != NULL) {\n+    dest->mnt_opts = strdup(src->mnt_opts);\n+    if (dest->mnt_opts == NULL) {\n+      return false;\n+    }\n+  }\n+  dest->mnt_freq = src->mnt_freq;\n+  dest->mnt_passno = src->mnt_passno;\n+  return true;\n+}\n+\n+static void free_mntent_array(struct mntent* entries, size_t num_entries) {\n+  if (entries != NULL) {\n+    size_t i;\n+    for (i = 0; i < num_entries; ++i) {\n+      struct mntent* me = entries + i;\n+      free(me->mnt_fsname);\n+      free(me->mnt_dir);\n+      free(me->mnt_type);\n+      free(me->mnt_opts);\n+    }\n+    free(entries);\n+  }\n+}\n+\n+/**\n+ * Get the array of mount table entries that are layer mounts.\n+ *\n+ * Returns the heap-allocated array of mount entries or NULL on error.\n+ * The num_entries argument is updated to the number of elements in the array.\n+ */\n+static struct mntent* get_layer_mounts(size_t* num_entries_out,\n+    const char* layers_path) {\n+  const size_t layers_path_len = strlen(layers_path);\n+  char* read_buffer = NULL;\n+  FILE* f = NULL;\n+  const size_t num_entries_per_alloc = 8192;\n+  size_t num_entries = 0;\n+  size_t entries_capacity = num_entries_per_alloc;\n+  struct mntent* entries = malloc(sizeof(*entries) * entries_capacity);\n+  if (entries == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - malloc\\n\", ERRORFILE);\n+    goto fail;\n+  }\n+\n+  read_buffer = malloc(MOUNT_TABLE_BUFFER_SIZE);\n+  if (read_buffer == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to allocate read buffer of %d bytes\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  f = fopen(\"/proc/mounts\", \"r\");\n+  if (f == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open /proc/mounts : %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  if (setvbuf(f, read_buffer, _IOFBF, MOUNT_TABLE_BUFFER_SIZE) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to set mount table buffer to %d\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  struct mntent* me;\n+  while ((me = getmntent(f)) != NULL) {\n+    // Skip mounts that are not loopback mounts\n+    if (strncmp(me->mnt_fsname, DEV_LOOP_PREFIX, DEV_LOOP_PREFIX_LEN)) {\n+      continue;\n+    }\n+\n+    // skip destinations that are not under the layers mount area\n+    if (strncmp(layers_path, me->mnt_dir, layers_path_len)) {\n+      continue;\n+    }\n+\n+    if (num_entries == entries_capacity) {\n+      entries_capacity += num_entries_per_alloc;\n+      entries = realloc(entries, sizeof(*entries) * entries_capacity);\n+      if (entries == NULL) {\n+        fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - realloc\\n\", ERRORFILE);\n+        goto fail;\n+      }\n+    }\n+\n+    if (!copy_mntent(entries + num_entries, me)) {\n+      fputs(\"ERROR: Failed to copy_mntent\", ERRORFILE);\n+      goto fail;\n+    }\n+    ++num_entries;\n+  }\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(read_buffer);\n+  *num_entries_out = num_entries;\n+  return entries;\n+\n+fail:\n+  free_mntent_array(entries, num_entries);\n+  entries = NULL;\n+  num_entries = 0;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Search for layer mounts that correspond with deleted files and unmount them.\n+ */\n+static bool reap_deleted_mounts_with_lock(oci_base_ctx* ctx) {\n+  const char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_deleted_mounts_with_lock\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  size_t num_mnt_entries = 0;\n+  struct mntent* mnt_entries = get_layer_mounts(&num_mnt_entries, layers_path);\n+  if (mnt_entries == NULL) {\n+    fputs(\"ERROR: Error parsing mount table\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool have_write_lock = false;\n+  size_t i;\n+  for (i = 0; i < num_mnt_entries; ++i) {\n+    const struct mntent* me = mnt_entries + i;\n+    if (is_loop_file_deleted(me->mnt_fsname)) {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(ctx)) {\n+          goto cleanup;\n+        }\n+        have_write_lock = true;\n+      }\n+\n+      char* layer_dir = get_oci_layer_path_from_mount_path(me->mnt_dir);\n+      if (layer_dir != NULL) {\n+        if (unmount_layer(layer_dir)) {\n+          printf(\"Unmounted layer %s (deleted)\\n\", basename(layer_dir));\n+        }\n+        free(layer_dir);\n+      }\n+    }\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_mntent_array(mnt_entries, num_mnt_entries);\n+  return result;\n+}\n+\n+/**\n+ * Equivalent to reap_oci_layer_mounts but avoids the need to re-create the\n+ * OCI base context.\n+ */\n+int reap_oci_layer_mounts_with_ctx(oci_base_ctx* ctx, int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  int layers_fd = -1;\n+  char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_oci_layer_mounts_with_ctx\\n\", ERRORFILE);\n+    rc = OUT_OF_MEMORY;\n+    goto cleanup;\n+  }\n+\n+  layers_fd = open(layers_path, O_RDONLY | O_NOFOLLOW);\n+  if (layers_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open layers directory at %s : %s\\n\",\n+        layers_path, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_read_lock(ctx)) {\n+    fputs(\"ERROR: Unable to obtain layer lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool reap_deleted_ok = reap_deleted_mounts_with_lock(ctx);\n+  bool reap_layers_ok = do_reap_layer_mounts_with_lock(ctx, layers_fd,\n+      num_preserve);\n+  if (reap_deleted_ok && reap_layers_ok) {\n+    rc = 0;\n+  }", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1MzMyOA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550553328", "bodyText": "should this have an error message?", "author": "agresch", "createdAt": "2020-12-31T16:52:43Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;\n+  }\n+\n+  qsort(&dsa->stats[0], dsa->length, sizeof(*dsa->stats),\n+      compare_dent_stats_mtime);\n+\n+  bool result = false;\n+  size_t num_remain = dsa->length;\n+  if (num_remain <= num_preserve) {\n+    result = true;\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_write_lock(ctx)) {\n+    fputs(\"ERROR: Unable to acquire layer write lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+  size_t i;\n+  for (i = 0; i < dsa->length && num_remain > num_preserve; ++i) {\n+    char* layer_dir_path = get_oci_layer_path(ctx->run_root,\n+        dsa->stats[i].basename);\n+    if (layer_dir_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in do_reap_layer_mounts_with_lock\\n\", ERRORFILE);\n+      goto cleanup;\n+    }\n+    if (unmount_layer(layer_dir_path)) {\n+      --num_remain;\n+      printf(\"Unmounted layer %s\\n\", dsa->stats[i].basename);\n+    }\n+    free(layer_dir_path);\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_dent_stats(dsa);\n+  return result;\n+}\n+\n+/**\n+ * Determine if the specified loopback device is associated with a file that\n+ * has been deleted.\n+ *\n+ * Returns true if the loopback file is deleted or false otherwise or on error.\n+ */\n+bool is_loop_file_deleted(const char* loopdev) {\n+  bool result = false;\n+  FILE* f = NULL;\n+  char* path = NULL;\n+  char* linebuf = NULL;\n+\n+  // locate the numeric part of the loop device\n+  const char* loop_num_str = loopdev + DEV_LOOP_PREFIX_LEN;\n+\n+  if (asprintf(&path, \"/sys/devices/virtual/block/loop%s/loop/backing_file\",\n+      loop_num_str) == -1) {\n+    return false;\n+  }\n+\n+  f = fopen(path, \"r\");\n+  if (f == NULL) {\n+    goto cleanup;\n+  }\n+\n+  size_t linebuf_len = 0;\n+  ssize_t len = getline(&linebuf, &linebuf_len, f);\n+  if (len <= DELETED_SUFFIX_LEN) {\n+    goto cleanup;\n+  }\n+\n+  result = !strcmp(DELETED_SUFFIX, linebuf + len - DELETED_SUFFIX_LEN);\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(linebuf);\n+  free(path);\n+  return result;\n+}\n+\n+static bool copy_mntent(struct mntent* dest, const struct mntent* src) {\n+  memset(dest, 0, sizeof(*dest));\n+  if (src->mnt_fsname != NULL) {\n+    dest->mnt_fsname = strdup(src->mnt_fsname);\n+    if (dest->mnt_fsname == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_dir != NULL) {\n+    dest->mnt_dir = strdup(src->mnt_dir);\n+    if (dest->mnt_dir == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_type != NULL) {\n+    dest->mnt_type = strdup(src->mnt_type);\n+    if (dest->mnt_type == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_opts != NULL) {\n+    dest->mnt_opts = strdup(src->mnt_opts);\n+    if (dest->mnt_opts == NULL) {\n+      return false;\n+    }\n+  }\n+  dest->mnt_freq = src->mnt_freq;\n+  dest->mnt_passno = src->mnt_passno;\n+  return true;\n+}\n+\n+static void free_mntent_array(struct mntent* entries, size_t num_entries) {\n+  if (entries != NULL) {\n+    size_t i;\n+    for (i = 0; i < num_entries; ++i) {\n+      struct mntent* me = entries + i;\n+      free(me->mnt_fsname);\n+      free(me->mnt_dir);\n+      free(me->mnt_type);\n+      free(me->mnt_opts);\n+    }\n+    free(entries);\n+  }\n+}\n+\n+/**\n+ * Get the array of mount table entries that are layer mounts.\n+ *\n+ * Returns the heap-allocated array of mount entries or NULL on error.\n+ * The num_entries argument is updated to the number of elements in the array.\n+ */\n+static struct mntent* get_layer_mounts(size_t* num_entries_out,\n+    const char* layers_path) {\n+  const size_t layers_path_len = strlen(layers_path);\n+  char* read_buffer = NULL;\n+  FILE* f = NULL;\n+  const size_t num_entries_per_alloc = 8192;\n+  size_t num_entries = 0;\n+  size_t entries_capacity = num_entries_per_alloc;\n+  struct mntent* entries = malloc(sizeof(*entries) * entries_capacity);\n+  if (entries == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - malloc\\n\", ERRORFILE);\n+    goto fail;\n+  }\n+\n+  read_buffer = malloc(MOUNT_TABLE_BUFFER_SIZE);\n+  if (read_buffer == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to allocate read buffer of %d bytes\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  f = fopen(\"/proc/mounts\", \"r\");\n+  if (f == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open /proc/mounts : %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  if (setvbuf(f, read_buffer, _IOFBF, MOUNT_TABLE_BUFFER_SIZE) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to set mount table buffer to %d\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  struct mntent* me;\n+  while ((me = getmntent(f)) != NULL) {\n+    // Skip mounts that are not loopback mounts\n+    if (strncmp(me->mnt_fsname, DEV_LOOP_PREFIX, DEV_LOOP_PREFIX_LEN)) {\n+      continue;\n+    }\n+\n+    // skip destinations that are not under the layers mount area\n+    if (strncmp(layers_path, me->mnt_dir, layers_path_len)) {\n+      continue;\n+    }\n+\n+    if (num_entries == entries_capacity) {\n+      entries_capacity += num_entries_per_alloc;\n+      entries = realloc(entries, sizeof(*entries) * entries_capacity);\n+      if (entries == NULL) {\n+        fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - realloc\\n\", ERRORFILE);\n+        goto fail;\n+      }\n+    }\n+\n+    if (!copy_mntent(entries + num_entries, me)) {\n+      fputs(\"ERROR: Failed to copy_mntent\", ERRORFILE);\n+      goto fail;\n+    }\n+    ++num_entries;\n+  }\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(read_buffer);\n+  *num_entries_out = num_entries;\n+  return entries;\n+\n+fail:\n+  free_mntent_array(entries, num_entries);\n+  entries = NULL;\n+  num_entries = 0;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Search for layer mounts that correspond with deleted files and unmount them.\n+ */\n+static bool reap_deleted_mounts_with_lock(oci_base_ctx* ctx) {\n+  const char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_deleted_mounts_with_lock\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  size_t num_mnt_entries = 0;\n+  struct mntent* mnt_entries = get_layer_mounts(&num_mnt_entries, layers_path);\n+  if (mnt_entries == NULL) {\n+    fputs(\"ERROR: Error parsing mount table\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool have_write_lock = false;\n+  size_t i;\n+  for (i = 0; i < num_mnt_entries; ++i) {\n+    const struct mntent* me = mnt_entries + i;\n+    if (is_loop_file_deleted(me->mnt_fsname)) {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(ctx)) {\n+          goto cleanup;\n+        }\n+        have_write_lock = true;\n+      }\n+\n+      char* layer_dir = get_oci_layer_path_from_mount_path(me->mnt_dir);\n+      if (layer_dir != NULL) {\n+        if (unmount_layer(layer_dir)) {\n+          printf(\"Unmounted layer %s (deleted)\\n\", basename(layer_dir));\n+        }\n+        free(layer_dir);\n+      }\n+    }\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_mntent_array(mnt_entries, num_mnt_entries);\n+  return result;\n+}\n+\n+/**\n+ * Equivalent to reap_oci_layer_mounts but avoids the need to re-create the\n+ * OCI base context.\n+ */\n+int reap_oci_layer_mounts_with_ctx(oci_base_ctx* ctx, int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  int layers_fd = -1;\n+  char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_oci_layer_mounts_with_ctx\\n\", ERRORFILE);\n+    rc = OUT_OF_MEMORY;\n+    goto cleanup;\n+  }\n+\n+  layers_fd = open(layers_path, O_RDONLY | O_NOFOLLOW);\n+  if (layers_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open layers directory at %s : %s\\n\",\n+        layers_path, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_read_lock(ctx)) {\n+    fputs(\"ERROR: Unable to obtain layer lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool reap_deleted_ok = reap_deleted_mounts_with_lock(ctx);\n+  bool reap_layers_ok = do_reap_layer_mounts_with_lock(ctx, layers_fd,\n+      num_preserve);\n+  if (reap_deleted_ok && reap_layers_ok) {\n+    rc = 0;\n+  }\n+\n+  release_oci_layers_lock(ctx);\n+\n+cleanup:\n+  if (layers_fd != -1) {\n+    close(layers_fd);\n+  }\n+  free(layers_path);\n+  return rc;\n+}\n+\n+/**\n+ * Attempt to trim the number of layer mounts to the specified target number to\n+ * preserve. Layers are unmounted in a least-recently-used fashion. Layers that\n+ * are still in use by containers are preserved, so the number of layers mounts\n+ * after trimming may exceed the target number.\n+ *\n+ * Returns 0 on success or a non-zero error code on failure.\n+ */\n+int reap_oci_layer_mounts(int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  oci_base_ctx* ctx = setup_oci_base_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Failed to setup_oci_base_ctx\", ERRORFILE);\n+    return rc;\n+  }\n+\n+  rc = reap_oci_layer_mounts_with_ctx(ctx, num_preserve);\n+  free_oci_base_ctx(ctx);\n+  return rc;\n+}\n+\n+int cleanup_oci_container_by_id(const char* container_id, int num_reap_layers_keep) {\n+  char* run_root = get_value(OCI_RUN_ROOT_CONFIG_KEY);\n+  int rc = 0;\n+  if (run_root == NULL) {\n+    run_root = strdup(DEFAULT_OCI_RUN_ROOT);\n+    if (run_root == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - strdup\", ERRORFILE);\n+      goto mem_fail;\n+    }\n+  }\n+\n+  oci_overlay_desc* desc = malloc(sizeof(oci_overlay_desc));\n+  if (desc == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - malloc\", ERRORFILE);\n+    goto mem_fail;\n+  }\n+  init_oci_overlay_desc(desc);\n+  if (!init_overlay_descriptor(desc, run_root, container_id)) {\n+      fputs(\"ERROR: init_overlay_descriptor Failed\\n\", ERRORFILE);\n+      goto mem_fail;\n+  }\n+  rc = cleanup_oci_container(container_id, desc->mount_path, desc->top_path, NULL, num_reap_layers_keep);\n+\n+cleanup:\n+  free(run_root);\n+  destroy_oci_overlay_desc(desc);\n+  free(desc);\n+  return rc;\n+\n+mem_fail:\n+  rc = OUT_OF_MEMORY;\n+  goto cleanup;\n+}\n+\n+char* get_next_word(char* line, int* start_index) {\n+    int temp = *start_index;\n+    while (line[*start_index] != ' ') {\n+        *start_index  += 1;\n+    }\n+    char* word = malloc(sizeof(char) * (*start_index - temp + 1));\n+    int i=0;\n+    while (temp < *(start_index)) {\n+        word[i++]  = line[temp++];\n+    }\n+    word[i] = '\\0';\n+\n+    while (line[*start_index] == ' ') {\n+            *start_index += 1;\n+    }\n+\n+    return word;\n+}\n+\n+static bool unmount_and_remove(const char* path) {\n+  if (umount(path) == -1 && errno != EINVAL && errno != ENOENT) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      return false;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1NDMwOA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550554308", "bodyText": "is it expected to need retries?  What are the cases?  Should we expose configuration to adjust?", "author": "agresch", "createdAt": "2020-12-31T16:53:54Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;\n+  }\n+\n+  qsort(&dsa->stats[0], dsa->length, sizeof(*dsa->stats),\n+      compare_dent_stats_mtime);\n+\n+  bool result = false;\n+  size_t num_remain = dsa->length;\n+  if (num_remain <= num_preserve) {\n+    result = true;\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_write_lock(ctx)) {\n+    fputs(\"ERROR: Unable to acquire layer write lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+  size_t i;\n+  for (i = 0; i < dsa->length && num_remain > num_preserve; ++i) {\n+    char* layer_dir_path = get_oci_layer_path(ctx->run_root,\n+        dsa->stats[i].basename);\n+    if (layer_dir_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in do_reap_layer_mounts_with_lock\\n\", ERRORFILE);\n+      goto cleanup;\n+    }\n+    if (unmount_layer(layer_dir_path)) {\n+      --num_remain;\n+      printf(\"Unmounted layer %s\\n\", dsa->stats[i].basename);\n+    }\n+    free(layer_dir_path);\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_dent_stats(dsa);\n+  return result;\n+}\n+\n+/**\n+ * Determine if the specified loopback device is associated with a file that\n+ * has been deleted.\n+ *\n+ * Returns true if the loopback file is deleted or false otherwise or on error.\n+ */\n+bool is_loop_file_deleted(const char* loopdev) {\n+  bool result = false;\n+  FILE* f = NULL;\n+  char* path = NULL;\n+  char* linebuf = NULL;\n+\n+  // locate the numeric part of the loop device\n+  const char* loop_num_str = loopdev + DEV_LOOP_PREFIX_LEN;\n+\n+  if (asprintf(&path, \"/sys/devices/virtual/block/loop%s/loop/backing_file\",\n+      loop_num_str) == -1) {\n+    return false;\n+  }\n+\n+  f = fopen(path, \"r\");\n+  if (f == NULL) {\n+    goto cleanup;\n+  }\n+\n+  size_t linebuf_len = 0;\n+  ssize_t len = getline(&linebuf, &linebuf_len, f);\n+  if (len <= DELETED_SUFFIX_LEN) {\n+    goto cleanup;\n+  }\n+\n+  result = !strcmp(DELETED_SUFFIX, linebuf + len - DELETED_SUFFIX_LEN);\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(linebuf);\n+  free(path);\n+  return result;\n+}\n+\n+static bool copy_mntent(struct mntent* dest, const struct mntent* src) {\n+  memset(dest, 0, sizeof(*dest));\n+  if (src->mnt_fsname != NULL) {\n+    dest->mnt_fsname = strdup(src->mnt_fsname);\n+    if (dest->mnt_fsname == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_dir != NULL) {\n+    dest->mnt_dir = strdup(src->mnt_dir);\n+    if (dest->mnt_dir == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_type != NULL) {\n+    dest->mnt_type = strdup(src->mnt_type);\n+    if (dest->mnt_type == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_opts != NULL) {\n+    dest->mnt_opts = strdup(src->mnt_opts);\n+    if (dest->mnt_opts == NULL) {\n+      return false;\n+    }\n+  }\n+  dest->mnt_freq = src->mnt_freq;\n+  dest->mnt_passno = src->mnt_passno;\n+  return true;\n+}\n+\n+static void free_mntent_array(struct mntent* entries, size_t num_entries) {\n+  if (entries != NULL) {\n+    size_t i;\n+    for (i = 0; i < num_entries; ++i) {\n+      struct mntent* me = entries + i;\n+      free(me->mnt_fsname);\n+      free(me->mnt_dir);\n+      free(me->mnt_type);\n+      free(me->mnt_opts);\n+    }\n+    free(entries);\n+  }\n+}\n+\n+/**\n+ * Get the array of mount table entries that are layer mounts.\n+ *\n+ * Returns the heap-allocated array of mount entries or NULL on error.\n+ * The num_entries argument is updated to the number of elements in the array.\n+ */\n+static struct mntent* get_layer_mounts(size_t* num_entries_out,\n+    const char* layers_path) {\n+  const size_t layers_path_len = strlen(layers_path);\n+  char* read_buffer = NULL;\n+  FILE* f = NULL;\n+  const size_t num_entries_per_alloc = 8192;\n+  size_t num_entries = 0;\n+  size_t entries_capacity = num_entries_per_alloc;\n+  struct mntent* entries = malloc(sizeof(*entries) * entries_capacity);\n+  if (entries == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - malloc\\n\", ERRORFILE);\n+    goto fail;\n+  }\n+\n+  read_buffer = malloc(MOUNT_TABLE_BUFFER_SIZE);\n+  if (read_buffer == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to allocate read buffer of %d bytes\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  f = fopen(\"/proc/mounts\", \"r\");\n+  if (f == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open /proc/mounts : %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  if (setvbuf(f, read_buffer, _IOFBF, MOUNT_TABLE_BUFFER_SIZE) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to set mount table buffer to %d\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  struct mntent* me;\n+  while ((me = getmntent(f)) != NULL) {\n+    // Skip mounts that are not loopback mounts\n+    if (strncmp(me->mnt_fsname, DEV_LOOP_PREFIX, DEV_LOOP_PREFIX_LEN)) {\n+      continue;\n+    }\n+\n+    // skip destinations that are not under the layers mount area\n+    if (strncmp(layers_path, me->mnt_dir, layers_path_len)) {\n+      continue;\n+    }\n+\n+    if (num_entries == entries_capacity) {\n+      entries_capacity += num_entries_per_alloc;\n+      entries = realloc(entries, sizeof(*entries) * entries_capacity);\n+      if (entries == NULL) {\n+        fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - realloc\\n\", ERRORFILE);\n+        goto fail;\n+      }\n+    }\n+\n+    if (!copy_mntent(entries + num_entries, me)) {\n+      fputs(\"ERROR: Failed to copy_mntent\", ERRORFILE);\n+      goto fail;\n+    }\n+    ++num_entries;\n+  }\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(read_buffer);\n+  *num_entries_out = num_entries;\n+  return entries;\n+\n+fail:\n+  free_mntent_array(entries, num_entries);\n+  entries = NULL;\n+  num_entries = 0;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Search for layer mounts that correspond with deleted files and unmount them.\n+ */\n+static bool reap_deleted_mounts_with_lock(oci_base_ctx* ctx) {\n+  const char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_deleted_mounts_with_lock\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  size_t num_mnt_entries = 0;\n+  struct mntent* mnt_entries = get_layer_mounts(&num_mnt_entries, layers_path);\n+  if (mnt_entries == NULL) {\n+    fputs(\"ERROR: Error parsing mount table\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool have_write_lock = false;\n+  size_t i;\n+  for (i = 0; i < num_mnt_entries; ++i) {\n+    const struct mntent* me = mnt_entries + i;\n+    if (is_loop_file_deleted(me->mnt_fsname)) {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(ctx)) {\n+          goto cleanup;\n+        }\n+        have_write_lock = true;\n+      }\n+\n+      char* layer_dir = get_oci_layer_path_from_mount_path(me->mnt_dir);\n+      if (layer_dir != NULL) {\n+        if (unmount_layer(layer_dir)) {\n+          printf(\"Unmounted layer %s (deleted)\\n\", basename(layer_dir));\n+        }\n+        free(layer_dir);\n+      }\n+    }\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_mntent_array(mnt_entries, num_mnt_entries);\n+  return result;\n+}\n+\n+/**\n+ * Equivalent to reap_oci_layer_mounts but avoids the need to re-create the\n+ * OCI base context.\n+ */\n+int reap_oci_layer_mounts_with_ctx(oci_base_ctx* ctx, int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  int layers_fd = -1;\n+  char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_oci_layer_mounts_with_ctx\\n\", ERRORFILE);\n+    rc = OUT_OF_MEMORY;\n+    goto cleanup;\n+  }\n+\n+  layers_fd = open(layers_path, O_RDONLY | O_NOFOLLOW);\n+  if (layers_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open layers directory at %s : %s\\n\",\n+        layers_path, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_read_lock(ctx)) {\n+    fputs(\"ERROR: Unable to obtain layer lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool reap_deleted_ok = reap_deleted_mounts_with_lock(ctx);\n+  bool reap_layers_ok = do_reap_layer_mounts_with_lock(ctx, layers_fd,\n+      num_preserve);\n+  if (reap_deleted_ok && reap_layers_ok) {\n+    rc = 0;\n+  }\n+\n+  release_oci_layers_lock(ctx);\n+\n+cleanup:\n+  if (layers_fd != -1) {\n+    close(layers_fd);\n+  }\n+  free(layers_path);\n+  return rc;\n+}\n+\n+/**\n+ * Attempt to trim the number of layer mounts to the specified target number to\n+ * preserve. Layers are unmounted in a least-recently-used fashion. Layers that\n+ * are still in use by containers are preserved, so the number of layers mounts\n+ * after trimming may exceed the target number.\n+ *\n+ * Returns 0 on success or a non-zero error code on failure.\n+ */\n+int reap_oci_layer_mounts(int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  oci_base_ctx* ctx = setup_oci_base_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Failed to setup_oci_base_ctx\", ERRORFILE);\n+    return rc;\n+  }\n+\n+  rc = reap_oci_layer_mounts_with_ctx(ctx, num_preserve);\n+  free_oci_base_ctx(ctx);\n+  return rc;\n+}\n+\n+int cleanup_oci_container_by_id(const char* container_id, int num_reap_layers_keep) {\n+  char* run_root = get_value(OCI_RUN_ROOT_CONFIG_KEY);\n+  int rc = 0;\n+  if (run_root == NULL) {\n+    run_root = strdup(DEFAULT_OCI_RUN_ROOT);\n+    if (run_root == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - strdup\", ERRORFILE);\n+      goto mem_fail;\n+    }\n+  }\n+\n+  oci_overlay_desc* desc = malloc(sizeof(oci_overlay_desc));\n+  if (desc == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - malloc\", ERRORFILE);\n+    goto mem_fail;\n+  }\n+  init_oci_overlay_desc(desc);\n+  if (!init_overlay_descriptor(desc, run_root, container_id)) {\n+      fputs(\"ERROR: init_overlay_descriptor Failed\\n\", ERRORFILE);\n+      goto mem_fail;\n+  }\n+  rc = cleanup_oci_container(container_id, desc->mount_path, desc->top_path, NULL, num_reap_layers_keep);\n+\n+cleanup:\n+  free(run_root);\n+  destroy_oci_overlay_desc(desc);\n+  free(desc);\n+  return rc;\n+\n+mem_fail:\n+  rc = OUT_OF_MEMORY;\n+  goto cleanup;\n+}\n+\n+char* get_next_word(char* line, int* start_index) {\n+    int temp = *start_index;\n+    while (line[*start_index] != ' ') {\n+        *start_index  += 1;\n+    }\n+    char* word = malloc(sizeof(char) * (*start_index - temp + 1));\n+    int i=0;\n+    while (temp < *(start_index)) {\n+        word[i++]  = line[temp++];\n+    }\n+    word[i] = '\\0';\n+\n+    while (line[*start_index] == ' ') {\n+            *start_index += 1;\n+    }\n+\n+    return word;\n+}\n+\n+static bool unmount_and_remove(const char* path) {\n+  if (umount(path) == -1 && errno != EINVAL && errno != ENOENT) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      return false;\n+    }\n+    fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s in unmount_and_remove \\n\", path, strerror(errno));\n+    return false;\n+  }\n+  if (rmdir(path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing mount directory %s : %s\\n\", path,\n+        strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool unmount_and_remove_with_retry(const char* path, int max_attempts,", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1NTYyNw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550555627", "bodyText": "error message", "author": "agresch", "createdAt": "2020-12-31T16:55:33Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;\n+  }\n+\n+  qsort(&dsa->stats[0], dsa->length, sizeof(*dsa->stats),\n+      compare_dent_stats_mtime);\n+\n+  bool result = false;\n+  size_t num_remain = dsa->length;\n+  if (num_remain <= num_preserve) {\n+    result = true;\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_write_lock(ctx)) {\n+    fputs(\"ERROR: Unable to acquire layer write lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+  size_t i;\n+  for (i = 0; i < dsa->length && num_remain > num_preserve; ++i) {\n+    char* layer_dir_path = get_oci_layer_path(ctx->run_root,\n+        dsa->stats[i].basename);\n+    if (layer_dir_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in do_reap_layer_mounts_with_lock\\n\", ERRORFILE);\n+      goto cleanup;\n+    }\n+    if (unmount_layer(layer_dir_path)) {\n+      --num_remain;\n+      printf(\"Unmounted layer %s\\n\", dsa->stats[i].basename);\n+    }\n+    free(layer_dir_path);\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_dent_stats(dsa);\n+  return result;\n+}\n+\n+/**\n+ * Determine if the specified loopback device is associated with a file that\n+ * has been deleted.\n+ *\n+ * Returns true if the loopback file is deleted or false otherwise or on error.\n+ */\n+bool is_loop_file_deleted(const char* loopdev) {\n+  bool result = false;\n+  FILE* f = NULL;\n+  char* path = NULL;\n+  char* linebuf = NULL;\n+\n+  // locate the numeric part of the loop device\n+  const char* loop_num_str = loopdev + DEV_LOOP_PREFIX_LEN;\n+\n+  if (asprintf(&path, \"/sys/devices/virtual/block/loop%s/loop/backing_file\",\n+      loop_num_str) == -1) {\n+    return false;\n+  }\n+\n+  f = fopen(path, \"r\");\n+  if (f == NULL) {\n+    goto cleanup;\n+  }\n+\n+  size_t linebuf_len = 0;\n+  ssize_t len = getline(&linebuf, &linebuf_len, f);\n+  if (len <= DELETED_SUFFIX_LEN) {\n+    goto cleanup;\n+  }\n+\n+  result = !strcmp(DELETED_SUFFIX, linebuf + len - DELETED_SUFFIX_LEN);\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(linebuf);\n+  free(path);\n+  return result;\n+}\n+\n+static bool copy_mntent(struct mntent* dest, const struct mntent* src) {\n+  memset(dest, 0, sizeof(*dest));\n+  if (src->mnt_fsname != NULL) {\n+    dest->mnt_fsname = strdup(src->mnt_fsname);\n+    if (dest->mnt_fsname == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_dir != NULL) {\n+    dest->mnt_dir = strdup(src->mnt_dir);\n+    if (dest->mnt_dir == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_type != NULL) {\n+    dest->mnt_type = strdup(src->mnt_type);\n+    if (dest->mnt_type == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_opts != NULL) {\n+    dest->mnt_opts = strdup(src->mnt_opts);\n+    if (dest->mnt_opts == NULL) {\n+      return false;\n+    }\n+  }\n+  dest->mnt_freq = src->mnt_freq;\n+  dest->mnt_passno = src->mnt_passno;\n+  return true;\n+}\n+\n+static void free_mntent_array(struct mntent* entries, size_t num_entries) {\n+  if (entries != NULL) {\n+    size_t i;\n+    for (i = 0; i < num_entries; ++i) {\n+      struct mntent* me = entries + i;\n+      free(me->mnt_fsname);\n+      free(me->mnt_dir);\n+      free(me->mnt_type);\n+      free(me->mnt_opts);\n+    }\n+    free(entries);\n+  }\n+}\n+\n+/**\n+ * Get the array of mount table entries that are layer mounts.\n+ *\n+ * Returns the heap-allocated array of mount entries or NULL on error.\n+ * The num_entries argument is updated to the number of elements in the array.\n+ */\n+static struct mntent* get_layer_mounts(size_t* num_entries_out,\n+    const char* layers_path) {\n+  const size_t layers_path_len = strlen(layers_path);\n+  char* read_buffer = NULL;\n+  FILE* f = NULL;\n+  const size_t num_entries_per_alloc = 8192;\n+  size_t num_entries = 0;\n+  size_t entries_capacity = num_entries_per_alloc;\n+  struct mntent* entries = malloc(sizeof(*entries) * entries_capacity);\n+  if (entries == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - malloc\\n\", ERRORFILE);\n+    goto fail;\n+  }\n+\n+  read_buffer = malloc(MOUNT_TABLE_BUFFER_SIZE);\n+  if (read_buffer == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to allocate read buffer of %d bytes\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  f = fopen(\"/proc/mounts\", \"r\");\n+  if (f == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open /proc/mounts : %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  if (setvbuf(f, read_buffer, _IOFBF, MOUNT_TABLE_BUFFER_SIZE) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to set mount table buffer to %d\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  struct mntent* me;\n+  while ((me = getmntent(f)) != NULL) {\n+    // Skip mounts that are not loopback mounts\n+    if (strncmp(me->mnt_fsname, DEV_LOOP_PREFIX, DEV_LOOP_PREFIX_LEN)) {\n+      continue;\n+    }\n+\n+    // skip destinations that are not under the layers mount area\n+    if (strncmp(layers_path, me->mnt_dir, layers_path_len)) {\n+      continue;\n+    }\n+\n+    if (num_entries == entries_capacity) {\n+      entries_capacity += num_entries_per_alloc;\n+      entries = realloc(entries, sizeof(*entries) * entries_capacity);\n+      if (entries == NULL) {\n+        fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - realloc\\n\", ERRORFILE);\n+        goto fail;\n+      }\n+    }\n+\n+    if (!copy_mntent(entries + num_entries, me)) {\n+      fputs(\"ERROR: Failed to copy_mntent\", ERRORFILE);\n+      goto fail;\n+    }\n+    ++num_entries;\n+  }\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(read_buffer);\n+  *num_entries_out = num_entries;\n+  return entries;\n+\n+fail:\n+  free_mntent_array(entries, num_entries);\n+  entries = NULL;\n+  num_entries = 0;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Search for layer mounts that correspond with deleted files and unmount them.\n+ */\n+static bool reap_deleted_mounts_with_lock(oci_base_ctx* ctx) {\n+  const char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_deleted_mounts_with_lock\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  size_t num_mnt_entries = 0;\n+  struct mntent* mnt_entries = get_layer_mounts(&num_mnt_entries, layers_path);\n+  if (mnt_entries == NULL) {\n+    fputs(\"ERROR: Error parsing mount table\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool have_write_lock = false;\n+  size_t i;\n+  for (i = 0; i < num_mnt_entries; ++i) {\n+    const struct mntent* me = mnt_entries + i;\n+    if (is_loop_file_deleted(me->mnt_fsname)) {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(ctx)) {\n+          goto cleanup;\n+        }\n+        have_write_lock = true;\n+      }\n+\n+      char* layer_dir = get_oci_layer_path_from_mount_path(me->mnt_dir);\n+      if (layer_dir != NULL) {\n+        if (unmount_layer(layer_dir)) {\n+          printf(\"Unmounted layer %s (deleted)\\n\", basename(layer_dir));\n+        }\n+        free(layer_dir);\n+      }\n+    }\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_mntent_array(mnt_entries, num_mnt_entries);\n+  return result;\n+}\n+\n+/**\n+ * Equivalent to reap_oci_layer_mounts but avoids the need to re-create the\n+ * OCI base context.\n+ */\n+int reap_oci_layer_mounts_with_ctx(oci_base_ctx* ctx, int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  int layers_fd = -1;\n+  char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_oci_layer_mounts_with_ctx\\n\", ERRORFILE);\n+    rc = OUT_OF_MEMORY;\n+    goto cleanup;\n+  }\n+\n+  layers_fd = open(layers_path, O_RDONLY | O_NOFOLLOW);\n+  if (layers_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open layers directory at %s : %s\\n\",\n+        layers_path, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_read_lock(ctx)) {\n+    fputs(\"ERROR: Unable to obtain layer lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool reap_deleted_ok = reap_deleted_mounts_with_lock(ctx);\n+  bool reap_layers_ok = do_reap_layer_mounts_with_lock(ctx, layers_fd,\n+      num_preserve);\n+  if (reap_deleted_ok && reap_layers_ok) {\n+    rc = 0;\n+  }\n+\n+  release_oci_layers_lock(ctx);\n+\n+cleanup:\n+  if (layers_fd != -1) {\n+    close(layers_fd);\n+  }\n+  free(layers_path);\n+  return rc;\n+}\n+\n+/**\n+ * Attempt to trim the number of layer mounts to the specified target number to\n+ * preserve. Layers are unmounted in a least-recently-used fashion. Layers that\n+ * are still in use by containers are preserved, so the number of layers mounts\n+ * after trimming may exceed the target number.\n+ *\n+ * Returns 0 on success or a non-zero error code on failure.\n+ */\n+int reap_oci_layer_mounts(int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  oci_base_ctx* ctx = setup_oci_base_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Failed to setup_oci_base_ctx\", ERRORFILE);\n+    return rc;\n+  }\n+\n+  rc = reap_oci_layer_mounts_with_ctx(ctx, num_preserve);\n+  free_oci_base_ctx(ctx);\n+  return rc;\n+}\n+\n+int cleanup_oci_container_by_id(const char* container_id, int num_reap_layers_keep) {\n+  char* run_root = get_value(OCI_RUN_ROOT_CONFIG_KEY);\n+  int rc = 0;\n+  if (run_root == NULL) {\n+    run_root = strdup(DEFAULT_OCI_RUN_ROOT);\n+    if (run_root == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - strdup\", ERRORFILE);\n+      goto mem_fail;\n+    }\n+  }\n+\n+  oci_overlay_desc* desc = malloc(sizeof(oci_overlay_desc));\n+  if (desc == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - malloc\", ERRORFILE);\n+    goto mem_fail;\n+  }\n+  init_oci_overlay_desc(desc);\n+  if (!init_overlay_descriptor(desc, run_root, container_id)) {\n+      fputs(\"ERROR: init_overlay_descriptor Failed\\n\", ERRORFILE);\n+      goto mem_fail;\n+  }\n+  rc = cleanup_oci_container(container_id, desc->mount_path, desc->top_path, NULL, num_reap_layers_keep);\n+\n+cleanup:\n+  free(run_root);\n+  destroy_oci_overlay_desc(desc);\n+  free(desc);\n+  return rc;\n+\n+mem_fail:\n+  rc = OUT_OF_MEMORY;\n+  goto cleanup;\n+}\n+\n+char* get_next_word(char* line, int* start_index) {\n+    int temp = *start_index;\n+    while (line[*start_index] != ' ') {\n+        *start_index  += 1;\n+    }\n+    char* word = malloc(sizeof(char) * (*start_index - temp + 1));\n+    int i=0;\n+    while (temp < *(start_index)) {\n+        word[i++]  = line[temp++];\n+    }\n+    word[i] = '\\0';\n+\n+    while (line[*start_index] == ' ') {\n+            *start_index += 1;\n+    }\n+\n+    return word;\n+}\n+\n+static bool unmount_and_remove(const char* path) {\n+  if (umount(path) == -1 && errno != EINVAL && errno != ENOENT) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      return false;\n+    }\n+    fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s in unmount_and_remove \\n\", path, strerror(errno));\n+    return false;\n+  }\n+  if (rmdir(path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing mount directory %s : %s\\n\", path,\n+        strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool unmount_and_remove_with_retry(const char* path, int max_attempts,\n+    long max_backoff_msec) {\n+  long backoff_msec = 1;\n+  int i;\n+  for (i = 0; i < max_attempts - 1; ++i) {\n+    if (unmount_and_remove(path)) {\n+      return true;\n+    }\n+    struct timespec ts;\n+    memset(&ts, 0, sizeof(ts));\n+    ts.tv_sec = backoff_msec / 1000;\n+    ts.tv_nsec = (backoff_msec % 1000) * 1000 * 1000;\n+    nanosleep(&ts, NULL);\n+    backoff_msec *= 2;\n+    if (backoff_msec > max_backoff_msec) {\n+      backoff_msec = max_backoff_msec;\n+    }\n+  }\n+\n+  return unmount_and_remove(path);\n+}\n+\n+/**\n+ * Unmounts the container rootfs directory and MAY unmount layers on the host\n+ * based on the specified number of total layer mounts on the host specified.\n+ * We need to delete the container using runc since we launch it in detached mode.\n+ */\n+int cleanup_oci_container(const char* container_id, const char* mount_path, const char* top_path, \n+  oci_base_ctx* base_ctx, int num_reap_layers_keep) {\n+  unmount_and_remove_with_retry(mount_path,\n+      NUM_ROOTFS_UNMOUNT_ATTEMPTS, MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC);\n+  rmdir_recursive(top_path);\n+  if (base_ctx == NULL) {\n+    reap_oci_layer_mounts(num_reap_layers_keep);\n+  } else {\n+    reap_oci_layer_mounts_with_ctx(base_ctx, num_reap_layers_keep);\n+  }\n+\n+  //delete container\n+  int rc = 0;\n+  char* runc_path = get_value(OCI_RUNC_CONFIG_KEY);\n+  if (runc_path == NULL) {\n+    runc_path = strdup(DEFAULT_OCI_RUNC);\n+    if (runc_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container\\n\", ERRORFILE);\n+      rc = OUT_OF_MEMORY;\n+      goto cleanup;\n+    }\n+  }\n+\n+  char* cmd = NULL;\n+  if (asprintf(&cmd, \"%s delete %s\", runc_path, container_id) == -1) {\n+    rc = 1;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1NzMwOQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550557309", "bodyText": "is this the case where the container was already cleaned up?  Does the calling code properly handle this error?  Is this why the retries are necessary?", "author": "agresch", "createdAt": "2020-12-31T16:57:40Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_reap.c", "diffHunk": "@@ -0,0 +1,770 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/types.h>\n+#include <sys/mount.h>\n+#include <sys/stat.h>\n+#include <dirent.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <mntent.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+#include <time.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"configuration.h\"\n+#include \"oci.h\"\n+#include \"oci_base_ctx.h\"\n+#include \"oci_reap.h\"\n+#include \"oci_config.h\"\n+\n+\n+#define DEV_LOOP_PREFIX       \"/dev/loop\"\n+#define DEV_LOOP_PREFIX_LEN   (sizeof(DEV_LOOP_PREFIX) - 1)\n+#define DELETED_SUFFIX        \" (deleted)\\n\"\n+#define DELETED_SUFFIX_LEN    (sizeof(DELETED_SUFFIX) - 1)\n+\n+#define NUM_ROOTFS_UNMOUNT_ATTEMPTS      40\n+#define MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC  1000\n+\n+// The size of the buffer to use when reading the mount table. This should be\n+// large enough so ideally the mount table is read all at once.\n+// Otherwise the mount table could change in-between underlying read() calls\n+// and result in a table with missing or corrupted entries.\n+#define MOUNT_TABLE_BUFFER_SIZE (1024*1024)\n+\n+// NOTE: Update destroy_dent_stat when this is updated.\n+typedef struct dent_stat_struct {\n+  char* basename;         // basename of directory entry\n+  struct timespec mtime;  // modification time\n+} dent_stat;\n+\n+// NOTE: Update init_dent_stats and destroy_dent_stats when this is changed.\n+typedef struct dent_stats_array_struct {\n+  dent_stat* stats;       // array of dent_stat structures\n+  size_t capacity;        // capacity of the stats array\n+  size_t length;          // number of valid entries in the stats array\n+} dent_stats_array;\n+\n+\n+/**\n+ * Releases the resources associated with a dent_stat structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated structures or other structures that embed this structure.\n+ */\n+static void destroy_dent_stat(dent_stat* ds) {\n+  if (ds != NULL) {\n+    free(ds->basename);\n+    ds->basename = NULL;\n+  }\n+}\n+\n+/**\n+ * Initialize an uninitialized dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool init_dent_stats(dent_stats_array* dsa, size_t initial_size) {\n+  memset(dsa, 0, sizeof(*dsa));\n+  dsa->stats = malloc(sizeof(*dsa->stats) * initial_size);\n+  if (dsa->stats == NULL) {\n+    return false;\n+  }\n+  dsa->capacity = initial_size;\n+  dsa->length = 0;\n+  return true;\n+}\n+\n+/**\n+ * Allocates and initializes a dent_stats_array with the specified\n+ * number of entries as its initial capacity.\n+ *\n+ * Returns a pointer to the dent_stats_array or NULL on error.\n+ */\n+static dent_stats_array* alloc_dent_stats(size_t initial_size) {\n+  dent_stats_array* dsa = malloc(sizeof(*dsa));\n+  if (dsa != NULL) {\n+    if (!init_dent_stats(dsa, initial_size)) {\n+      free(dsa);\n+      dsa = NULL;\n+    }\n+  }\n+  return dsa;\n+}\n+\n+/**\n+ * Grows the capacity of a dent_stats_array to the new specified number of\n+ * elements.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool realloc_dent_stats(dent_stats_array* dsa, size_t new_size) {\n+  if (new_size < dsa->length) {\n+    // New capacity would result in a truncation.\n+    return false;\n+  }\n+\n+  dent_stat* new_stats = realloc(dsa->stats, new_size * sizeof(*dsa->stats));\n+  if (new_stats == NULL) {\n+    return false;\n+  }\n+\n+  dsa->stats = new_stats;\n+  dsa->capacity = new_size;\n+  return true;\n+}\n+\n+/**\n+ * Append a new dent_stat entry to a dent_stats_array, reallocating the\n+ * array if necessary with the specified increase in capacity.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool append_dent_stat(dent_stats_array* dsa, size_t stats_size_incr,\n+    const char* basename, const struct timespec* mtime) {\n+  if (dsa->length == dsa->capacity) {\n+    if (!realloc_dent_stats(dsa, dsa->capacity + stats_size_incr)) {\n+      return false;\n+    }\n+  }\n+\n+  char* ds_name = strdup(basename);\n+  if (ds_name == NULL) {\n+    return false;\n+  }\n+\n+  dent_stat* ds = &dsa->stats[dsa->length++];\n+  ds->basename = ds_name;\n+  ds->mtime = *mtime;\n+  return true;\n+}\n+\n+/**\n+ * Releases the resources associated with a dent_stats_array structure but\n+ * does NOT free the structure itself. This is particularly useful for\n+ * stack-allocated contexts or other structures that embed this structure.\n+ */\n+static void destroy_dent_stats(dent_stats_array* dsa) {\n+  if (dsa != NULL ) {\n+    size_t i;\n+    for (i = 0; i < dsa->length; ++i) {\n+      destroy_dent_stat(&dsa->stats[i]);\n+    }\n+    free(dsa->stats);\n+    dsa->capacity = 0;\n+    dsa->length = 0;\n+  }\n+}\n+\n+/**\n+ * Frees a dent_stats_array structure and all memory associted with it.\n+ */\n+static void free_dent_stats(dent_stats_array* dsa) {\n+  destroy_dent_stats(dsa);\n+  free(dsa);\n+}\n+\n+/**\n+ * Get the array of dent_stats for the layers directory.\n+ * Only directory entries that look like layers will be returned.\n+ *\n+ * Returns the array of dent_stats or NULL on error.\n+ */\n+static dent_stats_array* get_dent_stats(int layers_fd) {\n+  DIR* layers_dir = NULL;\n+  // number of stat buffers to allocate each time we run out\n+  const size_t stats_size_incr = 8192;\n+  dent_stats_array* dsa = alloc_dent_stats(stats_size_incr);\n+  if (dsa == NULL) {\n+    return NULL;\n+  }\n+\n+  int dir_fd = dup(layers_fd);\n+  if (dir_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to duplicate layer dir fd: %s\\n\",\n+        strerror(errno));\n+    goto fail;\n+  }\n+\n+  layers_dir = fdopendir(dir_fd);\n+  if (layers_dir == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Cannot open layers directory: %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  struct dirent* de;\n+  while ((de = readdir(layers_dir)) != NULL) {\n+    // skip entries that don't look like layers\n+    if (strlen(de->d_name) != LAYER_NAME_LENGTH) {\n+      continue;\n+    }\n+\n+    struct stat statbuf;\n+    if (fstatat(layers_fd, de->d_name, &statbuf, AT_SYMLINK_NOFOLLOW) == -1) {\n+      if (errno == ENOENT) {\n+        continue;\n+      }\n+      fprintf(ERRORFILE, \"ERROR: Error getting stats for layer %s : %s\\n\", de->d_name,\n+          strerror(errno));\n+      goto fail;\n+    }\n+\n+    if (!append_dent_stat(dsa, stats_size_incr, de->d_name,\n+        &statbuf.st_mtim)) {\n+      fputs(\"ERROR: Unable to allocate memory in get_dent_stats\\n\", ERRORFILE);\n+      goto fail;\n+    }\n+  }\n+\n+cleanup:\n+  if (layers_dir != NULL) {\n+    closedir(layers_dir);\n+  }\n+  return dsa;\n+\n+fail:\n+  free_dent_stats(dsa);\n+  dsa = NULL;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Umount a layer and remove the directories associated with the layer mount.\n+ *\n+ * Returns true on success or false on error.\n+ */\n+static bool unmount_layer(const char* layer_dir_path) {\n+  char* mount_path = get_oci_layer_mount_path(layer_dir_path);\n+  if (mount_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in unmount_layer\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  if (umount(mount_path) == -1) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      goto cleanup;\n+    } else if (errno != ENOENT && errno != EINVAL) {\n+      fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s\\n\", mount_path,\n+          strerror(errno));\n+      goto cleanup;\n+    }\n+  } else {\n+    // unmount was successful so report success even if directory removals\n+    // fail after this.\n+    result = true;\n+  }\n+\n+  if (rmdir(mount_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(mount_path)\\n\", mount_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (rmdir(layer_dir_path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing %s : %s in rmdir(layer_dir_path)\\n\", layer_dir_path,\n+        strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free(mount_path);\n+  return result;\n+}\n+\n+/**\n+ * Order directory entries by increasing modification time.\n+ */\n+static int compare_dent_stats_mtime(const void* va, const void* vb) {\n+  const dent_stat* a = (const dent_stat*)va;\n+  const dent_stat* b = (const dent_stat*)vb;\n+  if (a->mtime.tv_sec < b->mtime.tv_sec) {\n+    return -1;\n+  } else if (a->mtime.tv_sec > b->mtime.tv_sec) {\n+    return 1;\n+  }\n+  return a->mtime.tv_nsec - b->mtime.tv_nsec;\n+}\n+\n+static bool do_reap_layer_mounts_with_lock(oci_base_ctx* ctx,\n+    int layers_fd, int num_preserve) {\n+  dent_stats_array* dsa = get_dent_stats(layers_fd);\n+  if (dsa == NULL) {\n+    return false;\n+  }\n+\n+  qsort(&dsa->stats[0], dsa->length, sizeof(*dsa->stats),\n+      compare_dent_stats_mtime);\n+\n+  bool result = false;\n+  size_t num_remain = dsa->length;\n+  if (num_remain <= num_preserve) {\n+    result = true;\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_write_lock(ctx)) {\n+    fputs(\"ERROR: Unable to acquire layer write lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+  size_t i;\n+  for (i = 0; i < dsa->length && num_remain > num_preserve; ++i) {\n+    char* layer_dir_path = get_oci_layer_path(ctx->run_root,\n+        dsa->stats[i].basename);\n+    if (layer_dir_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in do_reap_layer_mounts_with_lock\\n\", ERRORFILE);\n+      goto cleanup;\n+    }\n+    if (unmount_layer(layer_dir_path)) {\n+      --num_remain;\n+      printf(\"Unmounted layer %s\\n\", dsa->stats[i].basename);\n+    }\n+    free(layer_dir_path);\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_dent_stats(dsa);\n+  return result;\n+}\n+\n+/**\n+ * Determine if the specified loopback device is associated with a file that\n+ * has been deleted.\n+ *\n+ * Returns true if the loopback file is deleted or false otherwise or on error.\n+ */\n+bool is_loop_file_deleted(const char* loopdev) {\n+  bool result = false;\n+  FILE* f = NULL;\n+  char* path = NULL;\n+  char* linebuf = NULL;\n+\n+  // locate the numeric part of the loop device\n+  const char* loop_num_str = loopdev + DEV_LOOP_PREFIX_LEN;\n+\n+  if (asprintf(&path, \"/sys/devices/virtual/block/loop%s/loop/backing_file\",\n+      loop_num_str) == -1) {\n+    return false;\n+  }\n+\n+  f = fopen(path, \"r\");\n+  if (f == NULL) {\n+    goto cleanup;\n+  }\n+\n+  size_t linebuf_len = 0;\n+  ssize_t len = getline(&linebuf, &linebuf_len, f);\n+  if (len <= DELETED_SUFFIX_LEN) {\n+    goto cleanup;\n+  }\n+\n+  result = !strcmp(DELETED_SUFFIX, linebuf + len - DELETED_SUFFIX_LEN);\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(linebuf);\n+  free(path);\n+  return result;\n+}\n+\n+static bool copy_mntent(struct mntent* dest, const struct mntent* src) {\n+  memset(dest, 0, sizeof(*dest));\n+  if (src->mnt_fsname != NULL) {\n+    dest->mnt_fsname = strdup(src->mnt_fsname);\n+    if (dest->mnt_fsname == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_dir != NULL) {\n+    dest->mnt_dir = strdup(src->mnt_dir);\n+    if (dest->mnt_dir == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_type != NULL) {\n+    dest->mnt_type = strdup(src->mnt_type);\n+    if (dest->mnt_type == NULL) {\n+      return false;\n+    }\n+  }\n+  if (src->mnt_opts != NULL) {\n+    dest->mnt_opts = strdup(src->mnt_opts);\n+    if (dest->mnt_opts == NULL) {\n+      return false;\n+    }\n+  }\n+  dest->mnt_freq = src->mnt_freq;\n+  dest->mnt_passno = src->mnt_passno;\n+  return true;\n+}\n+\n+static void free_mntent_array(struct mntent* entries, size_t num_entries) {\n+  if (entries != NULL) {\n+    size_t i;\n+    for (i = 0; i < num_entries; ++i) {\n+      struct mntent* me = entries + i;\n+      free(me->mnt_fsname);\n+      free(me->mnt_dir);\n+      free(me->mnt_type);\n+      free(me->mnt_opts);\n+    }\n+    free(entries);\n+  }\n+}\n+\n+/**\n+ * Get the array of mount table entries that are layer mounts.\n+ *\n+ * Returns the heap-allocated array of mount entries or NULL on error.\n+ * The num_entries argument is updated to the number of elements in the array.\n+ */\n+static struct mntent* get_layer_mounts(size_t* num_entries_out,\n+    const char* layers_path) {\n+  const size_t layers_path_len = strlen(layers_path);\n+  char* read_buffer = NULL;\n+  FILE* f = NULL;\n+  const size_t num_entries_per_alloc = 8192;\n+  size_t num_entries = 0;\n+  size_t entries_capacity = num_entries_per_alloc;\n+  struct mntent* entries = malloc(sizeof(*entries) * entries_capacity);\n+  if (entries == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - malloc\\n\", ERRORFILE);\n+    goto fail;\n+  }\n+\n+  read_buffer = malloc(MOUNT_TABLE_BUFFER_SIZE);\n+  if (read_buffer == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to allocate read buffer of %d bytes\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  f = fopen(\"/proc/mounts\", \"r\");\n+  if (f == NULL) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open /proc/mounts : %s\\n\", strerror(errno));\n+    goto fail;\n+  }\n+\n+  if (setvbuf(f, read_buffer, _IOFBF, MOUNT_TABLE_BUFFER_SIZE) != 0) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to set mount table buffer to %d\\n\",\n+        MOUNT_TABLE_BUFFER_SIZE);\n+    goto fail;\n+  }\n+\n+  struct mntent* me;\n+  while ((me = getmntent(f)) != NULL) {\n+    // Skip mounts that are not loopback mounts\n+    if (strncmp(me->mnt_fsname, DEV_LOOP_PREFIX, DEV_LOOP_PREFIX_LEN)) {\n+      continue;\n+    }\n+\n+    // skip destinations that are not under the layers mount area\n+    if (strncmp(layers_path, me->mnt_dir, layers_path_len)) {\n+      continue;\n+    }\n+\n+    if (num_entries == entries_capacity) {\n+      entries_capacity += num_entries_per_alloc;\n+      entries = realloc(entries, sizeof(*entries) * entries_capacity);\n+      if (entries == NULL) {\n+        fputs(\"ERROR: Unable to allocate memory in get_layer_mounts - realloc\\n\", ERRORFILE);\n+        goto fail;\n+      }\n+    }\n+\n+    if (!copy_mntent(entries + num_entries, me)) {\n+      fputs(\"ERROR: Failed to copy_mntent\", ERRORFILE);\n+      goto fail;\n+    }\n+    ++num_entries;\n+  }\n+\n+cleanup:\n+  if (f != NULL) {\n+    fclose(f);\n+  }\n+  free(read_buffer);\n+  *num_entries_out = num_entries;\n+  return entries;\n+\n+fail:\n+  free_mntent_array(entries, num_entries);\n+  entries = NULL;\n+  num_entries = 0;\n+  goto cleanup;\n+}\n+\n+/**\n+ * Search for layer mounts that correspond with deleted files and unmount them.\n+ */\n+static bool reap_deleted_mounts_with_lock(oci_base_ctx* ctx) {\n+  const char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_deleted_mounts_with_lock\\n\", ERRORFILE);\n+    return false;\n+  }\n+\n+  bool result = false;\n+  size_t num_mnt_entries = 0;\n+  struct mntent* mnt_entries = get_layer_mounts(&num_mnt_entries, layers_path);\n+  if (mnt_entries == NULL) {\n+    fputs(\"ERROR: Error parsing mount table\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool have_write_lock = false;\n+  size_t i;\n+  for (i = 0; i < num_mnt_entries; ++i) {\n+    const struct mntent* me = mnt_entries + i;\n+    if (is_loop_file_deleted(me->mnt_fsname)) {\n+      if (!have_write_lock) {\n+        if (!acquire_oci_layers_write_lock(ctx)) {\n+          goto cleanup;\n+        }\n+        have_write_lock = true;\n+      }\n+\n+      char* layer_dir = get_oci_layer_path_from_mount_path(me->mnt_dir);\n+      if (layer_dir != NULL) {\n+        if (unmount_layer(layer_dir)) {\n+          printf(\"Unmounted layer %s (deleted)\\n\", basename(layer_dir));\n+        }\n+        free(layer_dir);\n+      }\n+    }\n+  }\n+\n+  result = true;\n+\n+cleanup:\n+  free_mntent_array(mnt_entries, num_mnt_entries);\n+  return result;\n+}\n+\n+/**\n+ * Equivalent to reap_oci_layer_mounts but avoids the need to re-create the\n+ * OCI base context.\n+ */\n+int reap_oci_layer_mounts_with_ctx(oci_base_ctx* ctx, int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  int layers_fd = -1;\n+  char* layers_path = get_oci_layers_path(ctx->run_root);\n+  if (layers_path == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in reap_oci_layer_mounts_with_ctx\\n\", ERRORFILE);\n+    rc = OUT_OF_MEMORY;\n+    goto cleanup;\n+  }\n+\n+  layers_fd = open(layers_path, O_RDONLY | O_NOFOLLOW);\n+  if (layers_fd == -1) {\n+    fprintf(ERRORFILE, \"ERROR: Unable to open layers directory at %s : %s\\n\",\n+        layers_path, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  if (!acquire_oci_layers_read_lock(ctx)) {\n+    fputs(\"ERROR: Unable to obtain layer lock\\n\", ERRORFILE);\n+    goto cleanup;\n+  }\n+\n+  bool reap_deleted_ok = reap_deleted_mounts_with_lock(ctx);\n+  bool reap_layers_ok = do_reap_layer_mounts_with_lock(ctx, layers_fd,\n+      num_preserve);\n+  if (reap_deleted_ok && reap_layers_ok) {\n+    rc = 0;\n+  }\n+\n+  release_oci_layers_lock(ctx);\n+\n+cleanup:\n+  if (layers_fd != -1) {\n+    close(layers_fd);\n+  }\n+  free(layers_path);\n+  return rc;\n+}\n+\n+/**\n+ * Attempt to trim the number of layer mounts to the specified target number to\n+ * preserve. Layers are unmounted in a least-recently-used fashion. Layers that\n+ * are still in use by containers are preserved, so the number of layers mounts\n+ * after trimming may exceed the target number.\n+ *\n+ * Returns 0 on success or a non-zero error code on failure.\n+ */\n+int reap_oci_layer_mounts(int num_preserve) {\n+  int rc = ERROR_OCI_REAP_LAYER_MOUNTS_FAILED;\n+  oci_base_ctx* ctx = setup_oci_base_ctx();\n+  if (ctx == NULL) {\n+    fputs(\"ERROR: Failed to setup_oci_base_ctx\", ERRORFILE);\n+    return rc;\n+  }\n+\n+  rc = reap_oci_layer_mounts_with_ctx(ctx, num_preserve);\n+  free_oci_base_ctx(ctx);\n+  return rc;\n+}\n+\n+int cleanup_oci_container_by_id(const char* container_id, int num_reap_layers_keep) {\n+  char* run_root = get_value(OCI_RUN_ROOT_CONFIG_KEY);\n+  int rc = 0;\n+  if (run_root == NULL) {\n+    run_root = strdup(DEFAULT_OCI_RUN_ROOT);\n+    if (run_root == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - strdup\", ERRORFILE);\n+      goto mem_fail;\n+    }\n+  }\n+\n+  oci_overlay_desc* desc = malloc(sizeof(oci_overlay_desc));\n+  if (desc == NULL) {\n+    fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container_by_id - malloc\", ERRORFILE);\n+    goto mem_fail;\n+  }\n+  init_oci_overlay_desc(desc);\n+  if (!init_overlay_descriptor(desc, run_root, container_id)) {\n+      fputs(\"ERROR: init_overlay_descriptor Failed\\n\", ERRORFILE);\n+      goto mem_fail;\n+  }\n+  rc = cleanup_oci_container(container_id, desc->mount_path, desc->top_path, NULL, num_reap_layers_keep);\n+\n+cleanup:\n+  free(run_root);\n+  destroy_oci_overlay_desc(desc);\n+  free(desc);\n+  return rc;\n+\n+mem_fail:\n+  rc = OUT_OF_MEMORY;\n+  goto cleanup;\n+}\n+\n+char* get_next_word(char* line, int* start_index) {\n+    int temp = *start_index;\n+    while (line[*start_index] != ' ') {\n+        *start_index  += 1;\n+    }\n+    char* word = malloc(sizeof(char) * (*start_index - temp + 1));\n+    int i=0;\n+    while (temp < *(start_index)) {\n+        word[i++]  = line[temp++];\n+    }\n+    word[i] = '\\0';\n+\n+    while (line[*start_index] == ' ') {\n+            *start_index += 1;\n+    }\n+\n+    return word;\n+}\n+\n+static bool unmount_and_remove(const char* path) {\n+  if (umount(path) == -1 && errno != EINVAL && errno != ENOENT) {\n+    if (errno == EBUSY) {\n+      // Layer is in use by another container.\n+      return false;\n+    }\n+    fprintf(ERRORFILE, \"ERROR: Error unmounting %s : %s in unmount_and_remove \\n\", path, strerror(errno));\n+    return false;\n+  }\n+  if (rmdir(path) == -1 && errno != ENOENT) {\n+    fprintf(ERRORFILE, \"ERROR: Error removing mount directory %s : %s\\n\", path,\n+        strerror(errno));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+static bool unmount_and_remove_with_retry(const char* path, int max_attempts,\n+    long max_backoff_msec) {\n+  long backoff_msec = 1;\n+  int i;\n+  for (i = 0; i < max_attempts - 1; ++i) {\n+    if (unmount_and_remove(path)) {\n+      return true;\n+    }\n+    struct timespec ts;\n+    memset(&ts, 0, sizeof(ts));\n+    ts.tv_sec = backoff_msec / 1000;\n+    ts.tv_nsec = (backoff_msec % 1000) * 1000 * 1000;\n+    nanosleep(&ts, NULL);\n+    backoff_msec *= 2;\n+    if (backoff_msec > max_backoff_msec) {\n+      backoff_msec = max_backoff_msec;\n+    }\n+  }\n+\n+  return unmount_and_remove(path);\n+}\n+\n+/**\n+ * Unmounts the container rootfs directory and MAY unmount layers on the host\n+ * based on the specified number of total layer mounts on the host specified.\n+ * We need to delete the container using runc since we launch it in detached mode.\n+ */\n+int cleanup_oci_container(const char* container_id, const char* mount_path, const char* top_path, \n+  oci_base_ctx* base_ctx, int num_reap_layers_keep) {\n+  unmount_and_remove_with_retry(mount_path,\n+      NUM_ROOTFS_UNMOUNT_ATTEMPTS, MAX_ROOTFS_UNMOUNT_BACKOFF_MSEC);\n+  rmdir_recursive(top_path);\n+  if (base_ctx == NULL) {\n+    reap_oci_layer_mounts(num_reap_layers_keep);\n+  } else {\n+    reap_oci_layer_mounts_with_ctx(base_ctx, num_reap_layers_keep);\n+  }\n+\n+  //delete container\n+  int rc = 0;\n+  char* runc_path = get_value(OCI_RUNC_CONFIG_KEY);\n+  if (runc_path == NULL) {\n+    runc_path = strdup(DEFAULT_OCI_RUNC);\n+    if (runc_path == NULL) {\n+      fputs(\"ERROR: Unable to allocate memory in cleanup_oci_container\\n\", ERRORFILE);\n+      rc = OUT_OF_MEMORY;\n+      goto cleanup;\n+    }\n+  }\n+\n+  char* cmd = NULL;\n+  if (asprintf(&cmd, \"%s delete %s\", runc_path, container_id) == -1) {\n+    rc = 1;\n+    goto cleanup;\n+  }\n+\n+  fprintf(LOGFILE, \"oci cleanup container command: %s\\n\", cmd);\n+  if (system(cmd) != 0) {\n+    fprintf(ERRORFILE, \"WARN: oci cleanup container command %s failed\\n\", cmd);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1ODI3Mw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550558273", "bodyText": "should we have error messages for these?", "author": "agresch", "createdAt": "2020-12-31T16:58:49Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_write_config.c", "diffHunk": "@@ -0,0 +1,464 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/utsname.h>\n+#include <stdarg.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+#include \"utils/storm_user_info.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_write_config.h\"\n+\n+#define RUNC_CONFIG_FILENAME    \"config.json\"\n+#define STARTING_JSON_BUFFER_SIZE  (128*1024)\n+\n+\n+static cJSON* build_runc_config_root(const char* rootfs_path) {\n+  cJSON* root = cJSON_CreateObject();\n+  if (cJSON_AddStringToObject(root, \"path\", rootfs_path) == NULL) {\n+    goto fail;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1ODY1MQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550558651", "bodyText": "error message?", "author": "agresch", "createdAt": "2020-12-31T16:59:13Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_write_config.c", "diffHunk": "@@ -0,0 +1,464 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/utsname.h>\n+#include <stdarg.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+#include \"utils/storm_user_info.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_write_config.h\"\n+\n+#define RUNC_CONFIG_FILENAME    \"config.json\"\n+#define STARTING_JSON_BUFFER_SIZE  (128*1024)\n+\n+\n+static cJSON* build_runc_config_root(const char* rootfs_path) {\n+  cJSON* root = cJSON_CreateObject();\n+  if (cJSON_AddStringToObject(root, \"path\", rootfs_path) == NULL) {\n+    goto fail;\n+  }\n+  if (cJSON_AddTrueToObject(root, \"readonly\") == NULL) {\n+    goto fail;\n+  }\n+  return root;\n+\n+fail:\n+  cJSON_Delete(root);\n+  return NULL;\n+}\n+\n+static cJSON* build_runc_config_process_user(const char* username) {\n+  cJSON* user_json = cJSON_CreateObject();\n+  struct storm_user_info* sui = storm_user_info_alloc();\n+  if (sui == NULL) {\n+    return NULL;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1ODk4OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550558988", "bodyText": "error messages for remaining failures here and below?", "author": "agresch", "createdAt": "2020-12-31T16:59:40Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_write_config.c", "diffHunk": "@@ -0,0 +1,464 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/utsname.h>\n+#include <stdarg.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+#include \"utils/storm_user_info.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_write_config.h\"\n+\n+#define RUNC_CONFIG_FILENAME    \"config.json\"\n+#define STARTING_JSON_BUFFER_SIZE  (128*1024)\n+\n+\n+static cJSON* build_runc_config_root(const char* rootfs_path) {\n+  cJSON* root = cJSON_CreateObject();\n+  if (cJSON_AddStringToObject(root, \"path\", rootfs_path) == NULL) {\n+    goto fail;\n+  }\n+  if (cJSON_AddTrueToObject(root, \"readonly\") == NULL) {\n+    goto fail;\n+  }\n+  return root;\n+\n+fail:\n+  cJSON_Delete(root);\n+  return NULL;\n+}\n+\n+static cJSON* build_runc_config_process_user(const char* username) {\n+  cJSON* user_json = cJSON_CreateObject();\n+  struct storm_user_info* sui = storm_user_info_alloc();\n+  if (sui == NULL) {\n+    return NULL;\n+  }\n+\n+  int rc = storm_user_info_fetch(sui, username);\n+  if (rc != 0) {\n+    fprintf(ERRORFILE, \"Error looking up user %s : %s\\n\", username,\n+        strerror(rc));\n+    goto fail;\n+  }\n+\n+  if (cJSON_AddNumberToObject(user_json, \"uid\", sui->pwd.pw_uid) == NULL) {\n+    goto fail;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU1OTk3Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550559977", "bodyText": "error messages?", "author": "agresch", "createdAt": "2020-12-31T17:00:57Z", "path": "storm-core/src/native/worker-launcher/impl/oci/oci_write_config.c", "diffHunk": "@@ -0,0 +1,464 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+#include <sys/utsname.h>\n+#include <stdarg.h>\n+#include <stdbool.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+#include \"utils/storm_user_info.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"worker-launcher.h\"\n+#include \"utils/cJSON.h\"\n+#include \"utils/file-utils.h\"\n+\n+#include \"oci_launch_cmd.h\"\n+#include \"oci_write_config.h\"\n+\n+#define RUNC_CONFIG_FILENAME    \"config.json\"\n+#define STARTING_JSON_BUFFER_SIZE  (128*1024)\n+\n+\n+static cJSON* build_runc_config_root(const char* rootfs_path) {\n+  cJSON* root = cJSON_CreateObject();\n+  if (cJSON_AddStringToObject(root, \"path\", rootfs_path) == NULL) {\n+    goto fail;\n+  }\n+  if (cJSON_AddTrueToObject(root, \"readonly\") == NULL) {\n+    goto fail;\n+  }\n+  return root;\n+\n+fail:\n+  cJSON_Delete(root);\n+  return NULL;\n+}\n+\n+static cJSON* build_runc_config_process_user(const char* username) {\n+  cJSON* user_json = cJSON_CreateObject();\n+  struct storm_user_info* sui = storm_user_info_alloc();\n+  if (sui == NULL) {\n+    return NULL;\n+  }\n+\n+  int rc = storm_user_info_fetch(sui, username);\n+  if (rc != 0) {\n+    fprintf(ERRORFILE, \"Error looking up user %s : %s\\n\", username,\n+        strerror(rc));\n+    goto fail;\n+  }\n+\n+  if (cJSON_AddNumberToObject(user_json, \"uid\", sui->pwd.pw_uid) == NULL) {\n+    goto fail;\n+  }\n+  if (cJSON_AddNumberToObject(user_json, \"gid\", sui->pwd.pw_gid) == NULL) {\n+    goto fail;\n+  }\n+\n+  rc = storm_user_info_getgroups(sui);\n+  if (rc != 0) {\n+    fprintf(ERRORFILE, \"Error getting groups for user %s : %s\\n\", username,\n+        strerror(rc));\n+    goto fail;\n+  }\n+\n+  if (sui->num_gids > 1) {\n+    cJSON* garray = cJSON_AddArrayToObject(user_json, \"additionalGids\");\n+    if (garray == NULL) {\n+      goto fail;\n+    }\n+\n+    // first gid entry is the primary group which is accounted for above\n+    int i;\n+    for (i = 1; i < sui->num_gids; ++i) {\n+      cJSON* g = cJSON_CreateNumber(sui->gids[i]);\n+      if (g == NULL) {\n+        goto fail;\n+      }\n+      cJSON_AddItemToArray(garray, g);\n+    }\n+  }\n+\n+  return user_json;\n+\n+fail:\n+  storm_user_info_free(sui);\n+  cJSON_Delete(user_json);\n+  return NULL;\n+}\n+\n+static cJSON* build_runc_config_process(const oci_launch_cmd* olc) {\n+  cJSON* process = cJSON_CreateObject();\n+  if (process == NULL) {\n+    return NULL;", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2MTE4Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550561187", "bodyText": "do we need to adjust any licensing due to this?", "author": "agresch", "createdAt": "2020-12-31T17:02:38Z", "path": "storm-core/src/native/worker-launcher/impl/utils/cJSON.c", "diffHunk": "@@ -0,0 +1,2932 @@\n+/*\n+  Copyright (c) 2009-2017 Dave Gamble and cJSON contributors\n+\n+  Permission is hereby granted, free of charge, to any person obtaining a copy", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTg5MzI5MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671893290", "bodyText": "I don't think so. Hadoop uses this the same way", "author": "Ethanlm", "createdAt": "2021-07-18T20:28:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2MTE4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2MjM3Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550562377", "bodyText": "prepend ERROR to messages here?", "author": "agresch", "createdAt": "2020-12-31T17:04:10Z", "path": "storm-core/src/native/worker-launcher/impl/utils/file-utils.c", "diffHunk": "@@ -0,0 +1,182 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#define FILE_BUFFER_INCREMENT (128*1024)\n+\n+#include <sys/types.h>\n+#include <sys/stat.h>\n+#include <errno.h>\n+#include <fcntl.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <unistd.h>\n+\n+#include \"worker-launcher.h\"\n+#include \"file-utils.h\"\n+\n+/**\n+ * Read the contents of the specified file into an allocated buffer and return\n+ * the contents as a NUL-terminated string. NOTE: The file contents must not\n+ * contain a NUL character or the result will appear to be truncated.\n+ *\n+ * Returns a pointer to the allocated, NUL-terminated string or NULL on error.\n+ */\n+char* read_file_to_string(const char* filename) {\n+  char* buff = NULL;\n+  int rc = -1;\n+  int fd = open(filename, O_RDONLY);\n+  if (fd < 0) {\n+    fprintf(ERRORFILE, \"Error opening %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  struct stat filestat;\n+  if (fstat(fd, &filestat) != 0) {\n+    fprintf(ERRORFILE, \"Error examining %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  size_t buff_size = FILE_BUFFER_INCREMENT;\n+  if (S_ISREG(filestat.st_mode)) {\n+    buff_size = filestat.st_size + 1;  // +1 for terminating NUL\n+  }\n+  buff = malloc(buff_size);\n+  if (buff == NULL) {\n+    fprintf(ERRORFILE, \"Unable to allocate %ld bytes\\n\", buff_size);\n+    goto cleanup;\n+  }\n+\n+  int bytes_left = buff_size;\n+  char* cp = buff;\n+  int bytes_read;\n+  while ((bytes_read = read(fd, cp, bytes_left)) > 0) {\n+    cp += bytes_read;\n+    bytes_left -= bytes_read;\n+    if (bytes_left == 0) {\n+      buff_size += FILE_BUFFER_INCREMENT;\n+      bytes_left += FILE_BUFFER_INCREMENT;\n+      buff = realloc(buff, buff_size);\n+      if (buff == NULL) {\n+        fprintf(ERRORFILE, \"Unable to allocate %ld bytes\\n\", buff_size);\n+        goto cleanup;\n+      }\n+    }\n+  }\n+  if (bytes_left < 0) {\n+    fprintf(ERRORFILE, \"Error reading %s : %s\\n\", filename, strerror(errno));\n+    goto cleanup;\n+  }\n+\n+  *cp = '\\0';\n+  rc = 0;\n+\n+cleanup:\n+  if (fd != -1) {\n+    close(fd);\n+  }\n+  if (rc != 0) {\n+    free(buff);\n+    buff = NULL;\n+  }\n+  return buff;\n+}\n+\n+/**\n+ * Read a file to a string as the worker-launcher user and returns the\n+ * result as a string. See read_file_to_string for more details.\n+ *\n+ * Returns a pointer to the allocated, NUL-terminated string or NULL on error.\n+ */\n+char* read_file_to_string_as_wl_user(const char* filename) {\n+  uid_t user = geteuid();\n+  gid_t group = getegid();\n+  if (change_effective_user_to_wl() != 0) {\n+    fputs(\"Cannot change to worker-launcher user\\n\", ERRORFILE);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2NDI4OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550564288", "bodyText": "seems like this falls outside of string type utils?", "author": "agresch", "createdAt": "2020-12-31T17:06:46Z", "path": "storm-core/src/native/worker-launcher/impl/utils/string-utils.h", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+#ifdef __FreeBSD__\n+#define _WITH_GETLINE\n+#endif\n+\n+#ifndef _UTILS_STRING_UTILS_H_\n+#define _UTILS_STRING_UTILS_H_\n+\n+#include <stdbool.h>\n+#include <stddef.h>\n+\n+typedef struct strbuf_struct {\n+  char* buffer;               // points to beginning of the string\n+  size_t length;              // strlen of buffer (sans trailing NUL)\n+  size_t capacity;            // capacity of the buffer\n+} strbuf;\n+\n+\n+/*\n+ * Validate if the input is a valid container id\n+ * return false/true\n+ */\n+bool validate_container_id(const char* input);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTkyOTEyNw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671929127", "bodyText": "Strictly, yes. Should I move it to oci_launch_cmd.c where it is used?", "author": "Ethanlm", "createdAt": "2021-07-19T01:06:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2NDI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NTE2NTU1Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r675165552", "bodyText": "I would prefer that for cleanliness.", "author": "agresch", "createdAt": "2021-07-22T21:12:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2NDI4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU2OTUxNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550569515", "bodyText": "if for some reason this PR is not committed, this looks like a separate PR that should be addressed to get in", "author": "agresch", "createdAt": "2020-12-31T17:13:25Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/OciContainerManager.java", "diffHunk": "@@ -118,6 +118,8 @@ public void reserveResourcesForWorker(String workerId, Integer workerMemoryMb, I\n     public void releaseResourcesForWorker(String workerId) {\n         workerToCpu.remove(workerId);\n         workerToMemoryMb.remove(workerId);\n+        workerToCores.remove(workerId);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU3NTg1Mg==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550575852", "bodyText": "Is it expected that checkContainersAlive() throw an exception without a message?", "author": "agresch", "createdAt": "2020-12-31T17:21:34Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();\n+    private StormTimer checkContainerAliveTimer;\n+\n+    @Override\n+    public void prepare(Map<String, Object> conf) throws IOException {\n+        super.prepare(conf);\n+\n+        imageTagToManifestPlugin = chooseImageTagToManifestPlugin();\n+        imageTagToManifestPlugin.init(conf);\n+\n+        manifestToResourcesPlugin = chooseManifestToResourcesPlugin();\n+        manifestToResourcesPlugin.init(conf);\n+\n+        ociResourcesLocalizer = chooseOciResourcesLocalizer();\n+        ociResourcesLocalizer.init(conf);\n+\n+        layersToKeep = ObjectReader.getInt(\n+                conf.get(DaemonConfig.STORM_OCI_LAYER_MOUNTS_TO_KEEP),\n+                100\n+        );\n+\n+        mapper = new ObjectMapper();\n+\n+        if (seccompJsonFile != null) {\n+            seccomp = new String(Files.readAllBytes(Paths.get(seccompJsonFile)));\n+        }\n+\n+        if (checkContainerAliveTimer == null) {\n+            checkContainerAliveTimer =\n+                new StormTimer(\"CheckRuncContainerAlive\", Utils.createDefaultUncaughtExceptionHandler());\n+            checkContainerAliveTimer\n+                .scheduleRecurring(0, (Integer) conf.get(DaemonConfig.SUPERVISOR_MONITOR_FREQUENCY_SECS), () -> {\n+                    try {\n+                        checkContainersAlive();\n+                    } catch (Exception e) {\n+                        //Ignore\n+                        LOG.debug(\"The CheckRuncContainerAlive thread has exception. Ignored\", e);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTkyODEyMw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671928123", "bodyText": "changing to warn", "author": "Ethanlm", "createdAt": "2021-07-19T01:00:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU3NTg1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU4NTM1OA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550585358", "bodyText": "looks like it should be \"container for workerId {}\"", "author": "agresch", "createdAt": "2020-12-31T17:33:39Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();\n+    private StormTimer checkContainerAliveTimer;\n+\n+    @Override\n+    public void prepare(Map<String, Object> conf) throws IOException {\n+        super.prepare(conf);\n+\n+        imageTagToManifestPlugin = chooseImageTagToManifestPlugin();\n+        imageTagToManifestPlugin.init(conf);\n+\n+        manifestToResourcesPlugin = chooseManifestToResourcesPlugin();\n+        manifestToResourcesPlugin.init(conf);\n+\n+        ociResourcesLocalizer = chooseOciResourcesLocalizer();\n+        ociResourcesLocalizer.init(conf);\n+\n+        layersToKeep = ObjectReader.getInt(\n+                conf.get(DaemonConfig.STORM_OCI_LAYER_MOUNTS_TO_KEEP),\n+                100\n+        );\n+\n+        mapper = new ObjectMapper();\n+\n+        if (seccompJsonFile != null) {\n+            seccomp = new String(Files.readAllBytes(Paths.get(seccompJsonFile)));\n+        }\n+\n+        if (checkContainerAliveTimer == null) {\n+            checkContainerAliveTimer =\n+                new StormTimer(\"CheckRuncContainerAlive\", Utils.createDefaultUncaughtExceptionHandler());\n+            checkContainerAliveTimer\n+                .scheduleRecurring(0, (Integer) conf.get(DaemonConfig.SUPERVISOR_MONITOR_FREQUENCY_SECS), () -> {\n+                    try {\n+                        checkContainersAlive();\n+                    } catch (Exception e) {\n+                        //Ignore\n+                        LOG.debug(\"The CheckRuncContainerAlive thread has exception. Ignored\", e);\n+                    }\n+                });\n+        }\n+    }\n+\n+    private OciImageTagToManifestPluginInterface chooseImageTagToManifestPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_IMAGE_TAG_TO_MANIFEST_PLUGIN)\n+        );\n+        LOG.info(\"imageTag-to-manifest Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciManifestToResourcesPluginInterface chooseManifestToResourcesPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_MANIFEST_TO_RESOURCES_PLUGIN)\n+        );\n+        LOG.info(\"manifest to resource Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciResourcesLocalizerInterface chooseOciResourcesLocalizer()\n+        throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCALIZER)\n+        );\n+        LOG.info(\"oci resource localizer is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    //the container process ID in the process namespace of the host.\n+    private String containerPidFile(String workerId) {\n+        return ConfigUtils.workerArtifactsSymlink(conf, workerId) + FILE_SEPARATOR + \"container-\" + workerId + \".pid\";\n+    }\n+\n+    @Override\n+    public void launchWorkerProcess(String user, String topologyId,  Map<String, Object> topoConf,\n+                                    int port, String workerId,\n+                                    List<String> command, Map<String, String> env, String logPrefix,\n+                                    ExitCodeCallback processExitCallback, File targetDir) throws IOException {\n+\n+        String imageName = getImageName(topoConf);\n+        if (imageName == null) {\n+            LOG.error(\"Image name for {} is not configured properly; will not continue to launch the worker\", topologyId);\n+            return;\n+        }\n+\n+        //set container ID to port + worker ID\n+        String containerId = getContainerId(workerId, port);\n+\n+        //get manifest\n+        ImageManifest manifest = imageTagToManifestPlugin.getManifestFromImageTag(imageName);\n+        LOG.debug(\"workerId {}: Got manifest: {}\", workerId, manifest.toString());\n+\n+        //get layers metadata\n+        OciResource configResource = manifestToResourcesPlugin.getConfigResource(manifest);\n+        LOG.info(\"workerId {}: Got config metadata: {}\", workerId, configResource.toString());\n+\n+        saveRuncYaml(topologyId, port, containerId, imageName, configResource);\n+\n+        List<OciResource> layersResource = manifestToResourcesPlugin.getLayerResources(manifest);\n+        LOG.info(\"workerId {}: Got layers metadata: {}\", workerId, layersResource.toString());\n+\n+        //localize resource\n+        String configLocalPath = ociResourcesLocalizer.localize(configResource);\n+\n+        List<String> ociEnv = new ArrayList<>();\n+        List<String> args = new ArrayList<>();\n+\n+        ArrayList<OciLayer> layers = new ArrayList<>();\n+\n+        File file = new File(configLocalPath);\n+        //extract env\n+        List<String> imageEnv = extractImageEnv(file);\n+        if (imageEnv != null && !imageEnv.isEmpty()) {\n+            ociEnv.addAll(imageEnv);\n+        }\n+        for (Map.Entry<String, String> entry : env.entrySet()) {\n+            ociEnv.add(entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        LOG.debug(\"workerId {}: ociEnv: {}\", workerId, ociEnv);\n+\n+        //extract entrypoint\n+        List<String> entrypoint = extractImageEntrypoint(file);\n+        if (entrypoint != null && !entrypoint.isEmpty()) {\n+            args.addAll(entrypoint);\n+        }\n+        LOG.debug(\"workerId {}: args: {}\", workerId, args);\n+\n+        //localize layers\n+        List<String> layersLocalPath = ociResourcesLocalizer.localize((layersResource));\n+        //compose layers\n+        for (String layerLocalPath : layersLocalPath) {\n+            OciLayer layer = new OciLayer(SQUASHFS_MEDIA_TYPE, layerLocalPath);\n+            layers.add(layer);\n+        }\n+        LOG.debug(\"workerId {}: layers: {}\", workerId, layers);\n+        ArrayList<OciMount> mounts = new ArrayList<>();\n+        setContainerMounts(mounts, topologyId, workerId, port);\n+        LOG.debug(\"workerId {}: mounts: {}\", workerId, mounts);\n+\n+        //calculate the cpusQuotas based on CPU_CFS_PERIOD and assigned CPU\n+        Long cpusQuotas = null;\n+        if (workerToCpu.containsKey(workerId)) {\n+            cpusQuotas = workerToCpu.get(workerId) * CPU_CFS_PERIOD_US / 100;\n+        }\n+\n+        Long memoryInBytes = null;\n+        if (workerToMemoryMb.containsKey(workerId)) {\n+            memoryInBytes = workerToMemoryMb.get(workerId) * 1024 * 1024L;\n+        }\n+        LOG.info(\"workerId {}: memoryInBytes set to {}; cpusQuotas set to {}\", workerId, memoryInBytes, cpusQuotas);\n+\n+        //<workerRoot>/<workerId>\n+        String workerDir = targetDir.getAbsolutePath();\n+        String workerScriptPath = ServerUtils.writeScript(workerDir, command, env, \"0027\");\n+\n+        args.add(\"bash\");\n+        args.add(workerScriptPath);\n+\n+        //The container PID (on the host) will be written to this file.\n+        String containerPidFilePath = containerPidFile(workerId);\n+\n+        OciProcessConfig processConfig = createOciProcessConfig(workerDir, ociEnv, args);\n+\n+        OciLinuxConfig linuxConfig =\n+            createOciLinuxConfig(cpusQuotas, memoryInBytes, cgroupParent + \"/\" + containerId, seccomp, workerId);\n+\n+        OciRuntimeConfig ociRuntimeConfig = new OciRuntimeConfig(null, mounts, processConfig, null,\n+                                                          null, null, linuxConfig);\n+\n+        OciContainerExecutorConfig ociContainerExecutorConfig =\n+            createOciContainerExecutorConfig(user, containerId, containerPidFilePath,\n+                                             workerScriptPath, null, null, null, layers, ociRuntimeConfig);\n+\n+        //launch the container using worker-launcher\n+        String executorConfigToJsonFile = writeOciExecutorConfigToJsonFile(mapper, ociContainerExecutorConfig, workerDir);\n+        LOG.info(\"workerId {}: oci-config.json file path: {}\", workerId, executorConfigToJsonFile);\n+\n+        List<String> cmdArgs = Arrays.asList(CmdType.RUN_OCI_CONTAINER.toString(), workerDir, executorConfigToJsonFile,\n+                                             ConfigUtils.workerArtifactsSymlink(conf, workerId));\n+\n+        // launch the oci container. waiting prevents possible race condition that could prevent cleanup of container\n+        int exitCode = ClientSupervisorUtils.processLauncherAndWait(conf, user, cmdArgs, env, logPrefix, targetDir);\n+        if (exitCode != 0) {\n+            LOG.error(\"launchWorkerProcess RuncCommand {} exited with code: {}\", \"LaunchWorker-\" + containerId, exitCode);\n+            throw new RuntimeException(\"launchWorkerProcess Failed to create Runc Container. ContainerId: \" + containerId);\n+        }\n+\n+        //Add to the watched list\n+        LOG.debug(\"Adding {} to the watched workers list\", workerId);\n+        workerToExitCallback.put(workerId, processExitCallback);\n+        workerToUser.put(workerId, user);\n+\n+    }\n+\n+    private void checkContainersAlive() {\n+        //Check if all watched workers are still alive\n+        workerToUser.forEach((workerId, user) -> {\n+            if (isContainerDead(workerId, user)) {\n+                invokeProcessExitCallback(workerId);\n+            }\n+        });\n+    }\n+\n+    private boolean isContainerDead(String workerId, String user) {\n+        boolean isDead = true;\n+        Long pid = getContainerPid(workerId);\n+        LOG.debug(\"Checking container {}, pid {}, user {}\", workerId, pid, user);\n+        //do nothing if pid is null.\n+        if (pid != null && user != null) {\n+            try {\n+                isDead = ServerUtils.areAllProcessesDead(conf, user, workerId, Collections.singleton(pid));\n+            } catch (IOException e) {\n+                //ignore\n+                LOG.debug(\"Error while checking if container is dead.\", e);\n+            }\n+        }\n+        return isDead;\n+    }\n+\n+    private void invokeProcessExitCallback(String workerId) {\n+        LOG.info(\"processExitCallback returned for workerId {}\", workerId);\n+        ExitCodeCallback processExitCallback = workerToExitCallback.get(workerId);\n+        if (processExitCallback != null) {\n+            processExitCallback.call(0);\n+        }\n+    }\n+\n+    private String getContainerId(String workerId, int port) throws IOException {\n+        if (port <= 0) { // when killing workers, we will have the workerId and a port of -1\n+            return getContainerIdFromOciJson(workerId);\n+        }\n+        return port + \"-\" + workerId;\n+    }\n+\n+    private String getContainerIdFromOciJson(String workerId) throws IOException {\n+        String ociJson = ConfigUtils.workerRoot(conf, workerId) + FILE_SEPARATOR + OCI_CONFIG_JSON;\n+        LOG.info(\"port unknown for workerId {}, looking up from {}\", workerId, ociJson);\n+        JSONParser parser = new JSONParser();\n+\n+        try (Reader reader = new FileReader(ociJson)) {\n+            JSONObject jsonObject = (JSONObject) parser.parse(reader);\n+            return (String) jsonObject.get(\"containerId\");\n+        } catch (ParseException e) {\n+            throw new IOException(\"Unable to parse {}\", e);\n+        }\n+    }\n+\n+    // save runc.yaml in artifacts dir so we can track which image the worker was launched with\n+    private void saveRuncYaml(String topologyId, int port, String containerId, String imageName, OciResource configResource) {\n+        String fname = String.format(\"runc-%s.yaml\", containerId);\n+        File file = new File(ConfigUtils.workerArtifactsRoot(conf, topologyId, port), fname);\n+        DumperOptions options = new DumperOptions();\n+        options.setIndent(2);\n+        options.setPrettyFlow(true);\n+        options.setDefaultFlowStyle(DumperOptions.FlowStyle.BLOCK);\n+        Yaml yaml = new Yaml(options);\n+        Map<String, Object> data = new HashMap<>();\n+        data.put(\"imageName\", imageName);\n+        data.put(\"manifest\", configResource.getFileName());\n+        data.put(\"configPath\", configResource.getPath());\n+        try (Writer writer = new FileWriter(file)) {\n+            yaml.dump(data, writer);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private String writeOciExecutorConfigToJsonFile(ObjectMapper mapper, OciContainerExecutorConfig ociContainerExecutorConfig,\n+                                                    String workerDir) throws IOException {\n+        File cmdDir = new File(workerDir);\n+        if (!cmdDir.exists()) {\n+            throw new IOException(workerDir + \" doesn't exist\");\n+        }\n+\n+        File commandFile = new File(cmdDir + FILE_SEPARATOR + OCI_CONFIG_JSON);\n+        mapper.writeValue(commandFile, ociContainerExecutorConfig);\n+        return commandFile.getAbsolutePath();\n+    }\n+\n+    private void setContainerMounts(ArrayList<OciMount> mounts, String topologyId, String workerId, Integer port) throws IOException {\n+        //read-only bindmounts need to be added before read-write bindmounts otherwise read-write bindmounts may be overridden.\n+        for (String readonlyMount : readonlyBindmounts) {\n+            addOciMountLocation(mounts, readonlyMount, readonlyMount, false, false);\n+        }\n+\n+        for (String readwriteMount : readwriteBindmounts) {\n+            addOciMountLocation(mounts, readwriteMount, readwriteMount, false, true);\n+        }\n+\n+        addOciMountLocation(mounts, RESOLV_CONF, RESOLV_CONF, false, false);\n+        addOciMountLocation(mounts, HOSTNAME, HOSTNAME, false, false);\n+        addOciMountLocation(mounts, HOSTS, HOSTS, false, false);\n+        addOciMountLocation(mounts, nscdPath, nscdPath, false, false);\n+        addOciMountLocation(mounts, stormHome, stormHome, false, false);\n+        addOciMountLocation(mounts, cgroupRootPath, cgroupRootPath, false, false);\n+\n+        //set of locations to be bind mounted\n+        String supervisorLocalDir = ConfigUtils.supervisorLocalDir(conf);\n+        addOciMountLocation(mounts, supervisorLocalDir, supervisorLocalDir, false, false);\n+\n+        String workerRootDir = ConfigUtils.workerRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerRootDir, workerRootDir, false, true);\n+\n+        String workerArtifactsRoot = ConfigUtils.workerArtifactsRoot(conf, topologyId, port);\n+        addOciMountLocation(mounts, workerArtifactsRoot, workerArtifactsRoot, false, true);\n+\n+        String workerUserFile = ConfigUtils.workerUserFile(conf, workerId);\n+        addOciMountLocation(mounts, workerUserFile, workerUserFile, false, true);\n+\n+        String sharedByTopologyDir = ConfigUtils.sharedByTopologyDir(conf, topologyId);\n+        addOciMountLocation(mounts, sharedByTopologyDir, sharedByTopologyDir, false, true);\n+\n+        String workerTmpRoot = ConfigUtils.workerTmpRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerTmpRoot, TMP_DIR, false, true);\n+    }\n+\n+    private List<String> extractImageEnv(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode envNode = node.path(\"config\").path(\"Env\");\n+        if (envNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(envNode, List.class);\n+    }\n+\n+    private List<String> extractImageEntrypoint(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode entrypointNode = node.path(\"config\").path(\"Entrypoint\");\n+        if (entrypointNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(entrypointNode, List.class);\n+    }\n+\n+    private OciContainerExecutorConfig createOciContainerExecutorConfig(\n+            String username, String containerId, String pidFile,\n+            String containerScriptPath, String containerCredentialsPath,\n+            List<String> localDirs, List<String> logDirs,\n+            List<OciLayer> layers, OciRuntimeConfig ociRuntimeConfig) {\n+\n+        return new OciContainerExecutorConfig(username, containerId,\n+                pidFile, containerScriptPath, containerCredentialsPath,\n+                localDirs, logDirs, layers, layersToKeep, ociRuntimeConfig);\n+    }\n+\n+    private OciProcessConfig createOciProcessConfig(String cwd,\n+                                                    List<String> env, List<String> args) {\n+        return new OciProcessConfig(false, null, cwd, env,\n+                args, null, null, null, true, 0, null, null);\n+    }\n+\n+    private OciLinuxConfig createOciLinuxConfig(Long cpusQuotas, Long memInBytes,\n+                                                String cgroupsPath, String seccomp, String workerId) {\n+        OciLinuxConfig.Resources.Cpu cgroupCpu = null;\n+\n+        if (cpusQuotas != null) {\n+            cgroupCpu = new OciLinuxConfig.Resources.Cpu(0, cpusQuotas, CPU_CFS_PERIOD_US, 0, 0,\n+                    null, null);\n+\n+            if (workerToCores.containsKey(workerId)) {\n+                cgroupCpu.setCpus(StringUtils.join(workerToCores.get(workerId), \",\"));\n+                cgroupCpu.setMems(workerToMemoryZone.get(workerId));\n+            }\n+        }\n+\n+        OciLinuxConfig.Resources.Memory cgroupMem = null;\n+        if (memInBytes != null) {\n+            cgroupMem = new OciLinuxConfig.Resources.Memory(memInBytes, 0, 0, 0, 0, 0, false);\n+        }\n+\n+        OciLinuxConfig.Resources cgroupResources =\n+                new OciLinuxConfig.Resources(null, cgroupMem, cgroupCpu, null, null, null,\n+                        null, null);\n+\n+        return new OciLinuxConfig(null, null, null, null,\n+                cgroupsPath, cgroupResources, null, null, seccomp, null, null,\n+                null, null);\n+    }\n+\n+    private void addOciMountLocation(List<OciMount> mounts, String srcPath,\n+                                     String dstPath, boolean createSource, boolean isReadWrite) throws IOException {\n+        if (!createSource) {\n+            boolean sourceExists = new File(srcPath).exists();\n+            if (!sourceExists) {\n+                throw new IOException(\"SourcePath \" + srcPath + \" doesn't exit\");\n+            }\n+        }\n+\n+        ArrayList<String> options = new ArrayList<>();\n+        if (isReadWrite) {\n+            options.add(\"rw\");\n+        } else {\n+            options.add(\"ro\");\n+        }\n+        options.add(\"rbind\");\n+        options.add(\"rprivate\");\n+        mounts.add(new OciMount(dstPath, \"bind\", srcPath, options));\n+    }\n+\n+    @Override\n+    public long getMemoryUsage(String user, String workerId, int port) throws IOException {\n+        // \"/sys/fs/cgroup/memory/storm/containerId/\"\n+        String containerId = getContainerId(workerId, port);\n+        String memoryCgroupPath = memoryCgroupRootPath + File.separator  + containerId;\n+        MemoryCore memoryCore = new MemoryCore(memoryCgroupPath);\n+        LOG.debug(\"ContainerId {} : Got memory getPhysicalUsage {} from {}\", containerId, memoryCore.getPhysicalUsage(), memoryCgroupPath);\n+        return memoryCore.getPhysicalUsage();\n+    }\n+\n+    @Override\n+    public void kill(String user, String workerId) throws IOException {\n+        LOG.info(\"Killing {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 15, user);\n+        } else {\n+            LOG.warn(\"Trying to kill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    private void signal(long pid, int signal, String user) throws IOException {\n+        List<String> commands = Arrays.asList(\"signal\", String.valueOf(pid), String.valueOf(signal));\n+        String logPrefix = \"kill -\" + signal + \" \" + pid;\n+        ClientSupervisorUtils.processLauncherAndWait(conf, user, commands, null, logPrefix);\n+    }\n+\n+    @Override\n+    public void forceKill(String user, String workerId) throws IOException {\n+        LOG.debug(\"ForceKilling {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 9, user);\n+        } else {\n+            LOG.warn(\"Trying to forceKill container {} but pidfile is not found\", workerId);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU4NzUyNQ==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550587525", "bodyText": "should we release workerToExitCallback?", "author": "agresch", "createdAt": "2020-12-31T17:36:23Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();\n+    private StormTimer checkContainerAliveTimer;\n+\n+    @Override\n+    public void prepare(Map<String, Object> conf) throws IOException {\n+        super.prepare(conf);\n+\n+        imageTagToManifestPlugin = chooseImageTagToManifestPlugin();\n+        imageTagToManifestPlugin.init(conf);\n+\n+        manifestToResourcesPlugin = chooseManifestToResourcesPlugin();\n+        manifestToResourcesPlugin.init(conf);\n+\n+        ociResourcesLocalizer = chooseOciResourcesLocalizer();\n+        ociResourcesLocalizer.init(conf);\n+\n+        layersToKeep = ObjectReader.getInt(\n+                conf.get(DaemonConfig.STORM_OCI_LAYER_MOUNTS_TO_KEEP),\n+                100\n+        );\n+\n+        mapper = new ObjectMapper();\n+\n+        if (seccompJsonFile != null) {\n+            seccomp = new String(Files.readAllBytes(Paths.get(seccompJsonFile)));\n+        }\n+\n+        if (checkContainerAliveTimer == null) {\n+            checkContainerAliveTimer =\n+                new StormTimer(\"CheckRuncContainerAlive\", Utils.createDefaultUncaughtExceptionHandler());\n+            checkContainerAliveTimer\n+                .scheduleRecurring(0, (Integer) conf.get(DaemonConfig.SUPERVISOR_MONITOR_FREQUENCY_SECS), () -> {\n+                    try {\n+                        checkContainersAlive();\n+                    } catch (Exception e) {\n+                        //Ignore\n+                        LOG.debug(\"The CheckRuncContainerAlive thread has exception. Ignored\", e);\n+                    }\n+                });\n+        }\n+    }\n+\n+    private OciImageTagToManifestPluginInterface chooseImageTagToManifestPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_IMAGE_TAG_TO_MANIFEST_PLUGIN)\n+        );\n+        LOG.info(\"imageTag-to-manifest Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciManifestToResourcesPluginInterface chooseManifestToResourcesPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_MANIFEST_TO_RESOURCES_PLUGIN)\n+        );\n+        LOG.info(\"manifest to resource Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciResourcesLocalizerInterface chooseOciResourcesLocalizer()\n+        throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCALIZER)\n+        );\n+        LOG.info(\"oci resource localizer is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    //the container process ID in the process namespace of the host.\n+    private String containerPidFile(String workerId) {\n+        return ConfigUtils.workerArtifactsSymlink(conf, workerId) + FILE_SEPARATOR + \"container-\" + workerId + \".pid\";\n+    }\n+\n+    @Override\n+    public void launchWorkerProcess(String user, String topologyId,  Map<String, Object> topoConf,\n+                                    int port, String workerId,\n+                                    List<String> command, Map<String, String> env, String logPrefix,\n+                                    ExitCodeCallback processExitCallback, File targetDir) throws IOException {\n+\n+        String imageName = getImageName(topoConf);\n+        if (imageName == null) {\n+            LOG.error(\"Image name for {} is not configured properly; will not continue to launch the worker\", topologyId);\n+            return;\n+        }\n+\n+        //set container ID to port + worker ID\n+        String containerId = getContainerId(workerId, port);\n+\n+        //get manifest\n+        ImageManifest manifest = imageTagToManifestPlugin.getManifestFromImageTag(imageName);\n+        LOG.debug(\"workerId {}: Got manifest: {}\", workerId, manifest.toString());\n+\n+        //get layers metadata\n+        OciResource configResource = manifestToResourcesPlugin.getConfigResource(manifest);\n+        LOG.info(\"workerId {}: Got config metadata: {}\", workerId, configResource.toString());\n+\n+        saveRuncYaml(topologyId, port, containerId, imageName, configResource);\n+\n+        List<OciResource> layersResource = manifestToResourcesPlugin.getLayerResources(manifest);\n+        LOG.info(\"workerId {}: Got layers metadata: {}\", workerId, layersResource.toString());\n+\n+        //localize resource\n+        String configLocalPath = ociResourcesLocalizer.localize(configResource);\n+\n+        List<String> ociEnv = new ArrayList<>();\n+        List<String> args = new ArrayList<>();\n+\n+        ArrayList<OciLayer> layers = new ArrayList<>();\n+\n+        File file = new File(configLocalPath);\n+        //extract env\n+        List<String> imageEnv = extractImageEnv(file);\n+        if (imageEnv != null && !imageEnv.isEmpty()) {\n+            ociEnv.addAll(imageEnv);\n+        }\n+        for (Map.Entry<String, String> entry : env.entrySet()) {\n+            ociEnv.add(entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        LOG.debug(\"workerId {}: ociEnv: {}\", workerId, ociEnv);\n+\n+        //extract entrypoint\n+        List<String> entrypoint = extractImageEntrypoint(file);\n+        if (entrypoint != null && !entrypoint.isEmpty()) {\n+            args.addAll(entrypoint);\n+        }\n+        LOG.debug(\"workerId {}: args: {}\", workerId, args);\n+\n+        //localize layers\n+        List<String> layersLocalPath = ociResourcesLocalizer.localize((layersResource));\n+        //compose layers\n+        for (String layerLocalPath : layersLocalPath) {\n+            OciLayer layer = new OciLayer(SQUASHFS_MEDIA_TYPE, layerLocalPath);\n+            layers.add(layer);\n+        }\n+        LOG.debug(\"workerId {}: layers: {}\", workerId, layers);\n+        ArrayList<OciMount> mounts = new ArrayList<>();\n+        setContainerMounts(mounts, topologyId, workerId, port);\n+        LOG.debug(\"workerId {}: mounts: {}\", workerId, mounts);\n+\n+        //calculate the cpusQuotas based on CPU_CFS_PERIOD and assigned CPU\n+        Long cpusQuotas = null;\n+        if (workerToCpu.containsKey(workerId)) {\n+            cpusQuotas = workerToCpu.get(workerId) * CPU_CFS_PERIOD_US / 100;\n+        }\n+\n+        Long memoryInBytes = null;\n+        if (workerToMemoryMb.containsKey(workerId)) {\n+            memoryInBytes = workerToMemoryMb.get(workerId) * 1024 * 1024L;\n+        }\n+        LOG.info(\"workerId {}: memoryInBytes set to {}; cpusQuotas set to {}\", workerId, memoryInBytes, cpusQuotas);\n+\n+        //<workerRoot>/<workerId>\n+        String workerDir = targetDir.getAbsolutePath();\n+        String workerScriptPath = ServerUtils.writeScript(workerDir, command, env, \"0027\");\n+\n+        args.add(\"bash\");\n+        args.add(workerScriptPath);\n+\n+        //The container PID (on the host) will be written to this file.\n+        String containerPidFilePath = containerPidFile(workerId);\n+\n+        OciProcessConfig processConfig = createOciProcessConfig(workerDir, ociEnv, args);\n+\n+        OciLinuxConfig linuxConfig =\n+            createOciLinuxConfig(cpusQuotas, memoryInBytes, cgroupParent + \"/\" + containerId, seccomp, workerId);\n+\n+        OciRuntimeConfig ociRuntimeConfig = new OciRuntimeConfig(null, mounts, processConfig, null,\n+                                                          null, null, linuxConfig);\n+\n+        OciContainerExecutorConfig ociContainerExecutorConfig =\n+            createOciContainerExecutorConfig(user, containerId, containerPidFilePath,\n+                                             workerScriptPath, null, null, null, layers, ociRuntimeConfig);\n+\n+        //launch the container using worker-launcher\n+        String executorConfigToJsonFile = writeOciExecutorConfigToJsonFile(mapper, ociContainerExecutorConfig, workerDir);\n+        LOG.info(\"workerId {}: oci-config.json file path: {}\", workerId, executorConfigToJsonFile);\n+\n+        List<String> cmdArgs = Arrays.asList(CmdType.RUN_OCI_CONTAINER.toString(), workerDir, executorConfigToJsonFile,\n+                                             ConfigUtils.workerArtifactsSymlink(conf, workerId));\n+\n+        // launch the oci container. waiting prevents possible race condition that could prevent cleanup of container\n+        int exitCode = ClientSupervisorUtils.processLauncherAndWait(conf, user, cmdArgs, env, logPrefix, targetDir);\n+        if (exitCode != 0) {\n+            LOG.error(\"launchWorkerProcess RuncCommand {} exited with code: {}\", \"LaunchWorker-\" + containerId, exitCode);\n+            throw new RuntimeException(\"launchWorkerProcess Failed to create Runc Container. ContainerId: \" + containerId);\n+        }\n+\n+        //Add to the watched list\n+        LOG.debug(\"Adding {} to the watched workers list\", workerId);\n+        workerToExitCallback.put(workerId, processExitCallback);\n+        workerToUser.put(workerId, user);\n+\n+    }\n+\n+    private void checkContainersAlive() {\n+        //Check if all watched workers are still alive\n+        workerToUser.forEach((workerId, user) -> {\n+            if (isContainerDead(workerId, user)) {\n+                invokeProcessExitCallback(workerId);\n+            }\n+        });\n+    }\n+\n+    private boolean isContainerDead(String workerId, String user) {\n+        boolean isDead = true;\n+        Long pid = getContainerPid(workerId);\n+        LOG.debug(\"Checking container {}, pid {}, user {}\", workerId, pid, user);\n+        //do nothing if pid is null.\n+        if (pid != null && user != null) {\n+            try {\n+                isDead = ServerUtils.areAllProcessesDead(conf, user, workerId, Collections.singleton(pid));\n+            } catch (IOException e) {\n+                //ignore\n+                LOG.debug(\"Error while checking if container is dead.\", e);\n+            }\n+        }\n+        return isDead;\n+    }\n+\n+    private void invokeProcessExitCallback(String workerId) {\n+        LOG.info(\"processExitCallback returned for workerId {}\", workerId);\n+        ExitCodeCallback processExitCallback = workerToExitCallback.get(workerId);\n+        if (processExitCallback != null) {\n+            processExitCallback.call(0);\n+        }\n+    }\n+\n+    private String getContainerId(String workerId, int port) throws IOException {\n+        if (port <= 0) { // when killing workers, we will have the workerId and a port of -1\n+            return getContainerIdFromOciJson(workerId);\n+        }\n+        return port + \"-\" + workerId;\n+    }\n+\n+    private String getContainerIdFromOciJson(String workerId) throws IOException {\n+        String ociJson = ConfigUtils.workerRoot(conf, workerId) + FILE_SEPARATOR + OCI_CONFIG_JSON;\n+        LOG.info(\"port unknown for workerId {}, looking up from {}\", workerId, ociJson);\n+        JSONParser parser = new JSONParser();\n+\n+        try (Reader reader = new FileReader(ociJson)) {\n+            JSONObject jsonObject = (JSONObject) parser.parse(reader);\n+            return (String) jsonObject.get(\"containerId\");\n+        } catch (ParseException e) {\n+            throw new IOException(\"Unable to parse {}\", e);\n+        }\n+    }\n+\n+    // save runc.yaml in artifacts dir so we can track which image the worker was launched with\n+    private void saveRuncYaml(String topologyId, int port, String containerId, String imageName, OciResource configResource) {\n+        String fname = String.format(\"runc-%s.yaml\", containerId);\n+        File file = new File(ConfigUtils.workerArtifactsRoot(conf, topologyId, port), fname);\n+        DumperOptions options = new DumperOptions();\n+        options.setIndent(2);\n+        options.setPrettyFlow(true);\n+        options.setDefaultFlowStyle(DumperOptions.FlowStyle.BLOCK);\n+        Yaml yaml = new Yaml(options);\n+        Map<String, Object> data = new HashMap<>();\n+        data.put(\"imageName\", imageName);\n+        data.put(\"manifest\", configResource.getFileName());\n+        data.put(\"configPath\", configResource.getPath());\n+        try (Writer writer = new FileWriter(file)) {\n+            yaml.dump(data, writer);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private String writeOciExecutorConfigToJsonFile(ObjectMapper mapper, OciContainerExecutorConfig ociContainerExecutorConfig,\n+                                                    String workerDir) throws IOException {\n+        File cmdDir = new File(workerDir);\n+        if (!cmdDir.exists()) {\n+            throw new IOException(workerDir + \" doesn't exist\");\n+        }\n+\n+        File commandFile = new File(cmdDir + FILE_SEPARATOR + OCI_CONFIG_JSON);\n+        mapper.writeValue(commandFile, ociContainerExecutorConfig);\n+        return commandFile.getAbsolutePath();\n+    }\n+\n+    private void setContainerMounts(ArrayList<OciMount> mounts, String topologyId, String workerId, Integer port) throws IOException {\n+        //read-only bindmounts need to be added before read-write bindmounts otherwise read-write bindmounts may be overridden.\n+        for (String readonlyMount : readonlyBindmounts) {\n+            addOciMountLocation(mounts, readonlyMount, readonlyMount, false, false);\n+        }\n+\n+        for (String readwriteMount : readwriteBindmounts) {\n+            addOciMountLocation(mounts, readwriteMount, readwriteMount, false, true);\n+        }\n+\n+        addOciMountLocation(mounts, RESOLV_CONF, RESOLV_CONF, false, false);\n+        addOciMountLocation(mounts, HOSTNAME, HOSTNAME, false, false);\n+        addOciMountLocation(mounts, HOSTS, HOSTS, false, false);\n+        addOciMountLocation(mounts, nscdPath, nscdPath, false, false);\n+        addOciMountLocation(mounts, stormHome, stormHome, false, false);\n+        addOciMountLocation(mounts, cgroupRootPath, cgroupRootPath, false, false);\n+\n+        //set of locations to be bind mounted\n+        String supervisorLocalDir = ConfigUtils.supervisorLocalDir(conf);\n+        addOciMountLocation(mounts, supervisorLocalDir, supervisorLocalDir, false, false);\n+\n+        String workerRootDir = ConfigUtils.workerRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerRootDir, workerRootDir, false, true);\n+\n+        String workerArtifactsRoot = ConfigUtils.workerArtifactsRoot(conf, topologyId, port);\n+        addOciMountLocation(mounts, workerArtifactsRoot, workerArtifactsRoot, false, true);\n+\n+        String workerUserFile = ConfigUtils.workerUserFile(conf, workerId);\n+        addOciMountLocation(mounts, workerUserFile, workerUserFile, false, true);\n+\n+        String sharedByTopologyDir = ConfigUtils.sharedByTopologyDir(conf, topologyId);\n+        addOciMountLocation(mounts, sharedByTopologyDir, sharedByTopologyDir, false, true);\n+\n+        String workerTmpRoot = ConfigUtils.workerTmpRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerTmpRoot, TMP_DIR, false, true);\n+    }\n+\n+    private List<String> extractImageEnv(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode envNode = node.path(\"config\").path(\"Env\");\n+        if (envNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(envNode, List.class);\n+    }\n+\n+    private List<String> extractImageEntrypoint(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode entrypointNode = node.path(\"config\").path(\"Entrypoint\");\n+        if (entrypointNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(entrypointNode, List.class);\n+    }\n+\n+    private OciContainerExecutorConfig createOciContainerExecutorConfig(\n+            String username, String containerId, String pidFile,\n+            String containerScriptPath, String containerCredentialsPath,\n+            List<String> localDirs, List<String> logDirs,\n+            List<OciLayer> layers, OciRuntimeConfig ociRuntimeConfig) {\n+\n+        return new OciContainerExecutorConfig(username, containerId,\n+                pidFile, containerScriptPath, containerCredentialsPath,\n+                localDirs, logDirs, layers, layersToKeep, ociRuntimeConfig);\n+    }\n+\n+    private OciProcessConfig createOciProcessConfig(String cwd,\n+                                                    List<String> env, List<String> args) {\n+        return new OciProcessConfig(false, null, cwd, env,\n+                args, null, null, null, true, 0, null, null);\n+    }\n+\n+    private OciLinuxConfig createOciLinuxConfig(Long cpusQuotas, Long memInBytes,\n+                                                String cgroupsPath, String seccomp, String workerId) {\n+        OciLinuxConfig.Resources.Cpu cgroupCpu = null;\n+\n+        if (cpusQuotas != null) {\n+            cgroupCpu = new OciLinuxConfig.Resources.Cpu(0, cpusQuotas, CPU_CFS_PERIOD_US, 0, 0,\n+                    null, null);\n+\n+            if (workerToCores.containsKey(workerId)) {\n+                cgroupCpu.setCpus(StringUtils.join(workerToCores.get(workerId), \",\"));\n+                cgroupCpu.setMems(workerToMemoryZone.get(workerId));\n+            }\n+        }\n+\n+        OciLinuxConfig.Resources.Memory cgroupMem = null;\n+        if (memInBytes != null) {\n+            cgroupMem = new OciLinuxConfig.Resources.Memory(memInBytes, 0, 0, 0, 0, 0, false);\n+        }\n+\n+        OciLinuxConfig.Resources cgroupResources =\n+                new OciLinuxConfig.Resources(null, cgroupMem, cgroupCpu, null, null, null,\n+                        null, null);\n+\n+        return new OciLinuxConfig(null, null, null, null,\n+                cgroupsPath, cgroupResources, null, null, seccomp, null, null,\n+                null, null);\n+    }\n+\n+    private void addOciMountLocation(List<OciMount> mounts, String srcPath,\n+                                     String dstPath, boolean createSource, boolean isReadWrite) throws IOException {\n+        if (!createSource) {\n+            boolean sourceExists = new File(srcPath).exists();\n+            if (!sourceExists) {\n+                throw new IOException(\"SourcePath \" + srcPath + \" doesn't exit\");\n+            }\n+        }\n+\n+        ArrayList<String> options = new ArrayList<>();\n+        if (isReadWrite) {\n+            options.add(\"rw\");\n+        } else {\n+            options.add(\"ro\");\n+        }\n+        options.add(\"rbind\");\n+        options.add(\"rprivate\");\n+        mounts.add(new OciMount(dstPath, \"bind\", srcPath, options));\n+    }\n+\n+    @Override\n+    public long getMemoryUsage(String user, String workerId, int port) throws IOException {\n+        // \"/sys/fs/cgroup/memory/storm/containerId/\"\n+        String containerId = getContainerId(workerId, port);\n+        String memoryCgroupPath = memoryCgroupRootPath + File.separator  + containerId;\n+        MemoryCore memoryCore = new MemoryCore(memoryCgroupPath);\n+        LOG.debug(\"ContainerId {} : Got memory getPhysicalUsage {} from {}\", containerId, memoryCore.getPhysicalUsage(), memoryCgroupPath);\n+        return memoryCore.getPhysicalUsage();\n+    }\n+\n+    @Override\n+    public void kill(String user, String workerId) throws IOException {\n+        LOG.info(\"Killing {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 15, user);\n+        } else {\n+            LOG.warn(\"Trying to kill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    private void signal(long pid, int signal, String user) throws IOException {\n+        List<String> commands = Arrays.asList(\"signal\", String.valueOf(pid), String.valueOf(signal));\n+        String logPrefix = \"kill -\" + signal + \" \" + pid;\n+        ClientSupervisorUtils.processLauncherAndWait(conf, user, commands, null, logPrefix);\n+    }\n+\n+    @Override\n+    public void forceKill(String user, String workerId) throws IOException {\n+        LOG.debug(\"ForceKilling {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 9, user);\n+        } else {\n+            LOG.warn(\"Trying to forceKill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    // return null if not found.\n+    private Long getContainerPid(String workerId) {\n+        Long pid = workerToContainerPid.get(workerId);\n+        if (pid == null) {\n+            String containerPidFilePath = containerPidFile(workerId);\n+            if (!new File(containerPidFilePath).exists()) {\n+                LOG.warn(\"{} doesn't exist\", containerPidFilePath);\n+            } else {\n+                try {\n+                    pid = Long.parseLong(CgroupUtils.readFileByLine(containerPidFilePath).get(0));\n+                    workerToContainerPid.put(workerId, pid);\n+                } catch (IOException e) {\n+                    LOG.warn(\"failed to read {}\", containerPidFilePath);\n+                }\n+            }\n+        }\n+        return pid;\n+    }\n+\n+    @Override\n+    public void releaseResourcesForWorker(String workerId) {\n+        super.releaseResourcesForWorker(workerId);\n+        workerToContainerPid.remove(workerId);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTg5NjE1MA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671896150", "bodyText": "yes it is done in cleanup.\nMoving workerToContainerPid.remove(workerId); to cleanup as it makes more sense to me", "author": "Ethanlm", "createdAt": "2021-07-18T20:53:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU4NzUyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU4ODk5Nw==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550588997", "bodyText": "call releaseResourcesForWorker() instead?\nIt looks like releaseResourcesForWorker() is called before cleanup() already.\nDo we need both?\nI didn't see a javadoc for cleanup().  I'm fuzzy on the difference.  I am all for combining into one if we can.", "author": "agresch", "createdAt": "2020-12-31T17:38:22Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();\n+    private StormTimer checkContainerAliveTimer;\n+\n+    @Override\n+    public void prepare(Map<String, Object> conf) throws IOException {\n+        super.prepare(conf);\n+\n+        imageTagToManifestPlugin = chooseImageTagToManifestPlugin();\n+        imageTagToManifestPlugin.init(conf);\n+\n+        manifestToResourcesPlugin = chooseManifestToResourcesPlugin();\n+        manifestToResourcesPlugin.init(conf);\n+\n+        ociResourcesLocalizer = chooseOciResourcesLocalizer();\n+        ociResourcesLocalizer.init(conf);\n+\n+        layersToKeep = ObjectReader.getInt(\n+                conf.get(DaemonConfig.STORM_OCI_LAYER_MOUNTS_TO_KEEP),\n+                100\n+        );\n+\n+        mapper = new ObjectMapper();\n+\n+        if (seccompJsonFile != null) {\n+            seccomp = new String(Files.readAllBytes(Paths.get(seccompJsonFile)));\n+        }\n+\n+        if (checkContainerAliveTimer == null) {\n+            checkContainerAliveTimer =\n+                new StormTimer(\"CheckRuncContainerAlive\", Utils.createDefaultUncaughtExceptionHandler());\n+            checkContainerAliveTimer\n+                .scheduleRecurring(0, (Integer) conf.get(DaemonConfig.SUPERVISOR_MONITOR_FREQUENCY_SECS), () -> {\n+                    try {\n+                        checkContainersAlive();\n+                    } catch (Exception e) {\n+                        //Ignore\n+                        LOG.debug(\"The CheckRuncContainerAlive thread has exception. Ignored\", e);\n+                    }\n+                });\n+        }\n+    }\n+\n+    private OciImageTagToManifestPluginInterface chooseImageTagToManifestPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_IMAGE_TAG_TO_MANIFEST_PLUGIN)\n+        );\n+        LOG.info(\"imageTag-to-manifest Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciManifestToResourcesPluginInterface chooseManifestToResourcesPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_MANIFEST_TO_RESOURCES_PLUGIN)\n+        );\n+        LOG.info(\"manifest to resource Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciResourcesLocalizerInterface chooseOciResourcesLocalizer()\n+        throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCALIZER)\n+        );\n+        LOG.info(\"oci resource localizer is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    //the container process ID in the process namespace of the host.\n+    private String containerPidFile(String workerId) {\n+        return ConfigUtils.workerArtifactsSymlink(conf, workerId) + FILE_SEPARATOR + \"container-\" + workerId + \".pid\";\n+    }\n+\n+    @Override\n+    public void launchWorkerProcess(String user, String topologyId,  Map<String, Object> topoConf,\n+                                    int port, String workerId,\n+                                    List<String> command, Map<String, String> env, String logPrefix,\n+                                    ExitCodeCallback processExitCallback, File targetDir) throws IOException {\n+\n+        String imageName = getImageName(topoConf);\n+        if (imageName == null) {\n+            LOG.error(\"Image name for {} is not configured properly; will not continue to launch the worker\", topologyId);\n+            return;\n+        }\n+\n+        //set container ID to port + worker ID\n+        String containerId = getContainerId(workerId, port);\n+\n+        //get manifest\n+        ImageManifest manifest = imageTagToManifestPlugin.getManifestFromImageTag(imageName);\n+        LOG.debug(\"workerId {}: Got manifest: {}\", workerId, manifest.toString());\n+\n+        //get layers metadata\n+        OciResource configResource = manifestToResourcesPlugin.getConfigResource(manifest);\n+        LOG.info(\"workerId {}: Got config metadata: {}\", workerId, configResource.toString());\n+\n+        saveRuncYaml(topologyId, port, containerId, imageName, configResource);\n+\n+        List<OciResource> layersResource = manifestToResourcesPlugin.getLayerResources(manifest);\n+        LOG.info(\"workerId {}: Got layers metadata: {}\", workerId, layersResource.toString());\n+\n+        //localize resource\n+        String configLocalPath = ociResourcesLocalizer.localize(configResource);\n+\n+        List<String> ociEnv = new ArrayList<>();\n+        List<String> args = new ArrayList<>();\n+\n+        ArrayList<OciLayer> layers = new ArrayList<>();\n+\n+        File file = new File(configLocalPath);\n+        //extract env\n+        List<String> imageEnv = extractImageEnv(file);\n+        if (imageEnv != null && !imageEnv.isEmpty()) {\n+            ociEnv.addAll(imageEnv);\n+        }\n+        for (Map.Entry<String, String> entry : env.entrySet()) {\n+            ociEnv.add(entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        LOG.debug(\"workerId {}: ociEnv: {}\", workerId, ociEnv);\n+\n+        //extract entrypoint\n+        List<String> entrypoint = extractImageEntrypoint(file);\n+        if (entrypoint != null && !entrypoint.isEmpty()) {\n+            args.addAll(entrypoint);\n+        }\n+        LOG.debug(\"workerId {}: args: {}\", workerId, args);\n+\n+        //localize layers\n+        List<String> layersLocalPath = ociResourcesLocalizer.localize((layersResource));\n+        //compose layers\n+        for (String layerLocalPath : layersLocalPath) {\n+            OciLayer layer = new OciLayer(SQUASHFS_MEDIA_TYPE, layerLocalPath);\n+            layers.add(layer);\n+        }\n+        LOG.debug(\"workerId {}: layers: {}\", workerId, layers);\n+        ArrayList<OciMount> mounts = new ArrayList<>();\n+        setContainerMounts(mounts, topologyId, workerId, port);\n+        LOG.debug(\"workerId {}: mounts: {}\", workerId, mounts);\n+\n+        //calculate the cpusQuotas based on CPU_CFS_PERIOD and assigned CPU\n+        Long cpusQuotas = null;\n+        if (workerToCpu.containsKey(workerId)) {\n+            cpusQuotas = workerToCpu.get(workerId) * CPU_CFS_PERIOD_US / 100;\n+        }\n+\n+        Long memoryInBytes = null;\n+        if (workerToMemoryMb.containsKey(workerId)) {\n+            memoryInBytes = workerToMemoryMb.get(workerId) * 1024 * 1024L;\n+        }\n+        LOG.info(\"workerId {}: memoryInBytes set to {}; cpusQuotas set to {}\", workerId, memoryInBytes, cpusQuotas);\n+\n+        //<workerRoot>/<workerId>\n+        String workerDir = targetDir.getAbsolutePath();\n+        String workerScriptPath = ServerUtils.writeScript(workerDir, command, env, \"0027\");\n+\n+        args.add(\"bash\");\n+        args.add(workerScriptPath);\n+\n+        //The container PID (on the host) will be written to this file.\n+        String containerPidFilePath = containerPidFile(workerId);\n+\n+        OciProcessConfig processConfig = createOciProcessConfig(workerDir, ociEnv, args);\n+\n+        OciLinuxConfig linuxConfig =\n+            createOciLinuxConfig(cpusQuotas, memoryInBytes, cgroupParent + \"/\" + containerId, seccomp, workerId);\n+\n+        OciRuntimeConfig ociRuntimeConfig = new OciRuntimeConfig(null, mounts, processConfig, null,\n+                                                          null, null, linuxConfig);\n+\n+        OciContainerExecutorConfig ociContainerExecutorConfig =\n+            createOciContainerExecutorConfig(user, containerId, containerPidFilePath,\n+                                             workerScriptPath, null, null, null, layers, ociRuntimeConfig);\n+\n+        //launch the container using worker-launcher\n+        String executorConfigToJsonFile = writeOciExecutorConfigToJsonFile(mapper, ociContainerExecutorConfig, workerDir);\n+        LOG.info(\"workerId {}: oci-config.json file path: {}\", workerId, executorConfigToJsonFile);\n+\n+        List<String> cmdArgs = Arrays.asList(CmdType.RUN_OCI_CONTAINER.toString(), workerDir, executorConfigToJsonFile,\n+                                             ConfigUtils.workerArtifactsSymlink(conf, workerId));\n+\n+        // launch the oci container. waiting prevents possible race condition that could prevent cleanup of container\n+        int exitCode = ClientSupervisorUtils.processLauncherAndWait(conf, user, cmdArgs, env, logPrefix, targetDir);\n+        if (exitCode != 0) {\n+            LOG.error(\"launchWorkerProcess RuncCommand {} exited with code: {}\", \"LaunchWorker-\" + containerId, exitCode);\n+            throw new RuntimeException(\"launchWorkerProcess Failed to create Runc Container. ContainerId: \" + containerId);\n+        }\n+\n+        //Add to the watched list\n+        LOG.debug(\"Adding {} to the watched workers list\", workerId);\n+        workerToExitCallback.put(workerId, processExitCallback);\n+        workerToUser.put(workerId, user);\n+\n+    }\n+\n+    private void checkContainersAlive() {\n+        //Check if all watched workers are still alive\n+        workerToUser.forEach((workerId, user) -> {\n+            if (isContainerDead(workerId, user)) {\n+                invokeProcessExitCallback(workerId);\n+            }\n+        });\n+    }\n+\n+    private boolean isContainerDead(String workerId, String user) {\n+        boolean isDead = true;\n+        Long pid = getContainerPid(workerId);\n+        LOG.debug(\"Checking container {}, pid {}, user {}\", workerId, pid, user);\n+        //do nothing if pid is null.\n+        if (pid != null && user != null) {\n+            try {\n+                isDead = ServerUtils.areAllProcessesDead(conf, user, workerId, Collections.singleton(pid));\n+            } catch (IOException e) {\n+                //ignore\n+                LOG.debug(\"Error while checking if container is dead.\", e);\n+            }\n+        }\n+        return isDead;\n+    }\n+\n+    private void invokeProcessExitCallback(String workerId) {\n+        LOG.info(\"processExitCallback returned for workerId {}\", workerId);\n+        ExitCodeCallback processExitCallback = workerToExitCallback.get(workerId);\n+        if (processExitCallback != null) {\n+            processExitCallback.call(0);\n+        }\n+    }\n+\n+    private String getContainerId(String workerId, int port) throws IOException {\n+        if (port <= 0) { // when killing workers, we will have the workerId and a port of -1\n+            return getContainerIdFromOciJson(workerId);\n+        }\n+        return port + \"-\" + workerId;\n+    }\n+\n+    private String getContainerIdFromOciJson(String workerId) throws IOException {\n+        String ociJson = ConfigUtils.workerRoot(conf, workerId) + FILE_SEPARATOR + OCI_CONFIG_JSON;\n+        LOG.info(\"port unknown for workerId {}, looking up from {}\", workerId, ociJson);\n+        JSONParser parser = new JSONParser();\n+\n+        try (Reader reader = new FileReader(ociJson)) {\n+            JSONObject jsonObject = (JSONObject) parser.parse(reader);\n+            return (String) jsonObject.get(\"containerId\");\n+        } catch (ParseException e) {\n+            throw new IOException(\"Unable to parse {}\", e);\n+        }\n+    }\n+\n+    // save runc.yaml in artifacts dir so we can track which image the worker was launched with\n+    private void saveRuncYaml(String topologyId, int port, String containerId, String imageName, OciResource configResource) {\n+        String fname = String.format(\"runc-%s.yaml\", containerId);\n+        File file = new File(ConfigUtils.workerArtifactsRoot(conf, topologyId, port), fname);\n+        DumperOptions options = new DumperOptions();\n+        options.setIndent(2);\n+        options.setPrettyFlow(true);\n+        options.setDefaultFlowStyle(DumperOptions.FlowStyle.BLOCK);\n+        Yaml yaml = new Yaml(options);\n+        Map<String, Object> data = new HashMap<>();\n+        data.put(\"imageName\", imageName);\n+        data.put(\"manifest\", configResource.getFileName());\n+        data.put(\"configPath\", configResource.getPath());\n+        try (Writer writer = new FileWriter(file)) {\n+            yaml.dump(data, writer);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private String writeOciExecutorConfigToJsonFile(ObjectMapper mapper, OciContainerExecutorConfig ociContainerExecutorConfig,\n+                                                    String workerDir) throws IOException {\n+        File cmdDir = new File(workerDir);\n+        if (!cmdDir.exists()) {\n+            throw new IOException(workerDir + \" doesn't exist\");\n+        }\n+\n+        File commandFile = new File(cmdDir + FILE_SEPARATOR + OCI_CONFIG_JSON);\n+        mapper.writeValue(commandFile, ociContainerExecutorConfig);\n+        return commandFile.getAbsolutePath();\n+    }\n+\n+    private void setContainerMounts(ArrayList<OciMount> mounts, String topologyId, String workerId, Integer port) throws IOException {\n+        //read-only bindmounts need to be added before read-write bindmounts otherwise read-write bindmounts may be overridden.\n+        for (String readonlyMount : readonlyBindmounts) {\n+            addOciMountLocation(mounts, readonlyMount, readonlyMount, false, false);\n+        }\n+\n+        for (String readwriteMount : readwriteBindmounts) {\n+            addOciMountLocation(mounts, readwriteMount, readwriteMount, false, true);\n+        }\n+\n+        addOciMountLocation(mounts, RESOLV_CONF, RESOLV_CONF, false, false);\n+        addOciMountLocation(mounts, HOSTNAME, HOSTNAME, false, false);\n+        addOciMountLocation(mounts, HOSTS, HOSTS, false, false);\n+        addOciMountLocation(mounts, nscdPath, nscdPath, false, false);\n+        addOciMountLocation(mounts, stormHome, stormHome, false, false);\n+        addOciMountLocation(mounts, cgroupRootPath, cgroupRootPath, false, false);\n+\n+        //set of locations to be bind mounted\n+        String supervisorLocalDir = ConfigUtils.supervisorLocalDir(conf);\n+        addOciMountLocation(mounts, supervisorLocalDir, supervisorLocalDir, false, false);\n+\n+        String workerRootDir = ConfigUtils.workerRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerRootDir, workerRootDir, false, true);\n+\n+        String workerArtifactsRoot = ConfigUtils.workerArtifactsRoot(conf, topologyId, port);\n+        addOciMountLocation(mounts, workerArtifactsRoot, workerArtifactsRoot, false, true);\n+\n+        String workerUserFile = ConfigUtils.workerUserFile(conf, workerId);\n+        addOciMountLocation(mounts, workerUserFile, workerUserFile, false, true);\n+\n+        String sharedByTopologyDir = ConfigUtils.sharedByTopologyDir(conf, topologyId);\n+        addOciMountLocation(mounts, sharedByTopologyDir, sharedByTopologyDir, false, true);\n+\n+        String workerTmpRoot = ConfigUtils.workerTmpRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerTmpRoot, TMP_DIR, false, true);\n+    }\n+\n+    private List<String> extractImageEnv(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode envNode = node.path(\"config\").path(\"Env\");\n+        if (envNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(envNode, List.class);\n+    }\n+\n+    private List<String> extractImageEntrypoint(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode entrypointNode = node.path(\"config\").path(\"Entrypoint\");\n+        if (entrypointNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(entrypointNode, List.class);\n+    }\n+\n+    private OciContainerExecutorConfig createOciContainerExecutorConfig(\n+            String username, String containerId, String pidFile,\n+            String containerScriptPath, String containerCredentialsPath,\n+            List<String> localDirs, List<String> logDirs,\n+            List<OciLayer> layers, OciRuntimeConfig ociRuntimeConfig) {\n+\n+        return new OciContainerExecutorConfig(username, containerId,\n+                pidFile, containerScriptPath, containerCredentialsPath,\n+                localDirs, logDirs, layers, layersToKeep, ociRuntimeConfig);\n+    }\n+\n+    private OciProcessConfig createOciProcessConfig(String cwd,\n+                                                    List<String> env, List<String> args) {\n+        return new OciProcessConfig(false, null, cwd, env,\n+                args, null, null, null, true, 0, null, null);\n+    }\n+\n+    private OciLinuxConfig createOciLinuxConfig(Long cpusQuotas, Long memInBytes,\n+                                                String cgroupsPath, String seccomp, String workerId) {\n+        OciLinuxConfig.Resources.Cpu cgroupCpu = null;\n+\n+        if (cpusQuotas != null) {\n+            cgroupCpu = new OciLinuxConfig.Resources.Cpu(0, cpusQuotas, CPU_CFS_PERIOD_US, 0, 0,\n+                    null, null);\n+\n+            if (workerToCores.containsKey(workerId)) {\n+                cgroupCpu.setCpus(StringUtils.join(workerToCores.get(workerId), \",\"));\n+                cgroupCpu.setMems(workerToMemoryZone.get(workerId));\n+            }\n+        }\n+\n+        OciLinuxConfig.Resources.Memory cgroupMem = null;\n+        if (memInBytes != null) {\n+            cgroupMem = new OciLinuxConfig.Resources.Memory(memInBytes, 0, 0, 0, 0, 0, false);\n+        }\n+\n+        OciLinuxConfig.Resources cgroupResources =\n+                new OciLinuxConfig.Resources(null, cgroupMem, cgroupCpu, null, null, null,\n+                        null, null);\n+\n+        return new OciLinuxConfig(null, null, null, null,\n+                cgroupsPath, cgroupResources, null, null, seccomp, null, null,\n+                null, null);\n+    }\n+\n+    private void addOciMountLocation(List<OciMount> mounts, String srcPath,\n+                                     String dstPath, boolean createSource, boolean isReadWrite) throws IOException {\n+        if (!createSource) {\n+            boolean sourceExists = new File(srcPath).exists();\n+            if (!sourceExists) {\n+                throw new IOException(\"SourcePath \" + srcPath + \" doesn't exit\");\n+            }\n+        }\n+\n+        ArrayList<String> options = new ArrayList<>();\n+        if (isReadWrite) {\n+            options.add(\"rw\");\n+        } else {\n+            options.add(\"ro\");\n+        }\n+        options.add(\"rbind\");\n+        options.add(\"rprivate\");\n+        mounts.add(new OciMount(dstPath, \"bind\", srcPath, options));\n+    }\n+\n+    @Override\n+    public long getMemoryUsage(String user, String workerId, int port) throws IOException {\n+        // \"/sys/fs/cgroup/memory/storm/containerId/\"\n+        String containerId = getContainerId(workerId, port);\n+        String memoryCgroupPath = memoryCgroupRootPath + File.separator  + containerId;\n+        MemoryCore memoryCore = new MemoryCore(memoryCgroupPath);\n+        LOG.debug(\"ContainerId {} : Got memory getPhysicalUsage {} from {}\", containerId, memoryCore.getPhysicalUsage(), memoryCgroupPath);\n+        return memoryCore.getPhysicalUsage();\n+    }\n+\n+    @Override\n+    public void kill(String user, String workerId) throws IOException {\n+        LOG.info(\"Killing {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 15, user);\n+        } else {\n+            LOG.warn(\"Trying to kill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    private void signal(long pid, int signal, String user) throws IOException {\n+        List<String> commands = Arrays.asList(\"signal\", String.valueOf(pid), String.valueOf(signal));\n+        String logPrefix = \"kill -\" + signal + \" \" + pid;\n+        ClientSupervisorUtils.processLauncherAndWait(conf, user, commands, null, logPrefix);\n+    }\n+\n+    @Override\n+    public void forceKill(String user, String workerId) throws IOException {\n+        LOG.debug(\"ForceKilling {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 9, user);\n+        } else {\n+            LOG.warn(\"Trying to forceKill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    // return null if not found.\n+    private Long getContainerPid(String workerId) {\n+        Long pid = workerToContainerPid.get(workerId);\n+        if (pid == null) {\n+            String containerPidFilePath = containerPidFile(workerId);\n+            if (!new File(containerPidFilePath).exists()) {\n+                LOG.warn(\"{} doesn't exist\", containerPidFilePath);\n+            } else {\n+                try {\n+                    pid = Long.parseLong(CgroupUtils.readFileByLine(containerPidFilePath).get(0));\n+                    workerToContainerPid.put(workerId, pid);\n+                } catch (IOException e) {\n+                    LOG.warn(\"failed to read {}\", containerPidFilePath);\n+                }\n+            }\n+        }\n+        return pid;\n+    }\n+\n+    @Override\n+    public void releaseResourcesForWorker(String workerId) {\n+        super.releaseResourcesForWorker(workerId);\n+        workerToContainerPid.remove(workerId);\n+    }\n+\n+    /**\n+     * The container terminates if any process inside the container dies.\n+     * So we only need to check if the initial process is alive or not.\n+     * @param user the user that the processes are running as\n+     * @param workerId the id of the worker to kill\n+     * @return true if all processes are dead; false otherwise\n+     * @throws IOException on I/O exception\n+     */\n+    @Override\n+    public boolean areAllProcessesDead(String user, String workerId) throws IOException {\n+        boolean areAllDead = isContainerDead(workerId, user);\n+        LOG.debug(\"WorkerId {}: Checking areAllProcessesDead: {}\", workerId, areAllDead);\n+        return areAllDead;\n+    }\n+\n+    @Override\n+    public void cleanup(String user, String workerId, int port) throws IOException {\n+        LOG.debug(\"clean up worker {}\", workerId);\n+        try {\n+            String containerId = getContainerId(workerId, port);\n+            List<String> commands = Arrays.asList(CmdType.REAP_OCI_CONTAINER.toString(), containerId, String.valueOf(layersToKeep));\n+            String logPrefix = \"Worker Process \" + workerId;\n+            int result = ClientSupervisorUtils.processLauncherAndWait(conf, user, commands, null, logPrefix);\n+            if (result != 0) {\n+                LOG.warn(\"Failed cleaning up RuncWorker {}\", workerId);\n+            }\n+        } catch (FileNotFoundException e) {\n+            // This could happen if we had an IOException and failed launching the worker.\n+            // We need to continue on in order for the worker directory to get cleaned up.\n+            LOG.error(\"Failed to find container id for {} ({}), unable to reap container\", workerId, e.getMessage());\n+        }\n+        //remove from the watched list\n+        LOG.debug(\"Removing {} from the watched workers list\", workerId);\n+        workerToUser.remove(workerId);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTg5ODMwMA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r671898300", "bodyText": "makes sense. keeping cleanup and removing releaseResourcesForWorker", "author": "Ethanlm", "createdAt": "2021-07-18T21:12:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU4ODk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NTYzODcxNA==", "url": "https://github.com/apache/storm/pull/3366#discussion_r675638714", "bodyText": "Thanks for addressing this.", "author": "agresch", "createdAt": "2021-07-23T15:09:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU4ODk5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDU5MzI2Ng==", "url": "https://github.com/apache/storm/pull/3366#discussion_r550593266", "bodyText": "Counldn't spelling", "author": "agresch", "createdAt": "2020-12-31T17:44:22Z", "path": "storm-server/src/main/java/org/apache/storm/container/oci/RuncLibContainerManager.java", "diffHunk": "@@ -0,0 +1,631 @@\n+/*\n+ *\n+ *  Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.storm.container.oci;\n+\n+import static org.apache.storm.utils.ConfigUtils.FILE_SEPARATOR;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.Reader;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.storm.DaemonConfig;\n+import org.apache.storm.StormTimer;\n+import org.apache.storm.container.cgroup.CgroupUtils;\n+import org.apache.storm.container.cgroup.core.MemoryCore;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciLayer;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciLinuxConfig;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciMount;\n+import org.apache.storm.container.oci.OciContainerExecutorConfig.OciRuntimeConfig.OciProcessConfig;\n+import org.apache.storm.daemon.supervisor.ClientSupervisorUtils;\n+import org.apache.storm.daemon.supervisor.ExitCodeCallback;\n+import org.apache.storm.utils.ConfigUtils;\n+import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.ReflectionUtils;\n+import org.apache.storm.utils.ServerUtils;\n+import org.apache.storm.utils.Utils;\n+\n+import org.json.simple.JSONObject;\n+import org.json.simple.parser.JSONParser;\n+import org.json.simple.parser.ParseException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.DumperOptions;\n+import org.yaml.snakeyaml.Yaml;\n+\n+public class RuncLibContainerManager extends OciContainerManager {\n+    private static final Logger LOG = LoggerFactory.getLogger(RuncLibContainerManager.class);\n+\n+    private OciImageTagToManifestPluginInterface imageTagToManifestPlugin;\n+    private OciManifestToResourcesPluginInterface manifestToResourcesPlugin;\n+    private OciResourcesLocalizerInterface ociResourcesLocalizer;\n+    private ObjectMapper mapper;\n+    private int layersToKeep;\n+    private String seccomp;\n+\n+    private static final String RESOLV_CONF = \"/etc/resolv.conf\";\n+    private static final String HOSTNAME = \"/etc/hostname\";\n+    private static final String HOSTS = \"/etc/hosts\";\n+    private static final String OCI_CONFIG_JSON = \"oci-config.json\";\n+\n+    private static final String SQUASHFS_MEDIA_TYPE = \"application/vnd.squashfs\";\n+\n+    //CPU CFS (Completely Fair Scheduler) period\n+    private static final long CPU_CFS_PERIOD_US = 100000;\n+\n+    private Map<String, Long> workerToContainerPid = new ConcurrentHashMap<>();\n+    private Map<String, ExitCodeCallback> workerToExitCallback = new ConcurrentHashMap<>();\n+    private Map<String, String> workerToUser = new ConcurrentHashMap<>();\n+    private StormTimer checkContainerAliveTimer;\n+\n+    @Override\n+    public void prepare(Map<String, Object> conf) throws IOException {\n+        super.prepare(conf);\n+\n+        imageTagToManifestPlugin = chooseImageTagToManifestPlugin();\n+        imageTagToManifestPlugin.init(conf);\n+\n+        manifestToResourcesPlugin = chooseManifestToResourcesPlugin();\n+        manifestToResourcesPlugin.init(conf);\n+\n+        ociResourcesLocalizer = chooseOciResourcesLocalizer();\n+        ociResourcesLocalizer.init(conf);\n+\n+        layersToKeep = ObjectReader.getInt(\n+                conf.get(DaemonConfig.STORM_OCI_LAYER_MOUNTS_TO_KEEP),\n+                100\n+        );\n+\n+        mapper = new ObjectMapper();\n+\n+        if (seccompJsonFile != null) {\n+            seccomp = new String(Files.readAllBytes(Paths.get(seccompJsonFile)));\n+        }\n+\n+        if (checkContainerAliveTimer == null) {\n+            checkContainerAliveTimer =\n+                new StormTimer(\"CheckRuncContainerAlive\", Utils.createDefaultUncaughtExceptionHandler());\n+            checkContainerAliveTimer\n+                .scheduleRecurring(0, (Integer) conf.get(DaemonConfig.SUPERVISOR_MONITOR_FREQUENCY_SECS), () -> {\n+                    try {\n+                        checkContainersAlive();\n+                    } catch (Exception e) {\n+                        //Ignore\n+                        LOG.debug(\"The CheckRuncContainerAlive thread has exception. Ignored\", e);\n+                    }\n+                });\n+        }\n+    }\n+\n+    private OciImageTagToManifestPluginInterface chooseImageTagToManifestPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_IMAGE_TAG_TO_MANIFEST_PLUGIN)\n+        );\n+        LOG.info(\"imageTag-to-manifest Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciManifestToResourcesPluginInterface chooseManifestToResourcesPlugin() throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_MANIFEST_TO_RESOURCES_PLUGIN)\n+        );\n+        LOG.info(\"manifest to resource Plugin is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    private OciResourcesLocalizerInterface chooseOciResourcesLocalizer()\n+        throws IllegalArgumentException {\n+        String pluginName = ObjectReader.getString(\n+                conf.get(DaemonConfig.STORM_OCI_RESOURCES_LOCALIZER)\n+        );\n+        LOG.info(\"oci resource localizer is: {}\", pluginName);\n+        return ReflectionUtils.newInstance(pluginName);\n+    }\n+\n+    //the container process ID in the process namespace of the host.\n+    private String containerPidFile(String workerId) {\n+        return ConfigUtils.workerArtifactsSymlink(conf, workerId) + FILE_SEPARATOR + \"container-\" + workerId + \".pid\";\n+    }\n+\n+    @Override\n+    public void launchWorkerProcess(String user, String topologyId,  Map<String, Object> topoConf,\n+                                    int port, String workerId,\n+                                    List<String> command, Map<String, String> env, String logPrefix,\n+                                    ExitCodeCallback processExitCallback, File targetDir) throws IOException {\n+\n+        String imageName = getImageName(topoConf);\n+        if (imageName == null) {\n+            LOG.error(\"Image name for {} is not configured properly; will not continue to launch the worker\", topologyId);\n+            return;\n+        }\n+\n+        //set container ID to port + worker ID\n+        String containerId = getContainerId(workerId, port);\n+\n+        //get manifest\n+        ImageManifest manifest = imageTagToManifestPlugin.getManifestFromImageTag(imageName);\n+        LOG.debug(\"workerId {}: Got manifest: {}\", workerId, manifest.toString());\n+\n+        //get layers metadata\n+        OciResource configResource = manifestToResourcesPlugin.getConfigResource(manifest);\n+        LOG.info(\"workerId {}: Got config metadata: {}\", workerId, configResource.toString());\n+\n+        saveRuncYaml(topologyId, port, containerId, imageName, configResource);\n+\n+        List<OciResource> layersResource = manifestToResourcesPlugin.getLayerResources(manifest);\n+        LOG.info(\"workerId {}: Got layers metadata: {}\", workerId, layersResource.toString());\n+\n+        //localize resource\n+        String configLocalPath = ociResourcesLocalizer.localize(configResource);\n+\n+        List<String> ociEnv = new ArrayList<>();\n+        List<String> args = new ArrayList<>();\n+\n+        ArrayList<OciLayer> layers = new ArrayList<>();\n+\n+        File file = new File(configLocalPath);\n+        //extract env\n+        List<String> imageEnv = extractImageEnv(file);\n+        if (imageEnv != null && !imageEnv.isEmpty()) {\n+            ociEnv.addAll(imageEnv);\n+        }\n+        for (Map.Entry<String, String> entry : env.entrySet()) {\n+            ociEnv.add(entry.getKey() + \"=\" + entry.getValue());\n+        }\n+        LOG.debug(\"workerId {}: ociEnv: {}\", workerId, ociEnv);\n+\n+        //extract entrypoint\n+        List<String> entrypoint = extractImageEntrypoint(file);\n+        if (entrypoint != null && !entrypoint.isEmpty()) {\n+            args.addAll(entrypoint);\n+        }\n+        LOG.debug(\"workerId {}: args: {}\", workerId, args);\n+\n+        //localize layers\n+        List<String> layersLocalPath = ociResourcesLocalizer.localize((layersResource));\n+        //compose layers\n+        for (String layerLocalPath : layersLocalPath) {\n+            OciLayer layer = new OciLayer(SQUASHFS_MEDIA_TYPE, layerLocalPath);\n+            layers.add(layer);\n+        }\n+        LOG.debug(\"workerId {}: layers: {}\", workerId, layers);\n+        ArrayList<OciMount> mounts = new ArrayList<>();\n+        setContainerMounts(mounts, topologyId, workerId, port);\n+        LOG.debug(\"workerId {}: mounts: {}\", workerId, mounts);\n+\n+        //calculate the cpusQuotas based on CPU_CFS_PERIOD and assigned CPU\n+        Long cpusQuotas = null;\n+        if (workerToCpu.containsKey(workerId)) {\n+            cpusQuotas = workerToCpu.get(workerId) * CPU_CFS_PERIOD_US / 100;\n+        }\n+\n+        Long memoryInBytes = null;\n+        if (workerToMemoryMb.containsKey(workerId)) {\n+            memoryInBytes = workerToMemoryMb.get(workerId) * 1024 * 1024L;\n+        }\n+        LOG.info(\"workerId {}: memoryInBytes set to {}; cpusQuotas set to {}\", workerId, memoryInBytes, cpusQuotas);\n+\n+        //<workerRoot>/<workerId>\n+        String workerDir = targetDir.getAbsolutePath();\n+        String workerScriptPath = ServerUtils.writeScript(workerDir, command, env, \"0027\");\n+\n+        args.add(\"bash\");\n+        args.add(workerScriptPath);\n+\n+        //The container PID (on the host) will be written to this file.\n+        String containerPidFilePath = containerPidFile(workerId);\n+\n+        OciProcessConfig processConfig = createOciProcessConfig(workerDir, ociEnv, args);\n+\n+        OciLinuxConfig linuxConfig =\n+            createOciLinuxConfig(cpusQuotas, memoryInBytes, cgroupParent + \"/\" + containerId, seccomp, workerId);\n+\n+        OciRuntimeConfig ociRuntimeConfig = new OciRuntimeConfig(null, mounts, processConfig, null,\n+                                                          null, null, linuxConfig);\n+\n+        OciContainerExecutorConfig ociContainerExecutorConfig =\n+            createOciContainerExecutorConfig(user, containerId, containerPidFilePath,\n+                                             workerScriptPath, null, null, null, layers, ociRuntimeConfig);\n+\n+        //launch the container using worker-launcher\n+        String executorConfigToJsonFile = writeOciExecutorConfigToJsonFile(mapper, ociContainerExecutorConfig, workerDir);\n+        LOG.info(\"workerId {}: oci-config.json file path: {}\", workerId, executorConfigToJsonFile);\n+\n+        List<String> cmdArgs = Arrays.asList(CmdType.RUN_OCI_CONTAINER.toString(), workerDir, executorConfigToJsonFile,\n+                                             ConfigUtils.workerArtifactsSymlink(conf, workerId));\n+\n+        // launch the oci container. waiting prevents possible race condition that could prevent cleanup of container\n+        int exitCode = ClientSupervisorUtils.processLauncherAndWait(conf, user, cmdArgs, env, logPrefix, targetDir);\n+        if (exitCode != 0) {\n+            LOG.error(\"launchWorkerProcess RuncCommand {} exited with code: {}\", \"LaunchWorker-\" + containerId, exitCode);\n+            throw new RuntimeException(\"launchWorkerProcess Failed to create Runc Container. ContainerId: \" + containerId);\n+        }\n+\n+        //Add to the watched list\n+        LOG.debug(\"Adding {} to the watched workers list\", workerId);\n+        workerToExitCallback.put(workerId, processExitCallback);\n+        workerToUser.put(workerId, user);\n+\n+    }\n+\n+    private void checkContainersAlive() {\n+        //Check if all watched workers are still alive\n+        workerToUser.forEach((workerId, user) -> {\n+            if (isContainerDead(workerId, user)) {\n+                invokeProcessExitCallback(workerId);\n+            }\n+        });\n+    }\n+\n+    private boolean isContainerDead(String workerId, String user) {\n+        boolean isDead = true;\n+        Long pid = getContainerPid(workerId);\n+        LOG.debug(\"Checking container {}, pid {}, user {}\", workerId, pid, user);\n+        //do nothing if pid is null.\n+        if (pid != null && user != null) {\n+            try {\n+                isDead = ServerUtils.areAllProcessesDead(conf, user, workerId, Collections.singleton(pid));\n+            } catch (IOException e) {\n+                //ignore\n+                LOG.debug(\"Error while checking if container is dead.\", e);\n+            }\n+        }\n+        return isDead;\n+    }\n+\n+    private void invokeProcessExitCallback(String workerId) {\n+        LOG.info(\"processExitCallback returned for workerId {}\", workerId);\n+        ExitCodeCallback processExitCallback = workerToExitCallback.get(workerId);\n+        if (processExitCallback != null) {\n+            processExitCallback.call(0);\n+        }\n+    }\n+\n+    private String getContainerId(String workerId, int port) throws IOException {\n+        if (port <= 0) { // when killing workers, we will have the workerId and a port of -1\n+            return getContainerIdFromOciJson(workerId);\n+        }\n+        return port + \"-\" + workerId;\n+    }\n+\n+    private String getContainerIdFromOciJson(String workerId) throws IOException {\n+        String ociJson = ConfigUtils.workerRoot(conf, workerId) + FILE_SEPARATOR + OCI_CONFIG_JSON;\n+        LOG.info(\"port unknown for workerId {}, looking up from {}\", workerId, ociJson);\n+        JSONParser parser = new JSONParser();\n+\n+        try (Reader reader = new FileReader(ociJson)) {\n+            JSONObject jsonObject = (JSONObject) parser.parse(reader);\n+            return (String) jsonObject.get(\"containerId\");\n+        } catch (ParseException e) {\n+            throw new IOException(\"Unable to parse {}\", e);\n+        }\n+    }\n+\n+    // save runc.yaml in artifacts dir so we can track which image the worker was launched with\n+    private void saveRuncYaml(String topologyId, int port, String containerId, String imageName, OciResource configResource) {\n+        String fname = String.format(\"runc-%s.yaml\", containerId);\n+        File file = new File(ConfigUtils.workerArtifactsRoot(conf, topologyId, port), fname);\n+        DumperOptions options = new DumperOptions();\n+        options.setIndent(2);\n+        options.setPrettyFlow(true);\n+        options.setDefaultFlowStyle(DumperOptions.FlowStyle.BLOCK);\n+        Yaml yaml = new Yaml(options);\n+        Map<String, Object> data = new HashMap<>();\n+        data.put(\"imageName\", imageName);\n+        data.put(\"manifest\", configResource.getFileName());\n+        data.put(\"configPath\", configResource.getPath());\n+        try (Writer writer = new FileWriter(file)) {\n+            yaml.dump(data, writer);\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private String writeOciExecutorConfigToJsonFile(ObjectMapper mapper, OciContainerExecutorConfig ociContainerExecutorConfig,\n+                                                    String workerDir) throws IOException {\n+        File cmdDir = new File(workerDir);\n+        if (!cmdDir.exists()) {\n+            throw new IOException(workerDir + \" doesn't exist\");\n+        }\n+\n+        File commandFile = new File(cmdDir + FILE_SEPARATOR + OCI_CONFIG_JSON);\n+        mapper.writeValue(commandFile, ociContainerExecutorConfig);\n+        return commandFile.getAbsolutePath();\n+    }\n+\n+    private void setContainerMounts(ArrayList<OciMount> mounts, String topologyId, String workerId, Integer port) throws IOException {\n+        //read-only bindmounts need to be added before read-write bindmounts otherwise read-write bindmounts may be overridden.\n+        for (String readonlyMount : readonlyBindmounts) {\n+            addOciMountLocation(mounts, readonlyMount, readonlyMount, false, false);\n+        }\n+\n+        for (String readwriteMount : readwriteBindmounts) {\n+            addOciMountLocation(mounts, readwriteMount, readwriteMount, false, true);\n+        }\n+\n+        addOciMountLocation(mounts, RESOLV_CONF, RESOLV_CONF, false, false);\n+        addOciMountLocation(mounts, HOSTNAME, HOSTNAME, false, false);\n+        addOciMountLocation(mounts, HOSTS, HOSTS, false, false);\n+        addOciMountLocation(mounts, nscdPath, nscdPath, false, false);\n+        addOciMountLocation(mounts, stormHome, stormHome, false, false);\n+        addOciMountLocation(mounts, cgroupRootPath, cgroupRootPath, false, false);\n+\n+        //set of locations to be bind mounted\n+        String supervisorLocalDir = ConfigUtils.supervisorLocalDir(conf);\n+        addOciMountLocation(mounts, supervisorLocalDir, supervisorLocalDir, false, false);\n+\n+        String workerRootDir = ConfigUtils.workerRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerRootDir, workerRootDir, false, true);\n+\n+        String workerArtifactsRoot = ConfigUtils.workerArtifactsRoot(conf, topologyId, port);\n+        addOciMountLocation(mounts, workerArtifactsRoot, workerArtifactsRoot, false, true);\n+\n+        String workerUserFile = ConfigUtils.workerUserFile(conf, workerId);\n+        addOciMountLocation(mounts, workerUserFile, workerUserFile, false, true);\n+\n+        String sharedByTopologyDir = ConfigUtils.sharedByTopologyDir(conf, topologyId);\n+        addOciMountLocation(mounts, sharedByTopologyDir, sharedByTopologyDir, false, true);\n+\n+        String workerTmpRoot = ConfigUtils.workerTmpRoot(conf, workerId);\n+        addOciMountLocation(mounts, workerTmpRoot, TMP_DIR, false, true);\n+    }\n+\n+    private List<String> extractImageEnv(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode envNode = node.path(\"config\").path(\"Env\");\n+        if (envNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(envNode, List.class);\n+    }\n+\n+    private List<String> extractImageEntrypoint(File config) throws IOException {\n+        JsonNode node = mapper.readTree(config);\n+        JsonNode entrypointNode = node.path(\"config\").path(\"Entrypoint\");\n+        if (entrypointNode.isMissingNode()) {\n+            return null;\n+        }\n+        return mapper.treeToValue(entrypointNode, List.class);\n+    }\n+\n+    private OciContainerExecutorConfig createOciContainerExecutorConfig(\n+            String username, String containerId, String pidFile,\n+            String containerScriptPath, String containerCredentialsPath,\n+            List<String> localDirs, List<String> logDirs,\n+            List<OciLayer> layers, OciRuntimeConfig ociRuntimeConfig) {\n+\n+        return new OciContainerExecutorConfig(username, containerId,\n+                pidFile, containerScriptPath, containerCredentialsPath,\n+                localDirs, logDirs, layers, layersToKeep, ociRuntimeConfig);\n+    }\n+\n+    private OciProcessConfig createOciProcessConfig(String cwd,\n+                                                    List<String> env, List<String> args) {\n+        return new OciProcessConfig(false, null, cwd, env,\n+                args, null, null, null, true, 0, null, null);\n+    }\n+\n+    private OciLinuxConfig createOciLinuxConfig(Long cpusQuotas, Long memInBytes,\n+                                                String cgroupsPath, String seccomp, String workerId) {\n+        OciLinuxConfig.Resources.Cpu cgroupCpu = null;\n+\n+        if (cpusQuotas != null) {\n+            cgroupCpu = new OciLinuxConfig.Resources.Cpu(0, cpusQuotas, CPU_CFS_PERIOD_US, 0, 0,\n+                    null, null);\n+\n+            if (workerToCores.containsKey(workerId)) {\n+                cgroupCpu.setCpus(StringUtils.join(workerToCores.get(workerId), \",\"));\n+                cgroupCpu.setMems(workerToMemoryZone.get(workerId));\n+            }\n+        }\n+\n+        OciLinuxConfig.Resources.Memory cgroupMem = null;\n+        if (memInBytes != null) {\n+            cgroupMem = new OciLinuxConfig.Resources.Memory(memInBytes, 0, 0, 0, 0, 0, false);\n+        }\n+\n+        OciLinuxConfig.Resources cgroupResources =\n+                new OciLinuxConfig.Resources(null, cgroupMem, cgroupCpu, null, null, null,\n+                        null, null);\n+\n+        return new OciLinuxConfig(null, null, null, null,\n+                cgroupsPath, cgroupResources, null, null, seccomp, null, null,\n+                null, null);\n+    }\n+\n+    private void addOciMountLocation(List<OciMount> mounts, String srcPath,\n+                                     String dstPath, boolean createSource, boolean isReadWrite) throws IOException {\n+        if (!createSource) {\n+            boolean sourceExists = new File(srcPath).exists();\n+            if (!sourceExists) {\n+                throw new IOException(\"SourcePath \" + srcPath + \" doesn't exit\");\n+            }\n+        }\n+\n+        ArrayList<String> options = new ArrayList<>();\n+        if (isReadWrite) {\n+            options.add(\"rw\");\n+        } else {\n+            options.add(\"ro\");\n+        }\n+        options.add(\"rbind\");\n+        options.add(\"rprivate\");\n+        mounts.add(new OciMount(dstPath, \"bind\", srcPath, options));\n+    }\n+\n+    @Override\n+    public long getMemoryUsage(String user, String workerId, int port) throws IOException {\n+        // \"/sys/fs/cgroup/memory/storm/containerId/\"\n+        String containerId = getContainerId(workerId, port);\n+        String memoryCgroupPath = memoryCgroupRootPath + File.separator  + containerId;\n+        MemoryCore memoryCore = new MemoryCore(memoryCgroupPath);\n+        LOG.debug(\"ContainerId {} : Got memory getPhysicalUsage {} from {}\", containerId, memoryCore.getPhysicalUsage(), memoryCgroupPath);\n+        return memoryCore.getPhysicalUsage();\n+    }\n+\n+    @Override\n+    public void kill(String user, String workerId) throws IOException {\n+        LOG.info(\"Killing {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 15, user);\n+        } else {\n+            LOG.warn(\"Trying to kill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    private void signal(long pid, int signal, String user) throws IOException {\n+        List<String> commands = Arrays.asList(\"signal\", String.valueOf(pid), String.valueOf(signal));\n+        String logPrefix = \"kill -\" + signal + \" \" + pid;\n+        ClientSupervisorUtils.processLauncherAndWait(conf, user, commands, null, logPrefix);\n+    }\n+\n+    @Override\n+    public void forceKill(String user, String workerId) throws IOException {\n+        LOG.debug(\"ForceKilling {}\", workerId);\n+        Long pid = getContainerPid(workerId);\n+        if (pid != null) {\n+            signal(pid, 9, user);\n+        } else {\n+            LOG.warn(\"Trying to forceKill container {} but pidfile is not found\", workerId);\n+        }\n+    }\n+\n+    // return null if not found.\n+    private Long getContainerPid(String workerId) {\n+        Long pid = workerToContainerPid.get(workerId);\n+        if (pid == null) {\n+            String containerPidFilePath = containerPidFile(workerId);\n+            if (!new File(containerPidFilePath).exists()) {\n+                LOG.warn(\"{} doesn't exist\", containerPidFilePath);\n+            } else {\n+                try {\n+                    pid = Long.parseLong(CgroupUtils.readFileByLine(containerPidFilePath).get(0));\n+                    workerToContainerPid.put(workerId, pid);\n+                } catch (IOException e) {\n+                    LOG.warn(\"failed to read {}\", containerPidFilePath);\n+                }\n+            }\n+        }\n+        return pid;\n+    }\n+\n+    @Override\n+    public void releaseResourcesForWorker(String workerId) {\n+        super.releaseResourcesForWorker(workerId);\n+        workerToContainerPid.remove(workerId);\n+    }\n+\n+    /**\n+     * The container terminates if any process inside the container dies.\n+     * So we only need to check if the initial process is alive or not.\n+     * @param user the user that the processes are running as\n+     * @param workerId the id of the worker to kill\n+     * @return true if all processes are dead; false otherwise\n+     * @throws IOException on I/O exception\n+     */\n+    @Override\n+    public boolean areAllProcessesDead(String user, String workerId) throws IOException {\n+        boolean areAllDead = isContainerDead(workerId, user);\n+        LOG.debug(\"WorkerId {}: Checking areAllProcessesDead: {}\", workerId, areAllDead);\n+        return areAllDead;\n+    }\n+\n+    @Override\n+    public void cleanup(String user, String workerId, int port) throws IOException {\n+        LOG.debug(\"clean up worker {}\", workerId);\n+        try {\n+            String containerId = getContainerId(workerId, port);\n+            List<String> commands = Arrays.asList(CmdType.REAP_OCI_CONTAINER.toString(), containerId, String.valueOf(layersToKeep));\n+            String logPrefix = \"Worker Process \" + workerId;\n+            int result = ClientSupervisorUtils.processLauncherAndWait(conf, user, commands, null, logPrefix);\n+            if (result != 0) {\n+                LOG.warn(\"Failed cleaning up RuncWorker {}\", workerId);\n+            }\n+        } catch (FileNotFoundException e) {\n+            // This could happen if we had an IOException and failed launching the worker.\n+            // We need to continue on in order for the worker directory to get cleaned up.\n+            LOG.error(\"Failed to find container id for {} ({}), unable to reap container\", workerId, e.getMessage());\n+        }\n+        //remove from the watched list\n+        LOG.debug(\"Removing {} from the watched workers list\", workerId);\n+        workerToUser.remove(workerId);\n+        workerToExitCallback.remove(workerId);\n+    }\n+\n+    /**\n+     * Run profiling command in the container.\n+     * @param user the user that the worker is running as\n+     * @param workerId the id of the worker\n+     * @param command the command to run.\n+     *                The profiler to be used is configured in worker-launcher.cfg.\n+     * @param env the environment to run the command\n+     * @param logPrefix the prefix to include in the logs\n+     * @param targetDir the working directory to run the command in\n+     * @return true if the command succeeds, false otherwise.\n+     * @throws IOException on I/O exception\n+     * @throws InterruptedException if interrupted\n+     */\n+    @Override\n+    public boolean runProfilingCommand(String user, String workerId, List<String> command, Map<String, String> env,\n+                                       String logPrefix, File targetDir) throws IOException, InterruptedException {\n+        String workerDir = targetDir.getAbsolutePath();\n+\n+        String profilingArgs = StringUtils.join(command, \" \");\n+\n+        //run nsenter\n+        String nsenterScriptPath = writeToCommandFile(workerDir, profilingArgs, \"profile\");\n+\n+        Long containerPid = getContainerPid(workerId);\n+        if (containerPid == null) {\n+            LOG.error(\"Counldn't get container PID for the worker {}. Skip profiling\", workerId);", "originalCommit": "690e02091244f33b32a1dc3c449413e6aff1d964", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7cbd29b95829e24bdde780b0458477e75c5fdb82", "url": "https://github.com/apache/storm/commit/7cbd29b95829e24bdde780b0458477e75c5fdb82", "message": "[STORM-3388] change Indentation of docker-to-squash.py to 4 spaces", "committedDate": "2021-01-11T22:51:22Z", "type": "commit"}, {"oid": "f904159d2a451ef156731a8fc4747d5f1d286ac0", "url": "https://github.com/apache/storm/commit/f904159d2a451ef156731a8fc4747d5f1d286ac0", "message": "[STORM-3388] address review comments on docker-to-squash.py", "committedDate": "2021-07-09T21:16:16Z", "type": "commit"}, {"oid": "10d13fd1e88ad84b2b082eb4738c7554a5390971", "url": "https://github.com/apache/storm/commit/10d13fd1e88ad84b2b082eb4738c7554a5390971", "message": "[STORM-3388] fix typo", "committedDate": "2021-07-09T21:19:31Z", "type": "commit"}, {"oid": "de2afc8fdc053d732a7f74bf045aa21c88a717fb", "url": "https://github.com/apache/storm/commit/de2afc8fdc053d732a7f74bf045aa21c88a717fb", "message": "[STORM-3388] use javadoc; add final modifier, add static", "committedDate": "2021-07-12T20:10:55Z", "type": "commit"}, {"oid": "5fc077dfa5631f28063b65efd6a770380db8b2ce", "url": "https://github.com/apache/storm/commit/5fc077dfa5631f28063b65efd6a770380db8b2ce", "message": "[STORM-3388] check return value of mkdir and rename operations", "committedDate": "2021-07-12T21:13:04Z", "type": "commit"}, {"oid": "b477ba006e3b7acc277400c82b9b9037c899ec50", "url": "https://github.com/apache/storm/commit/b477ba006e3b7acc277400c82b9b9037c899ec50", "message": "nit on configuration.c", "committedDate": "2021-07-13T19:33:53Z", "type": "commit"}, {"oid": "9f208bf24e8ae667e7ec8c0a669db2b0d6f1de0f", "url": "https://github.com/apache/storm/commit/9f208bf24e8ae667e7ec8c0a669db2b0d6f1de0f", "message": "remove unnecessary code in utils/file-utils.c", "committedDate": "2021-07-13T20:29:43Z", "type": "commit"}, {"oid": "9dd11141b08a947ee2732e77f85d9b8123494e59", "url": "https://github.com/apache/storm/commit/9dd11141b08a947ee2732e77f85d9b8123494e59", "message": "doc update", "committedDate": "2021-07-14T20:19:40Z", "type": "commit"}, {"oid": "248ff3ae2b08d685b9a11dc7268e3caa90f0aa54", "url": "https://github.com/apache/storm/commit/248ff3ae2b08d685b9a11dc7268e3caa90f0aa54", "message": "more nit fix", "committedDate": "2021-07-14T20:22:20Z", "type": "commit"}, {"oid": "ceec321df96ba25ec82f42aa6c343761eaac0199", "url": "https://github.com/apache/storm/commit/ceec321df96ba25ec82f42aa6c343761eaac0199", "message": "[STORM-3388] address comments in java code", "committedDate": "2021-07-18T21:36:38Z", "type": "commit"}, {"oid": "53ff164d2db1c52eb433aaaa7843dc019fe9319a", "url": "https://github.com/apache/storm/commit/53ff164d2db1c52eb433aaaa7843dc019fe9319a", "message": "[STORM-3388] address comments in java code", "committedDate": "2021-07-18T21:54:50Z", "type": "commit"}, {"oid": "f3286cf838a7ab117897ae30e2cedd6b23706e72", "url": "https://github.com/apache/storm/commit/f3286cf838a7ab117897ae30e2cedd6b23706e72", "message": "[STORM-3388] address comments in main.c", "committedDate": "2021-07-18T23:59:01Z", "type": "commit"}, {"oid": "0b80c1597d2ddaeff31cdf5cf1af370c70703785", "url": "https://github.com/apache/storm/commit/0b80c1597d2ddaeff31cdf5cf1af370c70703785", "message": "[STORM-3388] address comments in hdfs-oci", "committedDate": "2021-07-19T00:36:46Z", "type": "commit"}, {"oid": "dcad06769f2235d2624101da03c2ac1c02e9c1e7", "url": "https://github.com/apache/storm/commit/dcad06769f2235d2624101da03c2ac1c02e9c1e7", "message": "[STORM-3388] make storm_user_info generic", "committedDate": "2021-07-19T00:41:03Z", "type": "commit"}, {"oid": "6aa4a8dd901ff8987d089661052d6b95f34565c9", "url": "https://github.com/apache/storm/commit/6aa4a8dd901ff8987d089661052d6b95f34565c9", "message": "[STORM-3388] prepend ERROR to error messages", "committedDate": "2021-07-19T00:55:34Z", "type": "commit"}, {"oid": "9704f6f6540f61c803aafce8854e9de035a2b199", "url": "https://github.com/apache/storm/commit/9704f6f6540f61c803aafce8854e9de035a2b199", "message": "[STORM-3388] change log level to warn", "committedDate": "2021-07-19T01:01:49Z", "type": "commit"}, {"oid": "6b9f785b0876b85cb57c43324a1ee0252276d08e", "url": "https://github.com/apache/storm/commit/6b9f785b0876b85cb57c43324a1ee0252276d08e", "message": "[STORM-3388] change ERROR to warn", "committedDate": "2021-07-19T14:28:33Z", "type": "commit"}, {"oid": "3b5f64c31183f2b5fd8c1995c5c02c6f189d524a", "url": "https://github.com/apache/storm/commit/3b5f64c31183f2b5fd8c1995c5c02c6f189d524a", "message": "[STORM-3388] address review comments", "committedDate": "2021-08-06T14:50:10Z", "type": "commit"}]}