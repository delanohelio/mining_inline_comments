{"pr_number": 973, "pr_title": "[DOCS] Expands classification documentation with multiclass", "pr_createdAt": "2020-04-02T13:50:48Z", "pr_url": "https://github.com/elastic/stack-docs/pull/973", "timeline": [{"oid": "02b196a6346f1b933b40f6d00a733caa58973480", "url": "https://github.com/elastic/stack-docs/commit/02b196a6346f1b933b40f6d00a733caa58973480", "message": "[DOCS] Edits classification conceptual docs to expand it with multi-class.", "committedDate": "2020-04-02T09:26:33Z", "type": "commit"}, {"oid": "3e39186d6afd51bc0295609ee7e8192318c4048e", "url": "https://github.com/elastic/stack-docs/commit/3e39186d6afd51bc0295609ee7e8192318c4048e", "message": "[DOCS] Adds confusion matrix examples and evaluation amendments.", "committedDate": "2020-04-02T11:26:59Z", "type": "commit"}, {"oid": "28b1514096a361e8bd743737b30770c81d996909", "url": "https://github.com/elastic/stack-docs/commit/28b1514096a361e8bd743737b30770c81d996909", "message": "[DOCS] Expands classification documentation with mult-class.", "committedDate": "2020-04-02T13:49:19Z", "type": "commit"}, {"oid": "73eb02f580f53b6f2b9c1d024185f58fd02d812f", "url": "https://github.com/elastic/stack-docs/commit/73eb02f580f53b6f2b9c1d024185f58fd02d812f", "message": "[DOCS] Adjusts description of confusion matrix.", "committedDate": "2020-04-02T14:09:26Z", "type": "commit"}, {"oid": "6c22fb325b884554a5dcdbea6d40729383da2658", "url": "https://github.com/elastic/stack-docs/commit/6c22fb325b884554a5dcdbea6d40729383da2658", "message": "[DOCS] Fine-tunes wording.", "committedDate": "2020-04-03T09:12:07Z", "type": "commit"}, {"oid": "c19635431c21730c78bacc42bff7b7ceae0cfa64", "url": "https://github.com/elastic/stack-docs/commit/c19635431c21730c78bacc42bff7b7ceae0cfa64", "message": "[DOCS] Fine-tunes wording in evaluate piece.", "committedDate": "2020-04-03T09:42:20Z", "type": "commit"}, {"oid": "05f28aaabf336436d823904412bce8155d306eb5", "url": "https://github.com/elastic/stack-docs/commit/05f28aaabf336436d823904412bce8155d306eb5", "message": "[DOCS] Omits the categorical separation between binary and multiclass.", "committedDate": "2020-04-06T14:00:52Z", "type": "commit"}, {"oid": "6427ba6bf3008e3e7630c237230291a76196a285", "url": "https://github.com/elastic/stack-docs/commit/6427ba6bf3008e3e7630c237230291a76196a285", "message": "[DOCS] Provides tips for faster runtime.", "committedDate": "2020-04-07T09:15:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE3NTYzMA==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r405175630", "bodyText": "Minor detail: \"dataset\" is two words in the style guide\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Your training dataset should be approximately balanced. It means the number of \n          \n          \n            \n            Your training data set should be approximately balanced. It means the number of", "author": "lcawl", "createdAt": "2020-04-07T23:39:07Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -49,11 +41,25 @@ means that you need to supply a labeled training dataset that has some\n {feature-vars} and a {depvar}. The {classification} algorithm learns the \n relationships between the features and the {depvar}. Once you\u2019ve trained the \n model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+learned about the relationships between the data points to classify new data. In \n+case there are more than two classes, an automated process called stratification \n+makes sure that the proportions of each class in the training data are equal so \n+that the training is consistent. \n+\n+Your training dataset should be approximately balanced. It means the number of ", "originalCommit": "6427ba6bf3008e3e7630c237230291a76196a285", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2c13510e4e8cb1f113f07c89f2489318c0ae68c7", "url": "https://github.com/elastic/stack-docs/commit/2c13510e4e8cb1f113f07c89f2489318c0ae68c7", "message": "Update docs/en/stack/ml/df-analytics/dfa-classification.asciidoc\n\nCo-Authored-By: Lisa Cawley <lcawley@elastic.co>", "committedDate": "2020-04-08T07:41:50Z", "type": "commit"}, {"oid": "81458518dc39f37d66cbef56b284770c7c9dd43c", "url": "https://github.com/elastic/stack-docs/commit/81458518dc39f37d66cbef56b284770c7c9dd43c", "message": "[DOCS] Fixes typos.", "committedDate": "2020-04-08T07:49:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg3MzY4OQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r405873689", "bodyText": "As a rule of thumb...\n\nThis sentence seems like it should be at the start of the next paragraph, not this one. This paragraph seems to be talking mostly about the number of documents, whereas the next one is talking about the number of classes.", "author": "lcawl", "createdAt": "2020-04-08T23:33:57Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -64,10 +70,33 @@ otherwise the {classanalysis} may not provide the best predictions. Read\n The ensemble algorithm that we use in the {stack} for {classification} is a type \n of boosting called boosted tree regression model which combines multiple weak \n models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+probability that a data point belongs to a certain class. A sequence of decision \n+trees are trained and every decision tree learns from the mistakes of the \n+previous one. Every tree is an iteration of the last one, hence it improves the \n+decision made by the previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run ", "originalCommit": "81458518dc39f37d66cbef56b284770c7c9dd43c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg4NTEwOQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r405885109", "bodyText": "Feature variables\n\nThis can perhaps be pursued in a separate PR, but it occurred to me while reading this page that neither our UI nor the API refer to \"feature variables\". They refer to a \"dependent variable\" and to included or excluded \"analyzed fields\". Should we therefore remove this section label and term? Or make it less prominent?\nI think this section boils down to something like this: When you create a classification job, you must specify which field contains the classification labels/values/categories that you want to predict (no more than 30). You can also optionally specify which fields to include or exclude from the analysis.  [It might be nice to mention here why you would choose to explicitly include/exclude fields as opposed to letting the analytics do it for you. Why bother? And also maybe mention how you can use the explain API to see which fields are used]\nIMO we should also omit the details about which data types are supported for the depvars and analyzed fields here and refer to the API instead. That's the kind of low-level detail that changes and can get out of synch here.", "author": "lcawl", "createdAt": "2020-04-09T00:10:08Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -37,23 +29,37 @@ these fields as _{feature-vars}_ and _{depvar}_, respectively.\n {feature-vars-cap} are the values that the {depvar} value depends on. There are \n three different types of {feature-vars} that you can use with our \n {classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+supported in the {feature-var} fields.  ", "originalCommit": "81458518dc39f37d66cbef56b284770c7c9dd43c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjA0OTgyMA==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406049820", "bodyText": "@lcawl\nIn 860f884, I made feature variables less prominent. I still use the term between brackets though, I felt it won't hurt to name it even if we don't use the term on the UI or in the API docs. If you think we should omit it entirely, we can easily delete it without further complications. Also mentioned why you would choose to include/exclude fields and mentioned the Explain API with a link. I also removed the details of supported fields, but put a link that points to the supported field-types in the PUT DFA API docs (which creates a dependency between this PR and the other creating the link).", "author": "szabosteve", "createdAt": "2020-04-09T08:43:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg4NTEwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg4OTIyNw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r405889227", "bodyText": "In other words, how many data points...\n\nIn my opinion, this sentence is redundant (i.e. doesn't add anything to the previous statement). What I think would be more interesting to add (in a separate PR if necessary) is what to do about poor classification results.  Can we provide tips about whether to improve it by re-running with feature importance enabled or using the explain API to determine which fields we should explicitly include or exclude? Or by curating the training data?", "author": "lcawl", "createdAt": "2020-04-09T00:25:16Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -127,18 +157,20 @@ include::{docdir}/shared-ml-concepts.asciidoc[tag=feature-importance]\n [[dfa-classification-evaluation]]\n ==== Measuring model performance\n \n-You can measure how well the model has performed on your dataset by using the \n+You can measure how well the model has performed on your data set by using the \n `classification` evaluation type of the \n {ref}/evaluate-dfanalytics.html[evaluate {dfanalytics} API]. The metric that the \n-evaluation provides you is the multi-class confusion matrix which tells you how \n-many times a given data point that belongs to a given class was classified \n-correctly and incorrectly. In other words, how many times your data point that \n-belongs to the X class was mistakenly classified as Y.\n+evaluation provides you is a confusion matrix. The more classes you have, the \n+more complex the confusion matrix is. The matrix tells you how many data points \n+that belong to a given class were classified correctly and incorrectly. In other \n+words, how many data points that belong to the X class were classified correctly \n+and mistakenly classified as Y or Z or any other class in the data set other than \n+X.", "originalCommit": "81458518dc39f37d66cbef56b284770c7c9dd43c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjA2MTAwMw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406061003", "bodyText": "I deleted the sentence and address the rest in a separate PR.", "author": "szabosteve", "createdAt": "2020-04-09T09:02:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg4OTIyNw=="}], "type": "inlineReview"}, {"oid": "860f8841964450bd5fcd6c23f5c13e4133c618a6", "url": "https://github.com/elastic/stack-docs/commit/860f8841964450bd5fcd6c23f5c13e4133c618a6", "message": "[DOCS] Reworks section on dependent variable and feature variables.", "committedDate": "2020-04-09T08:35:47Z", "type": "commit"}, {"oid": "b1e2097f826abeeab3fcd41bc8365372e47c3de6", "url": "https://github.com/elastic/stack-docs/commit/b1e2097f826abeeab3fcd41bc8365372e47c3de6", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-04-09T09:03:47Z", "type": "commit"}, {"oid": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "url": "https://github.com/elastic/stack-docs/commit/3d959ec9d04ce52cf142d275da8c9a6f74233b98", "message": "[DOCS] Reworks section about imbalanced class sizes.", "committedDate": "2020-04-09T13:25:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ4NDcwNQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406484705", "bodyText": "In the {version} version of the {stack}, the {classification} evaluation handles two classes.\n\nI think this sentence is no longer true and should be removed.", "author": "lcawl", "createdAt": "2020-04-09T21:21:44Z", "path": "docs/en/stack/ml/df-analytics/evaluatedf-api.asciidoc", "diffHunk": "@@ -147,15 +147,37 @@ This evaluation type is suitable for evaluating {classification} models. In the\n classes. The {classification} evaluation offers the following metrics to ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ4ODUxMQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406488511", "bodyText": "{depvar-cap}\n\nThis attribute doesn't exist in the shared attributes file, so it's not resolving.  I actually recommend omitting this section header and anchor.  I think this paragraph flows well from the one above it.", "author": "lcawl", "createdAt": "2020-04-09T21:29:57Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyMjg5NQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406522895", "bodyText": "Minor suggestion to avoid \"we\" if it's not necessary.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            the classes that you want to predict. We refer to this field as {depvar}. The \n          \n          \n            \n            the classes that you want to predict. This field is known as the {depvar}. The", "author": "lcawl", "createdAt": "2020-04-09T23:02:05Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyMzI1NQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406523255", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Since the runtime and the necessary resources for the analysis are increasing as \n          \n          \n            \n            Since the runtime and the necessary resources for the analysis increase as", "author": "lcawl", "createdAt": "2020-04-09T23:03:12Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The \n+rest of the fields that are included in the analysis are used to create the \n+model for predicting the value of the {depvar} (these are the {feature-vars}). \n+All {ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are \n+included by default, however, you can explicitly exclude and/or include fields. \n+Since the runtime and the necessary resources for the analysis are increasing as ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyMzU1NQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406523555", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            the number of included fields is growing, consider to include only relevant \n          \n          \n            \n            the number of included fields grow, consider including only relevant", "author": "lcawl", "createdAt": "2020-04-09T23:04:12Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The \n+rest of the fields that are included in the analysis are used to create the \n+model for predicting the value of the {depvar} (these are the {feature-vars}). \n+All {ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are \n+included by default, however, you can explicitly exclude and/or include fields. \n+Since the runtime and the necessary resources for the analysis are increasing as \n+the number of included fields is growing, consider to include only relevant ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyNDQ1NA==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406524454", "bodyText": "Not mandatory, but I think it would be more impactful to split this sentence.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Although the effects of imbalanced data are automatically mitigated before the \n          \n          \n            \n            The effects of imbalanced data are automatically mitigated before the", "author": "lcawl", "createdAt": "2020-04-09T23:07:41Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The \n+rest of the fields that are included in the analysis are used to create the \n+model for predicting the value of the {depvar} (these are the {feature-vars}). \n+All {ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are \n+included by default, however, you can explicitly exclude and/or include fields. \n+Since the runtime and the necessary resources for the analysis are increasing as \n+the number of included fields is growing, consider to include only relevant \n+fields. For more information about field selection, see \n+{ref}/explain-dfanalytics.html[Explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+Although the effects of imbalanced data are automatically mitigated before the ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyNDk1Nw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406524957", "bodyText": "Another minor suggestion to remove \"we\" if possible:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            training, we still recommend using an approximately balanced data set to train \n          \n          \n            \n            training. Nonetheless, it is a good idea to train your model with a data set that is approximately balanced.", "author": "lcawl", "createdAt": "2020-04-09T23:09:25Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The \n+rest of the fields that are included in the analysis are used to create the \n+model for predicting the value of the {depvar} (these are the {feature-vars}). \n+All {ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are \n+included by default, however, you can explicitly exclude and/or include fields. \n+Since the runtime and the necessary resources for the analysis are increasing as \n+the number of included fields is growing, consider to include only relevant \n+fields. For more information about field selection, see \n+{ref}/explain-dfanalytics.html[Explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+Although the effects of imbalanced data are automatically mitigated before the \n+training, we still recommend using an approximately balanced data set to train ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyNjEyMA==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406526120", "bodyText": "I find when sentences start with \"it\", I have to go back to previous sentences to figure out what \"it\" is.  So I'd reword to something like this:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            the model. It means the number of data points belonging to the various classes \n          \n          \n            \n            That is to say, ideally your data set should have a similar number of data points for each class.", "author": "lcawl", "createdAt": "2020-04-09T23:13:07Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The \n+rest of the fields that are included in the analysis are used to create the \n+model for predicting the value of the {depvar} (these are the {feature-vars}). \n+All {ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are \n+included by default, however, you can explicitly exclude and/or include fields. \n+Since the runtime and the necessary resources for the analysis are increasing as \n+the number of included fields is growing, consider to include only relevant \n+fields. For more information about field selection, see \n+{ref}/explain-dfanalytics.html[Explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+Although the effects of imbalanced data are automatically mitigated before the \n+training, we still recommend using an approximately balanced data set to train \n+the model. It means the number of data points belonging to the various classes ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyNjQ0Mw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406526443", "bodyText": "If you merge the previous suggestions, this sentence fragment is not longer required:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            is not widely different.", "author": "lcawl", "createdAt": "2020-04-09T23:13:48Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -5,55 +5,51 @@\n experimental[]\n \n {classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n+given data point in a data set. Typical examples of {classification} problems are \n predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n+In the first case, for example, our data set consists of data on loan applicants \n that covers investment history, employment status, debit status, and so on. \n Based on historical data, the {classification} analysis predicts whether it is \n safe or risky to lend money to a given loan applicant. In the second case, the \n data we have represents songs and the analysis \u2013 based on the features of the \n data points \u2013 classifies the songs as hip-hop, country, classical, or any \n other genres available in the set of categories we have. Therefore, \n {classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n+{reganalysis} which predicts continuous, numerical values. The maximum number of \n+classes for {classanalysis} is 30.\n \n \n [discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n+[[dfa-classification-depvar]]\n+==== {depvar-cap}\n \n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. We refer to this field as {depvar}. The \n+rest of the fields that are included in the analysis are used to create the \n+model for predicting the value of the {depvar} (these are the {feature-vars}). \n+All {ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are \n+included by default, however, you can explicitly exclude and/or include fields. \n+Since the runtime and the necessary resources for the analysis are increasing as \n+the number of included fields is growing, consider to include only relevant \n+fields. For more information about field selection, see \n+{ref}/explain-dfanalytics.html[Explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+Although the effects of imbalanced data are automatically mitigated before the \n+training, we still recommend using an approximately balanced data set to train \n+the model. It means the number of data points belonging to the various classes \n+is not widely different.", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUyNzA0Ng==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406527046", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The runtime scales approximately linearly with the number of involved documents \n          \n          \n            \n            The runtime also scales approximately linearly with the number of involved documents", "author": "lcawl", "createdAt": "2020-04-09T23:15:54Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -64,10 +60,32 @@ otherwise the {classanalysis} may not provide the best predictions. Read\n The ensemble algorithm that we use in the {stack} for {classification} is a type \n of boosting called boosted tree regression model which combines multiple weak \n models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+probability that a data point belongs to a certain class. A sequence of decision \n+trees are trained and every decision tree learns from the mistakes of the \n+previous one. Every tree is an iteration of the last one, hence it improves the \n+decision made by the previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime scales approximately linearly with the number of involved documents ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUzMTMwNQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406531305", "bodyText": "To achieve faster runtime...\n\nThis sentence is similar to the previous sentence (\"runtime increases faster\"), but their meanings are different in a way that I find a bit confusing.  To avoid confusion, maybe we could change this sentence to something like:\n\nTo improve the performance of your {classanalysis}, you can ...", "author": "lcawl", "createdAt": "2020-04-09T23:31:03Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -64,10 +60,32 @@ otherwise the {classanalysis} may not provide the best predictions. Read\n The ensemble algorithm that we use in the {stack} for {classification} is a type \n of boosting called boosted tree regression model which combines multiple weak \n models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+probability that a data point belongs to a certain class. A sequence of decision \n+trees are trained and every decision tree learns from the mistakes of the \n+previous one. Every tree is an iteration of the last one, hence it improves the \n+decision made by the previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime scales approximately linearly with the number of involved documents \n+below 200.000 data points. Therefore, if you double the number of documents, \n+then the runtime of the analysis doubles respectively. Above 200.000 data \n+points, runtime increases faster.\n+\n+To achieve faster runtime, consider to set a smaller training percent, prepare ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjUzMjA3Ng==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r406532076", "bodyText": "This sentence is quite long, so I'd recommend splitting it:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            your input data to have less classes if it is possible, and remove the fields \n          \n          \n            \n            If possible, prepare your input data such that is has less classes. You can also remove the fields", "author": "lcawl", "createdAt": "2020-04-09T23:34:00Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -64,10 +60,32 @@ otherwise the {classanalysis} may not provide the best predictions. Read\n The ensemble algorithm that we use in the {stack} for {classification} is a type \n of boosting called boosted tree regression model which combines multiple weak \n models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+probability that a data point belongs to a certain class. A sequence of decision \n+trees are trained and every decision tree learns from the mistakes of the \n+previous one. Every tree is an iteration of the last one, hence it improves the \n+decision made by the previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime scales approximately linearly with the number of involved documents \n+below 200.000 data points. Therefore, if you double the number of documents, \n+then the runtime of the analysis doubles respectively. Above 200.000 data \n+points, runtime increases faster.\n+\n+To achieve faster runtime, consider to set a smaller training percent, prepare \n+your input data to have less classes if it is possible, and remove the fields ", "originalCommit": "3d959ec9d04ce52cf142d275da8c9a6f74233b98", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "32b6959456a476248177fe322774a2cca5091ce3", "url": "https://github.com/elastic/stack-docs/commit/32b6959456a476248177fe322774a2cca5091ce3", "message": "Apply suggestions from code review\n\nCo-Authored-By: Lisa Cawley <lcawley@elastic.co>", "committedDate": "2020-04-16T07:29:09Z", "type": "commit"}, {"oid": "483d78ce436431894e15a3c42dfaed1c23d8ff5a", "url": "https://github.com/elastic/stack-docs/commit/483d78ce436431894e15a3c42dfaed1c23d8ff5a", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-04-16T09:15:00Z", "type": "commit"}, {"oid": "365926f70d3728cc657687b0dcaa26286e8a7cc7", "url": "https://github.com/elastic/stack-docs/commit/365926f70d3728cc657687b0dcaa26286e8a7cc7", "message": "[DOCS] Moves max class info into dependent variable section", "committedDate": "2020-04-16T15:21:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY4MDcwNQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r409680705", "bodyText": "To improve the performance of your {classanalysis}, consider to set a smaller training percent.\n\nWhen I read this, it's not immediately obvious what this means.  I had to go look at the API for a definition. Could we maybe change it to something like this?:\n\nTo improve... consider using a smaller training_percent value when you create the job. That is to say, use a smaller percentage of your documents to train the model more quickly.", "author": "lcawl", "createdAt": "2020-04-16T16:14:28Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -64,10 +54,33 @@ otherwise the {classanalysis} may not provide the best predictions. Read\n The ensemble algorithm that we use in the {stack} for {classification} is a type \n of boosting called boosted tree regression model which combines multiple weak \n models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+probability that a data point belongs to a certain class. A sequence of decision \n+trees are trained and every decision tree learns from the mistakes of the \n+previous one. Every tree is an iteration of the last one, hence it improves the \n+decision made by the previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200.000 data points. Therefore, if you double the number of \n+documents, then the runtime of the analysis doubles respectively. Above 200.000 \n+data points, runtime increases faster.\n+\n+To improve the performance of your {classanalysis}, consider to set a smaller ", "originalCommit": "365926f70d3728cc657687b0dcaa26286e8a7cc7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY4MjA3OQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r409682079", "bodyText": "The ensemble algorithm that we use....\n\nThis can likely be addressed in a separate PR, but I think we can rewrite these sentences to take \"us\" out of the picture.  For example, something like:  Classification analysis uses an ensemble algorithm... It uses decision trees...", "author": "lcawl", "createdAt": "2020-04-16T16:16:38Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -64,10 +54,33 @@ otherwise the {classanalysis} may not provide the best predictions. Read\n The ensemble algorithm that we use in the {stack} for {classification} is a type ", "originalCommit": "365926f70d3728cc657687b0dcaa26286e8a7cc7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0bf5a874b1bfc54c61e567bd9b248ce3cb0bc669", "url": "https://github.com/elastic/stack-docs/commit/0bf5a874b1bfc54c61e567bd9b248ce3cb0bc669", "message": "[DOCS] Minor edits to classification evaluation", "committedDate": "2020-04-16T16:36:32Z", "type": "commit"}, {"oid": "84211f1395d3c19836ead926f360d175a953fe61", "url": "https://github.com/elastic/stack-docs/commit/84211f1395d3c19836ead926f360d175a953fe61", "message": "[DOCS] Improves readability.", "committedDate": "2020-04-17T09:16:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMzMjY3NQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r410332675", "bodyText": "Minor wording change. I think it works better as \"setting\" or \"using\" than \"to set\".\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To improve the performance of your {classanalysis}, consider to set a smaller \n          \n          \n            \n            To improve the performance of your {classanalysis}, consider using a smaller", "author": "lcawl", "createdAt": "2020-04-17T16:24:58Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -17,57 +17,72 @@ other genres available in the set of categories we have. Therefore,\n {classification} is for predicting discrete, categorical values, unlike \n {reganalysis} which predicts continuous, numerical values.\n \n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the {depvar}. It\n+must contain no more than 30 classes. The rest of the fields that are included\n+in the analysis are used to create the model for predicting the value of the\n+{depvar} (these are the {feature-vars}). All\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+by default, however, you can explicitly exclude and/or include fields. Since the\n+runtime and the necessary resources for the analysis increase as the number of\n+included fields grow, consider including only relevant fields. For more\n+information about field selection, see \n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n \n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200.000 data points. Therefore, if you double the number of \n+documents, then the runtime of the analysis doubles respectively. Above 200.000 \n+data points, runtime increases faster.\n+\n+To improve the performance of your {classanalysis}, consider to set a smaller ", "originalCommit": "84211f1395d3c19836ead926f360d175a953fe61", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMzMzU3Mg==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r410333572", "bodyText": "Small typo\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            prepare your input data such that is has less classes. You can also remove the \n          \n          \n            \n            prepare your input data such that it has less classes. You can also remove the", "author": "lcawl", "createdAt": "2020-04-17T16:26:26Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -17,57 +17,72 @@ other genres available in the set of categories we have. Therefore,\n {classification} is for predicting discrete, categorical values, unlike \n {reganalysis} which predicts continuous, numerical values.\n \n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the {depvar}. It\n+must contain no more than 30 classes. The rest of the fields that are included\n+in the analysis are used to create the model for predicting the value of the\n+{depvar} (these are the {feature-vars}). All\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+by default, however, you can explicitly exclude and/or include fields. Since the\n+runtime and the necessary resources for the analysis increase as the number of\n+included fields grow, consider including only relevant fields. For more\n+information about field selection, see \n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n \n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200.000 data points. Therefore, if you double the number of \n+documents, then the runtime of the analysis doubles respectively. Above 200.000 \n+data points, runtime increases faster.\n+\n+To improve the performance of your {classanalysis}, consider to set a smaller \n+`training_percent` value when you create the job. That is to say, use a smaller \n+percentage of your documents to train the model more quickly. If possible, \n+prepare your input data such that is has less classes. You can also remove the ", "originalCommit": "84211f1395d3c19836ead926f360d175a953fe61", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDQ2OTA4NA==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r410469084", "bodyText": "Our style guide recommends using a comma to separate out numbers larger than 999.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            documents below 200.000 data points. Therefore, if you double the number of \n          \n          \n            \n            documents below 200,000 data points. Therefore, if you double the number of", "author": "lcawl", "createdAt": "2020-04-17T21:04:15Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -17,57 +17,72 @@ other genres available in the set of categories we have. Therefore,\n {classification} is for predicting discrete, categorical values, unlike \n {reganalysis} which predicts continuous, numerical values.\n \n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the {depvar}. It\n+must contain no more than 30 classes. The rest of the fields that are included\n+in the analysis are used to create the model for predicting the value of the\n+{depvar} (these are the {feature-vars}). All\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+by default, however, you can explicitly exclude and/or include fields. Since the\n+runtime and the necessary resources for the analysis increase as the number of\n+included fields grow, consider including only relevant fields. For more\n+information about field selection, see \n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n \n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200.000 data points. Therefore, if you double the number of ", "originalCommit": "84211f1395d3c19836ead926f360d175a953fe61", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDQ2OTI4OQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r410469289", "bodyText": "Ditto re thousand separator:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            documents, then the runtime of the analysis doubles respectively. Above 200.000 \n          \n          \n            \n            documents, then the runtime of the analysis doubles respectively. Above 200,000", "author": "lcawl", "createdAt": "2020-04-17T21:04:45Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -17,57 +17,72 @@ other genres available in the set of categories we have. Therefore,\n {classification} is for predicting discrete, categorical values, unlike \n {reganalysis} which predicts continuous, numerical values.\n \n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the {depvar}. It\n+must contain no more than 30 classes. The rest of the fields that are included\n+in the analysis are used to create the model for predicting the value of the\n+{depvar} (these are the {feature-vars}). All\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+by default, however, you can explicitly exclude and/or include fields. Since the\n+runtime and the necessary resources for the analysis increase as the number of\n+included fields grow, consider including only relevant fields. For more\n+information about field selection, see \n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n {classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n+means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n \n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200.000 data points. Therefore, if you double the number of \n+documents, then the runtime of the analysis doubles respectively. Above 200.000 ", "originalCommit": "84211f1395d3c19836ead926f360d175a953fe61", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "06af2f39b8668cc3fec130404b4b6192d01780fe", "url": "https://github.com/elastic/stack-docs/commit/06af2f39b8668cc3fec130404b4b6192d01780fe", "message": "[DOCS] Shortens sentences in introduction", "committedDate": "2020-04-18T00:19:18Z", "type": "commit"}, {"oid": "9010d2c2b3484df475d64bd5145b82bde87781da", "url": "https://github.com/elastic/stack-docs/commit/9010d2c2b3484df475d64bd5145b82bde87781da", "message": "[DOCS] Shortens sentences in second paragraph", "committedDate": "2020-04-18T00:48:24Z", "type": "commit"}, {"oid": "e9ad9e779ea8e8e2080f9269e0e42ecb110c0bb0", "url": "https://github.com/elastic/stack-docs/commit/e9ad9e779ea8e8e2080f9269e0e42ecb110c0bb0", "message": "Apply suggestions from code review\n\nCo-Authored-By: Lisa Cawley <lcawley@elastic.co>", "committedDate": "2020-04-20T07:11:55Z", "type": "commit"}, {"oid": "8ebf68f022ae2e55dac90d3b30c490f4709652e6", "url": "https://github.com/elastic/stack-docs/commit/8ebf68f022ae2e55dac90d3b30c490f4709652e6", "message": "[DOCS] Augment classification training details", "committedDate": "2020-04-20T17:57:04Z", "type": "commit"}, {"oid": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "url": "https://github.com/elastic/stack-docs/commit/9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "message": "[DOCS] Fixes broken link", "committedDate": "2020-04-20T18:12:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyMzA4NQ==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413123085", "bodyText": "Hello everyone! \ud83d\udc4b\nVery minor issue, but I would consider rewording this sentence detecting cancer in a DNA sequence to something like detecting the potential for cancer from a DNA sequence , because technically cancer is an illness in a tissue/organ and not in the DNA sequence.", "author": "Winterflower", "createdAt": "2020-04-22T16:18:17Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyNDUyMw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413124523", "bodyText": "Could we please clarify what eligible documents are? For ex, I know we exclude documents if they have a field that has an array with more than one element (cc: @dimitris-athanasiou - could you please assist in getting this worded correctly). We don't have to define it in this paragraph, but it would be nice to link to a section that explains what documents are eligible.", "author": "Winterflower", "createdAt": "2020-04-22T16:20:17Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the\n+investment history, employment status, debit status, and other financial details\n+for loan applicants. Based on this data, you could use {classanalysis} to create\n+a model that predicts whether it is safe or risky to lend money to applicants.\n+In the second case, the data contains song details that enable you to classify\n+music into genres like hip-hop, country, or classical, for example.\n+{classification-cap} is for predicting discrete, categorical values, whereas\n+<<dfa-regression,{reganalysis}>> predicts continuous, numerical values.\n+\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the _{depvar}_. It\n+must contain no more than 30 classes. By default, all other\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+in the analysis and are known as _{feature-vars}_. The runtime and resources\n+used by the job increase with the number of feature variables. Therefore, you\n+can optionally include or exclude fields from the analysis. For more information\n+about field selection, see the\n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n-{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n-\n+{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process.\n+When you create the {dfanalytics-job}, you must provide a data set that contains\n+the _ground truth_. That is to say, your data set must contain the {depvar} \n+and the {feature-vars} fields that are related to it. You can divide the data\n+set into training and testing data by specifying a `training_percent`. By\n+default when you use the\n+{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API], 100% of the eligible", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyNjE4Mw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413126183", "bodyText": "I would clarify the concept of stratification here by saying the training and testing data contains classes in proportions that are representative of the class proportions in the full data set and maybe take out the next sentence - the one starting with That is to say, (cc: @tveasey )", "author": "Winterflower", "createdAt": "2020-04-22T16:22:21Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the\n+investment history, employment status, debit status, and other financial details\n+for loan applicants. Based on this data, you could use {classanalysis} to create\n+a model that predicts whether it is safe or risky to lend money to applicants.\n+In the second case, the data contains song details that enable you to classify\n+music into genres like hip-hop, country, or classical, for example.\n+{classification-cap} is for predicting discrete, categorical values, whereas\n+<<dfa-regression,{reganalysis}>> predicts continuous, numerical values.\n+\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the _{depvar}_. It\n+must contain no more than 30 classes. By default, all other\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+in the analysis and are known as _{feature-vars}_. The runtime and resources\n+used by the job increase with the number of feature variables. Therefore, you\n+can optionally include or exclude fields from the analysis. For more information\n+about field selection, see the\n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n-{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n-\n+{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process.\n+When you create the {dfanalytics-job}, you must provide a data set that contains\n+the _ground truth_. That is to say, your data set must contain the {depvar} \n+and the {feature-vars} fields that are related to it. You can divide the data\n+set into training and testing data by specifying a `training_percent`. By\n+default when you use the\n+{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API], 100% of the eligible\n+documents in the data set are used for training. If you divide your data set,\n+the job stratifies the data to ensure that both the training and testing data\n+sets are representative of the full data set. That is to say, the same", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyODk4Mg==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413128982", "bodyText": "I would clarify this part If some classes are poorly represented in the training data set by saying something like If some classes are poorly represented in the training data set (that is, you have very few data points per class)", "author": "Winterflower", "createdAt": "2020-04-22T16:26:05Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the\n+investment history, employment status, debit status, and other financial details\n+for loan applicants. Based on this data, you could use {classanalysis} to create\n+a model that predicts whether it is safe or risky to lend money to applicants.\n+In the second case, the data contains song details that enable you to classify\n+music into genres like hip-hop, country, or classical, for example.\n+{classification-cap} is for predicting discrete, categorical values, whereas\n+<<dfa-regression,{reganalysis}>> predicts continuous, numerical values.\n+\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the _{depvar}_. It\n+must contain no more than 30 classes. By default, all other\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+in the analysis and are known as _{feature-vars}_. The runtime and resources\n+used by the job increase with the number of feature variables. Therefore, you\n+can optionally include or exclude fields from the analysis. For more information\n+about field selection, see the\n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n-{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n-\n+{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process.\n+When you create the {dfanalytics-job}, you must provide a data set that contains\n+the _ground truth_. That is to say, your data set must contain the {depvar} \n+and the {feature-vars} fields that are related to it. You can divide the data\n+set into training and testing data by specifying a `training_percent`. By\n+default when you use the\n+{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API], 100% of the eligible\n+documents in the data set are used for training. If you divide your data set,\n+the job stratifies the data to ensure that both the training and testing data\n+sets are representative of the full data set. That is to say, the same\n+proportions of each class are fairly represented in both data sets.\n+\n+When you are collecting a data set to train your model, ensure that it\n+captures information for all of the classes. If some classes are poorly\n+represented in the training data set, the model might be unaware of them. In", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEzMDAyNw==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413130027", "bodyText": "I would say the runtime is roughly linear here to allow ourselves some wiggle room.", "author": "Winterflower", "createdAt": "2020-04-22T16:27:27Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the\n+investment history, employment status, debit status, and other financial details\n+for loan applicants. Based on this data, you could use {classanalysis} to create\n+a model that predicts whether it is safe or risky to lend money to applicants.\n+In the second case, the data contains song details that enable you to classify\n+music into genres like hip-hop, country, or classical, for example.\n+{classification-cap} is for predicting discrete, categorical values, whereas\n+<<dfa-regression,{reganalysis}>> predicts continuous, numerical values.\n+\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the _{depvar}_. It\n+must contain no more than 30 classes. By default, all other\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+in the analysis and are known as _{feature-vars}_. The runtime and resources\n+used by the job increase with the number of feature variables. Therefore, you\n+can optionally include or exclude fields from the analysis. For more information\n+about field selection, see the\n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n-{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n-\n+{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process.\n+When you create the {dfanalytics-job}, you must provide a data set that contains\n+the _ground truth_. That is to say, your data set must contain the {depvar} \n+and the {feature-vars} fields that are related to it. You can divide the data\n+set into training and testing data by specifying a `training_percent`. By\n+default when you use the\n+{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API], 100% of the eligible\n+documents in the data set are used for training. If you divide your data set,\n+the job stratifies the data to ensure that both the training and testing data\n+sets are representative of the full data set. That is to say, the same\n+proportions of each class are fairly represented in both data sets.\n+\n+When you are collecting a data set to train your model, ensure that it\n+captures information for all of the classes. If some classes are poorly\n+represented in the training data set, the model might be unaware of them. In\n+general, complex decision boundaries between classes are harder to learn and\n+require more data points per class in the training data.\n+\n+////\n+It means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n+////\n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEzMTU3Ng==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413131576", "bodyText": "I think this paragraph might be a too much detail, because the exact conditions that we have when testing the runtime won't necessarily translate to the user's environment, so they might experience something different. I would leave in this sentence starting with Therefore, if you double the number of  documents, ...\nI would remove this Above 200,000  data points, runtime increases faster., because it is a bit too specific.", "author": "Winterflower", "createdAt": "2020-04-22T16:29:25Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the\n+investment history, employment status, debit status, and other financial details\n+for loan applicants. Based on this data, you could use {classanalysis} to create\n+a model that predicts whether it is safe or risky to lend money to applicants.\n+In the second case, the data contains song details that enable you to classify\n+music into genres like hip-hop, country, or classical, for example.\n+{classification-cap} is for predicting discrete, categorical values, whereas\n+<<dfa-regression,{reganalysis}>> predicts continuous, numerical values.\n+\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the _{depvar}_. It\n+must contain no more than 30 classes. By default, all other\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+in the analysis and are known as _{feature-vars}_. The runtime and resources\n+used by the job increase with the number of feature variables. Therefore, you\n+can optionally include or exclude fields from the analysis. For more information\n+about field selection, see the\n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n-{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n-\n+{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process.\n+When you create the {dfanalytics-job}, you must provide a data set that contains\n+the _ground truth_. That is to say, your data set must contain the {depvar} \n+and the {feature-vars} fields that are related to it. You can divide the data\n+set into training and testing data by specifying a `training_percent`. By\n+default when you use the\n+{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API], 100% of the eligible\n+documents in the data set are used for training. If you divide your data set,\n+the job stratifies the data to ensure that both the training and testing data\n+sets are representative of the full data set. That is to say, the same\n+proportions of each class are fairly represented in both data sets.\n+\n+When you are collecting a data set to train your model, ensure that it\n+captures information for all of the classes. If some classes are poorly\n+represented in the training data set, the model might be unaware of them. In\n+general, complex decision boundaries between classes are harder to learn and\n+require more data points per class in the training data.\n+\n+////\n+It means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n+////\n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200,000 data points. Therefore, if you double the number of ", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEzMjE5MA==", "url": "https://github.com/elastic/stack-docs/pull/973#discussion_r413132190", "bodyText": "I would add here that the key is iteration. The user can start by using a smaller training percentage, run the job, check the performance and then decide if it's necessary to increase the training percentage.", "author": "Winterflower", "createdAt": "2020-04-22T16:30:18Z", "path": "docs/en/stack/ml/df-analytics/dfa-classification.asciidoc", "diffHunk": "@@ -4,70 +4,100 @@\n \n experimental[]\n \n-{classification-cap} is a {ml} process for predicting the class or category of a \n-given data point in a dataset. Typical examples of {classification} problems are \n-predicting loan risk, classifying music, or detecting cancer in a DNA sequence. \n-In the first case, for example, our dataset consists of data on loan applicants \n-that covers investment history, employment status, debit status, and so on. \n-Based on historical data, the {classification} analysis predicts whether it is \n-safe or risky to lend money to a given loan applicant. In the second case, the \n-data we have represents songs and the analysis \u2013 based on the features of the \n-data points \u2013 classifies the songs as hip-hop, country, classical, or any \n-other genres available in the set of categories we have. Therefore, \n-{classification} is for predicting discrete, categorical values, unlike \n-{reganalysis} which predicts continuous, numerical values.\n-\n-From the perspective of the possible output, there are two types of \n-{classification}: binary and multi-class {classification}. In binary \n-{classification} the variable you want to predict has only two potential values. \n-The loan example above is a binary {classification} problem where the two \n-potential outputs are `safe` or `risky`. The music classification problem is an \n-example of multi-class {classification} where there are many different potential \n-outputs; one for every possible music genre. In the {version} version of the \n-{stack}, you can perform only binary {classanalysis}.\n-\n-\n-[discrete]\n-[[dfa-classification-features]]\n-==== {feature-vars-cap}\n-\n-When you perform {classification}, you must identify a subset of fields that you \n-want to use to create a model for predicting another field value. We refer to \n-these fields as _{feature-vars}_ and _{depvar}_, respectively. \n-{feature-vars-cap} are the values that the {depvar} value depends on. There are \n-three different types of {feature-vars} that you can use with our \n-{classification} algorithm: numerical, categorical, and boolean. Arrays are not \n-supported in the {feature-var} fields.\n+{classification-cap} is a {ml} process that enables you to predict the class or\n+category of a data point in your data set. Typical examples of {classification}\n+problems are predicting loan risk, classifying music, or detecting cancer in a\n+DNA sequence. In the first case, for example, the data set might contain the\n+investment history, employment status, debit status, and other financial details\n+for loan applicants. Based on this data, you could use {classanalysis} to create\n+a model that predicts whether it is safe or risky to lend money to applicants.\n+In the second case, the data contains song details that enable you to classify\n+music into genres like hip-hop, country, or classical, for example.\n+{classification-cap} is for predicting discrete, categorical values, whereas\n+<<dfa-regression,{reganalysis}>> predicts continuous, numerical values.\n+\n+When you create a {classification} job, you must specify which field contains \n+the classes that you want to predict. This field is known as the _{depvar}_. It\n+must contain no more than 30 classes. By default, all other\n+{ref}/put-dfanalytics.html#dfa-supported-fields[supported fields] are included\n+in the analysis and are known as _{feature-vars}_. The runtime and resources\n+used by the job increase with the number of feature variables. Therefore, you\n+can optionally include or exclude fields from the analysis. For more information\n+about field selection, see the\n+{ref}/explain-dfanalytics.html[explain data frame analytics API].\n \n \n [discrete]\n [[dfa-classification-supervised]]\n ==== Training the {classification} model\n \n-{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process. It \n-means that you need to supply a labeled training dataset that has some \n-{feature-vars} and a {depvar}. The {classification} algorithm learns the \n-relationships between the features and the {depvar}. Once you\u2019ve trained the \n-model on your training dataset, you can reuse the knowledge that the model has \n-learned about the relationships between the data points to classify new data. \n-Your training dataset should be approximately balanced which means the number of \n-data points belonging to the various classes should not be widely different, \n-otherwise the {classanalysis} may not provide the best predictions. Read \n-<<dfa-classification-imbalanced-classes>> to learn more.\n-\n+{classification-cap} \u2013 just like {regression} \u2013 is a supervised {ml} process.\n+When you create the {dfanalytics-job}, you must provide a data set that contains\n+the _ground truth_. That is to say, your data set must contain the {depvar} \n+and the {feature-vars} fields that are related to it. You can divide the data\n+set into training and testing data by specifying a `training_percent`. By\n+default when you use the\n+{ref}/put-dfanalytics.html[create {dfanalytics-jobs} API], 100% of the eligible\n+documents in the data set are used for training. If you divide your data set,\n+the job stratifies the data to ensure that both the training and testing data\n+sets are representative of the full data set. That is to say, the same\n+proportions of each class are fairly represented in both data sets.\n+\n+When you are collecting a data set to train your model, ensure that it\n+captures information for all of the classes. If some classes are poorly\n+represented in the training data set, the model might be unaware of them. In\n+general, complex decision boundaries between classes are harder to learn and\n+require more data points per class in the training data.\n+\n+////\n+It means that you need to supply a labeled training data set that has a {depvar} \n+and some fields that are related to it. The {classification} algorithm learns \n+the relationships between these fields and the {depvar}. Once you\u2019ve trained the \n+model on your training data set, you can reuse the knowledge that the model has \n+learned about the relationships between the data points to classify new data.\n+\n+The effects of imbalanced data are automatically mitigated before the \n+training. Nonetheless, it is a good idea to train your model with a data set \n+that is approximately balanced. That is to say, ideally your data set should \n+have a similar number of data points for each class.\n+////\n \n [discrete]\n [[dfa-classification-algorithm]]\n ===== {classification-cap} algorithms\n \n //tag::classification-algorithms[]\n-The ensemble algorithm that we use in the {stack} for {classification} is a type \n-of boosting called boosted tree regression model which combines multiple weak \n-models into a composite one. We use decision trees to learn to predict the \n-probability that a data point belongs to a certain class.\n+{classanalysis-cap} uses an ensemble algorithm that is a type of boosting called \n+boosted tree regression model which combines multiple weak models into a \n+composite one. It uses decision trees to learn to predict the probability that a \n+data point belongs to a certain class. A sequence of decision trees are trained \n+and every decision tree learns from the mistakes of the previous one. Every tree \n+is an iteration of the last one, hence it improves the decision made by the \n+previous tree.\n //end::classification-algorithms[]\n \n \n+[discrete]\n+[[dfa-classification-performance]]\n+==== {classification-cap} performance\n+\n+As a rule of thumb, a {classanalysis} with many classes takes more time to run \n+than a binary {classification} process when there are only two classes. The \n+relationship between the number of classes and the runtime is linear.\n+\n+The runtime also scales approximately linearly with the number of involved \n+documents below 200,000 data points. Therefore, if you double the number of \n+documents, then the runtime of the analysis doubles respectively. Above 200,000 \n+data points, runtime increases faster.\n+\n+To improve the performance of your {classanalysis}, consider using a smaller \n+`training_percent` value when you create the job. That is to say, use a smaller \n+percentage of your documents to train the model more quickly. If possible, ", "originalCommit": "9a8eb36dd670b06b16c57f19d4d12e1a0fda9d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1663d1c2d813081a198b02ea317a0a33fa7fd320", "url": "https://github.com/elastic/stack-docs/commit/1663d1c2d813081a198b02ea317a0a33fa7fd320", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-04-23T13:34:56Z", "type": "commit"}]}