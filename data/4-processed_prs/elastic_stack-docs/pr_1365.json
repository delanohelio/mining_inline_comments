{"pr_number": 1365, "pr_title": "[DOCS] Adds classification AUC ROC metric description", "pr_createdAt": "2020-09-18T07:35:08Z", "pr_url": "https://github.com/elastic/stack-docs/pull/1365", "timeline": [{"oid": "bb413da73bcfea320b4f27aa0738bbabed94c66a", "url": "https://github.com/elastic/stack-docs/commit/bb413da73bcfea320b4f27aa0738bbabed94c66a", "message": "[DOCS] Adds classification AUC ROC metric description.", "committedDate": "2020-09-18T07:32:54Z", "type": "commit"}, {"oid": "1596b5ef58f83d84f14680ec5953965d86518083", "url": "https://github.com/elastic/stack-docs/commit/1596b5ef58f83d84f14680ec5953965d86518083", "message": "[DOCS] Makes example more exact.", "committedDate": "2020-09-18T09:53:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTIxNjMwOA==", "url": "https://github.com/elastic/stack-docs/pull/1365#discussion_r491216308", "bodyText": "I think you need to use \"unconstrained\" backticks to make this format properly:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            calculate AUC ROC for `A`. In this case, the number of correctly classified `A`s \n          \n          \n            \n            calculate AUC ROC for `A`. In this case, the number of correctly classified ``A``s", "author": "lcawl", "createdAt": "2020-09-18T22:11:55Z", "path": "docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc", "diffHunk": "@@ -163,3 +164,21 @@ The matrix contains the actual labels on the left side while the predicted\n labels are on the top. The proportion of correct and incorrect predictions is \n broken down for each class. This enables you to examine how the {classanalysis}\n confused the different classes while it made its predictions.\n+\n+\n+[[ml-dfanalytics-class-aucroc]]\n+=== Area under the curve of receiver operating characteristic (AUC ROC)\n+\n+The receiver operating characteristic (ROC) curve is a plot that represents the \n+performance of the classification process at different predicted probability \n+thresholds. It compares the true positive rate for a specific class against the \n+rate of all the other classes combined (\"one versus all\" strategy) at the \n+different threshold levels to create the curve.\n+\n+Let's see an example. You have three classes: `A`, `B`, and `C`, you want to \n+calculate AUC ROC for `A`. In this case, the number of correctly classified `A`s ", "originalCommit": "1596b5ef58f83d84f14680ec5953965d86518083", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTIxNjQxOQ==", "url": "https://github.com/elastic/stack-docs/pull/1365#discussion_r491216419", "bodyText": "Ditto re backticks:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            (true positives) are compared to the number of `B`s and `C`s that are \n          \n          \n            \n            (true positives) are compared to the number of ``B``s and ``C``s that are", "author": "lcawl", "createdAt": "2020-09-18T22:12:24Z", "path": "docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc", "diffHunk": "@@ -163,3 +164,21 @@ The matrix contains the actual labels on the left side while the predicted\n labels are on the top. The proportion of correct and incorrect predictions is \n broken down for each class. This enables you to examine how the {classanalysis}\n confused the different classes while it made its predictions.\n+\n+\n+[[ml-dfanalytics-class-aucroc]]\n+=== Area under the curve of receiver operating characteristic (AUC ROC)\n+\n+The receiver operating characteristic (ROC) curve is a plot that represents the \n+performance of the classification process at different predicted probability \n+thresholds. It compares the true positive rate for a specific class against the \n+rate of all the other classes combined (\"one versus all\" strategy) at the \n+different threshold levels to create the curve.\n+\n+Let's see an example. You have three classes: `A`, `B`, and `C`, you want to \n+calculate AUC ROC for `A`. In this case, the number of correctly classified `A`s \n+(true positives) are compared to the number of `B`s and `C`s that are ", "originalCommit": "1596b5ef58f83d84f14680ec5953965d86518083", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTIxNjUxNw==", "url": "https://github.com/elastic/stack-docs/pull/1365#discussion_r491216517", "bodyText": "Ditto:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            misclassified as `A`s (false positives).\n          \n          \n            \n            misclassified as ``A``s (false positives).", "author": "lcawl", "createdAt": "2020-09-18T22:12:43Z", "path": "docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc", "diffHunk": "@@ -163,3 +164,21 @@ The matrix contains the actual labels on the left side while the predicted\n labels are on the top. The proportion of correct and incorrect predictions is \n broken down for each class. This enables you to examine how the {classanalysis}\n confused the different classes while it made its predictions.\n+\n+\n+[[ml-dfanalytics-class-aucroc]]\n+=== Area under the curve of receiver operating characteristic (AUC ROC)\n+\n+The receiver operating characteristic (ROC) curve is a plot that represents the \n+performance of the classification process at different predicted probability \n+thresholds. It compares the true positive rate for a specific class against the \n+rate of all the other classes combined (\"one versus all\" strategy) at the \n+different threshold levels to create the curve.\n+\n+Let's see an example. You have three classes: `A`, `B`, and `C`, you want to \n+calculate AUC ROC for `A`. In this case, the number of correctly classified `A`s \n+(true positives) are compared to the number of `B`s and `C`s that are \n+misclassified as `A`s (false positives).", "originalCommit": "1596b5ef58f83d84f14680ec5953965d86518083", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTIyMDcxOQ==", "url": "https://github.com/elastic/stack-docs/pull/1365#discussion_r491220719", "bodyText": "The close to 1, the better the algorithm performance.\n\nI got to this point and wasn't sure which \"algorithm\" this sentence was referring to or what aspect of its performance we were judging.  Can we be more specific  in summing this up?  For example, something like this:\n\nThe higher the AUC, the better the model is at predicting As as As, in this case.", "author": "lcawl", "createdAt": "2020-09-18T22:28:48Z", "path": "docs/en/stack/ml/df-analytics/ml-dfanalytics-evaluate.asciidoc", "diffHunk": "@@ -163,3 +164,21 @@ The matrix contains the actual labels on the left side while the predicted\n labels are on the top. The proportion of correct and incorrect predictions is \n broken down for each class. This enables you to examine how the {classanalysis}\n confused the different classes while it made its predictions.\n+\n+\n+[[ml-dfanalytics-class-aucroc]]\n+=== Area under the curve of receiver operating characteristic (AUC ROC)\n+\n+The receiver operating characteristic (ROC) curve is a plot that represents the \n+performance of the classification process at different predicted probability \n+thresholds. It compares the true positive rate for a specific class against the \n+rate of all the other classes combined (\"one versus all\" strategy) at the \n+different threshold levels to create the curve.\n+\n+Let's see an example. You have three classes: `A`, `B`, and `C`, you want to \n+calculate AUC ROC for `A`. In this case, the number of correctly classified `A`s \n+(true positives) are compared to the number of `B`s and `C`s that are \n+misclassified as `A`s (false positives).\n+\n+From this plot, you can compute the area under the curve (AUC) value, which is a \n+number between 0 and 1. The closer to 1, the better the algorithm performance.", "originalCommit": "1596b5ef58f83d84f14680ec5953965d86518083", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3c07d2bf2fdd7b636a85d0538a846e5816f15d76", "url": "https://github.com/elastic/stack-docs/commit/3c07d2bf2fdd7b636a85d0538a846e5816f15d76", "message": "Apply suggestions from code review\n\nCo-authored-by: Lisa Cawley <lcawley@elastic.co>", "committedDate": "2020-09-21T08:03:17Z", "type": "commit"}, {"oid": "21315693f24a0b92f7f7b776f2b175f1537ebe09", "url": "https://github.com/elastic/stack-docs/commit/21315693f24a0b92f7f7b776f2b175f1537ebe09", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-09-21T08:08:05Z", "type": "commit"}, {"oid": "97d51074c99d0f85360a58783f2dc6636a57605f", "url": "https://github.com/elastic/stack-docs/commit/97d51074c99d0f85360a58783f2dc6636a57605f", "message": "[DOCS] Fixes monospaced characters.", "committedDate": "2020-09-21T08:48:38Z", "type": "commit"}]}