{"pr_number": 1176, "pr_title": "[HUDI-430] Adding InlineFileSystem to support embedding any file format as an InlineFile", "pr_createdAt": "2020-01-03T22:46:33Z", "pr_url": "https://github.com/apache/hudi/pull/1176", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEzMjQzNg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r386132436", "bodyText": "can we move all of this code to hudi-common", "author": "vinothchandar", "createdAt": "2020-03-01T19:10:44Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InMemoryFileSystem.java", "diffHunk": "@@ -0,0 +1,120 @@\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Progressable;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+\n+/**\n+ * A FileSystem which stores all content in memory and returns a byte[] when {@link #getFileAsBytes()} is called\n+ * This FileSystem is used only in write path. Does not support any read apis except {@link #getFileAsBytes()}.\n+ */\n+public class InMemoryFileSystem extends FileSystem {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzExMTgyMw==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r387111823", "bodyText": "Sure. will address along with other feedback. Guess you are not blocked from your review on this.", "author": "nsivabalan", "createdAt": "2020-03-03T15:49:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjEzMjQzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTU3NQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393285575", "bodyText": "may be a better example on the second line?", "author": "vinothchandar", "createdAt": "2020-03-16T20:15:27Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NjI2NQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393286265", "bodyText": "rename: getInlineFilePath()? (Prefer Inline to InLine everywhere for camelcasing it)", "author": "vinothchandar", "createdAt": "2020-03-16T20:16:56Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40\n+   * Output: \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\"\n+   *\n+   * @param outerPath\n+   * @param origScheme\n+   * @param inLineStartOffset\n+   * @param inLineLength\n+   * @return\n+   */\n+  public static Path getEmbeddedInLineFilePath(Path outerPath, String origScheme, long inLineStartOffset, long inLineLength) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4Njk1NA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393286954", "bodyText": "ensure that toString() will always yield something with the scheme? may be there is a more direct method for this?", "author": "vinothchandar", "createdAt": "2020-03-16T20:18:33Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40\n+   * Output: \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\"\n+   *\n+   * @param outerPath\n+   * @param origScheme\n+   * @param inLineStartOffset\n+   * @param inLineLength\n+   * @return\n+   */\n+  public static Path getEmbeddedInLineFilePath(Path outerPath, String origScheme, long inLineStartOffset, long inLineLength) {\n+    String subPath = outerPath.toString().substring(outerPath.toString().indexOf(\":\") + 1);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTEyMDgyMQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395120821", "bodyText": "I checked Path, but couldn't find anything. toString() does have scheme if present.\n@OverRide\npublic String toString() {\n// we can't use uri.toString(), which escapes everything, because we want\n// illegal characters unescaped in the string, for glob processing, etc.\nStringBuilder buffer = new StringBuilder();\nif (uri.getScheme() != null) {\nbuffer.append(uri.getScheme());\nbuffer.append(\":\");\n}\nif (uri.getAuthority() != null) {\nbuffer.append(\"//\");\nbuffer.append(uri.getAuthority());\n}\nif (uri.getPath() != null) {\nString path = uri.getPath();\nif (path.indexOf('/')==0 &&\nhasWindowsDrive(path) &&                // has windows drive\nuri.getScheme() == null &&              // but no scheme\nuri.getAuthority() == null)             // or authority\npath = path.substring(1);                 // remove slash before drive\nbuffer.append(path);\n}\nif (uri.getFragment() != null) {\nbuffer.append(\"#\");\nbuffer.append(uri.getFragment());\n}\nreturn buffer.toString();\n}", "author": "nsivabalan", "createdAt": "2020-03-19T15:37:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4Njk1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NzYzMw==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393287633", "bodyText": "use a different scheme like hdfs: or s3a for illustration? :)", "author": "vinothchandar", "createdAt": "2020-03-16T20:20:02Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4ODM0Mw==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393288343", "bodyText": "whats the purpose of this string?", "author": "vinothchandar", "createdAt": "2020-03-16T20:21:31Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5NTA4NA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395395084", "bodyText": "Nothing significant. I am just using it to delimit regular path info from inline related attributes.\nEg: \"inlinefs://<path_to_outer_file>/s3a/inline_file/?start_offset=20&length=40\". If you feel, its not adding much value, I can remove it.", "author": "nsivabalan", "createdAt": "2020-03-20T00:49:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4ODM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4ODY3Ng==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393288676", "bodyText": "break to a new line at \"&\" for readability?", "author": "vinothchandar", "createdAt": "2020-03-16T20:22:19Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40\n+   * Output: \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\"\n+   *\n+   * @param outerPath\n+   * @param origScheme\n+   * @param inLineStartOffset\n+   * @param inLineLength\n+   * @return\n+   */\n+  public static Path getEmbeddedInLineFilePath(Path outerPath, String origScheme, long inLineStartOffset, long inLineLength) {\n+    String subPath = outerPath.toString().substring(outerPath.toString().indexOf(\":\") + 1);\n+    return new Path(\n+        InlineFileSystem.SCHEME + \"://\" + subPath + \"/\" + origScheme + \"/\" + INLINE_FILE_STR + \"/\"\n+            + \"?\" + START_OFFSET_STR + EQUALS_STR + inLineStartOffset + \"&\" + LENGTH_STR + EQUALS_STR + inLineLength", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4OTQ4NA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393289484", "bodyText": "Similarly above, could we have just replaced file: with inlinefs, instead of indexOf().", "author": "vinothchandar", "createdAt": "2020-03-16T20:24:04Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40\n+   * Output: \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\"\n+   *\n+   * @param outerPath\n+   * @param origScheme\n+   * @param inLineStartOffset\n+   * @param inLineLength\n+   * @return\n+   */\n+  public static Path getEmbeddedInLineFilePath(Path outerPath, String origScheme, long inLineStartOffset, long inLineLength) {\n+    String subPath = outerPath.toString().substring(outerPath.toString().indexOf(\":\") + 1);\n+    return new Path(\n+        InlineFileSystem.SCHEME + \"://\" + subPath + \"/\" + origScheme + \"/\" + INLINE_FILE_STR + \"/\"\n+            + \"?\" + START_OFFSET_STR + EQUALS_STR + inLineStartOffset + \"&\" + LENGTH_STR + EQUALS_STR + inLineLength\n+    );\n+  }\n+\n+  /**\n+   * Eg input : \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\".\n+   * Output : \"file:/file1\"\n+   *\n+   * @param inlinePath\n+   * @param outerScheme\n+   * @return\n+   */\n+  public static Path getOuterfilePathFromInlinePath(Path inlinePath, String outerScheme) {\n+    String scheme = inlinePath.getParent().getParent().getName();\n+    Path basePath = inlinePath.getParent().getParent().getParent();\n+    return new Path(basePath.toString().replaceFirst(outerScheme, scheme));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5NTgzMQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395395831", "bodyText": "sorry I don't get you. I haven't used indexOf() in this method at all. not sure I get your feedback.", "author": "nsivabalan", "createdAt": "2020-03-20T00:53:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4OTQ4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4OTk2NQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393289965", "bodyText": "above example does not make it easy to understand what outerScheme is? is n't outerScheme always inlinefs if this is an inlinePath? Should we need to pass it in?", "author": "vinothchandar", "createdAt": "2020-03-16T20:25:05Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40\n+   * Output: \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\"\n+   *\n+   * @param outerPath\n+   * @param origScheme\n+   * @param inLineStartOffset\n+   * @param inLineLength\n+   * @return\n+   */\n+  public static Path getEmbeddedInLineFilePath(Path outerPath, String origScheme, long inLineStartOffset, long inLineLength) {\n+    String subPath = outerPath.toString().substring(outerPath.toString().indexOf(\":\") + 1);\n+    return new Path(\n+        InlineFileSystem.SCHEME + \"://\" + subPath + \"/\" + origScheme + \"/\" + INLINE_FILE_STR + \"/\"\n+            + \"?\" + START_OFFSET_STR + EQUALS_STR + inLineStartOffset + \"&\" + LENGTH_STR + EQUALS_STR + inLineLength\n+    );\n+  }\n+\n+  /**\n+   * Eg input : \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\".\n+   * Output : \"file:/file1\"\n+   *\n+   * @param inlinePath\n+   * @param outerScheme\n+   * @return\n+   */\n+  public static Path getOuterfilePathFromInlinePath(Path inlinePath, String outerScheme) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5ODI3MQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395398271", "bodyText": "actually you are right. will fix it.", "author": "nsivabalan", "createdAt": "2020-03-20T01:04:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4OTk2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MDYyNw==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393290627", "bodyText": "can we implement this using split() and then picking the ith index.. instead of relying on first and last?", "author": "vinothchandar", "createdAt": "2020-03-16T20:26:33Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InLineFSUtils.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Utils to parse InlineFileSystem paths.\n+ * Inline FS format: \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/<start_offset>/<length>\"\n+ * \"inlinefs:/<path_to_outer_file>/<outer_file_scheme>/inline_file/?start_offset=start_offset>&length=<length>\"\n+ */\n+public class InLineFSUtils {\n+\n+  private static final String INLINE_FILE_STR = \"inline_file\";\n+  private static final String START_OFFSET_STR = \"start_offset\";\n+  private static final String LENGTH_STR = \"length\";\n+  private static final String EQUALS_STR = \"=\";\n+\n+  /**\n+   * Fetch embedded inline file path from outer path.\n+   * Eg\n+   * Input:\n+   * Path = file:/file1, origScheme: file, startOffset = 20, length = 40\n+   * Output: \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\"\n+   *\n+   * @param outerPath\n+   * @param origScheme\n+   * @param inLineStartOffset\n+   * @param inLineLength\n+   * @return\n+   */\n+  public static Path getEmbeddedInLineFilePath(Path outerPath, String origScheme, long inLineStartOffset, long inLineLength) {\n+    String subPath = outerPath.toString().substring(outerPath.toString().indexOf(\":\") + 1);\n+    return new Path(\n+        InlineFileSystem.SCHEME + \"://\" + subPath + \"/\" + origScheme + \"/\" + INLINE_FILE_STR + \"/\"\n+            + \"?\" + START_OFFSET_STR + EQUALS_STR + inLineStartOffset + \"&\" + LENGTH_STR + EQUALS_STR + inLineLength\n+    );\n+  }\n+\n+  /**\n+   * Eg input : \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\".\n+   * Output : \"file:/file1\"\n+   *\n+   * @param inlinePath\n+   * @param outerScheme\n+   * @return\n+   */\n+  public static Path getOuterfilePathFromInlinePath(Path inlinePath, String outerScheme) {\n+    String scheme = inlinePath.getParent().getParent().getName();\n+    Path basePath = inlinePath.getParent().getParent().getParent();\n+    return new Path(basePath.toString().replaceFirst(outerScheme, scheme));\n+  }\n+\n+  /**\n+   * Eg input : \"inlinefs:/file1/file/inline_file/?start_offset=20&length=40\".\n+   * output: 20\n+   *\n+   * @param inlinePath\n+   * @return\n+   */\n+  public static int startOffset(Path inlinePath) {\n+    String pathName = inlinePath.getName();\n+    return Integer.parseInt(pathName.substring(pathName.indexOf('=') + 1, pathName.indexOf('&')));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MTMxMQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393291311", "bodyText": "can you expand on this? supporting parquet summary metadata is a critical thing for the PR IMO", "author": "vinothchandar", "createdAt": "2020-03-16T20:28:05Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InlineFileSystem.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Progressable;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * Enables reading any inline file at a given offset and length. This {@link FileSystem} is used only in read path and does not support\n+ * any write apis.\n+ * <p>\n+ * - Reading an inlined file at a given offset, length, read it out as if it were an independent file of that length\n+ * - Inlined path is of the form \"inlinefs:///path/to/outer/file/<outer_file_scheme>/inline_file/?start_offset=<start_offset>&length=<length>\n+ * <p>\n+ * TODO: The reader/writer may try to use relative paths based on the inlinepath and it may not work. Need to handle\n+ * this gracefully eg. the parquet summary metadata reading. TODO: If this shows promise, also support directly writing", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MTUyNA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393291524", "bodyText": "In any case, please file JIRA for these gaps after we land this", "author": "vinothchandar", "createdAt": "2020-03-16T20:28:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MTMxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5OTQ4OA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395399488", "bodyText": "actually I wanted to sync up with you on this. Will sycn up offline.", "author": "nsivabalan", "createdAt": "2020-03-20T01:10:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MTMxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MjMyMw==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393292323", "bodyText": "I think the InlineFSUtils can assume this scheme and can become lot simpler to read, with fewer args in methods.", "author": "vinothchandar", "createdAt": "2020-03-16T20:30:21Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InlineFileSystem.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Progressable;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * Enables reading any inline file at a given offset and length. This {@link FileSystem} is used only in read path and does not support\n+ * any write apis.\n+ * <p>\n+ * - Reading an inlined file at a given offset, length, read it out as if it were an independent file of that length\n+ * - Inlined path is of the form \"inlinefs:///path/to/outer/file/<outer_file_scheme>/inline_file/?start_offset=<start_offset>&length=<length>\n+ * <p>\n+ * TODO: The reader/writer may try to use relative paths based on the inlinepath and it may not work. Need to handle\n+ * this gracefully eg. the parquet summary metadata reading. TODO: If this shows promise, also support directly writing\n+ * the inlined file to the underneath file without buffer\n+ */\n+public class InlineFileSystem extends FileSystem {\n+\n+  static final String SCHEME = \"inlinefs\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTM5OTY2MQ==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395399661", "bodyText": "yes, I have fixed the scheme issue. Can you check once I have addressed all comments.", "author": "nsivabalan", "createdAt": "2020-03-20T01:11:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI5MjMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjAwMg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393336002", "bodyText": "can we introduce a pojo for this? Something that can keep an outerPath, scheme, startOffset and length together.. we can have this utils method return that..", "author": "vinothchandar", "createdAt": "2020-03-16T22:06:46Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InlineFileSystem.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Progressable;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * Enables reading any inline file at a given offset and length. This {@link FileSystem} is used only in read path and does not support\n+ * any write apis.\n+ * <p>\n+ * - Reading an inlined file at a given offset, length, read it out as if it were an independent file of that length\n+ * - Inlined path is of the form \"inlinefs:///path/to/outer/file/<outer_file_scheme>/inline_file/?start_offset=<start_offset>&length=<length>\n+ * <p>\n+ * TODO: The reader/writer may try to use relative paths based on the inlinepath and it may not work. Need to handle\n+ * this gracefully eg. the parquet summary metadata reading. TODO: If this shows promise, also support directly writing\n+ * the inlined file to the underneath file without buffer\n+ */\n+public class InlineFileSystem extends FileSystem {\n+\n+  static final String SCHEME = \"inlinefs\";\n+  private Configuration conf = null;\n+\n+  @Override\n+  public void initialize(URI name, Configuration conf) throws IOException {\n+    super.initialize(name, conf);\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    return URI.create(getScheme());\n+  }\n+\n+  public String getScheme() {\n+    return SCHEME;\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(Path inlinePath, int bufferSize) throws IOException {\n+    Path outerPath = InLineFSUtils.getOuterfilePathFromInlinePath(inlinePath, getScheme());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQwMDk0Mg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395400942", "bodyText": "Within InlineFileSystem, we need to use Path in most places. So even if we introduce a POJO, I feel it may not be of much use. 1: all arguments to this class is Path. So, we have to convert to P\nOJO before we do anything. We can't store it as instance variable as well 2: Introducing a POJO might help in fetching start offset and length which is done only once in this class.  Not sure how much of value it adds to define a POJO. But open to making change if you feel so.", "author": "nsivabalan", "createdAt": "2020-03-20T01:17:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjIwMg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393336202", "bodyText": "and all of this code will read nicely.. as just getters on that pojo", "author": "vinothchandar", "createdAt": "2020-03-16T22:07:22Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/inline/fs/InlineFileSystem.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+import org.apache.hadoop.util.Progressable;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+\n+/**\n+ * Enables reading any inline file at a given offset and length. This {@link FileSystem} is used only in read path and does not support\n+ * any write apis.\n+ * <p>\n+ * - Reading an inlined file at a given offset, length, read it out as if it were an independent file of that length\n+ * - Inlined path is of the form \"inlinefs:///path/to/outer/file/<outer_file_scheme>/inline_file/?start_offset=<start_offset>&length=<length>\n+ * <p>\n+ * TODO: The reader/writer may try to use relative paths based on the inlinepath and it may not work. Need to handle\n+ * this gracefully eg. the parquet summary metadata reading. TODO: If this shows promise, also support directly writing\n+ * the inlined file to the underneath file without buffer\n+ */\n+public class InlineFileSystem extends FileSystem {\n+\n+  static final String SCHEME = \"inlinefs\";\n+  private Configuration conf = null;\n+\n+  @Override\n+  public void initialize(URI name, Configuration conf) throws IOException {\n+    super.initialize(name, conf);\n+    this.conf = conf;\n+  }\n+\n+  @Override\n+  public URI getUri() {\n+    return URI.create(getScheme());\n+  }\n+\n+  public String getScheme() {\n+    return SCHEME;\n+  }\n+\n+  @Override\n+  public FSDataInputStream open(Path inlinePath, int bufferSize) throws IOException {\n+    Path outerPath = InLineFSUtils.getOuterfilePathFromInlinePath(inlinePath, getScheme());\n+    FileSystem outerFs = outerPath.getFileSystem(conf);\n+    FSDataInputStream outerStream = outerFs.open(outerPath, bufferSize);\n+    return new InlineFsDataInputStream(InLineFSUtils.startOffset(inlinePath), outerStream, InLineFSUtils.length(inlinePath));\n+  }\n+\n+  @Override\n+  public boolean exists(Path f) {\n+    try {\n+      return getFileStatus(f) != null;\n+    } catch (Exception e) {\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public FileStatus getFileStatus(Path inlinePath) throws IOException {\n+    Path outerPath = InLineFSUtils.getOuterfilePathFromInlinePath(inlinePath, getScheme());\n+    FileSystem outerFs = outerPath.getFileSystem(conf);\n+    FileStatus status = outerFs.getFileStatus(outerPath);\n+    FileStatus toReturn = new FileStatus(InLineFSUtils.length(inlinePath), status.isDirectory(), status.getReplication(), status.getBlockSize(),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQwMTAxMw==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395401013", "bodyText": "have commented above on this.", "author": "nsivabalan", "createdAt": "2020-03-20T01:18:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjIwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjk2OA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393336968", "bodyText": "remove?", "author": "vinothchandar", "createdAt": "2020-03-16T22:09:23Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/inline/fs/TestHFileReadWriteFlow.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.KeyValue;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.io.hfile.HFile;\n+import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;\n+import org.apache.hadoop.hbase.io.hfile.HFileScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.FILE_SCHEME;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.RANDOM;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getPhantomFile;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getRandomOuterInMemPath;\n+\n+/**\n+ * Tests {@link InlineFileSystem} using HFile writer and reader.\n+ */\n+public class TestHFileReadWriteFlow {\n+\n+  private final Configuration inMemoryConf;\n+  private final Configuration inlineConf;\n+  private final int minBlockSize = 1024;\n+  private static final String LOCAL_FORMATTER = \"%010d\";\n+  private int maxRows = 100 + RANDOM.nextInt(1000);\n+  private Path generatedPath;\n+\n+  public TestHFileReadWriteFlow() {\n+    inMemoryConf = new Configuration();\n+    inMemoryConf.set(\"fs.\" + InMemoryFileSystem.SCHEME + \".impl\", InMemoryFileSystem.class.getName());\n+    inlineConf = new Configuration();\n+    inlineConf.set(\"fs.\" + InlineFileSystem.SCHEME + \".impl\", InlineFileSystem.class.getName());\n+  }\n+\n+  @After\n+  public void teardown() throws IOException {\n+    if (generatedPath != null) {\n+      File filePath = new File(generatedPath.toString().substring(generatedPath.toString().indexOf(':') + 1));\n+      if (filePath.exists()) {\n+        FileSystemTestUtils.deleteFile(filePath);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testSimpleInlineFileSystem() throws IOException {\n+    Path outerInMemFSPath = getRandomOuterInMemPath();\n+    Path outerPath = new Path(FILE_SCHEME + outerInMemFSPath.toString().substring(outerInMemFSPath.toString().indexOf(':')));\n+    generatedPath = outerPath;\n+    CacheConfig cacheConf = new CacheConfig(inMemoryConf);\n+    FSDataOutputStream fout = createFSOutput(outerInMemFSPath, inMemoryConf);\n+    HFileContext meta = new HFileContextBuilder()\n+        .withBlockSize(minBlockSize)\n+        .build();\n+    HFile.Writer writer = HFile.getWriterFactory(inMemoryConf, cacheConf)\n+        .withOutputStream(fout)\n+        .withFileContext(meta)\n+        .withComparator(new KeyValue.KVComparator())\n+        .create();\n+\n+    writeRecords(writer);\n+    fout.close();\n+\n+    byte[] inlineBytes = getBytesToInline(outerInMemFSPath);\n+    long startOffset = generateOuterFile(outerPath, inlineBytes);\n+\n+    long inlineLength = inlineBytes.length;\n+\n+    // Generate phantom inline file\n+    Path inlinePath = getPhantomFile(outerPath, startOffset, inlineLength);\n+\n+    InlineFileSystem inlineFileSystem = (InlineFileSystem) inlinePath.getFileSystem(inlineConf);\n+    FSDataInputStream fin = inlineFileSystem.open(inlinePath);\n+\n+    HFile.Reader reader = HFile.createReader(inlineFileSystem, inlinePath, cacheConf, inlineConf);\n+    // Load up the index.\n+    reader.loadFileInfo();\n+    // Get a scanner that caches and that does not use pread.\n+    HFileScanner scanner = reader.getScanner(true, false);\n+    // Align scanner at start of the file.\n+    scanner.seekTo();\n+    readAllRecords(scanner);\n+\n+    Set<Integer> rowIdsToSearch = getRandomValidRowIds(10);\n+    for (int rowId : rowIdsToSearch) {\n+      Assert.assertTrue(\"location lookup failed\",\n+          scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId))) == 0);\n+      // read the key and see if it matches\n+      ByteBuffer readKey = scanner.getKey();\n+      Assert.assertTrue(\"seeked key does not match\", Arrays.equals(getSomeKey(rowId),\n+          Bytes.toBytes(readKey)));\n+      scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId)));\n+      ByteBuffer val1 = scanner.getValue();\n+      scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId)));\n+      ByteBuffer val2 = scanner.getValue();\n+      Assert.assertTrue(Arrays.equals(Bytes.toBytes(val1), Bytes.toBytes(val2)));\n+    }\n+\n+    int[] invalidRowIds = {-4, maxRows, maxRows + 1, maxRows + 120, maxRows + 160, maxRows + 1000};\n+    for (int rowId : invalidRowIds) {\n+      Assert.assertFalse(\"location lookup should have failed\",\n+          scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId))) == 0);\n+    }\n+    reader.close();\n+    fin.close();\n+    outerPath.getFileSystem(inMemoryConf).delete(outerPath, true);\n+  }\n+\n+  private Set<Integer> getRandomValidRowIds(int count) {\n+    Set<Integer> rowIds = new HashSet<>();\n+    while (rowIds.size() < count) {\n+      int index = RANDOM.nextInt(maxRows);\n+      if (!rowIds.contains(index)) {\n+        rowIds.add(index);\n+      }\n+    }\n+    return rowIds;\n+  }\n+\n+  private byte[] getSomeKey(int rowId) {\n+    KeyValue kv = new KeyValue(String.format(LOCAL_FORMATTER, Integer.valueOf(rowId)).getBytes(),\n+        Bytes.toBytes(\"family\"), Bytes.toBytes(\"qual\"), HConstants.LATEST_TIMESTAMP, KeyValue.Type.Put);\n+    return kv.getKey();\n+  }\n+\n+  private FSDataOutputStream createFSOutput(Path name, Configuration conf) throws IOException {\n+    //if (fs.exists(name)) fs.delete(name, true);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNzAyMA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393337020", "bodyText": "single line return?", "author": "vinothchandar", "createdAt": "2020-03-16T22:09:29Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/inline/fs/TestHFileReadWriteFlow.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.KeyValue;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.io.hfile.HFile;\n+import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;\n+import org.apache.hadoop.hbase.io.hfile.HFileScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.FILE_SCHEME;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.RANDOM;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getPhantomFile;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getRandomOuterInMemPath;\n+\n+/**\n+ * Tests {@link InlineFileSystem} using HFile writer and reader.\n+ */\n+public class TestHFileReadWriteFlow {\n+\n+  private final Configuration inMemoryConf;\n+  private final Configuration inlineConf;\n+  private final int minBlockSize = 1024;\n+  private static final String LOCAL_FORMATTER = \"%010d\";\n+  private int maxRows = 100 + RANDOM.nextInt(1000);\n+  private Path generatedPath;\n+\n+  public TestHFileReadWriteFlow() {\n+    inMemoryConf = new Configuration();\n+    inMemoryConf.set(\"fs.\" + InMemoryFileSystem.SCHEME + \".impl\", InMemoryFileSystem.class.getName());\n+    inlineConf = new Configuration();\n+    inlineConf.set(\"fs.\" + InlineFileSystem.SCHEME + \".impl\", InlineFileSystem.class.getName());\n+  }\n+\n+  @After\n+  public void teardown() throws IOException {\n+    if (generatedPath != null) {\n+      File filePath = new File(generatedPath.toString().substring(generatedPath.toString().indexOf(':') + 1));\n+      if (filePath.exists()) {\n+        FileSystemTestUtils.deleteFile(filePath);\n+      }\n+    }\n+  }\n+\n+  @Test\n+  public void testSimpleInlineFileSystem() throws IOException {\n+    Path outerInMemFSPath = getRandomOuterInMemPath();\n+    Path outerPath = new Path(FILE_SCHEME + outerInMemFSPath.toString().substring(outerInMemFSPath.toString().indexOf(':')));\n+    generatedPath = outerPath;\n+    CacheConfig cacheConf = new CacheConfig(inMemoryConf);\n+    FSDataOutputStream fout = createFSOutput(outerInMemFSPath, inMemoryConf);\n+    HFileContext meta = new HFileContextBuilder()\n+        .withBlockSize(minBlockSize)\n+        .build();\n+    HFile.Writer writer = HFile.getWriterFactory(inMemoryConf, cacheConf)\n+        .withOutputStream(fout)\n+        .withFileContext(meta)\n+        .withComparator(new KeyValue.KVComparator())\n+        .create();\n+\n+    writeRecords(writer);\n+    fout.close();\n+\n+    byte[] inlineBytes = getBytesToInline(outerInMemFSPath);\n+    long startOffset = generateOuterFile(outerPath, inlineBytes);\n+\n+    long inlineLength = inlineBytes.length;\n+\n+    // Generate phantom inline file\n+    Path inlinePath = getPhantomFile(outerPath, startOffset, inlineLength);\n+\n+    InlineFileSystem inlineFileSystem = (InlineFileSystem) inlinePath.getFileSystem(inlineConf);\n+    FSDataInputStream fin = inlineFileSystem.open(inlinePath);\n+\n+    HFile.Reader reader = HFile.createReader(inlineFileSystem, inlinePath, cacheConf, inlineConf);\n+    // Load up the index.\n+    reader.loadFileInfo();\n+    // Get a scanner that caches and that does not use pread.\n+    HFileScanner scanner = reader.getScanner(true, false);\n+    // Align scanner at start of the file.\n+    scanner.seekTo();\n+    readAllRecords(scanner);\n+\n+    Set<Integer> rowIdsToSearch = getRandomValidRowIds(10);\n+    for (int rowId : rowIdsToSearch) {\n+      Assert.assertTrue(\"location lookup failed\",\n+          scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId))) == 0);\n+      // read the key and see if it matches\n+      ByteBuffer readKey = scanner.getKey();\n+      Assert.assertTrue(\"seeked key does not match\", Arrays.equals(getSomeKey(rowId),\n+          Bytes.toBytes(readKey)));\n+      scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId)));\n+      ByteBuffer val1 = scanner.getValue();\n+      scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId)));\n+      ByteBuffer val2 = scanner.getValue();\n+      Assert.assertTrue(Arrays.equals(Bytes.toBytes(val1), Bytes.toBytes(val2)));\n+    }\n+\n+    int[] invalidRowIds = {-4, maxRows, maxRows + 1, maxRows + 120, maxRows + 160, maxRows + 1000};\n+    for (int rowId : invalidRowIds) {\n+      Assert.assertFalse(\"location lookup should have failed\",\n+          scanner.seekTo(KeyValue.createKeyValueFromKey(getSomeKey(rowId))) == 0);\n+    }\n+    reader.close();\n+    fin.close();\n+    outerPath.getFileSystem(inMemoryConf).delete(outerPath, true);\n+  }\n+\n+  private Set<Integer> getRandomValidRowIds(int count) {\n+    Set<Integer> rowIds = new HashSet<>();\n+    while (rowIds.size() < count) {\n+      int index = RANDOM.nextInt(maxRows);\n+      if (!rowIds.contains(index)) {\n+        rowIds.add(index);\n+      }\n+    }\n+    return rowIds;\n+  }\n+\n+  private byte[] getSomeKey(int rowId) {\n+    KeyValue kv = new KeyValue(String.format(LOCAL_FORMATTER, Integer.valueOf(rowId)).getBytes(),\n+        Bytes.toBytes(\"family\"), Bytes.toBytes(\"qual\"), HConstants.LATEST_TIMESTAMP, KeyValue.Type.Put);\n+    return kv.getKey();\n+  }\n+\n+  private FSDataOutputStream createFSOutput(Path name, Configuration conf) throws IOException {\n+    //if (fs.exists(name)) fs.delete(name, true);\n+    FSDataOutputStream fout = name.getFileSystem(conf).create(name);\n+    return fout;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQwMTI0Mg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395401242", "bodyText": "Sorry had some debug statements before and hence. will fix it.", "author": "nsivabalan", "createdAt": "2020-03-20T01:19:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNzAyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNzk4Ng==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393337986", "bodyText": "this file has a fair amount of test code.. any way to simply/reuse?", "author": "vinothchandar", "createdAt": "2020-03-16T22:12:05Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/inline/fs/TestHFileReadWriteFlow.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.KeyValue;\n+import org.apache.hadoop.hbase.io.hfile.CacheConfig;\n+import org.apache.hadoop.hbase.io.hfile.HFile;\n+import org.apache.hadoop.hbase.io.hfile.HFileContext;\n+import org.apache.hadoop.hbase.io.hfile.HFileContextBuilder;\n+import org.apache.hadoop.hbase.io.hfile.HFileScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.UUID;\n+\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.FILE_SCHEME;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.RANDOM;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getPhantomFile;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getRandomOuterInMemPath;\n+\n+/**\n+ * Tests {@link InlineFileSystem} using HFile writer and reader.\n+ */\n+public class TestHFileReadWriteFlow {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzODE1Mg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393338152", "bodyText": "rename to TestHFileInlining", "author": "vinothchandar", "createdAt": "2020-03-16T22:12:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNzk4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQwMjIyMg==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r395402222", "bodyText": "Most of it is supporting cast for HFile read and write. So, not sure how much we re-use we could do here. Not too much value in modularizing it because the TestParquetInLining may have lot of supporting cast for Parquet.", "author": "nsivabalan", "createdAt": "2020-03-20T01:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNzk4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzODc5MA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393338790", "bodyText": "rename TestParquetInlining", "author": "vinothchandar", "createdAt": "2020-03-16T22:14:06Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/inline/fs/TestParquetReadWriteFlow.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.utilities.inline.fs;\n+\n+import org.apache.hudi.common.HoodieTestDataGenerator;\n+import org.apache.hudi.common.model.HoodieRecord;\n+\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.avro.AvroParquetReader;\n+import org.apache.parquet.avro.AvroParquetWriter;\n+import org.apache.parquet.hadoop.ParquetReader;\n+import org.apache.parquet.hadoop.ParquetWriter;\n+import org.apache.parquet.hadoop.metadata.CompressionCodecName;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.UUID;\n+\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.FILE_SCHEME;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getPhantomFile;\n+import static org.apache.hudi.utilities.inline.fs.FileSystemTestUtils.getRandomOuterInMemPath;\n+\n+/**\n+ * Tests {@link InlineFileSystem} with Parquet writer and reader.\n+ */\n+public class TestParquetReadWriteFlow {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzODkzNA==", "url": "https://github.com/apache/hudi/pull/1176#discussion_r393338934", "bodyText": "scope to be test?", "author": "vinothchandar", "createdAt": "2020-03-16T22:14:30Z", "path": "pom.xml", "diffHunk": "@@ -684,6 +684,11 @@\n         <artifactId>hbase-client</artifactId>\n         <version>${hbase.version}</version>\n       </dependency>\n+      <dependency>\n+        <groupId>org.apache.hbase</groupId>\n+        <artifactId>hbase-server</artifactId>\n+        <version>${hbase.version}</version>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f7983bb53a15a976b398c7240f7ef84b697435ff", "url": "https://github.com/apache/hudi/commit/f7983bb53a15a976b398c7240f7ef84b697435ff", "message": "Trial Paruet Logging", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "1455fc47c0ffae2e16444a98bba04a02ad00282c", "url": "https://github.com/apache/hudi/commit/1455fc47c0ffae2e16444a98bba04a02ad00282c", "message": "Adding log, reader and writer abstractions", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "0a877902184022fcd9731e3573f150ebcc26da61", "url": "https://github.com/apache/hudi/commit/0a877902184022fcd9731e3573f150ebcc26da61", "message": "Fixing InlineFS", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "e0acbfd571eafd8844d3d52a73a830f8c875d32c", "url": "https://github.com/apache/hudi/commit/e0acbfd571eafd8844d3d52a73a830f8c875d32c", "message": "Adding tests for ImlineFS and inMemFS", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "36c7dcd753bc7c8266597763f35cc83d63b9820d", "url": "https://github.com/apache/hudi/commit/36c7dcd753bc7c8266597763f35cc83d63b9820d", "message": "Adding tests for HFile Inlining", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "59b444f95b1a17609a2ecbc1b03a94e1ca533c77", "url": "https://github.com/apache/hudi/commit/59b444f95b1a17609a2ecbc1b03a94e1ca533c77", "message": "Adding InlineFileSystem", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "e485c95be7e15b28d8275c547c462dad8f15ae16", "url": "https://github.com/apache/hudi/commit/e485c95be7e15b28d8275c547c462dad8f15ae16", "message": "Fixing build failures", "committedDate": "2020-03-20T11:21:32Z", "type": "commit"}, {"oid": "6a650e822e81053f1b0fd5365d9c441e6a26490f", "url": "https://github.com/apache/hudi/commit/6a650e822e81053f1b0fd5365d9c441e6a26490f", "message": "Addressing comments", "committedDate": "2020-03-20T11:21:33Z", "type": "commit"}, {"oid": "6a650e822e81053f1b0fd5365d9c441e6a26490f", "url": "https://github.com/apache/hudi/commit/6a650e822e81053f1b0fd5365d9c441e6a26490f", "message": "Addressing comments", "committedDate": "2020-03-20T11:21:33Z", "type": "forcePushed"}, {"oid": "43580371ed453867998b8eeb53c9a3be6525cf24", "url": "https://github.com/apache/hudi/commit/43580371ed453867998b8eeb53c9a3be6525cf24", "message": "Addressing one last comment", "committedDate": "2020-03-25T16:29:51Z", "type": "commit"}]}