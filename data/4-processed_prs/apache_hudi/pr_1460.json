{"pr_number": 1460, "pr_title": "[HUDI-679] Make io package Spark free", "pr_createdAt": "2020-03-28T06:36:29Z", "pr_url": "https://github.com/apache/hudi/pull/1460", "timeline": [{"oid": "5f65bfb02846ce61bd733b70bccb981f98348777", "url": "https://github.com/apache/hudi/commit/5f65bfb02846ce61bd733b70bccb981f98348777", "message": "[HUDI-679] Make io package Spark free", "committedDate": "2020-03-28T06:32:12Z", "type": "commit"}, {"oid": "24e68e3a8238453a603455eb9c69b438a82bc25c", "url": "https://github.com/apache/hudi/commit/24e68e3a8238453a603455eb9c69b438a82bc25c", "message": "address travis failure", "committedDate": "2020-03-28T08:31:41Z", "type": "commit"}, {"oid": "bb7268f4d20e9bffa60220487fed03a945916b99", "url": "https://github.com/apache/hudi/commit/bb7268f4d20e9bffa60220487fed03a945916b99", "message": "add travis", "committedDate": "2020-03-28T09:25:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY0OTE5Ng==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399649196", "bodyText": "Considering this interface supports some information about TaskContext, can we rename to SparkTaskContextDetailSupplier?", "author": "yanghua", "createdAt": "2020-03-28T11:01:54Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkSupplier.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkSupplier<T> extends Supplier<T>, Serializable {", "originalCommit": "bb7268f4d20e9bffa60220487fed03a945916b99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MTQ5NQ==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399651495", "bodyText": "sounds reasonable.", "author": "leesf", "createdAt": "2020-03-28T11:28:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY0OTE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY0OTI1OA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399649258", "bodyText": "Can we add empty line to split this definition?  Additionally, add some comments?", "author": "yanghua", "createdAt": "2020-03-28T11:02:47Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkSupplier.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkSupplier<T> extends Supplier<T>, Serializable {\n+  SparkSupplier<Integer> PARTITION_SUPPLIER = () -> TaskContext.getPartitionId();", "originalCommit": "bb7268f4d20e9bffa60220487fed03a945916b99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY1MTUwNw==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399651507", "bodyText": "Can we add empty line to split this definition? Additionally, add some comments?\n\nsure", "author": "leesf", "createdAt": "2020-03-28T11:28:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY0OTI1OA=="}], "type": "inlineReview"}, {"oid": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "url": "https://github.com/apache/hudi/commit/9ef6c852631c8344a77def77a9e8f8d81a67c283", "message": "address comments", "committedDate": "2020-03-28T11:31:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDA5NA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660094", "bodyText": "PARTITION_ID_SUPPLIER ?", "author": "yanghua", "createdAt": "2020-03-28T13:02:40Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkTaskContextDetailSupplier.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkTaskContextDetailSupplier<T> extends Supplier<T>, Serializable {\n+\n+  /**\n+   * Supplier to get partition id.\n+   */\n+  SparkTaskContextDetailSupplier<Integer> PARTITION_SUPPLIER = () -> TaskContext.getPartitionId();", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDEzMg==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660132", "bodyText": "STAGE_ID_SUPPLIER ?", "author": "yanghua", "createdAt": "2020-03-28T13:03:01Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkTaskContextDetailSupplier.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkTaskContextDetailSupplier<T> extends Supplier<T>, Serializable {\n+\n+  /**\n+   * Supplier to get partition id.\n+   */\n+  SparkTaskContextDetailSupplier<Integer> PARTITION_SUPPLIER = () -> TaskContext.getPartitionId();\n+\n+  /**\n+   * Supplier to get stage id.\n+   */\n+  SparkTaskContextDetailSupplier<Integer> STAGE_SUPPLIER = () -> TaskContext.get().stageId();", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDE2Nw==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660167", "bodyText": "ATTEMPT_ID_SUPPLIER ?", "author": "yanghua", "createdAt": "2020-03-28T13:03:29Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkTaskContextDetailSupplier.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkTaskContextDetailSupplier<T> extends Supplier<T>, Serializable {\n+\n+  /**\n+   * Supplier to get partition id.\n+   */\n+  SparkTaskContextDetailSupplier<Integer> PARTITION_SUPPLIER = () -> TaskContext.getPartitionId();\n+\n+  /**\n+   * Supplier to get stage id.\n+   */\n+  SparkTaskContextDetailSupplier<Integer> STAGE_SUPPLIER = () -> TaskContext.get().stageId();\n+\n+  /**\n+   * Supplier to get task attempt id.\n+   */\n+  SparkTaskContextDetailSupplier<Long> ATTEMPT_SUPPLIER = () -> TaskContext.get().taskAttemptId();", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDMzOA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660338", "bodyText": "hoodieTable.getIdSupplier() is not clear here. I suggest we can rename these getter to e.g. getPartitionIdSupplier, getStageId and getAttemptId?", "author": "yanghua", "createdAt": "2020-03-28T13:05:15Z", "path": "hudi-client/src/main/java/org/apache/hudi/execution/BulkInsertMapFunction.java", "diffHunk": "@@ -51,6 +51,7 @@ public BulkInsertMapFunction(String instantTime, HoodieWriteConfig config, Hoodi\n   @Override\n   public Iterator<List<WriteStatus>> call(Integer partition, Iterator<HoodieRecord<T>> sortedRecordItr) {\n     return new CopyOnWriteLazyInsertIterable<>(sortedRecordItr, config, instantTime, hoodieTable,\n-        fileIDPrefixes.get(partition));\n+        fileIDPrefixes.get(partition), hoodieTable.getIdSupplier(), hoodieTable.getStageSupplier(),", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDM3Mg==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660372", "bodyText": "ditto", "author": "yanghua", "createdAt": "2020-03-28T13:05:33Z", "path": "hudi-client/src/main/java/org/apache/hudi/execution/CopyOnWriteLazyInsertIterable.java", "diffHunk": "@@ -50,15 +51,23 @@\n   protected final HoodieTable<T> hoodieTable;\n   protected final String idPrefix;\n   protected int numFilesWritten;\n+  protected Supplier<Integer> idSupplier;", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDQ2Ng==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660466", "bodyText": "Actually, I am not sure if we can package these three args into a DTO structure. Just a thought, you can ignore.", "author": "yanghua", "createdAt": "2020-03-28T13:06:49Z", "path": "hudi-client/src/main/java/org/apache/hudi/execution/CopyOnWriteLazyInsertIterable.java", "diffHunk": "@@ -50,15 +51,23 @@\n   protected final HoodieTable<T> hoodieTable;\n   protected final String idPrefix;\n   protected int numFilesWritten;\n+  protected Supplier<Integer> idSupplier;\n+  protected Supplier<Integer> stageSupplier;\n+  protected Supplier<Long> attemptSupplier;\n \n   public CopyOnWriteLazyInsertIterable(Iterator<HoodieRecord<T>> sortedRecordItr, HoodieWriteConfig config,\n-                                       String instantTime, HoodieTable<T> hoodieTable, String idPrefix) {\n+                                       String instantTime, HoodieTable<T> hoodieTable, String idPrefix,\n+                                       Supplier<Integer> idSupplier, Supplier<Integer> stageSupplier,\n+                                       Supplier<Long> attemptSupplier) {", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY3Mzg3MA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399673870", "bodyText": "Actually, I am not sure if we can package these three args into a DTO structure. Just a thought, you can ignore.\n\nYes, I think it is better.", "author": "leesf", "createdAt": "2020-03-28T15:22:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDQ2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY2MDU5NQ==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399660595", "bodyText": "ditto, IMO, id here is not clear. partition id is better.", "author": "yanghua", "createdAt": "2020-03-28T13:08:31Z", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "diffHunk": "@@ -55,26 +55,32 @@\n   protected final String partitionPath;\n   protected final String fileId;\n   protected final String writeToken;\n+  protected final Supplier<Integer> idSupplier;", "originalCommit": "9ef6c852631c8344a77def77a9e8f8d81a67c283", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "934c41dea3b8931288f1b339f95140f5e8f5b048", "url": "https://github.com/apache/hudi/commit/934c41dea3b8931288f1b339f95140f5e8f5b048", "message": "address comments", "committedDate": "2020-03-28T15:21:28Z", "type": "commit"}, {"oid": "e9a3c06b0907886d62812d9ed5255bfa47babcd6", "url": "https://github.com/apache/hudi/commit/e9a3c06b0907886d62812d9ed5255bfa47babcd6", "message": "address comments", "committedDate": "2020-03-28T15:22:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY5OTUwNg==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399699506", "bodyText": "Should be interface be something generic like WriteTaskContextSupplier  which is extended by SparkTaskContextSupplier ?", "author": "vinothchandar", "createdAt": "2020-03-28T19:24:56Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkTaskContextDetailSupplier.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkTaskContextDetailSupplier<T> extends Supplier<T>, Serializable {", "originalCommit": "e9a3c06b0907886d62812d9ed5255bfa47babcd6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY5OTc5NA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399699794", "bodyText": "I am not sure this abstraction is at the right level.. Should this have to be Supplier.. I think we can just have three methods that return Supplier<Integer> and Supplier<Long> and pass just one argument through the code path i.e the SparkTaskContextSuppler instance..", "author": "vinothchandar", "createdAt": "2020-03-28T19:27:59Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/SparkTaskContextDetailSupplier.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import org.apache.spark.TaskContext;\n+\n+import java.io.Serializable;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Spark Supplier.\n+ */\n+public interface SparkTaskContextDetailSupplier<T> extends Supplier<T>, Serializable {", "originalCommit": "e9a3c06b0907886d62812d9ed5255bfa47babcd6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTczNzk5MA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399737990", "bodyText": "Just online seeing the latest changes comes from @leesf . Yes, it seems this is a better abstraction.", "author": "yanghua", "createdAt": "2020-03-29T03:12:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY5OTc5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTY5OTk0MQ==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399699941", "bodyText": "then this can go away.. I feel this is additional abstraction, that we may not need..", "author": "vinothchandar", "createdAt": "2020-03-28T19:29:06Z", "path": "hudi-client/src/main/java/org/apache/hudi/client/Suppliers.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * A bundle of Suppliers.\n+ */\n+public class Suppliers implements Serializable {", "originalCommit": "e9a3c06b0907886d62812d9ed5255bfa47babcd6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcwMDA1OA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399700058", "bodyText": "side point: we should fix method arg formatting  consistently between intellij and checkstyle. Keep seeing these sort of whitespace changes in PRs.", "author": "vinothchandar", "createdAt": "2020-03-28T19:30:23Z", "path": "hudi-client/src/main/java/org/apache/hudi/execution/MergeOnReadLazyInsertIterable.java", "diffHunk": "@@ -35,8 +36,9 @@\n public class MergeOnReadLazyInsertIterable<T extends HoodieRecordPayload> extends CopyOnWriteLazyInsertIterable<T> {\n \n   public MergeOnReadLazyInsertIterable(Iterator<HoodieRecord<T>> sortedRecordItr, HoodieWriteConfig config,\n-      String instantTime, HoodieTable<T> hoodieTable, String idPfx) {\n-    super(sortedRecordItr, config, instantTime, hoodieTable, idPfx);\n+                                       String instantTime, HoodieTable<T> hoodieTable, String idPfx,", "originalCommit": "e9a3c06b0907886d62812d9ed5255bfa47babcd6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcwMDE4NA==", "url": "https://github.com/apache/hudi/pull/1460#discussion_r399700184", "bodyText": "rename to just makeWriteToken()?", "author": "vinothchandar", "createdAt": "2020-03-28T19:31:33Z", "path": "hudi-client/src/main/java/org/apache/hudi/io/HoodieWriteHandle.java", "diffHunk": "@@ -55,26 +55,27 @@\n   protected final String partitionPath;\n   protected final String fileId;\n   protected final String writeToken;\n+  protected final Suppliers suppliers;\n \n   public HoodieWriteHandle(HoodieWriteConfig config, String instantTime, String partitionPath,\n-                           String fileId, HoodieTable<T> hoodieTable) {\n+                           String fileId, HoodieTable<T> hoodieTable, Suppliers suppliers) {\n     super(config, instantTime, hoodieTable);\n     this.partitionPath = partitionPath;\n     this.fileId = fileId;\n-    this.writeToken = makeSparkWriteToken();\n     this.originalSchema = new Schema.Parser().parse(config.getSchema());\n     this.writerSchema = createHoodieWriteSchema(originalSchema);\n     this.timer = new HoodieTimer().startTimer();\n     this.writeStatus = (WriteStatus) ReflectionUtils.loadClass(config.getWriteStatusClassName(),\n         !hoodieTable.getIndex().isImplicitWithStorage(), config.getWriteStatusFailureFraction());\n+    this.suppliers = suppliers;\n+    this.writeToken = makeSparkWriteToken();", "originalCommit": "e9a3c06b0907886d62812d9ed5255bfa47babcd6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3d215b83c25e3df548d44d8a8c4d20a16efbf863", "url": "https://github.com/apache/hudi/commit/3d215b83c25e3df548d44d8a8c4d20a16efbf863", "message": "address comments", "committedDate": "2020-03-29T05:09:06Z", "type": "commit"}, {"oid": "07f073a7b0c5e326524961105fed84a2b92e2c18", "url": "https://github.com/apache/hudi/commit/07f073a7b0c5e326524961105fed84a2b92e2c18", "message": "format", "committedDate": "2020-03-29T05:12:15Z", "type": "commit"}]}