{"pr_number": 1822, "pr_title": "[HUDI-766]: added section for HoodieMultiTableDeltaStreamer", "pr_createdAt": "2020-07-11T12:27:07Z", "pr_url": "https://github.com/apache/hudi/pull/1822", "timeline": [{"oid": "0cf47ac796f5f75d451780875d9fe22e4b1ef7b6", "url": "https://github.com/apache/hudi/commit/0cf47ac796f5f75d451780875d9fe22e4b1ef7b6", "message": "[HUDI-766]: added section for HoodieMultiTableDeltaStreamer", "committedDate": "2020-07-11T12:26:00Z", "type": "commit"}, {"oid": "4ff8abe5bdcd6e0ac807603388d3cf74c7d5c09a", "url": "https://github.com/apache/hudi/commit/4ff8abe5bdcd6e0ac807603388d3cf74c7d5c09a", "message": "[HUDI-766]: small changes", "committedDate": "2020-07-11T15:48:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA3NjY5MA==", "url": "https://github.com/apache/hudi/pull/1822#discussion_r454076690", "bodyText": "ingest multiple topics at a single go ... ?", "author": "vinothchandar", "createdAt": "2020-07-14T03:27:49Z", "path": "docs/_docs/2_2_writing_data.md", "diffHunk": "@@ -174,6 +174,42 @@ and then ingest it as follows.\n \n In some cases, you may want to migrate your existing table into Hudi beforehand. Please refer to [migration guide](/docs/migration_guide.html). \n \n+## MultiTableDeltaStreamer\n+\n+`HoodieMultiTableDeltaStreamer`, a wrapper on top of `HoodieDeltaStreamer`, enables one to ingest multiple tables at a go into hudi datasets. Currently it only supports sequential processing of tables to be ingested and COPY_ON_WRITE storage type. The command line options for `HoodieMultiTableDeltaStreamer` are pretty much similar to `HoodieDeltaStreamer` with the only exception that you are required to provide table wise configs in separate files in a dedicated config folder. The following command line options are introduced", "originalCommit": "4ff8abe5bdcd6e0ac807603388d3cf74c7d5c09a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA3NzIxMQ==", "url": "https://github.com/apache/hudi/pull/1822#discussion_r454077211", "bodyText": "do we specify a --target-table ?", "author": "vinothchandar", "createdAt": "2020-07-14T03:29:52Z", "path": "docs/_docs/2_2_writing_data.md", "diffHunk": "@@ -174,6 +174,42 @@ and then ingest it as follows.\n \n In some cases, you may want to migrate your existing table into Hudi beforehand. Please refer to [migration guide](/docs/migration_guide.html). \n \n+## MultiTableDeltaStreamer\n+\n+`HoodieMultiTableDeltaStreamer`, a wrapper on top of `HoodieDeltaStreamer`, enables one to ingest multiple tables at a go into hudi datasets. Currently it only supports sequential processing of tables to be ingested and COPY_ON_WRITE storage type. The command line options for `HoodieMultiTableDeltaStreamer` are pretty much similar to `HoodieDeltaStreamer` with the only exception that you are required to provide table wise configs in separate files in a dedicated config folder. The following command line options are introduced\n+\n+```java\n+  * --config-folder\n+    the path to the folder which contains all the table wise config files\n+    --base-path-prefix\n+    this is added to enable users to create all the hudi datasets for related tables under one path in FS. The datasets are then created under the path - <base_path_prefix>/<database>/<table_to_be_ingested>. However you can override the paths for every table by setting the property hoodie.deltastreamer.ingestion.targetBasePath\n+```\n+\n+The following properties are needed to be set properly to ingest data using `HoodieMultiTableDeltaStreamer`. \n+\n+```java\n+hoodie.deltastreamer.ingestion.tablesToBeIngested\n+  comma separated names of tables to be ingested in the format <database>.<table>, for example db1.table1,db1.table2\n+hoodie.deltastreamer.ingestion.targetBasePath\n+  if you wish to ingest a particular table in a separate path, you can mention that path here\n+hoodie.deltastreamer.ingestion.<database>.<table>.configFile\n+  path to the config file in dedicated config folder which contains table overridden properties for the particular table to be ingested.\n+```\n+\n+Sample config files for table wise overridden properties can be found under `hudi-utilities/src/test/resources/delta-streamer-config`. The command to run `HoodieMultiTableDeltaStreamer` is also similar to how you run `HoodieDeltaStreamer`.\n+\n+```java\n+[hoodie]$ spark-submit --class org.apache.hudi.utilities.deltastreamer.HoodieMultiTableDeltaStreamer `ls packaging/hudi-utilities-bundle/target/hudi-utilities-bundle-*.jar` \\\n+  --props file://${PWD}/hudi-utilities/src/test/resources/delta-streamer-config/kafka-source.properties \\\n+  --config-folder file://tmp/hudi-ingestion-config \\\n+  --schemaprovider-class org.apache.hudi.utilities.schema.SchemaRegistryProvider \\\n+  --source-class org.apache.hudi.utilities.sources.AvroKafkaSource \\\n+  --source-ordering-field impresssiontime \\\n+  --base-path-prefix file:\\/\\/\\/tmp/hudi-deltastreamer-op \\ \n+  --target-table uber.impressions \\", "originalCommit": "4ff8abe5bdcd6e0ac807603388d3cf74c7d5c09a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTM4NjY3OQ==", "url": "https://github.com/apache/hudi/pull/1822#discussion_r459386679", "bodyText": "yes we have a option to specify --target-table in HoodieMultiTableDeltaStreamer, though it gets overwritten later through our code.", "author": "pratyakshsharma", "createdAt": "2020-07-23T11:39:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA3NzIxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTcyNDkyNw==", "url": "https://github.com/apache/hudi/pull/1822#discussion_r469724927", "bodyText": "@pratyakshsharma Is this a default target-table if its not overwritten by the individual table properties files ?", "author": "bhasudha", "createdAt": "2020-08-13T06:29:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA3NzIxMQ=="}], "type": "inlineReview"}, {"oid": "c878124ac6f7610b0e374691ac7800bfee21548e", "url": "https://github.com/apache/hudi/commit/c878124ac6f7610b0e374691ac7800bfee21548e", "message": "[HUDI-766]: addressed code review comments", "committedDate": "2020-07-23T11:39:50Z", "type": "commit"}]}