{"pr_number": 2188, "pr_title": "[HUDI-1347]fix Hbase index partition changes cause data duplication p\u2026", "pr_createdAt": "2020-10-18T08:01:43Z", "pr_url": "https://github.com/apache/hudi/pull/2188", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNjMzNA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r513536334", "bodyText": "Surprised checkstyle is not failing for no space after the \",\"", "author": "n3nash", "createdAt": "2020-10-28T15:25:36Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/hbase/SparkHoodieHBaseIndex.java", "diffHunk": "@@ -171,6 +173,10 @@ private Get generateStatement(String key) throws IOException {\n         .addColumn(SYSTEM_COLUMN_FAMILY, FILE_NAME_COLUMN).addColumn(SYSTEM_COLUMN_FAMILY, PARTITION_PATH_COLUMN);\n   }\n \n+  private Get generateStatement(String key, long startTime, long endTime) throws IOException {\n+    return generateStatement(key).setTimeRange(startTime,endTime);", "originalCommit": "8c39fbc41b88a704dce77a3b475c1c49e37fd32a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNzk4Ng==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r513537986", "bodyText": "@hj2016 We don't fire deletes to Hbase to enable rollback, instead, we just check for whether that update is present or not, if that entry is not valid, the record key will be re-ingested and the entry will be overwritten. Can you talk about a use-case where you require to delete entries ?", "author": "n3nash", "createdAt": "2020-10-28T15:27:42Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/hbase/SparkHoodieHBaseIndex.java", "diffHunk": "@@ -480,6 +486,61 @@ private Integer getNumRegionServersAliveForTable() {\n   @Override\n   public boolean rollbackCommit(String instantTime) {\n     // Rollback in HbaseIndex is managed via method {@link #checkIfValidCommit()}\n+    synchronized (SparkHoodieHBaseIndex.class) {", "originalCommit": "8c39fbc41b88a704dce77a3b475c1c49e37fd32a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDIyOTAzNA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r514229034", "bodyText": "Of course, the checkIfValidCommit method will detect whether the index commitTime is a valid index, and it has no effect on writing data after rollback. Here, it is possible to write hbase index data incorrectly without deleting the last commit failure. But what I consider is to ensure that the data and the content of the index are consistent. Is it possible to add a configuration here for users to choose? Or is it better not to delete?", "author": "hj2016", "createdAt": "2020-10-29T12:44:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNzk4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDI3NjcyOA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r514276728", "bodyText": "@hj2016 The problem with firing deletes is that you end up putting extra load on the Hbase cluster for every rollback which is undesirable. The index and data should eventually be in sync always, let me explain how :\n\nSay the batch of records with 4 records (uuid1, uuid2, uuid3, uuid4) was inserted into the index but the batch failed.\nRollback will delete the data but let the index be\nThe next batch of records with 6 records (uuid1, uuid2, uuid3, uuid4, uuid5, uuid6) will now be retried. The HbaseIndex for the first 4 records will be overwritten and there won't be any dangling or remnant indexes.\nThe one way this can happen is if you tried a batch of records, they failed and then you skipped those batch of records, which isn't a very common scenario.\nIf there is another use-case for which you want to delete the records from Hbase, we can consider having a config, let me know.", "author": "n3nash", "createdAt": "2020-10-29T13:55:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNzk4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDc1OTMxNQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r514759315", "bodyText": "ok, then I add a parameter to control, the default is not to delete. how do you feel?", "author": "hj2016", "createdAt": "2020-10-30T03:08:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNzk4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAxOTExNw==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r520019117", "bodyText": "Okay, that makes sense to me, please go ahead with the change.", "author": "n3nash", "createdAt": "2020-11-09T18:15:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNzk4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4NjUxMA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r521386510", "bodyText": "@n3nash  I have changed it. Can you please confirm my pr  when you free?", "author": "hj2016", "createdAt": "2020-11-11T14:15:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzUzNzk4Ng=="}], "type": "inlineReview"}, {"oid": "8cb722529e0ef56bc252edf37e3700c2e0381f6a", "url": "https://github.com/apache/hudi/commit/8cb722529e0ef56bc252edf37e3700c2e0381f6a", "message": "[HUDI-1347]fix Hbase index partition changes cause data duplication problems", "committedDate": "2020-11-02T13:39:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzc4NQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549017785", "bodyText": "not sure why this is required. this is within reduceByKey and so rec1.getKey and rec2.getKey should be same right?", "author": "nsivabalan", "createdAt": "2020-12-26T18:23:55Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/commit/SparkWriteHelper.java", "diffHunk": "@@ -62,7 +62,7 @@ public static SparkWriteHelper newInstance() {\n       // we cannot allow the user to change the key or partitionPath, since that will affect\n       // everything\n       // so pick it from one of the records.\n-      return new HoodieRecord<T>(rec1.getKey(), reducedData);\n+      return new HoodieRecord<T>(rec1.getData().equals(reducedData) ? rec1.getKey() : rec2.getKey(), reducedData);", "originalCommit": "8cb722529e0ef56bc252edf37e3700c2e0381f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI0MDE0Mw==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549240143", "bodyText": "For example, there are two data with the same primary key for upsert\nid partitionPath updateTime\n1 2018 2019-01-01\n1 2019 2019-02-01\nAfter the data is deduplicated,\nExpected return: (1,2019)->(1,2019,2019-02-01)\nActual return: (1,2018)->(1,2019,2019-02-01)\nIn this way, the hoodile key and the data content will be inconsistent, resulting in writing to the wrong partition.", "author": "hj2016", "createdAt": "2020-12-28T07:13:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzc4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU0MzUyNQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549543525", "bodyText": "When I was resolving conflicts, it seemed that someone encountered a similar problem. #2248", "author": "hj2016", "createdAt": "2020-12-29T02:14:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzc4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzg3NQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549017875", "bodyText": "can you remove comment in line 488.", "author": "nsivabalan", "createdAt": "2020-12-26T18:25:13Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/hbase/SparkHoodieHBaseIndex.java", "diffHunk": "@@ -480,6 +486,68 @@ private Integer getNumRegionServersAliveForTable() {\n   @Override\n   public boolean rollbackCommit(String instantTime) {\n     // Rollback in HbaseIndex is managed via method {@link #checkIfValidCommit()}\n+    synchronized (SparkHoodieHBaseIndex.class) {", "originalCommit": "8cb722529e0ef56bc252edf37e3700c2e0381f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI0MDM0NQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549240345", "bodyText": "ok", "author": "hj2016", "createdAt": "2020-12-28T07:14:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDM0MTc4Ng==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r550341786", "bodyText": "@hj2016 Can you please make the following changes :\n`public boolean rollbackCommit(String instantTime) {\nif (config.getHBaseIndexRollbackSync()) {\n// \n}\nreturn true;\n`\nThis keeps old behavior unchanged and safe and allows you to control deletes via the config.", "author": "n3nash", "createdAt": "2020-12-30T22:14:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTY3NDAyOA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r551674028", "bodyText": "There will be problems with the hbase index. The scenario that needs to be rolled back is that the hbase partition change is turned on and an error is reported after the hbase index is written for some reasons (some reasons may be due to jvm memory overflow, hbase suddenly crashes), for example, At the beginning, the data was id:1 partition:2019, and then another commit failed and the index was written to hbase. At this time, the index partition was changed to 2020. So the next time the data is written, it will only be written to In the 2020 partition, resulting in data duplication. After judging based on the rollbackSync parameter, the following logic will not be executed. If you set hbase.index.rollback.sync = false, hoodie.hbase.index.update.partition.path = true, there will still be problems. I think it would be more reasonable to write like this:\nif (!config.getHbaseIndexUpdatePartitionPath()){\nreturn true;\n}\nsynchronized (SparkHoodieHBaseIndex.class) {\n....\n}\nreturn true;\nBecause only when the partition changes, problems may occur.", "author": "hj2016", "createdAt": "2021-01-05T02:00:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjAwNDY4Nw==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r572004687", "bodyText": "@n3nash : looks like author is waiting for your response.", "author": "nsivabalan", "createdAt": "2021-02-08T12:22:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxNzg3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxODA1NA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549018054", "bodyText": "why commented out code", "author": "nsivabalan", "createdAt": "2020-12-26T18:26:56Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/hbase/SparkHoodieHBaseIndex.java", "diffHunk": "@@ -480,6 +486,68 @@ private Integer getNumRegionServersAliveForTable() {\n   @Override\n   public boolean rollbackCommit(String instantTime) {\n     // Rollback in HbaseIndex is managed via method {@link #checkIfValidCommit()}\n+    synchronized (SparkHoodieHBaseIndex.class) {\n+      if (hbaseConnection == null || hbaseConnection.isClosed()) {\n+        hbaseConnection = getHBaseConnection();\n+      }\n+    }\n+    try (HTable hTable = (HTable) hbaseConnection.getTable(TableName.valueOf(tableName));\n+         BufferedMutator mutator = hbaseConnection.getBufferedMutator(TableName.valueOf(tableName))) {\n+      int multiGetBatchSize = config.getHbaseIndexGetBatchSize();\n+      boolean rollbackSync = config.getHBaseIndexRollbackSync();\n+\n+      Long rollbackTime = HoodieActiveTimeline.COMMIT_FORMATTER.parse(instantTime).getTime();\n+      Long currentTime = new Date().getTime();\n+      Scan scan = new Scan();\n+      scan.addFamily(SYSTEM_COLUMN_FAMILY);\n+      scan.setTimeRange(rollbackTime, currentTime);\n+      ResultScanner scanner = hTable.getScanner(scan);\n+      Iterator<Result> scannerIterator = scanner.iterator();\n+\n+      List<Get> statements = new ArrayList<>();\n+      List<Result> currentVersionResults = new ArrayList<Result>();\n+      List<Mutation> mutations = new ArrayList<>();\n+      while (scannerIterator.hasNext()) {\n+        Result result = scannerIterator.next();\n+        currentVersionResults.add(result);\n+        statements.add(generateStatement(Bytes.toString(result.getRow()), 0L, rollbackTime - 1));\n+\n+        if (scannerIterator.hasNext() &&  statements.size() < multiGetBatchSize) {\n+          continue;\n+        }\n+        Result[] lastVersionResults = hTable.get(statements);\n+        for (int i = 0; i < lastVersionResults.length; i++) {\n+          Result lastVersionResult = lastVersionResults[i];\n+          if (null == lastVersionResult.getRow() && rollbackSync) {\n+            Result currentVersionResult = currentVersionResults.get(i);\n+            Delete delete = new Delete(currentVersionResult.getRow());\n+            // delete.addColumn(SYSTEM_COLUMN_FAMILY, COMMIT_TS_COLUMN, currentTime);", "originalCommit": "8cb722529e0ef56bc252edf37e3700c2e0381f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI1NTUxMQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549255511", "bodyText": "Because I thought it was necessary to specify the column to delete, I later found that it is not necessary to specify the column. I think I can delete the comment code.", "author": "hj2016", "createdAt": "2020-12-28T08:15:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxODA1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxODEyOA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549018128", "bodyText": "so can you confirm that this test fails if not for the fix?", "author": "nsivabalan", "createdAt": "2020-12-26T18:28:12Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "diffHunk": "@@ -263,6 +265,66 @@ public void testTagLocationAndDuplicateUpdate() throws Exception {\n         && record.getCurrentLocation().getInstantTime().equals(newCommitTime))).distinct().count());\n   }\n \n+  @Test\n+  public void testTagLocationAndPartitionPathUpdateWithRollback() throws Exception {", "originalCommit": "8cb722529e0ef56bc252edf37e3700c2e0381f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNjU5NA==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549536594", "bodyText": "yes", "author": "hj2016", "createdAt": "2020-12-29T01:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTAxODEyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTIxNDk4NQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549214985", "bodyText": "Please rename this to `testTagLocationAndPartitionPathUpdateWithExplicitRollback\"", "author": "n3nash", "createdAt": "2020-12-28T05:04:25Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "diffHunk": "@@ -263,6 +265,66 @@ public void testTagLocationAndDuplicateUpdate() throws Exception {\n         && record.getCurrentLocation().getInstantTime().equals(newCommitTime))).distinct().count());\n   }\n \n+  @Test\n+  public void testTagLocationAndPartitionPathUpdateWithRollback() throws Exception {", "originalCommit": "8cb722529e0ef56bc252edf37e3700c2e0381f6a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTUzNjU4Mw==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r549536583", "bodyText": "ok", "author": "hj2016", "createdAt": "2020-12-29T01:28:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTIxNDk4NQ=="}], "type": "inlineReview"}, {"oid": "1573c9d8b55a5d9b7f0c3ffe2575349902ec3abe", "url": "https://github.com/apache/hudi/commit/1573c9d8b55a5d9b7f0c3ffe2575349902ec3abe", "message": "[HUDI-1347]fix Hbase index partition changes cause data duplication problems", "committedDate": "2020-12-29T01:19:43Z", "type": "forcePushed"}, {"oid": "c904625fb213b5ec4f6b7f6a218af15dff535d37", "url": "https://github.com/apache/hudi/commit/c904625fb213b5ec4f6b7f6a218af15dff535d37", "message": "[HUDI-1347]fix Hbase index partition changes cause data duplication problems", "committedDate": "2021-02-20T06:23:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDQzMjYwNQ==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r580432605", "bodyText": "getHBaseIndexRollbackSync", "author": "nsivabalan", "createdAt": "2021-02-22T17:18:44Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/hbase/SparkHoodieHBaseIndex.java", "diffHunk": "@@ -537,7 +545,71 @@ private Integer getNumRegionServersAliveForTable() {\n \n   @Override\n   public boolean rollbackCommit(String instantTime) {\n-    // Rollback in HbaseIndex is managed via method {@link #checkIfValidCommit()}\n+    int multiGetBatchSize = config.getHbaseIndexGetBatchSize();\n+    boolean rollbackSync = config.getHBaseIndexRollbackSync();\n+\n+    if (!config.getHbaseIndexUpdatePartitionPath()) {", "originalCommit": "c904625fb213b5ec4f6b7f6a218af15dff535d37", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDQ0MTI3Nw==", "url": "https://github.com/apache/hudi/pull/2188#discussion_r580441277", "bodyText": "Can you point me to the place where we set the new config to true.", "author": "nsivabalan", "createdAt": "2021-02-22T17:29:59Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/index/hbase/TestHBaseIndex.java", "diffHunk": "@@ -268,6 +268,66 @@ public void testTagLocationAndDuplicateUpdate() throws Exception {\n         && record.getCurrentLocation().getInstantTime().equals(newCommitTime))).distinct().count());\n   }\n \n+  @Test\n+  public void testTagLocationAndPartitionPathUpdateWithExplicitRollback() throws Exception {\n+    final int numRecords = 10;\n+    final String oldPartitionPath = \"1970/01/01\";\n+    final String emptyHoodieRecordPayloadClasssName = EmptyHoodieRecordPayload.class.getName();\n+    HoodieWriteConfig config = getConfig(true);\n+    SparkHoodieHBaseIndex index = new SparkHoodieHBaseIndex(getConfig(true));", "originalCommit": "c904625fb213b5ec4f6b7f6a218af15dff535d37", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d7ea9cd5817e6ef3693c3e36fef8fa5578e40b5b", "url": "https://github.com/apache/hudi/commit/d7ea9cd5817e6ef3693c3e36fef8fa5578e40b5b", "message": "[HUDI-1347]fix Hbase index partition changes cause data duplication problems", "committedDate": "2021-02-23T13:31:51Z", "type": "commit"}, {"oid": "be0114342aa55a2ce1dc5220685156ccdf952292", "url": "https://github.com/apache/hudi/commit/be0114342aa55a2ce1dc5220685156ccdf952292", "message": "Addressing comments", "committedDate": "2021-02-23T13:31:52Z", "type": "commit"}, {"oid": "e9bef5af2e1484517cb87da0b57c9a8977ab50fb", "url": "https://github.com/apache/hudi/commit/e9bef5af2e1484517cb87da0b57c9a8977ab50fb", "message": "Fetching and rebasing with master", "committedDate": "2021-02-23T13:49:21Z", "type": "commit"}, {"oid": "e9bef5af2e1484517cb87da0b57c9a8977ab50fb", "url": "https://github.com/apache/hudi/commit/e9bef5af2e1484517cb87da0b57c9a8977ab50fb", "message": "Fetching and rebasing with master", "committedDate": "2021-02-23T13:49:21Z", "type": "forcePushed"}, {"oid": "0c3a394c84a70886169940756f77cb6415075438", "url": "https://github.com/apache/hudi/commit/0c3a394c84a70886169940756f77cb6415075438", "message": "Fixing config naming", "committedDate": "2021-02-23T13:54:43Z", "type": "commit"}]}