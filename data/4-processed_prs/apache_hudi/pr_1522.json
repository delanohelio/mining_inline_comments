{"pr_number": 1522, "pr_title": "[HUDI-702]Add test for HoodieLogFileCommand", "pr_createdAt": "2020-04-16T07:47:24Z", "pr_url": "https://github.com/apache/hudi/pull/1522", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDUwMjUyNA==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r414502524", "bodyText": "We should protect the resource leak here.", "author": "yanghua", "createdAt": "2020-04-24T11:27:54Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestHoodieLogFileCommand.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.avro.HoodieAvroUtils;\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodieTableHeaderFields;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;\n+import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.SchemaTestUtil;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieMemoryConfig;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.common.util.SchemaTestUtil.getSimpleSchema;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link HoodieLogFileCommand}.\n+ */\n+public class TestHoodieLogFileCommand extends AbstractShellIntegrationTest {\n+\n+  private String partitionPath;\n+  private HoodieAvroDataBlock dataBlock;\n+  private String tablePath;\n+\n+  private static final String INSTANT_TIME = \"100\";\n+\n+  @Before\n+  public void init() throws IOException, InterruptedException, URISyntaxException {\n+    HoodieCLI.conf = jsc.hadoopConfiguration();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+    new TableCommand().createTable(\n+        tablePath, tableName, HoodieTableType.MERGE_ON_READ.name(),\n+        \"\", TimelineLayoutVersion.VERSION_1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    new File(partitionPath).mkdirs();\n+    HoodieLogFormat.Writer writer =\n+        HoodieLogFormat.newWriterBuilder().onParentPath(new Path(partitionPath))\n+            .withFileExtension(HoodieLogFile.DELTA_EXTENSION)\n+            .withFileId(\"test-log-fileid1\").overBaseCommit(\"100\").withFs(fs).build();\n+\n+    // write data to file\n+    List<IndexedRecord> records = SchemaTestUtil.generateTestRecords(0, 100);\n+    Map<HoodieLogBlock.HeaderMetadataType, String> header = new HashMap<>();\n+    header.put(HoodieLogBlock.HeaderMetadataType.INSTANT_TIME, INSTANT_TIME);\n+    header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, getSimpleSchema().toString());\n+    dataBlock = new HoodieAvroDataBlock(records, header);\n+    writer = writer.appendBlock(dataBlock);\n+    writer.close();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTMyNzIyNQ==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r415327225", "bodyText": "We should protect the resource leak here.\n\ntry (resource) does not work very well here, use try finally instead.", "author": "hddong", "createdAt": "2020-04-26T14:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDUwMjUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDUwMzUxMA==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r414503510", "bodyText": "ditto", "author": "yanghua", "createdAt": "2020-04-24T11:29:44Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestHoodieLogFileCommand.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.avro.HoodieAvroUtils;\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodieTableHeaderFields;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;\n+import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.SchemaTestUtil;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieMemoryConfig;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.common.util.SchemaTestUtil.getSimpleSchema;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link HoodieLogFileCommand}.\n+ */\n+public class TestHoodieLogFileCommand extends AbstractShellIntegrationTest {\n+\n+  private String partitionPath;\n+  private HoodieAvroDataBlock dataBlock;\n+  private String tablePath;\n+\n+  private static final String INSTANT_TIME = \"100\";\n+\n+  @Before\n+  public void init() throws IOException, InterruptedException, URISyntaxException {\n+    HoodieCLI.conf = jsc.hadoopConfiguration();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+    new TableCommand().createTable(\n+        tablePath, tableName, HoodieTableType.MERGE_ON_READ.name(),\n+        \"\", TimelineLayoutVersion.VERSION_1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    new File(partitionPath).mkdirs();\n+    HoodieLogFormat.Writer writer =\n+        HoodieLogFormat.newWriterBuilder().onParentPath(new Path(partitionPath))\n+            .withFileExtension(HoodieLogFile.DELTA_EXTENSION)\n+            .withFileId(\"test-log-fileid1\").overBaseCommit(\"100\").withFs(fs).build();\n+\n+    // write data to file\n+    List<IndexedRecord> records = SchemaTestUtil.generateTestRecords(0, 100);\n+    Map<HoodieLogBlock.HeaderMetadataType, String> header = new HashMap<>();\n+    header.put(HoodieLogBlock.HeaderMetadataType.INSTANT_TIME, INSTANT_TIME);\n+    header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, getSimpleSchema().toString());\n+    dataBlock = new HoodieAvroDataBlock(records, header);\n+    writer = writer.appendBlock(dataBlock);\n+    writer.close();\n+  }\n+\n+  /**\n+   * Test case for 'show logfile metadata'.\n+   */\n+  @Test\n+  public void testShowLogFileCommits() throws JsonProcessingException {\n+    CommandResult cr = getShell().executeCommand(\"show logfile metadata --logFilePathPattern \" + partitionPath + \"/*\");\n+    assertTrue(cr.isSuccess());\n+\n+    TableHeader header = new TableHeader().addTableHeaderField(HoodieTableHeaderFields.HEADER_INSTANT_TIME)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_RECORD_COUNT)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_BLOCK_TYPE)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_HEADER_METADATA)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_FOOTER_METADATA);\n+\n+    // construct expect result, there is only 1 line.\n+    List<Comparable[]> rows = new ArrayList<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    String headerStr = objectMapper.writeValueAsString(dataBlock.getLogBlockHeader());\n+    String footerStr = objectMapper.writeValueAsString(dataBlock.getLogBlockFooter());\n+    Comparable[] output = new Comparable[]{INSTANT_TIME, 100, dataBlock.getBlockType(), headerStr, footerStr};\n+    rows.add(output);\n+\n+    String expected = HoodiePrintHelper.print(header, new HashMap<>(), \"\", false, -1, false, rows);\n+\n+    assertEquals(expected, cr.getResult().toString());\n+  }\n+\n+  /**\n+   * Test case for 'show logfile records'.\n+   */\n+  @Test\n+  public void testShowLogFileRecords() throws IOException, URISyntaxException {\n+    CommandResult cr = getShell().executeCommand(\"show logfile records --logFilePathPattern \" + partitionPath + \"/*\");\n+    assertTrue(cr.isSuccess());\n+\n+    // construct expect result, get 10 records.\n+    List<IndexedRecord> records = SchemaTestUtil.generateTestRecords(0, 10);\n+    String[][] rows = records.stream().map(r -> new String[]{r.toString()}).toArray(String[][]::new);\n+    String expected = HoodiePrintHelper.print(new String[] {HoodieTableHeaderFields.HEADER_RECORDS}, rows);\n+\n+    assertEquals(expected, cr.getResult().toString());\n+  }\n+\n+  /**\n+   * Test case for 'show logfile records' with merge.\n+   */\n+  @Test\n+  public void testShowLogFileRecordsWithMerge() throws IOException, URISyntaxException, InterruptedException {\n+    // create commit instant\n+    HoodieTestCommitMetadataGenerator.createCommitFile(tablePath, INSTANT_TIME, HoodieCLI.conf);\n+\n+    // write to path '2015/03/16'.\n+    Schema schema = HoodieAvroUtils.addMetadataFields(getSimpleSchema());\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+    new File(partitionPath).mkdirs();\n+\n+    // set little threshold to split file.\n+    HoodieLogFormat.Writer writer =\n+        HoodieLogFormat.newWriterBuilder().onParentPath(new Path(partitionPath))\n+            .withFileExtension(HoodieLogFile.DELTA_EXTENSION)\n+            .withFileId(\"test-log-fileid1\").overBaseCommit(INSTANT_TIME).withFs(fs).withSizeThreshold(500).build();\n+\n+    //write1\n+    List<IndexedRecord> records1 = SchemaTestUtil.generateHoodieTestRecords(0, 100);\n+    Map<HoodieLogBlock.HeaderMetadataType, String> header = new HashMap<>();\n+    header.put(HoodieLogBlock.HeaderMetadataType.INSTANT_TIME, INSTANT_TIME);\n+    header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, schema.toString());\n+    HoodieAvroDataBlock dataBlock = new HoodieAvroDataBlock(records1, header);\n+    writer = writer.appendBlock(dataBlock);\n+\n+    //write2\n+    List<IndexedRecord> records2 = SchemaTestUtil.generateHoodieTestRecords(0, 100);\n+    header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, schema.toString());\n+    dataBlock = new HoodieAvroDataBlock(records2, header);\n+    writer = writer.appendBlock(dataBlock);\n+    writer.close();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMjk5Ng==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r416402996", "bodyText": "Do we need to sort this data set?", "author": "yanghua", "createdAt": "2020-04-28T07:48:44Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/HoodieLogFileCommand.java", "diffHunk": "@@ -173,7 +176,11 @@ public String showLogFileRecords(\n     HoodieTableMetaClient client = HoodieCLI.getTableMetaClient();\n     FileSystem fs = client.getFs();\n     List<String> logFilePaths = Arrays.stream(fs.globStatus(new Path(logFilePathPattern)))\n-        .map(status -> status.getPath().toString()).collect(Collectors.toList());\n+        .map(status -> status.getPath().toString()).sorted(Comparator.reverseOrder())", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ4MjgwMg==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r416482802", "bodyText": "Do we need to sort this data set?\n\nIMO, it should be. Default return value is unordered, we may touch the blank log file when readSchemaFromLogFile.", "author": "hddong", "createdAt": "2020-04-28T09:52:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMjk5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjcyMTc4Ng==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r416721786", "bodyText": "Got it! Github hid the unchanged part. I thought you only accessed the .size() method.", "author": "yanghua", "createdAt": "2020-04-28T15:44:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMjk5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ2NzEwMg==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r416467102", "bodyText": "For avoiding NPE, consider add :\nif (writer != null) {\n\n?", "author": "yanghua", "createdAt": "2020-04-28T09:27:47Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestHoodieLogFileCommand.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.avro.HoodieAvroUtils;\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodieTableHeaderFields;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;\n+import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.SchemaTestUtil;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieMemoryConfig;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.common.util.SchemaTestUtil.getSimpleSchema;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link HoodieLogFileCommand}.\n+ */\n+public class TestHoodieLogFileCommand extends AbstractShellIntegrationTest {\n+\n+  private String partitionPath;\n+  private HoodieAvroDataBlock dataBlock;\n+  private String tablePath;\n+\n+  private static final String INSTANT_TIME = \"100\";\n+\n+  @Before\n+  public void init() throws IOException, InterruptedException, URISyntaxException {\n+    HoodieCLI.conf = jsc.hadoopConfiguration();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+    new TableCommand().createTable(\n+        tablePath, tableName, HoodieTableType.MERGE_ON_READ.name(),\n+        \"\", TimelineLayoutVersion.VERSION_1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    new File(partitionPath).mkdirs();\n+\n+    HoodieLogFormat.Writer writer = null;\n+    try {\n+      writer =\n+          HoodieLogFormat.newWriterBuilder().onParentPath(new Path(partitionPath))\n+              .withFileExtension(HoodieLogFile.DELTA_EXTENSION)\n+              .withFileId(\"test-log-fileid1\").overBaseCommit(\"100\").withFs(fs).build();\n+\n+      // write data to file\n+      List<IndexedRecord> records = SchemaTestUtil.generateTestRecords(0, 100);\n+      Map<HoodieLogBlock.HeaderMetadataType, String> header = new HashMap<>();\n+      header.put(HoodieLogBlock.HeaderMetadataType.INSTANT_TIME, INSTANT_TIME);\n+      header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, getSimpleSchema().toString());\n+      dataBlock = new HoodieAvroDataBlock(records, header);\n+      writer = writer.appendBlock(dataBlock);\n+    } finally {\n+      writer.close();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjcyMzAzMg==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r416723032", "bodyText": "Replace it with Files.createDirectories is a better choice?", "author": "yanghua", "createdAt": "2020-04-28T15:46:37Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestHoodieLogFileCommand.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.avro.HoodieAvroUtils;\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodieTableHeaderFields;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;\n+import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.SchemaTestUtil;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieMemoryConfig;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.common.util.SchemaTestUtil.getSimpleSchema;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link HoodieLogFileCommand}.\n+ */\n+public class TestHoodieLogFileCommand extends AbstractShellIntegrationTest {\n+\n+  private String partitionPath;\n+  private HoodieAvroDataBlock dataBlock;\n+  private String tablePath;\n+\n+  private static final String INSTANT_TIME = \"100\";\n+\n+  @Before\n+  public void init() throws IOException, InterruptedException, URISyntaxException {\n+    HoodieCLI.conf = jsc.hadoopConfiguration();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+    new TableCommand().createTable(\n+        tablePath, tableName, HoodieTableType.MERGE_ON_READ.name(),\n+        \"\", TimelineLayoutVersion.VERSION_1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    new File(partitionPath).mkdirs();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjcyMzMwMw==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r416723303", "bodyText": "ditto", "author": "yanghua", "createdAt": "2020-04-28T15:46:55Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestHoodieLogFileCommand.java", "diffHunk": "@@ -0,0 +1,220 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.avro.HoodieAvroUtils;\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodieTableHeaderFields;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;\n+import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.SchemaTestUtil;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieMemoryConfig;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.common.util.SchemaTestUtil.getSimpleSchema;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link HoodieLogFileCommand}.\n+ */\n+public class TestHoodieLogFileCommand extends AbstractShellIntegrationTest {\n+\n+  private String partitionPath;\n+  private HoodieAvroDataBlock dataBlock;\n+  private String tablePath;\n+\n+  private static final String INSTANT_TIME = \"100\";\n+\n+  @Before\n+  public void init() throws IOException, InterruptedException, URISyntaxException {\n+    HoodieCLI.conf = jsc.hadoopConfiguration();\n+\n+    // Create table and connect\n+    String tableName = \"test_table\";\n+    tablePath = basePath + File.separator + tableName;\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_FIRST_PARTITION_PATH;\n+    new TableCommand().createTable(\n+        tablePath, tableName, HoodieTableType.MERGE_ON_READ.name(),\n+        \"\", TimelineLayoutVersion.VERSION_1, \"org.apache.hudi.common.model.HoodieAvroPayload\");\n+\n+    new File(partitionPath).mkdirs();\n+\n+    HoodieLogFormat.Writer writer = null;\n+    try {\n+      writer =\n+          HoodieLogFormat.newWriterBuilder().onParentPath(new Path(partitionPath))\n+              .withFileExtension(HoodieLogFile.DELTA_EXTENSION)\n+              .withFileId(\"test-log-fileid1\").overBaseCommit(\"100\").withFs(fs).build();\n+\n+      // write data to file\n+      List<IndexedRecord> records = SchemaTestUtil.generateTestRecords(0, 100);\n+      Map<HoodieLogBlock.HeaderMetadataType, String> header = new HashMap<>();\n+      header.put(HoodieLogBlock.HeaderMetadataType.INSTANT_TIME, INSTANT_TIME);\n+      header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, getSimpleSchema().toString());\n+      dataBlock = new HoodieAvroDataBlock(records, header);\n+      writer = writer.appendBlock(dataBlock);\n+    } finally {\n+      if (writer != null) {\n+        writer.close();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Test case for 'show logfile metadata'.\n+   */\n+  @Test\n+  public void testShowLogFileCommits() throws JsonProcessingException {\n+    CommandResult cr = getShell().executeCommand(\"show logfile metadata --logFilePathPattern \" + partitionPath + \"/*\");\n+    assertTrue(cr.isSuccess());\n+\n+    TableHeader header = new TableHeader().addTableHeaderField(HoodieTableHeaderFields.HEADER_INSTANT_TIME)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_RECORD_COUNT)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_BLOCK_TYPE)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_HEADER_METADATA)\n+        .addTableHeaderField(HoodieTableHeaderFields.HEADER_FOOTER_METADATA);\n+\n+    // construct expect result, there is only 1 line.\n+    List<Comparable[]> rows = new ArrayList<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    String headerStr = objectMapper.writeValueAsString(dataBlock.getLogBlockHeader());\n+    String footerStr = objectMapper.writeValueAsString(dataBlock.getLogBlockFooter());\n+    Comparable[] output = new Comparable[]{INSTANT_TIME, 100, dataBlock.getBlockType(), headerStr, footerStr};\n+    rows.add(output);\n+\n+    String expected = HoodiePrintHelper.print(header, new HashMap<>(), \"\", false, -1, false, rows);\n+\n+    assertEquals(expected, cr.getResult().toString());\n+  }\n+\n+  /**\n+   * Test case for 'show logfile records'.\n+   */\n+  @Test\n+  public void testShowLogFileRecords() throws IOException, URISyntaxException {\n+    CommandResult cr = getShell().executeCommand(\"show logfile records --logFilePathPattern \" + partitionPath + \"/*\");\n+    assertTrue(cr.isSuccess());\n+\n+    // construct expect result, get 10 records.\n+    List<IndexedRecord> records = SchemaTestUtil.generateTestRecords(0, 10);\n+    String[][] rows = records.stream().map(r -> new String[]{r.toString()}).toArray(String[][]::new);\n+    String expected = HoodiePrintHelper.print(new String[] {HoodieTableHeaderFields.HEADER_RECORDS}, rows);\n+\n+    assertEquals(expected, cr.getResult().toString());\n+  }\n+\n+  /**\n+   * Test case for 'show logfile records' with merge.\n+   */\n+  @Test\n+  public void testShowLogFileRecordsWithMerge() throws IOException, InterruptedException, URISyntaxException {\n+    // create commit instant\n+    HoodieTestCommitMetadataGenerator.createCommitFile(tablePath, INSTANT_TIME, HoodieCLI.conf);\n+\n+    // write to path '2015/03/16'.\n+    Schema schema = HoodieAvroUtils.addMetadataFields(getSimpleSchema());\n+    partitionPath = tablePath + File.separator + HoodieTestCommitMetadataGenerator.DEFAULT_SECOND_PARTITION_PATH;\n+    new File(partitionPath).mkdirs();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA3ODk4OQ==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r417078989", "bodyText": "Travis is red and reported NPE here? @hddong", "author": "yanghua", "createdAt": "2020-04-29T05:45:01Z", "path": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestHoodieLogFileCommand.java", "diffHunk": "@@ -0,0 +1,222 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.avro.HoodieAvroUtils;\n+import org.apache.hudi.cli.AbstractShellIntegrationTest;\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodieTableHeaderFields;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.common.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.common.model.HoodieLogFile;\n+import org.apache.hudi.common.model.HoodieRecord;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.model.HoodieTableType;\n+import org.apache.hudi.common.table.log.HoodieLogFormat;\n+import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;\n+import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;\n+import org.apache.hudi.common.table.log.block.HoodieLogBlock;\n+import org.apache.hudi.common.table.timeline.versioning.TimelineLayoutVersion;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.SchemaTestUtil;\n+import org.apache.hudi.config.HoodieCompactionConfig;\n+import org.apache.hudi.config.HoodieMemoryConfig;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.springframework.shell.core.CommandResult;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.hudi.common.util.SchemaTestUtil.getSimpleSchema;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Test Cases for {@link HoodieLogFileCommand}.\n+ */\n+public class TestHoodieLogFileCommand extends AbstractShellIntegrationTest {\n+\n+  private String partitionPath;\n+  private HoodieAvroDataBlock dataBlock;\n+  private String tablePath;\n+\n+  private static final String INSTANT_TIME = \"100\";\n+\n+  @Before\n+  public void init() throws IOException, InterruptedException, URISyntaxException {\n+    HoodieCLI.conf = jsc.hadoopConfiguration();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA4MTU1MA==", "url": "https://github.com/apache/hudi/pull/1522#discussion_r417081550", "bodyText": "Travis is red and reported NPE here? @hddong\n\nyes, due to upgrade Junit5, had rebase to master.", "author": "hddong", "createdAt": "2020-04-29T05:54:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzA3ODk4OQ=="}], "type": "inlineReview"}, {"oid": "46808cf6c0f671fac4c46d54d687ab22a6815e21", "url": "https://github.com/apache/hudi/commit/46808cf6c0f671fac4c46d54d687ab22a6815e21", "message": "Add test for HoodieLogFileCommand", "committedDate": "2020-04-29T05:51:11Z", "type": "commit"}, {"oid": "46808cf6c0f671fac4c46d54d687ab22a6815e21", "url": "https://github.com/apache/hudi/commit/46808cf6c0f671fac4c46d54d687ab22a6815e21", "message": "Add test for HoodieLogFileCommand", "committedDate": "2020-04-29T05:51:11Z", "type": "forcePushed"}]}