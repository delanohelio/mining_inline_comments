{"pr_number": 1719, "pr_title": "[HUDI-1006]deltastreamer use kafkaSource with offset reset strategy:latest can't consume data", "pr_createdAt": "2020-06-09T06:02:26Z", "pr_url": "https://github.com/apache/hudi/pull/1719", "timeline": [{"oid": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8", "url": "https://github.com/apache/hudi/commit/565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8", "message": "[HUDI-1006]deltastreamer use kafkaSource with offset reset strategy: latest can't consume data", "committedDate": "2020-06-09T04:11:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0MTc0NA==", "url": "https://github.com/apache/hudi/pull/1719#discussion_r437841744", "bodyText": "hmmm interesting... so right now if we use LATEST as reset key, then we will fall into a dead loop unless we are lucky enough to have message fall in between two consumer.endOffsets(topicPartitions) call.", "author": "garyli1019", "createdAt": "2020-06-10T03:38:36Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");", "originalCommit": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0NjQyOQ==", "url": "https://github.com/apache/hudi/pull/1719#discussion_r437846429", "bodyText": "could lastCheckpointStr be \"\" here?\nAlso, can we add a test for this case?\nhttps://github.com/apache/hudi/blob/master/hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java#L107", "author": "garyli1019", "createdAt": "2020-06-10T03:59:32Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/sources/AvroKafkaSource.java", "diffHunk": "@@ -57,10 +57,10 @@ public AvroKafkaSource(TypedProperties props, JavaSparkContext sparkContext, Spa\n   protected InputBatch<JavaRDD<GenericRecord>> fetchNewData(Option<String> lastCheckpointStr, long sourceLimit) {\n     OffsetRange[] offsetRanges = offsetGen.getNextOffsetRanges(lastCheckpointStr, sourceLimit);\n     long totalNewMsgs = CheckpointUtils.totalNewMessages(offsetRanges);\n+    LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n     if (totalNewMsgs <= 0) {\n-      return new InputBatch<>(Option.empty(), lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : \"\");\n-    } else {\n-      LOG.info(\"About to read \" + totalNewMsgs + \" from Kafka for topic :\" + offsetGen.getTopicName());\n+      return new InputBatch<>(Option.empty(),\n+              lastCheckpointStr.isPresent() ? lastCheckpointStr.get() : CheckpointUtils.offsetsToStr(offsetRanges));", "originalCommit": "565f9b4e82fa2e69baab1b4e92dbc0f9c1c97ad8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODA1ODI2Mg==", "url": "https://github.com/apache/hudi/pull/1719#discussion_r438058262", "bodyText": "For a hudi table already has a \"\" checkpoint, lastCheckpointStr can be \"\" here, so i change return value to return new endOffsets checkpoint string in all case.\nAnd i add a simple test case for kafka latest offset reset strategy in hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java.\nThanks for review! \ud83e\udd1d", "author": "Litianye", "createdAt": "2020-06-10T11:41:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg0NjQyOQ=="}], "type": "inlineReview"}, {"oid": "5f344b8e74eda103b1869a9d3141df286974622f", "url": "https://github.com/apache/hudi/commit/5f344b8e74eda103b1869a9d3141df286974622f", "message": "for case when last checkpoint str is an empty string & add test case for offset reset", "committedDate": "2020-06-10T11:28:57Z", "type": "commit"}, {"oid": "6853b8d8c1e02435bdfc0049b22cbe9539090bb9", "url": "https://github.com/apache/hudi/commit/6853b8d8c1e02435bdfc0049b22cbe9539090bb9", "message": "change TestKafkaSource local variable name for CI build", "committedDate": "2020-06-10T13:55:52Z", "type": "commit"}, {"oid": "690d9937d6041895795099959727b08bd5d52afe", "url": "https://github.com/apache/hudi/commit/690d9937d6041895795099959727b08bd5d52afe", "message": "handle empty string checkpoint in DeltaSync", "committedDate": "2020-06-11T07:49:43Z", "type": "commit"}, {"oid": "4e26a478118c510ecb0fd148eb67281f20f8119d", "url": "https://github.com/apache/hudi/commit/4e26a478118c510ecb0fd148eb67281f20f8119d", "message": "handle empty string checkpoint in DeltaSync", "committedDate": "2020-06-11T08:03:27Z", "type": "commit"}, {"oid": "46287522f5d0c43dea2fcab321145330c04f6f78", "url": "https://github.com/apache/hudi/commit/46287522f5d0c43dea2fcab321145330c04f6f78", "message": "delete whitespace for CI build", "committedDate": "2020-06-11T08:49:39Z", "type": "commit"}, {"oid": "e04512121ce33c8ad3e578657b1dd4533a64735e", "url": "https://github.com/apache/hudi/commit/e04512121ce33c8ad3e578657b1dd4533a64735e", "message": "remove checkpoint length check in kafkaOffsetGen", "committedDate": "2020-06-12T07:24:22Z", "type": "commit"}, {"oid": "2cc2375601dc92139cbfd58492600df44bb90157", "url": "https://github.com/apache/hudi/commit/2cc2375601dc92139cbfd58492600df44bb90157", "message": "revert changes in DeltaSync", "committedDate": "2020-06-12T07:34:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcyMzI3MQ==", "url": "https://github.com/apache/hudi/pull/1719#discussion_r439723271", "bodyText": "we would merge the method with createPropsForJsonSource to reuse code.", "author": "leesf", "createdAt": "2020-06-13T09:03:52Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/sources/TestKafkaSource.java", "diffHunk": "@@ -93,6 +93,18 @@ private TypedProperties createPropsForJsonSource(Long maxEventsToReadFromKafkaSo\n     return props;\n   }\n \n+  private TypedProperties createLatestPropsForJsonSource(Long maxEventsToReadFromKafkaSource) {\n+    TypedProperties props = new TypedProperties();\n+    props.setProperty(\"hoodie.deltastreamer.source.kafka.topic\", TEST_TOPIC_NAME);\n+    props.setProperty(\"bootstrap.servers\", testUtils.brokerAddress());\n+    props.setProperty(\"auto.offset.reset\", \"latest\");\n+    props.setProperty(\"hoodie.deltastreamer.kafka.source.maxEvents\",\n+            maxEventsToReadFromKafkaSource != null ? String.valueOf(maxEventsToReadFromKafkaSource) :\n+                    String.valueOf(Config.maxEventsFromKafkaSource));\n+    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());\n+    return props;\n+  }\n+", "originalCommit": "2cc2375601dc92139cbfd58492600df44bb90157", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "da0e2cb38562e00e95dfb3a82e63c08d9e8a34e6", "url": "https://github.com/apache/hudi/commit/da0e2cb38562e00e95dfb3a82e63c08d9e8a34e6", "message": "merge method reuse code", "committedDate": "2020-06-14T08:03:44Z", "type": "commit"}]}