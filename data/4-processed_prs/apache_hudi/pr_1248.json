{"pr_number": 1248, "pr_title": "[Minor] Adding delete docs to QuickStart", "pr_createdAt": "2020-01-18T18:40:27Z", "pr_url": "https://github.com/apache/hudi/pull/1248", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjI3Mw==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368242273", "bodyText": "could we avoid doing the insert again?  can we not reuse from the insert/update done above?", "author": "vinothchandar", "createdAt": "2020-01-18T18:48:09Z", "path": "docs/quickstart.md", "diffHunk": "@@ -109,6 +109,57 @@ Notice that the save mode is now `Append`. In general, always use append mode un\n [Querying](#query) the data again will now show updated trips. Each write operation generates a new [commit](http://hudi.incubator.apache.org/concepts.html) \n denoted by the timestamp. Look for changes in `_hoodie_commit_time`, `rider`, `driver` fields for the same `_hoodie_record_key`s in previous commit. \n \n+## Delete data {#deletes}\n+Delete records for the HoodieKeys passed in. Lets first generate a new batch of insert and delete the same. Query to verify\n+that all records are deleted.\n+\n+```\n+val inserts = convertToStringList(dataGen.generateInserts(10))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjMxNw==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368242317", "bodyText": "ideally,. we just have this part and remove everything above this line, to keep the quickstart small", "author": "vinothchandar", "createdAt": "2020-01-18T18:49:05Z", "path": "docs/quickstart.md", "diffHunk": "@@ -109,6 +109,57 @@ Notice that the save mode is now `Append`. In general, always use append mode un\n [Querying](#query) the data again will now show updated trips. Each write operation generates a new [commit](http://hudi.incubator.apache.org/concepts.html) \n denoted by the timestamp. Look for changes in `_hoodie_commit_time`, `rider`, `driver` fields for the same `_hoodie_record_key`s in previous commit. \n \n+## Delete data {#deletes}\n+Delete records for the HoodieKeys passed in. Lets first generate a new batch of insert and delete the same. Query to verify\n+that all records are deleted.\n+\n+```\n+val inserts = convertToStringList(dataGen.generateInserts(10))\n+val df = spark.read.json(spark.sparkContext.parallelize(inserts, 2))\n+df.write.format(\"org.apache.hudi\").\n+    options(getQuickstartWriteConfigs).\n+    option(PRECOMBINE_FIELD_OPT_KEY, \"ts\").\n+    option(RECORDKEY_FIELD_OPT_KEY, \"uuid\").\n+    option(PARTITIONPATH_FIELD_OPT_KEY, \"partitionpath\").\n+    option(TABLE_NAME, tableName).\n+    mode(Overwrite).\n+    save(basePath);\n+\n+// Fetch the rider value for the batch of records inserted just now\n+val roDeleteViewDF = spark.\n+    read.\n+    format(\"org.apache.hudi\").\n+    load(basePath + \"/*/*/*/*\")\n+roDeleteViewDF.registerTempTable(\"hudi_ro_table\")\n+spark.sql(\"select distinct rider from  hudi_ro_table where\").show()\n+\n+// replace the rider value in below query to a value from above. \"rider-213\" is first batch and \"rider-284\" is second batch.\n+val ds = spark.sql(\"select uuid, partitionPath from hudi_ro_table where rider = 'rider-284'\")\n+\n+// issue deletes", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0ODM2NA==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368248364", "bodyText": "I am deleting an entire batch of inserts and hence thought will do a new batch of inserts and delete the entire batch.", "author": "nsivabalan", "createdAt": "2020-01-18T21:02:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0ODU2MQ==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368248561", "bodyText": "So, if I do the same with initial insert batch, then all records will be deleted. But don't want to disrupt the flow for rest of the quick start.", "author": "nsivabalan", "createdAt": "2020-01-18T21:06:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0ODU4OA==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368248588", "bodyText": "I can move it as the last section. Hope thats fine.", "author": "nsivabalan", "createdAt": "2020-01-18T21:07:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0ODU4OQ==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368248589", "bodyText": "lets just delete a few existing records? and show that.. you can use .limit(2) to say get just 2 records out of the existing table and delete it", "author": "vinothchandar", "createdAt": "2020-01-18T21:07:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjMxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0ODY1MQ==", "url": "https://github.com/apache/hudi/pull/1248#discussion_r368248651", "bodyText": "Lets have it after incremental query.. deletes will conclude the flow of writing and reading nicely", "author": "vinothchandar", "createdAt": "2020-01-18T21:08:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODI0MjMxNw=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "8f42f1feff9131a027b0a2e40157d7a9ea5b7799", "url": "https://github.com/apache/hudi/commit/8f42f1feff9131a027b0a2e40157d7a9ea5b7799", "message": "Adding delete docs to QuickStart", "committedDate": "2020-01-22T13:49:12Z", "type": "commit"}, {"oid": "8f42f1feff9131a027b0a2e40157d7a9ea5b7799", "url": "https://github.com/apache/hudi/commit/8f42f1feff9131a027b0a2e40157d7a9ea5b7799", "message": "Adding delete docs to QuickStart", "committedDate": "2020-01-22T13:49:12Z", "type": "forcePushed"}]}