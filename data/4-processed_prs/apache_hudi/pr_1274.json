{"pr_number": 1274, "pr_title": "[HUDI-571] Add 'commits show archived' command to CLI", "pr_createdAt": "2020-01-23T01:25:53Z", "pr_url": "https://github.com/apache/hudi/pull/1274", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY0Mg==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370493642", "bodyText": "Can we use StringUtils.isNullOrEmpty (in all other places as well) ?", "author": "n3nash", "createdAt": "2020-01-24T06:52:04Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java", "diffHunk": "@@ -62,26 +110,33 @@ public String showCommits(\n       throws IOException {\n \n     HoodieActiveTimeline activeTimeline = HoodieCLI.getTableMetaClient().getActiveTimeline();\n-    HoodieTimeline timeline = activeTimeline.getCommitsTimeline().filterCompletedInstants();\n-    List<HoodieInstant> commits = timeline.getReverseOrderedInstants().collect(Collectors.toList());\n-    List<Comparable[]> rows = new ArrayList<>();\n-    for (HoodieInstant commit : commits) {\n-      HoodieCommitMetadata commitMetadata =\n-          HoodieCommitMetadata.fromBytes(timeline.getInstantDetails(commit).get(), HoodieCommitMetadata.class);\n-      rows.add(new Comparable[] {commit.getTimestamp(), commitMetadata.fetchTotalBytesWritten(),\n-          commitMetadata.fetchTotalFilesInsert(), commitMetadata.fetchTotalFilesUpdated(),\n-          commitMetadata.fetchTotalPartitionsWritten(), commitMetadata.fetchTotalRecordsWritten(),\n-          commitMetadata.fetchTotalUpdateRecordsWritten(), commitMetadata.fetchTotalWriteErrors()});\n-    }\n+    return printCommits(activeTimeline, limit, sortByField, descending, headerOnly);\n+  }\n \n-    Map<String, Function<Object, String>> fieldNameToConverterMap = new HashMap<>();\n-    fieldNameToConverterMap.put(\"Total Bytes Written\", entry -> NumericUtils.humanReadableByteCount((Double.parseDouble(entry.toString()))));\n+  @CliCommand(value = \"commits show archived\", help = \"Show the archived commits\")\n+  public String showArchivedCommits(\n+          @CliOption(key = {\"startTs\"},  mandatory = false, help = \"start time for commits, default: now - 10 days\")\n+          String startTs,\n+          @CliOption(key = {\"endTs\"},  mandatory = false, help = \"end time for commits, default: now - 1 day\")\n+          String endTs,\n+          @CliOption(key = {\"limit\"}, mandatory = false, help = \"Limit commits\", unspecifiedDefaultValue = \"-1\")\n+          final Integer limit,\n+          @CliOption(key = {\"sortBy\"}, help = \"Sorting Field\", unspecifiedDefaultValue = \"\")\n+          final String sortByField,\n+          @CliOption(key = {\"desc\"}, help = \"Ordering\", unspecifiedDefaultValue = \"false\")\n+          final boolean descending,\n+          @CliOption(key = {\"headeronly\"}, help = \"Print Header Only\", unspecifiedDefaultValue = \"false\")\n+          final boolean headerOnly)\n+          throws IOException {\n \n-    TableHeader header = new TableHeader().addTableHeaderField(\"CommitTime\").addTableHeaderField(\"Total Bytes Written\")\n-        .addTableHeaderField(\"Total Files Added\").addTableHeaderField(\"Total Files Updated\")\n-        .addTableHeaderField(\"Total Partitions Written\").addTableHeaderField(\"Total Records Written\")\n-        .addTableHeaderField(\"Total Update Records Written\").addTableHeaderField(\"Total Errors\");\n-    return HoodiePrintHelper.print(header, fieldNameToConverterMap, sortByField, descending, limit, headerOnly, rows);\n+    if (startTs == null || startTs.isEmpty()) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2NDY5Mw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370864693", "bodyText": "@satishkotha", "author": "n3nash", "createdAt": "2020-01-24T22:09:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg5MzM0OA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370893348", "bodyText": "sounds good. I'm sending an update", "author": "satishkotha", "createdAt": "2020-01-25T00:11:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY2Mw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370493663", "bodyText": "Can you explain why we need this change ?", "author": "n3nash", "createdAt": "2020-01-24T06:52:12Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodiePartitionMetadata.java", "diffHunk": "@@ -38,6 +38,7 @@\n   public static final String HOODIE_PARTITION_METAFILE = \".hoodie_partition_metadata\";\n   public static final String PARTITION_DEPTH_KEY = \"partitionDepth\";\n   public static final String COMMIT_TIME_KEY = \"commitTime\";\n+  public static final String ACTION_TYPE_KEY = \"actionType\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgxODc3Ng==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370818776", "bodyText": "I thought having all metadata constants in one place would make it simpler. This is used in reading archived commit. I can move the constant to ArchivedTimeline if you think thats a better place.", "author": "satishkotha", "createdAt": "2020-01-24T20:03:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MjUwNA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370862504", "bodyText": "Please move it to the ArchivedTimeline since it makes more senes there", "author": "n3nash", "createdAt": "2020-01-24T22:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg5MzM1OA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370893358", "bodyText": "sounds good. I'm sending an update", "author": "satishkotha", "createdAt": "2020-01-25T00:11:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5MzY2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MjcyNg==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370862726", "bodyText": "Any reason to remove if (archivedTimeline == null) check ?", "author": "n3nash", "createdAt": "2020-01-24T22:03:42Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/HoodieTableMetaClient.java", "diffHunk": "@@ -289,11 +288,8 @@ public ConsistencyGuardConfig getConsistencyGuardConfig() {\n    *\n    * @return Active commit timeline\n    */\n-  public synchronized HoodieArchivedTimeline getArchivedTimeline() {\n-    if (archivedTimeline == null) {\n-      archivedTimeline = new HoodieArchivedTimeline(this);\n-    }\n-    return archivedTimeline;\n+  public synchronized HoodieArchivedTimeline getArchivedTimeline(String startTs, String endTs) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg5MzgxOQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370893819", "bodyText": "archivedTimeline as instance variable does not make sense because we are creating archive timeline for small time window (depending on command line arguments). So we will create mutiple archivedTimelines when someone is paginating through archived commit files. null check prevents us from doing that.\nIn the long term, when we have lazy loading, we can consider creating one instance of ArchivedTimeline that stores all metadata. we can bring back instance variable at that time. Until we have that, this does not make sense.\nLet me know if you think there is a better way to organize this.", "author": "satishkotha", "createdAt": "2020-01-25T00:14:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MjcyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4MDI2Mg==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r371580262", "bodyText": "Isn't the instance variable loaded lazily only when getArchivedTimeline() is called in which case subsequent cases can use that instance variable. I think the concern here is that the only method we expose now is getArchivedTimeline(String startTs, String endTs) and caching the instance variable from that doesn't make sense as you are saying as well. I'm wondering if we should keep an instance variable and keep the same method as before getArchivedTimeline() and then the constructor below is also light. Finally, we expose a method on the archived timeline to filter(startTs, endTs). This way we don't have to create multiple objects for each window invocation. WDYT ?", "author": "n3nash", "createdAt": "2020-01-28T02:09:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MjcyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4NDA1OQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r371584059", "bodyText": "I initially wanted to do that. But HoodieDefaultTimeline(base class) keeps track of instants in private class variable. And we do all filtering operations on top of that. So, if we reuse same HoodieArchivedTimeline object, we will likely have to change structure of how instants are kept in memory for base class.  I can talk to you more in person tomorrow. But right now, i prefer creating multiple instances of archived timeline because its less error prone IMO.", "author": "satishkotha", "createdAt": "2020-01-28T02:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MjcyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MTg4NQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372151885", "bodyText": "After talking in person, changed behavior to create single instance of \"HoodieArchivedTimeline\" and load metadata for all  commits.\nNote that this means we read all archived files first. Then do a second pass for details of commits in specific time range. This increases overall time taken by first command. In the example dataset, it took ~20 minutes for initial metadata to load.\nThen subsequent commands are few seconds each.\nWith previous approach we only do one pass on files. All commands are few seconds each.\nSo I think we need to improve metadata to reduce time taken by first step with new approach.", "author": "satishkotha", "createdAt": "2020-01-29T01:43:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MjcyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2Mjk3MQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370862971", "bodyText": "The HoodieDefaultTimeline has implementation -> public HoodieDefaultTimeline findInstantsInRange(String startTs, String endTs) already, can we try to reuse that ?", "author": "n3nash", "createdAt": "2020-01-24T22:04:25Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/HoodieTimeline.java", "diffHunk": "@@ -230,6 +230,14 @@ static boolean compareTimestamps(String commit1, String commit2, BiPredicate<Str\n     return predicateToApply.test(commit1, commit2);\n   }\n \n+  /**\n+   * Return true if specified timestamp is in range (startTs, endTs].\n+   */\n+  static boolean isInRange(String timestamp, String startTs, String endTs) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg5NDA0Ng==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370894046", "bodyText": "HoodieDefaultTimeline has changes to use this method. I refactored to make this part reusable\n @Override public HoodieDefaultTimeline findInstantsInRange(String startTs, String endTs) { return new HoodieDefaultTimeline( instants.stream().filter(s -> HoodieTimeline.isInRange(s.getTimestamp(), startTs, endTs)), details); }", "author": "satishkotha", "createdAt": "2020-01-25T00:16:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2Mjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4MDQyOA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r371580428", "bodyText": "makes sense", "author": "n3nash", "createdAt": "2020-01-28T02:10:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2Mjk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MzE0OA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370863148", "bodyText": "This is just the prefix right ? May be rename is HOODIE_COMMIT_ARCHIVE_LOG_FILE_NAME_PREFIX ?", "author": "n3nash", "createdAt": "2020-01-24T22:04:55Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/HoodieArchivedTimeline.java", "diffHunk": "@@ -49,34 +60,76 @@\n  * This class can be serialized and de-serialized and on de-serialization the FileSystem is re-initialized.\n  */\n public class HoodieArchivedTimeline extends HoodieDefaultTimeline {\n+  private static final Pattern ARCHIVE_FILE_PATTERN =\n+          Pattern.compile(\"^\\\\.commits_\\\\.archive\\\\.([0-9]*)$\");\n \n   private static final String HOODIE_COMMIT_ARCHIVE_LOG_FILE = \"commits\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg5NDIwOQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r370894209", "bodyText": "regex captures everything [0-9]* at the end gives the suffix and is used for sorting files by 'version'", "author": "satishkotha", "createdAt": "2020-01-25T00:16:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MzE0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTQyMjM2Mg==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r371422362", "bodyText": "I'm referring to this variable HOODIE_COMMIT_ARCHIVE_LOG_FILE that stores just the string commits, regex is a different variable ?", "author": "n3nash", "createdAt": "2020-01-27T19:00:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MzE0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTQyNDY0NA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r371424644", "bodyText": "oh, my bad. I didnt change that line, so i thought you were referring to the line i changed. I can change HOODIE_COMMIT_ARCHIVE_LOG_FILE to include its prefix", "author": "satishkotha", "createdAt": "2020-01-27T19:04:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg2MzE0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3MjQwMw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372572403", "bodyText": "You can use a defaultValue during the cliOption itself so you don't have to use these checks ?", "author": "n3nash", "createdAt": "2020-01-29T19:02:43Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java", "diffHunk": "@@ -62,26 +111,38 @@ public String showCommits(\n       throws IOException {\n \n     HoodieActiveTimeline activeTimeline = HoodieCLI.getTableMetaClient().getActiveTimeline();\n-    HoodieTimeline timeline = activeTimeline.getCommitsTimeline().filterCompletedInstants();\n-    List<HoodieInstant> commits = timeline.getReverseOrderedInstants().collect(Collectors.toList());\n-    List<Comparable[]> rows = new ArrayList<>();\n-    for (HoodieInstant commit : commits) {\n-      HoodieCommitMetadata commitMetadata =\n-          HoodieCommitMetadata.fromBytes(timeline.getInstantDetails(commit).get(), HoodieCommitMetadata.class);\n-      rows.add(new Comparable[] {commit.getTimestamp(), commitMetadata.fetchTotalBytesWritten(),\n-          commitMetadata.fetchTotalFilesInsert(), commitMetadata.fetchTotalFilesUpdated(),\n-          commitMetadata.fetchTotalPartitionsWritten(), commitMetadata.fetchTotalRecordsWritten(),\n-          commitMetadata.fetchTotalUpdateRecordsWritten(), commitMetadata.fetchTotalWriteErrors()});\n-    }\n-\n-    Map<String, Function<Object, String>> fieldNameToConverterMap = new HashMap<>();\n-    fieldNameToConverterMap.put(\"Total Bytes Written\", entry -> NumericUtils.humanReadableByteCount((Double.parseDouble(entry.toString()))));\n+    return printCommits(activeTimeline, limit, sortByField, descending, headerOnly);\n+  }\n \n-    TableHeader header = new TableHeader().addTableHeaderField(\"CommitTime\").addTableHeaderField(\"Total Bytes Written\")\n-        .addTableHeaderField(\"Total Files Added\").addTableHeaderField(\"Total Files Updated\")\n-        .addTableHeaderField(\"Total Partitions Written\").addTableHeaderField(\"Total Records Written\")\n-        .addTableHeaderField(\"Total Update Records Written\").addTableHeaderField(\"Total Errors\");\n-    return HoodiePrintHelper.print(header, fieldNameToConverterMap, sortByField, descending, limit, headerOnly, rows);\n+  @CliCommand(value = \"commits show archived\", help = \"Show the archived commits\")\n+  public String showArchivedCommits(\n+          @CliOption(key = {\"startTs\"},  mandatory = false, help = \"start time for commits, default: now - 10 days\")\n+          String startTs,\n+          @CliOption(key = {\"endTs\"},  mandatory = false, help = \"end time for commits, default: now - 1 day\")\n+          String endTs,\n+          @CliOption(key = {\"limit\"}, mandatory = false, help = \"Limit commits\", unspecifiedDefaultValue = \"-1\")\n+          final Integer limit,\n+          @CliOption(key = {\"sortBy\"}, help = \"Sorting Field\", unspecifiedDefaultValue = \"\")\n+          final String sortByField,\n+          @CliOption(key = {\"desc\"}, help = \"Ordering\", unspecifiedDefaultValue = \"false\")\n+          final boolean descending,\n+          @CliOption(key = {\"headeronly\"}, help = \"Print Header Only\", unspecifiedDefaultValue = \"false\")\n+          final boolean headerOnly)\n+          throws IOException {\n+    if (StringUtils.isNullOrEmpty(startTs)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3NzIwMQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372577201", "bodyText": "CLIOption attribute can only be assigned a static value. i think default static value is not that friendly. I chose to pick '10 days before today' which is likely to be commonly used. Let me know if you prefer default constant date instead", "author": "satishkotha", "createdAt": "2020-01-29T19:12:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3MjQwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjYwMTc5Mw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372601793", "bodyText": "okay, that makes sense", "author": "n3nash", "createdAt": "2020-01-29T20:02:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3MjQwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3MzEwNQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372573105", "bodyText": "nit : s/removeInstantDetailsFromMemory/clearInstantDetailsFromMemory", "author": "n3nash", "createdAt": "2020-01-29T19:04:05Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/HoodieArchivedTimeline.java", "diffHunk": "@@ -96,7 +101,16 @@ private void readObject(java.io.ObjectInputStream in) throws IOException, ClassN\n   }\n \n   public static Path getArchiveLogPath(String archiveFolder) {\n-    return new Path(archiveFolder, HOODIE_COMMIT_ARCHIVE_LOG_FILE);\n+    return new Path(archiveFolder, HOODIE_COMMIT_ARCHIVE_LOG_FILE_PREFIX);\n+  }\n+\n+  public void loadInstantDetailsInMemory(String startTs, String endTs) {\n+    loadInstants(startTs, endTs);\n+  }\n+\n+  public void removeInstantDetailsFromMemory(String startTs, String endTs) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3NzM2NQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372577365", "bodyText": "ok, renamed", "author": "satishkotha", "createdAt": "2020-01-29T19:12:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3MzEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3NDU5MQ==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r372574591", "bodyText": "@vinothchandar can you ack that this is okay to move to this class ? This way the ArchivedTimeline can also use these methods (and is aligned with our thoughts on having the same operations on archived and active timeline..)", "author": "n3nash", "createdAt": "2020-01-29T19:07:10Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/table/timeline/HoodieDefaultTimeline.java", "diffHunk": "@@ -143,6 +143,83 @@ public HoodieTimeline filter(Predicate<HoodieInstant> filter) {\n     return new HoodieDefaultTimeline(instants.stream().filter(filter), details);\n   }\n \n+  /**\n+   * Get all instants (commits, delta commits) that produce new data, in the active timeline.\n+   */\n+  public HoodieTimeline getCommitsTimeline() {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTY1OA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r374439658", "bodyText": "@vinothchandar just pinging to resurface this since it might be lost in the large number of notifications :)", "author": "n3nash", "createdAt": "2020-02-04T01:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3NDU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDUzMjQ5OA==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r374532498", "bodyText": "@n3nash can't think of anything top of my mind.. Should be fine.", "author": "vinothchandar", "createdAt": "2020-02-04T08:33:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU3NDU5MQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjIzMw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r375016233", "bodyText": "Please avoid this change as part of this diff", "author": "n3nash", "createdAt": "2020-02-05T01:29:11Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java", "diffHunk": "@@ -135,6 +135,7 @@\n   /**\n    * Total number of rollback blocks seen in a compaction operation.\n    */\n+  @Nullable", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTA3NTU0Ng==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r375075546", "bodyText": "Discussed offline. Without this we are not able to read certain archived commits", "author": "satishkotha", "createdAt": "2020-02-05T06:16:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjI5Mw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r375016293", "bodyText": "same here, we can address this as part of some other refactoring diff", "author": "n3nash", "createdAt": "2020-02-05T01:29:27Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java", "diffHunk": "@@ -290,7 +291,7 @@ public long getTotalRollbackBlocks() {\n     return totalRollbackBlocks;\n   }\n \n-  public void setTotalRollbackBlocks(Long totalRollbackBlocks) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTA3NTU3Mw==", "url": "https://github.com/apache/hudi/pull/1274#discussion_r375075573", "bodyText": "Discussed offline. Without this we are not able to read certain archived commits", "author": "satishkotha", "createdAt": "2020-02-05T06:16:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjI5Mw=="}], "type": "inlineReview"}, {"oid": "2c94b175d5d658a6d57f3f2d9534d1aab6d1adb4", "url": "https://github.com/apache/hudi/commit/2c94b175d5d658a6d57f3f2d9534d1aab6d1adb4", "message": "[HUDI-571] Add 'commits show archived' command to CLI", "committedDate": "2020-02-05T06:14:39Z", "type": "commit"}, {"oid": "2c94b175d5d658a6d57f3f2d9534d1aab6d1adb4", "url": "https://github.com/apache/hudi/commit/2c94b175d5d658a6d57f3f2d9534d1aab6d1adb4", "message": "[HUDI-571] Add 'commits show archived' command to CLI", "committedDate": "2020-02-05T06:14:39Z", "type": "forcePushed"}]}