{"pr_number": 1580, "pr_title": "[HUDI-852] adding check for table name for Append Save mode ", "pr_createdAt": "2020-05-01T07:49:12Z", "pr_url": "https://github.com/apache/hudi/pull/1580", "timeline": [{"oid": "c71fb111582a0ad1bffb00360f0a912755e4166c", "url": "https://github.com/apache/hudi/commit/c71fb111582a0ad1bffb00360f0a912755e4166c", "message": "adding check for table name for Append Save mode", "committedDate": "2020-05-01T07:35:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk2NDUxOQ==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r418964519", "bodyText": "I think this check is applicable to both the if and else clause. Can you verify that and move it to may be line 85 (before the if clause) ?", "author": "bhasudha", "createdAt": "2020-05-02T14:21:22Z", "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -118,6 +118,12 @@ private[hudi] object HoodieSparkSqlWriter {\n         fs.delete(basePath, true)\n         exists = false\n       }\n+      if (exists && mode == SaveMode.Append) {", "originalCommit": "c71fb111582a0ad1bffb00360f0a912755e4166c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTE3NzMwNA==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r419177304", "bodyText": "Thanks for the comment. I have updated the code.", "author": "AakashPradeep", "createdAt": "2020-05-03T23:59:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk2NDUxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTE4MDk4NA==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r419180984", "bodyText": "@bhasudha please review!\nThanks!", "author": "AakashPradeep", "createdAt": "2020-05-04T00:38:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk2NDUxOQ=="}], "type": "inlineReview"}, {"oid": "679218955ed5488915c360a3096000b48a920952", "url": "https://github.com/apache/hudi/commit/679218955ed5488915c360a3096000b48a920952", "message": "adding existing table validation for delete and upsert operation", "committedDate": "2020-05-03T23:51:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY1NDg4NQ==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r419654885", "bodyText": "actually we could have pushed this check into the guts of hoodie-client.. Every write will initialize a HoodieTableMetaClient anyway.. And have it error out from inside, it will save this extra tableMetaClient initialization..  @bhasudha let's file a follow up, if you agree", "author": "vinothchandar", "createdAt": "2020-05-04T18:54:34Z", "path": "hudi-spark/src/main/scala/org/apache/hudi/HoodieSparkSqlWriter.scala", "diffHunk": "@@ -83,6 +83,13 @@ private[hudi] object HoodieSparkSqlWriter {\n     val fs = basePath.getFileSystem(sparkContext.hadoopConfiguration)\n     var exists = fs.exists(new Path(basePath, HoodieTableMetaClient.METAFOLDER_NAME))\n \n+    if (exists && mode == SaveMode.Append) {\n+      val existingTableName = new HoodieTableMetaClient(sparkContext.hadoopConfiguration, path.get).getTableConfig.getTableName\n+      if (!existingTableName.equals(tblName.get)) {\n+        throw new HoodieException(s\"hoodie table with name $existingTableName already exist at $basePath\")", "originalCommit": "679218955ed5488915c360a3096000b48a920952", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzNzYwNg==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r419837606", "bodyText": "Thanks for the comment @vinothchandar.\nI would suggest the following :\n\n\nI can use HoodieTableConfig here instead of HoodieTableMetaClient (which seems little  expensive here)\n\n\nI will explore the hoodie-client code. But I would suggest to either keep all the check based on save mode in this class or move all to hoodie-client.   The earlier it throws exception better it would be, but I would leave that on you guys to decide.\n\n\nIf we decide to keep all the checks as it is then I will suggest moving checks at Line number 116 to the beginning of the if section so that we can fail fast and avoid a lot of initialization. Same for the table existence check at 172, it should be moved to the beginning of else section.\n\n\nPlease let me know if it sounds reasonable to you. I can file another Jira for improvement.\nThanks!", "author": "AakashPradeep", "createdAt": "2020-05-05T02:53:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY1NDg4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDE3NDA2MA==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r420174060", "bodyText": "@AakashPradeep Thanks for the follow up..\nFor other save modes, e.g OVERWRITE (we first delete the existing dataset), this does not apply anyway.. So I was wondering if we can enforce this at the HoodieTable.create() level, which always reads hoodie.properties anyway... We can add a ValidationUtils.checkArgument() there to simply check the writeConfig table name matches what we read from props file?\nI will let you and @bhasudha take it from here.. :)", "author": "vinothchandar", "createdAt": "2020-05-05T14:55:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY1NDg4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDI4MjQxNA==", "url": "https://github.com/apache/hudi/pull/1580#discussion_r420282414", "bodyText": "Thanks !", "author": "AakashPradeep", "createdAt": "2020-05-05T17:27:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY1NDg4NQ=="}], "type": "inlineReview"}]}