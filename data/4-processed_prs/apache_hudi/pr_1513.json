{"pr_number": 1513, "pr_title": "[HUDI-793] Adding proper default to hudi metadata fields and proper handling to rewrite routine", "pr_createdAt": "2020-04-14T19:31:36Z", "pr_url": "https://github.com/apache/hudi/pull/1513", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408423175", "bodyText": "By doing this change, we are effectively going back to deprecated constructors again. Can you please explain the purpose of doing this?", "author": "pratyakshsharma", "createdAt": "2020-04-14T20:43:34Z", "path": "hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java", "diffHunk": "@@ -104,15 +105,15 @@ public static Schema addMetadataFields(Schema schema) {\n     List<Schema.Field> parentFields = new ArrayList<>();\n \n     Schema.Field commitTimeField =\n-        new Schema.Field(HoodieRecord.COMMIT_TIME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n+        new Schema.Field(HoodieRecord.COMMIT_TIME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance());\n     Schema.Field commitSeqnoField =\n-        new Schema.Field(HoodieRecord.COMMIT_SEQNO_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n+        new Schema.Field(HoodieRecord.COMMIT_SEQNO_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance());\n     Schema.Field recordKeyField =\n-        new Schema.Field(HoodieRecord.RECORD_KEY_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n+        new Schema.Field(HoodieRecord.RECORD_KEY_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance());\n     Schema.Field partitionPathField =\n-        new Schema.Field(HoodieRecord.PARTITION_PATH_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n+        new Schema.Field(HoodieRecord.PARTITION_PATH_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance());\n     Schema.Field fileNameField =\n-        new Schema.Field(HoodieRecord.FILENAME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n+        new Schema.Field(HoodieRecord.FILENAME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQzMTU2OQ==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408431569", "bodyText": "it doesn't generate correct avro schema. This might not be the correct fix, but passing (Object) null results is the schema without default value.", "author": "afilipchik", "createdAt": "2020-04-14T20:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQzNjIyNA==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408436224", "bodyText": "Ok.. I am still trying to understand what difference does it make if the schema is generated without defaultValue or if it is generated with defaultValue as null. Can you please provide more points to support this?", "author": "pratyakshsharma", "createdAt": "2020-04-14T21:08:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ0NzYwNg==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408447606", "bodyText": "Incorrect avro schema is a disaster waiting to happen. Current one says: it takes \"null\" or String, but no defaults. Given that it is serialized in both log and parquet files it has to be correct, as if we add new field it will not be readable. Here is example exception when message was written without a field and then attempted to be read with field that doesn't have default:\nCaused by: org.apache.avro.AvroTypeException: Found Event, expecting Event, missing required field exist at org.apache.avro.io.ResolvingDecoder.doAction(ResolvingDecoder.java:292) at org.apache.avro.io.parsing.Parser.advance(Parser.java:88) at org.apache.avro.io.ResolvingDecoder.readFieldOrder(ResolvingDecoder.java:130) at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:215) at org.apache.avro.generic.GenericDatumReader.readWithoutConversion(GenericDatumReader.java:175) at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:153) at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:145)", "author": "afilipchik", "createdAt": "2020-04-14T21:30:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3MjIxNg==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408472216", "bodyText": "Ok.. IMO hoodie metadata fields will never be written as null. If you strongly feel about doing this change, can we think of some alternate solution rather than going back to deprecated constructors. Also wanted to check with you how are you generating schema like you mentioned before?", "author": "pratyakshsharma", "createdAt": "2020-04-14T22:26:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NzU2Ng==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408477566", "bodyText": "Sure, there might be another way. I think there are changes with nulls in 1.9.0, but upgrading is not easy. Just to clarify, it is not for the write support, but for the read one. Consider situation:\nWe have avro with 4 metada fields written, and defaults are not set. Not an issue as it is written.\nWe add another metadata field (sourceOffset, or something), which also doesn't have default field and redeploy. When we try to read old record with new schema it will fail because old record doesn't have new field and there is no default for it. I hit this issue with spark-> avro transformation, have another PR to address", "author": "afilipchik", "createdAt": "2020-04-14T22:40:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4MDU1Mw==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408480553", "bodyText": "On schema generation, we had to do some stuff... Our service emits protobufs to kafka, which we transform to avro using ProtoToAvro converter. Because those are service to service messages, they are not perfect and we had to do some bending to make sure schema can evolve. Some things:\n\nWe made everything optional\nAvro and Protobuf allows records to have no fields. But parquet doesn't, so, we inject marker field called exists pretty much everywhere. We do it inside HUDI to avoid clutter in kafka. Originally added it only to records with no fields, but found out that when fields are added and exists is autoremoved, parquet-avro reader breaks as it expects every field in parquet schema to be present in avro. I have a fix to parquet-avro to skip those fields, will send a PR to show so we can discuss whether it is a good idea or not.\nThen we sometimes run sql transformation (same kafka stream produces multiple outputs). In this case, we infer schema from Spark (using NullTargetSchemaProvider). This schema must be correct as well which is not the case as spark omits defaults, so compaction breaks. Have a PR to address.", "author": "afilipchik", "createdAt": "2020-04-14T22:48:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU5ODMwMg==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408598302", "bodyText": "parquet-avro reader breaks as it expects every field in parquet schema to be present in avro. I have a fix to parquet-avro to skip those fields, will send a PR to show so we can discuss whether it is a good idea or not\n\nYes, please. Would love to see how you are approaching that fix.", "author": "pratyakshsharma", "createdAt": "2020-04-15T05:58:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDgxNDE2MA==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r424814160", "bodyText": "Overloading of null to denote absence of a default value in avro, is confusing to say the least.. (atleast I learnt that now) But I am trying to grok the actual change in behavior..\nThis change seems to be orthogonal to the fix below.. Effectively, we are making the metadata fields nullable (as opposed to having no default values), with this change... While I agree, metadata fields won't have nulls.. Having this safety is better..", "author": "vinothchandar", "createdAt": "2020-05-14T01:03:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyMzE3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyNTM3Mw==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408425373", "bodyText": "Why do you need this? If f.defaultVal() is null, it will be automatically populated like that.", "author": "pratyakshsharma", "createdAt": "2020-04-14T20:47:44Z", "path": "hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java", "diffHunk": "@@ -206,7 +207,11 @@ private static GenericRecord rewrite(GenericRecord record, LinkedHashSet<Field>\n     GenericRecord newRecord = new GenericData.Record(newSchema);\n     for (Schema.Field f : fieldsToWrite) {\n       if (record.get(f.name()) == null) {\n-        newRecord.put(f.name(), f.defaultVal());\n+        if (f.defaultVal() instanceof Null) {\n+          newRecord.put(f.name(), null);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQzMDgzOQ==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408430839", "bodyText": "just run the test without it. You will get an exception.\nif schema has \"default\": null it breaks, which should not be the case.", "author": "afilipchik", "createdAt": "2020-04-14T20:57:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyNTM3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQzNTE5MQ==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408435191", "bodyText": "Which test you are talking about?", "author": "pratyakshsharma", "createdAt": "2020-04-14T21:06:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyNTM3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ0MzEwOA==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408443108", "bodyText": "the one that was modified in this PR: TestHoodieAvroUtils.java. I updated test avro schema.", "author": "afilipchik", "createdAt": "2020-04-14T21:21:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyNTM3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ2OTYzNQ==", "url": "https://github.com/apache/hudi/pull/1513#discussion_r408469635", "bodyText": "Ok so when using f.defaultVal(), NullNode corresponds to JsonProperties.Null class and hence the test case fails. Good catch :)", "author": "pratyakshsharma", "createdAt": "2020-04-14T22:19:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQyNTM3Mw=="}], "type": "inlineReview"}, {"oid": "9bccd32376962ae43997cd1510f6b2baa488492e", "url": "https://github.com/apache/hudi/commit/9bccd32376962ae43997cd1510f6b2baa488492e", "message": "Adding proper default to hudi metadata fields and proper handling to rewrite routine", "committedDate": "2020-04-20T22:19:25Z", "type": "commit"}, {"oid": "8e208a6e95f93b106fb219f30b4deccd6dab1f84", "url": "https://github.com/apache/hudi/commit/8e208a6e95f93b106fb219f30b4deccd6dab1f84", "message": "Force spark to generate nullables", "committedDate": "2020-04-20T22:19:26Z", "type": "commit"}, {"oid": "97fbcf55a6dcf423ba30a5e03ca6dc5e3b0d32fb", "url": "https://github.com/apache/hudi/commit/97fbcf55a6dcf423ba30a5e03ca6dc5e3b0d32fb", "message": "Removed nullables as spark generates broken schema :(", "committedDate": "2020-04-20T22:19:26Z", "type": "commit"}, {"oid": "97fbcf55a6dcf423ba30a5e03ca6dc5e3b0d32fb", "url": "https://github.com/apache/hudi/commit/97fbcf55a6dcf423ba30a5e03ca6dc5e3b0d32fb", "message": "Removed nullables as spark generates broken schema :(", "committedDate": "2020-04-20T22:19:26Z", "type": "forcePushed"}]}