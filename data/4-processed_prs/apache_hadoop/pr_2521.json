{"pr_number": 2521, "pr_title": "HDFS-15711. Add Metrics to HttpFS Server.", "pr_createdAt": "2020-12-05T00:14:47Z", "pr_url": "https://github.com/apache/hadoop/pull/2521", "timeline": [{"oid": "c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "url": "https://github.com/apache/hadoop/commit/c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "message": "HDFS-15711. Add Metrics to HttpFS Server.", "committedDate": "2020-12-07T14:38:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0Njg5Mg==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538846892", "bodyText": "I think you need to increment OpsCheckAccess() in FSAccess.execute().", "author": "jbrennan333", "createdAt": "2020-12-08T22:13:23Z", "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/HttpFSServerWebApp.java", "diffHunk": "@@ -123,6 +143,14 @@ public static HttpFSServerWebApp get() {\n     return SERVER;\n   }\n \n+  /**\n+   * gets the HttpFSServerMetrics instance.\n+   * @return the HttpFSServerMetrics singleton.\n+   */\n+  public static HttpFSServerMetrics getMetrics() {\n+    return metrics;\n+  }\n+\n   /**\n    * Returns HttpFSServer admin group.\n    *", "originalCommit": "c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTA1Mw==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538849053", "bodyText": "It's not clear to me why we need this metricsGetter.   Seems to add complexity with no added value.  Can't you just call the appropriate HttpFSServerWebApp.get().getMetrics().get* function wherever this is used?", "author": "jbrennan333", "createdAt": "2020-12-08T22:17:05Z", "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServer.java", "diffHunk": "@@ -120,6 +122,25 @@\n  */\n public class TestHttpFSServer extends HFSTestCase {\n \n+  /**\n+   * define metric getters for unit tests.\n+   */\n+  private static Callable<Long> defaultEntryMetricGetter = () -> 0L;\n+  private static Callable<Long> defaultExitMetricGetter = () -> 1L;\n+  private static HashMap<String, Callable<Long>> metricsGetter =\n+      new HashMap<String, Callable<Long>>() {\n+        {\n+          put(\"LISTSTATUS\",\n+              () -> HttpFSServerWebApp.get().getMetrics().getOpsListing());\n+          put(\"MKDIRS\",\n+              () -> HttpFSServerWebApp.get().getMetrics().getOpsMkdir());\n+          put(\"GETFILESTATUS\",\n+              () -> HttpFSServerWebApp.get().getMetrics().getOpsStat());\n+        }\n+      };\n+", "originalCommit": "c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODkwNTU0Mg==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538905542", "bodyText": "I found that the best way to check the metrics is to inject code in getStatus. This reduced the diff significantly. getStatus() accepts the cmd as a string, so adding if-then-else for each cmd will be more difficult to maintain. Finally, it is easier to add a command to the metricsGetter to extend the set of tests.\nAlso, the default callable saves NPE in case the command is not mapped to a metricGetter.", "author": "amahussein", "createdAt": "2020-12-09T00:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTYwMTYxNg==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r539601616", "bodyText": "Oh I see that makes sense for getStatus().  I was looking at testMkdirs() when I was trying to understand why you were using it, and it didn't make sense to me.  I don't think you should use the metricsGetter in testMkdirs(), or at least not use getOrDefault() - the default case here does not make sense - it renders that part of the test meaningless.  I'd prefer to just get the ops directly in this case.", "author": "jbrennan333", "createdAt": "2020-12-09T19:53:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDM3MjU0OA==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r540372548", "bodyText": "Thanks @jbrennan333 .\nThis makes sense.\nI fixed testMkdirs, createDirWithHttp, testGlobFilter, and testHdfsAccess", "author": "amahussein", "createdAt": "2020-12-10T17:46:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTg1Mw==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538849853", "bodyText": "Seems like extra blank lines were added by accident.", "author": "jbrennan333", "createdAt": "2020-12-08T22:17:57Z", "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/test/java/org/apache/hadoop/fs/http/server/TestHttpFSServer.java", "diffHunk": "@@ -542,8 +572,12 @@ private void createDirWithHttp(String dirname, String perms,\n     conn.setRequestMethod(\"PUT\");\n     conn.connect();\n     Assert.assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());\n+    Assert.assertEquals(1 + oldOpsMkdir,\n+        HttpFSServerWebApp.get().getMetrics().getOpsMkdir());\n   }\n \n+\n+", "originalCommit": "c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODkwNTYzMA==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538905630", "bodyText": "done", "author": "amahussein", "createdAt": "2020-12-09T00:12:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0OTg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg2MDMyNw==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538860327", "bodyText": "Can you make this private?  It is only used by init() in this class.", "author": "jbrennan333", "createdAt": "2020-12-08T22:36:51Z", "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/HttpFSServerWebApp.java", "diffHunk": "@@ -110,9 +116,23 @@ public void init() throws ServerException {\n   @Override\n   public void destroy() {\n     SERVER = null;\n+    if (metrics != null) {\n+      metrics.shutdown();\n+    }\n     super.destroy();\n   }\n \n+  public static void setMetrics(Configuration config) {", "originalCommit": "c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg2MTE0Nw==", "url": "https://github.com/apache/hadoop/pull/2521#discussion_r538861147", "bodyText": "Can't you just use metrics instead of HttpFSServerWebApp.metrics?  Same a few lines below.", "author": "jbrennan333", "createdAt": "2020-12-08T22:38:26Z", "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/HttpFSServerWebApp.java", "diffHunk": "@@ -110,9 +116,23 @@ public void init() throws ServerException {\n   @Override\n   public void destroy() {\n     SERVER = null;\n+    if (metrics != null) {\n+      metrics.shutdown();\n+    }\n     super.destroy();\n   }\n \n+  public static void setMetrics(Configuration config) {\n+    LOG.info(\"Initializing HttpFSServerMetrics\");\n+    HttpFSServerWebApp.metrics =", "originalCommit": "c2cc329d0e77c16a5c68e55f616eacbb63ac36b3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b833540d47457d02c831a9f2dacdea0e60423fbf", "url": "https://github.com/apache/hadoop/commit/b833540d47457d02c831a9f2dacdea0e60423fbf", "message": "HDFS-15711. code reviews.", "committedDate": "2020-12-09T00:16:10Z", "type": "forcePushed"}, {"oid": "06a3276d392dcb7d5924a21cba30062b6c832ae6", "url": "https://github.com/apache/hadoop/commit/06a3276d392dcb7d5924a21cba30062b6c832ae6", "message": "HDFS-15711. Add Metrics to HttpFS Server.", "committedDate": "2020-12-10T17:39:43Z", "type": "commit"}, {"oid": "dfa6bc9c1f4eb77a2cdcc91810b2e1b5526c4514", "url": "https://github.com/apache/hadoop/commit/dfa6bc9c1f4eb77a2cdcc91810b2e1b5526c4514", "message": "HDFS-15711. code reviews.", "committedDate": "2020-12-10T17:39:43Z", "type": "commit"}, {"oid": "989b16ee779551734e36dabc8ea787218d5565df", "url": "https://github.com/apache/hadoop/commit/989b16ee779551734e36dabc8ea787218d5565df", "message": "HDFS-15711. fix mkdir ops getter.", "committedDate": "2020-12-10T17:39:43Z", "type": "commit"}, {"oid": "989b16ee779551734e36dabc8ea787218d5565df", "url": "https://github.com/apache/hadoop/commit/989b16ee779551734e36dabc8ea787218d5565df", "message": "HDFS-15711. fix mkdir ops getter.", "committedDate": "2020-12-10T17:39:43Z", "type": "forcePushed"}]}