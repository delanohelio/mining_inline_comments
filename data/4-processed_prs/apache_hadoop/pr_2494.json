{"pr_number": 2494, "pr_title": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "pr_createdAt": "2020-11-27T03:06:18Z", "pr_url": "https://github.com/apache/hadoop/pull/2494", "timeline": [{"oid": "cad6881da696a0fbc427f3dcb199e95ffc81804b", "url": "https://github.com/apache/hadoop/commit/cad6881da696a0fbc427f3dcb199e95ffc81804b", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-11-27T03:17:04Z", "type": "forcePushed"}, {"oid": "80388afb28c8d2b92fff95416bf0a0f76d9d202d", "url": "https://github.com/apache/hadoop/commit/80388afb28c8d2b92fff95416bf0a0f76d9d202d", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-01T05:40:57Z", "type": "commit"}, {"oid": "80388afb28c8d2b92fff95416bf0a0f76d9d202d", "url": "https://github.com/apache/hadoop/commit/80388afb28c8d2b92fff95416bf0a0f76d9d202d", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-01T05:40:57Z", "type": "forcePushed"}, {"oid": "fb506a09bcf17d30468cb22231e710492168a1c8", "url": "https://github.com/apache/hadoop/commit/fb506a09bcf17d30468cb22231e710492168a1c8", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-01T14:25:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjUxMg==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533502512", "bodyText": "Why remove this variable and add new within if-else block?", "author": "jiwq", "createdAt": "2020-12-01T15:29:41Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -531,11 +531,11 @@ private static boolean shouldSkipNodeSchedule(FiCaSchedulerNode node,\n \n   /**\n    * Schedule on all nodes by starting at a random point.\n+   * Schedule on all partitions by starting at a random partition\n+   * when multiNodePlacementEnabled is true.\n    * @param cs\n    */\n   static void schedule(CapacityScheduler cs) throws InterruptedException{\n-    // First randomize the start point\n-    int current = 0;", "originalCommit": "fb506a09bcf17d30468cb22231e710492168a1c8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTkxNg==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865916", "bodyText": "Fixed it.", "author": "zhuqi-lucas", "createdAt": "2020-12-02T03:07:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg0MQ==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533502841", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  //Get all partitions\n          \n          \n            \n                  // Get all partitions", "author": "jiwq", "createdAt": "2020-12-01T15:30:03Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions", "originalCommit": "fb506a09bcf17d30468cb22231e710492168a1c8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTg3MQ==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865871", "bodyText": "Fixed it.", "author": "zhuqi-lucas", "createdAt": "2020-12-02T03:06:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwNjAyNg==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533506026", "bodyText": "Due to getCandiateNodeSet(String) method maybe return null, so call allocateContainersToNode can cause NPE.", "author": "jiwq", "createdAt": "2020-12-01T15:34:09Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java", "diffHunk": "@@ -544,44 +544,73 @@ static void schedule(CapacityScheduler cs) throws InterruptedException{\n     if(nodeSize == 0) {\n       return;\n     }\n-    int start = random.nextInt(nodeSize);\n+    if (!cs.multiNodePlacementEnabled) {\n+      // First randomize the start point\n+      int current = 0;\n+      int start = random.nextInt(nodeSize);\n \n-    // To avoid too verbose DEBUG logging, only print debug log once for\n-    // every 10 secs.\n-    boolean printSkipedNodeLogging = false;\n-    if (Time.monotonicNow() / 1000 % 10 == 0) {\n-      printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n-    } else {\n-      printedVerboseLoggingForAsyncScheduling = false;\n-    }\n+      // To avoid too verbose DEBUG logging, only print debug log once for\n+      // every 10 secs.\n+      boolean printSkipedNodeLogging = false;\n+      if (Time.monotonicNow() / 1000 % 10 == 0) {\n+        printSkipedNodeLogging = (!printedVerboseLoggingForAsyncScheduling);\n+      } else {\n+        printedVerboseLoggingForAsyncScheduling = false;\n+      }\n+\n+      // Allocate containers of node [start, end)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ >= start) {\n+          if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n+            continue;\n+          }\n+          cs.allocateContainersToNode(node.getNodeID(), false);\n+        }\n+      }\n \n-    // Allocate containers of node [start, end)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ >= start) {\n+      current = 0;\n+\n+      // Allocate containers of node [0, start)\n+      for (FiCaSchedulerNode node : nodes) {\n+        if (current++ > start) {\n+          break;\n+        }\n         if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n           continue;\n         }\n         cs.allocateContainersToNode(node.getNodeID(), false);\n       }\n-    }\n-\n-    current = 0;\n \n-    // Allocate containers of node [0, start)\n-    for (FiCaSchedulerNode node : nodes) {\n-      if (current++ > start) {\n-        break;\n+      if (printSkipedNodeLogging) {\n+        printedVerboseLoggingForAsyncScheduling = true;\n       }\n-      if (shouldSkipNodeSchedule(node, cs, printSkipedNodeLogging)) {\n-        continue;\n+    } else {\n+      //Get all partitions\n+      List<String> partitions = cs.nodeTracker.getPartitions();\n+      int partitionSize = partitions.size();\n+      // First randomize the start point\n+      int start = random.nextInt(partitionSize);\n+      int current = 0;\n+      // Allocate containers of partition [start, end)\n+      for (String partititon : partitions) {\n+        if (current++ >= start) {\n+          cs.allocateContainersToNode(cs.getCandidateNodeSet(partititon),", "originalCommit": "fb506a09bcf17d30468cb22231e710492168a1c8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg2NTc4Ng==", "url": "https://github.com/apache/hadoop/pull/2494#discussion_r533865786", "bodyText": "Fixed it.", "author": "zhuqi-lucas", "createdAt": "2020-12-02T03:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwNjAyNg=="}], "type": "inlineReview"}, {"oid": "c0f03143911fc5e0527304da8e8f05d9563748fe", "url": "https://github.com/apache/hadoop/commit/c0f03143911fc5e0527304da8e8f05d9563748fe", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-02T03:02:22Z", "type": "commit"}, {"oid": "c0f03143911fc5e0527304da8e8f05d9563748fe", "url": "https://github.com/apache/hadoop/commit/c0f03143911fc5e0527304da8e8f05d9563748fe", "message": "YARN-10380: Import logic of multi-node allocation in CapacityScheduler", "committedDate": "2020-12-02T03:02:22Z", "type": "forcePushed"}]}