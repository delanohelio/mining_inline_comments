{"pr_number": 2363, "pr_title": "HDFS-13293. RBF: The RouterRPCServer should transfer client IP via CallerContext to NamenodeRpcServer", "pr_createdAt": "2020-10-06T13:42:37Z", "pr_url": "https://github.com/apache/hadoop/pull/2363", "timeline": [{"oid": "df5f3b5aec48b6f1fe1eb0b460dd8eb0dcfb9deb", "url": "https://github.com/apache/hadoop/commit/df5f3b5aec48b6f1fe1eb0b460dd8eb0dcfb9deb", "message": "HDFS-13293. RBF: The RouterRPCServer should transfer CallerContext and client ip to NamenodeRpcServer", "committedDate": "2020-10-06T13:40:44Z", "type": "commit"}, {"oid": "98e97d8608614d931224450a11bb2b9d9119f16a", "url": "https://github.com/apache/hadoop/commit/98e97d8608614d931224450a11bb2b9d9119f16a", "message": "fix checkstyle", "committedDate": "2020-10-06T15:43:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMTI5NQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500431295", "bodyText": "Extract the builder.build()", "author": "goiri", "createdAt": "2020-10-06T16:22:33Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,21 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIp2CallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    CallerContext.Builder builder;\n+    String origContext = ctx == null ? null : ctx.getContext();\n+    byte[] origSignature = ctx == null ? null : ctx.getSignature();\n+    builder = new CallerContext.Builder(origContext, clientConf);\n+    builder.append(CLIENT_IP_STR, Server.getRemoteAddress());\n+    builder.setSignature(origSignature);\n+    CallerContext.setCurrent(builder.build());", "originalCommit": "98e97d8608614d931224450a11bb2b9d9119f16a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NDY1NQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500454655", "bodyText": "Ok", "author": "ferhui", "createdAt": "2020-10-06T16:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMTI5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjQwMg==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500432402", "bodyText": "Do this in the moment you create it in line 537.", "author": "goiri", "createdAt": "2020-10-06T16:24:12Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,21 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIp2CallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    CallerContext.Builder builder;", "originalCommit": "98e97d8608614d931224450a11bb2b9d9119f16a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NDg1OA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500454858", "bodyText": "Ok", "author": "ferhui", "createdAt": "2020-10-06T16:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjQwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500432918", "bodyText": "Can we verify we still contain the old context we had?", "author": "goiri", "createdAt": "2020-10-06T16:25:00Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1903,19 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testCreateWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"705\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientIp:\"\n+    assertTrue(auditlog.getOutput().contains(\"callerContext=clientIp:\"));", "originalCommit": "98e97d8608614d931224450a11bb2b9d9119f16a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NTE1Ng==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500455156", "bodyText": "old context is null, Will add a check.", "author": "ferhui", "createdAt": "2020-10-06T16:59:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU0MTIwNQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500541205", "bodyText": "I was referring to having this test with a null context but also a test with some already passed context.", "author": "goiri", "createdAt": "2020-10-06T19:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDcyMjk1OA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500722958", "bodyText": "ok", "author": "ferhui", "createdAt": "2020-10-07T03:55:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMjkxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzY5OQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500433699", "bodyText": "I would do it more formal: appendClientIpToCallerContext", "author": "goiri", "createdAt": "2020-10-06T16:26:12Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -404,6 +409,7 @@ private Object invokeMethod(\n           \" with params \" + Arrays.deepToString(params) + \" from \"\n           + router.getRouterId());\n     }\n+    appendClientIp2CallerContext();", "originalCommit": "98e97d8608614d931224450a11bb2b9d9119f16a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NTI0Ng==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500455246", "bodyText": "ok", "author": "ferhui", "createdAt": "2020-10-06T16:59:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzY5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500433968", "bodyText": "Is there something else we need to add?", "author": "goiri", "createdAt": "2020-10-06T16:26:42Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -116,10 +118,13 @@\n   /** Optional perf monitor. */\n   private final RouterRpcMonitor rpcMonitor;\n \n+  private final Configuration clientConf;\n+\n   /** Pattern to parse a stack trace line. */\n   private static final Pattern STACK_TRACE_PATTERN =\n       Pattern.compile(\"\\\\tat (.*)\\\\.(.*)\\\\((.*):(\\\\d*)\\\\)\");\n \n+  private static final String CLIENT_IP_STR = \"clientIp\";", "originalCommit": "98e97d8608614d931224450a11bb2b9d9119f16a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ1NTgyNQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500455825", "bodyText": "Now don't know Whether add anything else except client ip, any thoughts?", "author": "ferhui", "createdAt": "2020-10-06T17:00:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDU0MDg0OQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500540849", "bodyText": "One of the things that was brought up in the past was to send back in the context which was the namespace that executed this.\nAnyway, let's focus on the locality one for now.\nDoes it make sense to add a test to make sure we can do proper locality from the Namenode side with this change? Or should we leave this for the future.", "author": "goiri", "createdAt": "2020-10-06T19:22:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDcyMjgzOA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r500722838", "bodyText": "HDFS-13248 focuses on the locality, here we focus on audit log, does it make sense?", "author": "ferhui", "createdAt": "2020-10-07T03:55:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzNzIwOA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501137208", "bodyText": "Makes sense, let's just keep in mind HDFS-13248 when doing this.\nSo far it looks like is covered.", "author": "goiri", "createdAt": "2020-10-07T16:10:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQzMzk2OA=="}], "type": "inlineReview"}, {"oid": "e08f3596cf6e00624f95b01ff87fdbb25dca89a9", "url": "https://github.com/apache/hadoop/commit/e08f3596cf6e00624f95b01ff87fdbb25dca89a9", "message": "extract builder, check original context", "committedDate": "2020-10-06T17:02:31Z", "type": "commit"}, {"oid": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1", "url": "https://github.com/apache/hadoop/commit/d211231660a37f5d7fc6aaad9c0949ecfe0791f1", "message": "fix checkstyle and add context to UT", "committedDate": "2020-10-07T04:21:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501138092", "bodyText": "Anyway we can check for the actual IP?", "author": "goiri", "createdAt": "2020-10-07T16:12:16Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRpc.java", "diffHunk": "@@ -1901,4 +1904,27 @@ private DFSClient getFileDFSClient(final String path) {\n     }\n     return null;\n   }\n+\n+  @Test\n+  public void testMkdirsWithCallerContext() throws IOException {\n+    GenericTestUtils.LogCapturer auditlog =\n+        GenericTestUtils.LogCapturer.captureLogs(FSNamesystem.auditLog);\n+\n+    // Current callerContext is null\n+    assertNull(CallerContext.getCurrent());\n+\n+    // Set client context\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(\"clientContext\").build());\n+\n+    // Create a directory via the router\n+    String dirPath = \"/test_dir_with_callercontext\";\n+    FsPermission permission = new FsPermission(\"755\");\n+    routerProtocol.mkdirs(dirPath, permission, false);\n+\n+    // The audit log should contains \"callerContext=clientContext,clientIp:\"\n+    assertTrue(auditlog.getOutput()\n+        .contains(\"callerContext=clientContext,clientIp:\"));", "originalCommit": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE3Njk4OQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501176989", "bodyText": "Had thought  about this. DFSClient & Client do not expose ip, and TestAuditLogger & TestAuditLogs do not check client ip. So do you have any suggestions?", "author": "ferhui", "createdAt": "2020-10-07T17:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTE4NTcwMg==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501185702", "bodyText": "Or just keep it that way, and do not modify UT", "author": "ferhui", "createdAt": "2020-10-07T17:26:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTIzMDU1Mw==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501230553", "bodyText": "The only issue I see is to grab random logs but I guess is fine.", "author": "goiri", "createdAt": "2020-10-07T18:38:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTI0MDEwMg==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501240102", "bodyText": "Sorry, do not understand it.\nI think If we check the actual IP, we should get the client actual IP, e.g \"w.x.y.z\", and then check the audit log, it should contain \"callerContext=clientContext,clientIp:w.x.y.z\", is it right?\nNow it's hard to get client ip.", "author": "ferhui", "createdAt": "2020-10-07T18:55:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNjEzMw==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501316133", "bodyText": "Correct, grabbing the proper Client IP is not trivial and error prone so I'm fine with this.", "author": "goiri", "createdAt": "2020-10-07T21:19:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzODA5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQyMDQ4MA==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501420480", "bodyText": "Can we pass the string separator instead of configuration to avoid unnecessary Configuration.get() for each RPC?", "author": "aajisaka", "createdAt": "2020-10-08T03:00:42Z", "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java", "diffHunk": "@@ -519,6 +525,20 @@ private Object invokeMethod(\n     }\n   }\n \n+  /**\n+   * For Tracking which is the actual client address.\n+   * It adds key/value (clientIp/\"ip\") pair to the caller context.\n+   */\n+  private void appendClientIpToCallerContext() {\n+    final CallerContext ctx = CallerContext.getCurrent();\n+    String origContext = ctx == null ? null : ctx.getContext();\n+    byte[] origSignature = ctx == null ? null : ctx.getSignature();\n+    CallerContext.setCurrent(\n+        new CallerContext.Builder(origContext, clientConfiguration)", "originalCommit": "d211231660a37f5d7fc6aaad9c0949ecfe0791f1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQ0MzE0MQ==", "url": "https://github.com/apache/hadoop/pull/2363#discussion_r501443141", "bodyText": "OK, fixed, please review again, thanks!", "author": "ferhui", "createdAt": "2020-10-08T04:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTQyMDQ4MA=="}], "type": "inlineReview"}, {"oid": "41c579d31d96488039d0ccb3c8b121c9f09ef085", "url": "https://github.com/apache/hadoop/commit/41c579d31d96488039d0ccb3c8b121c9f09ef085", "message": "pass separator instead of conf to builder", "committedDate": "2020-10-08T04:32:20Z", "type": "commit"}]}