{"pr_number": 2228, "pr_title": "YARN-10399 Refactor NodeQueueLoadMonitor class to make it extendable", "pr_createdAt": "2020-08-14T19:13:00Z", "pr_url": "https://github.com/apache/hadoop/pull/2228", "timeline": [{"oid": "df923741d5163bae15cf2a9769390649007ca53b", "url": "https://github.com/apache/hadoop/commit/df923741d5163bae15cf2a9769390649007ca53b", "message": "Refactor NodeQueueLoadMonitor class to make it extendable", "committedDate": "2020-08-14T19:06:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgyMTk3Nw==", "url": "https://github.com/apache/hadoop/pull/2228#discussion_r470821977", "bodyText": "As we are moving this, we can make it a proper logger comment with {}.", "author": "goiri", "createdAt": "2020-08-14T19:18:17Z", "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/distributed/NodeQueueLoadMonitor.java", "diffHunk": "@@ -260,55 +236,72 @@ public void updateNode(RMNode rmNode) {\n       opportunisticContainersStatus =\n           OpportunisticContainersStatus.newInstance();\n     }\n-    int opportQueueCapacity =\n-        opportunisticContainersStatus.getOpportQueueCapacity();\n-    int estimatedQueueWaitTime =\n-        opportunisticContainersStatus.getEstimatedQueueWaitTime();\n-    int waitQueueLength = opportunisticContainersStatus.getWaitQueueLength();\n+\n     // Add nodes to clusterNodes. If estimatedQueueTime is -1, ignore node\n     // UNLESS comparator is based on queue length.\n     ReentrantReadWriteLock.WriteLock writeLock = clusterNodesLock.writeLock();\n     writeLock.lock();\n     try {\n-      ClusterNode currentNode = this.clusterNodes.get(rmNode.getNodeID());\n-      if (currentNode == null) {\n-        if (rmNode.getState() != NodeState.DECOMMISSIONING &&\n-            (estimatedQueueWaitTime != -1 ||\n-                comparator == LoadComparator.QUEUE_LENGTH)) {\n-          this.clusterNodes.put(rmNode.getNodeID(),\n-              new ClusterNode(rmNode.getNodeID())\n-                  .setQueueWaitTime(estimatedQueueWaitTime)\n-                  .setQueueLength(waitQueueLength)\n-                  .setQueueCapacity(opportQueueCapacity));\n-          LOG.info(\"Inserting ClusterNode [\" + rmNode.getNodeID() + \"] \" +\n-              \"with queue wait time [\" + estimatedQueueWaitTime + \"] and \" +\n-              \"wait queue length [\" + waitQueueLength + \"]\");\n-        } else {\n-          LOG.warn(\"IGNORING ClusterNode [\" + rmNode.getNodeID() + \"] \" +\n-              \"with queue wait time [\" + estimatedQueueWaitTime + \"] and \" +\n-              \"wait queue length [\" + waitQueueLength + \"]\");\n-        }\n+      ClusterNode clusterNode = this.clusterNodes.get(rmNode.getNodeID());\n+      if (clusterNode == null) {\n+        onNewNodeAdded(rmNode, opportunisticContainersStatus);\n       } else {\n-        if (rmNode.getState() != NodeState.DECOMMISSIONING &&\n-            (estimatedQueueWaitTime != -1 ||\n-                comparator == LoadComparator.QUEUE_LENGTH)) {\n-          currentNode\n+        onExistingNodeUpdated(rmNode, clusterNode, opportunisticContainersStatus);\n+      }\n+    } finally {\n+      writeLock.unlock();\n+    }\n+  }\n+\n+  protected void onNewNodeAdded(\n+      RMNode rmNode, OpportunisticContainersStatus status) {\n+    int opportQueueCapacity = status.getOpportQueueCapacity();\n+    int estimatedQueueWaitTime = status.getEstimatedQueueWaitTime();\n+    int waitQueueLength = status.getWaitQueueLength();\n+\n+    if (rmNode.getState() != NodeState.DECOMMISSIONING &&\n+        (estimatedQueueWaitTime != -1 ||\n+            comparator == LoadComparator.QUEUE_LENGTH)) {\n+      this.clusterNodes.put(rmNode.getNodeID(),\n+          new ClusterNode(rmNode.getNodeID())\n               .setQueueWaitTime(estimatedQueueWaitTime)\n               .setQueueLength(waitQueueLength)\n-              .updateTimestamp();\n-          LOG.debug(\"Updating ClusterNode [{}] with queue wait time [{}] and\"\n+              .setNodeLabels(rmNode.getNodeLabels())\n+              .setQueueCapacity(opportQueueCapacity));\n+      LOG.info(\"Inserting ClusterNode [\" + rmNode.getNodeID() + \"] \" +", "originalCommit": "df923741d5163bae15cf2a9769390649007ca53b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgyOTMyNA==", "url": "https://github.com/apache/hadoop/pull/2228#discussion_r470829324", "bodyText": "Updated", "author": "zhengbli", "createdAt": "2020-08-14T19:35:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDgyMTk3Nw=="}], "type": "inlineReview"}, {"oid": "0932068f0e6a879e42cff44754910f3154562c0f", "url": "https://github.com/apache/hadoop/commit/0932068f0e6a879e42cff44754910f3154562c0f", "message": "Use proper logging format", "committedDate": "2020-08-14T19:34:30Z", "type": "commit"}, {"oid": "c1e760627947d29632352a6a76ea2d5b57dc8773", "url": "https://github.com/apache/hadoop/commit/c1e760627947d29632352a6a76ea2d5b57dc8773", "message": "Add more comments", "committedDate": "2020-08-18T22:16:36Z", "type": "commit"}]}