{"pr_number": 2370, "pr_title": "HDFS-15614. Initialize snapshot trash root during NameNode startup if enabled", "pr_createdAt": "2020-10-08T17:40:03Z", "pr_url": "https://github.com/apache/hadoop/pull/2370", "timeline": [{"oid": "dce5752068a327b86e28c8cf1c642691f95d6741", "url": "https://github.com/apache/hadoop/commit/dce5752068a327b86e28c8cf1c642691f95d6741", "message": "Add checkAndProvisionSnapshotTrashRoots in FSNamesystem.\nAdd UT.\n\nChange-Id: If679da69024056697bf633094a359530bffc74d3", "committedDate": "2020-10-08T17:36:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTkwMDA1Ng==", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r501900056", "bodyText": "I am not 100% sure about this condition check. Any suggestions/confirmations?\nThe goal is to only let Active NN to check and provision snapshot trash roots. The assumption is that the mkdirs() call below propagates the write to standby NameNode.", "author": "smengcl", "createdAt": "2020-10-08T17:43:47Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -8524,6 +8530,39 @@ void checkAccess(String src, FsAction mode) throws IOException {\n     logAuditEvent(true, operationName, src);\n   }\n \n+  /**\n+   * Check if snapshot roots are created for all existing snapshottable\n+   * directories. Create them if not.\n+   */\n+  void checkAndProvisionSnapshotTrashRoots() throws IOException {\n+    if (haEnabled) {\n+      if (!inActiveState()) {", "originalCommit": "dce5752068a327b86e28c8cf1c642691f95d6741", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzMjkwMQ==", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r502332901", "bodyText": "getIsSnapshotTrashRootEnabled --> isSnapshotTrashRootEnabled??", "author": "bshashikant", "createdAt": "2020-10-09T10:22:12Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java", "diffHunk": "@@ -2031,6 +2033,10 @@ private String metaSaveAsString() {\n     return sw.toString();\n   }\n \n+  public boolean getIsSnapshotTrashRootEnabled() {", "originalCommit": "dce5752068a327b86e28c8cf1c642691f95d6741", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzNDY0Mw==", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r502334643", "bodyText": "how about doing this here:\n @Override\n    public void startActiveServices() throws IOException {\n      try {\n        namesystem.startActiveServices();\n        startTrashEmptier(getConf());\n      } catch (Throwable t) {\n        doImmediateShutdown(t);\n      }\n    }\n\njust before starting the trashEmptier thread. We don't need to check for Active or standby state here as these should be called in only Active NameNode.", "author": "bshashikant", "createdAt": "2020-10-09T10:25:52Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java", "diffHunk": "@@ -781,6 +781,10 @@ protected void initialize(Configuration conf) throws IOException {\n       }\n     }\n \n+    if (namesystem.getIsSnapshotTrashRootEnabled()) {", "originalCommit": "dce5752068a327b86e28c8cf1c642691f95d6741", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQyMjQyMw==", "url": "https://github.com/apache/hadoop/pull/2370#discussion_r503422423", "bodyText": "good idea", "author": "smengcl", "createdAt": "2020-10-12T16:59:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjMzNDY0Mw=="}], "type": "inlineReview"}, {"oid": "78c9621978c83a9484eae3c54c18121480aa988f", "url": "https://github.com/apache/hadoop/commit/78c9621978c83a9484eae3c54c18121480aa988f", "message": "Move check to startActiveServices;\nremove redundant getIsSnapshotTrashRootEnabled method.\n\nChange-Id: Ic9293e36907ee88ab2bf17855a8927e4e6c4c949", "committedDate": "2020-10-12T17:01:39Z", "type": "commit"}, {"oid": "8a66b25308975eb1eca621526879d3cf53467691", "url": "https://github.com/apache/hadoop/commit/8a66b25308975eb1eca621526879d3cf53467691", "message": "Checkstyle.\n\nChange-Id: Ibd167312dd6a2db5f90e15fe6b01300274770867", "committedDate": "2020-10-12T17:06:53Z", "type": "commit"}, {"oid": "be0a2825b419f502083a8999b9acdf9b315b00c0", "url": "https://github.com/apache/hadoop/commit/be0a2825b419f502083a8999b9acdf9b315b00c0", "message": "Retrigger checks\n\nChange-Id: Ib761a58fec35f8f967e008268a020db28effbc8f", "committedDate": "2020-10-13T14:15:24Z", "type": "commit"}, {"oid": "bea0c156e64047002d2b45194825149514d40c87", "url": "https://github.com/apache/hadoop/commit/bea0c156e64047002d2b45194825149514d40c87", "message": "Merge branch 'trunk' into HDFS-15614", "committedDate": "2020-10-13T16:08:20Z", "type": "commit"}]}