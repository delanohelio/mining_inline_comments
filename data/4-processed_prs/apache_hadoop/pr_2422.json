{"pr_number": 2422, "pr_title": "HADOOP-17311. ABFS: Logs should redact SAS signature", "pr_createdAt": "2020-10-29T10:13:17Z", "pr_url": "https://github.com/apache/hadoop/pull/2422", "timeline": [{"oid": "0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "url": "https://github.com/apache/hadoop/commit/0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "message": "ABFS: Masking SAS signatures from logs", "committedDate": "2020-10-29T10:17:25Z", "type": "forcePushed"}, {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "url": "https://github.com/apache/hadoop/commit/8883b59a819d5aa77cb37a2a422d9039cab943a3", "message": "ABFS: Masking SAS signatures from logs", "committedDate": "2020-10-29T10:20:05Z", "type": "commit"}, {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "url": "https://github.com/apache/hadoop/commit/8883b59a819d5aa77cb37a2a422d9039cab943a3", "message": "ABFS: Masking SAS signatures from logs", "committedDate": "2020-10-29T10:20:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0MjM5Ng==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514442396", "bodyText": "now all shaded I'm afraid. Making backporting harder already", "author": "steveloughran", "createdAt": "2020-10-29T17:33:26Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -36,6 +36,7 @@\n import org.codehaus.jackson.JsonParser;\n import org.codehaus.jackson.JsonToken;\n import org.codehaus.jackson.map.ObjectMapper;\n+import com.google.common.annotations.VisibleForTesting;", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDQ4OQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894489", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0MjM5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0Mzc3MA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514443770", "bodyText": "While you are there\n\nadd a catch for UnknownHostException\nmove from String.format to Log.warn(\"unknown host {}\", httpOperation,getHost()", "author": "steveloughran", "createdAt": "2020-10-29T17:35:29Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java", "diffHunk": "@@ -256,7 +256,9 @@ private boolean executeHttpOperation(final int retryCount) throws AzureBlobFileS\n       }\n     } catch (IOException ex) {\n       if (ex instanceof UnknownHostException) {\n-        LOG.warn(String.format(\"Unknown host name: %s. Retrying to resolve the host name...\", httpOperation.getUrl().getHost()));\n+        LOG.warn(String.format(\n+            \"Unknown host name: %s. Retrying to resolve the host name...\",\n+            httpOperation.getHost()));", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDU0Mw==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894543", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0Mzc3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NDU1NA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514444554", "bodyText": "use LambdaTestUtils.intercept(). Not only simpler, it will (correctly) fail if the rest operation didn't actually raise an exception", "author": "steveloughran", "createdAt": "2020-10-29T17:36:42Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java", "diffHunk": "@@ -381,4 +383,39 @@ public void testProperties() throws Exception {\n \n     assertArrayEquals(propertyValue, fs.getXAttr(reqPath, propertyName));\n   }\n+\n+  @Test\n+  public void testSignatureMask() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String src = \"/testABC/test.xt\";\n+    fs.create(new Path(src));\n+    AbfsRestOperation abfsHttpRestOperation = fs.getAbfsClient()\n+        .renamePath(src, \"/testABC\" + \"/abc.txt\", null);\n+    AbfsHttpOperation result = abfsHttpRestOperation.getResult();\n+    String url = result.getSignatureMaskedUrlStr();\n+    String encodedUrl = result.getSignatureMaskedEncodedUrlStr();\n+    Assertions.assertThat(url.substring(url.indexOf(\"sig=\")))\n+        .describedAs(\"Signature query param should be masked\")\n+        .startsWith(\"sig=XXXX\");\n+    Assertions.assertThat(encodedUrl.substring(encodedUrl.indexOf(\"sig%3D\")))\n+        .describedAs(\"Signature query param should be masked\")\n+        .startsWith(\"sig%3DXXXX\");\n+  }\n+\n+  @Test\n+  public void testSignatureMaskOnExceptionMessage() {\n+    final AzureBlobFileSystem fs;\n+    String msg = null;\n+    try {\n+      fs = getFileSystem();", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDU3NQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894575", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NDU1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NTcwNg==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514445706", "bodyText": "This is complicated enough it could be pulled out into a static method, and so its handling fully tested in (new) Unit tests, as well as in the ITests.", "author": "steveloughran", "createdAt": "2020-10-29T17:38:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDY5Ng==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894696", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NTcwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0ODQzNA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515748434", "bodyText": "create a private static final string. - private static final String SIGNATURE_QUERY_PARAM_KEY = \"sig=\";", "author": "snvijaya", "createdAt": "2020-11-02T05:36:05Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();\n+    final String qpStr = \"sig=\";", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDc1OA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894758", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:01:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0ODQzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0OTExOQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515749119", "bodyText": "Using string replace should be easier.\nint sigStartIndex = urlStr.indexOf(SIGNATURE_QUERY_PARAM_KEY);\nif (sigStartIndex == -1) {\n  // no signature query param in the url\n  return urlStr;\n}\n\nsigStartIndex += SIGNATURE_QUERY_PARAM_KEY.length();\nint sigEndIndex = urlStr.indexOf(\"&\", sigStartIndex);\nString sigValue = (sigEndIndex == -1)\n    ? urlStr.substring(sigStartIndex)\n    : urlStr.substring(sigStartIndex, sigEndIndex);\n\nreturn urlStr.replace(sigValue, \"XXXX\");", "author": "snvijaya", "createdAt": "2020-11-02T05:39:11Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();\n+    final String qpStr = \"sig=\";\n+    final int qpStrIdx = urlStr.indexOf(qpStr);\n+    if (qpStrIdx < 0) {\n+      return urlStr;\n+    }\n+    final StringBuilder sb = new StringBuilder();\n+    sb.append(urlStr, 0, qpStrIdx);\n+    sb.append(qpStr);\n+    sb.append(\"XXXX\");\n+    if (qpStrIdx + qpStr.length() < urlStr.length()) {\n+      String urlStrSecondPart = urlStr.substring(qpStrIdx + qpStr.length());\n+      int idx = urlStrSecondPart.indexOf(\"&\");\n+      if (idx > -1) {\n+        sb.append(urlStrSecondPart.substring(idx));\n+      }", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDgxNA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894814", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:01:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0OTExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc1MDUwOA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515750508", "bodyText": "Is a header called \"sig\" getting added when SAS ?", "author": "snvijaya", "createdAt": "2020-11-02T05:44:53Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsIoUtils.java", "diffHunk": "@@ -58,6 +58,9 @@ public static void dumpHeadersToDebugLog(final String origin,\n         if (key.contains(\"Cookie\")) {\n           values = \"*cookie info*\";\n         }\n+        if (key.equals(\"sig\")) {", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NTE5Mw==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515895193", "bodyText": "The latency tracker sends all the query params through headers.", "author": "bilaharith", "createdAt": "2020-11-02T11:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc1MDUwOA=="}], "type": "inlineReview"}, {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "url": "https://github.com/apache/hadoop/commit/f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "message": "Addressing review comments", "committedDate": "2020-11-02T09:33:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5ODc2NQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515898765", "bodyText": "Remove Str suffix", "author": "bilaharith", "createdAt": "2020-11-02T11:08:33Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -61,6 +64,8 @@\n \n   private final String method;\n   private final URL url;\n+  private String maskedUrlStr;", "originalCommit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwODkwOA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515908908", "bodyText": "query params ending mysig/*sig.", "author": "bilaharith", "createdAt": "2020-11-02T11:27:57Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.UnsupportedEncodingException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.net.URLEncoder;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsHttpOperation.getAbfsHttpOperationWithFixedResult;\n+\n+public class TestAbfsHttpOperation {\n+\n+  @Test\n+  public void testForURLs()\n+      throws MalformedURLException, UnsupportedEncodingException {\n+    testIfMaskedSuccessfully(\"Where sig is the only query param\"\n+        ,\"http://www.testurl.net?sig=abcd\"\n+        ,\"http://www.testurl.net?sig=XXXX\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is the first query param\"\n+        ,\"http://www.testurl.net?sig=abcd&abc=xyz\"\n+        ,\"http://www.testurl.net?sig=XXXX&abc=xyz\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is neither first nor last query param\"\n+        ,\"http://www.testurl.net?lmn=abc&sig=abcd&abc=xyz\"\n+        ,\"http://www.testurl.net?lmn=abc&sig=XXXX&abc=xyz\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is the last query param\"\n+        ,\"http://www.testurl.net?abc=xyz&sig=abcd\"\n+        ,\"http://www.testurl.net?abc=xyz&sig=XXXX\");\n+\n+    testIfMaskedSuccessfully(\"Where sig query param is not present\"", "originalCommit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwOTM4Nw==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515909387", "bodyText": "sig in other cases, like caps,\nsig as suffix in the param names and values", "author": "bilaharith", "createdAt": "2020-11-02T11:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwODkwOA=="}], "type": "inlineReview"}, {"oid": "d227991654a5f1b49b3ef3bd9144e96b513f731f", "url": "https://github.com/apache/hadoop/commit/d227991654a5f1b49b3ef3bd9144e96b513f731f", "message": "Adding more test cases and addressing review comments", "committedDate": "2020-11-02T14:09:49Z", "type": "commit"}, {"oid": "723f7206e836a7040bbc00c3b639d672e1cfa591", "url": "https://github.com/apache/hadoop/commit/723f7206e836a7040bbc00c3b639d672e1cfa591", "message": "Checkstyle fixes", "committedDate": "2020-11-03T06:16:01Z", "type": "commit"}, {"oid": "bd872b60e7ed0e402b903a90cdf392da9d6e3ada", "url": "https://github.com/apache/hadoop/commit/bd872b60e7ed0e402b903a90cdf392da9d6e3ada", "message": "Fixing findbugs issues", "committedDate": "2020-11-04T07:54:40Z", "type": "commit"}]}