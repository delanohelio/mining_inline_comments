{"pr_number": 2483, "pr_title": "HDFS-14904. Option to let Balancer prefer top used nodes in each iteration.", "pr_createdAt": "2020-11-23T01:30:14Z", "pr_url": "https://github.com/apache/hadoop/pull/2483", "timeline": [{"oid": "1a293a9a3b2c52716c73087cb8e44db0ff3ec094", "url": "https://github.com/apache/hadoop/commit/1a293a9a3b2c52716c73087cb8e44db0ff3ec094", "message": "Initial code", "committedDate": "2020-11-22T23:46:58Z", "type": "commit"}, {"oid": "3e495b7db13f4c8869aa83b08bfddc7f9d07b1a6", "url": "https://github.com/apache/hadoop/commit/3e495b7db13f4c8869aa83b08bfddc7f9d07b1a6", "message": "Fix style", "committedDate": "2020-11-23T01:17:59Z", "type": "commit"}, {"oid": "8d36dc29ba9ca1a2467272c8461d183598f431fb", "url": "https://github.com/apache/hadoop/commit/8d36dc29ba9ca1a2467272c8461d183598f431fb", "message": "Fix style", "committedDate": "2020-11-23T06:05:54Z", "type": "commit"}, {"oid": "ddd66e0b65e51ca31cb1b628fb05505554078ba6", "url": "https://github.com/apache/hadoop/commit/ddd66e0b65e51ca31cb1b628fb05505554078ba6", "message": "Fix style", "committedDate": "2020-11-23T06:11:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkxODY1Nw==", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r532918657", "bodyText": "How about describe the parameter option as: \"sort datanodes based on the utilization so that highly utilized datanodes get scheduled first\"?", "author": "Jing9", "createdAt": "2020-11-30T21:35:38Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -199,7 +199,10 @@\n       + \"\\tWhether to run the balancer during an ongoing HDFS upgrade.\"\n       + \"This is usually not desired since it will not affect used space \"\n       + \"on over-utilized machines.\"\n-      + \"\\n\\t[-asService]\\tRun as a long running service.\";\n+      + \"\\n\\t[-asService]\\tRun as a long running service.\"\n+      + \"\\n\\t[-sortTopNodes]\"\n+      + \"\\tSort over-utilized nodes by capacity to\"\n+      + \" bring down top used datanode faster.\";", "originalCommit": "ddd66e0b65e51ca31cb1b628fb05505554078ba6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0OTg4Nw==", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r533649887", "bodyText": "Sounds good, will update", "author": "LeonGao91", "createdAt": "2020-12-01T18:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkxODY1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyNTA5MA==", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r532925090", "bodyText": "Do we need this \"if\" statement? Maybe use a Preconditions instead?", "author": "Jing9", "createdAt": "2020-11-30T21:48:17Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -435,6 +444,22 @@ private long init(List<DatanodeStorageReport> reports) {\n     return Math.max(overLoadedBytes, underLoadedBytes);\n   }\n \n+  private void sortOverUtilizedNodes() {\n+    LOG.info(\"Sorting over-utilized nodes by capacity\" +\n+        \" to bring down top used datanode capacity faster\");\n+\n+    if (overUtilized instanceof List) {", "originalCommit": "ddd66e0b65e51ca31cb1b628fb05505554078ba6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1MDQ4Mg==", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r533650482", "bodyText": "This is for findbugs, will check if I can get around it with precondition", "author": "LeonGao91", "createdAt": "2020-12-01T19:00:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjkyNTA5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk4MTMzMw==", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r532981333", "bodyText": "Do we need to consider StorageType (which is associated with Source)? E.g., suppose a DN has 2 storage types, one of which is highly utilized and the other is just above average. Do we want to first schedule the movement for the highly-utilized storage type on this node?", "author": "Jing9", "createdAt": "2020-11-30T23:55:58Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java", "diffHunk": "@@ -435,6 +444,22 @@ private long init(List<DatanodeStorageReport> reports) {\n     return Math.max(overLoadedBytes, underLoadedBytes);\n   }\n \n+  private void sortOverUtilizedNodes() {\n+    LOG.info(\"Sorting over-utilized nodes by capacity\" +\n+        \" to bring down top used datanode capacity faster\");\n+\n+    if (overUtilized instanceof List) {\n+      List<Source> list = (List<Source>) overUtilized;\n+      list.sort(\n+          (Source source1, Source source2) ->", "originalCommit": "ddd66e0b65e51ca31cb1b628fb05505554078ba6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1MDg1Nw==", "url": "https://github.com/apache/hadoop/pull/2483#discussion_r533650857", "bodyText": "Good idea, we should use utilization for storage type instead of datanode utilization. Will fix", "author": "LeonGao91", "createdAt": "2020-12-01T19:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk4MTMzMw=="}], "type": "inlineReview"}, {"oid": "ca36965781af65ee61f753a6afe4f3683a374133", "url": "https://github.com/apache/hadoop/commit/ca36965781af65ee61f753a6afe4f3683a374133", "message": "Resolve comments", "committedDate": "2020-12-01T21:19:22Z", "type": "commit"}, {"oid": "4d22df48c89b94c572958d5a82218d8f83b517c3", "url": "https://github.com/apache/hadoop/commit/4d22df48c89b94c572958d5a82218d8f83b517c3", "message": "Trigger Build", "committedDate": "2020-12-01T23:52:17Z", "type": "commit"}]}