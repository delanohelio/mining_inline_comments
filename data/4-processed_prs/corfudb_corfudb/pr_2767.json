{"pr_number": 2767, "pr_title": "Calculate Remaining Replicated Entries based on TxStream", "pr_createdAt": "2020-09-10T05:27:35Z", "pr_url": "https://github.com/CorfuDB/CorfuDB/pull/2767", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4MTcyMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486081722", "bodyText": "when can this happen?  Does it mean no data is present on the sender?", "author": "pankti-m", "createdAt": "2020-09-10T05:52:47Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5MjA3NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486092075", "bodyText": "I don't think it can ever happen... but I was just being safe in case the get on that map does not find it... we can assume that stream has not been written so there is nothing remaining.", "author": "annym", "createdAt": "2020-09-10T06:21:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4MTcyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDE2MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486084160", "bodyText": "Can we add a small comment explaining the role of this param?  It can be a bit confusing..", "author": "pankti-m", "createdAt": "2020-09-10T06:00:16Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5MjYzMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486092633", "bodyText": "sure, added.", "author": "annym", "createdAt": "2020-09-10T06:23:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDU1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486084555", "bodyText": "nit - tx stream's", "author": "pankti-m", "createdAt": "2020-09-10T06:01:30Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDg0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486084844", "bodyText": "in case of holes, Tx stream's tail will not be above the stream tail, right?  It will be the other way round", "author": "pankti-m", "createdAt": "2020-09-10T06:02:27Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5NjAyMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486096022", "bodyText": "it could right, imagine by the time we query the tail it's 10.. when we check lastProcessedEntry we see 12... and 12 is a hole.. cause on non-switchover cases the tail can continue growing but we freezed it at a certain point.", "author": "annym", "createdAt": "2020-09-10T06:31:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NDg0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NTM5Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486085393", "bodyText": "remove?", "author": "pankti-m", "createdAt": "2020-09-10T06:04:06Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5NDUzMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486094530", "bodyText": "I was going to add trace on all and missed it. Let me add it!", "author": "annym", "createdAt": "2020-09-10T06:27:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NTM5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NjY1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486086655", "bodyText": "where are we ignoring the invalid entry?", "author": "pankti-m", "createdAt": "2020-09-10T06:07:46Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");\n+                    // (Case 2.0)\n+                    return noRemainingEntriesToSend;\n+                }\n+\n+                // (Case 2.2)\n+                // Last ack'ed timestamp should match the last processed tx stream timestamp.\n+                // Calculate how many entries are missing, based on the tx stream's address map\n+                return getTxStreamTotalEntries(lastAckedTs, currentTxStreamProcessedTs.getTimestamp());\n+            }\n+\n+            // (Case 2.1)\n+            // Since last tx stream processed timestamp is not intended to be replicated\n+            // and we're at or beyond the last known tail, no entries remaining to be sent\n+            // at this point.\n+            return noRemainingEntriesToSend;\n         }\n-        return remainingEntriesToSend;\n+\n+        // (Case 1 from description)\n+        if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+            // (Case 1.0)\n+            return getTxStreamTotalEntries(lastAckedTs, txStreamTail);\n+        }\n+\n+        // Case (1.1)\n+        return getTxStreamTotalEntries(currentTxStreamProcessedTs.getTimestamp(), txStreamTail);\n+    }\n+\n+    private long getTxStreamTotalEntries(long lowerBoundary, long upperBoundary) {\n+        long totalEntries = 0;\n+\n+        if (upperBoundary > lowerBoundary) {\n+            StreamAddressRange range = new StreamAddressRange(TRANSACTION_STREAM_ID, upperBoundary, lowerBoundary);\n+            StreamAddressSpace txStreamAddressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n+            // Count how many entries are present in the Tx Stream (this can include holes,\n+            // valid entries and invalid entries), but we count them all (equal weight).\n+            // An invalid entry, is a transactional entry with no streams to replicate (which will be ignored)", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5NjI2Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486096267", "bodyText": "In StreamsLogEntryReader isValidTransactionEntry method", "author": "annym", "createdAt": "2020-09-10T06:32:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NjY1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYwNDU5Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486604592", "bodyText": "that entry will not get replicated but will get counted here, right?  We may want to update the comment if so?", "author": "pankti-m", "createdAt": "2020-09-10T20:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NjY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4Njg4OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486086888", "bodyText": "why do we start this later?", "author": "pankti-m", "createdAt": "2020-09-10T06:08:28Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -74,13 +80,18 @@ public void setAckedTsAndSyncType(long ackedTs, LogReplicationMetadata.Replicati\n         }\n     }\n \n+    public void startAckReader(LogEntryReader logEntryReader) {", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5NjY2Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486096666", "bodyText": "because it needs the LogEntryReader which comes from the FSM, which in turn the FSM needs the logReplicationAckReader, so I need to set it after FSM is initialized. Take a look at class LogReplicationSourceManager", "author": "annym", "createdAt": "2020-09-10T06:33:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4Njg4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA4NzIxOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486087219", "bodyText": "can you move it below along with the other getTail function?", "author": "pankti-m", "createdAt": "2020-09-10T06:09:28Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -74,13 +80,18 @@ public void setAckedTsAndSyncType(long ackedTs, LogReplicationMetadata.Replicati\n         }\n     }\n \n+    public void startAckReader(LogEntryReader logEntryReader) {\n+        this.logEntryReader = logEntryReader;\n+        lastAckedTsPoller.scheduleWithFixedDelay(new TsPollingTask(), 0,\n+                ACKED_TS_READ_INTERVAL_SECONDS, TimeUnit.SECONDS);\n+    }\n+\n     /**\n      * For the given replication runtime, query max stream tail for all streams to be replicated.\n      *\n      * @return max tail of all streams to be replicated for the given runtime\n      */\n-    private long getMaxReplicatedStreamsTail() {\n-        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+    private long getMaxReplicatedStreamsTail(Map<UUID, Long> tailMap) {", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjA5NDU0OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486094549", "bodyText": "empty log", "author": "zhangn49", "createdAt": "2020-09-10T06:27:52Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +122,169 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n+\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n \n-        // No data to send on the Active, so no replication remaining\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n         }\n \n-        // When in LogEntry Sync, no CP and trim has taken place so the remaining entries can be queried using the\n-        // global tail and address maps of the replicated streams\n-        if (lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY) {\n-            return calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, ackedTimestamp);\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n         }\n \n-        // In Snapshot Sync\n-        // Simply subtract the ackedTimestamp from the global log tail from the time the snapshot sync started.\n-        // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n-        // for replicated streams.\n-        // When snapshot sync is ongoing, there may be delta updates also.  Add those new entries by querying the address maps\n-        return ((baseSnapshotTimestamp - ackedTimestamp) +\n-            calculateRemainingEntriesForLogEntrySync(maxReplicatedStreamTail, baseSnapshotTimestamp));\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n     }\n \n-    private long calculateRemainingEntriesForLogEntrySync(long start, long end) {\n-        long remainingEntriesToSend = 0;\n-        for (String stream : config.getStreamsToReplicate()) {\n-            UUID streamId = CorfuRuntime.getStreamID(stream);\n-            StreamAddressRange range = new StreamAddressRange(streamId, start, end);\n-            StreamAddressSpace addressSpace = runtime.getSequencerView().getStreamAddressSpace(range);\n-            remainingEntriesToSend += addressSpace.getAddressMap().getLongCardinality();\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp\n+     * - txStreamTail\n+     * - currentTxStreamProcessedTs\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+\n+     * Case 2.0: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 70\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (contains replicated streams)\n+     *\n+     *          remainingEntries = 0\n+\n+     * Case 2.1: Log Entry Sync Up to Date\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, false (does not contain replicated streams,\n+     *          so there is no expectation that lastAckedTimestamp reaches 70)\n+     *\n+     *          remainingEntries = 0\n+\n+\n+     * Case 2.2: Log Entry Sync Lagging Behind (in ack)\n+     *          - lastAckedTimestamp = 60\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 70, true (does contain replicated streams,\n+     *           wait until lastAckedTimestamp reflects this)\n+     *\n+     *          remainingEntries = entriesBetween(60, 70] = 1\n+     *\n+     */\n+    private long calculateRemainingEntriesIncrementalUpdates(long lastAckedTs, long txStreamTail,\n+                                                             StreamIteratorMetadata currentTxStreamProcessedTs) {\n+        long noRemainingEntriesToSend = 0;\n+\n+        // If we have processed up to or beyond the latest known tx stream tail\n+        // we can assume we are up to date.\n+        // Note: in the case of a switchover the tail won't be moving so we can assume\n+        // the tx's stream last processed timestamp will never be above the stream's tail,\n+        // but in the case of ongoing replication or holes, it might be above.\n+        // We can't do much other than report that we're up to date (as it might continue moving)\n+        if (txStreamTail <= currentTxStreamProcessedTs.getTimestamp()) {\n+            // (Case 2 from description)\n+            // If the current processed tx stream entry has data to replicate,\n+            // we need to ensure we have received an ACK it, otherwise,\n+            // we might be signalling completion when there is still an entry for which\n+            // we haven't received confirmation of the recipient.\n+            if (currentTxStreamProcessedTs.isStreamsToReplicatePresent()) {\n+                if (lastAckedTs == currentTxStreamProcessedTs.getTimestamp()) {\n+                    log.trace(\"\");", "originalCommit": "6fc8a9b862126fbcd42ac20069f3c6d211d1cd40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "285e07a3489c1d96ec23661cdd86c7604cb8c2be", "url": "https://github.com/CorfuDB/CorfuDB/commit/285e07a3489c1d96ec23661cdd86c7604cb8c2be", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging", "committedDate": "2020-09-10T06:44:37Z", "type": "forcePushed"}, {"oid": "b6699dc56934b55782b150e9e8a439713324c34f", "url": "https://github.com/CorfuDB/CorfuDB/commit/b6699dc56934b55782b150e9e8a439713324c34f", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging", "committedDate": "2020-09-10T06:50:59Z", "type": "forcePushed"}, {"oid": "9ee82197f9fb07373d4acf3df9e892e2526a8a32", "url": "https://github.com/CorfuDB/CorfuDB/commit/9ee82197f9fb07373d4acf3df9e892e2526a8a32", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging", "committedDate": "2020-09-10T07:02:32Z", "type": "forcePushed"}, {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430", "url": "https://github.com/CorfuDB/CorfuDB/commit/4146661ef07957fd59411b53a46e6fe323b4d430", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging", "committedDate": "2020-09-10T08:04:00Z", "type": "commit"}, {"oid": "4146661ef07957fd59411b53a46e6fe323b4d430", "url": "https://github.com/CorfuDB/CorfuDB/commit/4146661ef07957fd59411b53a46e6fe323b4d430", "message": "Calculate Remaining Replicated Entries based on TxStream\n\n- Calculate replicated remaining entries based on the txStream\n  to avoid the issue of holes enforced on regular streams by the checkpointer.\n- Minor bug fix, restarted Snapshot Sync same baseSnapshot (not reject)\n- Add some valuable logging for debugging", "committedDate": "2020-09-10T08:04:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYwMDA4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486600080", "bodyText": "shouldnt this be '... entries between txStreamTail and currentTxStreamProcessed'?", "author": "pankti-m", "createdAt": "2020-09-10T20:00:23Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/LogReplicationAckReader.java", "diffHunk": "@@ -111,43 +114,199 @@ private long getMaxReplicatedStreamsTail() {\n      * been done.\n      */\n     private long calculateRemainingEntriesToSend(long ackedTimestamp) {\n-        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail();\n+        // Get all streams tails, which will be used in the computation of remaining entries\n+        Map<UUID, Long> tailMap = runtime.getAddressSpaceView().getAllTails().getStreamTails();\n+\n+        long txStreamTail = getTxStreamTail(tailMap);\n+        long maxReplicatedStreamTail = getMaxReplicatedStreamsTail(tailMap);\n+        StreamIteratorMetadata currentTxStreamProcessedTs = logEntryReader.getCurrentProcessedEntryMetadata();\n \n-        // No data to send on the Active, so no replication remaining\n+        log.trace(\"calculateRemainingEntriesToSend:: maxTailReplicateStreams={}, txStreamTail={}, lastTxStreamProcessedTs={}, \" +\n+                        \"lastTxStreamProcessedStreamsPresent={}, sync={}\",\n+                maxReplicatedStreamTail, txStreamTail, currentTxStreamProcessedTs.getTimestamp(),\n+                currentTxStreamProcessedTs.isStreamsToReplicatePresent(), lastSyncType);\n+\n+        // No data to send on the active, so no replication remaining\n         if (maxReplicatedStreamTail == Address.NON_ADDRESS) {\n+            log.debug(\"No data to replicate, replication complete.\");\n             return NO_REPLICATION_REMAINING_ENTRIES;\n         }\n \n-        // If doing a snapshot sync and nothing has been acked, all replication is remaining.  So set ack=0\n-        if (ackedTimestamp == Address.NON_ADDRESS &&\n-                lastSyncType == LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT) {\n-            ackedTimestamp = 0;\n+        if (lastSyncType.equals(LogReplicationMetadata.ReplicationStatusVal.SyncType.SNAPSHOT)) {\n+\n+            // If during snapshot sync nothing has been ack'ed, all replication is remaining\n+            if (ackedTimestamp == Address.NON_ADDRESS) {\n+                ackedTimestamp = 0;\n+            }\n+\n+            // In Snapshot Sync\n+            // Simply subtract the ack'ed timestamp from the global log tail from the time the snapshot sync started.\n+            // Note that this is not accurate because the global log tail does not accurately represent the remaining entries\n+            // for replicated streams.\n+            // When snapshot sync is ongoing, there may be delta updates also. Add those new entries by querying the address maps\n+            return ((baseSnapshotTimestamp - ackedTimestamp) +\n+                    getTxStreamTotalEntries(baseSnapshotTimestamp, txStreamTail));\n+        }\n+\n+        // In Log Entry Sync\n+        return calculateRemainingEntriesIncrementalUpdates(ackedTimestamp, txStreamTail, currentTxStreamProcessedTs);\n+    }\n+\n+    private long getTxStreamTail(Map<UUID, Long> tailMap) {\n+        if (tailMap.containsKey(TRANSACTION_STREAM_ID)) {\n+            return tailMap.get(TRANSACTION_STREAM_ID);\n+        }\n+\n+        log.warn(\"Tx Stream tail not present in sequencer, id={}\", TRANSACTION_STREAM_ID);\n+        return Address.NON_ADDRESS;\n+    }\n+\n+    /**\n+     * For the given replication runtime, query max stream tail for all streams to be replicated.\n+     *\n+     * @return max tail of all streams to be replicated for the given runtime\n+     */\n+    private long getMaxReplicatedStreamsTail(Map<UUID, Long> tailMap) {\n+        long maxTail = Address.NON_ADDRESS;\n+        for (String streamName : config.getStreamsToReplicate()) {\n+            UUID streamUuid = CorfuRuntime.getStreamID(streamName);\n+            if (tailMap.containsKey(streamUuid)) {\n+                long streamTail = tailMap.get(streamUuid);\n+                maxTail = Math.max(maxTail, streamTail);\n+            }\n+        }\n+        return maxTail;\n+    }\n+\n+    /**\n+     * The calculation of remaining entries during log entry sync takes into account:\n+     * - lastAckedTimestamp: last timestamp of entry for which we've received an ACK\n+     * - txStreamTail: transaction stream tail\n+     * - currentTxStreamProcessedTs: metadata of current entry being processed by the StreamsLogEntryReader,\n+     *           it contains the timestamp and a boolean indicating if that entry has data to replicate or not,\n+     *           this will give an indication whether if an ACK is expected or not.\n+     *\n+     * Consider the following representation of the data log, where entries 20, 50, 60, 70 belong to the\n+     * tx stream.\n+     *\n+\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     |   |   |   |   |   |   |   |   |   |   |   |   |\n+     +---+---+---+---+---+---+---+---+---+---+---+---+\n+     20          50          60       70         100\n+     tx          tx          tx       tx        (log tail / not part of tx stream)\n+\n+\n+     * Case 1.0: Log Entry Sync lagging behind (in processing) current processing not acked with entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, true (contains replicated streams)\n+     *\n+     *          remainingEntries = entriesBetween(50, 70] = 2\n+\n+     * Case 1.1: Log Entry Sync lagging behind (in processing) current processing no entries to replicate\n+     *          - lastAckedTimestamp = 50\n+     *          - txStreamTail = 70\n+     *          - currentTxStreamProcessedTs = 60, false (does not contain streams to replicate)\n+     *\n+     * (despite the current processed not requiring ACk, there might be entries between lastAcked and currentProcessed", "originalCommit": "4146661ef07957fd59411b53a46e6fe323b4d430", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjYxMDc0Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2767#discussion_r486610742", "bodyText": "why do we need to set the state here?", "author": "pankti-m", "createdAt": "2020-09-10T20:21:41Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/InLogEntrySyncState.java", "diffHunk": "@@ -134,6 +135,9 @@ public void onEntry(LogReplicationState from) {\n             // address and send incremental updates from this point onwards.\n             if (from.getType() == LogReplicationStateType.WAIT_SNAPSHOT_APPLY\n                     || from.getType() == LogReplicationStateType.INITIALIZED) {\n+                // Set LogEntryAckReader to Log Entry Sync state, to compute remaining entries based\n+                // on the tx stream, regardless of ACKs or updates being processed for the tx stream\n+                fsm.getAckReader().setSyncType(LogReplicationMetadata.ReplicationStatusVal.SyncType.LOG_ENTRY);", "originalCommit": "4146661ef07957fd59411b53a46e6fe323b4d430", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}