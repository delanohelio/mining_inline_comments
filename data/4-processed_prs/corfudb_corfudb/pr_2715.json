{"pr_number": 2715, "pr_title": "Sequencer Reconfiguration Corruption Fixes", "pr_createdAt": "2020-08-14T02:33:05Z", "pr_url": "https://github.com/CorfuDB/CorfuDB/pull/2715", "timeline": [{"oid": "b5d853d4f702b395f9d5c475d15abb7d0810be22", "url": "https://github.com/CorfuDB/CorfuDB/commit/b5d853d4f702b395f9d5c475d15abb7d0810be22", "message": "Sequencer Reconfiguration Corruption Fixes\n\nPrior to this patch, the global tail, stream tails and stream bit\nsets were retrieved and computed from the first node in the last\nsegment. This assumption is incorrect because it can be a node\nthat is being rebuilt (via state transfer), or in some edge cases\nit is not possible to compute the sequencer state from a single node.\nThis leads to the possibility of computing a view of the log that\nis incomplete during reconfiguration of the sequencer. In\nconsequence, leading to inconsistent reads, data loss and\ncluster instability.\n\nThis patch introduces multiple fixes to compute the sequencer's\nstate from all the segments (possibly aggregating views from different\nnodes) and forcing the view computation and the reconfiguration to\nhappen on the same epoch.", "committedDate": "2020-08-14T02:36:26Z", "type": "forcePushed"}, {"oid": "3a21c269f66aeb93a3e21450e4aae99483490794", "url": "https://github.com/CorfuDB/CorfuDB/commit/3a21c269f66aeb93a3e21450e4aae99483490794", "message": "fix tail query epoch", "committedDate": "2020-08-14T07:00:50Z", "type": "forcePushed"}, {"oid": "49b5c6050b2943ce1ac5cfd24c78bfc0319e5fbe", "url": "https://github.com/CorfuDB/CorfuDB/commit/49b5c6050b2943ce1ac5cfd24c78bfc0319e5fbe", "message": "fix tail query epoch", "committedDate": "2020-08-14T07:17:22Z", "type": "forcePushed"}, {"oid": "7e377a88863233e38efc20a7fb5cbf2f1446279a", "url": "https://github.com/CorfuDB/CorfuDB/commit/7e377a88863233e38efc20a7fb5cbf2f1446279a", "message": "fix tail query epoch", "committedDate": "2020-08-14T07:24:47Z", "type": "forcePushed"}, {"oid": "4d113d9a9f9b8205ab3d17be51464a4432968710", "url": "https://github.com/CorfuDB/CorfuDB/commit/4d113d9a9f9b8205ab3d17be51464a4432968710", "message": "fix tail query epoch", "committedDate": "2020-08-14T21:57:48Z", "type": "forcePushed"}, {"oid": "be0c1a1271fa3fbd23aea6771b03b0545e18b710", "url": "https://github.com/CorfuDB/CorfuDB/commit/be0c1a1271fa3fbd23aea6771b03b0545e18b710", "message": "Added StreamAddressSpace Unit Tesst", "committedDate": "2020-08-14T22:20:23Z", "type": "forcePushed"}, {"oid": "5338e61051943a191bf15644f437fa5a9145ca8a", "url": "https://github.com/CorfuDB/CorfuDB/commit/5338e61051943a191bf15644f437fa5a9145ca8a", "message": "more unit tests", "committedDate": "2020-08-15T00:28:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNDMzMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470914332", "bodyText": "This can be moved to the first line.", "author": "WenbinZhu", "createdAt": "2020-08-15T00:29:43Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -205,99 +229,78 @@ public static void updateCommittedTail(RuntimeLayout runtimeLayout,\n     }\n \n     /**\n-     * Get global log tail.\n+     * Find the chain's head node of each segment\n+     * @param layout layout to search in\n+     * @return returns a set of nodes the represent the first node in all segments\n+     */\n+    private static Set<String> getChainHeadFromAllSegments(Layout layout) {\n+        List<Layout.LayoutSegment> segments = layout.getSegments();\n+        validateSegments(layout.getSegments());", "originalCommit": "5338e61051943a191bf15644f437fa5a9145ca8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMjU0MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470922540", "bodyText": "Done.", "author": "Maithem", "createdAt": "2020-08-15T01:41:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNDMzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNTI1Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470915252", "bodyText": "AtomicLong is cleaner than array.", "author": "WenbinZhu", "createdAt": "2020-08-15T00:36:26Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -205,99 +229,78 @@ public static void updateCommittedTail(RuntimeLayout runtimeLayout,\n     }\n \n     /**\n-     * Get global log tail.\n+     * Find the chain's head node of each segment\n+     * @param layout layout to search in\n+     * @return returns a set of nodes the represent the first node in all segments\n+     */\n+    private static Set<String> getChainHeadFromAllSegments(Layout layout) {\n+        List<Layout.LayoutSegment> segments = layout.getSegments();\n+        validateSegments(layout.getSegments());\n+        return segments.stream()\n+                .map(Layout.LayoutSegment::getFirstStripe)\n+                .map(Layout.LayoutStripe::getLogServers)\n+                .map(strip -> strip.get(0))\n+                .collect(Collectors.toSet());\n+    }\n+\n+    /**\n+     * Compute the max tail across the first node of each segment in the layout\n+     * on the same epoch.\n      *\n      * @param runtimeLayout current RuntimeLayout\n      * @return Log global tail\n      */\n     public static long getLogTail(RuntimeLayout runtimeLayout) {\n-        long globalLogTail = Address.NON_EXIST;\n-\n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                TailsResponse response = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getLogTail());\n-                globalLogTail = Long.max(globalLogTail, response.getLogTail());\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n+        long globalLogTail = segmentsHeadNodes.stream()\n+                .map(node -> runtimeLayout\n+                        .getLogUnitClient(node)\n+                        .getLogTail())\n+                .map(CFUtils::getUninterruptibly)\n+                .mapToLong(TailsResponse::getLogTail)\n+                .max().orElseThrow(NoSuchElementException::new);\n \n+        log.debug(\"getLogTail: nodes selected {} global tail {}\",\n+                segmentsHeadNodes,globalLogTail);\n         return globalLogTail;\n     }\n \n     /**\n      * Fetches the max global log tail and all stream tails from the log unit cluster. This depends on the mode of\n      * replication being used.\n-     * CHAIN: Block on fetch of global log tail from the head log unit in every stripe.\n-     * QUORUM: Block on fetch of global log tail from a majority in every stripe.\n-     *\n+     * CHAIN: Block on fetch of global log tail from the head log unit in every segment.*\n      * @param runtimeLayout current RuntimeLayout\n-     * @return The max global log tail obtained from the log unit servers.\n+     * @return The max global log tail and max global tails across all segments\n      */\n     public static TailsResponse getAllTails(RuntimeLayout runtimeLayout) {\n-        Set<TailsResponse> luResponses = new HashSet<>();\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n \n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the tail of the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                TailsResponse res = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getAllTails());\n-                luResponses.add(res);\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n+        long[] globalTail = {Address.NON_EXIST};", "originalCommit": "5338e61051943a191bf15644f437fa5a9145ca8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMjgwNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470922806", "bodyText": "Done.", "author": "Maithem", "createdAt": "2020-08-15T01:44:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNTI1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNTI3NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470915275", "bodyText": "AtomicLong is cleaner than array.", "author": "WenbinZhu", "createdAt": "2020-08-15T00:36:33Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -307,34 +310,27 @@ static TailsResponse aggregateLogUnitTails(Set<TailsResponse> responses) {\n      * @return response with all streams addresses and global log tail.\n      */\n     public static StreamsAddressResponse getLogAddressSpace(RuntimeLayout runtimeLayout) {\n-        Set<StreamsAddressResponse> luResponses = new HashSet<>();\n-\n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                StreamsAddressResponse res = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getLogAddressSpace());\n-                luResponses.add(res);\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n-\n-        return aggregateLogAddressSpace(luResponses);\n-    }\n-\n-    static StreamsAddressResponse aggregateLogAddressSpace(Set<StreamsAddressResponse> responses) {\n-        Map<UUID, StreamAddressSpace> streamAddressSpace = new HashMap<>();\n-        long logTail = Address.NON_ADDRESS;\n-\n-        for (StreamsAddressResponse res : responses) {\n-            logTail = Math.max(logTail, res.getLogTail());\n-            streamAddressSpace = aggregateStreamAddressMap(res.getAddressMap(), streamAddressSpace);\n-        }\n-        return new StreamsAddressResponse(logTail, streamAddressSpace);\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n+        long[] globalTail = {Address.NON_EXIST};", "originalCommit": "5338e61051943a191bf15644f437fa5a9145ca8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzY0OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470923649", "bodyText": "Done.", "author": "Maithem", "createdAt": "2020-08-15T01:53:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNTI3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzQzNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470917437", "bodyText": "Because of java stream's lazy evaluation property, if CFUtils.get is put in map(), then the futures are actually executed sequentially. We need to parallelize it to get better performance, by gathering all the futures first and then wait on them, similar to this: https://github.com/CorfuDB/CorfuDB/blob/master/runtime/src/main/java/org/corfudb/util/Utils.java#L152-L162", "author": "WenbinZhu", "createdAt": "2020-08-15T00:54:45Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -205,99 +229,78 @@ public static void updateCommittedTail(RuntimeLayout runtimeLayout,\n     }\n \n     /**\n-     * Get global log tail.\n+     * Find the chain's head node of each segment\n+     * @param layout layout to search in\n+     * @return returns a set of nodes the represent the first node in all segments\n+     */\n+    private static Set<String> getChainHeadFromAllSegments(Layout layout) {\n+        List<Layout.LayoutSegment> segments = layout.getSegments();\n+        validateSegments(layout.getSegments());\n+        return segments.stream()\n+                .map(Layout.LayoutSegment::getFirstStripe)\n+                .map(Layout.LayoutStripe::getLogServers)\n+                .map(strip -> strip.get(0))\n+                .collect(Collectors.toSet());\n+    }\n+\n+    /**\n+     * Compute the max tail across the first node of each segment in the layout\n+     * on the same epoch.\n      *\n      * @param runtimeLayout current RuntimeLayout\n      * @return Log global tail\n      */\n     public static long getLogTail(RuntimeLayout runtimeLayout) {\n-        long globalLogTail = Address.NON_EXIST;\n-\n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                TailsResponse response = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getLogTail());\n-                globalLogTail = Long.max(globalLogTail, response.getLogTail());\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n+        long globalLogTail = segmentsHeadNodes.stream()\n+                .map(node -> runtimeLayout\n+                        .getLogUnitClient(node)\n+                        .getLogTail())\n+                .map(CFUtils::getUninterruptibly)\n+                .mapToLong(TailsResponse::getLogTail)\n+                .max().orElseThrow(NoSuchElementException::new);\n \n+        log.debug(\"getLogTail: nodes selected {} global tail {}\",\n+                segmentsHeadNodes,globalLogTail);\n         return globalLogTail;\n     }\n \n     /**\n      * Fetches the max global log tail and all stream tails from the log unit cluster. This depends on the mode of\n      * replication being used.\n-     * CHAIN: Block on fetch of global log tail from the head log unit in every stripe.\n-     * QUORUM: Block on fetch of global log tail from a majority in every stripe.\n-     *\n+     * CHAIN: Block on fetch of global log tail from the head log unit in every segment.*\n      * @param runtimeLayout current RuntimeLayout\n-     * @return The max global log tail obtained from the log unit servers.\n+     * @return The max global log tail and max global tails across all segments\n      */\n     public static TailsResponse getAllTails(RuntimeLayout runtimeLayout) {\n-        Set<TailsResponse> luResponses = new HashSet<>();\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n \n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the tail of the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                TailsResponse res = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getAllTails());\n-                luResponses.add(res);\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n+        long[] globalTail = {Address.NON_EXIST};\n+        final Map<UUID, Long> streamTails = new HashMap<>();\n \n-        return aggregateLogUnitTails(luResponses);\n-    }\n-\n-    /**\n-     * Given a set of request tails, we aggregate them and maintain\n-     * the greatest address per stream and the greatest tail over\n-     * all responses.\n-     * @param responses a set of tail responses\n-     * @return An max-aggregation of all tails\n-     */\n-    static TailsResponse aggregateLogUnitTails(Set<TailsResponse> responses) {\n-        long globalTail = Address.NON_ADDRESS;\n-        Map<UUID, Long> globalStreamTails = new HashMap<>();\n-\n-        for (TailsResponse res : responses) {\n-            globalTail = Math.max(globalTail, res.getLogTail());\n-\n-            for (Map.Entry<UUID, Long> stream : res.getStreamTails().entrySet()) {\n-                long streamTail = globalStreamTails.getOrDefault(stream.getKey(), Address.NON_ADDRESS);\n-                globalStreamTails.put(stream.getKey(), Math.max(streamTail, stream.getValue()));\n-            }\n-        }\n-        // All epochs should be equal as all the tails are queried using a single runtime layout.\n-        return new TailsResponse(globalTail, globalStreamTails);\n+        segmentsHeadNodes.stream()\n+                .map(node -> runtimeLayout\n+                        .getLogUnitClient(node)\n+                        .getAllTails())\n+                .map(CFUtils::getUninterruptibly)\n+                .forEach(resp -> {\n+                    // All responses should be computed on the same epoch\n+                    checkArgument(resp.getEpoch() == runtimeLayout.getLayout().getEpoch());\n+                    // Find the global max global tail and stream tails across all responses\n+                    globalTail[0] = Long.max(resp.getLogTail(), globalTail[0]);\n+                    resp.getStreamTails().forEach((k, v) -> streamTails.merge(k, v, Long::max));\n+                });", "originalCommit": "5338e61051943a191bf15644f437fa5a9145ca8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMjg1Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470922857", "bodyText": "Yea, I thought about it, but didnt think it was worth it.\nWill change it anyways.", "author": "Maithem", "createdAt": "2020-08-15T01:44:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzQzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzc5NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470917794", "bodyText": "Same here.", "author": "WenbinZhu", "createdAt": "2020-08-15T00:57:48Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -307,34 +310,27 @@ static TailsResponse aggregateLogUnitTails(Set<TailsResponse> responses) {\n      * @return response with all streams addresses and global log tail.\n      */\n     public static StreamsAddressResponse getLogAddressSpace(RuntimeLayout runtimeLayout) {\n-        Set<StreamsAddressResponse> luResponses = new HashSet<>();\n-\n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                StreamsAddressResponse res = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getLogAddressSpace());\n-                luResponses.add(res);\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n-\n-        return aggregateLogAddressSpace(luResponses);\n-    }\n-\n-    static StreamsAddressResponse aggregateLogAddressSpace(Set<StreamsAddressResponse> responses) {\n-        Map<UUID, StreamAddressSpace> streamAddressSpace = new HashMap<>();\n-        long logTail = Address.NON_ADDRESS;\n-\n-        for (StreamsAddressResponse res : responses) {\n-            logTail = Math.max(logTail, res.getLogTail());\n-            streamAddressSpace = aggregateStreamAddressMap(res.getAddressMap(), streamAddressSpace);\n-        }\n-        return new StreamsAddressResponse(logTail, streamAddressSpace);\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n+        long[] globalTail = {Address.NON_EXIST};\n+        final Map<UUID, StreamAddressSpace> streamsAddressSpace = new HashMap<>();\n+        segmentsHeadNodes.stream()\n+                .map(node -> runtimeLayout\n+                        .getLogUnitClient(node)\n+                        .getLogAddressSpace())\n+                .map(CFUtils::getUninterruptibly)\n+                .forEach(resp -> {", "originalCommit": "5338e61051943a191bf15644f437fa5a9145ca8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzM5NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470923395", "bodyText": "Done.", "author": "Maithem", "createdAt": "2020-08-15T01:50:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxNzc5NA=="}], "type": "inlineReview"}, {"oid": "26238bfd82ddd6f128a9b55bc64a2aa7565999c1", "url": "https://github.com/CorfuDB/CorfuDB/commit/26238bfd82ddd6f128a9b55bc64a2aa7565999c1", "message": "more unit tests", "committedDate": "2020-08-15T01:03:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxMzk4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470913980", "bodyText": "*returns a", "author": "PavelZaytsev", "createdAt": "2020-08-15T00:27:06Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/stream/StreamAddressSpace.java", "diffHunk": "@@ -41,10 +41,36 @@ public StreamAddressSpace(long trimMark, Roaring64NavigableMap addressMap) {\n         this.addressMap = addressMap;\n     }\n \n+    public StreamAddressSpace() {\n+        this.addressMap = Roaring64NavigableMap.bitmapOf();\n+        this.trimMark = Address.NON_ADDRESS;\n+    }\n+\n     public Roaring64NavigableMap getAddressMap() {\n         return addressMap;\n     }\n \n+    /**\n+     * Merges b into a and returns b as the final result.", "originalCommit": "1ff11ef0b2aa2d4d7ef8f9536b89726124accc7f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzYzOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470923639", "bodyText": "Done.", "author": "Maithem", "createdAt": "2020-08-15T01:52:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxMzk4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxOTAwNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470919007", "bodyText": "Why did we comment this check out?", "author": "PavelZaytsev", "createdAt": "2020-08-15T01:08:12Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -307,34 +313,27 @@ static TailsResponse aggregateLogUnitTails(Set<TailsResponse> responses) {\n      * @return response with all streams addresses and global log tail.\n      */\n     public static StreamsAddressResponse getLogAddressSpace(RuntimeLayout runtimeLayout) {\n-        Set<StreamsAddressResponse> luResponses = new HashSet<>();\n-\n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                StreamsAddressResponse res = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getLogAddressSpace());\n-                luResponses.add(res);\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n-\n-        return aggregateLogAddressSpace(luResponses);\n-    }\n-\n-    static StreamsAddressResponse aggregateLogAddressSpace(Set<StreamsAddressResponse> responses) {\n-        Map<UUID, StreamAddressSpace> streamAddressSpace = new HashMap<>();\n-        long logTail = Address.NON_ADDRESS;\n-\n-        for (StreamsAddressResponse res : responses) {\n-            logTail = Math.max(logTail, res.getLogTail());\n-            streamAddressSpace = aggregateStreamAddressMap(res.getAddressMap(), streamAddressSpace);\n-        }\n-        return new StreamsAddressResponse(logTail, streamAddressSpace);\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n+        long[] globalTail = {Address.NON_EXIST};\n+        final Map<UUID, StreamAddressSpace> streamsAddressSpace = new HashMap<>();\n+        segmentsHeadNodes.stream()\n+                .map(node -> runtimeLayout\n+                        .getLogUnitClient(node)\n+                        .getLogAddressSpace())\n+                .map(CFUtils::getUninterruptibly)\n+                .forEach(resp -> {\n+                    // All responses should be computed on the same epoch\n+                    //checkArgument(resp.getEpoch() == runtimeLayout.getLayout().getEpoch());", "originalCommit": "26238bfd82ddd6f128a9b55bc64a2aa7565999c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyMzQ3MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470923471", "bodyText": "That response doesn't actually has an epoch field. I fixed the API, un-commented and added tests.", "author": "Maithem", "createdAt": "2020-08-15T01:51:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkxOTAwNw=="}], "type": "inlineReview"}, {"oid": "2645860890a538f7c45c6082600f184c7d9293d8", "url": "https://github.com/CorfuDB/CorfuDB/commit/2645860890a538f7c45c6082600f184c7d9293d8", "message": "more unit tests", "committedDate": "2020-08-15T01:08:59Z", "type": "forcePushed"}, {"oid": "2a3e17c4d7f5486342c04902b746806621d35230", "url": "https://github.com/CorfuDB/CorfuDB/commit/2a3e17c4d7f5486342c04902b746806621d35230", "message": "more unit tests", "committedDate": "2020-08-15T01:26:10Z", "type": "forcePushed"}, {"oid": "c1beca7da7d7966b0b9c055b93a2e37337298199", "url": "https://github.com/CorfuDB/CorfuDB/commit/c1beca7da7d7966b0b9c055b93a2e37337298199", "message": "addressed comments", "committedDate": "2020-08-15T01:51:35Z", "type": "forcePushed"}, {"oid": "3ab3138e0c61e764c107b7e354a731715c7dd6a5", "url": "https://github.com/CorfuDB/CorfuDB/commit/3ab3138e0c61e764c107b7e354a731715c7dd6a5", "message": "addressed comments", "committedDate": "2020-08-15T01:53:23Z", "type": "forcePushed"}, {"oid": "75cd7e7f9e5a18858cc4c4649a6497eb477f4e4f", "url": "https://github.com/CorfuDB/CorfuDB/commit/75cd7e7f9e5a18858cc4c4649a6497eb477f4e4f", "message": "Sequencer Reconfiguration Corruption Fixes\n\nPrior to this patch, the global tail, stream tails and stream bit\nsets were retrieved and computed from the first node in the last\nsegment. This assumption is incorrect because it can be a node\nthat is being rebuilt (via state transfer), or in some edge cases\nit is not possible to compute the sequencer state from a single node.\nThis leads to the possibility of computing a view of the log that\nis incomplete during reconfiguration of the sequencer. In\nconsequence, leading to inconsistent reads, data loss and\ncluster instability.\n\nThis patch introduces multiple fixes to compute the sequencer's\nstate from all the segments (possibly aggregating views from different\nnodes) and forcing the view computation and the reconfiguration to\nhappen on the same epoch.", "committedDate": "2020-08-15T01:58:41Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyNDM5NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470924394", "bodyText": "This will throw IllegalArgumentException, but should be throw WrongEpochException to be more clear?", "author": "WenbinZhu", "createdAt": "2020-08-15T02:01:34Z", "path": "runtime/src/main/java/org/corfudb/util/Utils.java", "diffHunk": "@@ -307,34 +319,29 @@ static TailsResponse aggregateLogUnitTails(Set<TailsResponse> responses) {\n      * @return response with all streams addresses and global log tail.\n      */\n     public static StreamsAddressResponse getLogAddressSpace(RuntimeLayout runtimeLayout) {\n-        Set<StreamsAddressResponse> luResponses = new HashSet<>();\n-\n-        Layout.LayoutSegment segment = runtimeLayout.getLayout().getLatestSegment();\n-\n-        // Query the head log unit in every stripe.\n-        if (segment.getReplicationMode() == Layout.ReplicationMode.CHAIN_REPLICATION) {\n-            for (Layout.LayoutStripe stripe : segment.getStripes()) {\n-\n-                StreamsAddressResponse res = CFUtils.getUninterruptibly(runtimeLayout\n-                                .getLogUnitClient(stripe.getLogServers().get(DEFAULT_LOGUNIT))\n-                                .getLogAddressSpace());\n-                luResponses.add(res);\n-            }\n-        } else if (segment.getReplicationMode() == Layout.ReplicationMode.QUORUM_REPLICATION) {\n-            throw new UnsupportedOperationException();\n-        }\n-\n-        return aggregateLogAddressSpace(luResponses);\n-    }\n-\n-    static StreamsAddressResponse aggregateLogAddressSpace(Set<StreamsAddressResponse> responses) {\n-        Map<UUID, StreamAddressSpace> streamAddressSpace = new HashMap<>();\n-        long logTail = Address.NON_ADDRESS;\n+        // Since a node can exist as a head for multiple segments we need to a set to\n+        // coalesce the candidates to unique nodes only\n+        Set<String> segmentsHeadNodes = getChainHeadFromAllSegments(runtimeLayout.getLayout());\n+        AtomicLong globalTail = new AtomicLong(Address.NON_EXIST);\n+        final Map<UUID, StreamAddressSpace> streamsAddressSpace = new HashMap<>();\n+        List<CompletableFuture<StreamsAddressResponse>> cfs = segmentsHeadNodes.stream()\n+                .map(node -> runtimeLayout\n+                        .getLogUnitClient(node)\n+                        .getLogAddressSpace())\n+                .collect(Collectors.toList());\n \n-        for (StreamsAddressResponse res : responses) {\n-            logTail = Math.max(logTail, res.getLogTail());\n-            streamAddressSpace = aggregateStreamAddressMap(res.getAddressMap(), streamAddressSpace);\n-        }\n-        return new StreamsAddressResponse(logTail, streamAddressSpace);\n+        cfs.stream().map(CFUtils::getUninterruptibly)\n+                .forEach(resp -> {\n+                    // All responses should be computed on the same epoch\n+                    checkArgument(resp.getEpoch() == runtimeLayout.getLayout().getEpoch());", "originalCommit": "75cd7e7f9e5a18858cc4c4649a6497eb477f4e4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyNjk1Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2715#discussion_r470926957", "bodyText": "good catch.", "author": "Maithem", "createdAt": "2020-08-15T02:31:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkyNDM5NA=="}], "type": "inlineReview"}, {"oid": "0a26b937b58a948d3f55720f276fac260d6b1617", "url": "https://github.com/CorfuDB/CorfuDB/commit/0a26b937b58a948d3f55720f276fac260d6b1617", "message": "Sequencer Reconfiguration Corruption Fixes\n\nPrior to this patch, the global tail, stream tails and stream bit\nsets were retrieved and computed from the first node in the last\nsegment. This assumption is incorrect because it can be a node\nthat is being rebuilt (via state transfer), or in some edge cases\nit is not possible to compute the sequencer state from a single node.\nThis leads to the possibility of computing a view of the log that\nis incomplete during reconfiguration of the sequencer. In\nconsequence, leading to inconsistent reads, data loss and\ncluster instability.\n\nThis patch introduces multiple fixes to compute the sequencer's\nstate from all the segments (possibly aggregating views from different\nnodes) and forcing the view computation and the reconfiguration to\nhappen on the same epoch.", "committedDate": "2020-08-15T03:59:14Z", "type": "forcePushed"}, {"oid": "ec0f37479fac449abba32d92a14ab94e34798cff", "url": "https://github.com/CorfuDB/CorfuDB/commit/ec0f37479fac449abba32d92a14ab94e34798cff", "message": "Sequencer Reconfiguration Corruption Fixes\n\nPrior to this patch, the global tail, stream tails and stream bit\nsets were retrieved and computed from the first node in the last\nsegment. This assumption is incorrect because it can be a node\nthat is being rebuilt (via state transfer), or in some edge cases\nit is not possible to compute the sequencer state from a single node.\nThis leads to the possibility of computing a view of the log that\nis incomplete during reconfiguration of the sequencer. In\nconsequence, leading to inconsistent reads, data loss and\ncluster instability.\n\nThis patch introduces multiple fixes to compute the sequencer's\nstate from all the segments (possibly aggregating views from different\nnodes) and forcing the view computation and the reconfiguration to\nhappen on the same epoch.", "committedDate": "2020-08-15T06:12:33Z", "type": "forcePushed"}, {"oid": "2f2ba44ec63101d5eebae62bcf7dbeca22a1f6e9", "url": "https://github.com/CorfuDB/CorfuDB/commit/2f2ba44ec63101d5eebae62bcf7dbeca22a1f6e9", "message": "Sequencer Reconfiguration Corruption Fixes\n\nPrior to this patch, the global tail, stream tails and stream bit\nsets were retrieved and computed from the first node in the last\nsegment. This assumption is incorrect because it can be a node\nthat is being rebuilt (via state transfer), or in some edge cases\nit is not possible to compute the sequencer state from a single node.\nThis leads to the possibility of computing a view of the log that\nis incomplete during reconfiguration of the sequencer. In\nconsequence, leading to inconsistent reads, data loss and\ncluster instability.\n\nThis patch introduces multiple fixes to compute the sequencer's\nstate from all the segments (possibly aggregating views from different\nnodes) and forcing the view computation and the reconfiguration to\nhappen on the same epoch.", "committedDate": "2020-08-15T06:30:36Z", "type": "commit"}, {"oid": "2f2ba44ec63101d5eebae62bcf7dbeca22a1f6e9", "url": "https://github.com/CorfuDB/CorfuDB/commit/2f2ba44ec63101d5eebae62bcf7dbeca22a1f6e9", "message": "Sequencer Reconfiguration Corruption Fixes\n\nPrior to this patch, the global tail, stream tails and stream bit\nsets were retrieved and computed from the first node in the last\nsegment. This assumption is incorrect because it can be a node\nthat is being rebuilt (via state transfer), or in some edge cases\nit is not possible to compute the sequencer state from a single node.\nThis leads to the possibility of computing a view of the log that\nis incomplete during reconfiguration of the sequencer. In\nconsequence, leading to inconsistent reads, data loss and\ncluster instability.\n\nThis patch introduces multiple fixes to compute the sequencer's\nstate from all the segments (possibly aggregating views from different\nnodes) and forcing the view computation and the reconfiguration to\nhappen on the same epoch.", "committedDate": "2020-08-15T06:30:36Z", "type": "forcePushed"}]}