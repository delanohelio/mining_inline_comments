{"pr_number": 10401, "pr_title": "vectorized expressions and expression virtual columns", "pr_createdAt": "2020-09-16T12:37:57Z", "pr_url": "https://github.com/apache/druid/pull/10401", "timeline": [{"oid": "88f898fbf4276878b341b063fa525225c589b6bb", "url": "https://github.com/apache/druid/commit/88f898fbf4276878b341b063fa525225c589b6bb", "message": "vectorized expression virtual columns", "committedDate": "2020-09-16T12:36:33Z", "type": "commit"}, {"oid": "44f9a6cdbdd02e9492431fa69d761a1108216760", "url": "https://github.com/apache/druid/commit/44f9a6cdbdd02e9492431fa69d761a1108216760", "message": "cleanup", "committedDate": "2020-09-16T19:32:47Z", "type": "commit"}, {"oid": "00f764fc92c1a101006e29cf43b8ca730b9428d0", "url": "https://github.com/apache/druid/commit/00f764fc92c1a101006e29cf43b8ca730b9428d0", "message": "fixes", "committedDate": "2020-09-16T21:44:18Z", "type": "commit"}, {"oid": "8dfb16035b8ffa223991d939338e5ce596b849b7", "url": "https://github.com/apache/druid/commit/8dfb16035b8ffa223991d939338e5ce596b849b7", "message": "preserve float if explicitly specified", "committedDate": "2020-09-16T22:51:27Z", "type": "commit"}, {"oid": "cc0c851aad7effb5f29ae6bdc385053dab6a39ef", "url": "https://github.com/apache/druid/commit/cc0c851aad7effb5f29ae6bdc385053dab6a39ef", "message": "oops", "committedDate": "2020-09-16T23:40:50Z", "type": "commit"}, {"oid": "ec5937d904170d3850642d84a4a9111b42c3219b", "url": "https://github.com/apache/druid/commit/ec5937d904170d3850642d84a4a9111b42c3219b", "message": "null handling fixes, more tests", "committedDate": "2020-09-17T03:33:48Z", "type": "commit"}, {"oid": "c56095c87e26ebdfc49bc2132d3908c9dcf349c2", "url": "https://github.com/apache/druid/commit/c56095c87e26ebdfc49bc2132d3908c9dcf349c2", "message": "what is an expression planner?", "committedDate": "2020-09-17T16:52:36Z", "type": "commit"}, {"oid": "e89ad7d345e6d9dde232cba8bdf3e31eaf13ab56", "url": "https://github.com/apache/druid/commit/e89ad7d345e6d9dde232cba8bdf3e31eaf13ab56", "message": "better names", "committedDate": "2020-09-17T18:33:00Z", "type": "commit"}, {"oid": "482192457ec02e86ef4806f0f8b5d6118d473bbf", "url": "https://github.com/apache/druid/commit/482192457ec02e86ef4806f0f8b5d6118d473bbf", "message": "remove unused method, add pi", "committedDate": "2020-09-18T10:39:57Z", "type": "commit"}, {"oid": "9698124c0b4bdb621b0fe23f08426c5122910afe", "url": "https://github.com/apache/druid/commit/9698124c0b4bdb621b0fe23f08426c5122910afe", "message": "move vector processor builders into static methods", "committedDate": "2020-09-18T22:14:31Z", "type": "commit"}, {"oid": "9a42ef1662663b060030079a9b945375f5b7d51f", "url": "https://github.com/apache/druid/commit/9a42ef1662663b060030079a9b945375f5b7d51f", "message": "reduce boilerplate", "committedDate": "2020-09-19T00:26:04Z", "type": "commit"}, {"oid": "2b097b601d586016f396ef8919a03e1cfddff240", "url": "https://github.com/apache/druid/commit/2b097b601d586016f396ef8919a03e1cfddff240", "message": "oops", "committedDate": "2020-09-19T00:27:09Z", "type": "commit"}, {"oid": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "url": "https://github.com/apache/druid/commit/e8d240a71c339f44b96beca5a749e8e237bb2f2d", "message": "more naming adjustments", "committedDate": "2020-09-19T02:29:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxNzQ1OA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491717458", "bodyText": "Can be simplified to areNumeric(Arrays.asList(args)).", "author": "jihoonson", "createdAt": "2020-09-20T18:09:02Z", "path": "core/src/main/java/org/apache/druid/math/expr/Expr.java", "diffHunk": "@@ -148,6 +170,60 @@ default ExprType getOutputType(InputBindingTypes inputTypes)\n   {\n     @Nullable\n     ExprType getType(String name);\n+\n+    default boolean areNumeric(List<Expr> args)\n+    {\n+      boolean numeric = args.size() > 0;\n+      for (Expr arg : args) {\n+        ExprType argType = arg.getOutputType(this);\n+        if (argType == null) {\n+          numeric = false;\n+          break;\n+        }\n+        numeric &= argType.isNumeric();\n+      }\n+      return numeric;\n+    }\n+\n+    default boolean areNumeric(Expr... args)\n+    {\n+      boolean numeric = args.length > 0;\n+      for (Expr arg : args) {\n+        ExprType argType = arg.getOutputType(this);\n+        if (argType == null) {\n+          numeric = false;\n+          break;\n+        }\n+        numeric &= argType.isNumeric();\n+      }\n+      return numeric;", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzE0OQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457149", "bodyText": "done", "author": "clintropolis", "createdAt": "2020-09-22T03:34:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxNzQ1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxNzg3NA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491717874", "bodyText": "Same here. Can be canVectorize(Arrays.asList(args)).", "author": "jihoonson", "createdAt": "2020-09-20T18:13:25Z", "path": "core/src/main/java/org/apache/druid/math/expr/Expr.java", "diffHunk": "@@ -148,6 +170,60 @@ default ExprType getOutputType(InputBindingTypes inputTypes)\n   {\n     @Nullable\n     ExprType getType(String name);\n+\n+    default boolean areNumeric(List<Expr> args)\n+    {\n+      boolean numeric = args.size() > 0;\n+      for (Expr arg : args) {\n+        ExprType argType = arg.getOutputType(this);\n+        if (argType == null) {\n+          numeric = false;\n+          break;\n+        }\n+        numeric &= argType.isNumeric();\n+      }\n+      return numeric;\n+    }\n+\n+    default boolean areNumeric(Expr... args)\n+    {\n+      boolean numeric = args.length > 0;\n+      for (Expr arg : args) {\n+        ExprType argType = arg.getOutputType(this);\n+        if (argType == null) {\n+          numeric = false;\n+          break;\n+        }\n+        numeric &= argType.isNumeric();\n+      }\n+      return numeric;\n+    }\n+\n+    default boolean canVectorize(List<Expr> args)\n+    {\n+      boolean canVectorize = true;\n+      for (Expr arg : args) {\n+        canVectorize &= arg.canVectorize(this);\n+      }\n+      return canVectorize;\n+    }\n+\n+    default boolean canVectorize(Expr... args)\n+    {\n+      boolean canVectorize = true;", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzE3Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457172", "bodyText": "done", "author": "clintropolis", "createdAt": "2020-09-22T03:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxNzg3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxOTM0MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491719340", "bodyText": "Hmm, what is the reason for splitting VectorInputBindingTypes and VectorInputBinding? The latter extends the former and there is only one implementation of the latter in this PR. Can VectorInputBinding extend InputBindingTypes and VectorSizeInspector instead? VectorSizeInspector needs to be moved in that case though as it is currently in processing.", "author": "jihoonson", "createdAt": "2020-09-20T18:26:55Z", "path": "core/src/main/java/org/apache/druid/math/expr/Expr.java", "diffHunk": "@@ -148,6 +170,60 @@ default ExprType getOutputType(InputBindingTypes inputTypes)\n   {\n     @Nullable\n     ExprType getType(String name);\n+\n+    default boolean areNumeric(List<Expr> args)\n+    {\n+      boolean numeric = args.size() > 0;\n+      for (Expr arg : args) {\n+        ExprType argType = arg.getOutputType(this);\n+        if (argType == null) {\n+          numeric = false;\n+          break;\n+        }\n+        numeric &= argType.isNumeric();\n+      }\n+      return numeric;\n+    }\n+\n+    default boolean areNumeric(Expr... args)\n+    {\n+      boolean numeric = args.length > 0;\n+      for (Expr arg : args) {\n+        ExprType argType = arg.getOutputType(this);\n+        if (argType == null) {\n+          numeric = false;\n+          break;\n+        }\n+        numeric &= argType.isNumeric();\n+      }\n+      return numeric;\n+    }\n+\n+    default boolean canVectorize(List<Expr> args)\n+    {\n+      boolean canVectorize = true;\n+      for (Expr arg : args) {\n+        canVectorize &= arg.canVectorize(this);\n+      }\n+      return canVectorize;\n+    }\n+\n+    default boolean canVectorize(Expr... args)\n+    {\n+      boolean canVectorize = true;\n+      for (Expr arg : args) {\n+        canVectorize &= arg.canVectorize(this);\n+      }\n+      return canVectorize;\n+    }\n+  }\n+\n+  /**\n+   * {@link InputBindingTypes} + vectorizations stuff for {@link #buildVectorized}\n+   */\n+  interface VectorInputBindingTypes extends InputBindingTypes", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzQzNA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457434", "bodyText": "I think VectorInputBindingTypes and VectorInputBinding could be consolidated. They exist in split form from an earlier prototype before I had expression output type inference using InputBindingTypes existed.\nConceptually it sort of makes sense to me to have them split because you don't really need a full binding backed by selectors in order to build a vectorized expression processor, just the input types and the max vector size. But, there isn't currently a need for this, so I will consider/look into consolidating these interfaces.\nIt probably does make sense to consider moving VectorSizeInspector as well, but I would rather not move into core from processing in this PR.", "author": "clintropolis", "createdAt": "2020-09-22T03:36:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcxOTM0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcyMDYyMQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491720621", "bodyText": "nit: maybe Numbers is a better home.", "author": "jihoonson", "createdAt": "2020-09-20T18:40:09Z", "path": "core/src/main/java/org/apache/druid/math/expr/ExprEval.java", "diffHunk": "@@ -121,6 +121,23 @@ public static ExprEval bestEffortOf(@Nullable Object val)\n     return new StringExprEval(val == null ? null : String.valueOf(val));\n   }\n \n+  @Nullable\n+  public static Number computeNumber(@Nullable String value)", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzU1NA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457554", "bodyText": "Maybe, but I think I would rather save this until a follow-up PR when we look into consolidating these redundant methods re: the other comment", "author": "clintropolis", "createdAt": "2020-09-22T03:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcyMDYyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcyMDg1Mw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491720853", "bodyText": "Heh, we have a couple of similar methods such as Numbers.parseLongObject(), GuavaUtils.tryParseLong(), etc. We should perhaps clean up them by merging similar methods later.", "author": "jihoonson", "createdAt": "2020-09-20T18:42:15Z", "path": "core/src/main/java/org/apache/druid/math/expr/ExprEval.java", "diffHunk": "@@ -121,6 +121,23 @@ public static ExprEval bestEffortOf(@Nullable Object val)\n     return new StringExprEval(val == null ? null : String.valueOf(val));\n   }\n \n+  @Nullable\n+  public static Number computeNumber(@Nullable String value)\n+  {\n+    if (value == null) {\n+      return null;\n+    }\n+    Number rv;\n+    Long v = GuavaUtils.tryParseLong(value);", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzUxNg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457516", "bodyText": "I agree that we should look into consolidating these methods, not in this PR though.", "author": "clintropolis", "createdAt": "2020-09-22T03:36:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTcyMDg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0MTI4OA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491741288", "bodyText": "This code seems duplicate in binary operators, but I guess it would be nice to keep both canVectorize() and buildVectorized() together in the same class.", "author": "jihoonson", "createdAt": "2020-09-20T22:20:09Z", "path": "core/src/main/java/org/apache/druid/math/expr/BinaryLogicalOperatorExpr.java", "diffHunk": "@@ -68,6 +70,17 @@ public ExprType getOutputType(InputBindingTypes inputTypes)\n     }\n     return implicitCast;\n   }\n+  @Override\n+  public boolean canVectorize(InputBindingTypes inputTypes)\n+  {\n+    return inputTypes.areNumeric(left, right) && inputTypes.canVectorize(left, right);", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzU5NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457595", "bodyText": "Yeah, I was going to clean this up once all operators are implemented.", "author": "clintropolis", "createdAt": "2020-09-22T03:37:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0MTI4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0MjA4OA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491742088", "bodyText": "Is this something that should be resolved in this PR?", "author": "jihoonson", "createdAt": "2020-09-20T22:28:29Z", "path": "core/src/main/java/org/apache/druid/math/expr/Function.java", "diffHunk": "@@ -517,6 +532,24 @@ public ExprEval apply(List<Expr> args, Expr.ObjectBinding bindings)\n \n       return ExprEval.of(retVal);\n     }\n+\n+    @Override\n+    public boolean canVectorize(Expr.InputBindingTypes inputTypes, List<Expr> args)\n+    {\n+      return (args.size() == 1 || (args.get(1).isLiteral() && args.get(1).getLiteralValue() instanceof Number)) &&\n+             inputTypes.canVectorize(args);\n+    }\n+\n+    @Override\n+    public <T> ExprVectorProcessor<T> asVectorProcessor(Expr.VectorInputBindingTypes inputTypes, List<Expr> args)\n+    {\n+      if (args.size() == 1 || args.get(1).isLiteral()) {\n+        final int radix = args.size() == 1 ? 10 : ((Number) args.get(1).getLiteralValue()).intValue();\n+        return VectorProcessors.parseLong(inputTypes, args.get(0), radix);\n+      }\n+      // not yet implemented, how did we get here", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzYxNw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457617", "bodyText": "I don't think it needs to be resolved in this PR. This comment just refers to that the variable input radix (second argument is not a constant) case is not implemented, but canVectorize will return false, so this line should not be reached.", "author": "clintropolis", "createdAt": "2020-09-22T03:37:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0MjA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA0NDEyOQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493044129", "bodyText": "Could you add these details in the comment?", "author": "jihoonson", "createdAt": "2020-09-22T21:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0MjA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0NjA5NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491746095", "bodyText": "Maybe better to explicitly mention that this class is not for string vectors?", "author": "jihoonson", "createdAt": "2020-09-20T23:10:54Z", "path": "core/src/main/java/org/apache/druid/math/expr/vector/UnivariateFunctionVectorProcessor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.math.expr.vector;\n+\n+import org.apache.druid.math.expr.Expr;\n+\n+/**\n+ * common machinery for processing single input operators and functions, which should always treat null input as null\n+ * output, and are backed by a primitive value instead of an object value (and need to use the null vector instead of\n+ * checking the vector itself for nulls)", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzYzMw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457633", "bodyText": "Eh, is it necessary since strings vectors are object vectors? (and so are the array types, which I think will be handled by similar processors)", "author": "clintropolis", "createdAt": "2020-09-22T03:37:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0NjA5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc0ODExOQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491748119", "bodyText": "Nice tests.", "author": "jihoonson", "createdAt": "2020-09-20T23:31:38Z", "path": "core/src/test/java/org/apache/druid/math/expr/VectorExprSanityTest.java", "diffHunk": "@@ -0,0 +1,459 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.math.expr;\n+\n+import com.google.common.collect.ImmutableMap;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.java.util.common.NonnullPair;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.math.expr.vector.ExprEvalVector;\n+import org.apache.druid.testing.InitializedNullHandlingTest;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import javax.annotation.Nullable;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.function.BooleanSupplier;\n+import java.util.function.DoubleSupplier;\n+import java.util.function.LongSupplier;\n+import java.util.function.Supplier;\n+\n+/**\n+ * randomize inputs to various vector expressions and make sure the results match nonvectorized expressions\n+ *\n+ * this is not a replacement for correctness tests, but will ensure that vectorized and non-vectorized expression\n+ * evaluation is at least self consistent...\n+ */\n+public class VectorExprSanityTest extends InitializedNullHandlingTest", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1NzE1MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491757150", "bodyText": "Should this logic match to its non-vectorized version?", "author": "jihoonson", "createdAt": "2020-09-21T00:57:12Z", "path": "core/src/main/java/org/apache/druid/math/expr/vector/VectorProcessors.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.math.expr.vector;\n+\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.math.expr.ExprType;\n+\n+import javax.annotation.Nullable;\n+import java.util.Arrays;\n+\n+public class VectorProcessors\n+{\n+  public static <T> ExprVectorProcessor<T> constantString(@Nullable String constant, int maxVectorSize)\n+  {\n+    final String[] strings = new String[maxVectorSize];\n+    Arrays.fill(strings, constant);\n+    final ExprEvalStringVector eval = new ExprEvalStringVector(strings);\n+    return new ExprVectorProcessor<T>()\n+    {\n+      @Override\n+      public ExprEvalVector<T> evalVector(Expr.VectorInputBinding bindings)\n+      {\n+        return (ExprEvalVector<T>) eval;\n+      }\n+\n+      @Override\n+      public ExprType getOutputType()\n+      {\n+        return ExprType.STRING;\n+      }\n+    };\n+  }\n+\n+  public static <T> ExprVectorProcessor<T> constantDouble(@Nullable Double constant, int maxVectorSize)\n+  {\n+    final double[] doubles = new double[maxVectorSize];\n+    final boolean[] nulls;\n+    if (constant == null) {\n+      nulls = new boolean[maxVectorSize];\n+      Arrays.fill(nulls, true);\n+    } else {\n+      nulls = null;\n+      Arrays.fill(doubles, constant);\n+    }\n+    final ExprEvalDoubleVector eval = new ExprEvalDoubleVector(doubles, nulls);\n+    return new ExprVectorProcessor<T>()\n+    {\n+      @Override\n+      public ExprEvalVector<T> evalVector(Expr.VectorInputBinding bindings)\n+      {\n+        return (ExprEvalVector<T>) eval;\n+      }\n+\n+      @Override\n+      public ExprType getOutputType()\n+      {\n+        return ExprType.DOUBLE;\n+      }\n+    };\n+  }\n+\n+  public static <T> ExprVectorProcessor<T> constantLong(@Nullable Long constant, int maxVectorSize)\n+  {\n+    final long[] longs = new long[maxVectorSize];\n+    final boolean[] nulls;\n+    if (constant == null) {\n+      nulls = new boolean[maxVectorSize];\n+      Arrays.fill(nulls, true);\n+    } else {\n+      nulls = null;\n+      Arrays.fill(longs, constant);\n+    }\n+    final ExprEvalLongVector eval = new ExprEvalLongVector(longs, nulls);\n+    return new ExprVectorProcessor<T>()\n+    {\n+      @Override\n+      public ExprEvalVector<T> evalVector(Expr.VectorInputBinding bindings)\n+      {\n+        return (ExprEvalVector<T>) eval;\n+      }\n+\n+      @Override\n+      public ExprType getOutputType()\n+      {\n+        return ExprType.LONG;\n+      }\n+    };\n+  }\n+\n+  public static <T> ExprVectorProcessor<T> parseLong(Expr.VectorInputBindingTypes inputTypes, Expr arg, int radix)\n+  {\n+    final ExprVectorProcessor<?> processor = new LongOutStringInFunctionVectorProcessor(\n+        CastToTypeVectorProcessor.castToType(arg.buildVectorized(inputTypes), ExprType.STRING),\n+        inputTypes.getMaxVectorSize()\n+    )\n+    {\n+      @Override\n+      public void processIndex(String[] strings, long[] longs, boolean[] outputNulls, int i)\n+      {\n+        try {\n+          longs[i] = Long.parseLong(strings[i], radix);\n+          outputNulls[i] = false;", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzY4MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457680", "bodyText": "Oops yes, I stuck the constant 2 argument version in last minute and forgot about this \ud83d\udc4d", "author": "clintropolis", "createdAt": "2020-09-22T03:37:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc1NzE1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc4MzYxNQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491783615", "bodyText": "Please annotate these with @Nullable.", "author": "jihoonson", "createdAt": "2020-09-21T03:56:26Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/AggregatorUtil.java", "diffHunk": "@@ -225,6 +229,22 @@ public boolean isNull()\n     }\n   }\n \n+  public static VectorValueSelector makeVectorValueSelector(\n+      VectorColumnSelectorFactory columnSelectorFactory,\n+      String fieldName,\n+      String expression,", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzcyOQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457729", "bodyText": "added", "author": "clintropolis", "createdAt": "2020-09-22T03:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc4MzYxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc4Njk4Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491786982", "bodyText": "Hmm, is this correct? Should this be capabilities.hasMultipleValues().isMaybeTrue() instead?", "author": "jihoonson", "createdAt": "2020-09-21T04:18:12Z", "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionPlanner.java", "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.virtual;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.math.expr.ExprType;\n+import org.apache.druid.math.expr.Parser;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+\n+import java.util.EnumSet;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class ExpressionPlanner\n+{\n+  private ExpressionPlanner()\n+  {\n+    // No instantiation.\n+  }\n+\n+  /**\n+   * Druid tries to be chill to expressions to make up for not having a well defined table schema across segments. This\n+   * method performs some analysis to determine what sort of selectors can be constructed on top of an expression,\n+   * whether or not the expression will need implicitly mapped across multi-valued inputs, if the expression produces\n+   * multi-valued outputs, is vectorizable, and everything else interesting when making a selector.\n+   *\n+   * Results are stored in a {@link ExpressionPlan}, which can be examined to do whatever is necessary to make things\n+   * function properly.\n+   */\n+  public static ExpressionPlan plan(ColumnInspector inspector, Expr expression)\n+  {\n+    final Expr.BindingAnalysis analysis = expression.analyzeInputs();\n+    Parser.validateExpr(expression, analysis);\n+\n+    EnumSet<ExpressionPlan.Trait> traits = EnumSet.noneOf(ExpressionPlan.Trait.class);\n+    Set<String> maybeMultiValued = new HashSet<>();\n+    List<String> needsApplied = ImmutableList.of();\n+    ValueType singleInputType = null;\n+    ExprType outputType = null;\n+\n+    final Set<String> columns = analysis.getRequiredBindings();\n+\n+    // check and set traits which allow optimized selectors to be created\n+    if (columns.isEmpty()) {\n+      traits.add(ExpressionPlan.Trait.CONSTANT);\n+    } else if (columns.size() == 1) {\n+      final String column = Iterables.getOnlyElement(columns);\n+      final ColumnCapabilities capabilities = inspector.getColumnCapabilities(column);\n+\n+      // These flags allow for selectors that wrap a single underlying column to be optimized, through caching results\n+      // and via allowing deferred execution in the case of building dimension selectors.\n+      //    SINGLE_INPUT_SCALAR\n+      // is set if an input is single valued, and the output is definitely single valued, with an additional requirement\n+      // for strings that the column is dictionary encoded.\n+      //    SINGLE_INPUT_MAPPABLE\n+      // is set when a single input string column, which can be multi-valued, but if so, it must be implicitly mappable\n+      // (i.e. the expression is not treating its input as an array and not wanting to output an array)\n+      if (capabilities != null) {\n+        boolean isSingleInputMappable = false;\n+        boolean isSingleInputScalar = capabilities.hasMultipleValues().isFalse() &&\n+                                      !analysis.hasInputArrays() &&\n+                                      !analysis.isOutputArray();\n+        if (capabilities.getType() == ValueType.STRING) {\n+          isSingleInputScalar &= capabilities.isDictionaryEncoded().isTrue();\n+          isSingleInputMappable = capabilities.isDictionaryEncoded().isTrue() &&\n+                                  !capabilities.hasMultipleValues().isUnknown() &&", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1Nzg2OQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457869", "bodyText": "No, this is what it was doing in the previous check, looking for either explicitly true or false, which are both ok, but I can't quite remember why unknown isn't ok...\nBut, this does match the previous logic in ExpressionSelectors.makeDimensionSelector for checking single column string inputs to determine if it can use SingleStringInputDimensionSelector, so I would rather not change it as part of this PR", "author": "clintropolis", "createdAt": "2020-09-22T03:38:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc4Njk4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTc4OTM5MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491789390", "bodyText": "Maybe good to mention that float is default for a historical reason?", "author": "jihoonson", "createdAt": "2020-09-21T04:33:14Z", "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVectorValueSelector.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.virtual;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.math.expr.vector.ExprVectorProcessor;\n+import org.apache.druid.segment.vector.VectorValueSelector;\n+\n+import javax.annotation.Nullable;\n+\n+public class ExpressionVectorValueSelector implements VectorValueSelector\n+{\n+  final Expr.VectorInputBinding bindings;\n+  final ExprVectorProcessor<?> processor;\n+  final float[] floats;", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI4MjE2Nw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492282167", "bodyText": "Did you intend to check if rowCount and RowCountCursor match?", "author": "jihoonson", "createdAt": "2020-09-21T19:03:48Z", "path": "benchmarks/src/test/java/org/apache/druid/benchmark/ExpressionVectorSelectorBenchmark.java", "diffHunk": "@@ -0,0 +1,301 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.benchmark;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.io.Closer;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.math.expr.ExprMacroTable;\n+import org.apache.druid.math.expr.ExprType;\n+import org.apache.druid.math.expr.Parser;\n+import org.apache.druid.query.expression.TestExprMacroTable;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.generator.GeneratorBasicSchemas;\n+import org.apache.druid.segment.generator.GeneratorSchemaInfo;\n+import org.apache.druid.segment.generator.SegmentGenerator;\n+import org.apache.druid.segment.vector.VectorCursor;\n+import org.apache.druid.segment.vector.VectorObjectSelector;\n+import org.apache.druid.segment.vector.VectorValueSelector;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+import org.apache.druid.timeline.DataSegment;\n+import org.apache.druid.timeline.partition.LinearShardSpec;\n+import org.junit.Assert;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+\n+@State(Scope.Benchmark)\n+@Fork(value = 1)\n+@Warmup(iterations = 3)\n+@Measurement(iterations = 5)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+public class ExpressionVectorSelectorBenchmark\n+{\n+  static {\n+    NullHandling.initializeForTests();\n+  }\n+\n+  @Param({\"1000000\"})\n+  private int rowsPerSegment;\n+\n+  @Param({\"false\", \"true\"})\n+  private boolean vectorize;\n+\n+  @Param({\n+      \"long1 * long2\",\n+      \"double1 * double3\",\n+      \"float1 + float3\",\n+      \"(long1 - long4) / double3\",\n+      \"max(double3, double5)\",\n+      \"min(double4, double1)\",\n+      \"cos(float3)\",\n+      \"sin(long4)\",\n+      \"parse_long(string1)\",\n+      \"parse_long(string1) * double3\",\n+      \"parse_long(string5) * parse_long(string1)\",\n+      \"parse_long(string5) * parse_long(string1) * double3\"\n+  })\n+  private String expression;\n+\n+  private QueryableIndex index;\n+  private Closer closer;\n+\n+  @Nullable\n+  private ExprType outputType;\n+\n+  @Setup(Level.Trial)\n+  public void setup()\n+  {\n+    this.closer = Closer.create();\n+\n+    final GeneratorSchemaInfo schemaInfo = GeneratorBasicSchemas.SCHEMA_MAP.get(\"expression-testbench\");\n+\n+    final DataSegment dataSegment = DataSegment.builder()\n+                                               .dataSource(\"foo\")\n+                                               .interval(schemaInfo.getDataInterval())\n+                                               .version(\"1\")\n+                                               .shardSpec(new LinearShardSpec(0))\n+                                               .size(0)\n+                                               .build();\n+\n+    final SegmentGenerator segmentGenerator = closer.register(new SegmentGenerator());\n+    this.index = closer.register(\n+        segmentGenerator.generate(dataSegment, schemaInfo, Granularities.HOUR, rowsPerSegment)\n+    );\n+\n+    Expr parsed = Parser.parse(expression, ExprMacroTable.nil());\n+    outputType = parsed.getOutputType(\n+        new ColumnInspector()\n+        {\n+          @Nullable\n+          @Override\n+          public ColumnCapabilities getColumnCapabilities(String column)\n+          {\n+            return QueryableIndexStorageAdapter.getColumnCapabilities(index, column);\n+          }\n+        }\n+    );\n+    checkSanity();\n+  }\n+\n+  @TearDown(Level.Trial)\n+  public void tearDown() throws Exception\n+  {\n+    closer.close();\n+  }\n+\n+  @Benchmark\n+  @BenchmarkMode(Mode.AverageTime)\n+  @OutputTimeUnit(TimeUnit.MILLISECONDS)\n+  public void scan(Blackhole blackhole)\n+  {\n+    final VirtualColumns virtualColumns = VirtualColumns.create(\n+        ImmutableList.of(\n+            new ExpressionVirtualColumn(\n+                \"v\",\n+                expression,\n+                ExprType.toValueType(outputType),\n+                TestExprMacroTable.INSTANCE\n+            )\n+        )\n+    );\n+    if (vectorize) {\n+      VectorCursor cursor = new QueryableIndexStorageAdapter(index).makeVectorCursor(\n+          null,\n+          index.getDataInterval(),\n+          virtualColumns,\n+          false,\n+          512,\n+          null\n+      );\n+      if (outputType.isNumeric()) {\n+        VectorValueSelector selector = cursor.getColumnSelectorFactory().makeValueSelector(\"v\");\n+        if (outputType.equals(ExprType.DOUBLE)) {\n+          while (!cursor.isDone()) {\n+            blackhole.consume(selector.getDoubleVector());\n+            blackhole.consume(selector.getNullVector());\n+            cursor.advance();\n+          }\n+        } else {\n+          while (!cursor.isDone()) {\n+            blackhole.consume(selector.getLongVector());\n+            blackhole.consume(selector.getNullVector());\n+            cursor.advance();\n+          }\n+        }\n+        closer.register(cursor);\n+      }\n+    } else {\n+      Sequence<Cursor> cursors = new QueryableIndexStorageAdapter(index).makeCursors(\n+          null,\n+          index.getDataInterval(),\n+          virtualColumns,\n+          Granularities.ALL,\n+          false,\n+          null\n+      );\n+\n+      int rowCount = cursors\n+          .map(cursor -> {\n+            final ColumnValueSelector selector = cursor.getColumnSelectorFactory().makeColumnValueSelector(\"v\");\n+            int rows = 0;\n+            while (!cursor.isDone()) {\n+              blackhole.consume(selector.getObject());\n+              rows++;\n+              cursor.advance();\n+            }\n+            return rows;\n+          }).accumulate(0, (acc, in) -> acc + in);\n+\n+      blackhole.consume(rowCount);\n+    }\n+  }\n+\n+  private void checkSanity()\n+  {\n+    final List<Object> results = new ArrayList<>(rowsPerSegment);\n+    final VirtualColumns virtualColumns = VirtualColumns.create(\n+        ImmutableList.of(\n+            new ExpressionVirtualColumn(\n+                \"v\",\n+                expression,\n+                ExprType.toValueType(outputType),\n+                TestExprMacroTable.INSTANCE\n+            )\n+        )\n+    );\n+    VectorCursor cursor = new QueryableIndexStorageAdapter(index).makeVectorCursor(\n+        null,\n+        index.getDataInterval(),\n+        virtualColumns,\n+        false,\n+        512,\n+        null\n+    );\n+\n+    VectorValueSelector selector = null;\n+    VectorObjectSelector objectSelector = null;\n+    if (outputType.isNumeric()) {\n+      selector = cursor.getColumnSelectorFactory().makeValueSelector(\"v\");\n+    } else {\n+      objectSelector = cursor.getColumnSelectorFactory().makeObjectSelector(\"v\");\n+    }\n+    int rowCount = 0;\n+    while (!cursor.isDone()) {\n+      boolean[] nulls;\n+      switch (outputType) {\n+        case LONG:\n+          nulls = selector.getNullVector();\n+          long[] longs = selector.getLongVector();\n+          for (int i = 0; i < selector.getCurrentVectorSize(); i++, rowCount++) {\n+            results.add(nulls != null && nulls[i] ? null : longs[i]);\n+          }\n+          break;\n+        case DOUBLE:\n+          nulls = selector.getNullVector();\n+          double[] doubles = selector.getDoubleVector();\n+          for (int i = 0; i < selector.getCurrentVectorSize(); i++, rowCount++) {\n+            results.add(nulls != null && nulls[i] ? null : doubles[i]);\n+          }\n+          break;\n+        case STRING:\n+          Object[] objects = objectSelector.getObjectVector();\n+          for (int i = 0; i < objectSelector.getCurrentVectorSize(); i++, rowCount++) {\n+            results.add(objects[i]);\n+          }\n+          break;\n+      }\n+\n+      cursor.advance();\n+    }\n+    closer.register(cursor);\n+\n+    Sequence<Cursor> cursors = new QueryableIndexStorageAdapter(index).makeCursors(\n+        null,\n+        index.getDataInterval(),\n+        virtualColumns,\n+        Granularities.ALL,\n+        false,\n+        null\n+    );\n+\n+    int rowCountCursor = cursors\n+        .map(nonVectorized -> {\n+          final ColumnValueSelector nonSelector = nonVectorized.getColumnSelectorFactory().makeColumnValueSelector(\"v\");\n+          int rows = 0;\n+          while (!nonVectorized.isDone()) {\n+            Assert.assertEquals(StringUtils.format(\"Failed at row %s\", rows), nonSelector.getObject(), results.get(rows));\n+            rows++;\n+            nonVectorized.advance();\n+          }\n+          return rows;\n+        }).accumulate(0, (acc, in) -> acc + in);\n+\n+    Assert.assertTrue(rowCountCursor > 0);", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1Nzg5OQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457899", "bodyText": "oops yes, added, but moved this entire check into a newly added ExpressionVectorSelectorsTest.", "author": "clintropolis", "createdAt": "2020-09-22T03:38:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI4MjE2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI4MzM3OA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492283378", "bodyText": "Looking at what this method does, it seems pretty useful. What do you think about making this test a unit test, so that CI can run? Or, if we already have enough unit tests which cover the same logic, I guess we don't need this to make the benchmark faster.", "author": "jihoonson", "createdAt": "2020-09-21T19:06:07Z", "path": "benchmarks/src/test/java/org/apache/druid/benchmark/ExpressionVectorSelectorBenchmark.java", "diffHunk": "@@ -0,0 +1,301 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.benchmark;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.io.Closer;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.math.expr.ExprMacroTable;\n+import org.apache.druid.math.expr.ExprType;\n+import org.apache.druid.math.expr.Parser;\n+import org.apache.druid.query.expression.TestExprMacroTable;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.generator.GeneratorBasicSchemas;\n+import org.apache.druid.segment.generator.GeneratorSchemaInfo;\n+import org.apache.druid.segment.generator.SegmentGenerator;\n+import org.apache.druid.segment.vector.VectorCursor;\n+import org.apache.druid.segment.vector.VectorObjectSelector;\n+import org.apache.druid.segment.vector.VectorValueSelector;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+import org.apache.druid.timeline.DataSegment;\n+import org.apache.druid.timeline.partition.LinearShardSpec;\n+import org.junit.Assert;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+\n+@State(Scope.Benchmark)\n+@Fork(value = 1)\n+@Warmup(iterations = 3)\n+@Measurement(iterations = 5)\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+public class ExpressionVectorSelectorBenchmark\n+{\n+  static {\n+    NullHandling.initializeForTests();\n+  }\n+\n+  @Param({\"1000000\"})\n+  private int rowsPerSegment;\n+\n+  @Param({\"false\", \"true\"})\n+  private boolean vectorize;\n+\n+  @Param({\n+      \"long1 * long2\",\n+      \"double1 * double3\",\n+      \"float1 + float3\",\n+      \"(long1 - long4) / double3\",\n+      \"max(double3, double5)\",\n+      \"min(double4, double1)\",\n+      \"cos(float3)\",\n+      \"sin(long4)\",\n+      \"parse_long(string1)\",\n+      \"parse_long(string1) * double3\",\n+      \"parse_long(string5) * parse_long(string1)\",\n+      \"parse_long(string5) * parse_long(string1) * double3\"\n+  })\n+  private String expression;\n+\n+  private QueryableIndex index;\n+  private Closer closer;\n+\n+  @Nullable\n+  private ExprType outputType;\n+\n+  @Setup(Level.Trial)\n+  public void setup()\n+  {\n+    this.closer = Closer.create();\n+\n+    final GeneratorSchemaInfo schemaInfo = GeneratorBasicSchemas.SCHEMA_MAP.get(\"expression-testbench\");\n+\n+    final DataSegment dataSegment = DataSegment.builder()\n+                                               .dataSource(\"foo\")\n+                                               .interval(schemaInfo.getDataInterval())\n+                                               .version(\"1\")\n+                                               .shardSpec(new LinearShardSpec(0))\n+                                               .size(0)\n+                                               .build();\n+\n+    final SegmentGenerator segmentGenerator = closer.register(new SegmentGenerator());\n+    this.index = closer.register(\n+        segmentGenerator.generate(dataSegment, schemaInfo, Granularities.HOUR, rowsPerSegment)\n+    );\n+\n+    Expr parsed = Parser.parse(expression, ExprMacroTable.nil());\n+    outputType = parsed.getOutputType(\n+        new ColumnInspector()\n+        {\n+          @Nullable\n+          @Override\n+          public ColumnCapabilities getColumnCapabilities(String column)\n+          {\n+            return QueryableIndexStorageAdapter.getColumnCapabilities(index, column);\n+          }\n+        }\n+    );\n+    checkSanity();\n+  }\n+\n+  @TearDown(Level.Trial)\n+  public void tearDown() throws Exception\n+  {\n+    closer.close();\n+  }\n+\n+  @Benchmark\n+  @BenchmarkMode(Mode.AverageTime)\n+  @OutputTimeUnit(TimeUnit.MILLISECONDS)\n+  public void scan(Blackhole blackhole)\n+  {\n+    final VirtualColumns virtualColumns = VirtualColumns.create(\n+        ImmutableList.of(\n+            new ExpressionVirtualColumn(\n+                \"v\",\n+                expression,\n+                ExprType.toValueType(outputType),\n+                TestExprMacroTable.INSTANCE\n+            )\n+        )\n+    );\n+    if (vectorize) {\n+      VectorCursor cursor = new QueryableIndexStorageAdapter(index).makeVectorCursor(\n+          null,\n+          index.getDataInterval(),\n+          virtualColumns,\n+          false,\n+          512,\n+          null\n+      );\n+      if (outputType.isNumeric()) {\n+        VectorValueSelector selector = cursor.getColumnSelectorFactory().makeValueSelector(\"v\");\n+        if (outputType.equals(ExprType.DOUBLE)) {\n+          while (!cursor.isDone()) {\n+            blackhole.consume(selector.getDoubleVector());\n+            blackhole.consume(selector.getNullVector());\n+            cursor.advance();\n+          }\n+        } else {\n+          while (!cursor.isDone()) {\n+            blackhole.consume(selector.getLongVector());\n+            blackhole.consume(selector.getNullVector());\n+            cursor.advance();\n+          }\n+        }\n+        closer.register(cursor);\n+      }\n+    } else {\n+      Sequence<Cursor> cursors = new QueryableIndexStorageAdapter(index).makeCursors(\n+          null,\n+          index.getDataInterval(),\n+          virtualColumns,\n+          Granularities.ALL,\n+          false,\n+          null\n+      );\n+\n+      int rowCount = cursors\n+          .map(cursor -> {\n+            final ColumnValueSelector selector = cursor.getColumnSelectorFactory().makeColumnValueSelector(\"v\");\n+            int rows = 0;\n+            while (!cursor.isDone()) {\n+              blackhole.consume(selector.getObject());\n+              rows++;\n+              cursor.advance();\n+            }\n+            return rows;\n+          }).accumulate(0, (acc, in) -> acc + in);\n+\n+      blackhole.consume(rowCount);\n+    }\n+  }\n+\n+  private void checkSanity()", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1NzkxNg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457916", "bodyText": "added new test ExpressionVectorSelectorsTest", "author": "clintropolis", "createdAt": "2020-09-22T03:38:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjI4MzM3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMzODY1MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492338650", "bodyText": "Are warmups and measurements too small?", "author": "jihoonson", "createdAt": "2020-09-21T20:51:28Z", "path": "benchmarks/src/test/java/org/apache/druid/benchmark/ExpressionVectorSelectorBenchmark.java", "diffHunk": "@@ -0,0 +1,301 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.benchmark;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.io.Closer;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.math.expr.ExprMacroTable;\n+import org.apache.druid.math.expr.ExprType;\n+import org.apache.druid.math.expr.Parser;\n+import org.apache.druid.query.expression.TestExprMacroTable;\n+import org.apache.druid.segment.ColumnInspector;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.generator.GeneratorBasicSchemas;\n+import org.apache.druid.segment.generator.GeneratorSchemaInfo;\n+import org.apache.druid.segment.generator.SegmentGenerator;\n+import org.apache.druid.segment.vector.VectorCursor;\n+import org.apache.druid.segment.vector.VectorObjectSelector;\n+import org.apache.druid.segment.vector.VectorValueSelector;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+import org.apache.druid.timeline.DataSegment;\n+import org.apache.druid.timeline.partition.LinearShardSpec;\n+import org.junit.Assert;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+\n+@State(Scope.Benchmark)\n+@Fork(value = 1)\n+@Warmup(iterations = 3)\n+@Measurement(iterations = 5)", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1Nzk1Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457952", "bodyText": "Ah probably for super accurate results if I were making plots, but this was close enough for ballpark measurements while testing changes since the timing usually seemed to settle down after 2 warmup iterations.", "author": "clintropolis", "createdAt": "2020-09-22T03:39:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMzODY1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM0NTc3NA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492345774", "bodyText": "Maybe we should add this testing for the benchmark queries in CalciteQueryTest so that CI can run?", "author": "jihoonson", "createdAt": "2020-09-21T21:05:33Z", "path": "benchmarks/src/test/java/org/apache/druid/benchmark/query/SqlExpressionBenchmark.java", "diffHunk": "@@ -0,0 +1,363 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.benchmark.query;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import org.apache.calcite.schema.SchemaPlus;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.guava.Yielder;\n+import org.apache.druid.java.util.common.guava.Yielders;\n+import org.apache.druid.java.util.common.io.Closer;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.query.DruidProcessingConfig;\n+import org.apache.druid.query.QueryRunnerFactoryConglomerate;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.generator.GeneratorBasicSchemas;\n+import org.apache.druid.segment.generator.GeneratorSchemaInfo;\n+import org.apache.druid.segment.generator.SegmentGenerator;\n+import org.apache.druid.server.QueryStackTests;\n+import org.apache.druid.server.security.AuthTestUtils;\n+import org.apache.druid.server.security.AuthenticationResult;\n+import org.apache.druid.server.security.NoopEscalator;\n+import org.apache.druid.sql.calcite.planner.Calcites;\n+import org.apache.druid.sql.calcite.planner.DruidPlanner;\n+import org.apache.druid.sql.calcite.planner.PlannerConfig;\n+import org.apache.druid.sql.calcite.planner.PlannerFactory;\n+import org.apache.druid.sql.calcite.planner.PlannerResult;\n+import org.apache.druid.sql.calcite.util.CalciteTests;\n+import org.apache.druid.sql.calcite.util.SpecificSegmentsQuerySegmentWalker;\n+import org.apache.druid.timeline.DataSegment;\n+import org.apache.druid.timeline.partition.LinearShardSpec;\n+import org.junit.Assert;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+import javax.annotation.Nullable;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * Benchmark that tests various SQL queries.\n+ */\n+@State(Scope.Benchmark)\n+@Fork(value = 1)\n+@Warmup(iterations = 3)\n+@Measurement(iterations = 5)\n+public class SqlExpressionBenchmark\n+{\n+  private static final Logger log = new Logger(SqlExpressionBenchmark.class);\n+\n+  static {\n+    NullHandling.initializeForTests();\n+    Calcites.setSystemProperties();\n+  }\n+\n+  private static final DruidProcessingConfig PROCESSING_CONFIG = new DruidProcessingConfig()\n+  {\n+    @Override\n+    public int intermediateComputeSizeBytes()\n+    {\n+      return 512 * 1024 * 1024;\n+    }\n+\n+    @Override\n+    public int getNumMergeBuffers()\n+    {\n+      return 3;\n+    }\n+\n+    @Override\n+    public int getNumThreads()\n+    {\n+      return 1;\n+    }\n+\n+    @Override\n+    public boolean useParallelMergePoolConfigured()\n+    {\n+      return true;\n+    }\n+\n+    @Override\n+    public String getFormatString()\n+    {\n+      return \"benchmarks-processing-%s\";\n+    }\n+  };\n+\n+\n+  private static final List<String> QUERIES = ImmutableList.of(\n+      // ===========================\n+      // non-expression reference queries\n+      // ===========================\n+      // 0: non-expression timeseries reference, 1 columns\n+      \"SELECT SUM(long1) FROM foo\",\n+      // 1: non-expression timeseries reference, 2 columns\n+      \"SELECT SUM(long1), SUM(long2) FROM foo\",\n+      // 2: non-expression timeseries reference, 3 columns\n+      \"SELECT SUM(long1), SUM(long4), SUM(double1) FROM foo\",\n+      // 3: non-expression timeseries reference, 4 columns\n+      \"SELECT SUM(long1), SUM(long4), SUM(double1), SUM(float3) FROM foo\",\n+      // 4: non-expression timeseries reference, 5 columns\n+      \"SELECT SUM(long1), SUM(long4), SUM(double1), SUM(float3), SUM(long5) FROM foo\",\n+      // 5: group by non-expr with 1 agg\n+      \"SELECT string2, SUM(long1) FROM foo GROUP BY 1 ORDER BY 2\",\n+      // 6: group by non-expr with 2 agg\n+      \"SELECT string2, SUM(long1), SUM(double3) FROM foo GROUP BY 1 ORDER BY 2\",\n+      // ===========================\n+      // expressions\n+      // ===========================\n+      // 7: math op - 2 longs\n+      \"SELECT SUM(long1 * long2) FROM foo\",\n+      // 8: mixed math - 2 longs, 1 double\n+      \"SELECT SUM((long1 * long2) / double1) FROM foo\",\n+      // 9: mixed math - 2 longs, 1 double, 1 float\n+      \"SELECT SUM(float3 + ((long1 * long4)/double1)) FROM foo\",\n+      // 10: mixed math - 3 longs, 1 double, 1 float\n+      \"SELECT SUM(long5 - (float3 + ((long1 * long4)/double1))) FROM foo\",\n+      // 11: all same math op - 3 longs, 1 double, 1 float\n+      \"SELECT SUM(long5 * float3 * long1 * long4 * double1) FROM foo\",\n+      // 12: cos\n+      \"SELECT cos(double2) FROM foo\",\n+      // 13: unary negate\n+      \"SELECT SUM(-long4) FROM foo\",\n+      // 14: string long\n+      \"SELECT SUM(PARSE_LONG(string1)) FROM foo\",\n+      // 15: string longer\n+      \"SELECT SUM(PARSE_LONG(string3)) FROM foo\",\n+      // 16: time floor, non-expr col + reg agg\n+      \"SELECT TIME_FLOOR(__time, 'PT1H'), string2, SUM(double4) FROM foo GROUP BY 1,2 ORDER BY 3\",\n+      // 17: time floor, non-expr col + expr agg\n+      \"SELECT TIME_FLOOR(__time, 'PT1H'), string2, SUM(long1 * double4) FROM foo GROUP BY 1,2 ORDER BY 3\",\n+      // 18: time floor + non-expr agg (timeseries) (non-expression reference)\n+      \"SELECT TIME_FLOOR(__time, 'PT1H'), SUM(long1) FROM foo GROUP BY 1 ORDER BY 1\",\n+      // 19: time floor + expr agg (timeseries)\n+      \"SELECT TIME_FLOOR(__time, 'PT1H'), SUM(long1 * long4) FROM foo GROUP BY 1 ORDER BY 1\",\n+      // 20: time floor + non-expr agg (group by)\n+      \"SELECT TIME_FLOOR(__time, 'PT1H'), SUM(long1) FROM foo GROUP BY 1 ORDER BY 2\",\n+      // 21: time floor + expr agg (group by)\n+      \"SELECT TIME_FLOOR(__time, 'PT1H'), SUM(long1 * long4) FROM foo GROUP BY 1 ORDER BY 2\",\n+      // 22: time floor offset by 1 day + non-expr agg (group by)\n+      \"SELECT TIME_FLOOR(TIMESTAMPADD(DAY, -1, __time), 'PT1H'), SUM(long1) FROM foo GROUP BY 1 ORDER BY 1\",\n+      // 23: time floor offset by 1 day + expr agg (group by)\n+      \"SELECT TIME_FLOOR(TIMESTAMPADD(DAY, -1, __time), 'PT1H'), SUM(long1 * long4) FROM foo GROUP BY 1 ORDER BY 1\",\n+      // 24: group by long expr with non-expr agg\n+      \"SELECT (long1 * long2), SUM(double1) FROM foo GROUP BY 1 ORDER BY 2\",\n+      // 25: group by non-expr with expr agg\n+      \"SELECT string2, SUM(long1 * long4) FROM foo GROUP BY 1 ORDER BY 2\"\n+  );\n+\n+  @Param({\"5000000\"})\n+  private int rowsPerSegment;\n+\n+  @Param({\"false\", \"force\"})\n+  private String vectorize;\n+\n+  @Param({\n+      // non-expression reference\n+      \"0\",\n+      \"1\",\n+      \"2\",\n+      \"3\",\n+      \"4\",\n+      \"5\",\n+      \"6\",\n+      // expressions\n+      \"7\",\n+      \"8\",\n+      \"9\",\n+      \"10\",\n+      \"11\",\n+      \"12\",\n+      \"13\",\n+      \"14\",\n+      \"15\",\n+      \"16\",\n+      \"17\",\n+      \"18\",\n+      \"19\",\n+      \"20\",\n+      \"21\",\n+      \"22\",\n+      \"23\",\n+      \"24\",\n+      \"25\"\n+  })\n+  private String query;\n+\n+  @Nullable\n+  private PlannerFactory plannerFactory;\n+  private Closer closer = Closer.create();\n+\n+  @Setup(Level.Trial)\n+  public void setup() throws Exception\n+  {\n+    final GeneratorSchemaInfo schemaInfo = GeneratorBasicSchemas.SCHEMA_MAP.get(\"expression-testbench\");\n+\n+    final DataSegment dataSegment = DataSegment.builder()\n+                                               .dataSource(\"foo\")\n+                                               .interval(schemaInfo.getDataInterval())\n+                                               .version(\"1\")\n+                                               .shardSpec(new LinearShardSpec(0))\n+                                               .size(0)\n+                                               .build();\n+\n+    final PlannerConfig plannerConfig = new PlannerConfig();\n+\n+    final SegmentGenerator segmentGenerator = closer.register(new SegmentGenerator());\n+    log.info(\"Starting benchmark setup using cacheDir[%s], rows[%,d].\", segmentGenerator.getCacheDir(), rowsPerSegment);\n+    final QueryableIndex index = segmentGenerator.generate(dataSegment, schemaInfo, Granularities.NONE, rowsPerSegment);\n+\n+    final QueryRunnerFactoryConglomerate conglomerate = QueryStackTests.createQueryRunnerFactoryConglomerate(\n+        closer,\n+        PROCESSING_CONFIG\n+    );\n+\n+    final SpecificSegmentsQuerySegmentWalker walker = new SpecificSegmentsQuerySegmentWalker(conglomerate).add(\n+        dataSegment,\n+        index\n+    );\n+    closer.register(walker);\n+\n+    final SchemaPlus rootSchema =\n+        CalciteTests.createMockRootSchema(conglomerate, walker, plannerConfig, AuthTestUtils.TEST_AUTHORIZER_MAPPER);\n+    plannerFactory = new PlannerFactory(\n+        rootSchema,\n+        CalciteTests.createMockQueryLifecycleFactory(walker, conglomerate),\n+        CalciteTests.createOperatorTable(),\n+        CalciteTests.createExprMacroTable(),\n+        plannerConfig,\n+        AuthTestUtils.TEST_AUTHORIZER_MAPPER,\n+        CalciteTests.getJsonMapper(),\n+        CalciteTests.DRUID_SCHEMA_NAME\n+    );\n+\n+    checkSanity();\n+  }\n+\n+  @TearDown(Level.Trial)\n+  public void tearDown() throws Exception\n+  {\n+    closer.close();\n+  }\n+\n+  @Benchmark\n+  @BenchmarkMode(Mode.AverageTime)\n+  @OutputTimeUnit(TimeUnit.MILLISECONDS)\n+  public void querySql(Blackhole blackhole) throws Exception\n+  {\n+    final Map<String, Object> context = ImmutableMap.of(\"vectorize\", vectorize);\n+    final AuthenticationResult authenticationResult = NoopEscalator.getInstance()\n+                                                                   .createEscalatedAuthenticationResult();\n+    try (final DruidPlanner planner = plannerFactory.createPlanner(context, ImmutableList.of(), authenticationResult)) {\n+      final PlannerResult plannerResult = planner.plan(QUERIES.get(Integer.parseInt(query)));\n+      final Sequence<Object[]> resultSequence = plannerResult.run();\n+      final Object[] lastRow = resultSequence.accumulate(null, (accumulated, in) -> in);\n+      blackhole.consume(lastRow);\n+    }\n+  }\n+\n+  public void checkSanity() throws Exception", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1Nzk4NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492457985", "bodyText": "It seemed like too much work to add this to CalciteQueryTest, but I did add a new SqlVectorizedExpressionSanityTest which does some of these query tests as part of CI, and migrated this logic there so that this benchmark can call into the test method.", "author": "clintropolis", "createdAt": "2020-09-22T03:39:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM0NTc3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM0OTA5NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492349095", "bodyText": "nit: I guess we will want to keep this method until we merge ExprType and ValueType. Myabe getExprType() better to be more clear?", "author": "jihoonson", "createdAt": "2020-09-21T21:12:37Z", "path": "processing/src/main/java/org/apache/druid/segment/ColumnInspector.java", "diffHunk": "@@ -34,4 +36,15 @@\n    */\n   @Nullable\n   ColumnCapabilities getColumnCapabilities(String column);\n+\n+  @Nullable\n+  @Override\n+  default ExprType getType(String name)", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1MTU4Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492351582", "bodyText": "nit: duplicate ExprType.toValueType(inferredOutputType).", "author": "jihoonson", "createdAt": "2020-09-21T21:17:55Z", "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java", "diffHunk": "@@ -129,13 +139,74 @@ public DimensionSelector makeDimensionSelector(\n     return ExpressionSelectors.makeColumnValueSelector(factory, parsedExpression.get());\n   }\n \n+  @Override\n+  public boolean canVectorize(ColumnInspector inspector)\n+  {\n+    final ExpressionPlan plan = ExpressionPlanner.plan(inspector, parsedExpression.get());\n+    return plan.is(ExpressionPlan.Trait.VECTORIZABLE);\n+  }\n+\n+  @Override\n+  public VectorValueSelector makeVectorValueSelector(String columnName, VectorColumnSelectorFactory factory)\n+  {\n+    return ExpressionVectorSelectors.makeVectorValueSelector(factory, parsedExpression.get());\n+  }\n+\n+  @Override\n+  public VectorObjectSelector makeVectorObjectSelector(String columnName, VectorColumnSelectorFactory factory)\n+  {\n+    return ExpressionVectorSelectors.makeVectorObjectSelector(factory, parsedExpression.get());\n+  }\n+\n   @Override\n   public ColumnCapabilities capabilities(String columnName)\n   {\n-    // Note: Ideally we would fill out additional information instead of leaving capabilities as 'unknown', e.g. examine\n-    // if the expression in question could potentially return multiple values and anything else. However, we don't\n-    // currently have a good way of determining this, so fill this out more once we do\n-    return new ColumnCapabilitiesImpl().setType(outputType);\n+    // If possible, this should only be used as a fallback method for when capabilities are truly 'unknown', because we\n+    // are unable to compute the output type of the expression, either due to incomplete type information of the\n+    // inputs or because of unimplemented methods on expression implementations themselves, or, because a\n+    // ColumnInspector is not available\n+    return new ColumnCapabilitiesImpl().setType(outputType == null ? ValueType.FLOAT : outputType);\n+  }\n+\n+  @Override\n+  public ColumnCapabilities capabilities(ColumnInspector inspector, String columnName)\n+  {\n+    final ExpressionPlan plan = ExpressionPlanner.plan(inspector, parsedExpression.get());\n+\n+    if (plan.getOutputType() != null) {\n+\n+      if (outputType != null && ExprType.fromValueType(outputType) != plan.getOutputType()) {\n+        log.warn(\n+            \"Projected output type %s of expression %s does not match provided type %s\",\n+            plan.getOutputType(),\n+            expression,\n+            outputType\n+        );\n+      }\n+      final ExprType inferredOutputType = plan.getOutputType();\n+      final ValueType valueType = ExprType.toValueType(inferredOutputType);\n+      if (valueType.isNumeric()) {\n+        // if float was explicitly specified preserve it, because it will currently never be the computed output type\n+        if (ValueType.FLOAT == outputType) {\n+          return ColumnCapabilitiesImpl.createSimpleNumericColumnCapabilities(ValueType.FLOAT);\n+        }\n+        return ColumnCapabilitiesImpl.createSimpleNumericColumnCapabilities(ExprType.toValueType(inferredOutputType));", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1ODAzNA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492458034", "bodyText": "fixed", "author": "clintropolis", "createdAt": "2020-09-22T03:39:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1MTU4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1MzE2Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492353162", "bodyText": "Should hasMultipleValues be set when the plan has the NON_SCALAR_OUTPUT trait?", "author": "jihoonson", "createdAt": "2020-09-21T21:21:20Z", "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java", "diffHunk": "@@ -129,13 +139,74 @@ public DimensionSelector makeDimensionSelector(\n     return ExpressionSelectors.makeColumnValueSelector(factory, parsedExpression.get());\n   }\n \n+  @Override\n+  public boolean canVectorize(ColumnInspector inspector)\n+  {\n+    final ExpressionPlan plan = ExpressionPlanner.plan(inspector, parsedExpression.get());\n+    return plan.is(ExpressionPlan.Trait.VECTORIZABLE);\n+  }\n+\n+  @Override\n+  public VectorValueSelector makeVectorValueSelector(String columnName, VectorColumnSelectorFactory factory)\n+  {\n+    return ExpressionVectorSelectors.makeVectorValueSelector(factory, parsedExpression.get());\n+  }\n+\n+  @Override\n+  public VectorObjectSelector makeVectorObjectSelector(String columnName, VectorColumnSelectorFactory factory)\n+  {\n+    return ExpressionVectorSelectors.makeVectorObjectSelector(factory, parsedExpression.get());\n+  }\n+\n   @Override\n   public ColumnCapabilities capabilities(String columnName)\n   {\n-    // Note: Ideally we would fill out additional information instead of leaving capabilities as 'unknown', e.g. examine\n-    // if the expression in question could potentially return multiple values and anything else. However, we don't\n-    // currently have a good way of determining this, so fill this out more once we do\n-    return new ColumnCapabilitiesImpl().setType(outputType);\n+    // If possible, this should only be used as a fallback method for when capabilities are truly 'unknown', because we\n+    // are unable to compute the output type of the expression, either due to incomplete type information of the\n+    // inputs or because of unimplemented methods on expression implementations themselves, or, because a\n+    // ColumnInspector is not available\n+    return new ColumnCapabilitiesImpl().setType(outputType == null ? ValueType.FLOAT : outputType);\n+  }\n+\n+  @Override\n+  public ColumnCapabilities capabilities(ColumnInspector inspector, String columnName)\n+  {\n+    final ExpressionPlan plan = ExpressionPlanner.plan(inspector, parsedExpression.get());\n+\n+    if (plan.getOutputType() != null) {\n+\n+      if (outputType != null && ExprType.fromValueType(outputType) != plan.getOutputType()) {\n+        log.warn(\n+            \"Projected output type %s of expression %s does not match provided type %s\",\n+            plan.getOutputType(),\n+            expression,\n+            outputType\n+        );\n+      }\n+      final ExprType inferredOutputType = plan.getOutputType();\n+      final ValueType valueType = ExprType.toValueType(inferredOutputType);\n+      if (valueType.isNumeric()) {\n+        // if float was explicitly specified preserve it, because it will currently never be the computed output type\n+        if (ValueType.FLOAT == outputType) {\n+          return ColumnCapabilitiesImpl.createSimpleNumericColumnCapabilities(ValueType.FLOAT);\n+        }\n+        return ColumnCapabilitiesImpl.createSimpleNumericColumnCapabilities(ExprType.toValueType(inferredOutputType));\n+      }\n+\n+      // we don't have to check for unknown input here because output type is unable to be inferred if we don't know\n+      // the complete set of input types\n+      if (plan.any(ExpressionPlan.Trait.NON_SCALAR_OUTPUT, ExpressionPlan.Trait.NEEDS_APPLIED)) {", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1ODE1NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492458155", "bodyText": "Ah, unknown is effectively true in most cases (except for SINGLE_INPUT_MAPPABLE), but will change since both of these do imply multiple values", "author": "clintropolis", "createdAt": "2020-09-22T03:40:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1MzE2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1Mzk1MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492353950", "bodyText": "Please add javadoc for this method and update the javadoc of the other capabilities(String columnName). Also, should we deprecate the other one if we want to eventually use it only as a fallback?", "author": "jihoonson", "createdAt": "2020-09-21T21:23:05Z", "path": "processing/src/main/java/org/apache/druid/segment/VirtualColumn.java", "diffHunk": "@@ -246,6 +246,12 @@ default VectorObjectSelector makeVectorObjectSelector(\n    */\n   ColumnCapabilities capabilities(String columnName);\n \n+\n+  default ColumnCapabilities capabilities(ColumnInspector inspector, String columnName)", "originalCommit": "e8d240a71c339f44b96beca5a749e8e237bb2f2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ1ODI4Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492458282", "bodyText": "I was initially not planning to deprecate for virtual columns that don't care about the other columns in the segment, but I went ahead and did it, since they can just ignore the ColumnInspector.", "author": "clintropolis", "createdAt": "2020-09-22T03:40:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1Mzk1MA=="}], "type": "inlineReview"}, {"oid": "0a51738d7a8f0d37e70cc70c071e4079191fe05a", "url": "https://github.com/apache/druid/commit/0a51738d7a8f0d37e70cc70c071e4079191fe05a", "message": "changes", "committedDate": "2020-09-22T03:21:34Z", "type": "commit"}, {"oid": "774373656e353e4edba6708dde192210320975e5", "url": "https://github.com/apache/druid/commit/774373656e353e4edba6708dde192210320975e5", "message": "nullable", "committedDate": "2020-09-22T03:26:27Z", "type": "commit"}, {"oid": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "url": "https://github.com/apache/druid/commit/cf325119f9612fefb302fe9ff72f5f5b365e3522", "message": "missing hex", "committedDate": "2020-09-22T03:28:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE2OTU4MA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r491169580", "bodyText": "javadocs for both of these functions please", "author": "suneet-s", "createdAt": "2020-09-18T20:15:35Z", "path": "core/src/main/java/org/apache/druid/math/expr/ApplyFunction.java", "diffHunk": "@@ -49,6 +51,16 @@\n    */\n   String name();\n \n+  default boolean canVectorize(Expr.InputBindingTypes inputTypes, Expr lambda, List<Expr> args)\n+  {\n+    return false;\n+  }\n+\n+  default <T> VectorExprProcessor<T> asVectorProcessor(Expr.VectorInputBindingTypes inputTypes, Expr lambda, List<Expr> args)", "originalCommit": "482192457ec02e86ef4806f0f8b5d6118d473bbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjY4Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096682", "bodyText": "added", "author": "clintropolis", "createdAt": "2020-09-22T23:54:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE2OTU4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ5OTExMA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492499110", "bodyText": "javadocs for these functions please.", "author": "suneet-s", "createdAt": "2020-09-22T06:29:12Z", "path": "core/src/main/java/org/apache/druid/math/expr/ApplyFunction.java", "diffHunk": "@@ -49,6 +51,16 @@\n    */\n   String name();\n \n+  default boolean canVectorize(Expr.InputBindingTypes inputTypes, Expr lambda, List<Expr> args)\n+  {\n+    return false;\n+  }\n+\n+  default <T> ExprVectorProcessor<T> asVectorProcessor(Expr.VectorInputBindingTypes inputTypes, Expr lambda, List<Expr> args)", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjY1MQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096651", "bodyText": "added", "author": "clintropolis", "createdAt": "2020-09-22T23:54:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ5OTExMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUxMTgwMA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492511800", "bodyText": "Why is an empty list non numeric?\nMaybe add javadocs to clarify this behavior.", "author": "suneet-s", "createdAt": "2020-09-22T06:59:31Z", "path": "core/src/main/java/org/apache/druid/math/expr/Expr.java", "diffHunk": "@@ -148,6 +171,47 @@ default ExprType getOutputType(InputBindingTypes inputTypes)\n   {\n     @Nullable\n     ExprType getType(String name);\n+\n+    default boolean areNumeric(List<Expr> args)\n+    {\n+      boolean numeric = args.size() > 0;", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjU2NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096565", "bodyText": "there was nothing to compute an output type from, im not sure if nothing counts as numeric. added javadocs to explain this and other methods", "author": "clintropolis", "createdAt": "2020-09-22T23:53:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUxMTgwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUyMTg2OQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492521869", "bodyText": "\ud83c\udf89 so much more vectorization!", "author": "suneet-s", "createdAt": "2020-09-22T07:21:26Z", "path": "sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java", "diffHunk": "@@ -5912,9 +5912,6 @@ public void testExpressionFilteringAndGrouping() throws Exception\n   @Test\n   public void testExpressionFilteringAndGroupingUsingCastToLong() throws Exception\n   {\n-    // Cannot vectorize due to virtual columns.", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUyNDAyMA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492524020", "bodyText": "Does this mean a virtual column can't reference another virtual column? since the ColumnInspector is built with just he baseRowSignature?", "author": "suneet-s", "createdAt": "2020-09-22T07:25:43Z", "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/VirtualColumnRegistry.java", "diffHunk": "@@ -136,9 +137,11 @@ public RowSignature getFullRowSignature()\n     final RowSignature.Builder builder =\n         RowSignature.builder().addAll(baseRowSignature);\n \n+    ColumnInspector baseRowsInspector = builder.build().asColumnInspector();", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjQ5Nw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096497", "bodyText": "yeah, but this was true before. It would be possible to examine the expressions and resolve an execution order probably to allow it, but we haven't built it yet. This code would need to change to match I think", "author": "clintropolis", "createdAt": "2020-09-22T23:53:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjUyNDAyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgxMjQxNw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492812417", "bodyText": "should outNulls be null if we're not in sql compatible mode?", "author": "suneet-s", "createdAt": "2020-09-22T15:07:26Z", "path": "core/src/main/java/org/apache/druid/math/expr/vector/UnivariateFunctionVectorProcessor.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.math.expr.vector;\n+\n+import org.apache.druid.math.expr.Expr;\n+\n+/**\n+ * common machinery for processing single input operators and functions, which should always treat null input as null\n+ * output, and are backed by a primitive value instead of an object value (and need to use the null vector instead of\n+ * checking the vector itself for nulls)\n+ */\n+public abstract class UnivariateFunctionVectorProcessor<TInput, TOutput> implements ExprVectorProcessor<TOutput>\n+{\n+  final ExprVectorProcessor<TInput> processor;\n+  final int maxVectorSize;\n+  final boolean[] outNulls;\n+  final TOutput outValues;\n+\n+  public UnivariateFunctionVectorProcessor(\n+      ExprVectorProcessor<TInput> processor,\n+      int maxVectorSize,\n+      TOutput outValues\n+  )\n+  {\n+    this.processor = processor;\n+    this.maxVectorSize = maxVectorSize;\n+    this.outNulls = new boolean[maxVectorSize];", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjIxMw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096213", "bodyText": "it was easier to just always set it, but yeah this is an area that could probably be optimized a bit since we could ignore it totally for default mode I guess. I sort of dream of a world where default mode value coercion madness only lives at the borders and doesn't exist in expressions though...", "author": "clintropolis", "createdAt": "2020-09-22T23:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgxMjQxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgxMzU3Mg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492813572", "bodyText": "hmm interesting that this used to pass \ud83e\udd14", "author": "suneet-s", "createdAt": "2020-09-22T15:08:59Z", "path": "core/src/test/java/org/apache/druid/math/expr/FunctionTest.java", "diffHunk": "@@ -468,7 +468,7 @@ public void testGreatest()\n   {\n     // Same types\n     assertExpr(\"greatest(y, 0)\", 2L);\n-    assertExpr(\"greatest(34.0, z, 5.0, 767.0\", 767.0);\n+    assertExpr(\"greatest(34.0, z, 5.0, 767.0)\", 767.0);", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjEzOQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096139", "bodyText": "ah it still parses into the expression just complains about syntax on stderr", "author": "clintropolis", "createdAt": "2020-09-22T23:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgxMzU3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgxNzYxNg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492817616", "bodyText": "Similar question as the UnivariateFunctionProcessor\nI think with it written like this, ExprEvalDoubleVector and ExprEvalLongVector can't take advantage of the fact that there are no nulls in default mode. I don't know if there are any functions that produce nulls though... maybe that's why we need to do it this way?", "author": "suneet-s", "createdAt": "2020-09-22T15:13:09Z", "path": "core/src/main/java/org/apache/druid/math/expr/vector/BivariateFunctionVectorProcessor.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.math.expr.vector;\n+\n+import org.apache.druid.math.expr.Expr;\n+\n+/**\n+ * common machinery for processing two input operators and functions, which should always treat null inputs as null\n+ * output, and are backed by a primitive values instead of an object values (and need to use the null vectors instead of\n+ * checking the vector themselves for nulls)\n+ */\n+public abstract class BivariateFunctionVectorProcessor<TLeftInput, TRightInput, TOutput>\n+    implements ExprVectorProcessor<TOutput>\n+{\n+  final ExprVectorProcessor<TLeftInput> left;\n+  final ExprVectorProcessor<TRightInput> right;\n+  final int maxVectorSize;\n+  final boolean[] outNulls;\n+  final TOutput outValues;\n+\n+  protected BivariateFunctionVectorProcessor(\n+      ExprVectorProcessor<TLeftInput> left,\n+      ExprVectorProcessor<TRightInput> right,\n+      int maxVectorSize,\n+      TOutput outValues\n+  )\n+  {\n+    this.left = left;\n+    this.right = right;\n+    this.maxVectorSize = maxVectorSize;\n+    this.outNulls = new boolean[maxVectorSize];", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjQ3NQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096475", "bodyText": "Like i said in the other comment i just did this way because was slightly easier, it is worth revisiting this in follow-up work", "author": "clintropolis", "createdAt": "2020-09-22T23:53:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgxNzYxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgyMDA1OA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492820058", "bodyText": "Should we add a comment that this vector isn't thread safe? - because of how computeNumbers is written Are any of them thread safe?", "author": "suneet-s", "createdAt": "2020-09-22T15:15:25Z", "path": "core/src/main/java/org/apache/druid/math/expr/vector/ExprEvalStringVector.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.math.expr.vector;\n+\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.math.expr.ExprEval;\n+import org.apache.druid.math.expr.ExprType;\n+\n+import javax.annotation.Nullable;\n+\n+public final class ExprEvalStringVector extends ExprEvalVector<String[]>", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjExNg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096116", "bodyText": "These (and the selectors on top of them) don't need to be thread safe since only a single thread should be doing this per segment", "author": "clintropolis", "createdAt": "2020-09-22T23:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgyMDA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgyNDI0Nw==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492824247", "bodyText": "If I'm reading this correctly, this change isn't really needed in this PR, but it's some consolidation that was done across the various aggregator factories", "author": "suneet-s", "createdAt": "2020-09-22T15:20:48Z", "path": "processing/src/main/java/org/apache/druid/query/aggregation/SimpleDoubleAggregatorFactory.java", "diffHunk": "@@ -235,6 +244,19 @@ public String getExpression()\n     return expression;\n   }\n \n+  @Override\n+  public boolean canVectorize(ColumnInspector columnInspector)\n+  {\n+    if (fieldName != null) {\n+      final ColumnCapabilities capabilities = columnInspector.getColumnCapabilities(fieldName);\n+      return capabilities == null || ValueType.isNumeric(capabilities.getType());\n+    }\n+    if (expression != null) {\n+      return fieldExpression.get().canVectorize(columnInspector);\n+    }\n+    return false;\n+  }\n+", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5NjAxMQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096011", "bodyText": "Ah yeah, I was just consolidating. Since these were the same across all 3 still, I've moved this into a new static AggregatorUtil.canVectorize method.", "author": "clintropolis", "createdAt": "2020-09-22T23:51:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgyNDI0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjk2MzIxMQ==", "url": "https://github.com/apache/druid/pull/10401#discussion_r492963211", "bodyText": "Hmm, should RowSignature simply implement ColumnInspector?", "author": "jihoonson", "createdAt": "2020-09-22T18:54:53Z", "path": "processing/src/main/java/org/apache/druid/segment/column/RowSignature.java", "diffHunk": "@@ -157,6 +158,24 @@ public int indexOf(final String columnName)\n     return columnPositions.applyAsInt(columnName);\n   }\n \n+  public ColumnInspector asColumnInspector()", "originalCommit": "cf325119f9612fefb302fe9ff72f5f5b365e3522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzA5Njc5NA==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493096794", "bodyText": "oof, yes, changed", "author": "clintropolis", "createdAt": "2020-09-22T23:54:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mjk2MzIxMQ=="}], "type": "inlineReview"}, {"oid": "4fa4f299aeac07ab1b1f0c3bc51f84798c2305a0", "url": "https://github.com/apache/druid/commit/4fa4f299aeac07ab1b1f0c3bc51f84798c2305a0", "message": "more", "committedDate": "2020-09-22T23:51:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzY2MTUwMg==", "url": "https://github.com/apache/druid/pull/10401#discussion_r493661502", "bodyText": "It would be nice to explain the relationship between <T> and getOutputType here and in similar docs. Specifically I'm thinking something like \"As an implementor of the interface, do I need to ensure that the types are always the same? What happens if the types don't match? Is there something in the system that will throw an exception? or will be slow, because of some implicit casting somewhere else?\"", "author": "suneet-s", "createdAt": "2020-09-23T14:56:06Z", "path": "core/src/main/java/org/apache/druid/math/expr/ApplyFunction.java", "diffHunk": "@@ -51,11 +51,26 @@\n    */\n   String name();\n \n+  /**\n+   * Check if an apply function can be 'vectorized', for a given {@link LambdaExpr} and set of {@link Expr} inputs.\n+   * If this method returns true, {@link #asVectorProcessor} is expected to produce a {@link ExprVectorProcessor} which\n+   * can evaluate values in batches to use with vectorized query engines.\n+   *\n+   * @see Expr#canVectorize(Expr.InputBindingTypes)\n+   * @see Function#canVectorize(Expr.InputBindingTypes, List)\n+   */\n   default boolean canVectorize(Expr.InputBindingTypes inputTypes, Expr lambda, List<Expr> args)\n   {\n     return false;\n   }\n \n+  /**\n+   * Builds a 'vectorized' function expression processor, that can build vectorized processors for its input values\n+   * using {@link Expr#buildVectorized}, for use in vectorized query engines.\n+   *", "originalCommit": "4fa4f299aeac07ab1b1f0c3bc51f84798c2305a0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}