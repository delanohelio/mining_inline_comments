{"pr_number": 9959, "pr_title": "Fix Subquery could not be converted to groupBy query", "pr_createdAt": "2020-06-01T02:59:30Z", "pr_url": "https://github.com/apache/druid/pull/9959", "timeline": [{"oid": "c35242a3786adcbfbc90f1b22ef1017b3f3ca10c", "url": "https://github.com/apache/druid/commit/c35242a3786adcbfbc90f1b22ef1017b3f3ca10c", "message": "Fix join", "committedDate": "2020-05-29T11:52:01Z", "type": "commit"}, {"oid": "e9d549ab1c6895c3f3e4dd5af02021a75884c035", "url": "https://github.com/apache/druid/commit/e9d549ab1c6895c3f3e4dd5af02021a75884c035", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-05-31T15:06:42Z", "type": "commit"}, {"oid": "7fbffc2cb429431b12972a378751d5c31e06b6a7", "url": "https://github.com/apache/druid/commit/7fbffc2cb429431b12972a378751d5c31e06b6a7", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-01T02:45:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r433381288", "bodyText": "I think you diagnosed the bug right but the fix is a bit sketchy. If the Timeseries query accepts a DimensionSpec but then only uses it in the array signature, the following problems occur:\n\nThe input field, extractionFn, and decoration logic of the DimensionSpec are ignored.\nThe type might not actually be correct here; it will use the type from the DimensionSpec, but that might not match the actual type of the field, because the query engine isn't enforcing it.\nThe array signature should also match the maps returned from normal map-based responses, but this won't.\n\nI think the idea of a special parameter to the Timeseries query that makes the time column have a different name is a good idea, though. Maybe instead this would work:\n\nAdd an undocumented timeseries context parameter like timestampResultField that adds a new field containing the timestamp as a long, with the given name, to both the map and array responses.\nModify the SQL layer to generate this context parameter for timeseries queries when there is a time floor dimension.", "author": "gianm", "createdAt": "2020-06-01T17:31:15Z", "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java", "diffHunk": "@@ -404,11 +407,16 @@ public boolean isCacheable(TimeseriesQuery query, boolean willMergeRunners)\n   @Override\n   public RowSignature resultArraySignature(TimeseriesQuery query)\n   {\n-    return RowSignature.builder()\n-                       .addTimeColumn()\n-                       .addAggregators(query.getAggregatorSpecs())\n-                       .addPostAggregators(query.getPostAggregatorSpecs())\n-                       .build();\n+\n+    RowSignature.Builder rowSignatureBuilder = RowSignature.builder();\n+    if (query.getDimensionSpec() != null) {\n+      rowSignatureBuilder.addDimensions(Collections.singletonList(query.getDimensionSpec()));", "originalCommit": "7fbffc2cb429431b12972a378751d5c31e06b6a7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4NzYwOQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r433387609", "bodyText": "Thank you for the review. I think your suggestion with using a special parameter sounds good to me. Initially, I added dimensionSpec just to be similar to groupBy and TopN but you are right that we do not need dimensionSpec and it is confusing with how timeseries is using it compare to groupBy and TopN. All we need is a special field/parameter to know when we are doing time floor dimension.\nCan you explain a little bit about your first point with adds a new field containing the timestamp as a long, with the given name? What do you mean by the given name and do you mean the field containing the floor(timestamp) not the actual timestamp? Thanks!", "author": "maytasm", "createdAt": "2020-06-01T17:43:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU4MDUwNg==", "url": "https://github.com/apache/druid/pull/9959#discussion_r433580506", "bodyText": "What do you mean by the given name and do you mean the field containing the floor(timestamp) not the actual timestamp?\n\nBy \"the given name\" I meant the timestampResultField. (I was thinking you would do something like \"timestampResultField\": \"d0\".)\nIt should contain the floored timestamp, which at the point the query results are being returned, is the same as the timestamp in the response (it has already been floored).", "author": "gianm", "createdAt": "2020-06-02T02:00:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMzNDIwNw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434334207", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T06:25:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA=="}], "type": "inlineReview"}, {"oid": "4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "url": "https://github.com/apache/druid/commit/4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T04:47:20Z", "type": "commit"}, {"oid": "2b6fbd30a8272b3451e7fdc51fbbea1b8c2f3cac", "url": "https://github.com/apache/druid/commit/2b6fbd30a8272b3451e7fdc51fbbea1b8c2f3cac", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T05:20:33Z", "type": "commit"}, {"oid": "7af85ca9867df65962ffd9e24e86b7a2303a7bdc", "url": "https://github.com/apache/druid/commit/7af85ca9867df65962ffd9e24e86b7a2303a7bdc", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T06:25:09Z", "type": "commit"}, {"oid": "1b769953ce6a32b0998b7f30de386447bef51b2a", "url": "https://github.com/apache/druid/commit/1b769953ce6a32b0998b7f30de386447bef51b2a", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T07:09:42Z", "type": "commit"}, {"oid": "688878433a579efa34c61582ffa7e188fd2dbf2f", "url": "https://github.com/apache/druid/commit/688878433a579efa34c61582ffa7e188fd2dbf2f", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T07:43:14Z", "type": "commit"}, {"oid": "11d082761739f010652c188fcd0e15f94eb07e1c", "url": "https://github.com/apache/druid/commit/11d082761739f010652c188fcd0e15f94eb07e1c", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T09:31:01Z", "type": "commit"}, {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "url": "https://github.com/apache/druid/commit/7c11456fe1a622c0d3202e0c0ed1675bc6220338", "message": "add tests", "committedDate": "2020-06-03T12:14:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1OTcyMw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434759723", "bodyText": "nit: there's an unmatched parenthesis here.", "author": "gianm", "createdAt": "2020-06-03T18:09:43Z", "path": "processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java", "diffHunk": "@@ -235,4 +235,11 @@ public void testTimeseriesWithFilterOnNonExistentDimension()\n     // Skip this test because the timeseries test expects a day that doesn't have a filter match to be filled in,\n     // but group by just doesn't return a value if the filter doesn't match.\n   }\n+\n+  @Override\n+  public void testTimeseriesWithTimestampResultFieldContext()\n+  {\n+    // Skip this test because the timeseries test expects an extra column to be created (map from the timestamp_floor", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgyMjAzOQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434822039", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T20:03:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1OTcyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTIzNQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434761235", "bodyText": "\"testResultArraySignatureWithTimestampResultField\" would be a better name, because that's the feature we're testing from the TimeseriesQuery point of view (the fact that it's useful for SQL time floor groupings is more of a concern of the SQL layer).", "author": "gianm", "createdAt": "2020-06-03T18:12:32Z", "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java", "diffHunk": "@@ -388,6 +389,33 @@ public void testResultArraySignature()\n     );\n   }\n \n+  @Test\n+  public void testResultArraySignatureWithFloorTime()", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgyMjM2Mg==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434822362", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T20:04:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTIzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTMzNQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434761335", "bodyText": "\"testResultArraySignatureWithoutTimestampResultField\" would be a better name.", "author": "gianm", "createdAt": "2020-06-03T18:12:43Z", "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java", "diffHunk": "@@ -364,7 +365,7 @@ public void testResultLevelCacheKeyWithGrandTotal()\n   }\n \n   @Test\n-  public void testResultArraySignature()\n+  public void testResultArraySignatureWithoutFloorTime()", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgyMjY4OQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434822689", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T20:05:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTMzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2NDE4NQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434764185", "bodyText": "You should include a test that verifies behavior for the resultsAsArrays result type as well.", "author": "gianm", "createdAt": "2020-06-03T18:17:53Z", "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java", "diffHunk": "@@ -2471,6 +2472,123 @@ public void testTimeseriesWithBoundFilter1()\n     TestHelper.assertExpectedResults(expectedResults, results);\n   }\n \n+  @Test\n+  public void testTimeseriesWithTimestampResultFieldContext()", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MTkzMw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434841933", "bodyText": "Done. See testTimeseriesWithTimestampResultFieldContextForArrayResponse", "author": "maytasm", "createdAt": "2020-06-03T20:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2NDE4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MjM2MA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434772360", "bodyText": "I think we usually don't do import static like this, but if checkstyle was ok with it, then you can keep it.", "author": "gianm", "createdAt": "2020-06-03T18:32:04Z", "path": "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java", "diffHunk": "@@ -90,6 +94,8 @@\n import java.util.List;\n import java.util.Map;\n \n+import static org.apache.druid.sql.calcite.BaseCalciteQueryTest.TIMESERIES_CONTEXT_DEFAULT;", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MjgwNw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434842807", "bodyText": "It was unused. Removed", "author": "maytasm", "createdAt": "2020-06-03T20:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MjM2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NDI0Mg==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434774242", "bodyText": "This comment doesn't make a lot of sense to me. How about something like this instead:\n\nIf \"timestampResultField\" is set, we must include a copy of the timestamp in the result. This is used by the SQL layer when it generates a Timeseries query for a group-by-time-floor SQL query. The SQL layer expects the result of the time-floor to have a specific name that is not going to be \"__time\".", "author": "gianm", "createdAt": "2020-06-03T18:35:19Z", "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java", "diffHunk": "@@ -447,13 +454,21 @@ public RowSignature resultArraySignature(TimeseriesQuery query)\n     return result -> {\n       final TimeseriesResultValue holder = result.getValue();\n       final Map<String, Object> values = new HashMap<>(holder.getBaseObject());\n-      if (calculatePostAggs && !query.getPostAggregatorSpecs().isEmpty()) {\n-        // put non finalized aggregators for calculating dependent post Aggregators\n-        for (AggregatorFactory agg : query.getAggregatorSpecs()) {\n-          values.put(agg.getName(), holder.getMetric(agg.getName()));\n+      if (calculatePostAggs) {\n+        if (!query.getPostAggregatorSpecs().isEmpty()) {\n+          // put non finalized aggregators for calculating dependent post Aggregators\n+          for (AggregatorFactory agg : query.getAggregatorSpecs()) {\n+            values.put(agg.getName(), holder.getMetric(agg.getName()));\n+          }\n+          for (PostAggregator postAgg : query.getPostAggregatorSpecs()) {\n+            values.put(postAgg.getName(), postAgg.compute(values));\n+          }\n         }\n-        for (PostAggregator postAgg : query.getPostAggregatorSpecs()) {\n-          values.put(postAgg.getName(), postAgg.compute(values));\n+        // Timeseries query has timestamp_floor expression on the timestamp dimension so we need to\n+        // map the results to another dimension using the name (String) supplied by context key", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MzMwNA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434843304", "bodyText": "Sounds good. Done", "author": "maytasm", "createdAt": "2020-06-03T20:46:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NDI0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NTA2NA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434775064", "bodyText": "I think this could be clearer. How about:\n\n\"timestampResultField\" is an undocumented parameter used internally by the SQL layer. It is necessary because when the SQL layer generates a Timeseries query for a group-by-time-floor SQL query, it expects the result of the time-floor to have a specific name. That name is provided using this parameter.", "author": "gianm", "createdAt": "2020-06-03T18:36:50Z", "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java", "diffHunk": "@@ -50,6 +50,12 @@\n {\n   public static final String CTX_GRAND_TOTAL = \"grandTotal\";\n   public static final String SKIP_EMPTY_BUCKETS = \"skipEmptyBuckets\";\n+  // This context parameter is an undocumented parameter, used internally, to allow timeseries query with", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MzY5Nw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434843697", "bodyText": "Sounds good. Done", "author": "maytasm", "createdAt": "2020-06-03T20:47:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NTA2NA=="}], "type": "inlineReview"}, {"oid": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "url": "https://github.com/apache/druid/commit/eff405be76ceff3079cc342e5f8293b3ae2500e1", "message": "address comments", "committedDate": "2020-06-03T20:47:49Z", "type": "commit"}, {"oid": "865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589", "url": "https://github.com/apache/druid/commit/865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589", "message": "fix failing tests", "committedDate": "2020-06-03T22:16:43Z", "type": "commit"}]}