{"pr_number": 10267, "pr_title": "DruidInputSource: Fix issues in column projection, timestamp handling.", "pr_createdAt": "2020-08-12T02:47:54Z", "pr_url": "https://github.com/apache/druid/pull/10267", "timeline": [{"oid": "4b98828007ba1387b018bfa9919e228fbaacad24", "url": "https://github.com/apache/druid/commit/4b98828007ba1387b018bfa9919e228fbaacad24", "message": "DruidInputSource: Fix issues in column projection, timestamp handling.\n\nDruidInputSource, DruidSegmentReader changes:\n\n1) Remove \"dimensions\" and \"metrics\". They are not necessary, because we\n   can compute which columns we need to read based on what is going to\n   be used by the timestamp, transform, dimensions, and metrics.\n2) Start using ColumnsFilter (see below) to decide which columns we need\n   to read.\n3) Actually respect the \"timestampSpec\". Previously, it was ignored, and\n   the timestamp of the returned InputRows was set to the `__time` column\n   of the input datasource.\n\n(1) and (2) together fix a bug in which the DruidInputSource would not\nproperly read columns that are used as inputs to a transformSpec.\n\n(3) fixes a bug where the timestampSpec would be ignored if you attempted\nto set the column to something other than `__time`.\n\n(1) and (3) are breaking changes.\n\nWeb console changes:\n\n1) Remove \"Dimensions\" and \"Metrics\" from the Druid input source.\n2) Set timestampSpec to `{\"column\": \"__time\", \"format\": \"millis\"}` for\n   compatibility with the new behavior.\n\nOther changes:\n\n1) Add ColumnsFilter, a new class that allows input readers to determine\n   which columns they need to read. Currently, it's only used by the\n   DruidInputSource, but it could be used by other columnar input sources\n   in the future.\n2) Add a ColumnsFilter to InputRowSchema.\n3) Remove the metric names from InputRowSchema (they were unused).\n4) Add InputRowSchemas.fromDataSchema method that computes the proper\n   ColumnsFilter for given timestamp, dimensions, transform, and metrics.\n5) Add \"getRequiredColumns\" method to TransformSpec to support the above.", "committedDate": "2020-08-12T02:47:15Z", "type": "commit"}, {"oid": "be23e9852c4f547f33319b86f4239e26acfcce6d", "url": "https://github.com/apache/druid/commit/be23e9852c4f547f33319b86f4239e26acfcce6d", "message": "Various fixups.", "committedDate": "2020-08-12T07:30:56Z", "type": "commit"}, {"oid": "94046615f31796f14a88171e42352189449c8748", "url": "https://github.com/apache/druid/commit/94046615f31796f14a88171e42352189449c8748", "message": "Uncomment incorrectly commented lines.", "committedDate": "2020-08-12T09:29:06Z", "type": "commit"}, {"oid": "6a4a97eb8b803545fcec896d592bfb21d537db86", "url": "https://github.com/apache/druid/commit/6a4a97eb8b803545fcec896d592bfb21d537db86", "message": "Move TransformSpecTest to the proper module.", "committedDate": "2020-08-12T09:30:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE5MDU3Mw==", "url": "https://github.com/apache/druid/pull/10267#discussion_r469190573", "bodyText": "will it make sense to move DimFilter outside the InputSource in the task json? It seems more natural to me to put the filters alongside transforms, dimensions, and metrics and leave only the data source properties inside the InputSource section. On the flip side, it could make the compatibility situation more complicated than it is.", "author": "abhishekagarwal87", "createdAt": "2020-08-12T11:29:29Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/input/DruidInputSource.java", "diffHunk": "@@ -87,13 +91,21 @@\n   @Nullable\n   private final List<WindowedSegmentId> segmentIds;\n   private final DimFilter dimFilter;", "originalCommit": "6a4a97eb8b803545fcec896d592bfb21d537db86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTI3NjA3NQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r469276075", "bodyText": "It's possible to specify a filter alongside transforms today! You can do it in two places:\n\nIn the transformSpec (this works with any input source / format, see https://druid.apache.org/docs/latest/ingestion/index.html#filter)\nIn the druid inputSource itself (of course, only works with this input source)\n\nIt's a little silly to have both, perhaps, but there's a practical reason: specifying a filter in the druid inputSource is faster, because it is applied while creating the cursor that reads the data, and therefore it can use indexes, etc. The filter in the transformSpec is applied after the cursor generates rows.\nBut I think in the future, it'd be better to support pushing down the transformSpec filter into the cursor, and then we could deprecate the filter parameter in the inputSource, because it wouldn't be useful anymore.\nFor now, I suggest we leave it as-is.", "author": "gianm", "createdAt": "2020-08-12T13:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTE5MDU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3MjI4Mg==", "url": "https://github.com/apache/druid/pull/10267#discussion_r470372282", "bodyText": "\ud83d\udc4d", "author": "jon-wei", "createdAt": "2020-08-14T02:12:54Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/input/InputRowSchemas.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.input;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.druid.data.input.ColumnsFilter;\n+import org.apache.druid.data.input.InputRowSchema;\n+import org.apache.druid.data.input.impl.DimensionsSpec;\n+import org.apache.druid.data.input.impl.TimestampSpec;\n+import org.apache.druid.query.aggregation.AggregatorFactory;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.transform.Transform;\n+import org.apache.druid.segment.transform.TransformSpec;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Utilities that are helpful when implementing {@link org.apache.druid.data.input.InputEntityReader}.\n+ */\n+public class InputRowSchemas\n+{\n+  private InputRowSchemas()\n+  {\n+    // No instantiation.\n+  }\n+\n+  /**\n+   * Creates an {@link InputRowSchema} from a given {@link DataSchema}.\n+   */\n+  public static InputRowSchema fromDataSchema(final DataSchema dataSchema)\n+  {\n+    return new InputRowSchema(\n+        dataSchema.getTimestampSpec(),\n+        dataSchema.getDimensionsSpec(),\n+        createColumnsFilter(\n+            dataSchema.getTimestampSpec(),\n+            dataSchema.getDimensionsSpec(),\n+            dataSchema.getTransformSpec(),\n+            dataSchema.getAggregators()\n+        )\n+    );\n+  }\n+\n+  /**\n+   * Build a {@link ColumnsFilter} that can filter down the list of columns that must be read after flattening.\n+   *\n+   * @see InputRowSchema#getColumnsFilter()\n+   */\n+  @VisibleForTesting\n+  static ColumnsFilter createColumnsFilter(", "originalCommit": "6a4a97eb8b803545fcec896d592bfb21d537db86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDY1MzMwMA==", "url": "https://github.com/apache/druid/pull/10267#discussion_r470653300", "bodyText": "(What's the thumbs up for?)", "author": "gianm", "createdAt": "2020-08-14T14:20:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3MjI4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3OTE0MQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r470879141", "bodyText": "thought it was a good method \ud83d\udc4d", "author": "jon-wei", "createdAt": "2020-08-14T21:47:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM3MjI4Mg=="}], "type": "inlineReview"}, {"oid": "c9b088a898cbaa7752d290dddd42274a598eba0f", "url": "https://github.com/apache/druid/commit/c9b088a898cbaa7752d290dddd42274a598eba0f", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-08-25T06:34:46Z", "type": "commit"}, {"oid": "df7342752157ad3581d70d0721ea1c265fd7c835", "url": "https://github.com/apache/druid/commit/df7342752157ad3581d70d0721ea1c265fd7c835", "message": "Add druid.indexer.task.ignoreTimestampSpecForDruidInputSource setting.", "committedDate": "2020-08-25T07:34:07Z", "type": "commit"}, {"oid": "7bd0f908bf38f5b567286c5991c171f2591b2438", "url": "https://github.com/apache/druid/commit/7bd0f908bf38f5b567286c5991c171f2591b2438", "message": "Fix.", "committedDate": "2020-08-25T07:39:44Z", "type": "commit"}, {"oid": "cf68ace26924bb910038b57e4dd4d1d0b064e7de", "url": "https://github.com/apache/druid/commit/cf68ace26924bb910038b57e4dd4d1d0b064e7de", "message": "Fix build.", "committedDate": "2020-08-25T08:24:24Z", "type": "commit"}, {"oid": "6369cc0aa5e756c661ce9767262aa0fa255d9148", "url": "https://github.com/apache/druid/commit/6369cc0aa5e756c661ce9767262aa0fa255d9148", "message": "Checkstyle.", "committedDate": "2020-08-25T18:18:44Z", "type": "commit"}, {"oid": "14efe00d0546ab06b026c21f7ce118d9b72f35e7", "url": "https://github.com/apache/druid/commit/14efe00d0546ab06b026c21f7ce118d9b72f35e7", "message": "Misc fixes.", "committedDate": "2020-08-25T21:54:28Z", "type": "commit"}, {"oid": "1a961cdf4d756d46f9a07dca34e332bb34ad6d23", "url": "https://github.com/apache/druid/commit/1a961cdf4d756d46f9a07dca34e332bb34ad6d23", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-08-27T15:44:30Z", "type": "commit"}, {"oid": "7c6cf83327feef6deea1369f630b519a26f47d7f", "url": "https://github.com/apache/druid/commit/7c6cf83327feef6deea1369f630b519a26f47d7f", "message": "Fix test.", "committedDate": "2020-08-27T22:32:56Z", "type": "commit"}, {"oid": "530eb3280a04fa9db720e8d07e69126cd1583d22", "url": "https://github.com/apache/druid/commit/530eb3280a04fa9db720e8d07e69126cd1583d22", "message": "Move config.", "committedDate": "2020-08-29T21:21:59Z", "type": "commit"}, {"oid": "15b07b082fb1676027d1dd805d7c16c7b9101368", "url": "https://github.com/apache/druid/commit/15b07b082fb1676027d1dd805d7c16c7b9101368", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-09-23T04:18:15Z", "type": "commit"}, {"oid": "94f293017b51c2ff2fa03bcdb1f794df199f3078", "url": "https://github.com/apache/druid/commit/94f293017b51c2ff2fa03bcdb1f794df199f3078", "message": "Fix imports.", "committedDate": "2020-09-23T04:27:22Z", "type": "commit"}, {"oid": "34d47920168624071c5e8bf17a5bab3ce3ec4b45", "url": "https://github.com/apache/druid/commit/34d47920168624071c5e8bf17a5bab3ce3ec4b45", "message": "Fixup.", "committedDate": "2020-09-23T05:20:28Z", "type": "commit"}, {"oid": "3174b975172690bdd58c9c50ac4b7e32f5dd8e74", "url": "https://github.com/apache/druid/commit/3174b975172690bdd58c9c50ac4b7e32f5dd8e74", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-10-15T18:24:42Z", "type": "commit"}, {"oid": "f36fbf851afb9f69c3fe3d31424839979bf08b75", "url": "https://github.com/apache/druid/commit/f36fbf851afb9f69c3fe3d31424839979bf08b75", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-10-19T17:49:54Z", "type": "commit"}, {"oid": "96747f4cb0fede4f850a4517d97644788a2dd689", "url": "https://github.com/apache/druid/commit/96747f4cb0fede4f850a4517d97644788a2dd689", "message": "Fix ShuffleResourceTest.", "committedDate": "2020-10-19T23:31:09Z", "type": "commit"}, {"oid": "2e753d12e5dd3028a1c0ca3c21ec975b1f34b05f", "url": "https://github.com/apache/druid/commit/2e753d12e5dd3028a1c0ca3c21ec975b1f34b05f", "message": "Add import.", "committedDate": "2020-10-20T00:00:03Z", "type": "commit"}, {"oid": "20861748b9bf253c2bf06d895ca997285cf47da1", "url": "https://github.com/apache/druid/commit/20861748b9bf253c2bf06d895ca997285cf47da1", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-12-04T06:04:04Z", "type": "commit"}, {"oid": "be8a38950524036e25013e52088405fd3eaeb58e", "url": "https://github.com/apache/druid/commit/be8a38950524036e25013e52088405fd3eaeb58e", "message": "Smarter exclusions.", "committedDate": "2020-12-04T08:29:24Z", "type": "commit"}, {"oid": "76ccfd3f65ef65d0f14d694581d7231c7246fa1b", "url": "https://github.com/apache/druid/commit/76ccfd3f65ef65d0f14d694581d7231c7246fa1b", "message": "Fixes based on tests.\n\nAlso, add TIME_COLUMN constant in the web console.", "committedDate": "2020-12-06T00:26:09Z", "type": "commit"}, {"oid": "11783538edc0cc40f1cae6ffbd1677736839e773", "url": "https://github.com/apache/druid/commit/11783538edc0cc40f1cae6ffbd1677736839e773", "message": "Adjustments for tests.", "committedDate": "2020-12-07T03:13:12Z", "type": "commit"}, {"oid": "7695d8a5e67ad7a8a8414805b7ff389ad93724cd", "url": "https://github.com/apache/druid/commit/7695d8a5e67ad7a8a8414805b7ff389ad93724cd", "message": "Reorder test data.", "committedDate": "2020-12-07T05:15:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk3MTMzNA==", "url": "https://github.com/apache/druid/pull/10267#discussion_r537971334", "bodyText": "should be 0.20.1 at this point", "author": "vogievetsky", "createdAt": "2020-12-08T01:52:48Z", "path": "docs/configuration/index.md", "diffHunk": "@@ -1249,6 +1249,7 @@ Additional peon configs include:\n |`druid.indexer.task.gracefulShutdownTimeout`|Wait this long on middleManager restart for restorable tasks to gracefully exit.|PT5M|\n |`druid.indexer.task.hadoopWorkingPath`|Temporary working directory for Hadoop tasks.|`/tmp/druid-indexing`|\n |`druid.indexer.task.restoreTasksOnRestart`|If true, MiddleManagers will attempt to stop tasks gracefully on shutdown and restore them on restart.|false|\n+|`druid.indexer.task.ignoreTimestampSpecForDruidInputSource`|If true, tasks using the [Druid input source](../ingestion/native-batch.md#druid-input-source) will ignore the provided timestampSpec, and will use the `__time` column of the input datasource. This option is provided for compatibility with ingestion specs written before Druid 0.20.0.|false|", "originalCommit": "7695d8a5e67ad7a8a8414805b7ff389ad93724cd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk4NDc3MA==", "url": "https://github.com/apache/druid/pull/10267#discussion_r537984770", "bodyText": "I'll change it to 0.21.0, in the guess that this will be the next release.", "author": "gianm", "createdAt": "2020-12-08T02:28:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk3MTMzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk3MTM4NQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r537971385", "bodyText": "ditto", "author": "vogievetsky", "createdAt": "2020-12-08T01:52:57Z", "path": "docs/configuration/index.md", "diffHunk": "@@ -1313,6 +1314,7 @@ then the value from the configuration below is used:\n |`druid.indexer.task.gracefulShutdownTimeout`|Wait this long on Indexer restart for restorable tasks to gracefully exit.|PT5M|\n |`druid.indexer.task.hadoopWorkingPath`|Temporary working directory for Hadoop tasks.|`/tmp/druid-indexing`|\n |`druid.indexer.task.restoreTasksOnRestart`|If true, the Indexer will attempt to stop tasks gracefully on shutdown and restore them on restart.|false|\n+|`druid.indexer.task.ignoreTimestampSpecForDruidInputSource`|If true, tasks using the [Druid input source](../ingestion/native-batch.md#druid-input-source) will ignore the provided timestampSpec, and will use the `__time` column of the input datasource. This option is provided for compatibility with ingestion specs written before Druid 0.20.0.|false|", "originalCommit": "7695d8a5e67ad7a8a8414805b7ff389ad93724cd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "02dfb64633adee53d3fef0e7b915ccbf795b51e1", "url": "https://github.com/apache/druid/commit/02dfb64633adee53d3fef0e7b915ccbf795b51e1", "message": "Update docs.", "committedDate": "2020-12-08T02:28:35Z", "type": "commit"}, {"oid": "96aec6450f31cfb1071485bb75dca0f9ba63db04", "url": "https://github.com/apache/druid/commit/96aec6450f31cfb1071485bb75dca0f9ba63db04", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-12-08T16:08:52Z", "type": "commit"}, {"oid": "79402d01689c1b2f0876ed03bf3551413f3525a0", "url": "https://github.com/apache/druid/commit/79402d01689c1b2f0876ed03bf3551413f3525a0", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2020-12-21T20:19:01Z", "type": "commit"}, {"oid": "e22296a3c1c21ebbaabd401590af8cdbf89a31a8", "url": "https://github.com/apache/druid/commit/e22296a3c1c21ebbaabd401590af8cdbf89a31a8", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2021-01-06T22:11:51Z", "type": "commit"}, {"oid": "f513127f9c678067f6c5dfaa9b1327a5b55c767a", "url": "https://github.com/apache/druid/commit/f513127f9c678067f6c5dfaa9b1327a5b55c767a", "message": "Merge branch 'druid-input-source-projections' of https://github.com/gianm/druid into druid-input-source-projections", "committedDate": "2021-01-06T22:12:38Z", "type": "commit"}, {"oid": "5d68ea8677f40543f8eebe5b10519bace441642c", "url": "https://github.com/apache/druid/commit/5d68ea8677f40543f8eebe5b10519bace441642c", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2021-01-29T18:29:38Z", "type": "commit"}, {"oid": "8ce44bd2c43eea9dcfdde9b498bb1416ee32f112", "url": "https://github.com/apache/druid/commit/8ce44bd2c43eea9dcfdde9b498bb1416ee32f112", "message": "Update docs to say Druid 0.22.0 instead of 0.21.0.", "committedDate": "2021-01-29T18:30:40Z", "type": "commit"}, {"oid": "4b37cf265b0a10a5489ea758e602c7dee77f97d1", "url": "https://github.com/apache/druid/commit/4b37cf265b0a10a5489ea758e602c7dee77f97d1", "message": "Merge branch 'master' into druid-input-source-projections", "committedDate": "2021-02-25T16:06:18Z", "type": "commit"}, {"oid": "ade207e73bbc5410f3c7fa577e1fabce4d82000a", "url": "https://github.com/apache/druid/commit/ade207e73bbc5410f3c7fa577e1fabce4d82000a", "message": "Fix test.", "committedDate": "2021-02-25T16:54:55Z", "type": "commit"}, {"oid": "8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "url": "https://github.com/apache/druid/commit/8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "message": "Fix ITAutoCompactionTest.", "committedDate": "2021-02-25T21:05:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDcyNDU2Mw==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600724563", "bodyText": "Maybe good to suggest using auto compaction here instead of writing an ingestion spec.", "author": "jihoonson", "createdAt": "2021-03-24T17:52:18Z", "path": "docs/ingestion/native-batch.md", "diffHunk": "@@ -1282,60 +1282,81 @@ no `inputFormat` field needs to be specified in the ingestion spec when using th\n |type|This should be \"druid\".|yes|\n |dataSource|A String defining the Druid datasource to fetch rows from|yes|\n |interval|A String representing an ISO-8601 interval, which defines the time range to fetch the data over.|yes|\n-|dimensions|A list of Strings containing the names of dimension columns to select from the Druid datasource. If the list is empty, no dimensions are returned. If null, all dimensions are returned. |no|\n-|metrics|The list of Strings containing the names of metric columns to select. If the list is empty, no metrics are returned. If null, all metrics are returned.|no|\n |filter| See [Filters](../querying/filters.md). Only rows that match the filter, if specified, will be returned.|no|\n \n-A minimal example DruidInputSource spec is shown below:\n+The Druid input source can be used for a variety of purposes, including:\n \n-```json\n-...\n-    \"ioConfig\": {\n-      \"type\": \"index_parallel\",\n-      \"inputSource\": {\n-        \"type\": \"druid\",\n-        \"dataSource\": \"wikipedia\",\n-        \"interval\": \"2013-01-01/2013-01-02\"\n-      }\n-      ...\n-    },\n-...\n-```\n+- Creating new datasources that are rolled-up copies of existing datasources.\n+- Changing the [partitioning or sorting](index.md#partitioning) of a datasource to improve performance.\n+- Updating or removing rows using a [`transformSpec`](index.md#transformspec).\n \n-The spec above will read all existing dimension and metric columns from\n-the `wikipedia` datasource, including all rows with a timestamp (the `__time` column)\n-within the interval `2013-01-01/2013-01-02`.\n+When using the Druid input source, the timestamp column shows up as a numeric field named `__time` set to the number\n+of milliseconds since the epoch (January 1, 1970 00:00:00 UTC). It is common to use this in the timestampSpec, if you\n+want the output timestamp to be equivalent to the input timestamp. In this case, set the timestamp column to `__time`\n+and the format to `auto` or `millis`.\n \n-A spec that applies a filter and reads a subset of the original datasource's columns is shown below.\n+It is OK for the input and output datasources to be the same. In this case, newly generated data will overwrite the\n+previous data for the intervals specified in the `granularitySpec`. Generally, if you are going to do this, it is a\n+good idea to test out your reindexing by writing to a separate datasource before overwriting your main one.", "originalCommit": "8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk3MjMzMg==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600972332", "bodyText": "Good idea. I added this.\nAlternatively, if your goals can be satisfied by [compaction](compaction.md),\nconsider that instead as a simpler approach.", "author": "gianm", "createdAt": "2021-03-25T01:04:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDcyNDU2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDcyNjIzOQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600726239", "bodyText": "This part was not in the previous example. Was it intentional to use hashed partitionsSpec here? Seems unnecessary to me.", "author": "jihoonson", "createdAt": "2021-03-24T17:54:30Z", "path": "docs/ingestion/native-batch.md", "diffHunk": "@@ -1282,60 +1282,81 @@ no `inputFormat` field needs to be specified in the ingestion spec when using th\n |type|This should be \"druid\".|yes|\n |dataSource|A String defining the Druid datasource to fetch rows from|yes|\n |interval|A String representing an ISO-8601 interval, which defines the time range to fetch the data over.|yes|\n-|dimensions|A list of Strings containing the names of dimension columns to select from the Druid datasource. If the list is empty, no dimensions are returned. If null, all dimensions are returned. |no|\n-|metrics|The list of Strings containing the names of metric columns to select. If the list is empty, no metrics are returned. If null, all metrics are returned.|no|\n |filter| See [Filters](../querying/filters.md). Only rows that match the filter, if specified, will be returned.|no|\n \n-A minimal example DruidInputSource spec is shown below:\n+The Druid input source can be used for a variety of purposes, including:\n \n-```json\n-...\n-    \"ioConfig\": {\n-      \"type\": \"index_parallel\",\n-      \"inputSource\": {\n-        \"type\": \"druid\",\n-        \"dataSource\": \"wikipedia\",\n-        \"interval\": \"2013-01-01/2013-01-02\"\n-      }\n-      ...\n-    },\n-...\n-```\n+- Creating new datasources that are rolled-up copies of existing datasources.\n+- Changing the [partitioning or sorting](index.md#partitioning) of a datasource to improve performance.\n+- Updating or removing rows using a [`transformSpec`](index.md#transformspec).\n \n-The spec above will read all existing dimension and metric columns from\n-the `wikipedia` datasource, including all rows with a timestamp (the `__time` column)\n-within the interval `2013-01-01/2013-01-02`.\n+When using the Druid input source, the timestamp column shows up as a numeric field named `__time` set to the number\n+of milliseconds since the epoch (January 1, 1970 00:00:00 UTC). It is common to use this in the timestampSpec, if you\n+want the output timestamp to be equivalent to the input timestamp. In this case, set the timestamp column to `__time`\n+and the format to `auto` or `millis`.\n \n-A spec that applies a filter and reads a subset of the original datasource's columns is shown below.\n+It is OK for the input and output datasources to be the same. In this case, newly generated data will overwrite the\n+previous data for the intervals specified in the `granularitySpec`. Generally, if you are going to do this, it is a\n+good idea to test out your reindexing by writing to a separate datasource before overwriting your main one.\n+\n+An example task spec is shown below. It reads from a hypothetical raw datasource `wikipedia_raw` and creates a new\n+rolled-up datasource `wikipedia_rollup` by grouping on hour, \"countryName\", and \"page\".\n \n ```json\n-...\n+{\n+  \"type\": \"index_parallel\",\n+  \"spec\": {\n+    \"dataSchema\": {\n+      \"dataSource\": \"wikipedia_rollup\",\n+      \"timestampSpec\": {\n+        \"column\": \"__time\",\n+        \"format\": \"millis\"\n+      },\n+      \"dimensionsSpec\": {\n+        \"dimensions\": [\n+          \"countryName\",\n+          \"page\"\n+        ]\n+      },\n+      \"metricsSpec\": [\n+        {\n+          \"type\": \"count\",\n+          \"name\": \"cnt\"\n+        }\n+      ],\n+      \"granularitySpec\": {\n+        \"type\": \"uniform\",\n+        \"queryGranularity\": \"HOUR\",\n+        \"segmentGranularity\": \"DAY\",\n+        \"intervals\": [\"2016-06-27/P1D\"],\n+        \"rollup\": true\n+      }\n+    },\n     \"ioConfig\": {\n       \"type\": \"index_parallel\",\n       \"inputSource\": {\n         \"type\": \"druid\",\n-        \"dataSource\": \"wikipedia\",\n-        \"interval\": \"2013-01-01/2013-01-02\",\n-        \"dimensions\": [\n-          \"page\",\n-          \"user\"\n-        ],\n-        \"metrics\": [\n-          \"added\"\n-        ],\n-        \"filter\": {\n-          \"type\": \"selector\",\n-          \"dimension\": \"page\",\n-          \"value\": \"Druid\"\n-        }\n+        \"dataSource\": \"wikipedia_raw\",\n+        \"interval\": \"2016-06-27/P1D\"\n       }\n-      ...\n     },\n-...\n+    \"tuningConfig\": {\n+      \"type\": \"index_parallel\",\n+      \"partitionsSpec\": {\n+        \"type\": \"hashed\",\n+        \"numShards\": 1\n+      },\n+      \"forceGuaranteedRollup\": true,\n+      \"maxNumConcurrentSubTasks\": 1", "originalCommit": "8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk2Mjk2OA==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600962968", "bodyText": "What I was thinking was:\n\nI want to include a full ingest spec, not just the inputSource part, so people have a full example.\nThis spec uses rollup, so for a reindexing spec, it'd be good to use a partitionsSpec that guarantees rollup too.\n\nDo you have a better suggestion for what to put in the example?", "author": "gianm", "createdAt": "2021-03-25T00:34:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDcyNjIzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk2NDI5OQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600964299", "bodyText": "I see. It makes sense. If that's the case, I would suggest simply removing numShards from the spec. The parallel task will find the numShards automatically based on targetRowsPerSegment which is 5 million by default.", "author": "jihoonson", "createdAt": "2021-03-25T00:38:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDcyNjIzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk4MTE2Ng==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600981166", "bodyText": "OK, I'll do that.", "author": "gianm", "createdAt": "2021-03-25T01:32:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDcyNjIzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDczMjY3OQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600732679", "bodyText": "Is it better to add this annotation at the class-level? Seems reasonable to not include any fields in JSON if they are null.", "author": "jihoonson", "createdAt": "2021-03-24T18:02:57Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/input/DruidInputSource.java", "diffHunk": "@@ -160,6 +184,7 @@ public String getDataSource()\n \n   @Nullable\n   @JsonProperty\n+  @JsonInclude(Include.NON_NULL)", "originalCommit": "8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk3OTk5OQ==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600979999", "bodyText": "Interesting question. To answer it, I had to add some tests to make sure it worked properly. The answer is yes, it does work. I'll make the change and keep the new tests (look for them in DruidInputSourceTest).", "author": "gianm", "createdAt": "2021-03-25T01:28:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDczMjY3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDgyMDQyNg==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600820426", "bodyText": "Would be better to cache inputRowSchema since this function is called per row.", "author": "jihoonson", "createdAt": "2021-03-24T19:38:15Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/input/DruidSegmentReader.java", "diffHunk": "@@ -122,8 +147,16 @@\n   @Override\n   protected List<InputRow> parseInputRows(Map<String, Object> intermediateRow) throws ParseException\n   {\n-    final DateTime timestamp = (DateTime) intermediateRow.get(ColumnHolder.TIME_COLUMN_NAME);\n-    return Collections.singletonList(new MapBasedInputRow(timestamp.getMillis(), dimensions, intermediateRow));\n+    return Collections.singletonList(\n+        MapInputRowParser.parse(\n+            new InputRowSchema(", "originalCommit": "8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk0NDI2Ng==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600944266", "bodyText": "Do you know why this changed?", "author": "jihoonson", "createdAt": "2021-03-24T23:39:22Z", "path": "integration-tests/src/test/java/org/apache/druid/tests/coordinator/duty/ITAutoCompactionTest.java", "diffHunk": "@@ -129,7 +129,7 @@ public void testAutoCompactionDutySubmitAndVerifyCompaction() throws Exception\n           fullDatasourceName,\n           AutoCompactionSnapshot.AutoCompactionScheduleStatus.RUNNING,\n           0,\n-          22482,\n+          22481,", "originalCommit": "8fb44d7cd1e7f7f19ada2357baf18ae773a2d454", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk2NzAwMg==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600967002", "bodyText": "I guessed it was because the metadata changed. By that, I mean the org.apache.druid.segment.Metadata object stored in the segment, which contains the TimestampSpec.\nIt adds up, I think, since -1 character is the difference between the old default timestamp + auto (13 chars) and the new default __time + millis (12 chars).", "author": "gianm", "createdAt": "2021-03-25T00:46:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk0NDI2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk4ODc2Ng==", "url": "https://github.com/apache/druid/pull/10267#discussion_r600988766", "bodyText": "Ah, that seems likely the reason. Thanks \ud83d\udc4d", "author": "jihoonson", "createdAt": "2021-03-25T01:57:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMDk0NDI2Ng=="}], "type": "inlineReview"}, {"oid": "68c8cea6e2741ce4e37f83c4abab61b468560ff8", "url": "https://github.com/apache/druid/commit/68c8cea6e2741ce4e37f83c4abab61b468560ff8", "message": "Merge branch 'master' into ingest-druid-input-source-projections", "committedDate": "2021-03-25T00:31:10Z", "type": "commit"}, {"oid": "9bc0481e42ebcdc31f466871fea408b114da6a33", "url": "https://github.com/apache/druid/commit/9bc0481e42ebcdc31f466871fea408b114da6a33", "message": "Changes from review & from merging.", "committedDate": "2021-03-25T01:30:10Z", "type": "commit"}]}