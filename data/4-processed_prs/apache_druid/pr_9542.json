{"pr_number": 9542, "pr_title": "Add integration tests for HDFS", "pr_createdAt": "2020-03-19T20:00:09Z", "pr_url": "https://github.com/apache/druid/pull/9542", "timeline": [{"oid": "bbb3864775ac984196f3cb0719d4f72530aa6c64", "url": "https://github.com/apache/druid/commit/bbb3864775ac984196f3cb0719d4f72530aa6c64", "message": "HDFS IT", "committedDate": "2020-03-19T07:38:08Z", "type": "commit"}, {"oid": "ca910bcfd19a603120b8b9a7ad809088680b9e18", "url": "https://github.com/apache/druid/commit/ca910bcfd19a603120b8b9a7ad809088680b9e18", "message": "HDFS IT", "committedDate": "2020-03-19T07:44:03Z", "type": "commit"}, {"oid": "920cb96ee6830250bb5ec9e12e41fc10dd497410", "url": "https://github.com/apache/druid/commit/920cb96ee6830250bb5ec9e12e41fc10dd497410", "message": "HDFS IT", "committedDate": "2020-03-20T06:54:11Z", "type": "commit"}, {"oid": "fcf697dc224b4b51b7024f258da366e609b866d3", "url": "https://github.com/apache/druid/commit/fcf697dc224b4b51b7024f258da366e609b866d3", "message": "fix checkstyle", "committedDate": "2020-03-20T07:05:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2Mjk2MQ==", "url": "https://github.com/apache/druid/pull/9542#discussion_r395462961", "bodyText": "Mounting RESOURCEDIR which has some additional test data files", "author": "maytasm", "createdAt": "2020-03-20T06:59:52Z", "path": "integration-tests/run_cluster.sh", "diffHunk": "@@ -157,44 +160,11 @@ fi\n \n # Start docker containers for all Druid processes and dependencies\n {\n-  # Start zookeeper and kafka\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.2 ${COMMON_ENV} --name druid-zookeeper-kafka -p 2181:2181 -p 9092:9092 -p 9093:9093 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/zookeeper.conf:$SUPERVISORDIR/zookeeper.conf -v $SERVICE_SUPERVISORDS_DIR/kafka.conf:$SUPERVISORDIR/kafka.conf druid/cluster\n-\n-  # Start MYSQL\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.3 ${COMMON_ENV} --name druid-metadata-storage -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/metadata-storage.conf:$SUPERVISORDIR/metadata-storage.conf druid/cluster\n-\n-  # Start Overlord\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.4 ${COMMON_ENV} ${OVERLORD_ENV} ${OVERRIDE_ENV} --name druid-overlord -p 8090:8090 -p 8290:8290 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-metadata-storage:druid-metadata-storage --link druid-zookeeper-kafka:druid-zookeeper-kafka druid/cluster\n-\n-  # Start Coordinator\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.5 ${COMMON_ENV} ${COORDINATOR_ENV} ${OVERRIDE_ENV} --name druid-coordinator -p 8081:8081 -p 8281:8281 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-overlord:druid-overlord --link druid-metadata-storage:druid-metadata-storage --link druid-zookeeper-kafka:druid-zookeeper-kafka druid/cluster\n-\n-  # Start Historical\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.6 ${COMMON_ENV} ${HISTORICAL_ENV} ${OVERRIDE_ENV} --name druid-historical -p 8083:8083 -p 8283:8283 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka druid/cluster\n-\n-  # Start Middlemanger\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.7 ${COMMON_ENV} ${MIDDLEMANAGER_ENV} ${OVERRIDE_ENV} --name druid-middlemanager -p 8091:8091 -p 8291:8291 -p 8100:8100 -p 8101:8101 -p 8102:8102 -p 8103:8103 -p 8104:8104 -p 8105:8105 -p 8300:8300 -p 8301:8301 -p 8302:8302 -p 8303:8303 -p 8304:8304 -p 8305:8305 -v $RESOURCEDIR:/resources -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-overlord:druid-overlord druid/cluster\n-\n-  # Start Broker\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.8 ${COMMON_ENV} ${BROKER_ENV} ${OVERRIDE_ENV} --name druid-broker -p 8082:8082 -p 8282:8282 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-middlemanager:druid-middlemanager --link druid-historical:druid-historical druid/cluster\n-\n-  # Start Router\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.9 ${COMMON_ENV} ${ROUTER_ENV} ${OVERRIDE_ENV} --name druid-router -p 8888:8888 -p 9088:9088 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n-  # Start Router with permissive TLS settings (client auth enabled, no hostname verification, no revocation check)\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.10 ${COMMON_ENV} ${ROUTER_PERMISSIVE_TLS_ENV} ${OVERRIDE_ENV} --name druid-router-permissive-tls -p 8889:8889 -p 9089:9089 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n-  # Start Router with TLS but no client auth\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.11 ${COMMON_ENV} ${ROUTER_NO_CLIENT_AUTH_TLS_ENV} ${OVERRIDE_ENV} --name druid-router-no-client-auth-tls -p 8890:8890 -p 9090:9090 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n-  # Start Router with custom TLS cert checkers\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.12 ${COMMON_ENV} ${ROUTER_CUSTOM_CHECK_TLS_ENV} ${OVERRIDE_ENV} --hostname druid-router-custom-check-tls --name druid-router-custom-check-tls -p 8891:8891 -p 9091:9091 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n   # Start Hadoop docker if needed\n   if [ -n \"$DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER\" ] && [ \"$DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER\" == true ]\n   then\n     # Start Hadoop docker container\n-    docker run -d --privileged --net druid-it-net --ip 172.172.172.13 -h druid-it-hadoop --name druid-it-hadoop -p 2049:2049 -p 2122:2122 -p 8020:8020 -p 8021:8021 -p 8030:8030 -p 8031:8031 -p 8032:8032 -p 8033:8033 -p 8040:8040 -p 8042:8042 -p 8088:8088 -p 8443:8443 -p 9000:9000 -p 10020:10020 -p 19888:19888 -p 34455:34455 -p 49707:49707 -p 50010:50010 -p 50020:50020 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 -p 51111:51111 -v $SHARED_DIR:/shared druid-it/hadoop:2.8.5 sh -c \"/etc/bootstrap.sh && tail -f /dev/null\"\n+    docker run -d --privileged --net druid-it-net --ip 172.172.172.13 -h druid-it-hadoop --name druid-it-hadoop -p 2049:2049 -p 2122:2122 -p 8020:8020 -p 8021:8021 -p 8030:8030 -p 8031:8031 -p 8032:8032 -p 8033:8033 -p 8040:8040 -p 8042:8042 -p 8088:8088 -p 8443:8443 -p 9000:9000 -p 10020:10020 -p 19888:19888 -p 34455:34455 -p 49707:49707 -p 50010:50010 -p 50020:50020 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 -p 51111:51111 -v $RESOURCEDIR:/resources -v $SHARED_DIR:/shared druid-it/hadoop:2.8.5 sh -c \"/etc/bootstrap.sh && tail -f /dev/null\"", "originalCommit": "920cb96ee6830250bb5ec9e12e41fc10dd497410", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2MzExMQ==", "url": "https://github.com/apache/druid/pull/9542#discussion_r395463111", "bodyText": "Moved all these to after starting Hadoop since we need Hadoop XML files to be copied to shared before starting Druid", "author": "maytasm", "createdAt": "2020-03-20T07:00:27Z", "path": "integration-tests/run_cluster.sh", "diffHunk": "@@ -218,10 +188,44 @@ fi\n     docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod -R 777 /user\"\n     # Copy data files to Hadoop container\n     docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -put /shared/wikiticker-it/wikiticker-2015-09-12-sampled.json.gz /quickstart/wikiticker-2015-09-12-sampled.json.gz\"\n+    docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -put /resources/data/batch_index /batch_index\"\n     echo \"Finished setting up druid hadoop dirs\"\n \n     echo \"Copying Hadoop XML files to shared\"\n     docker exec -t druid-it-hadoop sh -c \"cp /usr/local/hadoop/etc/hadoop/*.xml /shared/hadoop_xml\"\n     echo \"Copied Hadoop XML files to shared\"\n   fi\n+\n+  # Start zookeeper and kafka", "originalCommit": "920cb96ee6830250bb5ec9e12e41fc10dd497410", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2MzgzMA==", "url": "https://github.com/apache/druid/pull/9542#discussion_r395463830", "bodyText": "Hadoop InputSource has a bug with batch parallel so using this non parallel for now.", "author": "maytasm", "createdAt": "2020-03-20T07:03:19Z", "path": "integration-tests/src/test/resources/indexer/wikipedia_cloud_simple_index_task.json", "diffHunk": "@@ -0,0 +1,81 @@\n+{", "originalCommit": "920cb96ee6830250bb5ec9e12e41fc10dd497410", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}