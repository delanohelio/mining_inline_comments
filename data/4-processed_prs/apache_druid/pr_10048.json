{"pr_number": 10048, "pr_title": "Coordinator loadstatus API full format does not consider Broadcast rules", "pr_createdAt": "2020-06-18T00:51:47Z", "pr_url": "https://github.com/apache/druid/pull/10048", "timeline": [{"oid": "fff1d86a20302aac9030ccf32bd50abf7033177a", "url": "https://github.com/apache/druid/commit/fff1d86a20302aac9030ccf32bd50abf7033177a", "message": "Coordinator loadstatus API full format does not consider Broadcast rules", "committedDate": "2020-06-18T00:50:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjAyMjU0OA==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442022548", "bodyText": "It's probably worth making a method that takes a CountDownLatch and a DruidServer and does the thing going on here (and in a few other tests)", "author": "clintropolis", "createdAt": "2020-06-18T07:28:23Z", "path": "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java", "diffHunk": "@@ -550,6 +551,241 @@ public void testCoordinatorTieredRun() throws Exception\n     EasyMock.verify(metadataRuleManager);\n   }\n \n+  @Test(timeout = 60_000L)\n+  public void testComputeUnderReplicationCountsPerDataSourcePerTierForSegmentsWithBroadcastRule() throws Exception\n+  {\n+    final String dataSource = \"dataSource\";\n+    final String hotTierName = \"hot\";\n+    final String coldTierName = \"cold\";\n+    final String tierName1 = \"tier1\";\n+    final String tierName2 = \"tier2\";\n+    final Rule broadcastDistributionRule = new ForeverBroadcastDistributionRule();\n+    final String loadPathCold = \"/druid/loadqueue/cold:1234\";\n+    final String loadPathBroker1 = \"/druid/loadqueue/broker1:1234\";\n+    final String loadPathBroker2 = \"/druid/loadqueue/broker2:1234\";\n+    final String loadPathPeon = \"/druid/loadqueue/peon:1234\";\n+    final DruidServer hotServer = new DruidServer(\"hot\", \"hot\", null, 5L, ServerType.HISTORICAL, hotTierName, 0);\n+    final DruidServer coldServer = new DruidServer(\"cold\", \"cold\", null, 5L, ServerType.HISTORICAL, coldTierName, 0);\n+    final DruidServer brokerServer1 = new DruidServer(\"broker1\", \"broker1\", null, 5L, ServerType.BROKER, tierName1, 0);\n+    final DruidServer brokerServer2 = new DruidServer(\"broker2\", \"broker2\", null, 5L, ServerType.BROKER, tierName2, 0);\n+    final DruidServer peonServer = new DruidServer(\"peon\", \"peon\", null, 5L, ServerType.INDEXER_EXECUTOR, tierName2, 0);\n+\n+    final Map<String, DataSegment> dataSegments = ImmutableMap.of(\n+        \"2018-01-02T00:00:00.000Z_2018-01-03T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-02/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2018-01-03T00:00:00.000Z_2018-01-04T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-03/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2017-01-01T00:00:00.000Z_2017-01-02T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2017-01-01/P1D\"), \"v1\", null, null, null, null, 0x9, 0)\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonCold = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathCold,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_cold_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_cold-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker1 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker1,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker1_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker1-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker2 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker2,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker2_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker2-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonPoenServer = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathPeon,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_peon_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_peon-%d\"),\n+        druidCoordinatorConfig\n+    );\n+    final PathChildrenCache pathChildrenCacheCold = new PathChildrenCache(\n+        curator,\n+        loadPathCold,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_cold-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker1 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker1,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker1-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker2 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker2,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker2-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCachePeon = new PathChildrenCache(\n+        curator,\n+        loadPathPeon,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_peon-%d\")\n+    );\n+\n+    loadManagementPeons.putAll(ImmutableMap.of(\"hot\", loadQueuePeon,\n+                                               \"cold\", loadQueuePeonCold,\n+                                               \"broker1\", loadQueuePeonBroker1,\n+                                               \"broker2\", loadQueuePeonBroker2,\n+                                               \"peon\", loadQueuePeonPoenServer));\n+\n+    loadQueuePeonCold.start();\n+    loadQueuePeonBroker1.start();\n+    loadQueuePeonBroker2.start();\n+    loadQueuePeonPoenServer.start();\n+    pathChildrenCache.start();\n+    pathChildrenCacheCold.start();\n+    pathChildrenCacheBroker1.start();\n+    pathChildrenCacheBroker2.start();\n+    pathChildrenCachePeon.start();\n+\n+    DruidDataSource[] druidDataSources = {new DruidDataSource(dataSource, Collections.emptyMap())};\n+    dataSegments.values().forEach(druidDataSources[0]::addSegment);\n+\n+    setupSegmentsMetadataMock(druidDataSources[0]);\n+\n+    EasyMock.expect(metadataRuleManager.getRulesWithDefault(EasyMock.anyString()))\n+            .andReturn(ImmutableList.of(broadcastDistributionRule)).atLeastOnce();\n+    EasyMock.expect(metadataRuleManager.getAllRules())\n+            .andReturn(ImmutableMap.of(dataSource, ImmutableList.of(broadcastDistributionRule))).atLeastOnce();\n+\n+    EasyMock.expect(serverInventoryView.getInventory())\n+            .andReturn(ImmutableList.of(hotServer, coldServer, brokerServer1, brokerServer2, peonServer))\n+            .atLeastOnce();\n+    EasyMock.expect(serverInventoryView.isStarted()).andReturn(true).anyTimes();\n+\n+    EasyMock.replay(metadataRuleManager, serverInventoryView);\n+\n+    coordinator.start();\n+    leaderAnnouncerLatch.await(); // Wait for this coordinator to become leader\n+\n+    final CountDownLatch assignSegmentLatchHot = new CountDownLatch(1);", "originalCommit": "fff1d86a20302aac9030ccf32bd50abf7033177a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjA2ODY3Mg==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442068672", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-18T08:47:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjAyMjU0OA=="}], "type": "inlineReview"}, {"oid": "bb005677a9408157414236c664eb6f4a8e285626", "url": "https://github.com/apache/druid/commit/bb005677a9408157414236c664eb6f4a8e285626", "message": "address comments", "committedDate": "2020-06-18T08:47:24Z", "type": "commit"}, {"oid": "f87ca9f325e8551b8f8037b5ffc283e8b0ab53cf", "url": "https://github.com/apache/druid/commit/f87ca9f325e8551b8f8037b5ffc283e8b0ab53cf", "message": "fix checkstyle", "committedDate": "2020-06-18T08:50:23Z", "type": "commit"}, {"oid": "95e84176a929717500d79ccaa92814ce1d04034d", "url": "https://github.com/apache/druid/commit/95e84176a929717500d79ccaa92814ce1d04034d", "message": "minor optimization", "committedDate": "2020-06-18T08:59:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNTk4Nw==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442415987", "bodyText": "In a previous PR there was a discussion about why it's ok for segmentReplicantLookup to be stale in this method:  https://github.com/apache/druid/pull/9965/files#r440541949\nWhat do you think about having that explanation as a code comment for this method?", "author": "ccaominh", "createdAt": "2020-06-18T18:18:06Z", "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -269,6 +270,13 @@ public boolean isLeader()\n   )\n   {\n     final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+    final Set<String> decommissioningServers = getDynamicConfigs().getDecommissioningNodes();", "originalCommit": "95e84176a929717500d79ccaa92814ce1d04034d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNzA2NA==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442437064", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-18T18:57:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNTk4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442416034", "bodyText": "If Rule subclasses are added in the future and should be considered in this method, is there a test that will fail?", "author": "ccaominh", "createdAt": "2020-06-18T18:18:10Z", "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -280,20 +288,38 @@ public boolean isLeader()\n       final List<Rule> rules = metadataRuleManager.getRulesWithDefault(segment.getDataSource());\n \n       for (final Rule rule : rules) {\n-        if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+        if (!rule.appliesTo(segment, now)) {\n           continue;\n         }\n \n-        ((LoadRule) rule)\n-            .getTieredReplicants()\n-            .forEach((final String tier, final Integer ruleReplicants) -> {\n-              int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n-              Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n-                  .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+        if (rule instanceof LoadRule) {\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(segment.getDataSource(), Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+        }\n+\n+        if (rule instanceof BroadcastDistributionRule) {", "originalCommit": "95e84176a929717500d79ccaa92814ce1d04034d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0MDM3NQ==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442440375", "bodyText": "Not right now. A Rule subclass may not always be needed to be considered in this method. Also not sure how the test will be able to automatically create new Rule subclass", "author": "maytasm", "createdAt": "2020-06-18T19:03:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU0NTY4Nw==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442545687", "bodyText": "Maybe adding some comments to somewhere like Rule will be sufficient for now. Not sure how likely we'll add future Rules, but if we do I think there's a good chance we'll forget to update this method if it's needed.", "author": "ccaominh", "createdAt": "2020-06-18T23:01:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU5NTE0OA==", "url": "https://github.com/apache/druid/pull/10048#discussion_r442595148", "bodyText": "#10054", "author": "maytasm", "createdAt": "2020-06-19T02:16:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA=="}], "type": "inlineReview"}, {"oid": "2eced94566472e7aa75172dd9023a863664809fe", "url": "https://github.com/apache/druid/commit/2eced94566472e7aa75172dd9023a863664809fe", "message": "address comments", "committedDate": "2020-06-18T19:11:14Z", "type": "commit"}]}