{"pr_number": 10524, "pr_title": "Dynamic auto scale Kafka-Stream ingest tasks", "pr_createdAt": "2020-10-21T06:30:01Z", "pr_url": "https://github.com/apache/druid/pull/10524", "timeline": [{"oid": "f3d6422ae289fc3821e07c4ef9ed5810d67c9f64", "url": "https://github.com/apache/druid/commit/f3d6422ae289fc3821e07c4ef9ed5810d67c9f64", "message": "druid task auto scale based on kafka lag", "committedDate": "2020-10-20T06:41:04Z", "type": "commit"}, {"oid": "5c1c21c44c2737fe0e55405f863cfd8c93329213", "url": "https://github.com/apache/druid/commit/5c1c21c44c2737fe0e55405f863cfd8c93329213", "message": "fix kafkaSupervisorIOConfig and KinesisSupervisorIOConfig", "committedDate": "2020-10-21T03:25:00Z", "type": "commit"}, {"oid": "6d7582be1e9c423a50085b57a3a163a5166316f4", "url": "https://github.com/apache/druid/commit/6d7582be1e9c423a50085b57a3a163a5166316f4", "message": "druid task auto scale based on kafka lag", "committedDate": "2020-10-21T03:27:47Z", "type": "commit"}, {"oid": "16b07446ad051fd8277bdba14b9b3bde4bab247b", "url": "https://github.com/apache/druid/commit/16b07446ad051fd8277bdba14b9b3bde4bab247b", "message": "fix kafkaSupervisorIOConfig and KinesisSupervisorIOConfig", "committedDate": "2020-10-21T03:27:47Z", "type": "commit"}, {"oid": "07eb9c089b9ba751dcb4c3b55728c3486406b278", "url": "https://github.com/apache/druid/commit/07eb9c089b9ba751dcb4c3b55728c3486406b278", "message": "test dynamic auto scale done", "committedDate": "2020-10-21T03:28:36Z", "type": "commit"}, {"oid": "a041b44ec5d39aca60bb319b681d9c5edea7a455", "url": "https://github.com/apache/druid/commit/a041b44ec5d39aca60bb319b681d9c5edea7a455", "message": "auto scale tasks tested on prd cluster", "committedDate": "2020-10-21T03:30:26Z", "type": "commit"}, {"oid": "746b033327ef51dd74c811c369444e51bac785ca", "url": "https://github.com/apache/druid/commit/746b033327ef51dd74c811c369444e51bac785ca", "message": "auto scale tasks tested on prd cluster", "committedDate": "2020-10-21T03:32:06Z", "type": "commit"}, {"oid": "d25f94a593a7b47207db44a8df838bbea46d0793", "url": "https://github.com/apache/druid/commit/d25f94a593a7b47207db44a8df838bbea46d0793", "message": "auto scale tasks tested on prd cluster", "committedDate": "2020-10-21T03:33:04Z", "type": "commit"}, {"oid": "e7a1af1e97a8f693b8f43ef6a20cda5a735e7fa4", "url": "https://github.com/apache/druid/commit/e7a1af1e97a8f693b8f43ef6a20cda5a735e7fa4", "message": "modify code style to solve 29055.10 29055.9 29055.17 29055.18 29055.19 29055.20", "committedDate": "2020-10-22T10:56:00Z", "type": "commit"}, {"oid": "d53ea7680fc8137e7197b8d7fa7fd887c633d566", "url": "https://github.com/apache/druid/commit/d53ea7680fc8137e7197b8d7fa7fd887c633d566", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks", "committedDate": "2020-10-22T11:04:43Z", "type": "commit"}, {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "url": "https://github.com/apache/druid/commit/78cbd45577dccc3abd39fb03db6d2a9298e6c252", "message": "rename test fiel function", "committedDate": "2020-10-23T04:54:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4Mjk4MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r529982981", "bodyText": "add comment stating why this is not implemented", "author": "capistrant", "createdAt": "2020-11-24T23:07:42Z", "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java", "diffHunk": "@@ -377,6 +377,11 @@ protected boolean useExclusiveStartSequenceNumberForNonFirstSequence()\n     return true;\n   }\n \n+  @Override\n+  protected void collectLag(ArrayList<Long> lags)\n+  {", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY2NzEzNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531667134", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:39:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4Mjk4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4MzM3OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r529983378", "bodyText": "nit: remove empty line", "author": "capistrant", "createdAt": "2020-11-24T23:08:10Z", "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorIOConfig.java", "diffHunk": "@@ -85,7 +88,9 @@ public KinesisSupervisorIOConfig(\n         completionTimeout,\n         lateMessageRejectionPeriod,\n         earlyMessageRejectionPeriod,\n+        dynamicAllocationTasksProperties,\n         lateMessageRejectionStartDateTime\n+", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3MTg5NQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531671895", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:49:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4MzM3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r529984556", "bodyText": "javadoc would be helpful as this is important/complex method", "author": "capistrant", "createdAt": "2020-11-24T23:09:29Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMTk5Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530501992", "bodyText": "logs added in this method should provide context about what supervisor they refer to. I also think we should evaluate what logs should be changed to debug too so limit the chattiness of info level", "author": "capistrant", "createdAt": "2020-11-25T16:30:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMjI3NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530502274", "bodyText": "should the config defaults be instantiated as final constants at top of class?", "author": "capistrant", "createdAt": "2020-11-25T16:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY2NzU5MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531667591", "bodyText": "All done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:40:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDk2Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r529984966", "bodyText": "javadoc would be helpful as this is complex/important method override", "author": "capistrant", "createdAt": "2020-11-24T23:09:57Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMDM1OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530500359", "bodyText": "also the logs added should add context about what supervisor is being logged. I think we should evaluate what logs should be changed to debug too so limit the chattiness of info level", "author": "capistrant", "createdAt": "2020-11-25T16:27:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDk2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY2NzM3MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531667371", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:39:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDk2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NjE2NQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r529986165", "bodyText": "javadoc please", "author": "capistrant", "createdAt": "2020-11-24T23:11:10Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3561,4 +3843,6 @@ protected void emitLag()\n    * sequences. In Kafka, start offsets are always inclusive.\n    */\n   protected abstract boolean useExclusiveStartSequenceNumberForNonFirstSequence();\n+\n+  protected abstract void collectLag(ArrayList<Long> lags);", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3MDkxMg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531670912", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:47:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NjE2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4Nzk2MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r529987960", "bodyText": "we need to document all of these new configs in kafka-ingestion.md in the KafkaSupervisorIOConfig section", "author": "capistrant", "createdAt": "2020-11-24T23:12:59Z", "path": "indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java", "diffHunk": "@@ -824,12 +827,32 @@ private static SeekableStreamSupervisorIOConfig getIOConfig()\n         false,\n         new Period(\"PT30M\"),\n         null,\n-        null, null\n+        null, getProperties(), null\n     )\n     {\n     };\n   }\n \n+  private static Map<String, Object> getProperties()\n+  {\n+    HashMap<String, Object> dynamicAllocationTasksProperties = new HashMap<>();", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3MTI5MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531671290", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:47:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4Nzk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwNTM0MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530005340", "bodyText": "what is the reasoning behind this default of 8?", "author": "capistrant", "createdAt": "2020-11-24T23:31:01Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -518,20 +684,52 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();\n+    log.info(\"Get dynamicAllocationTasksProperties from IOConfig : \" + dynamicAllocationTasksProperties);\n+\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      log.info(\"EnableDynamicAllocationTasks for datasource \" + dataSource);\n+      this.enableDynamicAllocationTasks = true;\n+    } else {\n+      log.info(\"Disable Dynamic Allocate Tasks\");\n+      this.enableDynamicAllocationTasks = false;\n+    }\n+    int taskCountMax = 0;\n+    if (enableDynamicAllocationTasks) {\n+      this.metricsCollectionIntervalMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionIntervalMillis\", 10000)));\n+      this.metricsCollectionRangeMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionRangeMillis\", 6 * 10 * 1000)));\n+      int slots = (int) (metricsCollectionRangeMillis / metricsCollectionIntervalMillis) + 1;\n+      log.info(\" The interval of metrics collection is \" + metricsCollectionIntervalMillis + \", \" + metricsCollectionRangeMillis + \" timeRange will collect \" + slots + \" data points at most.\");\n+      this.queue = new CircularFifoQueue<>(slots);\n+      taskCountMax = Integer.parseInt(String.valueOf(this.dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3NjIzMQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531676231", "bodyText": "We have deployed this auto scale feature on PRD environment for half a year. And it works stably and efficiently. The default values of all parameters are the best practice values continuously adjusted according to the online conditions. And the max number of ingest tasks in our cluster is 8. Just in case, maybe 4 is more reasonable, avoiding using up all resources. And users can set a larger value if 4 is not satisfied.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:58:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwNTM0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwNzEzMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530007133", "bodyText": "I don't think this log or the one below is needed since there aren't logs for the other Execs", "author": "capistrant", "createdAt": "2020-11-24T23:32:56Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -652,6 +857,11 @@ public void stop(boolean stopGracefully)\n       try {\n         scheduledExec.shutdownNow(); // stop recurring executions\n         reportingExec.shutdownNow();\n+        log.info(\"Shut Down allocationExec now\");", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3NjYzNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531676637", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:59:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwNzEzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwOTU5Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530009597", "bodyText": "is this supposed to be collectAndComputeLags()? As far as I can tell, the log on line 982 seems to suggest that is the name you may have meant to use", "author": "capistrant", "createdAt": "2020-11-24T23:35:38Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MDY2MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530060661", "bodyText": "also, a javadoc would be helpful too if you don't mind", "author": "capistrant", "createdAt": "2020-11-25T02:05:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwOTU5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3NjkzOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531676939", "bodyText": "Yes, collectAndComputeLags() is expected. Done :)", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:59:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwOTU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAxOTc4Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530019786", "bodyText": "as your comment says below, this could be null. Should we annotate as nullable?", "author": "capistrant", "createdAt": "2020-11-24T23:55:28Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorIOConfig.java", "diffHunk": "@@ -46,6 +48,7 @@\n   private final Optional<Duration> lateMessageRejectionPeriod;\n   private final Optional<Duration> earlyMessageRejectionPeriod;\n   private final Optional<DateTime> lateMessageRejectionStartDateTime;\n+  private final Map<String, Object> dynamicAllocationTasksProperties;", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3NzI5Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531677293", "bodyText": "Of course.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:00:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAxOTc4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMDE0Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530020147", "bodyText": "should this be annotated as nullable if the instance can be null as your comment in the constructor suggests?", "author": "capistrant", "createdAt": "2020-11-24T23:56:34Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorIOConfig.java", "diffHunk": "@@ -113,12 +119,23 @@ public Integer getReplicas()\n     return replicas;\n   }\n \n+  @JsonProperty", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3MDk5OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531670998", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:47:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMDE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMTA5OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530021098", "bodyText": "pretty straightforward method, but a short javadoc would be nice since we are updating an important lag related object", "author": "capistrant", "createdAt": "2020-11-24T23:59:29Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3526,6 +3789,25 @@ protected void emitLag()\n     }\n   }\n \n+\n+  protected void computeLags(Map<PartitionIdType, Long> partitionLags, ArrayList<Long> lags)", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3MDg3Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531670872", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMTA5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMjAwNQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530022005", "bodyText": "what are the implications of this failing? we are catching and carrying on. Can anything negative come from that?", "author": "capistrant", "createdAt": "2020-11-25T00:02:23Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -1137,6 +1394,20 @@ public void gracefulShutdownInternal() throws ExecutionException, InterruptedExc\n   @VisibleForTesting\n   public void resetInternal(DataSourceMetadata dataSourceMetadata)\n   {\n+    // clear queue for kafka lags\n+    if (enableDynamicAllocationTasks && queue != null) {\n+      try {\n+        lock.lock();\n+        queue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3MDgxMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531670813", "bodyText": "If this clear action is failed. The collection of lag points may be not as accurate as expected. May interfere with scale action. But this failing rarely happens and the  impact is acceptable. Because scale action is graceful and no data will lose or duplicate.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:46:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMjAwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMjIyMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530022220", "bodyText": "I think refactoring with a more descriptive name would be beneficial for readability", "author": "capistrant", "createdAt": "2020-11-25T00:03:05Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -495,6 +655,12 @@ boolean isValidTaskGroup(int taskGroupId, @Nullable TaskGroup taskGroup)\n   private volatile boolean stopped = false;\n   private volatile boolean lifecycleStarted = false;\n   private final ServiceEmitter emitter;\n+  private final boolean enableDynamicAllocationTasks;\n+  private volatile long metricsCollectionIntervalMillis;\n+  private volatile long metricsCollectionRangeMillis;\n+  private volatile long dynamicCheckStartDelayMillis;\n+  private volatile long dynamicCheckPeriod;\n+  private volatile CircularFifoQueue<Long> queue;", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY3NzU5Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531677593", "bodyText": "Done. renamed as lagMetricsQueue", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:01:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMjIyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NjEzNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530066134", "bodyText": "I think this method deserves a more specific name as it is actually re-submitting the supervisor. Perhaps submitSupervisorWithTaskCount or something of that sort?", "author": "capistrant", "createdAt": "2020-11-25T02:23:59Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));\n+    double triggerSaleInThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleInThresholdFrequency\", 0.8)));\n+    int taskCountMax = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+    int taskCountMin = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMin\", 1)));\n+    int scaleInStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInStep\", 1)));\n+    int scaleOutStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutStep\", 2)));\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= scaleOutThreshold) {\n+        beyond++;\n+      }\n+      if (lag <= scaleInThreshold) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+    log.info(\"triggerSaleOutThresholdFrequency is [ \" + triggerSaleOutThresholdFrequency + \" ] and triggerSaleInThresholdFrequency is [ \" + triggerSaleInThresholdFrequency + \" ]\");\n+    log.info(\"beyondProportion is [ \" + beyondProportion + \" ] and withinProportion is [ \" + withinProportion + \" ]\");\n+\n+    int currentActiveTaskCount;\n+    int desireActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (beyondProportion >= triggerSaleOutThresholdFrequency) {\n+      // Do Scale out\n+      int taskCount = currentActiveTaskCount + scaleOutStep;\n+      if (currentActiveTaskCount == taskCountMax) {\n+        log.info(\"CurrentActiveTaskCount reach task count Max limit, skip to scale out tasks\");\n+        return false;\n+      } else {\n+        desireActiveTaskCount = Math.min(taskCount, taskCountMax);\n+      }\n+      log.info(\"Start to scale out tasks , current active task number [ \" + currentActiveTaskCount + \" ] and desire task number is [ \" + desireActiveTaskCount + \" ] \");\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Set Task Count : \" + desireActiveTaskCount);\n+      setTaskCount(desireActiveTaskCount);\n+      return true;\n+    }\n+\n+    if (withinProportion >= triggerSaleInThresholdFrequency) {\n+      // Do Scale in\n+      int taskCount = currentActiveTaskCount - scaleInStep;\n+      if (currentActiveTaskCount == taskCountMin) {\n+        log.info(\"CurrentActiveTaskCount reach task count Min limit, skip to scale in tasks\");\n+        return false;\n+      } else {\n+        desireActiveTaskCount = Math.max(taskCount, taskCountMin);\n+      }\n+      log.info(\"Start to scale in tasks , current active task number [ \" + currentActiveTaskCount + \" ] and desire task number is [ \" + desireActiveTaskCount + \" ] \");\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Set Task Count : \" + desireActiveTaskCount);\n+      setTaskCount(desireActiveTaskCount);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  private void setTaskCount(int desireActiveTaskCount)", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwOTQyMg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530509422", "bodyText": "what are the consequences of failure at this point? we have called gracefulShutdownInternal so I assume we will be left with no active supervisor for the datasource?", "author": "capistrant", "createdAt": "2020-11-25T16:41:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NjEzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4MDU2Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531680563", "bodyText": "renamed as changeTaskCountInIOConfig\nthe method gracefulShutdownInternal will not suspend the supervisor. It will make the ingest tasks stop reading and start to publish data. So that whether the func fails or not, the supervisor is always active. What's more, if this func failed, current scale action will be canceled. And will try another scale action in dynamicCheckPeriod.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:08:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NjEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NjU5Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530496593", "bodyText": "same thought about debug level and context about the supervisor it is referring to", "author": "capistrant", "createdAt": "2020-11-25T16:22:16Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -518,20 +684,52 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();\n+    log.info(\"Get dynamicAllocationTasksProperties from IOConfig : \" + dynamicAllocationTasksProperties);\n+\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      log.info(\"EnableDynamicAllocationTasks for datasource \" + dataSource);\n+      this.enableDynamicAllocationTasks = true;\n+    } else {\n+      log.info(\"Disable Dynamic Allocate Tasks\");\n+      this.enableDynamicAllocationTasks = false;\n+    }\n+    int taskCountMax = 0;\n+    if (enableDynamicAllocationTasks) {\n+      this.metricsCollectionIntervalMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionIntervalMillis\", 10000)));\n+      this.metricsCollectionRangeMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionRangeMillis\", 6 * 10 * 1000)));\n+      int slots = (int) (metricsCollectionRangeMillis / metricsCollectionIntervalMillis) + 1;\n+      log.info(\" The interval of metrics collection is \" + metricsCollectionIntervalMillis + \", \" + metricsCollectionRangeMillis + \" timeRange will collect \" + slots + \" data points at most.\");\n+      this.queue = new CircularFifoQueue<>(slots);\n+      taskCountMax = Integer.parseInt(String.valueOf(this.dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+      this.dynamicCheckStartDelayMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"dynamicCheckStartDelayMillis\", 300000)));\n+      this.dynamicCheckPeriod = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"dynamicCheckPeriod\", 600000)));\n+      this.metricsCollectionRangeMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionRangeMillis\", 600000)));\n+    }\n+\n     this.tuningConfig = spec.getTuningConfig();\n     this.taskTuningConfig = this.tuningConfig.convertToTaskTuningConfig();\n     this.supervisorId = supervisorId;\n     this.exec = Execs.singleThreaded(supervisorId);\n     this.scheduledExec = Execs.scheduledSingleThreaded(supervisorId + \"-Scheduler-%d\");\n     this.reportingExec = Execs.scheduledSingleThreaded(supervisorId + \"-Reporting-%d\");\n+    this.allocationExec = Execs.scheduledSingleThreaded(supervisorId + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(supervisorId + \"-Computation-%d\");\n     this.stateManager = new SeekableStreamSupervisorStateManager(\n         spec.getSupervisorStateManagerConfig(),\n         spec.isSuspended()\n     );\n \n-    int workerThreads = (this.tuningConfig.getWorkerThreads() != null\n-                         ? this.tuningConfig.getWorkerThreads()\n-                         : Math.min(10, this.ioConfig.getTaskCount()));\n+    int workerThreads;\n+    if (enableDynamicAllocationTasks) {\n+      workerThreads = (this.tuningConfig.getWorkerThreads() != null\n+              ? this.tuningConfig.getWorkerThreads()\n+              : Math.min(10, taskCountMax));\n+    } else {\n+      workerThreads = (this.tuningConfig.getWorkerThreads() != null\n+              ? this.tuningConfig.getWorkerThreads()\n+              : Math.min(10, this.ioConfig.getTaskCount()));\n+    }\n \n     this.workerExec = MoreExecutors.listeningDecorator(Execs.multiThreaded(workerThreads, supervisorId + \"-Worker-%d\"));\n     log.info(\"Created worker pool with [%d] threads for dataSource [%s]\", workerThreads, this.dataSource);", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY2NzgyMQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531667821", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:40:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NjU5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5ODUwMg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530498502", "bodyText": "wondering if it would be better to have all these defaults be final constants instantiated at top of class for easy reference?", "author": "capistrant", "createdAt": "2020-11-25T16:25:06Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -518,20 +684,52 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();\n+    log.info(\"Get dynamicAllocationTasksProperties from IOConfig : \" + dynamicAllocationTasksProperties);\n+\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      log.info(\"EnableDynamicAllocationTasks for datasource \" + dataSource);\n+      this.enableDynamicAllocationTasks = true;\n+    } else {\n+      log.info(\"Disable Dynamic Allocate Tasks\");\n+      this.enableDynamicAllocationTasks = false;\n+    }\n+    int taskCountMax = 0;\n+    if (enableDynamicAllocationTasks) {\n+      this.metricsCollectionIntervalMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionIntervalMillis\", 10000)));", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4NjcwNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531686707", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:23:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5ODUwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5OTQ2Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530499467", "bodyText": "wondering if this default value should be final constant instantiated at top of class?", "author": "capistrant", "createdAt": "2020-11-25T16:26:24Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4Njc0OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531686748", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:24:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5OTQ2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxMTMzMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530511330", "bodyText": "logs in this constructor should include info on the supervisor being referred to. I think we should also evaluate what can be debug to reduce chattiness in info level logging.", "author": "capistrant", "createdAt": "2020-11-25T16:44:17Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -495,6 +655,12 @@ boolean isValidTaskGroup(int taskGroupId, @Nullable TaskGroup taskGroup)\n   private volatile boolean stopped = false;\n   private volatile boolean lifecycleStarted = false;\n   private final ServiceEmitter emitter;\n+  private final boolean enableDynamicAllocationTasks;\n+  private volatile long metricsCollectionIntervalMillis;\n+  private volatile long metricsCollectionRangeMillis;\n+  private volatile long dynamicCheckStartDelayMillis;\n+  private volatile long dynamicCheckPeriod;\n+  private volatile CircularFifoQueue<Long> queue;\n \n   public SeekableStreamSupervisor(", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY2NzY4NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531667684", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:40:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxMTMzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxMjY4OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530512688", "bodyText": "include reference to the datasource in this log and the one for the lag computation executor below. Should they be debug to reduce info level chattiness?", "author": "capistrant", "createdAt": "2020-11-25T16:46:16Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -768,7 +978,22 @@ public void tryInit()\n         );\n \n         scheduleReporting(reportingExec);\n-\n+        if (enableDynamicAllocationTasks) {\n+          log.info(\"Collect and compute lags at fixed rate of \" + metricsCollectionIntervalMillis);", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4Njc4Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531686782", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:24:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxMjY4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxODQ0Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530518442", "bodyText": "logs should provide context about what supervisor they are referring. As in other places, lets assess what can be changed to debug to reduce chattiness", "author": "capistrant", "createdAt": "2020-11-25T16:55:02Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()\n+  {\n+    return new Runnable() {\n+      @Override\n+      public void run()", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY2Nzg5NQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531667895", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T15:40:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxODQ0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxODgwNQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530518805", "bodyText": "should this be warn if we catch and move on?", "author": "capistrant", "createdAt": "2020-11-25T16:55:30Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()\n+  {\n+    return new Runnable() {\n+      @Override\n+      public void run()\n+      {\n+        lock.lock();\n+        try {\n+          if (!spec.isSuspended()) {\n+            ArrayList<Long> metricsInfo = new ArrayList<>(3);\n+            collectLag(metricsInfo);\n+            long totalLags = metricsInfo.size() < 3 ? 0 : metricsInfo.get(1);\n+            queue.offer(totalLags > 0 ? totalLags : 0);\n+            log.info(\"Current lag metric points : \" + new ArrayList<>(queue));\n+          } else {\n+            log.info(\"[%s] supervisor is suspended, skip to collect kafka lags\", dataSource);\n+          }\n+        }\n+        catch (Exception e) {\n+          log.error(e, \"Error, When collect kafka lags\");", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4NjkwNQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531686905", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:24:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxODgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyMjU5Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530522597", "bodyText": "does this mean we have not collected enough historical lag data to decide on scale in/scale out? I think the log can be updated to be more descriptive since it may not be obvious to log reader why it matters that queue is not full", "author": "capistrant", "createdAt": "2020-11-25T17:01:27Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4Njk3Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531686977", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:24:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyMjU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyNDA3OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530524078", "bodyText": "I think these may be spelling mistakes in variable name and config value for this and next config. triggerSale* --> triggerScale* ?", "author": "capistrant", "createdAt": "2020-11-25T17:03:57Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4NzAxNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531687014", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:24:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyNDA3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyNTU2Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r530525566", "bodyText": "same spelling callout as above", "author": "capistrant", "createdAt": "2020-11-25T17:06:21Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));\n+    double triggerSaleInThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleInThresholdFrequency\", 0.8)));\n+    int taskCountMax = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+    int taskCountMin = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMin\", 1)));\n+    int scaleInStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInStep\", 1)));\n+    int scaleOutStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutStep\", 2)));\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= scaleOutThreshold) {\n+        beyond++;\n+      }\n+      if (lag <= scaleInThreshold) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+    log.info(\"triggerSaleOutThresholdFrequency is [ \" + triggerSaleOutThresholdFrequency + \" ] and triggerSaleInThresholdFrequency is [ \" + triggerSaleInThresholdFrequency + \" ]\");", "originalCommit": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTY4NzA2Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r531687066", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2020-11-27T16:24:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyNTU2Ng=="}], "type": "inlineReview"}, {"oid": "e8b7e09333f086603c824c7983b2eee8b8ef7d21", "url": "https://github.com/apache/druid/commit/e8b7e09333f086603c824c7983b2eee8b8ef7d21", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks", "committedDate": "2020-11-27T02:12:39Z", "type": "commit"}, {"oid": "215844e6162e7095450b04aa6218989da939f37a", "url": "https://github.com/apache/druid/commit/215844e6162e7095450b04aa6218989da939f37a", "message": "change codes and add docs based on capistrant reviewed", "committedDate": "2020-11-27T12:07:24Z", "type": "commit"}, {"oid": "b3b75b20992d6a31e6c4012b6408eeaf03192c5b", "url": "https://github.com/apache/druid/commit/b3b75b20992d6a31e6c4012b6408eeaf03192c5b", "message": "midify test docs", "committedDate": "2020-11-27T12:10:24Z", "type": "commit"}, {"oid": "18375474208f172c5728a60f3935f4cc023ac981", "url": "https://github.com/apache/druid/commit/18375474208f172c5728a60f3935f4cc023ac981", "message": "modify docs", "committedDate": "2020-11-27T15:37:50Z", "type": "commit"}, {"oid": "50a94cadb70d153e5afc675e19ecf1b08654a8c1", "url": "https://github.com/apache/druid/commit/50a94cadb70d153e5afc675e19ecf1b08654a8c1", "message": "modify docs", "committedDate": "2020-11-27T16:25:40Z", "type": "commit"}, {"oid": "4a0d706626ab82ac438cb4c7c3ba89b4b94e653b", "url": "https://github.com/apache/druid/commit/4a0d706626ab82ac438cb4c7c3ba89b4b94e653b", "message": "modify docs", "committedDate": "2020-11-28T04:49:59Z", "type": "commit"}, {"oid": "aa70a5c33c6e1b50739a1b6f15ab3eb67586fb90", "url": "https://github.com/apache/druid/commit/aa70a5c33c6e1b50739a1b6f15ab3eb67586fb90", "message": "merge from master", "committedDate": "2021-01-15T00:11:13Z", "type": "commit"}, {"oid": "fb70688fa646c0d4826f1a8e224a76cf6a640427", "url": "https://github.com/apache/druid/commit/fb70688fa646c0d4826f1a8e224a76cf6a640427", "message": "merge from master", "committedDate": "2021-01-15T00:15:20Z", "type": "commit"}, {"oid": "c0b3ff258020bd17c1e370ac2b71b872b27f25a8", "url": "https://github.com/apache/druid/commit/c0b3ff258020bd17c1e370ac2b71b872b27f25a8", "message": "Extract the autoScale logic out of SeekableStreamSupervisor to minimize putting more stuff inside there &&  Make autoscaling algorithm configurable and scalable.", "committedDate": "2021-01-15T10:57:51Z", "type": "commit"}, {"oid": "76db5ba009fbd54d5b45ffcc3193d3c05373fbe0", "url": "https://github.com/apache/druid/commit/76db5ba009fbd54d5b45ffcc3193d3c05373fbe0", "message": "fix ci failed", "committedDate": "2021-01-16T07:52:06Z", "type": "commit"}, {"oid": "751175fc7cf449fe4adf533c3245878e483a70e6", "url": "https://github.com/apache/druid/commit/751175fc7cf449fe4adf533c3245878e483a70e6", "message": "revert msic.xml", "committedDate": "2021-01-16T07:53:16Z", "type": "commit"}, {"oid": "f8a67072ad8deeab6e1035589e568552cd5eec0c", "url": "https://github.com/apache/druid/commit/f8a67072ad8deeab6e1035589e568552cd5eec0c", "message": "add uts to test autoscaler create && scale out/in and kafka ingest with scale enable", "committedDate": "2021-01-16T22:33:41Z", "type": "commit"}, {"oid": "172cff7904038e2b700ca427cad490ea7751cf74", "url": "https://github.com/apache/druid/commit/172cff7904038e2b700ca427cad490ea7751cf74", "message": "add more uts", "committedDate": "2021-01-17T05:39:56Z", "type": "commit"}, {"oid": "57811be4b6fb66a4cfe7e32267a5730bb7e57e48", "url": "https://github.com/apache/druid/commit/57811be4b6fb66a4cfe7e32267a5730bb7e57e48", "message": "fix inner class check", "committedDate": "2021-01-17T06:49:13Z", "type": "commit"}, {"oid": "ff8105c173082116a9d346c6cd3caae44fda42d0", "url": "https://github.com/apache/druid/commit/ff8105c173082116a9d346c6cd3caae44fda42d0", "message": "add IT for kafka ingestion with autoscaler", "committedDate": "2021-01-26T02:39:38Z", "type": "commit"}, {"oid": "05571f7e0a124f3971ecc0716d85d3fb30581d5b", "url": "https://github.com/apache/druid/commit/05571f7e0a124f3971ecc0716d85d3fb30581d5b", "message": "add new IT in groups=kafka-index named testKafkaIndexDataWithWithAutoscaler", "committedDate": "2021-01-26T06:11:02Z", "type": "commit"}, {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e", "url": "https://github.com/apache/druid/commit/f09d3d5d4f8374f29288994c955945cb1e33199e", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks", "committedDate": "2021-01-26T06:16:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk4MTY0OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r556981649", "bodyText": "nit: I see that concept of storing lag stats in ArrayList<Long> predates your PR, it might be simpler to define a new class like and change to..... and make related changes in other places where this ArrayList is used\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              protected abstract void collectLag(ArrayList<Long> lags);\n          \n          \n            \n              protected abstract LagStats computeLagStats();\n          \n          \n            \n              \n          \n          \n            \n              static class LagStats\n          \n          \n            \n              {\n          \n          \n            \n                private final long maxLag;\n          \n          \n            \n                private final long totalLag;\n          \n          \n            \n                private final long avgLag;\n          \n          \n            \n            \n          \n          \n            \n                public LagStats(long maxLag, long totalLag, long avgLag)\n          \n          \n            \n                {\n          \n          \n            \n                  this.maxLag = maxLag;\n          \n          \n            \n                  this.totalLag = totalLag;\n          \n          \n            \n                  this.avgLag = avgLag;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public long getMaxLag()\n          \n          \n            \n                {\n          \n          \n            \n                  return maxLag;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public long getTotalLag()\n          \n          \n            \n                {\n          \n          \n            \n                  return totalLag;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public long getAvgLag()\n          \n          \n            \n                {\n          \n          \n            \n                  return avgLag;\n          \n          \n            \n                }\n          \n          \n            \n              }", "author": "himanshug", "createdAt": "2021-01-14T01:16:30Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3561,4 +3874,11 @@ protected void emitLag()\n    * sequences. In Kafka, start offsets are always inclusive.\n    */\n   protected abstract boolean useExclusiveStartSequenceNumberForNonFirstSequence();\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  protected abstract void collectLag(ArrayList<Long> lags);", "originalCommit": "4a0d706626ab82ac438cb4c7c3ba89b4b94e653b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk3NDA4MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569974080", "bodyText": "Nice idea. Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:24:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk4MTY0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ2NzQzNg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r561467436", "bodyText": "can this be added as default impl in SupervisorSpec interface?", "author": "himanshug", "createdAt": "2021-01-21T02:01:04Z", "path": "extensions-contrib/materialized-view-maintenance/src/main/java/org/apache/druid/indexing/materializedview/MaterializedViewSupervisorSpec.java", "diffHunk": "@@ -361,6 +362,12 @@ public Supervisor createSupervisor()\n     );\n   }\n \n+  @Override\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    return null;\n+  }\n+", "originalCommit": "57811be4b6fb66a4cfe7e32267a5730bb7e57e48", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk3NDEzOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569974139", "bodyText": "changed.", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:24:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ2NzQzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNTc5OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568235798", "bodyText": "At this time, I think this is very specific to KafkaSupervisor and it seems that currently we only want to support autoscaling for kafka indexing , so I would say in this PR, we rename DefaultAutoScaler to KafkaIndexingDefaultAutoScaler and let KafkaIndexingDefaultAutoScaler cast Supervisor to KafkaSupervisor so as to use KafkaSupervisor.collectLag(..) directly and not have it in the interface.\nIf, at a later time, Kinesis starts using it in some form, then Supervisor interface can be modified at that time.", "author": "himanshug", "createdAt": "2021-02-02T00:25:16Z", "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +66,18 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  void collectLag(ArrayList<Long> lags);", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk3OTkxNg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569979916", "bodyText": "Ya, for now, we only support Kafka autoScaler. But based on \n  \n    \n      druid/indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java\n    \n    \n         Line 3499\n      in\n      118b501\n    \n    \n    \n    \n\n        \n          \n           Map<PartitionIdType, Long> partitionTimeLags = getPartitionTimeLag(); \n        \n    \n  \n\n It   may be not hard to support kinesis autoscaler. And I'm glad to work on it soon. So maybe keep the code abstract is more meaningful and there are plenty preparation to ensure that users will not set kinesis auto scale by accident:\n\nDocs mention\nthrow new UnsupportedOperationException(\"Tasks auto scaler for kinesis is not supported yet. Please remove autoscalerConfig or set it null!\"); in KinesisSupervisorIOConfig\nset autoscalerConfig = null when super(xxx) in KinesisSupervisorIOConfig\n\nAlso we can't cast Supervisor to KafkaSupervisor directly unless add an extra dependency druid-kafka-indexing-service in indexing-service module.", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:40:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNTc5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNjUyNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568236524", "bodyText": "can we instead have void reconcileTaskCount() which looks at current task count in the io config, and does things to match that many number of active tasks.\nautoscale impl would be responsible for updating the task count in task io config and then calling this method.", "author": "himanshug", "createdAt": "2021-02-02T00:27:10Z", "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +66,18 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  void collectLag(ArrayList<Long> lags);\n+\n+  /**\n+   * use for autoscaler\n+   */\n+  Runnable buildDynamicAllocationTask(Callable<Integer> scaleAction);", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk4MDk4MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569980981", "bodyText": "Nice catch! I review the code and find out there is no need for this buildDynamicAllocationTask  method in Supervisor.java and autoscaler can build autoscale notice itself and supervisor will do scale action.\nSo I removed buildDynamicAllocationTask func in Supervisor.java", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:43:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNjUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNzE4Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568237183", "bodyText": "seems we only really need the active task group count, so, can we have int getActiveTaskGroupsCount() instead ?", "author": "himanshug", "createdAt": "2021-02-02T00:28:07Z", "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +66,18 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  void collectLag(ArrayList<Long> lags);\n+\n+  /**\n+   * use for autoscaler\n+   */\n+  Runnable buildDynamicAllocationTask(Callable<Integer> scaleAction);\n+\n+  Map getSupervisorTaskInfos();", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk4MTAzNg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569981036", "bodyText": "Sure. Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNzE4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzODE0Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568238143", "bodyText": "these should throw UnSupportedOperationException instead as they are not supposed to be called", "author": "himanshug", "createdAt": "2021-02-02T00:30:43Z", "path": "extensions-contrib/materialized-view-maintenance/src/main/java/org/apache/druid/indexing/materializedview/MaterializedViewSupervisor.java", "diffHunk": "@@ -282,6 +283,23 @@ public void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata)\n     // do nothing\n   }\n \n+  @Override\n+  public void collectLag(ArrayList<Long> lags)\n+  {\n+  }\n+\n+  @Override\n+  public Runnable buildDynamicAllocationTask(Callable<Integer> scaleAction)\n+  {\n+    return null;\n+  }\n+\n+  @Override\n+  public Map getSupervisorTaskInfos()\n+  {\n+    return null;\n+  }\n+", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk4MTExMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569981110", "bodyText": "Sure. Done.", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:44:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzODE0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzODcxMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568238710", "bodyText": "we should actually throw exception if someone sets this on a kinesis supervisor spec ... as that is not expected.", "author": "himanshug", "createdAt": "2021-02-02T00:32:31Z", "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorIOConfig.java", "diffHunk": "@@ -70,6 +72,7 @@ public KinesisSupervisorIOConfig(\n       @JsonProperty(\"fetchDelayMillis\") Integer fetchDelayMillis,\n       @JsonProperty(\"awsAssumedRoleArn\") String awsAssumedRoleArn,\n       @JsonProperty(\"awsExternalId\") String awsExternalId,\n+      @JsonProperty(\"dynamicAllocationTasksProperties\") Map<String, Object> dynamicAllocationTasksProperties,", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAxNDMwOA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570014308", "bodyText": "Sure. Done.", "author": "zhangyue19921010", "createdAt": "2021-02-04T07:59:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzODcxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0NTY1MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568245651", "bodyText": "could we instead get a handle to SupervisorTaskAutoscaler and have SupervisorTaskAutoscaler.getMaxTaskCount() provide maximum task count ?", "author": "himanshug", "createdAt": "2021-02-02T00:49:30Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -519,20 +636,40 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk4Mzg3MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569983870", "bodyText": "Sure, It is a little strange that use map.getOrDefault() here, because default value is hard to be unified.\nI modified the way of obtaining configurations from Map to new interface AutoScalerConfig with a default impl DefaultAutoScaleConfig. So that we can use JackSon to Instantiate a Config with default values instead of map.get/parse everywhere. Also ensure consistency of default values.\nIn this way, we don't need to get a handle to SupervisorTaskAutoscaler, just autoScalerConfig.getTaskCountMax() :)", "author": "zhangyue19921010", "createdAt": "2021-02-04T06:51:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0NTY1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0Nzk0NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568247944", "bodyText": "this type of logic should live inside the autoscaler impl I think which should decide when to trigger the autoscaling", "author": "himanshug", "createdAt": "2021-02-02T00:56:01Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +322,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk4ODAwOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r569988009", "bodyText": "Thanks for your attention.\nActually, there are three hard conditions before do scale action:\n\nDon't scale when supervisor is suspended.\nDon't scale when previous task is handing off to avoid inconsistent state.\nDon't scale durning cool down time to avoid overly frequent scaling.\n\nAnd I think no matter what the task type is, no matter what the autoscaler impl is, it maybe better to follow these three common conditions.\nAlso users can define their own conditions like TaskCountLimitation in specific impl :)", "author": "zhangyue19921010", "createdAt": "2021-02-04T07:01:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0Nzk0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTE2Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568249166", "bodyText": "I am not sure why we need extra property enableDynamicAllocationTasks, if user added a non-null dynamicAllocationTasksProperties that alone should mean that user wanted to enable autoscaling.", "author": "himanshug", "createdAt": "2021-02-02T00:59:31Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +156,29 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    String dataSource = getId();\n+    SupervisorTaskAutoscaler autoScaler = new DummyAutoScaler(supervisor, dataSource);\n+    Map<String, Object> dynamicAllocationTasksProperties = ingestionSchema.getIOConfig().getDynamicAllocationTasksProperties();\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAwMjIzNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570002234", "bodyText": "The reason for designing this condition is that users can disable/enable autoscaler for a while easily using this config rather than delete all the autoscaler-related configs.\nFor examples, advertising business in Super Bowl. Traffic is much higher during the break time and lower durning Gaming(Large traffic fluctuations in the short term). If users don't set scale-related configs properly, it will trigger scale action too frequently and creates lots of small segments.\nTraffic like this we usually set a larger number of tasks temporarily and set it false to disable autoscaler for a while.\nAlso when scale algorithms become more advanced, it is better to remove this config and let autoscaler to do everything. But for now maybe it would be better if we keep this parameter :)", "author": "zhangyue19921010", "createdAt": "2021-02-04T07:35:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTE2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTUyOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568249529", "bodyText": "can we create the autoscaler instance using jackson ... i.e. something like jsonMapper.readValueFrom...()", "author": "himanshug", "createdAt": "2021-02-02T01:00:29Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +156,29 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    String dataSource = getId();\n+    SupervisorTaskAutoscaler autoScaler = new DummyAutoScaler(supervisor, dataSource);\n+    Map<String, Object> dynamicAllocationTasksProperties = ingestionSchema.getIOConfig().getDynamicAllocationTasksProperties();\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      String autoScalerStrategy = String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"autoScalerStrategy\", \"default\"));\n+\n+      // will thorw 'Return value of String.hashCode() ignored : RV_RETURN_VALUE_IGNORED' just Suppress it.\n+      switch (StringUtils.toLowerCase(autoScalerStrategy)) {\n+        default: autoScaler = new DefaultAutoScaler(supervisor, dataSource, dynamicAllocationTasksProperties, this);\n+      }", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAwNDM0Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570004346", "bodyText": "Nice catch!  I modified the way of obtaining configurations using Jackson like I mentioned above.\nIn this way, Users can not only defined their own scale algorithms, but also can build corresponding configuration.\nAlso it is easier to ensure consistency of default values. We don't need to do map.get/parse work anymore.\nAssupervisor instance is newed in Druid everywhere. Is it necessary to create the autoscaler using Jackson which hold supervisor instance ? \ud83e\udd15", "author": "zhangyue19921010", "createdAt": "2021-02-04T07:39:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTUyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTgwMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568249800", "bodyText": "not sure if we need this, if user added dynamicAllocationTasksProperties  section in the supervisor spec, that alone should be enough to enable autoscaling?", "author": "himanshug", "createdAt": "2021-02-02T01:01:26Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`dynamicAllocationTasksProperties`|Object|`dynamicAllocationTasksProperties` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. See [Dynamic Allocation Tasks Properties](#Dynamic Allocation Tasks Properties) for details.|no (default == null)|\n+\n+#### Dynamic Allocation Tasks Properties\n+\n+| Property | Description | Default |\n+| ------------- | ------------- | ------------- |\n+| `enableDynamicAllocationTasks` | whether enable this feature or not | false |", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAxMzMxMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570013313", "bodyText": "like I mentioned above. This is an insurance and compromise. Current algorithms is relatively simple while can meet most scenarios(for examples regular traffic peak/sudden traffic peak).\nBut for extreme cases, if users don't set scale-related configs properly, it will trigger scale action too frequently and creates lots of small segments. At this time, the user needs to manually control taskCount and this config can make disable/enable work more convenient.\nWhen the algorithm is smart enough, It is better to remove this parameter.\nAs for default value false, I think it is the insurance to prevent users to enable autoscaler by accident like left \"autoscalerConfig\": {} after deleted all the autoscaler related configs.", "author": "zhangyue19921010", "createdAt": "2021-02-04T07:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTgwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDE2Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568250163", "bodyText": "I think autoscaling better describes this feature , so maybe call it autoscalerConfig", "author": "himanshug", "createdAt": "2021-02-02T01:02:33Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`dynamicAllocationTasksProperties`|Object|`dynamicAllocationTasksProperties` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. See [Dynamic Allocation Tasks Properties](#Dynamic Allocation Tasks Properties) for details.|no (default == null)|", "originalCommit": "f09d3d5d4f8374f29288994c955945cb1e33199e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDM5Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r568250397", "bodyText": "be very specific that this is  ONLY supported for kafka indexing as of now.", "author": "himanshug", "createdAt": "2021-02-02T01:03:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDE2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDAxMzUwMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570013500", "bodyText": "Make sense. Changed", "author": "zhangyue19921010", "createdAt": "2021-02-04T07:58:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDE2Mw=="}], "type": "inlineReview"}, {"oid": "e66d5d20428d39e0d71ae68a41c668d7e2d508a2", "url": "https://github.com/apache/druid/commit/e66d5d20428d39e0d71ae68a41c668d7e2d508a2", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks", "committedDate": "2021-02-02T05:05:10Z", "type": "commit"}, {"oid": "87a694ad10daa29b8934599a05e35bdbfea14059", "url": "https://github.com/apache/druid/commit/87a694ad10daa29b8934599a05e35bdbfea14059", "message": "review change", "committedDate": "2021-02-02T07:28:01Z", "type": "commit"}, {"oid": "71bdfbbad7c8ff87de78d388dd65c2a25903ca3e", "url": "https://github.com/apache/druid/commit/71bdfbbad7c8ff87de78d388dd65c2a25903ca3e", "message": "code review", "committedDate": "2021-02-02T07:49:58Z", "type": "commit"}, {"oid": "96025755975a2de106d7a9aa1930d48b17bc25b6", "url": "https://github.com/apache/druid/commit/96025755975a2de106d7a9aa1930d48b17bc25b6", "message": "remove unused imports", "committedDate": "2021-02-02T09:10:02Z", "type": "commit"}, {"oid": "6bbbf297d1ab84b675d07108f554bd765206ff08", "url": "https://github.com/apache/druid/commit/6bbbf297d1ab84b675d07108f554bd765206ff08", "message": "fix NLP", "committedDate": "2021-02-02T10:23:52Z", "type": "commit"}, {"oid": "0ae6a34821939049e6cae6312c6f8b796eb4af11", "url": "https://github.com/apache/druid/commit/0ae6a34821939049e6cae6312c6f8b796eb4af11", "message": "fix docs and UTs", "committedDate": "2021-02-03T02:20:38Z", "type": "commit"}, {"oid": "16e4f47421c442851a84c50326d39b3283234094", "url": "https://github.com/apache/druid/commit/16e4f47421c442851a84c50326d39b3283234094", "message": "revert misc.xml", "committedDate": "2021-02-03T02:24:43Z", "type": "commit"}, {"oid": "25fec0ff18d0acb79734dd93bedccff3ab43308a", "url": "https://github.com/apache/druid/commit/25fec0ff18d0acb79734dd93bedccff3ab43308a", "message": "use jackson to build autoScaleConfig with default values", "committedDate": "2021-02-03T11:06:24Z", "type": "commit"}, {"oid": "f0c8d7877590876ac9e1e2277eea7b0cb810ec06", "url": "https://github.com/apache/druid/commit/f0c8d7877590876ac9e1e2277eea7b0cb810ec06", "message": "add uts", "committedDate": "2021-02-03T14:27:30Z", "type": "commit"}, {"oid": "0733590862fa43068e19b15d85dc5507732f7620", "url": "https://github.com/apache/druid/commit/0733590862fa43068e19b15d85dc5507732f7620", "message": "use jackson to init AutoScalerConfig in IOConfig instead of Map<>", "committedDate": "2021-02-03T17:22:19Z", "type": "commit"}, {"oid": "972690294bf199ec0b93d01d5f44e3d9c008720c", "url": "https://github.com/apache/druid/commit/972690294bf199ec0b93d01d5f44e3d9c008720c", "message": " autoscalerConfig interface and provide a defaultAutoScalerConfig", "committedDate": "2021-02-04T04:21:32Z", "type": "commit"}, {"oid": "32fffa955c9ab06ed0a57378e95371e517794f4f", "url": "https://github.com/apache/druid/commit/32fffa955c9ab06ed0a57378e95371e517794f4f", "message": "modify uts", "committedDate": "2021-02-04T05:22:00Z", "type": "commit"}, {"oid": "34c2785dd4973dc1fd34b6739464e228654f4d9f", "url": "https://github.com/apache/druid/commit/34c2785dd4973dc1fd34b6739464e228654f4d9f", "message": "modify docs", "committedDate": "2021-02-04T06:18:57Z", "type": "commit"}, {"oid": "eb95830fe960ab0d28d22103b1d115a874fa04c7", "url": "https://github.com/apache/druid/commit/eb95830fe960ab0d28d22103b1d115a874fa04c7", "message": "fix checkstyle", "committedDate": "2021-02-04T10:56:42Z", "type": "commit"}, {"oid": "7de0f10e7b7a6f802d66983fed928dcf19233049", "url": "https://github.com/apache/druid/commit/7de0f10e7b7a6f802d66983fed928dcf19233049", "message": "revert misc.xml", "committedDate": "2021-02-04T10:57:48Z", "type": "commit"}, {"oid": "ce5945b18155d058f6899ea68db26147c3e03015", "url": "https://github.com/apache/druid/commit/ce5945b18155d058f6899ea68db26147c3e03015", "message": "modify uts", "committedDate": "2021-02-05T02:56:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5MzI3OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570893279", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n          \n          \n            \n               * @return Boolean flag, do scale action successfully or not. If true, it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.", "author": "pjain1", "createdAt": "2021-02-05T11:10:17Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA0Nzg1Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571047852", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:27:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5MzI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5MzY2Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570893662", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n          \n          \n            \n                      log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);", "author": "pjain1", "createdAt": "2021-02-05T11:11:03Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA0Nzk5MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571047991", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:27:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5MzY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NDExMQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570894111", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n          \n          \n            \n                    log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");", "author": "pjain1", "createdAt": "2021-02-05T11:12:00Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA0ODA2Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571048063", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:27:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NDExMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NDg1OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570894859", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n          \n          \n            \n               * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.", "author": "pjain1", "createdAt": "2021-02-05T11:13:35Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA0ODE2MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571048160", "bodyText": "Done.", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:27:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NDg1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NjAyNQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570896025", "bodyText": "We are not checking if desireActiveTaskCount is already equal to currentActiveTaskCount. If they are equal there is nothing to be done.", "author": "pjain1", "createdAt": "2021-02-05T11:15:49Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desireActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desireActiveTaskCount == -1) {\n+      return false;\n+    } else {", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA0ODgxMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571048810", "bodyText": "Nice catch! It is necessary to do this check. Thanks.", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:28:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NjAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA4NjkwNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571086904", "bodyText": "Actually desireActiveTaskCount usually can't be equal to currentActiveTaskCount here. Take scale out as an example :\nHere is the logic of computing desireActiveTaskCount in autoscaler\n      if (currentActiveTaskCount == defaultAutoScalerConfig.getTaskCountMax()) {\n        log.info(\"CurrentActiveTaskCount reach task count Max limit, skip to scale out tasks for dataSource [%s].\", dataSource);\n        return -1;\n      } else {\n        desiredActiveTaskCount = Math.min(taskCount, defaultAutoScalerConfig.getTaskCountMax());\n      }\n\nCondition 1: int taskCount = currentActiveTaskCount + defaultAutoScalerConfig.getScaleOutStep()\nCondition 2: currentActiveTaskCount != defaultAutoScalerConfig.getTaskCountMax() otherwise will return -1.\nCondition 3: desiredActiveTaskCount = Math.min(taskCount, defaultAutoScalerConfig.getTaskCountMax())\nCondition 4: defaultAutoScalerConfig.getScaleOutStep() > 0\n=>  get Condition5 based on Condition 1 and Condition 3: desiredActiveTaskCount = Math.min(currentActiveTaskCount + defaultAutoScalerConfig.getScaleOutStep(), defaultAutoScalerConfig.getTaskCountMax())\nAssume desireActiveTaskCount == currentActiveTaskCount\nCombine with Condition 4, 5 and assumption => we can get desiredActiveTaskCount == defaultAutoScalerConfig.getTaskCountMax()\nThen based on Condition 2 => We can get currentActiveTaskCount != desiredActiveTaskCount\nThis conclusion conflicts with the assumption, so the assumption does not hold.\nSo that desireActiveTaskCount can't be equal to currentActiveTaskCount here\nUNLESS! Users set defaultAutoScalerConfig.getScaleOutStep() = 0 by mistake.\nSo I changed the code as you suggested to avoid this scenario.\nThanks for your suggestion!", "author": "zhangyue19921010", "createdAt": "2021-02-05T16:21:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NjAyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDkxMDc0OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r570910749", "bodyText": "I think we should first update the count in metadata and then clear the allocation info. What if the database update fails then its not good to clear the allocation info.", "author": "pjain1", "createdAt": "2021-02-05T11:43:35Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desireActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desireActiveTaskCount == -1) {\n+      return false;\n+    } else {\n+      log.debug(\"Start to scale action tasks, current active task number [%s] and desire task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desireActiveTaskCount, dataSource);\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA0OTA3MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571049070", "bodyText": "Make sense. Changed!", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:28:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDkxMDc0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTAwNTcxMg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571005712", "bodyText": "desireActiveTaskCount -> desiredActiveTaskCount", "author": "pjain1", "createdAt": "2021-02-05T14:29:46Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desireActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException", "originalCommit": "ce5945b18155d058f6899ea68db26147c3e03015", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTA1MTYzNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r571051634", "bodyText": "All changed.", "author": "zhangyue19921010", "createdAt": "2021-02-05T15:31:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTAwNTcxMg=="}], "type": "inlineReview"}, {"oid": "85660b7614a43de30b1859f0e275213b7e1e2343", "url": "https://github.com/apache/druid/commit/85660b7614a43de30b1859f0e275213b7e1e2343", "message": "reviewed code change", "committedDate": "2021-02-05T15:23:49Z", "type": "commit"}, {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "url": "https://github.com/apache/druid/commit/feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "message": "reviewed code change", "committedDate": "2021-02-05T15:30:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDEwMDgzOA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580100838", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |`autoscalerConfig`|Object|`autoscalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Tasks Autoscaler Properties) for details.|no (default == null)|\n          \n          \n            \n            \n          \n          \n            \n            #### Tasks Autoscaler Properties\n          \n          \n            \n            \n          \n          \n            \n            | Property | Description | Default |\n          \n          \n            \n            | ------------- | ------------- | ------------- |\n          \n          \n            \n            | `enableTaskAutoscaler` | whether enable this feature or not. Set false or ignored here will disable `autoscaler` even though `autoscalerConfig` is not null| false |\n          \n          \n            \n            | `metricsCollectionIntervalMillis` | Define the frequency of lag points collection.  | 30000 |\n          \n          \n            \n            | `metricsCollectionRangeMillis` | The total time window of lag collection, Use with `metricsCollectionIntervalMillis`\uff0cit means that in the recent `metricsCollectionRangeMill`, collect lag metric points every `metricsCollectionIntervalMillis`. | 600000 |\n          \n          \n            \n            | `scaleOutThreshold` | The Threshold of scale out action | 6000000 |\n          \n          \n            \n            | `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | 0.3 |\n          \n          \n            \n            | `scaleInThreshold` | The Threshold of scale in action | 1000000 |\n          \n          \n            \n            | `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | 0.9 |\n          \n          \n            \n            | `dynamicCheckStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | 300000 |\n          \n          \n            \n            | `dynamicCheckPeriod` | the frequency of checking whether to do scale action | 60000 |\n          \n          \n            \n            |`autoscalerConfig`|Object|`autoscalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#task-autoscaler-properties) for details.|no (default == null)|\n          \n          \n            \n            \n          \n          \n            \n            ### Task Autoscaler Properties\n          \n          \n            \n            \n          \n          \n            \n            | Property | Description | Default |\n          \n          \n            \n            | ------------- | ------------- | ------------- |\n          \n          \n            \n            | `enableTaskAutoscaler` | Whether enable this feature or not. Not setting ot setting to false will disable `autoscaler` even though `autoscalerConfig` is not null| false |\n          \n          \n            \n            | `metricsCollectionIntervalMillis` | Define the frequency of lag points collection.  | 30000 |\n          \n          \n            \n            | `metricsCollectionRangeMillis` | The total time window of lag collection, Use with `metricsCollectionIntervalMillis`\uff0cit means that in the recent `metricsCollectionRangeMillis`, collect lag metric points every `metricsCollectionIntervalMillis`. | 600000 |\n          \n          \n            \n            | `scaleOutThreshold` | The Threshold of scale out action | 6000000 |\n          \n          \n            \n            | `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | 0.3 |\n          \n          \n            \n            | `scaleInThreshold` | The Threshold of scale in action | 1000000 |\n          \n          \n            \n            | `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | 0.9 |\n          \n          \n            \n            | `dynamicCheckStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | 300000 |\n          \n          \n            \n            | `dynamicCheckPeriod` | The frequency of checking whether to do scale action in millis | 60000 |", "author": "pjain1", "createdAt": "2021-02-22T09:33:09Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoscalerConfig`|Object|`autoscalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Tasks Autoscaler Properties) for details.|no (default == null)|\n+\n+#### Tasks Autoscaler Properties\n+\n+| Property | Description | Default |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoscaler` | whether enable this feature or not. Set false or ignored here will disable `autoscaler` even though `autoscalerConfig` is not null| false |\n+| `metricsCollectionIntervalMillis` | Define the frequency of lag points collection.  | 30000 |\n+| `metricsCollectionRangeMillis` | The total time window of lag collection, Use with `metricsCollectionIntervalMillis`\uff0cit means that in the recent `metricsCollectionRangeMill`, collect lag metric points every `metricsCollectionIntervalMillis`. | 600000 |\n+| `scaleOutThreshold` | The Threshold of scale out action | 6000000 |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | 0.3 |\n+| `scaleInThreshold` | The Threshold of scale in action | 1000000 |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | 0.9 |\n+| `dynamicCheckStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | 300000 |\n+| `dynamicCheckPeriod` | the frequency of checking whether to do scale action | 60000 |", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc4OTM5Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580789397", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:11:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDEwMDgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDEwNTM0Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580105343", "bodyText": "what is this used for ? lets move this to parent pom as done for other dependencies and just declare it here.", "author": "pjain1", "createdAt": "2021-02-22T09:39:37Z", "path": "indexing-service/pom.xml", "diffHunk": "@@ -62,7 +62,11 @@\n             <artifactId>druid-hll</artifactId>\n             <version>${project.parent.version}</version>\n         </dependency>\n-\n+        <dependency>", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc4OTkzMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580789933", "bodyText": "Used for  private final CircularFifoQueue<Long> lagMetricsQueue; to collect lag points. Moved this to parent pom.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDEwNTM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDE5NDMzMQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580194331", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.info(\"enableTaskAutoscaler for datasource [%s]\", dataSource);\n          \n          \n            \n                  log.info(\"Running Task autoscaler for datasource [%s]\", dataSource);", "author": "pjain1", "createdAt": "2021-02-22T11:58:34Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -519,20 +635,42 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.autoScalerConfig = ioConfig.getAutoscalerConfig();\n     this.tuningConfig = spec.getTuningConfig();\n     this.taskTuningConfig = this.tuningConfig.convertToTaskTuningConfig();\n     this.supervisorId = supervisorId;\n     this.exec = Execs.singleThreaded(StringUtils.encodeForFormat(supervisorId));\n     this.scheduledExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Scheduler-%d\");\n     this.reportingExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Reporting-%d\");\n+\n     this.stateManager = new SeekableStreamSupervisorStateManager(\n         spec.getSupervisorStateManagerConfig(),\n         spec.isSuspended()\n     );\n \n-    int workerThreads = (this.tuningConfig.getWorkerThreads() != null\n-                         ? this.tuningConfig.getWorkerThreads()\n-                         : Math.min(10, this.ioConfig.getTaskCount()));\n+    int workerThreads;\n+    int chatThreads;\n+    if (autoScalerConfig != null && autoScalerConfig.getEnableTaskAutoscaler()) {\n+      log.info(\"enableTaskAutoscaler for datasource [%s]\", dataSource);", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc4OTk3OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580789978", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDE5NDMzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDE5NDY3Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580194673", "bodyText": "IMO this log is not required as this is the default behaviour", "author": "pjain1", "createdAt": "2021-02-22T11:59:07Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -519,20 +635,42 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.autoScalerConfig = ioConfig.getAutoscalerConfig();\n     this.tuningConfig = spec.getTuningConfig();\n     this.taskTuningConfig = this.tuningConfig.convertToTaskTuningConfig();\n     this.supervisorId = supervisorId;\n     this.exec = Execs.singleThreaded(StringUtils.encodeForFormat(supervisorId));\n     this.scheduledExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Scheduler-%d\");\n     this.reportingExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Reporting-%d\");\n+\n     this.stateManager = new SeekableStreamSupervisorStateManager(\n         spec.getSupervisorStateManagerConfig(),\n         spec.isSuspended()\n     );\n \n-    int workerThreads = (this.tuningConfig.getWorkerThreads() != null\n-                         ? this.tuningConfig.getWorkerThreads()\n-                         : Math.min(10, this.ioConfig.getTaskCount()));\n+    int workerThreads;\n+    int chatThreads;\n+    if (autoScalerConfig != null && autoScalerConfig.getEnableTaskAutoscaler()) {\n+      log.info(\"enableTaskAutoscaler for datasource [%s]\", dataSource);\n+\n+      workerThreads = (this.tuningConfig.getWorkerThreads() != null\n+              ? this.tuningConfig.getWorkerThreads()\n+              : Math.min(10, autoScalerConfig.getTaskCountMax()));\n+\n+      chatThreads = (this.tuningConfig.getChatThreads() != null\n+              ? this.tuningConfig.getChatThreads()\n+              : Math.min(10, autoScalerConfig.getTaskCountMax() * this.ioConfig.getReplicas()));\n+    } else {\n+      log.info(\"Disable dynamic allocate tasks for [%s]\", dataSource);", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc4OTk5NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580789994", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDE5NDY3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwMjExNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580202114", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  try {\n          \n          \n            \n                    long nowTime = System.currentTimeMillis();\n          \n          \n            \n                    // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n          \n          \n            \n                    if (spec.isSuspended()) {\n          \n          \n            \n                      log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n          \n          \n            \n                      return;\n          \n          \n            \n                    }\n          \n          \n            \n                    log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n          \n          \n            \n                    for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n          \n          \n            \n                      if (!list.isEmpty()) {\n          \n          \n            \n                        log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n                    }\n          \n          \n            \n                    if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n          \n          \n            \n                      log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n          \n          \n            \n                      return;\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    Integer desriedTaskCount = scaleAction.call();\n          \n          \n            \n                    boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n          \n          \n            \n            \n          \n          \n            \n                    if (allocationSuccess) {\n          \n          \n            \n                      dynamicTriggerLastRunTime = nowTime;\n          \n          \n            \n                    }\n          \n          \n            \n                  }\n          \n          \n            \n                  catch (Exception ex) {\n          \n          \n            \n                    log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n          \n          \n            \n                  }\n          \n          \n            \n                }\n          \n          \n            \n                  if (autoScalerConfig == null) {\n          \n          \n            \n                    log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n          \n          \n            \n                  } else {\n          \n          \n            \n                    try {\n          \n          \n            \n                      long nowTime = System.currentTimeMillis();\n          \n          \n            \n                      if (spec.isSuspended()) {\n          \n          \n            \n                        log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n          \n          \n            \n                            dataSource\n          \n          \n            \n                        );\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n                      log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n          \n          \n            \n                          dataSource\n          \n          \n            \n                      );\n          \n          \n            \n                      for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n          \n          \n            \n                        if (!list.isEmpty()) {\n          \n          \n            \n                          log.info(\n          \n          \n            \n                              \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n          \n          \n            \n                              dataSource, pendingCompletionTaskGroups\n          \n          \n            \n                          );\n          \n          \n            \n                          return;\n          \n          \n            \n                        }\n          \n          \n            \n                      }\n          \n          \n            \n                      if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n          \n          \n            \n                        log.info(\n          \n          \n            \n                            \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n          \n          \n            \n                            nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource\n          \n          \n            \n                        );\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n            \n          \n          \n            \n                      Integer desriedTaskCount = scaleAction.call();\n          \n          \n            \n                      boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n          \n          \n            \n            \n          \n          \n            \n                      if (allocationSuccess) {\n          \n          \n            \n                        dynamicTriggerLastRunTime = nowTime;\n          \n          \n            \n                      }\n          \n          \n            \n                    } catch (Exception ex) {\n          \n          \n            \n                      log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n          \n          \n            \n                    }\n          \n          \n            \n                  }", "author": "pjain1", "createdAt": "2021-02-22T12:11:55Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc5MDAwNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580790007", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwMjExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwNzExMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580207110", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n          \n          \n            \n               *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n          \n          \n            \n               *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n          \n          \n            \n               * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n          \n          \n            \n               * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n          \n          \n            \n               * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n          \n          \n            \n               *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n          \n          \n            \n               *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n          \n          \n            \n               *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuild in the next 'RunNotice'.\n          \n          \n            \n               *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n          \n          \n            \n               * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n          \n          \n            \n               * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n          \n          \n            \n               * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n          \n          \n            \n               *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod' millis.", "author": "pjain1", "createdAt": "2021-02-22T12:20:27Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc5MDAyMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580790023", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwNzExMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwNzY0OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580207649", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.debug(\"Start to scale action tasks, current active task number [%s] and desired task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desiredActiveTaskCount, dataSource);\n          \n          \n            \n                  log.debug(\n          \n          \n            \n                      \"Starting scale action, current active task count is [%d] and desired task count is [%d] for dataSource [%s].\",\n          \n          \n            \n                      currentActiveTaskCount, desiredActiveTaskCount, dataSource\n          \n          \n            \n                  );", "author": "pjain1", "createdAt": "2021-02-22T12:21:22Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n+      return false;\n+    } else {\n+      log.debug(\"Start to scale action tasks, current active task number [%s] and desired task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desiredActiveTaskCount, dataSource);", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc5MDAyOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580790029", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwNzY0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwODI4Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580208287", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.warn(\"supervisorManager is null in taskMaster, skip to do scale action for dataSource [%s].\", dataSource);\n          \n          \n            \n                    log.warn(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);", "author": "pjain1", "createdAt": "2021-02-22T12:22:23Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n+      return false;\n+    } else {\n+      log.debug(\"Start to scale action tasks, current active task number [%s] and desired task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desiredActiveTaskCount, dataSource);\n+      gracefulShutdownInternal();\n+      changeTaskCountInIOConfig(desiredActiveTaskCount);\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Changed taskCount to [%s] for dataSource [%s].\", desiredActiveTaskCount, dataSource);\n+      return true;\n+    }\n+  }\n+\n+  private void changeTaskCountInIOConfig(int desiredActiveTaskCount)\n+  {\n+    ioConfig.setTaskCount(desiredActiveTaskCount);\n+    try {\n+      Optional<SupervisorManager> supervisorManager = taskMaster.getSupervisorManager();\n+      if (supervisorManager.isPresent()) {\n+        MetadataSupervisorManager metadataSupervisorManager = supervisorManager.get().getMetadataSupervisorManager();\n+        metadataSupervisorManager.insert(dataSource, spec);\n+      } else {\n+        log.warn(\"supervisorManager is null in taskMaster, skip to do scale action for dataSource [%s].\", dataSource);", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc5MDA0Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580790047", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwODI4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIxMDg3OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580210879", "bodyText": "Not sure what you mean by fill in 'lags'\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * This method compute maxLag, totalLag and avgLag then fill in 'lags'\n          \n          \n            \n               * This method computes maxLag, totalLag and avgLag", "author": "pjain1", "createdAt": "2021-02-22T12:27:03Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3543,6 +3682,24 @@ protected void emitLag()\n     }\n   }\n \n+\n+  /**\n+   * This method compute maxLag, totalLag and avgLag then fill in 'lags'", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc5MDA4MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580790081", "bodyText": "Thanks && Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:13:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIxMDg3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIzMTU0NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580231544", "bodyText": "if by mistake one submits autoScalerConfig for kinesis supervisor then seems like DefaultAutoScaler  is created for kinesis also ?", "author": "pjain1", "createdAt": "2021-02-22T13:01:05Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +157,37 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    String dataSource = getId();\n+    SupervisorTaskAutoscaler autoScaler = new DummyAutoScaler(supervisor, dataSource);\n+    AutoScalerConfig autoScalerConfig = ingestionSchema.getIOConfig().getAutoscalerConfig();\n+\n+    // kinesis'autoscalerConfig is always null for now, So that kinesis will hold a DummyAutoScaler.\n+    // only SeekableStreamSupervisor is supported here.\n+    if (autoScalerConfig != null", "originalCommit": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIzMzg3Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580233876", "bodyText": "I see null is being passed from KinesisSupervisorIOConfig so it will be null", "author": "pjain1", "createdAt": "2021-02-22T13:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIzMTU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDI4MDYzNg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580280636", "bodyText": "reviewed till here", "author": "pjain1", "createdAt": "2021-02-22T14:14:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIzMTU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDc5MDMwNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r580790307", "bodyText": "Thanks.", "author": "zhangyue19921010", "createdAt": "2021-02-23T06:14:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIzMTU0NA=="}], "type": "inlineReview"}, {"oid": "b6632d6c713f2bf87905de0ebb83756d3716edeb", "url": "https://github.com/apache/druid/commit/b6632d6c713f2bf87905de0ebb83756d3716edeb", "message": "code reviewed", "committedDate": "2021-02-23T06:07:26Z", "type": "commit"}, {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "url": "https://github.com/apache/druid/commit/688b9c4b4ff1841477d8139a7c83e54d36ccb986", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks", "committedDate": "2021-02-23T06:09:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxMzQ4MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581913481", "bodyText": "The way autoScaler instance is created here does not support custom autoScaler implementation in extensions as switch statement is used to create the instance. If a new strategy is implemented for autoScaler in an extension, this class needs to be changed to support it which is not ideal as its a change in core Druid. I have raised a PR on your branch on how we can fix this - zhangyue19921010#1\nThe changes are -\n\nAdd SupervisorTaskAutoScaler createAutoScaler(Supervisor supervisor, SupervisorSpec spec); method in AutoScalerConfig that will be called from SeekableStreamSupervisorSpec to create autoScaler.\nI don't think getAutoScalerStrategy method is needed in AutoScalerConfig as implementation of AutoScalerConfig can return instance of AutoScaler directly on call to createAutoScaler.", "author": "pjain1", "createdAt": "2021-02-24T12:21:35Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +157,37 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NDA3MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582664070", "bodyText": "Nice Coding! changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:13:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxMzQ4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxMzkxMg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581913912", "bodyText": "This is not required as mentioned above and add another method to create auto scaler as mentioned in above comment.", "author": "pjain1", "createdAt": "2021-02-24T12:22:15Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/AutoScalerConfig.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n+import com.fasterxml.jackson.annotation.JsonTypeInfo;\n+import org.apache.druid.guice.annotations.UnstableApi;\n+\n+@UnstableApi\n+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"autoScalerStrategy\", defaultImpl = DefaultAutoScalerConfig.class)\n+@JsonSubTypes(value = {\n+        @Type(name = \"default\", value = DefaultAutoScalerConfig.class)\n+})\n+public interface AutoScalerConfig\n+{\n+  boolean getEnableTaskAutoscaler();\n+  long getMinTriggerDynamicFrequencyMillis();\n+  String getAutoScalerStrategy();", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NDEwNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582664104", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:13:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxMzkxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNDc2Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581914767", "bodyText": "I think we should change the name of this to LagBasedAutoScalerConfig as it is using lag to make decisions about auto scaling. Also we should not use default as type names as it is confusing. See zhangyue19921010#1", "author": "pjain1", "createdAt": "2021-02-24T12:23:42Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/AutoScalerConfig.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n+import com.fasterxml.jackson.annotation.JsonTypeInfo;\n+import org.apache.druid.guice.annotations.UnstableApi;\n+\n+@UnstableApi\n+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"autoScalerStrategy\", defaultImpl = DefaultAutoScalerConfig.class)\n+@JsonSubTypes(value = {\n+        @Type(name = \"default\", value = DefaultAutoScalerConfig.class)", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NDE5Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582664193", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:13:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNDc2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNTkwNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581915904", "bodyText": "See https://github.com/zhangyue19921010/druid/pull/1/files#diff-f1b33808bb841d1e71e1f5ec3fbaeb3f94899066277b75e192942b66371667ce for suggestions on log lines, method and variable names.", "author": "pjain1", "createdAt": "2021-02-24T12:25:31Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DefaultAutoScaler.java", "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class DefaultAutoScaler implements SupervisorTaskAutoscaler", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NDI1Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582664256", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:13:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNTkwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNjQ3OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581916478", "bodyText": "not sure why we are encoding supervisorId, its already a constant string from line 56. Not sure why this is needed.", "author": "pjain1", "createdAt": "2021-02-24T12:26:31Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DefaultAutoScaler.java", "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class DefaultAutoScaler implements SupervisorTaskAutoscaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(DefaultAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final DefaultAutoScalerConfig defaultAutoScalerConfig;\n+\n+  private static ReentrantLock lock = new ReentrantLock(true);\n+\n+\n+  public DefaultAutoScaler(Supervisor supervisor, String dataSource, AutoScalerConfig autoScalerConfig, SupervisorSpec spec)\n+  {\n+    this.defaultAutoScalerConfig = (DefaultAutoScalerConfig) autoScalerConfig;\n+    String supervisorId = StringUtils.format(\"KafkaSupervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    int slots = (int) (defaultAutoScalerConfig.getMetricsCollectionRangeMillis() / defaultAutoScalerConfig.getMetricsCollectionIntervalMillis()) + 1;\n+    log.debug(\" The interval of metrics collection is [%s], [%s] timeRange will collect [%s] data points for dataSource [%s].\", defaultAutoScalerConfig.getMetricsCollectionIntervalMillis(), defaultAutoScalerConfig.getMetricsCollectionRangeMillis(), slots, dataSource);\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NDY4OA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582664688", "bodyText": "no need actually, removed. Thanks.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:14:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNjQ3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjkwNzYwMQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582907601", "bodyText": "Sorry. I just found it is necessary to do encoding for supervisorId.\nIf supervisorID itself contains special characters %s like \"dataSource\": \"kafka_transactional_parallelized_indexing_service_test_2ec894f4-3bb4-4909-91ca-8f934e14bc84 %\u0420\u043e\u0441\u0441\u0438\u044f \ud55c\uad6d \u4e2d\u56fd!?\" mentioned in Job 41, It will throw Caused by: java.util.UnknownFormatConversionException: Conversion = &apos;?&apos; exception without encoding(https://travis-ci.com/github/apache/druid/jobs/486176708)\nSo I revert this change here.", "author": "zhangyue19921010", "createdAt": "2021-02-25T15:05:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNjQ3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNzYzOA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581917638", "bodyText": "See https://github.com/zhangyue19921010/druid/pull/1/files#diff-943c4b0695e902cb2a3465b69f593a584dac7308037288db0f9fd97054efb12b for suggestions on log lines, method and variable names.", "author": "pjain1", "createdAt": "2021-02-24T12:28:14Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DefaultAutoScalerConfig.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import javax.annotation.Nullable;\n+\n+public class DefaultAutoScalerConfig implements AutoScalerConfig", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NDc1NQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582664755", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:14:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNzYzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODAzOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581918039", "bodyText": "I think we can call this NoopAutoScaler.", "author": "pjain1", "createdAt": "2021-02-24T12:28:53Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DummyAutoScaler.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+\n+public class DummyAutoScaler implements SupervisorTaskAutoscaler", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODQzNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581918437", "bodyText": "https://github.com/zhangyue19921010/druid/pull/1/files#diff-0621db18fa2257d0cd499178c842d96ae73df2264038ccc7de23d7a7ed5235a5", "author": "pjain1", "createdAt": "2021-02-24T12:29:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODAzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NjA5MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582666091", "bodyText": "NoopAutoScaler is used for mm autoscale. I just renamed it to NoopTaskAutoScaler :)", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:16:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODAzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODE4MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581918181", "bodyText": "This can be no-arg constructor.", "author": "pjain1", "createdAt": "2021-02-24T12:29:03Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DummyAutoScaler.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+\n+public class DummyAutoScaler implements SupervisorTaskAutoscaler\n+{\n+  public DummyAutoScaler(Supervisor supervisor, String dataSource)", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NjE2Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582666167", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODE4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxOTUyNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581919524", "bodyText": "Variable names will need to be changed here, if these suggestions are implemented -https://github.com/zhangyue19921010/druid/pull/1/files#diff-943c4b0695e902cb2a3465b69f593a584dac7308037288db0f9fd97054efb12b", "author": "pjain1", "createdAt": "2021-02-24T12:31:10Z", "path": "integration-tests/src/test/resources/stream/data/supervisor_with_autoscaler_spec_template.json", "diffHunk": "@@ -0,0 +1,73 @@\n+{\n+  \"type\": \"%%STREAM_TYPE%%\",\n+  \"dataSchema\": {\n+    \"dataSource\": \"%%DATASOURCE%%\",\n+    \"parser\": %%PARSER%%,\n+    \"timestampSpec\": {\n+      \"column\": \"timestamp\",\n+      \"format\": \"auto\"\n+    },\n+    \"dimensionsSpec\": {\n+      \"dimensions\": [\"page\", \"language\", \"user\", \"unpatrolled\", \"newPage\", \"robot\", \"anonymous\", \"namespace\", \"continent\", \"country\", \"region\", \"city\"],\n+      \"dimensionExclusions\": [],\n+      \"spatialDimensions\": []\n+    },\n+    \"metricsSpec\": [\n+      {\n+        \"type\": \"count\",\n+        \"name\": \"count\"\n+      },\n+      {\n+        \"type\": \"doubleSum\",\n+        \"name\": \"added\",\n+        \"fieldName\": \"added\"\n+      },\n+      {\n+        \"type\": \"doubleSum\",\n+        \"name\": \"deleted\",\n+        \"fieldName\": \"deleted\"\n+      },\n+      {\n+        \"type\": \"doubleSum\",\n+        \"name\": \"delta\",\n+        \"fieldName\": \"delta\"\n+      }\n+    ],\n+    \"granularitySpec\": {\n+      \"type\": \"uniform\",\n+      \"segmentGranularity\": \"MINUTE\",\n+      \"queryGranularity\": \"NONE\"\n+    }\n+  },\n+  \"tuningConfig\": {\n+    \"type\": \"%%STREAM_TYPE%%\",\n+    \"intermediatePersistPeriod\": \"PT30S\",\n+    \"maxRowsPerSegment\": 5000000,\n+    \"maxRowsInMemory\": 500000\n+  },\n+  \"ioConfig\": {\n+    \"%%TOPIC_KEY%%\": \"%%TOPIC_VALUE%%\",\n+    \"%%STREAM_PROPERTIES_KEY%%\": %%STREAM_PROPERTIES_VALUE%%,\n+    \"autoscalerConfig\": {", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NjIyMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582666223", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxOTUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkyMDA2MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581920061", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /**\n          \n          \n            \n               * Collect maxLag, totalLag, avgLag\n          \n          \n            \n               * Only support Kafka ingestion so far.\n          \n          \n            \n               */\n          \n          \n            \n              /**\n          \n          \n            \n               * Computes maxLag, totalLag and avgLag\n          \n          \n            \n               * Only supports Kafka ingestion so far.\n          \n          \n            \n               */", "author": "pjain1", "createdAt": "2021-02-24T12:32:07Z", "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +65,12 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag\n+   * Only support Kafka ingestion so far.\n+   */", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NjI4Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582666283", "bodyText": "Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkyMDA2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkyNzIxMA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r581927210", "bodyText": "We can just pass autoscalerConfig here and it will be null because if its not null then exception will be thrown at line 96.", "author": "pjain1", "createdAt": "2021-02-24T12:43:34Z", "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorIOConfig.java", "diffHunk": "@@ -85,8 +87,16 @@ public KinesisSupervisorIOConfig(\n         completionTimeout,\n         lateMessageRejectionPeriod,\n         earlyMessageRejectionPeriod,\n+        null,", "originalCommit": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2NjQwOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582666409", "bodyText": "changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T09:16:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkyNzIxMA=="}], "type": "inlineReview"}, {"oid": "00758e647c7137166b3e149607305a54db284dfb", "url": "https://github.com/apache/druid/commit/00758e647c7137166b3e149607305a54db284dfb", "message": "code review", "committedDate": "2021-02-25T09:10:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2OTg2Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582669862", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.error(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);\n          \n          \n            \n                  log.error(e, \"Failed to sync taskCount to MetaStorage for dataSource [%s].\", dataSource);\n          \n      \n    \n    \n  \n\nprobably you copied the above one by mistake", "author": "pjain1", "createdAt": "2021-02-25T09:21:19Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +323,127 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lag points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      if (autoScalerConfig == null) {\n+        log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n+      } else {\n+        try {\n+          long nowTime = System.currentTimeMillis();\n+          if (spec.isSuspended()) {\n+            log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n+                    dataSource\n+            );\n+            return;\n+          }\n+          log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n+                  dataSource\n+          );\n+          for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n+            if (!list.isEmpty()) {\n+              log.info(\n+                      \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n+                      dataSource, pendingCompletionTaskGroups\n+              );\n+              return;\n+            }\n+          }\n+          if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerScaleActionFrequencyMillis()) {\n+            log.info(\n+                    \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n+                    nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerScaleActionFrequencyMillis(), dataSource\n+            );\n+            return;\n+          }\n+          final Integer desriedTaskCount = scaleAction.call();\n+          boolean allocationSuccess = changeTaskCount(desriedTaskCount);\n+          if (allocationSuccess) {\n+            dynamicTriggerLastRunTime = nowTime;\n+          }\n+        }\n+        catch (Exception ex) {\n+          log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled in the next 'RunNotice'.\n+   *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n+   * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n+   * @param desiredActiveTaskCount desired taskCount computed from AutoScaler\n+   * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerScaleActionFrequencyMillis' before next 'changeTaskCount'.\n+   *         If false, it will do 'changeTaskCount' again after 'scaleActionPeriodMillis' millis.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n+      return false;\n+    } else {\n+      log.info(\n+              \"Starting scale action, current active task count is [%d] and desired task count is [%d] for dataSource [%s].\",\n+              currentActiveTaskCount, desiredActiveTaskCount, dataSource\n+      );\n+      gracefulShutdownInternal();\n+      changeTaskCountInIOConfig(desiredActiveTaskCount);\n+      clearAllocationInfo();\n+      log.info(\"Changed taskCount to [%s] for dataSource [%s].\", desiredActiveTaskCount, dataSource);\n+      return true;\n+    }\n+  }\n+\n+  private void changeTaskCountInIOConfig(int desiredActiveTaskCount)\n+  {\n+    ioConfig.setTaskCount(desiredActiveTaskCount);\n+    try {\n+      Optional<SupervisorManager> supervisorManager = taskMaster.getSupervisorManager();\n+      if (supervisorManager.isPresent()) {\n+        MetadataSupervisorManager metadataSupervisorManager = supervisorManager.get().getMetadataSupervisorManager();\n+        metadataSupervisorManager.insert(dataSource, spec);\n+      } else {\n+        log.error(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);\n+      }\n+    }\n+    catch (Exception e) {\n+      log.error(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);", "originalCommit": "00758e647c7137166b3e149607305a54db284dfb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjkwODA0NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582908044", "bodyText": "Woooo.. Changed.", "author": "zhangyue19921010", "createdAt": "2021-02-25T15:05:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2OTg2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY3NTYwNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582675607", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /**\n          \n          \n            \n               * need to notice that autoScaler would be null which means autoscale is dissable.\n          \n          \n            \n               * @param supervisor\n          \n          \n            \n               * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n          \n          \n            \n               */\n          \n          \n            \n              /**\n          \n          \n            \n               * An autoScaler instance will be returned depending on the autoScalerConfig. In case autoScalerConfig is null or autoScaler is disabled then NoopTaskAutoScaler will be returned.\n          \n          \n            \n               * @param supervisor\n          \n          \n            \n               * @return autoScaler\n          \n          \n            \n               */", "author": "pjain1", "createdAt": "2021-02-25T09:29:05Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +154,21 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */", "originalCommit": "00758e647c7137166b3e149607305a54db284dfb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjkwODI2Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r582908263", "bodyText": "Done. Thanks for your review!", "author": "zhangyue19921010", "createdAt": "2021-02-25T15:05:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY3NTYwNw=="}], "type": "inlineReview"}, {"oid": "1f1008266a0040a74f9bd8c0deffddf923d67d9e", "url": "https://github.com/apache/druid/commit/1f1008266a0040a74f9bd8c0deffddf923d67d9e", "message": "log changed", "committedDate": "2021-02-25T11:21:37Z", "type": "commit"}, {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "url": "https://github.com/apache/druid/commit/6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "message": "do StringUtils.encodeForFormat when create allocationExec", "committedDate": "2021-02-25T13:13:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE1NjQ4Mw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585156483", "bodyText": "Can we make the distinction that, following properties are common to any autoscaler and rest are specific to lagBased autoscaler , maybe have two tables.\nautoScalerStrategy\nenableTaskAutoScaler\ntaskCountMin\ntaskCountMax\nminTriggerScaleActionFrequencyMillis", "author": "himanshug", "createdAt": "2021-03-02T00:31:40Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |\n+| `scaleInThreshold` | The Threshold of scale in action | no (default == 1000000) |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |\n+| `scaleActionStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | no (default == 300000) |\n+| `scaleActionPeriodMillis` | The frequency of checking whether to do scale action in millis | no (default == 60000) |\n+| `taskCountMax` | Maximum value of task count. Make Sure `taskCountMax >= taskCountMin` | yes |\n+| `taskCountMin` | Minimum value of task count. When enable autoscaler, the value of taskCount in `IOConfig` will be ignored, and `taskCountMin` will be the number of tasks that ingestion starts going up to `taskCountMax`| yes |\n+| `scaleInStep` | How many tasks to reduce at a time | no (default == 1) |\n+| `scaleOutStep` | How many tasks to add at a time | no (default == 2) |\n+| `minTriggerScaleActionFrequencyMillis` | Minimum time interval between two scale actions | no (default == 600000) |\n+| `autoScalerStrategy` | The algorithm of `autoScaler`. ONLY `lagBased` is supported for now. | no (default == `lagBased`) |", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyMjUwOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585322509", "bodyText": "Sure. Done", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE1NjQ4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE1NzAwMg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585157002", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            | `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n          \n          \n            \n            | `lagCollectionIntervalMillis` | Period of lag points collection.  | no (default == 30000) |", "author": "himanshug", "createdAt": "2021-03-02T00:33:09Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyMjYwOQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585322609", "bodyText": "Thanks && changed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:34:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE1NzAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MDcxMQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585160711", "bodyText": "why shouldn't we expect lagStats.getTotalLag() to return a value >= 0 ?", "author": "himanshug", "createdAt": "2021-03-02T00:43:00Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),\n+        lagBasedAutoScalerConfig.getScaleActionPeriodMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    log.info(\n+        \"LagBasedAutoScaler will collect lag every [%d] millis and will keep [%d] data points for the last [%d] millis for dataSource [%s]\",\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(), lagMetricsQueue.size(),\n+        lagBasedAutoScalerConfig.getLagCollectionRangeMillis(), dataSource\n+    );\n+  }\n+\n+  @Override\n+  public void stop()\n+  {\n+    allocationExec.shutdownNow();\n+    lagComputationExec.shutdownNow();\n+  }\n+\n+  @Override\n+  public void reset()\n+  {\n+    // clear queue for kafka lags\n+    if (lagMetricsQueue != null) {\n+      try {\n+        LOCK.lock();\n+        lagMetricsQueue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method computes current consumer lag. Gets the total lag of all partitions and fill in the lagMetricsQueue\n+   *\n+   * @return a Runnbale object to compute and collect lag.\n+   */\n+  private Runnable computeAndCollectLag()\n+  {\n+    return () -> {\n+      LOCK.lock();\n+      try {\n+        if (!spec.isSuspended()) {\n+          LagStats lagStats = supervisor.computeLagStats();\n+          if (lagStats == null) {\n+            lagMetricsQueue.offer(0L);\n+          } else {\n+            long totalLags = lagStats.getTotalLag();\n+            lagMetricsQueue.offer(totalLags > 0 ? totalLags : 0L);", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyNTY4Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585325687", "bodyText": "Because we can occasionally get negative lags in our practice. Something like https://stackoverflow.com/questions/60847952/how-to-get-rid-of-negative-consumer-lag-in-kafka\nNegative lag values is un-necessary and a poison into our lag metrics. So just filter it here.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:39:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MDcxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MjI3NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585162274", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private Integer computeDesiredTaskCount(List<Long> lags)\n          \n          \n            \n              private int computeDesiredTaskCount(List<Long> lags)", "author": "himanshug", "createdAt": "2021-03-02T00:47:07Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),\n+        lagBasedAutoScalerConfig.getScaleActionPeriodMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    log.info(\n+        \"LagBasedAutoScaler will collect lag every [%d] millis and will keep [%d] data points for the last [%d] millis for dataSource [%s]\",\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(), lagMetricsQueue.size(),\n+        lagBasedAutoScalerConfig.getLagCollectionRangeMillis(), dataSource\n+    );\n+  }\n+\n+  @Override\n+  public void stop()\n+  {\n+    allocationExec.shutdownNow();\n+    lagComputationExec.shutdownNow();\n+  }\n+\n+  @Override\n+  public void reset()\n+  {\n+    // clear queue for kafka lags\n+    if (lagMetricsQueue != null) {\n+      try {\n+        LOCK.lock();\n+        lagMetricsQueue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method computes current consumer lag. Gets the total lag of all partitions and fill in the lagMetricsQueue\n+   *\n+   * @return a Runnbale object to compute and collect lag.\n+   */\n+  private Runnable computeAndCollectLag()\n+  {\n+    return () -> {\n+      LOCK.lock();\n+      try {\n+        if (!spec.isSuspended()) {\n+          LagStats lagStats = supervisor.computeLagStats();\n+          if (lagStats == null) {\n+            lagMetricsQueue.offer(0L);\n+          } else {\n+            long totalLags = lagStats.getTotalLag();\n+            lagMetricsQueue.offer(totalLags > 0 ? totalLags : 0L);\n+          }\n+          log.debug(\"Current lags [%s] for dataSource [%s].\", new ArrayList<>(lagMetricsQueue), dataSource);\n+        } else {\n+          log.warn(\"[%s] supervisor is suspended, skipping lag collection\", dataSource);\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error while collecting lags\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * This method determines whether to do scale actions based on collected lag points.\n+   * Current algorithm of scale is simple:\n+   * First of all, compute the proportion of lag points higher/lower than scaleOutThreshold/scaleInThreshold, getting scaleOutThreshold/scaleInThreshold.\n+   * Secondly, compare scaleOutThreshold/scaleInThreshold with triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency. P.S. Scale out action has higher priority than scale in action.\n+   * Finaly, if scaleOutThreshold/scaleInThreshold is higher than triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency, scale out/in action would be triggered.\n+   *\n+   * @param lags the lag metrics of Stream(Kafka/Kinesis)\n+   * @return Integer. target number of tasksCount, -1 means skip scale action.\n+   */\n+  private Integer computeDesiredTaskCount(List<Long> lags)", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyNTgwMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585325803", "bodyText": "Thanks && changed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:40:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MjI3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MzU3MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585163570", "bodyText": "is it legitimate for supervisor.getActiveTaskGroupsCount() to return a negative value? if not, then supervisor.getActiveTaskGroupsCount() should always return a value >= 0 and this check shouldn't be needed.", "author": "himanshug", "createdAt": "2021-03-02T00:50:15Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),\n+        lagBasedAutoScalerConfig.getScaleActionPeriodMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    log.info(\n+        \"LagBasedAutoScaler will collect lag every [%d] millis and will keep [%d] data points for the last [%d] millis for dataSource [%s]\",\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(), lagMetricsQueue.size(),\n+        lagBasedAutoScalerConfig.getLagCollectionRangeMillis(), dataSource\n+    );\n+  }\n+\n+  @Override\n+  public void stop()\n+  {\n+    allocationExec.shutdownNow();\n+    lagComputationExec.shutdownNow();\n+  }\n+\n+  @Override\n+  public void reset()\n+  {\n+    // clear queue for kafka lags\n+    if (lagMetricsQueue != null) {\n+      try {\n+        LOCK.lock();\n+        lagMetricsQueue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method computes current consumer lag. Gets the total lag of all partitions and fill in the lagMetricsQueue\n+   *\n+   * @return a Runnbale object to compute and collect lag.\n+   */\n+  private Runnable computeAndCollectLag()\n+  {\n+    return () -> {\n+      LOCK.lock();\n+      try {\n+        if (!spec.isSuspended()) {\n+          LagStats lagStats = supervisor.computeLagStats();\n+          if (lagStats == null) {\n+            lagMetricsQueue.offer(0L);\n+          } else {\n+            long totalLags = lagStats.getTotalLag();\n+            lagMetricsQueue.offer(totalLags > 0 ? totalLags : 0L);\n+          }\n+          log.debug(\"Current lags [%s] for dataSource [%s].\", new ArrayList<>(lagMetricsQueue), dataSource);\n+        } else {\n+          log.warn(\"[%s] supervisor is suspended, skipping lag collection\", dataSource);\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error while collecting lags\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * This method determines whether to do scale actions based on collected lag points.\n+   * Current algorithm of scale is simple:\n+   * First of all, compute the proportion of lag points higher/lower than scaleOutThreshold/scaleInThreshold, getting scaleOutThreshold/scaleInThreshold.\n+   * Secondly, compare scaleOutThreshold/scaleInThreshold with triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency. P.S. Scale out action has higher priority than scale in action.\n+   * Finaly, if scaleOutThreshold/scaleInThreshold is higher than triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency, scale out/in action would be triggered.\n+   *\n+   * @param lags the lag metrics of Stream(Kafka/Kinesis)\n+   * @return Integer. target number of tasksCount, -1 means skip scale action.\n+   */\n+  private Integer computeDesiredTaskCount(List<Long> lags)\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.debug(\"Computing desired task count for [%s], based on following lags : [%s]\", dataSource, lags);\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= lagBasedAutoScalerConfig.getScaleOutThreshold()) {\n+        beyond++;\n+      }\n+      if (lag <= lagBasedAutoScalerConfig.getScaleInThreshold()) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+\n+    log.debug(\"Calculated beyondProportion is [%s] and withinProportion is [%s] for dataSource [%s].\", beyondProportion,\n+        withinProportion, dataSource\n+    );\n+\n+    int currentActiveTaskCount = supervisor.getActiveTaskGroupsCount();\n+    if (currentActiveTaskCount < 0) {", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyNTk1MA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585325950", "bodyText": "Thanks && removed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:40:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MzU3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2NzA3OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585167079", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n          \n          \n            \n              private boolean changeTaskCount(int desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException", "author": "himanshug", "createdAt": "2021-03-02T00:59:17Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +323,127 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lag points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      if (autoScalerConfig == null) {\n+        log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n+      } else {\n+        try {\n+          long nowTime = System.currentTimeMillis();\n+          if (spec.isSuspended()) {\n+            log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n+                    dataSource\n+            );\n+            return;\n+          }\n+          log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n+                  dataSource\n+          );\n+          for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n+            if (!list.isEmpty()) {\n+              log.info(\n+                      \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n+                      dataSource, pendingCompletionTaskGroups\n+              );\n+              return;\n+            }\n+          }\n+          if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerScaleActionFrequencyMillis()) {\n+            log.info(\n+                    \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n+                    nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerScaleActionFrequencyMillis(), dataSource\n+            );\n+            return;\n+          }\n+          final Integer desriedTaskCount = scaleAction.call();\n+          boolean allocationSuccess = changeTaskCount(desriedTaskCount);\n+          if (allocationSuccess) {\n+            dynamicTriggerLastRunTime = nowTime;\n+          }\n+        }\n+        catch (Exception ex) {\n+          log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled in the next 'RunNotice'.\n+   *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n+   * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n+   * @param desiredActiveTaskCount desired taskCount computed from AutoScaler\n+   * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerScaleActionFrequencyMillis' before next 'changeTaskCount'.\n+   *         If false, it will do 'changeTaskCount' again after 'scaleActionPeriodMillis' millis.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyNjAxNw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585326017", "bodyText": "changed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:40:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2NzA3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2NzI3MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585167271", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n          \n          \n            \n                if (desiredActiveTaskCount < 0 || desiredActiveTaskCount == currentActiveTaskCount) {", "author": "himanshug", "createdAt": "2021-03-02T00:59:40Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +323,127 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lag points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      if (autoScalerConfig == null) {\n+        log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n+      } else {\n+        try {\n+          long nowTime = System.currentTimeMillis();\n+          if (spec.isSuspended()) {\n+            log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n+                    dataSource\n+            );\n+            return;\n+          }\n+          log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n+                  dataSource\n+          );\n+          for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n+            if (!list.isEmpty()) {\n+              log.info(\n+                      \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n+                      dataSource, pendingCompletionTaskGroups\n+              );\n+              return;\n+            }\n+          }\n+          if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerScaleActionFrequencyMillis()) {\n+            log.info(\n+                    \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n+                    nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerScaleActionFrequencyMillis(), dataSource\n+            );\n+            return;\n+          }\n+          final Integer desriedTaskCount = scaleAction.call();\n+          boolean allocationSuccess = changeTaskCount(desriedTaskCount);\n+          if (allocationSuccess) {\n+            dynamicTriggerLastRunTime = nowTime;\n+          }\n+        }\n+        catch (Exception ex) {\n+          log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled in the next 'RunNotice'.\n+   *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n+   * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n+   * @param desiredActiveTaskCount desired taskCount computed from AutoScaler\n+   * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerScaleActionFrequencyMillis' before next 'changeTaskCount'.\n+   *         If false, it will do 'changeTaskCount' again after 'scaleActionPeriodMillis' millis.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMzMjM4Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585332382", "bodyText": "Thanks && changed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:52:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2NzI3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2ODk0Ng==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585168946", "bodyText": "not sure why lagCollectionRangeMillis was added to scaleActionStartDelayMillis .", "author": "himanshug", "createdAt": "2021-03-02T01:03:50Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMyNjA3OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585326079", "bodyText": "When scaleActionStartDelayMillis meets, lagComputationExec start to work to collect metrics. And allocationExec need to wait for another lagCollectionRangeMillis which means wait for lagComputationExec to collect enough lag metrics.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:40:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2ODk0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MTkwNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585171904", "bodyText": "wouldn't time interval between two scale actions be always greater/equal to scaleActionPeriodMillis ?", "author": "himanshug", "createdAt": "2021-03-02T01:10:06Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |\n+| `scaleInThreshold` | The Threshold of scale in action | no (default == 1000000) |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |\n+| `scaleActionStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | no (default == 300000) |\n+| `scaleActionPeriodMillis` | The frequency of checking whether to do scale action in millis | no (default == 60000) |\n+| `taskCountMax` | Maximum value of task count. Make Sure `taskCountMax >= taskCountMin` | yes |\n+| `taskCountMin` | Minimum value of task count. When enable autoscaler, the value of taskCount in `IOConfig` will be ignored, and `taskCountMin` will be the number of tasks that ingestion starts going up to `taskCountMax`| yes |\n+| `scaleInStep` | How many tasks to reduce at a time | no (default == 1) |\n+| `scaleOutStep` | How many tasks to add at a time | no (default == 2) |\n+| `minTriggerScaleActionFrequencyMillis` | Minimum time interval between two scale actions | no (default == 600000) |", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMzMjAyNQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585332025", "bodyText": "Actually, scaleActionPeriodMillis is to control the frequency of detection and minTriggerScaleActionFrequencyMillis is to set a cool-down time between two scale actions. There is no hard association between the two parameters. For example users can set scaleActionPeriodMillis == 10min and minTriggerScaleActionFrequencyMillis == 5min. It means Druid will check lags every 10mins. If triggered scale action, then could not scale again within 5 minutes.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:52:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MTkwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MjMyNQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585172325", "bodyText": "not sure if it is a \"frequency\". maybe triggerScaleOutFractionThreshold", "author": "himanshug", "createdAt": "2021-03-02T01:11:21Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMzMjI1MQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585332251", "bodyText": "Thanks && changed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:52:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MjMyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MjQ2Mg==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585172462", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            | `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |\n          \n          \n            \n            | `triggerScaleInFractionThreshold` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |", "author": "himanshug", "createdAt": "2021-03-02T01:11:41Z", "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |\n+| `scaleInThreshold` | The Threshold of scale in action | no (default == 1000000) |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |", "originalCommit": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTMzMjI3Nw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r585332277", "bodyText": "Thanks && changed.", "author": "zhangyue19921010", "createdAt": "2021-03-02T07:52:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MjQ2Mg=="}], "type": "inlineReview"}, {"oid": "22339ddc83976758809570dd1c92d7506c26fcfa", "url": "https://github.com/apache/druid/commit/22339ddc83976758809570dd1c92d7506c26fcfa", "message": "code review && limit taskCountMax to partitionNumbers", "committedDate": "2021-03-02T06:06:57Z", "type": "commit"}, {"oid": "644e7320ce2f51521b470b022f3406395054bd60", "url": "https://github.com/apache/druid/commit/644e7320ce2f51521b470b022f3406395054bd60", "message": "modify docs", "committedDate": "2021-03-02T07:33:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc5MjYxMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r587792613", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public int getPartitionNumbers()\n          \n          \n            \n              public int getPartitionsCount()", "author": "himanshug", "createdAt": "2021-03-04T20:10:52Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -1901,6 +2058,11 @@ protected boolean supportsPartitionExpiration()\n     return false;\n   }\n \n+  public int getPartitionNumbers()", "originalCommit": "644e7320ce2f51521b470b022f3406395054bd60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAzMzYxMw==", "url": "https://github.com/apache/druid/pull/10524#discussion_r588033613", "bodyText": "Done. Thanks a lot for your review and approval!", "author": "zhangyue19921010", "createdAt": "2021-03-05T04:57:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc5MjYxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwMzY5NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r587903694", "bodyText": "Should this be included in toString below?", "author": "capistrant", "createdAt": "2021-03-04T23:20:56Z", "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorIOConfig.java", "diffHunk": "@@ -51,6 +53,7 @@ public KafkaSupervisorIOConfig(\n       @JsonProperty(\"taskCount\") Integer taskCount,\n       @JsonProperty(\"taskDuration\") Period taskDuration,\n       @JsonProperty(\"consumerProperties\") Map<String, Object> consumerProperties,\n+      @Nullable @JsonProperty(\"autoScalerConfig\") AutoScalerConfig autoScalerConfig,", "originalCommit": "644e7320ce2f51521b470b022f3406395054bd60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAzMTI0NQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r588031245", "bodyText": "Sure && Done.", "author": "zhangyue19921010", "createdAt": "2021-03-05T04:49:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwMzY5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwNDIwNA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r587904204", "bodyText": "Not sure if UnsupportedOperationException would be better here or if null is fine.", "author": "capistrant", "createdAt": "2021-03-04T23:22:21Z", "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java", "diffHunk": "@@ -378,6 +379,13 @@ protected boolean useExclusiveStartSequenceNumberForNonFirstSequence()\n     return true;\n   }\n \n+  // not yet supported, will be implemented in the future maybe? need to find a proper way to measure kinesis lag.\n+  @Override\n+  public LagStats computeLagStats()", "originalCommit": "644e7320ce2f51521b470b022f3406395054bd60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAzMTI2NA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r588031264", "bodyText": "Sure && Done.", "author": "zhangyue19921010", "createdAt": "2021-03-05T04:49:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwNDIwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwODgyOA==", "url": "https://github.com/apache/druid/pull/10524#discussion_r587908828", "bodyText": "does this need to be added added to licesnses.yaml? https://github.com/apache/druid/blob/master/dev/license.md#when-you-add-a-new-library-dependency-into-druid", "author": "capistrant", "createdAt": "2021-03-04T23:33:38Z", "path": "pom.xml", "diffHunk": "@@ -957,6 +957,11 @@\n                 <artifactId>jna</artifactId>\n                 <version>4.5.1</version>\n             </dependency>\n+            <dependency>", "originalCommit": "644e7320ce2f51521b470b022f3406395054bd60", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAzMTk0OQ==", "url": "https://github.com/apache/druid/pull/10524#discussion_r588031949", "bodyText": "It looks like this dependency is already added in licenses.yaml before according to \n  \n    \n      druid/licenses.yaml\n    \n    \n         Line 596\n      in\n      6040c30\n    \n    \n    \n    \n\n        \n          \n           - org.apache.commons: commons-collections4", "author": "zhangyue19921010", "createdAt": "2021-03-05T04:51:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwODgyOA=="}], "type": "inlineReview"}, {"oid": "1a9a09d05411476a27de69b0e22e8ddebe0d5f90", "url": "https://github.com/apache/druid/commit/1a9a09d05411476a27de69b0e22e8ddebe0d5f90", "message": "code review", "committedDate": "2021-03-05T02:40:11Z", "type": "commit"}]}