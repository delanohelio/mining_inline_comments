{"pr_number": 10689, "pr_title": "Multiphase segment merge for IndexMergerV9", "pr_createdAt": "2020-12-17T20:41:58Z", "pr_url": "https://github.com/apache/druid/pull/10689", "timeline": [{"oid": "6ee2340f5ab1227d5e61776de1333e9fb29587a6", "url": "https://github.com/apache/druid/commit/6ee2340f5ab1227d5e61776de1333e9fb29587a6", "message": "Multiphase merge for IndexMergerV9", "committedDate": "2020-12-17T20:34:48Z", "type": "commit"}, {"oid": "25a8d5789a893e6257c066e9a6a72034d8d3cc25", "url": "https://github.com/apache/druid/commit/25a8d5789a893e6257c066e9a6a72034d8d3cc25", "message": "JSON fix", "committedDate": "2020-12-17T23:44:21Z", "type": "commit"}, {"oid": "262f223fb71d6d4f2393d44d240cf300ed331108", "url": "https://github.com/apache/druid/commit/262f223fb71d6d4f2393d44d240cf300ed331108", "message": "Cleanup temp files", "committedDate": "2020-12-18T03:05:12Z", "type": "commit"}, {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "url": "https://github.com/apache/druid/commit/76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "message": "Docs", "committedDate": "2020-12-18T03:26:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk1MzgxNA==", "url": "https://github.com/apache/druid/pull/10689#discussion_r546953814", "bodyText": "Should this be a warn since we expected to always merge at least two segments regardless of column limit? The warning may be misleading as there is nothing to fix / change", "author": "maytasm", "createdAt": "2020-12-21T22:07:49Z", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {\n+          File phaseOutDir;\n+          if (currentPhases.size() == 1) {\n+            // use the given outDir on the final merge phase\n+            phaseOutDir = outDir;\n+          } else {\n+            phaseOutDir = FileUtils.createTempDir();\n+            tempDirs.add(phaseOutDir);\n+          }\n+          log.debug(\"phase outDir: \" + phaseOutDir);\n+\n+          File phaseOutput = merge(\n+              phase,\n+              rollup,\n+              metricAggs,\n+              phaseOutDir,\n+              indexSpec,\n+              progress,\n+              segmentWriteOutMediumFactory\n+          );\n+          currentOutputs.add(phaseOutput);\n+        }\n+        if (currentOutputs.size() == 1) {\n+          // we're done, we made a single File output\n+          return currentOutputs.get(0);\n+        } else {\n+          // convert Files to QueryableIndexIndexableAdapter and do another merge phase\n+          List<IndexableAdapter> qIndexAdapters = new ArrayList<>();\n+          for (File outputFile : currentOutputs) {\n+            QueryableIndex qIndex = indexIO.loadIndex(outputFile, true);\n+            qIndexAdapters.add(new QueryableIndexIndexableAdapter(qIndex));\n+          }\n+          currentPhases = getMergePhases(qIndexAdapters, maxColumnsToMerge);\n+          currentOutputs = new ArrayList<>();\n+        }\n+      }\n+    }\n+    finally {\n+      for (File tempDir : tempDirs) {\n+        if (tempDir.exists()) {\n+          try {\n+            FileUtils.deleteDirectory(tempDir);\n+          }\n+          catch (Exception e) {\n+            log.warn(e, \"Failed to remove directory[%s]\", tempDir);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private List<List<IndexableAdapter>> getMergePhases(List<IndexableAdapter> indexes, int maxColumnsToMerge)\n+  {\n+    List<List<IndexableAdapter>> toMerge = new ArrayList<>();\n+    // always merge at least two segments regardless of column limit\n+    if (indexes.size() <= 2) {\n+      if (getIndexColumnCount(indexes) > maxColumnsToMerge) {\n+        log.warn(\"index pair has more columns than maxColumnsToMerge [%d].\", maxColumnsToMerge);", "originalCommit": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTIwNw==", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965207", "bodyText": "Is it useful to log the iteration number of this loop?\nlike how many times have we done a pass so far?", "author": "maytasm", "createdAt": "2020-12-21T22:40:48Z", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {", "originalCommit": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTM1NA==", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965354", "bodyText": "is it useful to log the size of currentPhases? It might help to see the progress as the number should decrease after each pass", "author": "maytasm", "createdAt": "2020-12-21T22:41:19Z", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {", "originalCommit": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTgxNw==", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965817", "bodyText": "Should this be a warn since this can happen and is a expected / ok thing? The warning may be misleading as there is nothing to fix / change", "author": "maytasm", "createdAt": "2020-12-21T22:42:50Z", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {\n+          File phaseOutDir;\n+          if (currentPhases.size() == 1) {\n+            // use the given outDir on the final merge phase\n+            phaseOutDir = outDir;\n+          } else {\n+            phaseOutDir = FileUtils.createTempDir();\n+            tempDirs.add(phaseOutDir);\n+          }\n+          log.debug(\"phase outDir: \" + phaseOutDir);\n+\n+          File phaseOutput = merge(\n+              phase,\n+              rollup,\n+              metricAggs,\n+              phaseOutDir,\n+              indexSpec,\n+              progress,\n+              segmentWriteOutMediumFactory\n+          );\n+          currentOutputs.add(phaseOutput);\n+        }\n+        if (currentOutputs.size() == 1) {\n+          // we're done, we made a single File output\n+          return currentOutputs.get(0);\n+        } else {\n+          // convert Files to QueryableIndexIndexableAdapter and do another merge phase\n+          List<IndexableAdapter> qIndexAdapters = new ArrayList<>();\n+          for (File outputFile : currentOutputs) {\n+            QueryableIndex qIndex = indexIO.loadIndex(outputFile, true);\n+            qIndexAdapters.add(new QueryableIndexIndexableAdapter(qIndex));\n+          }\n+          currentPhases = getMergePhases(qIndexAdapters, maxColumnsToMerge);\n+          currentOutputs = new ArrayList<>();\n+        }\n+      }\n+    }\n+    finally {\n+      for (File tempDir : tempDirs) {\n+        if (tempDir.exists()) {\n+          try {\n+            FileUtils.deleteDirectory(tempDir);\n+          }\n+          catch (Exception e) {\n+            log.warn(e, \"Failed to remove directory[%s]\", tempDir);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private List<List<IndexableAdapter>> getMergePhases(List<IndexableAdapter> indexes, int maxColumnsToMerge)\n+  {\n+    List<List<IndexableAdapter>> toMerge = new ArrayList<>();\n+    // always merge at least two segments regardless of column limit\n+    if (indexes.size() <= 2) {\n+      if (getIndexColumnCount(indexes) > maxColumnsToMerge) {\n+        log.warn(\"index pair has more columns than maxColumnsToMerge [%d].\", maxColumnsToMerge);\n+      }\n+      toMerge.add(indexes);\n+    } else {\n+      List<IndexableAdapter> currentPhase = new ArrayList<>();\n+      int currentColumnCount = 0;\n+      for (IndexableAdapter index : indexes) {\n+        int indexColumnCount = getIndexColumnCount(index);\n+        if (indexColumnCount > maxColumnsToMerge) {\n+          log.warn(\"index has more columns [%d] than maxColumnsToMerge [%d]!\", indexColumnCount, maxColumnsToMerge);", "originalCommit": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1e90ea3e56a921585268e1a4a4a6039328a977ff", "url": "https://github.com/apache/druid/commit/1e90ea3e56a921585268e1a4a4a6039328a977ff", "message": "Address logging and add IT", "committedDate": "2020-12-25T00:56:21Z", "type": "commit"}, {"oid": "ccf61c32c1275cee9f254169b15dbccc207a0c53", "url": "https://github.com/apache/druid/commit/ccf61c32c1275cee9f254169b15dbccc207a0c53", "message": "Fix spelling and test unloader datasource name", "committedDate": "2020-12-25T03:06:00Z", "type": "commit"}]}