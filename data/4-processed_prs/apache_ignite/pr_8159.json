{"pr_number": 8159, "pr_title": "Loading in discovery tests.", "pr_createdAt": "2020-08-17T13:13:33Z", "pr_url": "https://github.com/apache/ignite/pull/8159", "timeline": [{"oid": "27aa1447e178129070430a09743fe85a7408c9bf", "url": "https://github.com/apache/ignite/commit/27aa1447e178129070430a09743fe85a7408c9bf", "message": "amend", "committedDate": "2020-08-13T18:03:36Z", "type": "commit"}, {"oid": "0803983cf489782092a2038e953863c44ed74586", "url": "https://github.com/apache/ignite/commit/0803983cf489782092a2038e953863c44ed74586", "message": "looks good", "committedDate": "2020-08-14T16:18:08Z", "type": "commit"}, {"oid": "95260bceb7df3a5b05df8472a92c610ff02b5720", "url": "https://github.com/apache/ignite/commit/95260bceb7df3a5b05df8472a92c610ff02b5720", "message": "amendme. in progress. fixing zk client", "committedDate": "2020-08-14T17:22:37Z", "type": "commit"}, {"oid": "13dd5764add5fc5dc3a8d8a56d910615633c29f6", "url": "https://github.com/apache/ignite/commit/13dd5764add5fc5dc3a8d8a56d910615633c29f6", "message": "Parametrization.", "committedDate": "2020-08-17T12:56:22Z", "type": "commit"}, {"oid": "399be251eff8908e70adb9db583e7341d1b8a043", "url": "https://github.com/apache/ignite/commit/399be251eff8908e70adb9db583e7341d1b8a043", "message": "Merge remote-tracking branch 'origin/ducktape-disco-load' into ducktape-disco-load\n\n# Conflicts:\n#\tmodules/ducktests/tests/ignitetest/tests/discovery_test.py", "committedDate": "2020-08-17T12:56:40Z", "type": "commit"}, {"oid": "403642c413a9e5caccfc683f97fcae01d9fe4704", "url": "https://github.com/apache/ignite/commit/403642c413a9e5caccfc683f97fcae01d9fe4704", "message": "Minorities.", "committedDate": "2020-08-17T13:12:11Z", "type": "commit"}, {"oid": "c64c5d8f4c362e415d7497cdc50c8ecc7a7ab8b8", "url": "https://github.com/apache/ignite/commit/c64c5d8f4c362e415d7497cdc50c8ecc7a7ab8b8", "message": "fix stage log. Better awaiting timeout", "committedDate": "2020-08-17T17:25:04Z", "type": "commit"}, {"oid": "25483bfa9cf1921b6bbc1171d19f3425f024e399", "url": "https://github.com/apache/ignite/commit/25483bfa9cf1921b6bbc1171d19f3425f024e399", "message": "fixes", "committedDate": "2020-08-17T21:37:33Z", "type": "commit"}, {"oid": "f838188945890deb019c1ea7577201cd69adf65b", "url": "https://github.com/apache/ignite/commit/f838188945890deb019c1ea7577201cd69adf65b", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load\n\n# Conflicts:\n#\tmodules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java\n#\tmodules/ducktests/tests/ignitetest/services/utils/ignite_aware_app.py\n#\tmodules/ducktests/tests/ignitetest/tests/discovery_test.py", "committedDate": "2020-08-18T09:12:45Z", "type": "commit"}, {"oid": "ec679f631ebd611807b3ef02d31fc254ac323400", "url": "https://github.com/apache/ignite/commit/ec679f631ebd611807b3ef02d31fc254ac323400", "message": "merged ignite-ducktape", "committedDate": "2020-08-18T10:48:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472836827", "bodyText": "according to the documentation, \"Data streamer will perform better if this flag is disabled.\"", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:06:00Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {\n+                log.warn(\"Interrupted waiting for background loading.\");\n+            }\n+        }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), optimized);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n         }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean optimized) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if(log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n \n-        markSyncExecutionComplete();\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(true);", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4OTg3OQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472889879", "bodyText": "Yes, but we don't need this performance for loading. Instead, we need to re-write data sometimes to keep loading.", "author": "Vladsz83", "createdAt": "2020-08-19T09:23:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NjkyMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472896922", "bodyText": "For the most of the tests, we need to load asap.\nYou may make this an option.", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:34:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NTY2NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473775665", "bodyText": "For the most of the tests, we need to load asap.\nYou may make this an option.\n\n'Optimized' was involved only for one goal: to work with hard failure of node/data_streamer on kill-signal. An error araises, not exception. It hinders to graceful shutdown, to finish instead of get broken. Current soulution is without 'optimized' option: kust a wrap on the error.", "author": "Vladsz83", "createdAt": "2020-08-20T08:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMTM1Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474601353", "bodyText": "If you need to continue streaming on topology change, just restart it.\nI don't like the idea of changing the semantic on the fly.", "author": "anton-vinogradov", "createdAt": "2020-08-21T10:02:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDcwNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474604706", "bodyText": "I think we don't need streaming at all. The idia is to put some load on cluster. There is no idea how exactly at now. Certain load type might be considered on next step as an option. I think cache.put() wold be enough. I just support the code which was before. We don't need restart streaming here. We need to begin and to spot it. That's all.", "author": "Vladsz83", "createdAt": "2020-08-21T10:09:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNTYwMA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474615600", "bodyText": "The idia is to put some load on cluster.\n\nThat's not true. The name is %Generation% and see the usage at AddNodeRebalanceTest (used to generate data, not to stream).\nMaybe you need to add new DataStreamingApplication instead?", "author": "anton-vinogradov", "createdAt": "2020-08-21T10:32:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyMjUzMA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474622530", "bodyText": "In AddNodeRebalanceTest it works as earlier: sequentially and with the datastreamer. This wasn't changed. AddNodeRebalanceTest uses streaming too.", "author": "Vladsz83", "createdAt": "2020-08-21T10:49:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1MzkyNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474653926", "bodyText": "Simplified.", "author": "Vladsz83", "createdAt": "2020-08-21T12:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzNjgyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472838202", "bodyText": "any reason to have constant with single usage?", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:07:33Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5MDQ3NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472890475", "bodyText": "The reason is we watch this message in the log. This is a marker. I think it should not be hardcoded.", "author": "Vladsz83", "createdAt": "2020-08-19T09:24:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NzQzMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472897432", "bodyText": "See my comments below, not sure we need this.", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:35:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NTk0NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473775944", "bodyText": "The constants got removed.", "author": "Vladsz83", "createdAt": "2020-08-20T08:46:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzODIwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472839997", "bodyText": "use asBoolean(dflt) instead", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:09:37Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5Mjc0Mg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472892742", "bodyText": "It crashes with NPE if memory serves. It doesn't expect null. Only tries to convert not-null to boolean.", "author": "Vladsz83", "createdAt": "2020-08-19T09:28:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5ODI0OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472898248", "bodyText": "Sound strange. What's the reason to have asBoolean with default in that case?", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:37:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMzA2Ng==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472903066", "bodyText": "It tries to convert not-null-value to a boolean.", "author": "Vladsz83", "createdAt": "2020-08-19T09:45:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwNzU3Nw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472907577", "bodyText": "according to documentation\n* If representation cannot be converted to a boolean value (including structured types\n* like Objects and Arrays),\n* specified defaultValue will be returned; no exceptions are thrown.", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:53:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzAzMDE4Ng==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473030186", "bodyText": "yes, but NPE happends before: jsonNode.get(\"infinite\") gives null.", "author": "Vladsz83", "createdAt": "2020-08-19T13:30:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA1MTU2Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473051563", "bodyText": "That's why I cant understand the reason to have API with default boolean :)", "author": "anton-vinogradov", "createdAt": "2020-08-19T13:59:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NjQ1OQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776459", "bodyText": "Did as earlier: with checking for null-json-node but without default values.", "author": "Vladsz83", "createdAt": "2020-08-20T08:47:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjgzOTk5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472847667", "bodyText": "you may extend run method with \"throws InterruptedException\" instead", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:17:51Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();\n             }\n+            catch (InterruptedException e) {", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NjczNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776736", "bodyText": "No need now: not separated thread runs.", "author": "Vladsz83", "createdAt": "2020-08-20T08:47:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNjU1OQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474616559", "bodyText": "The idea is just to allow framework to handle Exceptions. No need to overcomplicate your application", "author": "anton-vinogradov", "createdAt": "2020-08-21T10:34:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDE3NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654175", "bodyText": "No extra catch or throw now.", "author": "Vladsz83", "createdAt": "2020-08-21T12:04:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg0NzY2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472850625", "bodyText": "what's the reason to have separated thread here with sync wait at another?\ncan we enlarge possible threads count?", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:21:02Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -18,29 +18,139 @@\n package org.apache.ignite.internal.ducktest.tests;\n \n import com.fasterxml.jackson.databind.JsonNode;\n+import java.util.Random;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.function.Function;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final String PARAM_RANGE = \"range\";\n+\n+    /** */\n+    private static final String PARAM_INFINITE = \"infinite\";\n+\n+    /** */\n+    private static final String PARAM_CACHE_NAME = \"cacheName\";\n+\n+    /** */\n+    private static final String PARAM_OPTIMIZED = \"optimized\";\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final String WATCHEABLE_BEGIN_DATA_GEN_MSG = \"Begin generating data in background...\";\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(PARAM_CACHE_NAME).asText();\n+        boolean infinite = jsonNode.hasNonNull(PARAM_INFINITE) && jsonNode.get(PARAM_INFINITE).asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(PARAM_OPTIMIZED) || jsonNode.get(PARAM_OPTIMIZED).asBoolean();\n+        int range = jsonNode.get(PARAM_RANGE).asInt();\n+\n+        if (infinite) {\n+            Random rnd = new Random();\n+            CountDownLatch exitLatch = new CountDownLatch(1);\n+\n+            Thread th = new Thread(() -> {\n+                log.info(WATCHEABLE_BEGIN_DATA_GEN_MSG);\n+\n+                boolean error = false;\n+\n+                try {\n+                    while (!terminated())\n+                        generateData(cacheName, range, (idx) -> rnd.nextInt(range), optimized);\n+\n+                    log.info(\"Background data generation finished.\");\n+                }\n+                catch (Exception e) {\n+                    if (!X.hasCause(e, NodeStoppingException.class)) {\n+                        error = true;\n+\n+                        log.error(\"Failed to generate data in background.\", e);\n+                    }\n+                }\n+                finally {\n+                    if (error)\n+                        markBroken();\n+                    else\n+                        markFinished();\n+\n+                    exitLatch.countDown();\n+                }\n+\n+            }, DataGenerationApplication.class.getName() + \"_cacheLoader\");\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+            th.start();\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            markInitialized();\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+            try {\n+                exitLatch.await();", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NDk3NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472894975", "bodyText": "The reason is the application catches exit-signal right after exiting and stops the node.", "author": "Vladsz83", "createdAt": "2020-08-19T09:31:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NTg0Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472895843", "bodyText": "We can enlarge possible thread count if we need. But I think it is better to enlarge number of loading clients. Not part of this PR.", "author": "Vladsz83", "createdAt": "2020-08-19T09:33:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMDAxMQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472900011", "bodyText": "For now, you need no additional threads since you have ... sync wait for a single thread case which equals to executing code at the main thread.", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:40:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMjMyOQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472902329", "bodyText": "I need this thread to keep loading while nodes failes. Not before. The main test do not wait to exit main(), it waits for \"mark initialized\"", "author": "Vladsz83", "createdAt": "2020-08-19T09:44:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMzYwOA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472903608", "bodyText": "just relocate loop to main thread and markInitialized to finish waiting for service start.\nsee SingleKeyTxStreamerApplication for example", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:46:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NjkxNw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776917", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-20T08:47:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg1MDYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg2NzIwMA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472867200", "bodyText": "why __ needed?", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:48:03Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -45,6 +47,8 @@ class DiscoveryTest(IgniteTest):\n \n     FAILURE_DETECTION_TIMEOUT = 2000\n \n+    __DATA_AMOUNT = 100000", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3Njk5MQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473776991", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-20T08:48:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg2NzIwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3MDg0OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472870848", "bodyText": "seems you relocated method description to wrong place", "author": "anton-vinogradov", "createdAt": "2020-08-19T08:53:38Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzIyNA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777224", "bodyText": "Did some reallocations. Looks well to me.", "author": "Vladsz83", "createdAt": "2020-08-20T08:48:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3MDg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3NzE2Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472877163", "bodyText": "this will produce incomparable results.\nlet's have the same clusters.", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:03:24Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -91,81 +96,57 @@ def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n     @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n+        Test nodes failure scenario with TcpDiscoverySpi.\n         \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, kill_coordinator,\n+                                             nodes_to_kill, with_load)\n \n     @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n         self.__start_zk_quorum()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n \n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, kill_coordinator, nodes_to_kill,\n+                                             with_load)\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, kill_coordinator=False, nodes_to_kill=1,\n+                                 with_load=False):\n+        if nodes_to_kill == 0 and not kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n         \"\"\"\n         :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n         nodes of given number.\n         \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1 if with_load else self.NUM_NODES,", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzMwNA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777304", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-20T08:48:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg3NzE2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MDg1NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472880854", "bodyText": ".start() already waits for markInitialized() use this HB instead.", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:09:44Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzQxNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777415", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-20T08:48:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MDg1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472881357", "bodyText": "this should be covered by application as well", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:10:36Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -230,17 +218,38 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:\n+            to_kill.append(next(node for node in nodes if node.discovery_info().node_id == coordinator))\n \n-        to_kill = [to_kill] if not isinstance(to_kill, list) else to_kill\n+        if nodes_to_kill > 0:\n+            choice = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+            to_kill.extend([choice] if not isinstance(choice, list) else choice)\n \n         survive = random.choice([node for node in self.servers.nodes if node not in to_kill])\n \n         return to_kill, survive\n+\n+    def __start_loading(self, ignite_version, properties, modules, wait_sec=0):\n+        self.stage(\"Starting loading\")\n+\n+        self.loader = IgniteApplicationService(\n+            self.test_context,\n+            java_class_name=\"org.apache.ignite.internal.ducktest.tests.DataGenerationApplication\",\n+            version=ignite_version,\n+            modules=modules,\n+            properties=properties,\n+            params={\"cacheName\": \"test-cache\", \"range\": self.__DATA_AMOUNT, \"infinite\": True, \"optimized\": False})\n+\n+        self.loader.start()\n+\n+        for node in self.loader.nodes:\n+            self.loader.await_event_on_node(\"Begin generating data in background...\", node, 10, True, 1)\n+\n+        if wait_sec > 0:\n+            self.logger.info(\"Waiting for the data load for \" + str(wait_sec) + \" seconds...\")", "originalCommit": "ec679f631ebd611807b3ef02d31fc254ac323400", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwMTEzNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472901135", "bodyText": "Didn't catch you", "author": "Vladsz83", "createdAt": "2020-08-19T09:42:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwNjcwMQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472906701", "bodyText": "it related to the previous comment.\nyou should incapsulate this to app.\nmark app initialized when it did preparations, and finished when it finished.\n.start() will wait for initialisation but .run() will wait for finish", "author": "anton-vinogradov", "createdAt": "2020-08-19T09:52:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkwODkzNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472908936", "bodyText": "The application is initialized when it is just started, got a cache. The idea is to wait while it fills some amount of data.", "author": "Vladsz83", "createdAt": "2020-08-19T09:56:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkxOTg2Ng==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r472919866", "bodyText": "just initialize when you have some amount of data filled", "author": "anton-vinogradov", "createdAt": "2020-08-19T10:16:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc3NzUyNA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r473777524", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-20T08:48:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg4MTM1Nw=="}], "type": "inlineReview"}, {"oid": "fbedf807aa273cf361b5bdf350f63ca8874a4a9e", "url": "https://github.com/apache/ignite/commit/fbedf807aa273cf361b5bdf350f63ca8874a4a9e", "message": "fixes", "committedDate": "2020-08-19T10:33:21Z", "type": "commit"}, {"oid": "4d834baa0a61f2a950f977c3867d82f42ff27b30", "url": "https://github.com/apache/ignite/commit/4d834baa0a61f2a950f977c3867d82f42ff27b30", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load", "committedDate": "2020-08-19T10:33:48Z", "type": "commit"}, {"oid": "5f5245867e2f6a3a55cdecf6bbabed7f8319331a", "url": "https://github.com/apache/ignite/commit/5f5245867e2f6a3a55cdecf6bbabed7f8319331a", "message": "fixes2", "committedDate": "2020-08-19T10:50:48Z", "type": "commit"}, {"oid": "3c2a77af659afcd6899729dd1fd98ba8d53f75ce", "url": "https://github.com/apache/ignite/commit/3c2a77af659afcd6899729dd1fd98ba8d53f75ce", "message": "fixes2", "committedDate": "2020-08-19T19:28:56Z", "type": "commit"}, {"oid": "80e4718d6a39f6cd5b6be95cf55f60c91da31602", "url": "https://github.com/apache/ignite/commit/80e4718d6a39f6cd5b6be95cf55f60c91da31602", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load", "committedDate": "2020-08-19T19:29:38Z", "type": "commit"}, {"oid": "4b4a9ea7692f1761c8fd0d0e08df76665db89ea1", "url": "https://github.com/apache/ignite/commit/4b4a9ea7692f1761c8fd0d0e08df76665db89ea1", "message": "Merge remote-tracking branch 'origin/ducktape-disco-load' into ducktape-disco-load", "committedDate": "2020-08-19T19:52:43Z", "type": "commit"}, {"oid": "ac7005138446847346cf0dfe123eb4281b9a9f0c", "url": "https://github.com/apache/ignite/commit/ac7005138446847346cf0dfe123eb4281b9a9f0c", "message": "import order fix", "committedDate": "2020-08-20T06:32:27Z", "type": "commit"}, {"oid": "405298b6389d26a2558d8811f97e4feaab5d0770", "url": "https://github.com/apache/ignite/commit/405298b6389d26a2558d8811f97e4feaab5d0770", "message": "+overwrite", "committedDate": "2020-08-21T07:49:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU3Nzg5NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474577895", "bodyText": "AFAIK, single line javadocs allowed only for fields", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:32:16Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -102,24 +107,28 @@ protected void markInitialized() {\n         inited = true;\n     }\n \n-    /**\n-     *\n-     */\n-    protected void markFinished() {\n+    /** */\n+    protected void markFinished(boolean removeShutdownHook) {\n         assert !finished;\n         assert !broken;\n \n         log.info(APP_FINISHED);\n \n-        removeShutdownHook();\n+        if (removeShutdownHook)\n+            removeShutdownHook();\n \n         finished = true;\n     }\n \n+    /** */", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDM2OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654368", "bodyText": "Someone insist on inlining such comments :) Reverted.", "author": "Vladsz83", "createdAt": "2020-08-21T12:04:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU3Nzg5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474580631", "bodyText": "Some architectural leak here.\nThe application should not be aware of shutdown hook.", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:35:17Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyMzEwNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474623105", "bodyText": "Yes. I think markBroken, markTerminated, markFinished is overcomplicated and should be reconsidered. But not in this ticket. Is it ok?", "author": "Vladsz83", "createdAt": "2020-08-21T10:50:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDQ0NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654444", "bodyText": "Simplified.", "author": "Vladsz83", "createdAt": "2020-08-21T12:05:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MDYzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MTc5MQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474581791", "bodyText": "newline required here because of different variable purpose", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:36:31Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDUwNA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654504", "bodyText": "Fixed.", "author": "Vladsz83", "createdAt": "2020-08-21T12:05:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MTc5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MzIyOQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474583229", "bodyText": "seems to be overcomplicated", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:38:16Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDU5Ng==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654596", "bodyText": "Smplified.", "author": "Vladsz83", "createdAt": "2020-08-21T12:05:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU4MzIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474594735", "bodyText": "just do not catch such exceptions. App moll be marked as broken at IgniteAwareApplication#start", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:50:56Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNTAyNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474615025", "bodyText": "That has reasons. Some time was spent to make this code choise. Catching no exception causes app marked broken what is not actually broken. The datastreamer seems to have no way to stop correctly on node stoppage. I tried to cancel it on node stop event, on shutdown-hook. Another exception arises. Such behaviour is interesting but I decided not to research it within trivial and raw loading test.", "author": "Vladsz83", "createdAt": "2020-08-21T10:30:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDY3Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654673", "bodyText": "Simplified.", "author": "Vladsz83", "createdAt": "2020-08-21T12:05:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NDczNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NTQ4Ng==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474595486", "bodyText": "newline required here because of different variable purpose", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:51:40Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDcyNw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654727", "bodyText": "Fixed.", "author": "Vladsz83", "createdAt": "2020-08-21T12:05:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NTQ4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NjY2OQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474596669", "bodyText": "any reason to spend time on transforming the value?", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:53:22Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDgyNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654825", "bodyText": "Simplified.", "author": "Vladsz83", "createdAt": "2020-08-21T12:05:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5NjY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474598512", "bodyText": "Not sure I got how notification related to the initialization.\nHow about to relocate init to the loop(generate)?", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:56:16Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -17,30 +17,111 @@\n \n package org.apache.ignite.internal.ducktest.tests;\n \n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n import com.fasterxml.jackson.databind.JsonNode;\n-import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n+\n+        if (infinite) {\n+            boolean error = true;\n+            AtomicInteger cycle = new AtomicInteger();\n+\n+            log.info(\"Generating data in background...\");\n+\n+            try {\n+                while (active()) {\n+                    generateData(cacheName, range, (idx) -> idx + cycle.get(), true, cycle.get() > 0);\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+                    cycle.incrementAndGet();\n+                }\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+                log.info(\"Background data generation finished.\");\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                error = false;\n+            }\n+            catch (Throwable e) {\n+                // The data streamer fails with an error on node stoppage event before the termination.\n+                if (X.hasCause(e, NodeStoppingException.class))\n+                    error = false;\n+                else if (e instanceof Exception)\n+                    log.error(\"Failed to generate data in background.\", e);\n+            }\n+            finally {\n+                if (error)\n+                    markBroken();\n+                else\n+                    markFinished(false);\n             }\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, Function.identity(), false, false);\n \n-        markSyncExecutionComplete();\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, Function<Integer, Integer> supplier, boolean markInited,\n+        boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {\n+            streamer.allowOverwrite(overwrite);\n+\n+            for (int i = 0; i < range && active(); i++) {\n+                streamer.addData(i, supplier.apply(i));\n+\n+                if (notifyTime + DATAGEN_NOTIFY_INTERVAL_NANO < System.nanoTime() ||\n+                    i - streamed >= DATAGEN_NOTIFY_INTERVAL_AMOUNT) {\n+                    notifyTime = System.nanoTime();\n+\n+                    if (markInited && !inited())\n+                        markInitialized();", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNjYyMA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474616620", "bodyText": "As you advised the delayed initialization was put into the app code. It begins putting data, loads some anount ant realeses the test to crash nodes after. I think if we wont reallocate it secod time, we forgot what we wanted to do.", "author": "Vladsz83", "createdAt": "2020-08-21T10:34:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NDg4NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474654885", "bodyText": "Simplified.", "author": "Vladsz83", "createdAt": "2020-08-21T12:06:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5ODUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474599422", "bodyText": "do we really need this additional logging?", "author": "anton-vinogradov", "createdAt": "2020-08-21T09:58:10Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -76,8 +76,11 @@ protected IgniteAwareApplication() {\n             else\n                 log.info(\"Application already done [finished=\" + finished + \", broken=\" + broken + \"]\");\n \n+            log.info(\"Waiting for graceful termination...\");\n+\n             while (!finished && !broken) {\n-                log.info(\"Waiting for graceful termnation.\");\n+                if (log.isTraceEnabled())\n+                    log.trace(\"Waiting for graceful termination cycle...\");", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxNzc4OQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474617789", "bodyText": "To me helps a lot to see what is going on when the app catches the stop signal. Ok, lets remove it.", "author": "Vladsz83", "createdAt": "2020-08-21T10:37:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY5Nzg1MQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474697851", "bodyText": "oki-doki. lets keep", "author": "anton-vinogradov", "createdAt": "2020-08-21T13:30:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU5OTQyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474602971", "bodyText": "Kill 0 means kill_crd. Any reason to have special param?", "author": "anton-vinogradov", "createdAt": "2020-08-21T10:05:35Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,109 +75,60 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYxODA5NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474618094", "bodyText": "Yes. It kils 0 nodes, but kills the coordinator and kills coordinator with load.", "author": "Vladsz83", "createdAt": "2020-08-21T10:38:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyNjY5OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474626698", "bodyText": "\"Kill 0 means kill_crd. \" Was. In presious commit. Now it go as externalized, configurable params and there is no such hidden meanings. Now eacp param works according to its name.", "author": "Vladsz83", "createdAt": "2020-08-21T10:58:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDcxMDkxOQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474710919", "bodyText": "Seems overcomplicated", "author": "anton-vinogradov", "createdAt": "2020-08-21T13:50:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDcxMzk3NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474713975", "bodyText": "What exactly? Trivial to me. No idea how to change.", "author": "Vladsz83", "createdAt": "2020-08-21T13:56:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwMjk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDQ2MA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474604460", "bodyText": "overcomplicated", "author": "anton-vinogradov", "createdAt": "2020-08-21T10:08:56Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -175,16 +138,19 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n+        if config.nodes_to_kill + (1 if config.kill_coordinator else 0) > self.servers.num_nodes - 1:", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDY1NTI4Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474655283", "bodyText": "Removed.", "author": "Vladsz83", "createdAt": "2020-08-21T12:06:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNDQ2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNTg2NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474605864", "bodyText": "should not be the diff between what node to kill.", "author": "anton-vinogradov", "createdAt": "2020-08-21T10:11:49Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +177,78 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n-\n-        assert by_log > 0, \"Negative node failure detection delay: \" + by_log + \". Probably it is a timezone issue.\"\n-        assert by_log <= time_holder, \"Value of node failure detection delay taken from by the node log (\" + \\\n-                                      str(by_log) + \"ms) must be lesser than measured value (\" + str(time_holder) + \\\n-                                      \"ms) because watching this event consumes extra time.\"\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))\n \n-        data['Detection of node(s) failure, measured (ms)'] = time_holder\n-        data['Detection of node(s) failure, by the log (ms)'] = by_log\n         data['Nodes failed'] = len(failed_nodes)\n \n         return data\n \n+    @staticmethod\n+    def __check_and_store_results(data, measured, delay_by_log):\n+        assert delay_by_log > 0, \\\n+            \"Negative failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms). It is \\\n+            probably an issue of the timezone or system clock settings.\"\n+        assert delay_by_log <= measured, \\\n+            \"Failure detection delay from the survived node log (\" + str(delay_by_log) + \"ms) must be lesser than  \\\n+            measured value (\" + str(measured) + \"ms) because watching this event consumes extra time. It is  \\\n+            probably an issue of the timezone or system clock settings.\"\n+\n+        data['Detection of node(s) failure, measured (ms)'] = measured\n+        data['Detection of node(s) failure, by the log (ms)'] = delay_by_log\n+\n     @staticmethod\n     def __failed_pattern(failed_node_id):\n         return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + failed_node_id\n \n-    def __choose_node_to_kill(self, nodes_to_kill):\n+    def __choose_node_to_kill(self, kill_coordinator, nodes_to_kill):\n         nodes = self.servers.nodes\n         coordinator = nodes[0].discovery_info().coordinator\n+        to_kill = []\n \n-        if nodes_to_kill < 1:\n-            to_kill = next(node for node in nodes if node.discovery_info().node_id == coordinator)\n-        else:\n-            to_kill = random.sample([n for n in nodes if n.discovery_info().node_id != coordinator], nodes_to_kill)\n+        if kill_coordinator:", "originalCommit": "405298b6389d26a2558d8811f97e4feaab5d0770", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYyMTQzNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r474621436", "bodyText": "We decided to separete coordinator failure. It should fail too, but we wanted to see the differeace with an ordinary node. Didn't we? There are set op parametrized tests for it: kill only coordinator, kill coordinator + 1 node, kill coordinator + 2 nodes. All ander load and without. Also: kill 1 node without coordinator, kill 2 nodes without coordinator. Did we change our mind and don't check exactly coordinator failure?", "author": "Vladsz83", "createdAt": "2020-08-21T10:46:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYwNTg2NA=="}], "type": "inlineReview"}, {"oid": "2bbeaca014d0580b4e82e1eb55e0cc1d194d44a3", "url": "https://github.com/apache/ignite/commit/2bbeaca014d0580b4e82e1eb55e0cc1d194d44a3", "message": "Fixes", "committedDate": "2020-08-21T12:02:44Z", "type": "commit"}, {"oid": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "url": "https://github.com/apache/ignite/commit/83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "message": "Separated warmup.", "committedDate": "2020-08-21T13:58:08Z", "type": "commit"}, {"oid": "a205e2670a6d36498ff39038023a34284aebec6d", "url": "https://github.com/apache/ignite/commit/a205e2670a6d36498ff39038023a34284aebec6d", "message": "Fixed nodes num and coordinator", "committedDate": "2020-08-24T09:22:38Z", "type": "commit"}, {"oid": "ea9e184f519f9769409f8f7b87d38d5684af01e5", "url": "https://github.com/apache/ignite/commit/ea9e184f519f9769409f8f7b87d38d5684af01e5", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load", "committedDate": "2020-08-24T09:23:15Z", "type": "commit"}, {"oid": "53d082db24f889bec993ab282289fe5cd8556239", "url": "https://github.com/apache/ignite/commit/53d082db24f889bec993ab282289fe5cd8556239", "message": "Merge remote-tracking branch 'origin/ducktape-disco-load' into ducktape-disco-load", "committedDate": "2020-08-24T09:24:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwNzc3NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475407774", "bodyText": "let it be a \"warmup\" option", "author": "anton-vinogradov", "createdAt": "2020-08-24T07:55:43Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;", "originalCommit": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzMDkwNA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475530904", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-24T11:23:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwNzc3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475409323", "bodyText": "This makes behavior counter-intuitive.\nThe small range should not force warmup finish.\nRange 10 (keys 0-9) and warmup 10M is a possible case for small memory consumption checks.", "author": "anton-vinogradov", "createdAt": "2020-08-24T07:58:19Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).", "originalCommit": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwMTUwMQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475501501", "bodyText": "How do we make the app started witout markInitialized()? The test will fail witout the app initialization.", "author": "Vladsz83", "createdAt": "2020-08-24T10:27:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU0OTc0Nw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475549747", "bodyText": "we should markInitialized only when warmup is done.\nDoes not matter that is bigger (warmup or range)", "author": "anton-vinogradov", "createdAt": "2020-08-24T12:02:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1NTEzMQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475755131", "bodyText": "Used a % as an warming up amount.", "author": "Vladsz83", "createdAt": "2020-08-24T16:50:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQwOTMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475411126", "bodyText": "no reason to create datastreamer if (when) cache.put is used", "author": "anton-vinogradov", "createdAt": "2020-08-24T08:01:47Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();\n+        int range = jsonNode.get(\"range\").asInt();\n \n-        IgniteCache<Integer, Integer> cache = ignite.createCache(jsonNode.get(\"cacheName\").asText());\n+        if (infinite) {\n+            log.info(\"Generating data in background...\");\n \n-        try (IgniteDataStreamer<Integer, Integer> stmr = ignite.dataStreamer(cache.getName())) {\n-            for (int i = 0; i < jsonNode.get(\"range\").asInt(); i++) {\n-                stmr.addData(i, i);\n+            while (active()) {\n+                generateData(cacheName, range, true, optimized, true);\n \n-                if (i % 10_000 == 0)\n-                    log.info(\"Streamed \" + i + \" entries\");\n+                // Delayed initialization for small data amount ( < DELAYED_INITIALIZATION_AMOUNT ).\n+                if (!inited())\n+                    markInitialized();\n             }\n+\n+            log.info(\"Background data generation finished.\");\n+\n+            markFinished();\n         }\n+        else {\n+            log.info(\"Generating data...\");\n+\n+            generateData(cacheName, range, false, optimized, false);\n+\n+            log.info(\"Data generation finished. Generated \" + range + \" entries.\");\n+\n+            markSyncExecutionComplete();\n+        }\n+    }\n+\n+    /** */\n+    private void generateData(String cacheName, int range, boolean delayedInit, boolean optimized, boolean overwrite) {\n+        long notifyTime = System.nanoTime();\n \n-        markSyncExecutionComplete();\n+        int streamed = 0;\n+\n+        if (log.isDebugEnabled())\n+            log.debug(\"Creating cache...\");\n+\n+        IgniteCache<Integer, Integer> cache = ignite.getOrCreateCache(cacheName);\n+\n+        try (IgniteDataStreamer<Integer, Integer> streamer = ignite.dataStreamer(cacheName)) {", "originalCommit": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ5NDgxNQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475494815", "bodyText": "The reason is simplier code. If/ try-catch witch finally-close. Why not?", "author": "Vladsz83", "createdAt": "2020-08-24T10:17:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MDkzMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475550932", "bodyText": "This technique makes reading harder.\nYou see that DS created but put is used. This can scare you %)", "author": "anton-vinogradov", "createdAt": "2020-08-24T12:04:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1NTYxMw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475755613", "bodyText": "no optimized option makes this inactual.", "author": "Vladsz83", "createdAt": "2020-08-24T16:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMTEyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMjY4NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475412684", "bodyText": "one-line javadocs are not allowed for methods", "author": "anton-vinogradov", "createdAt": "2020-08-24T08:04:53Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/utils/IgniteAwareApplication.java", "diffHunk": "@@ -165,6 +173,16 @@ protected boolean terminated() {\n         return terminated;\n     }\n \n+    /** */", "originalCommit": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzMDg0MA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475530840", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-24T11:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQxMjY4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475441932", "bodyText": "does it really make sense to have backoff_sec=0.01?", "author": "anton-vinogradov", "createdAt": "2020-08-24T08:57:51Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[0, 1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0 and not config.kill_coordinator:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,", "originalCommit": "83a8ddb68a0bafa92feb72d6cd31736ca49eaa3f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwMzM3NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475503375", "bodyText": "Why not? We have slow test and we'll get more test and more. The faster the are, the better. Let's detect target values, indicators asap. Make sense?", "author": "Vladsz83", "createdAt": "2020-08-24T10:29:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MTY4OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475551688", "bodyText": "We should not use this approach.\nwe already have explicit time at logs.\nand we'll make sure time is sync across the cluster at other tests.", "author": "anton-vinogradov", "createdAt": "2020-08-24T12:06:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1MTE4Mw==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475751183", "bodyText": "Only the logged time left.", "author": "Vladsz83", "createdAt": "2020-08-24T16:44:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ0MTkzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475467779", "bodyText": "how about \"batched\" or something like that?", "author": "anton-vinogradov", "createdAt": "2020-08-24T09:32:41Z", "path": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/DataGenerationApplication.java", "diffHunk": "@@ -20,27 +20,103 @@\n import com.fasterxml.jackson.databind.JsonNode;\n import org.apache.ignite.IgniteCache;\n import org.apache.ignite.IgniteDataStreamer;\n+import org.apache.ignite.internal.NodeStoppingException;\n import org.apache.ignite.internal.ducktest.utils.IgniteAwareApplication;\n+import org.apache.ignite.internal.util.typedef.X;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n \n /**\n  *\n  */\n public class DataGenerationApplication extends IgniteAwareApplication {\n+    /** Logger. */\n+    protected static final Logger log = LogManager.getLogger(DataGenerationApplication.class.getName());\n+\n+    /** */\n+    private static final long DATAGEN_NOTIFY_INTERVAL_NANO = 1500 * 1000000L;\n+\n+    /** */\n+    private static final int DATAGEN_NOTIFY_INTERVAL_AMOUNT = 10_000;\n+\n+    /** */\n+    private static final int DELAYED_INITIALIZATION_AMOUNT = 10_000;\n+\n     /** {@inheritDoc} */\n     @Override protected void run(JsonNode jsonNode) {\n-        log.info(\"Creating cache...\");\n+        String cacheName = jsonNode.get(\"cacheName\").asText();\n+        boolean infinite = jsonNode.hasNonNull(\"infinite\") && jsonNode.get(\"infinite\").asBoolean();\n+        boolean optimized = !jsonNode.hasNonNull(\"optimized\") || jsonNode.get(\"optimized\").asBoolean();", "originalCommit": "53d082db24f889bec993ab282289fe5cd8556239", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwOTkxNg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475509916", "bodyText": "Why expose internal inplementation? It's not only buffered. It also choises nodes to load data by keys. It's an optimized load. What's the reason to name by one optimization step?", "author": "Vladsz83", "createdAt": "2020-08-24T10:38:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MjQ3OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475552478", "bodyText": "the better case is to create 2 classes (DSDataGenerator and PutDG, or something like this) to make this simple.\nJust overwrite method from abstract DGApplication class)", "author": "anton-vinogradov", "createdAt": "2020-08-24T12:08:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc1MDk1Mg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475750952", "bodyText": "'optimized' got removed. It was involved to wrap node-stop-issue of the data streamer. The code got changed, I kept it as simple option which looks useful. Thi look to me trivilab, but if rised discussion, we don't need it in this ticket. For now, we need only contiguous loading. The streamer was introdused before. It is ok.", "author": "Vladsz83", "createdAt": "2020-08-24T16:43:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2Nzc3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475481365", "bodyText": "how about to rename to last_blabla (as opposed to first_terminated)?", "author": "anton-vinogradov", "createdAt": "2020-08-24T09:52:29Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -63,143 +75,86 @@ def __init__(self, test_context):\n         super(DiscoveryTest, self).__init__(test_context=test_context)\n         self.zk_quorum = None\n         self.servers = None\n+        self.loader = None\n \n-    def __start_zk_quorum(self):\n-        self.zk_quorum = ZookeeperService(self.test_context, 3)\n-\n-        self.stage(\"Starting ZooKeeper quorum\")\n-\n-        self.zk_quorum.start()\n+    @cluster(num_nodes=NUM_NODES)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_tcp(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n+        \"\"\"\n+        Test nodes failure scenario with TcpDiscoverySpi.\n+        \"\"\"\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-        self.stage(\"ZooKeeper quorum started\")\n+        return self.__simulate_nodes_failure(ignite_version, self.__properties(), None, config)\n \n-    @staticmethod\n-    def __properties(zookeeper_settings=None):\n+    @cluster(num_nodes=NUM_NODES + 3)\n+    @matrix(ignite_version=[str(DEV_BRANCH), str(LATEST_2_8)],\n+            kill_coordinator=[False, True],\n+            nodes_to_kill=[1, 2],\n+            with_load=[False, True])\n+    def test_zk(self, ignite_version, kill_coordinator, nodes_to_kill, with_load):\n         \"\"\"\n-        :param zookeeper_settings: ZooKeeperDiscoverySpi settings. If None, TcpDiscoverySpi will be used.\n-        :return: Rendered node's properties.\n+        Test node failure scenario with ZooKeeperSpi.\n         \"\"\"\n-        return Template(DiscoveryTest.CONFIG_TEMPLATE) \\\n-            .render(failure_detection_timeout=DiscoveryTest.FAILURE_DETECTION_TIMEOUT,\n-                    zookeeper_settings=zookeeper_settings)\n+        config = DiscoveryTest.Config(nodes_to_kill, kill_coordinator, with_load)\n \n-    @staticmethod\n-    def __zk_properties(connection_string):\n-        return DiscoveryTest.__properties(zookeeper_settings={'connection_string': connection_string})\n+        self.__start_zk_quorum()\n+\n+        properties = self.__zk_properties(self.zk_quorum.connection_string())\n+        modules = [\"zookeeper\"]\n+\n+        return self.__simulate_nodes_failure(ignite_version, properties, modules, config)\n \n     def setUp(self):\n         pass\n \n     def teardown(self):\n-        if self.zk_quorum:\n-            self.zk_quorum.stop()\n+        if self.loader:\n+            self.loader.stop()\n \n         if self.servers:\n             self.servers.stop()\n \n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 1)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 2)\n-\n-    @cluster(num_nodes=NUM_NODES)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_tcp_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with TcpDiscoverySpi.\n-        \"\"\"\n-        return self.__simulate_nodes_failure(version, self.__properties(), 0)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_single(self, version):\n-        \"\"\"\n-        Test single node failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 1)\n-\n-    @cluster(num_nodes=NUM_NODES + 3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_not_coordinator_two(self, version):\n-        \"\"\"\n-        Test two-node-failure scenario (not the coordinator) with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n-\n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 2)\n-\n-    @cluster(num_nodes=NUM_NODES+3)\n-    @parametrize(version=str(DEV_BRANCH))\n-    @parametrize(version=str(LATEST_2_7))\n-    def test_zk_coordinator(self, version):\n-        \"\"\"\n-        Test coordinator-failure scenario with ZooKeeper.\n-        \"\"\"\n-        self.__start_zk_quorum()\n+        if self.zk_quorum:\n+            self.zk_quorum.stop()\n \n-        return self.__simulate_nodes_failure(version, self.__zk_properties(self.zk_quorum.connection_string()), 0)\n+    def __simulate_nodes_failure(self, version, properties, modules, config):\n+        if config.nodes_to_kill == 0:\n+            return {\"No nodes to kill\": \"Nothing to do\"}\n \n-    def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n-        \"\"\"\n-        :param nodes_to_kill: How many nodes to kill. If <1, the coordinator is the choice. Otherwise: not-coordinator\n-        nodes of given number.\n-        \"\"\"\n         self.servers = IgniteService(\n             self.test_context,\n-            num_nodes=self.NUM_NODES,\n-            modules=[\"zookeeper\"],\n+            num_nodes=self.NUM_NODES - 1,\n+            modules=modules,\n             properties=properties,\n             version=version)\n \n-        self.stage(\"Starting ignite cluster\")\n-\n         time_holder = self.monotonic()\n \n         self.servers.start()\n \n-        if nodes_to_kill > self.servers.num_nodes - 1:\n-            raise Exception(\"Too many nodes to kill: \" + str(nodes_to_kill))\n-\n         data = {'Ignite cluster start time (s)': round(self.monotonic() - time_holder, 1)}\n-        self.stage(\"Topology is ready\")\n \n-        failed_nodes, survived_node = self.__choose_node_to_kill(nodes_to_kill)\n+        failed_nodes, survived_node = self.__choose_node_to_kill(config.kill_coordinator, config.nodes_to_kill)\n \n         ids_to_wait = [node.discovery_info().node_id for node in failed_nodes]\n \n-        self.stage(\"Stopping \" + str(len(failed_nodes)) + \" nodes.\")\n+        if config.with_load:\n+            self.__start_loading(version, properties, modules)\n \n         first_terminated = self.servers.stop_nodes_async(failed_nodes, clean_shutdown=False, wait_for_stop=False)\n \n-        self.stage(\"Waiting for failure detection of \" + str(len(failed_nodes)) + \" nodes.\")\n-\n         # Keeps dates of logged node failures.\n         logged_timestamps = []\n \n         for failed_id in ids_to_wait:\n-            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 10,\n+            self.servers.await_event_on_node(self.__failed_pattern(failed_id), survived_node, 20,\n                                              from_the_beginning=True, backoff_sec=0.01)\n             # Save mono of last detected failure.\n             time_holder = self.monotonic()", "originalCommit": "53d082db24f889bec993ab282289fe5cd8556239", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUxMzY2OA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475513668", "bodyText": "This returns time of first kill command. Why last?", "author": "Vladsz83", "createdAt": "2020-08-24T10:46:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU1MzAxMA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475553010", "bodyText": "since you have a loop, it will record last turn time.", "author": "anton-vinogradov", "createdAt": "2020-08-24T12:09:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc0OTM0Mg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475749342", "bodyText": "first_terminated is out the loop, it's before it. There is an atomic inside. It holds time of the first kill command.", "author": "Vladsz83", "createdAt": "2020-08-24T16:40:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MTM2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MjU1NA==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475482554", "bodyText": "how about also provide raw list here? duration1 and duration2.", "author": "anton-vinogradov", "createdAt": "2020-08-24T09:54:30Z", "path": "modules/ducktests/tests/ignitetest/tests/discovery_test.py", "diffHunk": "@@ -210,37 +165,75 @@ def __simulate_nodes_failure(self, version, properties, nodes_to_kill=1):\n \n         logged_timestamps.sort(reverse=True)\n \n-        # Failure detection delay.\n-        time_holder = int((time_holder - first_terminated[0]) * 1000)\n-        # Failure detection delay by log.\n-        by_log = epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1])\n+        self.__check_and_store_results(data, int((time_holder - first_terminated[0]) * 1000),\n+                                       epoch_mills(logged_timestamps[0]) - epoch_mills(first_terminated[1]))", "originalCommit": "53d082db24f889bec993ab282289fe5cd8556239", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUzNjE2Mg==", "url": "https://github.com/apache/ignite/pull/8159#discussion_r475536162", "bodyText": "Fixed", "author": "Vladsz83", "createdAt": "2020-08-24T11:33:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ4MjU1NA=="}], "type": "inlineReview"}, {"oid": "7950c928424f31d00160e30521a38bbea707dda7", "url": "https://github.com/apache/ignite/commit/7950c928424f31d00160e30521a38bbea707dda7", "message": "Fixes", "committedDate": "2020-08-24T11:22:59Z", "type": "commit"}, {"oid": "5ef9e977a62085fa1d95565b33f6cd9e79e9fa7f", "url": "https://github.com/apache/ignite/commit/5ef9e977a62085fa1d95565b33f6cd9e79e9fa7f", "message": "Fixes", "committedDate": "2020-08-24T11:34:00Z", "type": "commit"}, {"oid": "2ad215619742db560ed0f28e608d366082f682e3", "url": "https://github.com/apache/ignite/commit/2ad215619742db560ed0f28e608d366082f682e3", "message": "removed results check", "committedDate": "2020-08-24T11:51:05Z", "type": "commit"}, {"oid": "b167ab98b46053604014c6904d83b70aba499ea7", "url": "https://github.com/apache/ignite/commit/b167ab98b46053604014c6904d83b70aba499ea7", "message": "Fixes.", "committedDate": "2020-08-25T07:54:41Z", "type": "commit"}, {"oid": "ee5dbf4a5ce6a99fbf2c88b29d577ca07d186a86", "url": "https://github.com/apache/ignite/commit/ee5dbf4a5ce6a99fbf2c88b29d577ca07d186a86", "message": "Merge branch 'ignite-ducktape' into ducktape-disco-load", "committedDate": "2020-08-25T08:41:43Z", "type": "commit"}, {"oid": "7ee5b244cb3241b66e9ce9a71063d81512bdd37e", "url": "https://github.com/apache/ignite/commit/7ee5b244cb3241b66e9ce9a71063d81512bdd37e", "message": "Separated data loading.", "committedDate": "2020-08-25T15:02:49Z", "type": "commit"}, {"oid": "79fc150ac5fb9e030031130ec367142f48d95836", "url": "https://github.com/apache/ignite/commit/79fc150ac5fb9e030031130ec367142f48d95836", "message": "spelling fix.", "committedDate": "2020-08-25T15:16:41Z", "type": "commit"}, {"oid": "951ce03d5e14cb3c04404d5cf8f4056a95b39923", "url": "https://github.com/apache/ignite/commit/951ce03d5e14cb3c04404d5cf8f4056a95b39923", "message": "+info", "committedDate": "2020-08-25T15:28:59Z", "type": "commit"}]}