{"pr_number": 735, "pr_title": "PHOENIX-5734 - IndexScrutinyTool should not report rows beyond maxLoo\u2026", "pr_createdAt": "2020-03-17T18:10:44Z", "pr_url": "https://github.com/apache/phoenix/pull/735", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU0NzAzNg==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394547036", "bodyText": "aah! nice :)", "author": "swaroopak", "createdAt": "2020-03-18T18:12:46Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyToolBaseIT.java", "diffHunk": "@@ -54,8 +54,9 @@\n                 new ReadOnlyProps(clientProps.entrySet().iterator()));\n     }\n \n-    protected List<Job> runScrutiny(String[] cmdArgs) throws Exception {\n-        IndexScrutinyTool scrutiny = new IndexScrutinyTool(IndexScrutinyMapperForTest.class);\n+    protected List<Job> runScrutiny(Class<? extends IndexScrutinyMapper> mapperClass,", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU2OTkyNg==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394569926", "bodyText": "nit : consider expected size = 2", "author": "gokceni", "createdAt": "2020-03-18T18:52:37Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyWithMaxLookbackIT.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import com.google.common.collect.Maps;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.regionserver.ScanInfoUtil;\n+import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyMapper;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyTool;\n+import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.ManualEnvironmentEdge;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.ReadOnlyProps;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.phoenix.mapreduce.index.IndexScrutinyMapperForTest.MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.INVALID_ROW_COUNT;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.VALID_ROW_COUNT;\n+import static org.apache.phoenix.util.TestUtil.TEST_PROPERTIES;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IndexScrutinyWithMaxLookbackIT extends IndexScrutinyToolBaseIT {\n+\n+    private static PreparedStatement upsertDataStmt;\n+    private static String dataTableFullName;\n+    private static String schema;\n+    private static String dataTableName;\n+    private static String indexTableName;\n+    private static String viewName;\n+    private static boolean isViewIndex;\n+    private static ManualEnvironmentEdge testClock;\n+    public static final String UPSERT_DATA = \"UPSERT INTO %s VALUES (?, ?, ?)\";\n+\n+    @BeforeClass\n+    public static synchronized void doSetup() throws Exception {\n+        Map<String, String> props = Maps.newHashMapWithExpectedSize(1);", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU3MDUxMQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394570511", "bodyText": "nit: consider prepending \"I_\" and \"D_\" to names", "author": "gokceni", "createdAt": "2020-03-18T18:53:39Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyWithMaxLookbackIT.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import com.google.common.collect.Maps;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.regionserver.ScanInfoUtil;\n+import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyMapper;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyTool;\n+import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.ManualEnvironmentEdge;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.ReadOnlyProps;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.phoenix.mapreduce.index.IndexScrutinyMapperForTest.MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.INVALID_ROW_COUNT;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.VALID_ROW_COUNT;\n+import static org.apache.phoenix.util.TestUtil.TEST_PROPERTIES;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IndexScrutinyWithMaxLookbackIT extends IndexScrutinyToolBaseIT {\n+\n+    private static PreparedStatement upsertDataStmt;\n+    private static String dataTableFullName;\n+    private static String schema;\n+    private static String dataTableName;\n+    private static String indexTableName;\n+    private static String viewName;\n+    private static boolean isViewIndex;\n+    private static ManualEnvironmentEdge testClock;\n+    public static final String UPSERT_DATA = \"UPSERT INTO %s VALUES (?, ?, ?)\";\n+\n+    @BeforeClass\n+    public static synchronized void doSetup() throws Exception {\n+        Map<String, String> props = Maps.newHashMapWithExpectedSize(1);\n+        props.put(QueryServices.GLOBAL_INDEX_ROW_AGE_THRESHOLD_TO_DELETE_MS_ATTRIB, Long.toString(0));\n+        props.put(ScanInfoUtil.PHOENIX_MAX_LOOKBACK_AGE_CONF_KEY,\n+            Integer.toString(MAX_LOOKBACK));\n+        setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookBack() throws Exception {\n+        schema = generateUniqueName();\n+        dataTableName = generateUniqueName();\n+        indexTableName = generateUniqueName();", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU3MjAzNA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394572034", "bodyText": "nit: Would be good to have a comment on what the clock increments are doing.", "author": "gokceni", "createdAt": "2020-03-18T18:56:33Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyWithMaxLookbackIT.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import com.google.common.collect.Maps;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.regionserver.ScanInfoUtil;\n+import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyMapper;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyTool;\n+import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.ManualEnvironmentEdge;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.ReadOnlyProps;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.phoenix.mapreduce.index.IndexScrutinyMapperForTest.MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.INVALID_ROW_COUNT;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.VALID_ROW_COUNT;\n+import static org.apache.phoenix.util.TestUtil.TEST_PROPERTIES;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IndexScrutinyWithMaxLookbackIT extends IndexScrutinyToolBaseIT {\n+\n+    private static PreparedStatement upsertDataStmt;\n+    private static String dataTableFullName;\n+    private static String schema;\n+    private static String dataTableName;\n+    private static String indexTableName;\n+    private static String viewName;\n+    private static boolean isViewIndex;\n+    private static ManualEnvironmentEdge testClock;\n+    public static final String UPSERT_DATA = \"UPSERT INTO %s VALUES (?, ?, ?)\";\n+\n+    @BeforeClass\n+    public static synchronized void doSetup() throws Exception {\n+        Map<String, String> props = Maps.newHashMapWithExpectedSize(1);\n+        props.put(QueryServices.GLOBAL_INDEX_ROW_AGE_THRESHOLD_TO_DELETE_MS_ATTRIB, Long.toString(0));\n+        props.put(ScanInfoUtil.PHOENIX_MAX_LOOKBACK_AGE_CONF_KEY,\n+            Integer.toString(MAX_LOOKBACK));\n+        setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookBack() throws Exception {\n+        schema = generateUniqueName();\n+        dataTableName = generateUniqueName();\n+        indexTableName = generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema, dataTableName);\n+        isViewIndex = false;\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES=0, VERSIONS=1\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP)\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                dataTableFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(dataTableName, dataTableFullName, testClock);\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookback_viewIndex() throws Exception {\n+        schema = \"S\"+generateUniqueName();\n+        dataTableName = \"T\"+generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema,dataTableName);\n+        indexTableName = \"VI\"+generateUniqueName();\n+        isViewIndex = true;\n+        viewName = \"V\"+generateUniqueName();\n+        String viewFullName = SchemaUtil.getTableName(schema,viewName);\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES = 0, VERSIONS = 1 \";\n+        String viewDDL = \"CREATE VIEW %s AS SELECT * FROM %s\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP) VERSIONS = 1\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(viewDDL, viewFullName, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                viewFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(viewName, viewFullName, testClock);\n+    }\n+\n+    private void upsertDataAndScrutinize(String tableName, String tableFullName,\n+                                         ManualEnvironmentEdge testClock)\n+        throws Exception {\n+        try(Connection conn =\n+                DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            // insert two rows\n+            upsertDataStmt = getUpsertDataStmt(tableFullName, conn);\n+\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(upsertDataStmt, 1, \"name-1\", 98051);\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(upsertDataStmt, 2, \"name-2\", 98052);\n+            conn.commit();\n+            long afterInsertSCN = EnvironmentEdgeManager.currentTimeMillis() + 1;\n+            testClock.setValue(afterInsertSCN);\n+            EnvironmentEdgeManager.injectEdge(testClock);\n+            testClock.incrementValue(1);", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU3MjI5NA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394572294", "bodyText": "Suggest to rename this function to be updateIndexRow", "author": "gokceni", "createdAt": "2020-03-18T18:57:00Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyWithMaxLookbackIT.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import com.google.common.collect.Maps;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.regionserver.ScanInfoUtil;\n+import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyMapper;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyTool;\n+import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.ManualEnvironmentEdge;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.ReadOnlyProps;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.phoenix.mapreduce.index.IndexScrutinyMapperForTest.MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.INVALID_ROW_COUNT;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.VALID_ROW_COUNT;\n+import static org.apache.phoenix.util.TestUtil.TEST_PROPERTIES;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IndexScrutinyWithMaxLookbackIT extends IndexScrutinyToolBaseIT {\n+\n+    private static PreparedStatement upsertDataStmt;\n+    private static String dataTableFullName;\n+    private static String schema;\n+    private static String dataTableName;\n+    private static String indexTableName;\n+    private static String viewName;\n+    private static boolean isViewIndex;\n+    private static ManualEnvironmentEdge testClock;\n+    public static final String UPSERT_DATA = \"UPSERT INTO %s VALUES (?, ?, ?)\";\n+\n+    @BeforeClass\n+    public static synchronized void doSetup() throws Exception {\n+        Map<String, String> props = Maps.newHashMapWithExpectedSize(1);\n+        props.put(QueryServices.GLOBAL_INDEX_ROW_AGE_THRESHOLD_TO_DELETE_MS_ATTRIB, Long.toString(0));\n+        props.put(ScanInfoUtil.PHOENIX_MAX_LOOKBACK_AGE_CONF_KEY,\n+            Integer.toString(MAX_LOOKBACK));\n+        setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookBack() throws Exception {\n+        schema = generateUniqueName();\n+        dataTableName = generateUniqueName();\n+        indexTableName = generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema, dataTableName);\n+        isViewIndex = false;\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES=0, VERSIONS=1\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP)\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                dataTableFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(dataTableName, dataTableFullName, testClock);\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookback_viewIndex() throws Exception {\n+        schema = \"S\"+generateUniqueName();\n+        dataTableName = \"T\"+generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema,dataTableName);\n+        indexTableName = \"VI\"+generateUniqueName();\n+        isViewIndex = true;\n+        viewName = \"V\"+generateUniqueName();\n+        String viewFullName = SchemaUtil.getTableName(schema,viewName);\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES = 0, VERSIONS = 1 \";\n+        String viewDDL = \"CREATE VIEW %s AS SELECT * FROM %s\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP) VERSIONS = 1\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(viewDDL, viewFullName, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                viewFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(viewName, viewFullName, testClock);\n+    }\n+\n+    private void upsertDataAndScrutinize(String tableName, String tableFullName,\n+                                         ManualEnvironmentEdge testClock)\n+        throws Exception {\n+        try(Connection conn =\n+                DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            // insert two rows\n+            upsertDataStmt = getUpsertDataStmt(tableFullName, conn);\n+\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(upsertDataStmt, 1, \"name-1\", 98051);\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(upsertDataStmt, 2, \"name-2\", 98052);\n+            conn.commit();\n+            long afterInsertSCN = EnvironmentEdgeManager.currentTimeMillis() + 1;\n+            testClock.setValue(afterInsertSCN);\n+            EnvironmentEdgeManager.injectEdge(testClock);\n+            testClock.incrementValue(1);\n+            testClock.incrementValue(MAX_LOOKBACK /2  * 1000);\n+            long scrutinyTs = EnvironmentEdgeManager.currentTimeMillis();\n+            changeIndexValue();\n+            testClock.incrementValue(MAX_LOOKBACK /2  * 1000);\n+            List<Job> completedJobs = runScrutiny(schema, tableName, indexTableName, scrutinyTs);\n+            Job job = completedJobs.get(0);\n+            assertTrue(job.isSuccessful());\n+            assertCounters(job.getCounters());\n+        }\n+    }\n+    private void changeIndexValue() throws SQLException {", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU4OTE5NA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394589194", "bodyText": "nit: unnecessary change", "author": "swaroopak", "createdAt": "2020-03-18T19:28:42Z", "path": "phoenix-core/src/test/java/org/apache/phoenix/mapreduce/index/IndexScrutinyMapperForTest.java", "diffHunk": "@@ -23,6 +23,8 @@\n public class IndexScrutinyMapperForTest extends IndexScrutinyMapper {\n \n     public static final int TEST_TABLE_TTL = 3600;\n+    public static final int MAX_LOOKBACK = 6;", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU5MzcxMg==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394593712", "bodyText": "why do we need them around?", "author": "swaroopak", "createdAt": "2020-03-18T19:37:20Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexScrutinyMapper.java", "diffHunk": "@@ -288,8 +301,15 @@ protected void checkIfInvalidRowsExpired(Context context,\n             Pair<Long, List<Object>> sourceValues = entry.getValue();\n             Long sourceTS = sourceValues.getFirst();\n             if (hasRowExpiredOnSource(sourceTS, ttl)) {\n-                context.getCounter(PhoenixScrutinyJobCounters.EXPIRED_ROW_COUNT).increment(1);\n-                itr.remove();\n+                context.getCounter(PhoenixScrutinyJobCounters.EXPIRED_ROW_COUNT).increment(1L);\n+                itr.remove(); //don't output to the scrutiny table\n+            } else if (isRowOlderThanMaxLookback(sourceTS)){\n+                context.getCounter(PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK).increment(1L);\n+                //still output to the scrutiny table just in case it's useful", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDM0MQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394674341", "bodyText": "Humans need to evaluate beyond max lookback counters to see if they're valid issues or not.", "author": "gjacoby126", "createdAt": "2020-03-18T22:25:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU5MzcxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkwNjcxMw==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395906713", "bodyText": "@gjacoby126 Any reason to be concerned about bloating the scrutiny table? This is an expected race condition that can happen pretty regularly if rows are updated at the cadence of around MaxLookbackAge. Humans may not necessarily have bandwidth to look at potentially large number of rows. If we are going to emit to scrutiny table, perhaps we should add a way to filter these out as well to make them manageable.", "author": "priyankporwal", "createdAt": "2020-03-20T21:54:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU5MzcxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDU5NDYzNQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394594635", "bodyText": "nit: space before '{' this and some other places.", "author": "swaroopak", "createdAt": "2020-03-18T19:39:11Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexScrutinyMapper.java", "diffHunk": "@@ -299,7 +319,16 @@ protected boolean hasRowExpiredOnSource(Long sourceTS, Long ttl) {\n         return ttl != Integer.MAX_VALUE && sourceTS + ttl*1000 < currentTS;\n     }\n \n-    private long getTableTtl() throws SQLException, IOException {\n+    protected boolean isRowOlderThanMaxLookback(Long sourceTS){", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwMTIzMg==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394601232", "bodyText": "why not take isNamespaceEnabled property from the config?", "author": "swaroopak", "createdAt": "2020-03-18T19:52:03Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyWithMaxLookbackIT.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import com.google.common.collect.Maps;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.regionserver.ScanInfoUtil;\n+import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyMapper;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyTool;\n+import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.ManualEnvironmentEdge;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.ReadOnlyProps;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.phoenix.mapreduce.index.IndexScrutinyMapperForTest.MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.INVALID_ROW_COUNT;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.VALID_ROW_COUNT;\n+import static org.apache.phoenix.util.TestUtil.TEST_PROPERTIES;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IndexScrutinyWithMaxLookbackIT extends IndexScrutinyToolBaseIT {\n+\n+    private static PreparedStatement upsertDataStmt;\n+    private static String dataTableFullName;\n+    private static String schema;\n+    private static String dataTableName;\n+    private static String indexTableName;\n+    private static String viewName;\n+    private static boolean isViewIndex;\n+    private static ManualEnvironmentEdge testClock;\n+    public static final String UPSERT_DATA = \"UPSERT INTO %s VALUES (?, ?, ?)\";\n+\n+    @BeforeClass\n+    public static synchronized void doSetup() throws Exception {\n+        Map<String, String> props = Maps.newHashMapWithExpectedSize(1);\n+        props.put(QueryServices.GLOBAL_INDEX_ROW_AGE_THRESHOLD_TO_DELETE_MS_ATTRIB, Long.toString(0));\n+        props.put(ScanInfoUtil.PHOENIX_MAX_LOOKBACK_AGE_CONF_KEY,\n+            Integer.toString(MAX_LOOKBACK));\n+        setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookBack() throws Exception {\n+        schema = generateUniqueName();\n+        dataTableName = generateUniqueName();\n+        indexTableName = generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema, dataTableName);\n+        isViewIndex = false;\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES=0, VERSIONS=1\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP)\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                dataTableFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(dataTableName, dataTableFullName, testClock);\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookback_viewIndex() throws Exception {\n+        schema = \"S\"+generateUniqueName();\n+        dataTableName = \"T\"+generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema,dataTableName);\n+        indexTableName = \"VI\"+generateUniqueName();\n+        isViewIndex = true;\n+        viewName = \"V\"+generateUniqueName();\n+        String viewFullName = SchemaUtil.getTableName(schema,viewName);\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES = 0, VERSIONS = 1 \";\n+        String viewDDL = \"CREATE VIEW %s AS SELECT * FROM %s\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP) VERSIONS = 1\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(viewDDL, viewFullName, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                viewFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(viewName, viewFullName, testClock);\n+    }\n+\n+    private void upsertDataAndScrutinize(String tableName, String tableFullName,\n+                                         ManualEnvironmentEdge testClock)\n+        throws Exception {\n+        try(Connection conn =\n+                DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            // insert two rows\n+            upsertDataStmt = getUpsertDataStmt(tableFullName, conn);\n+\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(upsertDataStmt, 1, \"name-1\", 98051);\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(upsertDataStmt, 2, \"name-2\", 98052);\n+            conn.commit();\n+            long afterInsertSCN = EnvironmentEdgeManager.currentTimeMillis() + 1;\n+            testClock.setValue(afterInsertSCN);\n+            EnvironmentEdgeManager.injectEdge(testClock);\n+            testClock.incrementValue(1);\n+            testClock.incrementValue(MAX_LOOKBACK /2  * 1000);\n+            long scrutinyTs = EnvironmentEdgeManager.currentTimeMillis();\n+            changeIndexValue();\n+            testClock.incrementValue(MAX_LOOKBACK /2  * 1000);\n+            List<Job> completedJobs = runScrutiny(schema, tableName, indexTableName, scrutinyTs);\n+            Job job = completedJobs.get(0);\n+            assertTrue(job.isSuccessful());\n+            assertCounters(job.getCounters());\n+        }\n+    }\n+    private void changeIndexValue() throws SQLException {\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            String tableName = isViewIndex ?\n+                SchemaUtil.getTableName(schema, viewName) : dataTableFullName;\n+            PreparedStatement stmt = getUpsertDataStmt(tableName, conn);\n+            NonParameterizedIndexScrutinyToolIT.upsertRow(stmt, 1, \"name-1\", 38139);\n+            conn.commit();\n+        }\n+    }\n+\n+    private static PreparedStatement getUpsertDataStmt(String tableFullName, Connection conn) throws SQLException {\n+        return conn.prepareStatement(String.format(UPSERT_DATA, tableFullName));\n+    }\n+\n+    private void assertCounters(Counters counters) {\n+        assertEquals(1, getCounterValue(counters, VALID_ROW_COUNT));\n+        assertEquals(1, getCounterValue(counters, BEYOND_MAX_LOOKBACK));\n+        assertEquals(0, getCounterValue(counters, INVALID_ROW_COUNT));\n+    }\n+\n+    private List<Job> runScrutiny(String schemaName, String dataTableName, String indexTableName,\n+                                  Long scrutinyTs)\n+        throws Exception {\n+        return runScrutiny(schemaName, dataTableName, indexTableName, null, null, scrutinyTs);\n+    }\n+\n+    private List<Job> runScrutiny(String schemaName, String dataTableName, String indexTableName,\n+                                  Long batchSize, IndexScrutinyTool.SourceTable sourceTable,\n+                                  Long scrutinyTs) throws Exception {\n+        final String[]\n+            cmdArgs =\n+            getArgValues(schemaName, dataTableName, indexTableName, batchSize, sourceTable,\n+                false, null, null, null, scrutinyTs);\n+        return runScrutiny(MaxLookbackIndexScrutinyMapper.class, cmdArgs);\n+    }\n+\n+    private static class MaxLookbackIndexScrutinyMapper extends IndexScrutinyMapper {\n+        @Override\n+        public void postSetup(){\n+            try {\n+                String tableToCompact;\n+                if (isViewIndex){\n+                    String physicalDataTableName =\n+                        SchemaUtil.getPhysicalHBaseTableName(schema, dataTableName, false).getString();", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njc3NTI3OA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r396775278", "bodyText": "@gjacoby126", "author": "swaroopak", "createdAt": "2020-03-23T21:44:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwMTIzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzk5MDUwNg==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r397990506", "bodyText": "I know it's going to be false.", "author": "gjacoby126", "createdAt": "2020-03-25T16:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwMTIzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYwOTc3MQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394609771", "bodyText": "Any reasons to have these empty methods?", "author": "gokceni", "createdAt": "2020-03-18T20:08:54Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexScrutinyMapper.java", "diffHunk": "@@ -161,12 +168,22 @@ protected void setup(final Context context) throws IOException, InterruptedExcep\n             LOGGER.info(\"Target table base query: \" + targetTableQuery);\n             md5 = MessageDigest.getInstance(\"MD5\");\n             ttl = getTableTtl();\n+            maxLookbackAgeMillis = ScanInfoUtil.getMaxLookbackInMillis(configuration);\n         } catch (SQLException | NoSuchAlgorithmException e) {\n             tryClosingResourceSilently(this.outputUpsertStmt);\n             tryClosingResourceSilently(this.connection);\n             tryClosingResourceSilently(this.outputConn);\n             throw new RuntimeException(e);\n         }\n+        postSetup();\n+    }\n+\n+    protected void preSetup() {", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYxMTM0Nw==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394611347", "bodyText": "Is there a chance that people coincidentally pick the same Max lookback age as the default one?", "author": "gokceni", "createdAt": "2020-03-18T20:11:56Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexScrutinyTool.java", "diffHunk": "@@ -505,6 +509,18 @@ public int run(String[] args) throws Exception {\n         }\n     }\n \n+    private void validateTimestamp(Configuration configuration, long ts) {\n+        long maxLookBackAge = ScanInfoUtil.getMaxLookbackInMillis(configuration);\n+        if (maxLookBackAge != ScanInfoUtil.DEFAULT_PHOENIX_MAX_LOOKBACK_AGE * 1000L) {", "originalCommit": "f799d86859f4eaaf6ca8415e3559d2a739d5f9b4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3Mjg4MQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r394672881", "bodyText": "The default age is the same as \"turn off max lookback\". It happens to be 0, which makes the 1000L not necessary, but I wanted to keep the discipline of always converting to millis from seconds to avoid accidentally missing it elsewhere.", "author": "gjacoby126", "createdAt": "2020-03-18T22:22:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDYxMTM0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIzNjAwMA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395236000", "bodyText": "Can we have tests for deletes in addition to upserts? I am also interested in the cases where rows are deleted within the max loopback window and before and after the scn.", "author": "kadirozde", "createdAt": "2020-03-19T18:29:47Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/IndexScrutinyWithMaxLookbackIT.java", "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.end2end;\n+\n+import com.google.common.collect.Maps;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.regionserver.ScanInfoUtil;\n+import org.apache.hadoop.mapreduce.Counters;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyMapper;\n+import org.apache.phoenix.mapreduce.index.IndexScrutinyTool;\n+import org.apache.phoenix.query.QueryServices;\n+import org.apache.phoenix.util.EnvironmentEdgeManager;\n+import org.apache.phoenix.util.ManualEnvironmentEdge;\n+import org.apache.phoenix.util.MetaDataUtil;\n+import org.apache.phoenix.util.PropertiesUtil;\n+import org.apache.phoenix.util.ReadOnlyProps;\n+import org.apache.phoenix.util.SchemaUtil;\n+import org.apache.phoenix.util.TestUtil;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.INVALID_ROW_COUNT;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.BEYOND_MAX_LOOKBACK;\n+import static org.apache.phoenix.mapreduce.index.PhoenixScrutinyJobCounters.VALID_ROW_COUNT;\n+import static org.apache.phoenix.util.TestUtil.TEST_PROPERTIES;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class IndexScrutinyWithMaxLookbackIT extends IndexScrutinyToolBaseIT {\n+\n+    private static PreparedStatement upsertDataStmt;\n+    private static String dataTableFullName;\n+    private static String schema;\n+    private static String dataTableName;\n+    private static String indexTableName;\n+    private static String viewName;\n+    private static boolean isViewIndex;\n+    private static ManualEnvironmentEdge testClock;\n+    public static final String UPSERT_DATA = \"UPSERT INTO %s VALUES (?, ?, ?)\";\n+    public static final int MAX_LOOKBACK = 6;\n+\n+\n+    @BeforeClass\n+    public static synchronized void doSetup() throws Exception {\n+        Map<String, String> props = Maps.newHashMapWithExpectedSize(2);\n+        props.put(QueryServices.GLOBAL_INDEX_ROW_AGE_THRESHOLD_TO_DELETE_MS_ATTRIB, Long.toString(0));\n+        props.put(ScanInfoUtil.PHOENIX_MAX_LOOKBACK_AGE_CONF_KEY,\n+            Integer.toString(MAX_LOOKBACK));\n+        setUpTestDriver(new ReadOnlyProps(props.entrySet().iterator()));\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookBack() throws Exception {\n+        schema = \"S\" + generateUniqueName();\n+        dataTableName = \"T\" + generateUniqueName();\n+        indexTableName = \"I\" + generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema, dataTableName);\n+        isViewIndex = false;\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES=0, VERSIONS=1\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP)\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                dataTableFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(dataTableName, dataTableFullName, testClock);\n+    }\n+\n+    @Test\n+    public void testScrutinyOnRowsBeyondMaxLookback_viewIndex() throws Exception {\n+        schema = \"S\"+generateUniqueName();\n+        dataTableName = \"T\"+generateUniqueName();\n+        dataTableFullName = SchemaUtil.getTableName(schema,dataTableName);\n+        indexTableName = \"VI\"+generateUniqueName();\n+        isViewIndex = true;\n+        viewName = \"V\"+generateUniqueName();\n+        String viewFullName = SchemaUtil.getTableName(schema,viewName);\n+        String dataTableDDL = \"CREATE TABLE %s (ID INTEGER NOT NULL PRIMARY KEY, NAME VARCHAR, \"\n+            + \"ZIP INTEGER) COLUMN_ENCODED_BYTES = 0, VERSIONS = 1 \";\n+        String viewDDL = \"CREATE VIEW %s AS SELECT * FROM %s\";\n+        String indexTableDDL = \"CREATE INDEX %s ON %s (NAME) INCLUDE (ZIP) VERSIONS = 1\";\n+        testClock = new ManualEnvironmentEdge();\n+\n+        try (Connection conn =\n+                 DriverManager.getConnection(getUrl(), PropertiesUtil.deepCopy(TEST_PROPERTIES))) {\n+            conn.createStatement().execute(String.format(dataTableDDL, dataTableFullName));\n+            conn.createStatement().execute(String.format(viewDDL, viewFullName, dataTableFullName));\n+            conn.createStatement().execute(String.format(indexTableDDL, indexTableName,\n+                viewFullName));\n+            conn.commit();\n+        }\n+        upsertDataAndScrutinize(viewName, viewFullName, testClock);\n+    }\n+\n+    private void upsertDataAndScrutinize(String tableName, String tableFullName,", "originalCommit": "4d4383ce79123ba01271282d6a16ff7e90b26a3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxNjcyNA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395316724", "bodyText": "Good idea, I will add a test for deletes.", "author": "gjacoby126", "createdAt": "2020-03-19T21:00:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIzNjAwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIzODkxMA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395238910", "bodyText": "In the tests above, major compactions run on both the data and index table. Can we pick only one table for one test, the other for another test, and so on? The interesting problems arise when compaction runs on one table but not on both", "author": "kadirozde", "createdAt": "2020-03-19T18:34:49Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -317,16 +300,16 @@ public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n             //after flush, check to make sure we can see all three versions at the appropriate times\n             assertMultiVersionLookbacks(dataTableSelectSql, allValues, allSCNs);\n             assertMultiVersionLookbacks(indexTableSelectSql, allValues, allSCNs);\n-            majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n-            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(dataTable);\n+            majorCompact(indexTable);\n             //after major compaction, check to make sure we can see all three versions\n             // at the appropriate times\n             assertMultiVersionLookbacks(dataTableSelectSql, allValues, allSCNs);\n             assertMultiVersionLookbacks(indexTableSelectSql, allValues, allSCNs);\n             injectEdge.incrementValue(MAX_LOOKBACK_AGE * 1000);\n             long afterLookbackAgeSCN = EnvironmentEdgeManager.currentTimeMillis();\n-            majorCompact(dataTable, afterLookbackAgeSCN);\n-            majorCompact(indexTable, afterLookbackAgeSCN);\n+            majorCompact(dataTable);\n+            majorCompact(indexTable);", "originalCommit": "4d4383ce79123ba01271282d6a16ff7e90b26a3d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMwMzc5Mg==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395303792", "bodyText": "First, this test suite only was modified because I needed to steal its major compaction code and put it into TestUtil. It's otherwise unrelated to this JIRA, and if it needs changes, that should be a separate issue.\nSecond, this isn't really a test of indexing per se, but of whether the max lookback coproc hooks correctly prevent data from being purged during the lookback window.", "author": "gjacoby126", "createdAt": "2020-03-19T20:34:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIzODkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMwNDYyNw==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395304627", "bodyText": "But if there are additional indexing tests we need, definitely please suggest them in a JIRA!", "author": "gjacoby126", "createdAt": "2020-03-19T20:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIzODkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTgwNTYxNQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395805615", "bodyText": "That is fair. Thanks.", "author": "kadirozde", "createdAt": "2020-03-20T18:01:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTIzODkxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg2MjY5MA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395862690", "bodyText": "All counters end with '_COUNT' here ... Perhaps we should remain consistent. That said, 'BEYOND_MAX_LOOKBACK_ROW_COUNT' looks too long. How about 'NO_LOOKBACK_ROW_COUNT'?", "author": "priyankporwal", "createdAt": "2020-03-20T20:00:00Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/PhoenixScrutinyJobCounters.java", "diffHunk": "@@ -41,5 +41,11 @@\n     /**\n      * Number of batches processed\n      */\n-    BATCHES_PROCESSED_COUNT;\n+    BATCHES_PROCESSED_COUNT,\n+    /**\n+     * Number of rows in source that became older than the max lookback age while scrutiny\n+     * was comparing them with the target, and didn't match. We break these out separately because\n+     * they could be due to extra versions being compacted, and are harmless.\n+     */\n+    BEYOND_MAX_LOOKBACK;", "originalCommit": "6a6443bd976bd2689722513d3d3367e40140c86b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg3NDM2NA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395874364", "bodyText": "No objection to appending _COUNT to the existing enum value, but NO_LOOKBACK_ROW_COUNT seems more confusing to me.", "author": "gjacoby126", "createdAt": "2020-03-20T20:27:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg2MjY5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkwNDM2NA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395904364", "bodyText": "True. They are similar to 'EXPIRED' but can't use the same name... 'UNREADABLE' can also be confusing. Anyways, pick what sounds best to you.", "author": "priyankporwal", "createdAt": "2020-03-20T21:47:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg2MjY5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg2NDMyNQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395864325", "bodyText": "when would this be the case? i.e. #CF==0", "author": "priyankporwal", "createdAt": "2020-03-20T20:03:39Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/util/SchemaUtil.java", "diffHunk": "@@ -1183,6 +1186,22 @@ public static int getIsNullableInt(boolean isNullable) {\n \t\treturn isNullable ? ResultSetMetaData.columnNullable : ResultSetMetaData.columnNoNulls;\n \t}\n \n+\tpublic static int getTimeToLive(PhoenixConnection conn, String physicalName) throws SQLException {\n+        byte[] tableQualifier = Bytes.toBytes(physicalName);\n+        return getTimeToLive(conn, tableQualifier);\n+    }\n+\n+    public static int getTimeToLive(PhoenixConnection conn, byte[] tableQualifier)\n+     throws SQLException {\n+        HTableDescriptor td = conn.getQueryServices().getTableDescriptor(tableQualifier);\n+        HColumnDescriptor[] cds = td.getColumnFamilies();\n+        if (cds.length > 0){\n+            return cds[0].getTimeToLive();\n+        } else {\n+            return HConstants.FOREVER;", "originalCommit": "6a6443bd976bd2689722513d3d3367e40140c86b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg4MDA5OQ==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r395880099", "bodyText": "I couldn't think of one, but decided to code the function defensively.", "author": "gjacoby126", "createdAt": "2020-03-20T20:41:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTg2NDMyNQ=="}], "type": "inlineReview"}, {"oid": "c274ac28e88f4c103f9b13b37b6a3cc7f9be1123", "url": "https://github.com/apache/phoenix/commit/c274ac28e88f4c103f9b13b37b6a3cc7f9be1123", "message": "PHOENIX-5734 - IndexScrutinyTool should not report rows beyond maxLookBack age", "committedDate": "2020-03-25T16:21:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0MDgwOA==", "url": "https://github.com/apache/phoenix/pull/735#discussion_r398340808", "bodyText": "Do we need to do anything to disable COLUMN_ENCODING for clusters with this table already existing?", "author": "priyankporwal", "createdAt": "2020-03-26T06:24:18Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/mapreduce/index/IndexScrutinyTableOutput.java", "diffHunk": "@@ -68,14 +68,18 @@\n             \"    SOURCE_TS BIGINT,\\n\" +\n             \"    TARGET_TS BIGINT,\\n\" +\n             \"    HAS_TARGET_ROW BOOLEAN,\\n\" +\n+            \"    BEYOND_MAX_LOOKBACK BOOLEAN,\\n\" +\n             \"    CONSTRAINT PK PRIMARY KEY\\n\" +\n             \"    (\\n\" +\n             \"        \" + SOURCE_TABLE_COL_NAME + \",\\n\" +\n             \"        \" + TARGET_TABLE_COL_NAME + \",\\n\" +\n             \"        \" + SCRUTINY_EXECUTE_TIME_COL_NAME + \",\\n\" + // time at which the scrutiny ran\n             \"        SOURCE_ROW_PK_HASH\\n\" + //  this hash makes the PK unique\n             \"    )\\n\" + // dynamic columns consisting of the source and target columns will follow\n-            \")\";\n+            \")  COLUMN_ENCODED_BYTES = 0 \"; //column encoding not supported with dyn columns (PHOENIX-5107)", "originalCommit": "c274ac28e88f4c103f9b13b37b6a3cc7f9be1123", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a810fdb8ead861dcd2207e130792f88977a7552c", "url": "https://github.com/apache/phoenix/commit/a810fdb8ead861dcd2207e130792f88977a7552c", "message": "PHOENIX-5734 - IndexScrutinyTool should not report rows beyond maxLookBack age", "committedDate": "2020-03-26T18:00:42Z", "type": "commit"}, {"oid": "a810fdb8ead861dcd2207e130792f88977a7552c", "url": "https://github.com/apache/phoenix/commit/a810fdb8ead861dcd2207e130792f88977a7552c", "message": "PHOENIX-5734 - IndexScrutinyTool should not report rows beyond maxLookBack age", "committedDate": "2020-03-26T18:00:42Z", "type": "forcePushed"}]}