{"pr_number": 915, "pr_title": "PHOENIX-6181 IndexRepairRegionScanner to verify and repair every glob\u2026", "pr_createdAt": "2020-10-08T04:14:46Z", "pr_url": "https://github.com/apache/phoenix/pull/915", "timeline": [{"oid": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "url": "https://github.com/apache/phoenix/commit/e143b8130bd77207e15a3bbae30a42dbbe379a25", "message": "PHOENIX-6181 IndexRepairRegionScanner to verify and repair every global index row", "committedDate": "2020-10-08T04:08:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NTM5NA==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r503665394", "bodyText": "I feel the same logic of checking if the region is closed and then sending the mutations is duplicated in multiple places and we can move it to a function to reduce the code duplication.", "author": "tkhurana", "createdAt": "2020-10-13T04:50:40Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRepairRegionScanner.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.coprocessor;\n+\n+import static org.apache.phoenix.coprocessor.BaseScannerRegionObserver.PHYSICAL_DATA_TABLE_NAME;\n+import static org.apache.phoenix.query.QueryConstants.AGG_TIMESTAMP;\n+import static org.apache.phoenix.query.QueryConstants.SINGLE_COLUMN;\n+import static org.apache.phoenix.query.QueryConstants.SINGLE_COLUMN_FAMILY;\n+import static org.apache.phoenix.query.QueryConstants.UNGROUPED_AGG_ROW_KEY;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.CellUtil;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.KeyValue;\n+import org.apache.hadoop.hbase.client.Delete;\n+import org.apache.hadoop.hbase.client.Mutation;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;\n+import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.phoenix.query.HBaseFactoryProvider;\n+import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.compile.ScanRanges;\n+import org.apache.phoenix.filter.SkipScanFilter;\n+import org.apache.phoenix.hbase.index.parallel.Task;\n+import org.apache.phoenix.hbase.index.parallel.TaskBatch;\n+import org.apache.phoenix.hbase.index.util.ImmutableBytesPtr;\n+import org.apache.phoenix.mapreduce.index.IndexTool;\n+import org.apache.phoenix.query.KeyRange;\n+import org.apache.phoenix.schema.types.PLong;\n+import org.apache.phoenix.schema.types.PVarbinary;\n+import org.apache.phoenix.util.KeyValueUtil;\n+import org.apache.phoenix.util.ServerUtil;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.collect.Maps;\n+\n+public class IndexRepairRegionScanner extends GlobalIndexRegionScanner {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(IndexRepairRegionScanner.class);\n+\n+    public IndexRepairRegionScanner(final RegionScanner innerScanner,\n+                                     final Region region,\n+                                     final Scan scan,\n+                                     final RegionCoprocessorEnvironment env,\n+                                     final UngroupedAggregateRegionObserver ungroupedAggregateRegionObserver)\n+            throws IOException {\n+        super(innerScanner, region, scan, env, ungroupedAggregateRegionObserver);\n+\n+        byte[] dataTableName = scan.getAttribute(PHYSICAL_DATA_TABLE_NAME);\n+        dataHTable = hTableFactory.getTable(new ImmutableBytesPtr(dataTableName));\n+        indexTableTTL = region.getTableDesc().getColumnFamilies()[0].getTimeToLive();\n+        try (org.apache.hadoop.hbase.client.Connection connection =\n+                     HBaseFactoryProvider.getHConnectionFactory().createConnection(env.getConfiguration())) {\n+            regionEndKeys = connection.getRegionLocator(dataHTable.getName()).getEndKeys();\n+        }\n+    }\n+\n+    public void prepareExpectedIndexMutations(Result dataRow, Map<byte[], List<Mutation>> expectedIndexMutationMap) throws IOException {\n+        Put put = null;\n+        Delete del = null;\n+        for (Cell cell : dataRow.rawCells()) {\n+            if (KeyValue.Type.codeToType(cell.getTypeByte()) == KeyValue.Type.Put) {\n+                if (put == null) {\n+                    put = new Put(CellUtil.cloneRow(cell));\n+                }\n+                put.add(cell);\n+            } else {\n+                if (del == null) {\n+                    del = new Delete(CellUtil.cloneRow(cell));\n+                }\n+                del.addDeleteMarker(cell);\n+            }\n+        }\n+        List<Mutation> indexMutations = prepareIndexMutationsForRebuild(indexMaintainer, put, del);\n+        Collections.reverse(indexMutations);\n+        for (Mutation mutation : indexMutations) {\n+            byte[] indexRowKey = mutation.getRow();\n+            List<Mutation> mutationList = expectedIndexMutationMap.get(indexRowKey);\n+            if (mutationList == null) {\n+                mutationList = new ArrayList<>();\n+                mutationList.add(mutation);\n+                expectedIndexMutationMap.put(indexRowKey, mutationList);\n+            } else {\n+                mutationList.add(mutation);\n+            }\n+        }\n+    }\n+\n+    private void repairIndexRows(Map<byte[], List<Mutation>> indexMutationMap,\n+                                 List<Mutation> indexRowsToBeDeleted,\n+                                 IndexToolVerificationResult verificationResult) throws IOException {\n+        try {\n+            int batchSize = 0;\n+            List<Mutation> indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+            for (List<Mutation> mutationList : indexMutationMap.values()) {\n+                indexUpdates.addAll(mutationList);\n+                batchSize += mutationList.size();\n+                if (batchSize >= maxBatchSize) {\n+                    ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                    region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                            HConstants.NO_NONCE, HConstants.NO_NONCE);\n+                    batchSize = 0;\n+                    indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+                }\n+            }\n+            if (batchSize > 0) {\n+                ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                        HConstants.NO_NONCE, HConstants.NO_NONCE);\n+            }\n+            batchSize = 0;\n+            indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+            for (Mutation mutation : indexRowsToBeDeleted) {\n+                indexUpdates.add(mutation);\n+                batchSize ++;\n+                if (batchSize >= maxBatchSize) {\n+                    ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                    region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                            HConstants.NO_NONCE, HConstants.NO_NONCE);\n+                    batchSize = 0;\n+                    indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+                }\n+            }\n+            if (batchSize > 0) {\n+                ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                        HConstants.NO_NONCE, HConstants.NO_NONCE);", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2OTE0Ng==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r503669146", "bodyText": "Question: Here we are calling region.batchMutate to update the index table but in IndexRebuildRegionScanner we call indexHTable.batch(). Why the difference ?", "author": "tkhurana", "createdAt": "2020-10-13T05:05:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NTM5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MjAzOQ==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504282039", "bodyText": "+1", "author": "gokceni", "createdAt": "2020-10-13T21:57:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NTM5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkwOTUxMw==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504909513", "bodyText": "I will reduce the code duplication here. When the index table is local (in the case of repair) we use the region API and when the index table is remote (in the case of rebuild), we use the table API.", "author": "kadirozde", "createdAt": "2020-10-14T19:08:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NTM5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY4NTg4Mg==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r506685882", "bodyText": "Done", "author": "kadirozde", "createdAt": "2020-10-16T19:41:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY2NTM5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3OTA1Mw==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504279053", "bodyText": "Once this function is called, shouldVerifyCheckDone is set to true and from that point on, it will always be true.\nEven if we want incremental, we will always do verify then why do we check lastVerifyTime? If lastVerifyTime is not 0, then shouldVerify check will not be set to true.\nCan we have just 1 global variable to decide if we should verify than multiple to make this easier?", "author": "gokceni", "createdAt": "2020-10-13T21:50:21Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/GlobalIndexRegionScanner.java", "diffHunk": "@@ -240,4 +320,1033 @@ protected boolean isColumnIncluded(Cell cell) {\n         byte[] qualifier = CellUtil.cloneQualifier(cell);\n         return set.contains(qualifier);\n     }\n+    @VisibleForTesting\n+    public boolean shouldVerify(IndexTool.IndexVerifyType verifyType,\n+                                byte[] indexRowKey, Scan scan, Region region, IndexMaintainer indexMaintainer,\n+                                IndexVerificationResultRepository verificationResultRepository, boolean shouldVerifyCheckDone) throws IOException {\n+        this.verifyType = verifyType;\n+        this.indexRowKeyforReadRepair = indexRowKey;\n+        this.scan = scan;\n+        this.region = region;\n+        this.indexMaintainer = indexMaintainer;\n+        this.verificationResultRepository = verificationResultRepository;\n+        this.shouldVerifyCheckDone = shouldVerifyCheckDone;\n+        return shouldVerify();\n+    }\n+\n+    protected boolean shouldVerify() throws IOException {\n+        // In case of read repair, proceed with rebuild\n+        // All other types of rebuilds/verification should be incrementally performed if appropriate param is passed\n+        byte[] lastVerifyTimeValue = scan.getAttribute(UngroupedAggregateRegionObserver.INDEX_RETRY_VERIFY);\n+        Long lastVerifyTime = lastVerifyTimeValue == null ? 0 : Bytes.toLong(lastVerifyTimeValue);\n+        if(indexRowKeyforReadRepair != null || lastVerifyTime == 0 || shouldVerifyCheckDone) {", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxNjM2MA==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504916360", "bodyText": "lastVerifyTime is not a global variable. We can improve this method by checking shouldVerifyCheckDone at the entry of this method.", "author": "kadirozde", "createdAt": "2020-10-14T19:21:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3OTA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3OTMzOA==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504279338", "bodyText": "What is the purpose of always returning 0?", "author": "gokceni", "createdAt": "2020-10-13T21:51:07Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/GlobalIndexRegionScanner.java", "diffHunk": "@@ -240,4 +320,1033 @@ protected boolean isColumnIncluded(Cell cell) {\n         byte[] qualifier = CellUtil.cloneQualifier(cell);\n         return set.contains(qualifier);\n     }\n+    @VisibleForTesting\n+    public boolean shouldVerify(IndexTool.IndexVerifyType verifyType,\n+                                byte[] indexRowKey, Scan scan, Region region, IndexMaintainer indexMaintainer,\n+                                IndexVerificationResultRepository verificationResultRepository, boolean shouldVerifyCheckDone) throws IOException {\n+        this.verifyType = verifyType;\n+        this.indexRowKeyforReadRepair = indexRowKey;\n+        this.scan = scan;\n+        this.region = region;\n+        this.indexMaintainer = indexMaintainer;\n+        this.verificationResultRepository = verificationResultRepository;\n+        this.shouldVerifyCheckDone = shouldVerifyCheckDone;\n+        return shouldVerify();\n+    }\n+\n+    protected boolean shouldVerify() throws IOException {\n+        // In case of read repair, proceed with rebuild\n+        // All other types of rebuilds/verification should be incrementally performed if appropriate param is passed\n+        byte[] lastVerifyTimeValue = scan.getAttribute(UngroupedAggregateRegionObserver.INDEX_RETRY_VERIFY);\n+        Long lastVerifyTime = lastVerifyTimeValue == null ? 0 : Bytes.toLong(lastVerifyTimeValue);\n+        if(indexRowKeyforReadRepair != null || lastVerifyTime == 0 || shouldVerifyCheckDone) {\n+            return true;\n+        }\n+\n+        IndexToolVerificationResult verificationResultTemp = verificationResultRepository\n+                .getVerificationResult(lastVerifyTime, scan, region, indexMaintainer.getIndexTableName()) ;\n+        if(verificationResultTemp != null) {\n+            verificationResult = verificationResultTemp;\n+        }\n+        shouldVerifyCheckDone = true;\n+        return verificationResultTemp == null;\n+    }\n+\n+    @Override\n+    public HRegionInfo getRegionInfo() {\n+        return region.getRegionInfo();\n+    }\n+\n+    @Override\n+    public boolean isFilterDone() {\n+        return false;\n+    }\n+\n+    private void closeTables() throws IOException {\n+        hTableFactory.shutdown();\n+        if (indexHTable != null) {\n+            indexHTable.close();\n+        }\n+        if (dataHTable != null) {\n+            dataHTable.close();\n+        }\n+    }\n+    @Override\n+    public void close() throws IOException {\n+        innerScanner.close();\n+        if (indexRowKeyforReadRepair != null) {\n+            closeTables();\n+            return;\n+        }\n+        if (verify) {\n+            try {\n+                if (verificationResultRepository != null) {\n+                    verificationResultRepository.logToIndexToolResultTable(verificationResult,\n+                            verifyType, region.getRegionInfo().getRegionName(), skipped);\n+                }\n+            } finally {\n+                this.pool.stop(\"IndexRegionObserverRegionScanner is closing\");\n+                closeTables();\n+                if (verificationResultRepository != null) {\n+                    verificationResultRepository.close();\n+                }\n+                if (verificationOutputRepository != null) {\n+                    verificationOutputRepository.close();\n+                }\n+            }\n+        }\n+        else {\n+            this.pool.stop(\"IndexRegionObserverRegionScanner is closing\");\n+            closeTables();\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public int setIndexTableTTL(int ttl) {\n+        indexTableTTL = ttl;\n+        return 0;", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkxNzE5NQ==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504917195", "bodyText": "This method is used only for the unit test. @swaroopak, can you answer the question?", "author": "kadirozde", "createdAt": "2020-10-14T19:23:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3OTMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MDQwMQ==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504280401", "bodyText": "Family qualifier will not be super useful if we do 5928", "author": "gokceni", "createdAt": "2020-10-13T21:53:36Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/GlobalIndexRegionScanner.java", "diffHunk": "@@ -240,4 +320,1033 @@ protected boolean isColumnIncluded(Cell cell) {\n         byte[] qualifier = CellUtil.cloneQualifier(cell);\n         return set.contains(qualifier);\n     }\n+    @VisibleForTesting\n+    public boolean shouldVerify(IndexTool.IndexVerifyType verifyType,\n+                                byte[] indexRowKey, Scan scan, Region region, IndexMaintainer indexMaintainer,\n+                                IndexVerificationResultRepository verificationResultRepository, boolean shouldVerifyCheckDone) throws IOException {\n+        this.verifyType = verifyType;\n+        this.indexRowKeyforReadRepair = indexRowKey;\n+        this.scan = scan;\n+        this.region = region;\n+        this.indexMaintainer = indexMaintainer;\n+        this.verificationResultRepository = verificationResultRepository;\n+        this.shouldVerifyCheckDone = shouldVerifyCheckDone;\n+        return shouldVerify();\n+    }\n+\n+    protected boolean shouldVerify() throws IOException {\n+        // In case of read repair, proceed with rebuild\n+        // All other types of rebuilds/verification should be incrementally performed if appropriate param is passed\n+        byte[] lastVerifyTimeValue = scan.getAttribute(UngroupedAggregateRegionObserver.INDEX_RETRY_VERIFY);\n+        Long lastVerifyTime = lastVerifyTimeValue == null ? 0 : Bytes.toLong(lastVerifyTimeValue);\n+        if(indexRowKeyforReadRepair != null || lastVerifyTime == 0 || shouldVerifyCheckDone) {\n+            return true;\n+        }\n+\n+        IndexToolVerificationResult verificationResultTemp = verificationResultRepository\n+                .getVerificationResult(lastVerifyTime, scan, region, indexMaintainer.getIndexTableName()) ;\n+        if(verificationResultTemp != null) {\n+            verificationResult = verificationResultTemp;\n+        }\n+        shouldVerifyCheckDone = true;\n+        return verificationResultTemp == null;\n+    }\n+\n+    @Override\n+    public HRegionInfo getRegionInfo() {\n+        return region.getRegionInfo();\n+    }\n+\n+    @Override\n+    public boolean isFilterDone() {\n+        return false;\n+    }\n+\n+    private void closeTables() throws IOException {\n+        hTableFactory.shutdown();\n+        if (indexHTable != null) {\n+            indexHTable.close();\n+        }\n+        if (dataHTable != null) {\n+            dataHTable.close();\n+        }\n+    }\n+    @Override\n+    public void close() throws IOException {\n+        innerScanner.close();\n+        if (indexRowKeyforReadRepair != null) {\n+            closeTables();\n+            return;\n+        }\n+        if (verify) {\n+            try {\n+                if (verificationResultRepository != null) {\n+                    verificationResultRepository.logToIndexToolResultTable(verificationResult,\n+                            verifyType, region.getRegionInfo().getRegionName(), skipped);\n+                }\n+            } finally {\n+                this.pool.stop(\"IndexRegionObserverRegionScanner is closing\");\n+                closeTables();\n+                if (verificationResultRepository != null) {\n+                    verificationResultRepository.close();\n+                }\n+                if (verificationOutputRepository != null) {\n+                    verificationOutputRepository.close();\n+                }\n+            }\n+        }\n+        else {\n+            this.pool.stop(\"IndexRegionObserverRegionScanner is closing\");\n+            closeTables();\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public int setIndexTableTTL(int ttl) {\n+        indexTableTTL = ttl;\n+        return 0;\n+    }\n+\n+    @VisibleForTesting\n+    public int setIndexMaintainer(IndexMaintainer indexMaintainer) {\n+        this.indexMaintainer = indexMaintainer;\n+        return 0;\n+    }\n+\n+    @VisibleForTesting\n+    public long setMaxLookBackInMills(long maxLookBackInMills) {\n+        this.maxLookBackInMills = maxLookBackInMills;\n+        return 0;\n+    }\n+\n+    public void logToIndexToolOutputTable(byte[] dataRowKey, byte[] indexRowKey, long dataRowTs, long indexRowTs,\n+                                          String errorMsg, boolean isBeforeRebuild,\n+                                          IndexVerificationOutputRepository.IndexVerificationErrorType errorType) throws IOException {\n+        logToIndexToolOutputTable(dataRowKey, indexRowKey, dataRowTs, indexRowTs, errorMsg, null,\n+                null, isBeforeRebuild, errorType);\n+    }\n+\n+    @VisibleForTesting\n+    public void logToIndexToolOutputTable(byte[] dataRowKey, byte[] indexRowKey, long dataRowTs, long indexRowTs,\n+                                          String errorMsg, byte[] expectedVaue, byte[] actualValue, boolean isBeforeRebuild,\n+                                          IndexVerificationOutputRepository.IndexVerificationErrorType errorType) throws IOException {\n+        ungroupedAggregateRegionObserver.checkForRegionClosing();\n+        verificationOutputRepository.logToIndexToolOutputTable(dataRowKey, indexRowKey, dataRowTs, indexRowTs,\n+                errorMsg, expectedVaue, actualValue, scan.getTimeRange().getMax(),\n+                region.getRegionInfo().getTable().getName(), isBeforeRebuild, errorType);\n+    }\n+\n+    private static Cell getCell(Mutation m, byte[] family, byte[] qualifier) {\n+        List<Cell> cellList = m.getFamilyCellMap().get(family);\n+        if (cellList == null) {\n+            return null;\n+        }\n+        for (Cell cell : cellList) {\n+            if (CellUtil.matchingQualifier(cell, qualifier)) {\n+                return cell;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void logMismatch(Mutation expected, Mutation actual, int iteration, IndexToolVerificationResult.PhaseResult verificationPhaseResult, boolean isBeforeRebuild) throws IOException {\n+        if (getTimestamp(expected) != getTimestamp(actual)) {\n+            String errorMsg = \"Not matching timestamp\";\n+            byte[] dataKey = indexMaintainer.buildDataRowKey(new ImmutableBytesWritable(expected.getRow()), viewConstants);\n+            logToIndexToolOutputTable(dataKey, expected.getRow(), getTimestamp(expected), getTimestamp(actual),\n+                    errorMsg, null, null, isBeforeRebuild, INVALID_ROW);\n+            return;\n+        }\n+        int expectedCellCount = 0;\n+        for (List<Cell> cells : expected.getFamilyCellMap().values()) {\n+            if (cells == null) {\n+                continue;\n+            }\n+            for (Cell expectedCell : cells) {\n+                expectedCellCount++;\n+                byte[] family = CellUtil.cloneFamily(expectedCell);\n+                byte[] qualifier = CellUtil.cloneQualifier(expectedCell);\n+                Cell actualCell = getCell(actual, family, qualifier);\n+                if (actualCell == null ||\n+                        !CellUtil.matchingType(expectedCell, actualCell)) {\n+                    byte[] dataKey = indexMaintainer.buildDataRowKey(new ImmutableBytesWritable(expected.getRow()), viewConstants);\n+                    String errorMsg = \"Missing cell (in iteration \" + iteration + \") \" + Bytes.toString(family) + \":\" + Bytes.toString(qualifier);\n+                    logToIndexToolOutputTable(dataKey, expected.getRow(), getTimestamp(expected),\n+                            getTimestamp(actual), errorMsg, isBeforeRebuild, INVALID_ROW);\n+                    verificationPhaseResult.setIndexHasMissingCellsCount(verificationPhaseResult.getIndexHasMissingCellsCount() + 1);\n+                    return;\n+                }\n+                if (!CellUtil.matchingValue(actualCell, expectedCell)) {\n+                    String errorMsg = \"Not matching value (in iteration \" + iteration + \") for \" + Bytes.toString(family) + \":\" + Bytes.toString(qualifier);", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyMjEzNg==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504922136", "bodyText": "Did you mean 5923? Single cell format for indexes will be optional. Also, please note that there will be a separate cell for each family.", "author": "kadirozde", "createdAt": "2020-10-14T19:31:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MDQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MjMxOA==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504282318", "bodyText": "Most of the other classes have small descriptions of what they do. Let's add one here as well.", "author": "gokceni", "createdAt": "2020-10-13T21:58:02Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRepairRegionScanner.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.coprocessor;\n+\n+import static org.apache.phoenix.coprocessor.BaseScannerRegionObserver.PHYSICAL_DATA_TABLE_NAME;\n+import static org.apache.phoenix.query.QueryConstants.AGG_TIMESTAMP;\n+import static org.apache.phoenix.query.QueryConstants.SINGLE_COLUMN;\n+import static org.apache.phoenix.query.QueryConstants.SINGLE_COLUMN_FAMILY;\n+import static org.apache.phoenix.query.QueryConstants.UNGROUPED_AGG_ROW_KEY;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.CellUtil;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.KeyValue;\n+import org.apache.hadoop.hbase.client.Delete;\n+import org.apache.hadoop.hbase.client.Mutation;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;\n+import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.phoenix.query.HBaseFactoryProvider;\n+import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.compile.ScanRanges;\n+import org.apache.phoenix.filter.SkipScanFilter;\n+import org.apache.phoenix.hbase.index.parallel.Task;\n+import org.apache.phoenix.hbase.index.parallel.TaskBatch;\n+import org.apache.phoenix.hbase.index.util.ImmutableBytesPtr;\n+import org.apache.phoenix.mapreduce.index.IndexTool;\n+import org.apache.phoenix.query.KeyRange;\n+import org.apache.phoenix.schema.types.PLong;\n+import org.apache.phoenix.schema.types.PVarbinary;\n+import org.apache.phoenix.util.KeyValueUtil;\n+import org.apache.phoenix.util.ServerUtil;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.collect.Maps;\n+", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY4NTY1Mw==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r506685653", "bodyText": "Done", "author": "kadirozde", "createdAt": "2020-10-16T19:41:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MjMxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MzQxMw==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504283413", "bodyText": "Don't we have IndexRegionObserver for new design all the time? What is the case when the index doesn't have both Indexer and IndexRegionObserver?", "author": "gokceni", "createdAt": "2020-10-13T22:00:34Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/UngroupedAggregateRegionObserver.java", "diffHunk": "@@ -1103,13 +1104,21 @@ private RegionScanner rebuildIndices(final RegionScanner innerScanner, final Reg\n             if (oldCoproc) {\n                 return new IndexerRegionScanner(scanner, region, scan, env, this);\n             } else {\n-                return new IndexRebuildRegionScanner(scanner, region, scan, env, this);\n+                if (region.getTableDesc().hasCoprocessor(IndexRegionObserver.class.getCanonicalName())) {", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4ODY4MQ==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504288681", "bodyText": "@gokceni IndexRegionObserver is only on the data table. Index table has neither Indexer nor IndexRegionObserver", "author": "tkhurana", "createdAt": "2020-10-13T22:13:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MzQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5MzQ3Ng==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504293476", "bodyText": "Yes you are right @tkhurana. I meant data table. Don't we remove Indexer and add IndexRegionObserver during upgrade?", "author": "gokceni", "createdAt": "2020-10-13T22:25:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MzQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMxNTAyNA==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504315024", "bodyText": "Is this an optimization for checking if this table is Index table @kadirozde rather than querying the PTable and looking at its type?", "author": "gokceni", "createdAt": "2020-10-13T23:27:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MzQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDkyNDg0Mg==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504924842", "bodyText": "We have not removed Indexer yet. Regarding the PTable comment, this is a server side code and in general we do not want to access the syscat on the server side for performance reasons mainly.", "author": "kadirozde", "createdAt": "2020-10-14T19:36:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4MzQxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMzODg2MQ==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r504338861", "bodyText": "The AFTER option will not remove the extra verified rows in the index table. Same with the NONE option. Does it make sense to have these options when using the index table as the source ?", "author": "tkhurana", "createdAt": "2020-10-14T00:53:29Z", "path": "phoenix-core/src/main/java/org/apache/phoenix/coprocessor/IndexRepairRegionScanner.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.phoenix.coprocessor;\n+\n+import static org.apache.phoenix.coprocessor.BaseScannerRegionObserver.PHYSICAL_DATA_TABLE_NAME;\n+import static org.apache.phoenix.query.QueryConstants.AGG_TIMESTAMP;\n+import static org.apache.phoenix.query.QueryConstants.SINGLE_COLUMN;\n+import static org.apache.phoenix.query.QueryConstants.SINGLE_COLUMN_FAMILY;\n+import static org.apache.phoenix.query.QueryConstants.UNGROUPED_AGG_ROW_KEY;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.CellUtil;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.KeyValue;\n+import org.apache.hadoop.hbase.client.Delete;\n+import org.apache.hadoop.hbase.client.Mutation;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;\n+import org.apache.hadoop.hbase.io.ImmutableBytesWritable;\n+import org.apache.hadoop.hbase.regionserver.Region;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.phoenix.query.HBaseFactoryProvider;\n+import org.apache.phoenix.util.ByteUtil;\n+import org.apache.phoenix.compile.ScanRanges;\n+import org.apache.phoenix.filter.SkipScanFilter;\n+import org.apache.phoenix.hbase.index.parallel.Task;\n+import org.apache.phoenix.hbase.index.parallel.TaskBatch;\n+import org.apache.phoenix.hbase.index.util.ImmutableBytesPtr;\n+import org.apache.phoenix.mapreduce.index.IndexTool;\n+import org.apache.phoenix.query.KeyRange;\n+import org.apache.phoenix.schema.types.PLong;\n+import org.apache.phoenix.schema.types.PVarbinary;\n+import org.apache.phoenix.util.KeyValueUtil;\n+import org.apache.phoenix.util.ServerUtil;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.collect.Maps;\n+\n+public class IndexRepairRegionScanner extends GlobalIndexRegionScanner {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(IndexRepairRegionScanner.class);\n+\n+    public IndexRepairRegionScanner(final RegionScanner innerScanner,\n+                                     final Region region,\n+                                     final Scan scan,\n+                                     final RegionCoprocessorEnvironment env,\n+                                     final UngroupedAggregateRegionObserver ungroupedAggregateRegionObserver)\n+            throws IOException {\n+        super(innerScanner, region, scan, env, ungroupedAggregateRegionObserver);\n+\n+        byte[] dataTableName = scan.getAttribute(PHYSICAL_DATA_TABLE_NAME);\n+        dataHTable = hTableFactory.getTable(new ImmutableBytesPtr(dataTableName));\n+        indexTableTTL = region.getTableDesc().getColumnFamilies()[0].getTimeToLive();\n+        try (org.apache.hadoop.hbase.client.Connection connection =\n+                     HBaseFactoryProvider.getHConnectionFactory().createConnection(env.getConfiguration())) {\n+            regionEndKeys = connection.getRegionLocator(dataHTable.getName()).getEndKeys();\n+        }\n+    }\n+\n+    public void prepareExpectedIndexMutations(Result dataRow, Map<byte[], List<Mutation>> expectedIndexMutationMap) throws IOException {\n+        Put put = null;\n+        Delete del = null;\n+        for (Cell cell : dataRow.rawCells()) {\n+            if (KeyValue.Type.codeToType(cell.getTypeByte()) == KeyValue.Type.Put) {\n+                if (put == null) {\n+                    put = new Put(CellUtil.cloneRow(cell));\n+                }\n+                put.add(cell);\n+            } else {\n+                if (del == null) {\n+                    del = new Delete(CellUtil.cloneRow(cell));\n+                }\n+                del.addDeleteMarker(cell);\n+            }\n+        }\n+        List<Mutation> indexMutations = prepareIndexMutationsForRebuild(indexMaintainer, put, del);\n+        Collections.reverse(indexMutations);\n+        for (Mutation mutation : indexMutations) {\n+            byte[] indexRowKey = mutation.getRow();\n+            List<Mutation> mutationList = expectedIndexMutationMap.get(indexRowKey);\n+            if (mutationList == null) {\n+                mutationList = new ArrayList<>();\n+                mutationList.add(mutation);\n+                expectedIndexMutationMap.put(indexRowKey, mutationList);\n+            } else {\n+                mutationList.add(mutation);\n+            }\n+        }\n+    }\n+\n+    private void repairIndexRows(Map<byte[], List<Mutation>> indexMutationMap,\n+                                 List<Mutation> indexRowsToBeDeleted,\n+                                 IndexToolVerificationResult verificationResult) throws IOException {\n+        try {\n+            int batchSize = 0;\n+            List<Mutation> indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+            for (List<Mutation> mutationList : indexMutationMap.values()) {\n+                indexUpdates.addAll(mutationList);\n+                batchSize += mutationList.size();\n+                if (batchSize >= maxBatchSize) {\n+                    ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                    region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                            HConstants.NO_NONCE, HConstants.NO_NONCE);\n+                    batchSize = 0;\n+                    indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+                }\n+            }\n+            if (batchSize > 0) {\n+                ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                        HConstants.NO_NONCE, HConstants.NO_NONCE);\n+            }\n+            batchSize = 0;\n+            indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+            for (Mutation mutation : indexRowsToBeDeleted) {\n+                indexUpdates.add(mutation);\n+                batchSize ++;\n+                if (batchSize >= maxBatchSize) {\n+                    ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                    region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                            HConstants.NO_NONCE, HConstants.NO_NONCE);\n+                    batchSize = 0;\n+                    indexUpdates = new ArrayList<Mutation>(maxBatchSize);\n+                }\n+            }\n+            if (batchSize > 0) {\n+                ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                region.batchMutate(indexUpdates.toArray(new Mutation[indexUpdates.size()]),\n+                        HConstants.NO_NONCE, HConstants.NO_NONCE);\n+            }\n+            if (verify) {\n+                verificationResult.setRebuiltIndexRowCount(verificationResult.getRebuiltIndexRowCount() + indexMutationMap.size());\n+            }\n+        } catch (Throwable t) {\n+            ServerUtil.throwIOException(region.getRegionInfo().getRegionNameAsString(), t);\n+        }\n+    }\n+\n+    private Map<byte[], List<Mutation>> populateExpectedIndexMutationMap(Set<byte[]> dataRowKeys) throws IOException {\n+        Map<byte[], List<Mutation>> expectedIndexMutationMap = Maps.newTreeMap(Bytes.BYTES_COMPARATOR);\n+        List<KeyRange> keys = new ArrayList<>(dataRowKeys.size());\n+        for (byte[] indexKey: dataRowKeys) {\n+            keys.add(PVarbinary.INSTANCE.getKeyRange(indexKey));\n+        }\n+        ScanRanges scanRanges = ScanRanges.createPointLookup(keys);\n+        Scan dataScan = new Scan();\n+        dataScan.setTimeRange(scan.getTimeRange().getMin(), scan.getTimeRange().getMax());\n+        scanRanges.initializeScan(dataScan);\n+        SkipScanFilter skipScanFilter = scanRanges.getSkipScanFilter();\n+        dataScan.setFilter(new SkipScanFilter(skipScanFilter, true));\n+        dataScan.setRaw(true);\n+        dataScan.setMaxVersions();\n+        dataScan.setCacheBlocks(false);\n+        try (ResultScanner resultScanner = dataHTable.getScanner(dataScan)) {\n+            for (Result result = resultScanner.next(); (result != null); result = resultScanner.next()) {\n+                ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                prepareExpectedIndexMutations(result, expectedIndexMutationMap);\n+            }\n+        } catch (Throwable t) {\n+            ServerUtil.throwIOException(dataHTable.getName().toString(), t);\n+        }\n+        return expectedIndexMutationMap;\n+    }\n+\n+    private Map<byte[], List<Mutation>> populateActualIndexMutationMap(Map<byte[], List<Mutation>> expectedIndexMutationMap) throws IOException {\n+        Map<byte[], List<Mutation>> actualIndexMutationMap = Maps.newTreeMap(Bytes.BYTES_COMPARATOR);\n+        Scan indexScan = prepareIndexScan(expectedIndexMutationMap);\n+        try (RegionScanner regionScanner = region.getScanner(indexScan)) {\n+            do {\n+                ungroupedAggregateRegionObserver.checkForRegionClosing();\n+                List<Cell> row = new ArrayList<Cell>();\n+                hasMore = regionScanner.nextRaw(row);\n+                if (!row.isEmpty()) {\n+                    populateIndexMutationFromIndexRow(row, actualIndexMutationMap);\n+                }\n+            } while (hasMore);\n+        } catch (Throwable t) {\n+            ServerUtil.throwIOException(region.getRegionInfo().getRegionNameAsString(), t);\n+        }\n+        return actualIndexMutationMap;\n+    }\n+\n+    private void repairAndOrVerifyIndexRows(Set<byte[]> dataRowKeys,\n+                                            Map<byte[], List<Mutation>> actualIndexMutationMap,\n+                                            IndexToolVerificationResult verificationResult) throws IOException {\n+        List<Mutation> indexRowsToBeDeleted = new ArrayList<>();\n+        Map<byte[], List<Mutation>> expectedIndexMutationMap = populateExpectedIndexMutationMap(dataRowKeys);\n+        if (verifyType == IndexTool.IndexVerifyType.NONE) {\n+            repairIndexRows(expectedIndexMutationMap, indexRowsToBeDeleted, verificationResult);\n+            return;\n+        }\n+        if (verifyType == IndexTool.IndexVerifyType.ONLY) {\n+            verifyIndexRows(actualIndexMutationMap, expectedIndexMutationMap, Collections.EMPTY_SET, Collections.EMPTY_LIST, verificationResult.getBefore(), true);\n+            return;\n+        }\n+        if (verifyType == IndexTool.IndexVerifyType.BEFORE) {\n+            verifyIndexRows(actualIndexMutationMap, expectedIndexMutationMap, Collections.EMPTY_SET, indexRowsToBeDeleted, verificationResult.getBefore(), true);\n+            if (!expectedIndexMutationMap.isEmpty() || !indexRowsToBeDeleted.isEmpty()) {\n+                repairIndexRows(expectedIndexMutationMap, indexRowsToBeDeleted, verificationResult);\n+            }\n+            return;\n+        }\n+        if (verifyType == IndexTool.IndexVerifyType.AFTER) {", "originalCommit": "e143b8130bd77207e15a3bbae30a42dbbe379a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc4OTY1Ng==", "url": "https://github.com/apache/phoenix/pull/915#discussion_r505789656", "bodyText": "I will leave this decision to be made within IndexTool. I think we can still allow these options and state in the help text for IndexTook that they do not remove the stale index rows.", "author": "kadirozde", "createdAt": "2020-10-15T19:32:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMzODg2MQ=="}], "type": "inlineReview"}, {"oid": "a5dd4088b188319f1e9db57680b82f90677f2cde", "url": "https://github.com/apache/phoenix/commit/a5dd4088b188319f1e9db57680b82f90677f2cde", "message": "Eliminated the repeated code for index table update", "committedDate": "2020-10-15T19:38:43Z", "type": "commit"}, {"oid": "f2fff4b73977cea8d48b5beb58b719cb8480e1f4", "url": "https://github.com/apache/phoenix/commit/f2fff4b73977cea8d48b5beb58b719cb8480e1f4", "message": "Added comments to describe the region scanner classes", "committedDate": "2020-10-16T19:38:55Z", "type": "commit"}, {"oid": "b182182f2fe546cf1ff192cdc66e972066680a15", "url": "https://github.com/apache/phoenix/commit/b182182f2fe546cf1ff192cdc66e972066680a15", "message": "Fixed ShouldVerifyTest", "committedDate": "2020-10-16T23:11:09Z", "type": "commit"}]}