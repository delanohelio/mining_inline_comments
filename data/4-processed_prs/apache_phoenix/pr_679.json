{"pr_number": 679, "pr_title": "PHOENIX-5645 - BaseScannerRegionObserver should prevent compaction from purg\u2026", "pr_createdAt": "2020-01-13T21:56:32Z", "pr_url": "https://github.com/apache/phoenix/pull/679", "timeline": [{"oid": "d6db13289202c5c2ae4a8f59e3f6c57b8f20d179", "url": "https://github.com/apache/phoenix/commit/d6db13289202c5c2ae4a8f59e3f6c57b8f20d179", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-13T23:03:25Z", "type": "forcePushed"}, {"oid": "986bd50c2f8518b61afc4613438d39ee485b3c80", "url": "https://github.com/apache/phoenix/commit/986bd50c2f8518b61afc4613438d39ee485b3c80", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-14T19:00:06Z", "type": "forcePushed"}, {"oid": "28edd1500a192ab700a56569f074503db7e409d4", "url": "https://github.com/apache/phoenix/commit/28edd1500a192ab700a56569f074503db7e409d4", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-14T21:44:21Z", "type": "commit"}, {"oid": "28edd1500a192ab700a56569f074503db7e409d4", "url": "https://github.com/apache/phoenix/commit/28edd1500a192ab700a56569f074503db7e409d4", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-14T21:44:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTI2NQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366589265", "bodyText": "Can we write the unit as part of const name?", "author": "gokceni", "createdAt": "2020-01-14T21:46:35Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -59,10 +57,31 @@\n @NeedsOwnMiniClusterTest\n public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n     private static final Log LOG = LogFactory.getLog(MaxLookbackIT.class);\n-    private static final int MAX_LOOKBACK_AGE = 10;\n+    private static final int MAX_LOOKBACK_AGE = 15;\n     private static final int ROWS_POPULATED = 2;\n+    public static final int WAIT_AFTER_TABLE_CREATION = 600000;", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjM5NA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622394", "bodyText": "Suggest setting WAIT_AFTER_TABLE_CREATION = MAX_LOOKBACK_AGE * 100 ... just in case someone increases MAX_LOOKBACK_AGE and leaves WAIT_AFTER_TABLE_CREATION as is.", "author": "priyankporwal", "createdAt": "2020-01-14T23:13:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTI2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTk0Mg==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366589942", "bodyText": "nit: remove commented code", "author": "gokceni", "createdAt": "2020-01-14T21:48:13Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY0OTE4MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366649181", "bodyText": "Not commented out anymore. :-)", "author": "gjacoby126", "createdAt": "2020-01-15T00:53:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU5Mzk1Nw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366593957", "bodyText": "nit: remove commented code", "author": "gokceni", "createdAt": "2020-01-14T21:57:29Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //force a flush\n-            flush(indexTable);\n+            flush(dataTable);\n             //flush shouldn't have changed it\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY0OTExMw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366649113", "bodyText": "Not commented out anymore. :-)", "author": "gjacoby126", "createdAt": "2020-01-15T00:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU5Mzk1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU5NDA2MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366594061", "bodyText": "nit: remove commented code", "author": "gokceni", "createdAt": "2020-01-14T21:57:43Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //force a flush\n-            flush(indexTable);\n+            flush(dataTable);\n             //flush shouldn't have changed it\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+                (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n+            if (timeToSleep > 0) {\n+                injectEdge.incValue(timeToSleep);\n+                //Thread.sleep(timeToSleep);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366619860", "bodyText": "does this value change now?", "author": "swaroopak", "createdAt": "2020-01-14T23:05:57Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -105,60 +129,52 @@ public void testTooLowSCNWithMaxLookbackAge() throws Exception {\n     public void testRecentlyDeletedRowsNotCompactedAway() throws Exception {\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            String fullIndexName = indexStem + \"1\";\n+            createTable(dataTableName);\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n             TableName dataTable = TableName.valueOf(dataTableName);\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n-            assertTableHasTtl(conn, indexTable, Integer.MAX_VALUE);\n-            long beforeDeleteSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n-            Thread.sleep(1); //make sure we delete at a different ts\n+            populateTable(dataTableName);\n+            //make sure we're after the inserts have been committed\n+            injectEdge.incValue(1);\n+            long beforeDeleteSCN = EnvironmentEdgeManager.currentTimeMillis();\n+            injectEdge.incValue(10); //make sure we delete at a different ts\n             Statement stmt = conn.createStatement();\n             stmt.execute(\"DELETE FROM \" + dataTableName + \" WHERE \" + \" id = 'a'\");\n             Assert.assertEquals(1, stmt.getUpdateCount());\n             conn.commit();\n             //select stmt to get row we deleted\n-            String sql = String.format(\"SELECT * FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT * FROM %s WHERE id = 'a'\", dataTableName);\n             int rowsPlusDeleteMarker = ROWS_POPULATED;\n-            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n             flush(dataTable);\n-            flush(indexTable);\n-            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n-            long beforeFirstCompactSCN = EnvironmentEdgeManager.currentTime();\n-            Thread.sleep(1);\n-            majorCompact(indexTable, beforeFirstCompactSCN);\n-            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n+            long beforeFirstCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n+            injectEdge.incValue(1); //new ts for major compaction\n+            majorCompact(dataTable, beforeFirstCompactSCN);\n+            assertRawRowCount(conn, dataTable, rowsPlusDeleteMarker);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n             //wait for the lookback time. After this compactions should purge the deleted row\n-            Thread.sleep(MAX_LOOKBACK_AGE * 1000);\n-            long beforeSecondCompactSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            injectEdge.incValue(MAX_LOOKBACK_AGE * 1000);\n+            long beforeSecondCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n             String notDeletedRowSql =\n-                String.format(\"SELECT * FROM %s WHERE val1 = 'bc'\", dataTableName);\n-            assertExplainPlan(conn, notDeletedRowSql, dataTableName, fullIndexName);\n+                String.format(\"SELECT * FROM %s WHERE id = 'b'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n-            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n             conn.createStatement().execute(\"upsert into \" + dataTableName +\n                 \" values ('c', 'cd', 'cde', 'cdef')\");\n             conn.commit();\n-            majorCompact(indexTable, beforeSecondCompactSCN);\n             majorCompact(dataTable, beforeSecondCompactSCN);\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n             //deleted row should be gone, but not deleted row should still be there.\n             assertRowExistsAtSCN(getUrl(), sql, beforeSecondCompactSCN, false);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n             //1 deleted row should be gone\n-            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n+            assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n         }\n     }\n \n     @Test(timeout=60000L)", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjExOA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622118", "bodyText": "Not sure exactly what the question means? Before it was testing the cleanup of the delete markers in an index, now it's testing the cleanup of the delete markers in a base table. The same code's getting exercised either way.", "author": "gjacoby126", "createdAt": "2020-01-14T23:12:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNTAwMA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366625000", "bodyText": "aah! my bad, I misunderstood this.", "author": "swaroopak", "createdAt": "2020-01-14T23:21:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTMyNw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366671327", "bodyText": "And now we're testing both.", "author": "gjacoby126", "createdAt": "2020-01-15T02:34:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMDA3Nw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366620077", "bodyText": "nit : timeToAdvance sounds better than timeToSleep to me", "author": "kadirozde", "createdAt": "2020-01-14T23:06:38Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //force a flush\n-            flush(indexTable);\n+            flush(dataTable);\n             //flush shouldn't have changed it\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+                (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n+            if (timeToSleep > 0) {\n+                injectEdge.incValue(timeToSleep);\n+                //Thread.sleep(timeToSleep);\n+            }\n+            //make sure it's still on disk\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+            injectEdge.incValue(1); //get a new timestamp for compaction\n+            majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            //nothing should have been purged by this major compaction\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //now wait the TTL\n-            Thread.sleep((ttl +1) * 1000);\n-            long afterTTLExpiresSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            //make sure we can't see it after expiration from masking\n-            assertRowExistsAtSCN(getUrl(), sql, afterTTLExpiresSCN, false);\n-            //but it's still on disk\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n-            long beforeMajorCompactSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n-            majorCompact(indexTable, beforeMajorCompactSCN);\n-            assertRawRowCount(conn, indexTable, 0);\n+            timeToSleep = (ttl * 1000) -", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMTYzNA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366621634", "bodyText": "nit: increamentValue", "author": "swaroopak", "createdAt": "2020-01-14T23:11:06Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -105,60 +129,52 @@ public void testTooLowSCNWithMaxLookbackAge() throws Exception {\n     public void testRecentlyDeletedRowsNotCompactedAway() throws Exception {\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            String fullIndexName = indexStem + \"1\";\n+            createTable(dataTableName);\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjYyOQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622629", "bodyText": "The ManualEnvironmentEdge is copied from HBase code, where that's the method name. I couldn't use the HBase class because Phoenix's EEM is odd and requires a specific abstract subclass of Edge", "author": "gjacoby126", "createdAt": "2020-01-14T23:14:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMTYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNDczNA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366624734", "bodyText": "Given that code does not override the method, it makes sense to rename the method.", "author": "swaroopak", "createdAt": "2020-01-14T23:21:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMTYzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622507", "bodyText": "What was the reason for eliminating index tables from the tests? Was not this JIRA originally about index tables?", "author": "kadirozde", "createdAt": "2020-01-14T23:13:54Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -213,62 +241,49 @@ public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         String thirdValue = \"ghi\";\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem, versions);\n-            long afterInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1); //increment by 1 so we can see our write\n+            long afterInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             //make sure table and index metadata is set up right for versions\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasVersions(conn, dataTable, versions);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNTA2OQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366625069", "bodyText": "It was originally about index tables, but I eventually realized that this needed to apply to all tables in order for SCN to work properly, so there's nothing \"index specific\" about the functionality anymore.\nIf the consensus is that we should have specific index cases in here to make sure nothing in the indexing coprocs break the general behavior, I'll put some (back) in.", "author": "gjacoby126", "createdAt": "2020-01-14T23:22:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNzI3Ng==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366627276", "bodyText": "I suggest including indexes back and applying the same operations/checks to the index tables along with their data tables.", "author": "kadirozde", "createdAt": "2020-01-14T23:29:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYzNDE1MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366634151", "bodyText": "All right, will do.", "author": "gjacoby126", "createdAt": "2020-01-14T23:55:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622515", "bodyText": "Nit: consistent comment here", "author": "priyankporwal", "createdAt": "2020-01-14T23:13:55Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNjQzOA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366626438", "bodyText": "WAIT_AFTER_TABLE_CREATION isn't meant to be a factor of MAX_LOOKBACK_AGE -- it's just an arbitrarily large number to make sure that all the metadata is older than the current timestamp. It could probably be lower, but since the size doesn't cost us anything I didn't spend too much time trying to optimize it.", "author": "gjacoby126", "createdAt": "2020-01-14T23:26:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNzQ3Ng==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366627476", "bodyText": "Turns out any value >= 1 works. I'll just switch it to 1", "author": "gjacoby126", "createdAt": "2020-01-14T23:30:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYzNDA0MA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366634040", "bodyText": "The suggestion was not to have WAIT_AFTER_TABLE_CREATION be a multiple of MAX_LOOKBACK_AGE necessarily, but something larger than MAX_LOOKBACK_AGE  -- just something so that if you did (now - MAX_LOOKBACK_AGE) it didn't go before table creation time.", "author": "priyankporwal", "createdAt": "2020-01-14T23:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY0OTM0MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366649341", "bodyText": "That's not necessary because we always advance time by MAX_LOOKBACK_AGE before trying to look back that far.", "author": "gjacoby126", "createdAt": "2020-01-15T00:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}], "type": "inlineReview"}, {"oid": "c1a379096486f55a77859eeea676c23f0e677914", "url": "https://github.com/apache/phoenix/commit/c1a379096486f55a77859eeea676c23f0e677914", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-15T00:51:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY1MzUxMQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366653511", "bodyText": "Nit: the comment is not right (nothing here equals 10mins).. wait is only 1 ms now", "author": "priyankporwal", "createdAt": "2020-01-15T01:10:56Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -213,51 +274,57 @@ public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         String thirdValue = \"ghi\";\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem, versions);\n-            long afterInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            String indexName = generateUniqueName();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation", "originalCommit": "c1a379096486f55a77859eeea676c23f0e677914", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTExMQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366671111", "bodyText": "Thanks, good catch. Fixed.", "author": "gjacoby126", "createdAt": "2020-01-15T02:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY1MzUxMQ=="}], "type": "inlineReview"}, {"oid": "6f94f04345f37e091f04241090f0b03256b63ad6", "url": "https://github.com/apache/phoenix/commit/6f94f04345f37e091f04241090f0b03256b63ad6", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-15T02:33:10Z", "type": "commit"}]}