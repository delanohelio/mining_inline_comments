{"pr_number": 3425, "pr_title": "Add approx_most_frequent aggregation function", "pr_createdAt": "2020-04-14T05:10:31Z", "pr_url": "https://github.com/trinodb/trino/pull/3425", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445251270", "bodyText": "Why do we need this?", "author": "martint", "createdAt": "2020-06-25T01:00:53Z", "path": "presto-phoenix/pom.xml", "diffHunk": "@@ -311,6 +311,12 @@\n                         <!-- io.airlift:joni and phoenix-client's org.jruby.joni:joni resource duplicates-->\n                         <ignoredResourcePattern>tables/.*\\.bin</ignoredResourcePattern>\n                     </ignoredResourcePatterns>\n+                    <ignoredDependencies>\n+                        <dependency>\n+                            <groupId>com.clearspring.analytics</groupId>\n+                            <artifactId>stream</artifactId>\n+                        </dependency>\n+                    </ignoredDependencies>", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwMTQ1MA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r446001450", "bodyText": "Without this exclusion, the compilation fails. Apache Phenix seems to depend on the stream library.\n[ERROR] Failed to execute goal org.basepom.maven:duplicate-finder-maven-plugin:1.4.0:check (default) on project presto-phoenix: Found duplicate classes/resources! -> [Help 1]", "author": "Lewuathe", "createdAt": "2020-06-26T06:55:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNTkzNg==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r446005936", "bodyText": "But why does this connector depend on presto-main? Or is it just for tests?", "author": "martint", "createdAt": "2020-06-26T07:07:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NjQ1OA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r446146458", "bodyText": "Yes. Phenix connector seems to depend on presto-main with test scope.", "author": "Lewuathe", "createdAt": "2020-06-26T12:14:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMzMTk3NA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r446331974", "bodyText": "@electrum, any thoughts on how to handle this? Adding an exclusion to the duplicate finder doesn't seem ideal. I guess the underlying problem is the fact that the connector depends on presto-main, even if it's just for tests. I know we do it everywhere, but this highlights the problem with that pattern.", "author": "martint", "createdAt": "2020-06-26T18:01:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU5MjU2OA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r452592568", "bodyText": "This looks like a problem with the Phoenix shading. They are including the classes but not repackaging them. (just a guess, I haven\u2019t looked at the failure in detail)", "author": "electrum", "createdAt": "2020-07-10T02:42:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTI3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTY1Nw==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445251657", "bodyText": "Use primitive long", "author": "martint", "createdAt": "2020-06-25T01:02:26Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/LongApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class LongApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.LongState>\n+{\n+    public static void serializeBucket(Long key, Long count, DynamicSliceOutput output)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MTc2Nw==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445251767", "bodyText": "Use primitive long", "author": "martint", "createdAt": "2020-06-25T01:02:54Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/LongApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class LongApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.LongState>\n+{\n+    public static void serializeBucket(Long key, Long count, DynamicSliceOutput output)\n+    {\n+        output.appendLong(key);\n+        output.appendLong(count);\n+    }\n+\n+    public static void deserializeBucket(SliceInput input, ApproximateMostFrequentHistogram<Long> histogram)\n+    {\n+        Long key = input.readLong();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MjMxNA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445252314", "bodyText": "Fields can be final", "author": "martint", "createdAt": "2020-06-25T01:04:52Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1Mjk5Nw==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445252997", "bodyText": "Why 1000? Can we estimate based on the number of buckets?", "author": "martint", "createdAt": "2020-06-25T01:07:09Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < maxBuckets; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        DynamicSliceOutput output = new DynamicSliceOutput(1000);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1MzQxNQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445253415", "bodyText": "This will return the raw allocated slice, which may be bigger than needed. Use output.slice() instead.", "author": "martint", "createdAt": "2020-06-25T01:08:42Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < maxBuckets; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        DynamicSliceOutput output = new DynamicSliceOutput(1000);\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        output.appendByte(FORMAT_TAG);\n+        output.appendInt(maxBuckets);\n+        output.appendInt(capacity);\n+        // Serialize key and counts.\n+        for (Counter<K> counter : counters) {\n+            serializer.serialize(counter.getItem(), counter.getCount(), output);\n+        }\n+\n+        return output.getUnderlyingSlice();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NDE3Nw==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445254177", "bodyText": "The implementation of StreamSummary is very \"object-y\" and will end up causing problems with object allocations at some point. It's fine to use for now, but we should consider reimplementing using flat structures (see, for instance, the implementation of QuantileDigest)", "author": "martint", "createdAt": "2020-06-25T01:11:38Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNDQ5NQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453104495", "bodyText": "Make this final", "author": "martint", "createdAt": "2020-07-10T22:26:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NDE3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NDQ2MQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445254461", "bodyText": "Use Slice for storing strings", "author": "martint", "createdAt": "2020-06-25T01:12:46Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,167 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.Slices;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import java.util.Map;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<String>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1NzQ4NA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445257484", "bodyText": "This could return an object with two parallel arrays or lists, one with the keys and one for the values (e.g., long[]) to avoid having to create a map every time. None of the callers really needs the map, since they iterate over the entries and write them out to the output.\nAlternatively, it could be replaced with a method that walks over the entires and calls back with each entry. E.g.:\nforEachBucket((key, value) -> {\n    VarcharType.VARCHAR.writeSlice(entryBuilder, key));\n    BigintType.BIGINT.writeLong(entryBuilder, value);\n});", "author": "martint", "createdAt": "2020-06-25T01:24:20Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+    // Larger capacity for stream summary improves the accuracy.\n+    private static final int MAX_CAPACITY_FACTOR = 5;\n+\n+    private StreamSummary<K> streamSummary;\n+    private int maxBuckets;\n+    private int capacity;\n+    private ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < maxBuckets; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        DynamicSliceOutput output = new DynamicSliceOutput(1000);\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        output.appendByte(FORMAT_TAG);\n+        output.appendInt(maxBuckets);\n+        output.appendInt(capacity);\n+        // Serialize key and counts.\n+        for (Counter<K> counter : counters) {\n+            serializer.serialize(counter.getItem(), counter.getCount(), output);\n+        }\n+\n+        return output.getUnderlyingSlice();\n+    }\n+\n+    public void merge(ApproximateMostFrequentHistogram<K> other)\n+    {\n+        List<Counter<K>> counters = other.streamSummary.topK(maxBuckets);\n+        for (Counter<K> counter : counters) {\n+            add(counter.getItem(), counter.getCount());\n+        }\n+    }\n+\n+    public Map<K, Long> getBuckets()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI1Nzk0MQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r445257941", "bodyText": "Add some tests involving GROUP BY", "author": "martint", "createdAt": "2020-06-25T01:26:04Z", "path": "presto-testing/src/main/java/io/prestosql/testing/AbstractTestAggregations.java", "diffHunk": "@@ -1315,4 +1316,28 @@ public void testGroupingSetsWithDefaultValue()\n                 \"SELECT orderkey, COUNT(DISTINCT k) FROM (SELECT orderkey, 1 k FROM orders) GROUP BY GROUPING SETS ((), orderkey) HAVING orderkey IS NULL\",\n                 \"VALUES (null, 1)\");\n     }\n+\n+    @Test\n+    public void testApproxMostFrequentWithLong()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwMzY2NQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453103665", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "author": "martint", "createdAt": "2020-07-10T22:23:25Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<Slice>\n+    {}\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState LongState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") long value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Long> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Long>(toIntExact(buckets), toIntExact(capacity),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwMzc3OA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453103778", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "author": "martint", "createdAt": "2020-07-10T22:23:50Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<Slice>\n+    {}\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState LongState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") long value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Long> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Long>(toIntExact(buckets), toIntExact(capacity),\n+                    LongApproximateMostFrequentStateSerializer::serializeBucket,\n+                    LongApproximateMostFrequentStateSerializer::deserializeBucket);\n+            state.set(histogram);\n+        }\n+\n+        histogram.add(value);\n+    }\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState StringState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") Slice value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Slice> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Slice>(toIntExact(buckets), toIntExact(capacity),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwMzgyMg==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453103822", "bodyText": "Remove", "author": "martint", "createdAt": "2020-07-10T22:24:01Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */\n+@AggregationFunction(\"approx_most_frequent\")\n+public final class ApproximateMostFrequentFunction\n+{\n+    private ApproximateMostFrequentFunction() {}\n+\n+    public interface State<K>\n+            extends AccumulatorState\n+    {\n+        ApproximateMostFrequentHistogram<K> get();\n+\n+        void set(ApproximateMostFrequentHistogram<K> value);\n+    }\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = LongApproximateMostFrequentStateSerializer.class, stateFactoryClass = LongApproximateMostFrequentStateFactory.class)\n+    public interface LongState\n+            extends State<Long>\n+    {}\n+\n+    @AccumulatorStateMetadata(stateSerializerClass = StringApproximateMostFrequentStateSerializer.class, stateFactoryClass = StringApproximateMostFrequentStateFactory.class)\n+    public interface StringState\n+            extends State<Slice>\n+    {}\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState LongState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") long value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Long> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Long>(toIntExact(buckets), toIntExact(capacity),\n+                    LongApproximateMostFrequentStateSerializer::serializeBucket,\n+                    LongApproximateMostFrequentStateSerializer::deserializeBucket);\n+            state.set(histogram);\n+        }\n+\n+        histogram.add(value);\n+    }\n+\n+    @InputFunction\n+    @TypeParameter(\"T\")\n+    public static void input(@AggregationState StringState state, @SqlType(BIGINT) long buckets, @SqlType(\"T\") Slice value, @SqlType(BIGINT) long capacity)\n+    {\n+        ApproximateMostFrequentHistogram<Slice> histogram = state.get();\n+        if (histogram == null) {\n+            checkCondition(buckets >= 2, INVALID_FUNCTION_ARGUMENT, \"approx_most_frequent bucket count must be greater than one\");\n+            histogram = new ApproximateMostFrequentHistogram<Slice>(toIntExact(buckets), toIntExact(capacity),\n+                    StringApproximateMostFrequentStateSerializer::serializeBucket,\n+                    StringApproximateMostFrequentStateSerializer::deserializeBucket);\n+            state.set(histogram);\n+        }\n+\n+        System.out.println(\"QQQQQQQQ\");\n+        System.out.println(value.toStringUtf8());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjE1OA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453106158", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    state.set(new ApproximateMostFrequentHistogram<Long>(VARBINARY.getSlice(block, index),\n          \n          \n            \n                    state.set(new ApproximateMostFrequentHistogram<>(VARBINARY.getSlice(block, index),\n          \n      \n    \n    \n  \n\nAlso, one argument per line when splitting arguments across multiple lines.", "author": "martint", "createdAt": "2020-07-10T22:32:46Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/LongApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class LongApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.LongState>\n+{\n+    public static void serializeBucket(long key, long count, DynamicSliceOutput output)\n+    {\n+        output.appendLong(key);\n+        output.appendLong(count);\n+    }\n+\n+    public static void deserializeBucket(SliceInput input, ApproximateMostFrequentHistogram<Long> histogram)\n+    {\n+        long key = input.readLong();\n+        long count = input.readLong();\n+        histogram.add(key, count);\n+    }\n+\n+    @Override\n+    public Type getSerializedType()\n+    {\n+        return VARBINARY;\n+    }\n+\n+    @Override\n+    public void serialize(ApproximateMostFrequentFunction.LongState state, BlockBuilder out)\n+    {\n+        if (state.get() == null) {\n+            out.appendNull();\n+        }\n+        else {\n+            VARBINARY.writeSlice(out, state.get().serialize());\n+        }\n+    }\n+\n+    @Override\n+    public void deserialize(Block block, int index, ApproximateMostFrequentFunction.LongState state)\n+    {\n+        state.set(new ApproximateMostFrequentHistogram<Long>(VARBINARY.getSlice(block, index),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjU1Ng==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453106556", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void serialize(K key, Long count, DynamicSliceOutput output);\n          \n          \n            \n                void serialize(K key, long count, DynamicSliceOutput output);", "author": "martint", "createdAt": "2020-07-10T22:34:23Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentBucketSerializer.java", "diffHunk": "@@ -0,0 +1,21 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+\n+public interface ApproximateMostFrequentBucketSerializer<K>\n+{\n+    public void serialize(K key, Long count, DynamicSliceOutput output);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNzg0OQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453107849", "bodyText": "This calculation seems off. From the code below, it needs:\n\n1 byte for the format tag\n4 bytes for maxBuckets\n4 bytes for capacity\n4 bytes for the number of counters\n8 * counters.size() bytes for the count\nfor long keys, 8 * counters.size() bytes for the keys. For string keys, it can vary, but if we just pick 8, it would be an ok estimate that works for most cases (add a comment explaining why we're picking such a number)", "author": "martint", "createdAt": "2020-07-10T22:39:44Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        int bucketSize = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < bucketSize; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        int estimatedSliceSize = Byte.BYTES + counters.size() * Integer.BYTES * 3; // FORMAT_TAG + Bytes allocated for total buckets\n+        DynamicSliceOutput output = new DynamicSliceOutput(estimatedSliceSize * 3);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwODQwMQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453108401", "bodyText": "Format as:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public ApproximateMostFrequentHistogram(int maxBuckets,\n          \n          \n            \n                                                        int capacity,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketDeserializer<K> deserializer)\n          \n          \n            \n                public ApproximateMostFrequentHistogram(\n          \n          \n            \n                        int maxBuckets,\n          \n          \n            \n                        int capacity,\n          \n          \n            \n                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                        ApproximateMostFrequentBucketDeserializer<K> deserializer)", "author": "martint", "createdAt": "2020-07-10T22:41:55Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwODUzOA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453108538", "bodyText": "Format as:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public ApproximateMostFrequentHistogram(Slice serialized,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                                                        ApproximateMostFrequentBucketDeserializer<K> deserializer)\n          \n          \n            \n                public ApproximateMostFrequentHistogram(\n          \n          \n            \n                        Slice serialized,\n          \n          \n            \n                        ApproximateMostFrequentBucketSerializer<K> serializer,\n          \n          \n            \n                        ApproximateMostFrequentBucketDeserializer<K> deserializer)", "author": "martint", "createdAt": "2020-07-10T22:42:28Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+                                            int capacity,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+                                            ApproximateMostFrequentBucketSerializer<K> serializer,\n+                                            ApproximateMostFrequentBucketDeserializer<K> deserializer)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyNzE2OQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453827169", "bodyText": "@mosabua, can you help review this section?", "author": "martint", "createdAt": "2020-07-13T17:54:17Z", "path": "presto-docs/src/main/sphinx/functions/aggregate.rst", "diffHunk": "@@ -327,6 +327,27 @@ Approximate Aggregate Functions\n     for all ``value``\\ s. This function is equivalent to the variant of\n     :func:`numeric_histogram` that takes a ``weight``, with a per-item weight of ``1``.\n \n+.. function:: approx_most_frequent(buckets, value, capacity) -> map<[same as value], bigint>\n+\n+    Computes the top frequent values up to ``buckets`` elements approximately.\n+    Approximate estimation of the function enables us to pick up the frequent\n+    values with less memory. Larger ``capacity`` improves the accuracy of\n+    underlying algorithm with sacrificing the memory capacity. The returned\n+    value is a map containing the top elements with corresponding estimated\n+    frequency.\n+\n+    ``buckets`` and ``capacity`` must be ``bigint``. ``value`` can be numeric\n+    or string type.\n+\n+    The function uses the stream summary data structure proposed in the\n+    following paper.\n+\n+    .. code-block:: none\n+\n+        A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent\n+        and top-k elements in data streams\"\n+\n+", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MTQ3NQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453881475", "bodyText": "Use a link in the sentence instead\nThe function uses the stream summary data structure proposed in the\n paper `Efficient computation of frequent and top-k elements in data streams by A.Metwalley, D.Agrawl, A.Abbadi`_.", "author": "mosabua", "createdAt": "2020-07-13T19:29:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyNzE2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzkxNDI5MQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453914291", "bodyText": "Or if you just want the title to be the link\nThe function uses the stream summary data structure proposed in the paper `Efficient computation of frequent and top-k elements in data streams`_ by A.Metwalley, D.Agrawl and A.Abbadi.", "author": "mosabua", "createdAt": "2020-07-13T20:31:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyNzE2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMDkzNA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453830934", "bodyText": ".. code-block :: none doesn't mean anything in javadocs -- it's an RST construct.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /**\n          \n          \n            \n             *  Aggregation function that approximates the frequency of the top-K elements.\n          \n          \n            \n             *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n          \n          \n            \n             *  once fewer than the least-frequent \"frequent\" element.\n          \n          \n            \n             *\n          \n          \n            \n             *   The algorithm is based loosely on:\n          \n          \n            \n             *   .. code-block:: none\n          \n          \n            \n             *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n          \n          \n            \n             *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n          \n          \n            \n             *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n          \n          \n            \n             */\n          \n          \n            \n            /**\n          \n          \n            \n             *  <p>\n          \n          \n            \n             *  Aggregation function that approximates the frequency of the top-K elements.\n          \n          \n            \n             *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n          \n          \n            \n             *  once fewer than the least-frequent \"frequent\" element.\n          \n          \n            \n             *  </p>\n          \n          \n            \n             *\n          \n          \n            \n             * <p>\n          \n          \n            \n             * The algorithm is based loosely on:\n          \n          \n            \n             * <a href=\"https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\">Efficient Computation of Frequent and Top-*k* Elements in Data Streams</a>\n          \n          \n            \n             * by Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi\n          \n          \n            \n             * </p>\n          \n          \n            \n             */", "author": "martint", "createdAt": "2020-07-13T18:00:38Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentFunction.java", "diffHunk": "@@ -0,0 +1,164 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorState;\n+import io.prestosql.spi.function.AccumulatorStateMetadata;\n+import io.prestosql.spi.function.AggregationFunction;\n+import io.prestosql.spi.function.AggregationState;\n+import io.prestosql.spi.function.CombineFunction;\n+import io.prestosql.spi.function.InputFunction;\n+import io.prestosql.spi.function.OutputFunction;\n+import io.prestosql.spi.function.SqlType;\n+import io.prestosql.spi.function.TypeParameter;\n+import io.prestosql.spi.type.BigintType;\n+import io.prestosql.spi.type.VarcharType;\n+\n+import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static io.prestosql.spi.type.StandardTypes.BIGINT;\n+import static io.prestosql.util.Failures.checkCondition;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ *  Aggregation function that approximates the frequency of the top-K elements.\n+ *  This function keeps counts for a \"frequent\" subset of elements and assumes all other elements\n+ *  once fewer than the least-frequent \"frequent\" element.\n+ *\n+ *   The algorithm is based loosely on:\n+ *   .. code-block:: none\n+ *   Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi,\n+ *  \"Efficient Computation of Frequent and Top-*k* Elements in Data Streams\",\n+ *  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27\n+ */", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTI0OQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453831249", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "author": "martint", "createdAt": "2020-07-13T18:01:10Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private final StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTM5OA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453831398", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "author": "martint", "createdAt": "2020-07-13T18:01:29Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private final StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+            int capacity,\n+            ApproximateMostFrequentBucketSerializer<K> serializer,\n+            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTg2OQ==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453831869", "bodyText": "Why * 3 ?", "author": "martint", "createdAt": "2020-07-13T18:02:15Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/ApproximateMostFrequentHistogram.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import com.clearspring.analytics.stream.Counter;\n+import com.clearspring.analytics.stream.StreamSummary;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ *  Calculate the histogram approximately for topk elements based on the\n+ *  <i>Space-Saving</i> algorithm and the <i>Stream-Summary</i> data structure\n+ *  as described in:\n+ *  <i>Efficient Computation of Frequent and Top-k Elements in Data Streams</i>\n+ *  by Metwally, Agrawal, and Abbadi\n+ * @param <K>\n+ */\n+public class ApproximateMostFrequentHistogram<K>\n+{\n+    private static final byte FORMAT_TAG = 0;\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(ApproximateMostFrequentHistogram.class).instanceSize();\n+\n+    private final StreamSummary<K> streamSummary;\n+    private final int maxBuckets;\n+    private final int capacity;\n+    private final ApproximateMostFrequentBucketSerializer<K> serializer;\n+    private final ApproximateMostFrequentBucketDeserializer<K> deserializer;\n+\n+    /**\n+     * @param maxBuckets The maximum number of elements stored in the bucket.\n+     * @param capacity The maximum capacity of the stream summary data structure.\n+     * @param serializer It serializes a bucket into varbinary slice.\n+     * @param deserializer It appends a bucket into the histogram.\n+     */\n+    public ApproximateMostFrequentHistogram(int maxBuckets,\n+            int capacity,\n+            ApproximateMostFrequentBucketSerializer<K> serializer,\n+            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        requireNonNull(serializer, \"serializer is null\");\n+        requireNonNull(deserializer, \"deserializer is null\");\n+        streamSummary = new StreamSummary<>(capacity);\n+        this.maxBuckets = maxBuckets;\n+        this.capacity = capacity;\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+    }\n+\n+    public ApproximateMostFrequentHistogram(Slice serialized,\n+            ApproximateMostFrequentBucketSerializer<K> serializer,\n+            ApproximateMostFrequentBucketDeserializer<K> deserializer)\n+    {\n+        SliceInput input = serialized.getInput();\n+\n+        checkArgument(input.readByte() == FORMAT_TAG, \"Unsupported format tag\");\n+\n+        this.maxBuckets = input.readInt();\n+        this.capacity = input.readInt();\n+        int bucketSize = input.readInt();\n+        this.streamSummary = new StreamSummary<>(capacity);\n+        this.serializer = serializer;\n+        this.deserializer = deserializer;\n+\n+        for (int i = 0; i < bucketSize; i++) {\n+            this.deserializer.deserialize(input, this);\n+        }\n+    }\n+\n+    public void add(K value)\n+    {\n+        streamSummary.offer(value);\n+    }\n+\n+    public void add(K value, long incrementCount)\n+    {\n+        streamSummary.offer(value, toIntExact(incrementCount));\n+    }\n+\n+    public Slice serialize()\n+    {\n+        List<Counter<K>> counters = streamSummary.topK(maxBuckets);\n+        int estimatedSliceSize = Byte.BYTES + // FORMAT_TAG\n+                Integer.BYTES + // maxBuckets\n+                Integer.BYTES + // capacity\n+                Integer.BYTES + // Counters size\n+                counters.size() * Long.BYTES * 2; // Bytes allocated for item and count. Although the estimation is not correct for variable length slices, it should work.\n+        DynamicSliceOutput output = new DynamicSliceOutput(estimatedSliceSize * 3);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMTkwMA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r454011900", "bodyText": "Sorry, I missed fixing that...", "author": "Lewuathe", "createdAt": "2020-07-13T23:43:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMTg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzMzgwMw==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453833803", "bodyText": "Let's rename this to BucketConsumer and the method below to processBucket, or simply process. Calling it a \"function\" is misleading, as this doesn't return any value.", "author": "martint", "createdAt": "2020-07-13T18:05:31Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/BucketReadFunction.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+@FunctionalInterface\n+public interface BucketReadFunction<K>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzNDI4MA==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453834280", "bodyText": "Place each argument on a separate line when splitting across multiple lines.", "author": "martint", "createdAt": "2020-07-13T18:06:20Z", "path": "presto-main/src/main/java/io/prestosql/operator/aggregation/StringApproximateMostFrequentStateSerializer.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator.aggregation;\n+\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.airlift.slice.SliceInput;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.function.AccumulatorStateSerializer;\n+import io.prestosql.spi.type.Type;\n+\n+import static io.prestosql.spi.type.VarbinaryType.VARBINARY;\n+\n+public class StringApproximateMostFrequentStateSerializer\n+        implements AccumulatorStateSerializer<ApproximateMostFrequentFunction.StringState>\n+{\n+    public static void serializeBucket(Slice key, Long count, DynamicSliceOutput output)\n+    {\n+        output.appendInt(key.length());\n+        output.appendBytes(key);\n+        output.appendLong(count);\n+    }\n+\n+    public static void deserializeBucket(SliceInput input, ApproximateMostFrequentHistogram<Slice> histogram)\n+    {\n+        int keySize = input.readInt();\n+        Slice key = input.readSlice(keySize);\n+        long count = input.readLong();\n+        histogram.add(key, count);\n+    }\n+\n+    @Override\n+    public Type getSerializedType()\n+    {\n+        return VARBINARY;\n+    }\n+\n+    @Override\n+    public void serialize(ApproximateMostFrequentFunction.StringState state, BlockBuilder out)\n+    {\n+        if (state.get() == null) {\n+            out.appendNull();\n+        }\n+        else {\n+            VARBINARY.writeSlice(out, state.get().serialize());\n+        }\n+    }\n+\n+    @Override\n+    public void deserialize(Block block, int index, ApproximateMostFrequentFunction.StringState state)\n+    {\n+        state.set(new ApproximateMostFrequentHistogram<Slice>(VARBINARY.getSlice(block, index),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzNTgwMw==", "url": "https://github.com/trinodb/trino/pull/3425#discussion_r453835803", "bodyText": "We may want to add some hint about what are reasonable values for capacity, or how it relates to buckets (if at all) or to the number of elements processed in total.", "author": "martint", "createdAt": "2020-07-13T18:09:08Z", "path": "presto-docs/src/main/sphinx/functions/aggregate.rst", "diffHunk": "@@ -327,6 +327,27 @@ Approximate Aggregate Functions\n     for all ``value``\\ s. This function is equivalent to the variant of\n     :func:`numeric_histogram` that takes a ``weight``, with a per-item weight of ``1``.\n \n+.. function:: approx_most_frequent(buckets, value, capacity) -> map<[same as value], bigint>\n+\n+    Computes the top frequent values up to ``buckets`` elements approximately.\n+    Approximate estimation of the function enables us to pick up the frequent\n+    values with less memory. Larger ``capacity`` improves the accuracy of", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "9380b2c7a14716eacb3f72be872ad65d593a9d4a", "url": "https://github.com/trinodb/trino/commit/9380b2c7a14716eacb3f72be872ad65d593a9d4a", "message": "Add approx_most_frequent aggregation function\n\nIn our experience, we need to get the samples from the underlying\ntable which can contain million of records and its cardinality is\nsignificantly skewed. (e.g. suggesting the selection items in UI)\nWe can get the frequent values by using group by count.\n\nBut since the grouping by the high cardinality column from huge\ntable causes out of memory error, we put the limitation on the\nnumber of samples. It sometimes provide us non-intuitive samples.\n(e.g. lack the frequent items)\n\nThe space saving algorithm with stream summary suggested in [1]\nwill mitigate this type of problem by counting the frequency\nand truncate low frequency data in online manner. The\n`approx_most_frequent` returns the map value containing the high\nfrequency element calculated approximately.\n\nReference\n\n* [1]: A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent and top-k elements in data streams\"\n  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27", "committedDate": "2020-07-15T03:31:27Z", "type": "commit"}, {"oid": "9380b2c7a14716eacb3f72be872ad65d593a9d4a", "url": "https://github.com/trinodb/trino/commit/9380b2c7a14716eacb3f72be872ad65d593a9d4a", "message": "Add approx_most_frequent aggregation function\n\nIn our experience, we need to get the samples from the underlying\ntable which can contain million of records and its cardinality is\nsignificantly skewed. (e.g. suggesting the selection items in UI)\nWe can get the frequent values by using group by count.\n\nBut since the grouping by the high cardinality column from huge\ntable causes out of memory error, we put the limitation on the\nnumber of samples. It sometimes provide us non-intuitive samples.\n(e.g. lack the frequent items)\n\nThe space saving algorithm with stream summary suggested in [1]\nwill mitigate this type of problem by counting the frequency\nand truncate low frequency data in online manner. The\n`approx_most_frequent` returns the map value containing the high\nfrequency element calculated approximately.\n\nReference\n\n* [1]: A.Metwalley, D.Agrawl, A.Abbadi, \"Efficient computation of frequent and top-k elements in data streams\"\n  https://dl.acm.org/doi/10.1007/978-3-540-30570-5_27", "committedDate": "2020-07-15T03:31:27Z", "type": "forcePushed"}]}