{"pr_number": 4451, "pr_title": "Support Iceberg table and column statistics", "pr_createdAt": "2020-07-14T19:40:11Z", "pr_url": "https://github.com/trinodb/trino/pull/4451", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkwNDQzNA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458904434", "bodyText": "Leftover?", "author": "electrum", "createdAt": "2020-07-22T16:02:48Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/IcebergMetadata.java", "diffHunk": "@@ -280,6 +281,16 @@ public ColumnMetadata getColumnMetadata(ConnectorSession session, ConnectorTable\n         return columns.build();\n     }\n \n+    @Override\n+    public TableStatistics getTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        IcebergTableHandle handle = (IcebergTableHandle) tableHandle;\n+        org.apache.iceberg.Table icebergTable = getIcebergTable(metastore, hdfsEnvironment, session, handle.getSchemaTableName());\n+        PartitionTable partitionTable = new PartitionTable(handle, typeManager, icebergTable);\n+        partitionTable.getTableMetadata();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk1MDA4NQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458950085", "bodyText": "No, AIUI this is necessary in order to populate the partition table.  It seems like a questionable API.", "author": "djsstarburst", "createdAt": "2020-07-22T17:09:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkwNDQzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjE2MQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092161", "bodyText": "In the commit I just force-pushed, I changed PartitionTable so that the ConnectorTableMetadata was created in the constructor.  That eliminated the strange API, and allowed a bunch of data members to be final.", "author": "djsstarburst", "createdAt": "2020-07-22T21:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkwNDQzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxMzc5OA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458913798", "bodyText": "No need for this check. ClassCastException provides a good error message now.", "author": "electrum", "createdAt": "2020-07-22T16:16:36Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -164,10 +180,119 @@ public RecordCursor cursor(ConnectorTransactionHandle transactionHandle, Connect\n         }\n     }\n \n+    public TableStatistics getTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        requireNonNull(session, \"session is null\");\n+        requireNonNull(tableHandle, \"tableHandle is null\");\n+        requireNonNull(constraint, \"constraint is null\");\n+        checkArgument(tableHandle instanceof IcebergTableHandle, \"tableHandle not class IcebergTableHandle, but instead %s\", tableHandle.getClass().getName());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjMzNA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092334", "bodyText": "Removed.", "author": "djsstarburst", "createdAt": "2020-07-22T21:24:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxMzc5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNDQ0NQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458914445", "bodyText": "No need to validate input arguments to methods. If null is passed, the caller will get a direct NPE.", "author": "electrum", "createdAt": "2020-07-22T16:17:38Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -164,10 +180,119 @@ public RecordCursor cursor(ConnectorTransactionHandle transactionHandle, Connect\n         }\n     }\n \n+    public TableStatistics getTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        requireNonNull(session, \"session is null\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjM2OA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092368", "bodyText": "Removed.", "author": "djsstarburst", "createdAt": "2020-07-22T21:24:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNDQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNDgwNw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458914807", "bodyText": "This is a bit long, wrap the arguments to ColumnFieldDetails()", "author": "electrum", "createdAt": "2020-07-22T16:18:13Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -164,10 +180,119 @@ public RecordCursor cursor(ConnectorTransactionHandle transactionHandle, Connect\n         }\n     }\n \n+    public TableStatistics getTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        requireNonNull(session, \"session is null\");\n+        requireNonNull(tableHandle, \"tableHandle is null\");\n+        requireNonNull(constraint, \"constraint is null\");\n+        checkArgument(tableHandle instanceof IcebergTableHandle, \"tableHandle not class IcebergTableHandle, but instead %s\", tableHandle.getClass().getName());\n+        IcebergTableHandle icebergTableHandle = (IcebergTableHandle) tableHandle;\n+\n+        if (constraint.getSummary().isNone()) {\n+            return empty();\n+        }\n+\n+        List<PartitionField> partitionFields = icebergTable.spec().fields();\n+        List<Type> icebergPartitionTypes = partitionTypes(partitionFields);\n+        List<IcebergColumnHandle> columnHandles = getColumns(icebergTable.schema(), typeManager);\n+        Map<Integer, IcebergColumnHandle> idToColumnHandle = columnHandles.stream()\n+                .collect(toUnmodifiableMap(IcebergColumnHandle::getId, identity()));\n+\n+        ImmutableMap.Builder<Integer, ColumnFieldDetails> idToDetailsBuilder = ImmutableMap.builder();\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            Type type = icebergPartitionTypes.get(index);\n+            idToDetailsBuilder.put(field.sourceId(), new ColumnFieldDetails(field, idToColumnHandle.get(field.sourceId()), type, toPrestoType(type, typeManager), type.typeId().javaClass()));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjM5Nw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092397", "bodyText": "Wrapped", "author": "djsstarburst", "createdAt": "2020-07-22T21:24:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNDgwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxODQ1Mw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458918453", "bodyText": "This seems to be unused", "author": "electrum", "createdAt": "2020-07-22T16:22:51Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -307,6 +435,12 @@ private static Object convert(Object value, Type type)\n         return value;\n     }\n \n+    private <T> Map<IcebergColumnHandle, T> translateFieldNumbers(Map<Integer, T> map, Map<Integer, IcebergColumnHandle> idToColumnHandle)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjQyMw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092423", "bodyText": "Oops, removed", "author": "djsstarburst", "createdAt": "2020-07-22T21:24:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxODQ1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTA0Ng==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458929046", "bodyText": "Perhaps it's common, but I haven't seen \"summing\" used this way. It might be clearer call this just summary and name the methods like updateSummaryMin.", "author": "electrum", "createdAt": "2020-07-22T16:34:50Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -164,10 +180,119 @@ public RecordCursor cursor(ConnectorTransactionHandle transactionHandle, Connect\n         }\n     }\n \n+    public TableStatistics getTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        requireNonNull(session, \"session is null\");\n+        requireNonNull(tableHandle, \"tableHandle is null\");\n+        requireNonNull(constraint, \"constraint is null\");\n+        checkArgument(tableHandle instanceof IcebergTableHandle, \"tableHandle not class IcebergTableHandle, but instead %s\", tableHandle.getClass().getName());\n+        IcebergTableHandle icebergTableHandle = (IcebergTableHandle) tableHandle;\n+\n+        if (constraint.getSummary().isNone()) {\n+            return empty();\n+        }\n+\n+        List<PartitionField> partitionFields = icebergTable.spec().fields();\n+        List<Type> icebergPartitionTypes = partitionTypes(partitionFields);\n+        List<IcebergColumnHandle> columnHandles = getColumns(icebergTable.schema(), typeManager);\n+        Map<Integer, IcebergColumnHandle> idToColumnHandle = columnHandles.stream()\n+                .collect(toUnmodifiableMap(IcebergColumnHandle::getId, identity()));\n+\n+        ImmutableMap.Builder<Integer, ColumnFieldDetails> idToDetailsBuilder = ImmutableMap.builder();\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            Type type = icebergPartitionTypes.get(index);\n+            idToDetailsBuilder.put(field.sourceId(), new ColumnFieldDetails(field, idToColumnHandle.get(field.sourceId()), type, toPrestoType(type, typeManager), type.typeId().javaClass()));\n+        }\n+        Map<Integer, ColumnFieldDetails> idToDetails = idToDetailsBuilder.build();\n+\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            TableScan tableScan = getTableScan(session, TupleDomain.all(), icebergTableHandle.getSnapshotId(), icebergTable).includeColumnStats();\n+            Map<StructLikeWrapper, Partition> partitions = getPartitions(tableScan);\n+\n+            Partition summingPartition = null;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjQ1Ng==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092456", "bodyText": "Changed", "author": "djsstarburst", "createdAt": "2020-07-22T21:24:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTA0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTQ2NQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r458929465", "bodyText": "Don't static import empty() as the name doesn't have enough context to be standalone.", "author": "electrum", "createdAt": "2020-07-22T16:35:29Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -164,10 +180,119 @@ public RecordCursor cursor(ConnectorTransactionHandle transactionHandle, Connect\n         }\n     }\n \n+    public TableStatistics getTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        requireNonNull(session, \"session is null\");\n+        requireNonNull(tableHandle, \"tableHandle is null\");\n+        requireNonNull(constraint, \"constraint is null\");\n+        checkArgument(tableHandle instanceof IcebergTableHandle, \"tableHandle not class IcebergTableHandle, but instead %s\", tableHandle.getClass().getName());\n+        IcebergTableHandle icebergTableHandle = (IcebergTableHandle) tableHandle;\n+\n+        if (constraint.getSummary().isNone()) {\n+            return empty();\n+        }\n+\n+        List<PartitionField> partitionFields = icebergTable.spec().fields();\n+        List<Type> icebergPartitionTypes = partitionTypes(partitionFields);\n+        List<IcebergColumnHandle> columnHandles = getColumns(icebergTable.schema(), typeManager);\n+        Map<Integer, IcebergColumnHandle> idToColumnHandle = columnHandles.stream()\n+                .collect(toUnmodifiableMap(IcebergColumnHandle::getId, identity()));\n+\n+        ImmutableMap.Builder<Integer, ColumnFieldDetails> idToDetailsBuilder = ImmutableMap.builder();\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            Type type = icebergPartitionTypes.get(index);\n+            idToDetailsBuilder.put(field.sourceId(), new ColumnFieldDetails(field, idToColumnHandle.get(field.sourceId()), type, toPrestoType(type, typeManager), type.typeId().javaClass()));\n+        }\n+        Map<Integer, ColumnFieldDetails> idToDetails = idToDetailsBuilder.build();\n+\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            TableScan tableScan = getTableScan(session, TupleDomain.all(), icebergTableHandle.getSnapshotId(), icebergTable).includeColumnStats();\n+            Map<StructLikeWrapper, Partition> partitions = getPartitions(tableScan);\n+\n+            Partition summingPartition = null;\n+            for (Partition partition : partitions.values()) {\n+                if (partitionMatches(partition, constraint, partitionFields, idToDetails)) {\n+                    if (summingPartition == null) {\n+                        summingPartition = partition;\n+                        continue;\n+                    }\n+                    summingPartition.incrementFileCount(partition.getFileCount());\n+                    summingPartition.incrementRecordCount(partition.getRecordCount());\n+                    summingPartition.incrementSize(partition.getSize());\n+                    summingPartition.updateSummingMin(partitionFields, partition.getMinValues(), partition.getNullCounts(), partition.getRecordCount());\n+                    summingPartition.updateSummingMax(partitionFields, partition.getMaxValues(), partition.getNullCounts(), partition.getRecordCount());\n+                    summingPartition.updateNullCount(partition.getNullCounts());\n+                    summingPartition.updateColumnSizes(partition.getColumnSizes());\n+                }\n+            }\n+\n+            if (summingPartition == null) {\n+                return empty();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5MjYyMw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r459092623", "bodyText": "Refilled.", "author": "djsstarburst", "createdAt": "2020-07-22T21:25:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTQ2NQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5Mzg4NQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463793885", "bodyText": "Revert this? Otherwise add a comment why this is only for ORC.", "author": "electrum", "createdAt": "2020-07-31T19:31:59Z", "path": "presto-iceberg/src/test/java/io/prestosql/plugin/iceberg/TestIcebergSmoke.java", "diffHunk": "@@ -593,6 +619,265 @@ private void testPredicating(Session session, FileFormat fileFormat)\n         dropTable(session, \"test_predicating_on_real\");\n     }\n \n+    @Test\n+    public void testBasicTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testBasicTableStatisticsForFormat);\n+    }\n+\n+    private void testBasicTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_basic_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col REAL) WITH (format = '%s')\", tableName, format.name().toLowerCase(ENGLISH)));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES -10\", 1);\n+        assertUpdate(session, insertStart + \" VALUES 100\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES 200\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        columnStatistics = checkColumnStatistics(getStatisticsForColumn(tableStatistics, \"col\", format), format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testMultipleColumnTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testMultipleColumnTableStatisticsForFormat);\n+    }\n+\n+    private void testMultipleColumnTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_multiple_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 INTEGER, col3 DATE) WITH (format = '%s')\", tableName, format.name()));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1, DATE '2019-06-28')\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10, DATE '2020-01-01')\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 10), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        LocalDate lowDate = LocalDate.of(2019, 6, 28);\n+        LocalDate highDate = LocalDate.of(2020, 1, 1);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES (200, 20, DATE '2020-06-28')\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(3.0, tableStatistics.getRowCount().getValue());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 20), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        highDate = LocalDate.of(2020, 6, 28);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(21, 25)\n+                .mapToObj(i -> format(\"(200, %d, DATE '2020-07-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(26, 30)\n+                .mapToObj(i -> format(\"(NULL, %d, DATE '2020-06-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 13.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 13.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testPartitionedTableStatistics()\n+    {\n+        testPartitionedTableStatisticsForFormat(getSession(), FileFormat.ORC);\n+        //testWithAllFileFormats(this::testPartitionedTableStatisticsForFormat);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2ODY3OQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r464568679", "bodyText": "Yes, a left-over turd, now removed.", "author": "djsstarburst", "createdAt": "2020-08-03T17:48:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5Mzg4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5NzQ4Nw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463797487", "bodyText": "I think you can do this with https://prestosql.io/docs/current/sql/show-stats.html\nTake a look at the SHOW STATS FOR usages in TestHiveIntegrationSmokeTest", "author": "electrum", "createdAt": "2020-07-31T19:40:36Z", "path": "presto-iceberg/src/test/java/io/prestosql/plugin/iceberg/TestIcebergSmoke.java", "diffHunk": "@@ -593,6 +619,265 @@ private void testPredicating(Session session, FileFormat fileFormat)\n         dropTable(session, \"test_predicating_on_real\");\n     }\n \n+    @Test\n+    public void testBasicTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testBasicTableStatisticsForFormat);\n+    }\n+\n+    private void testBasicTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_basic_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col REAL) WITH (format = '%s')\", tableName, format.name().toLowerCase(ENGLISH)));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES -10\", 1);\n+        assertUpdate(session, insertStart + \" VALUES 100\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES 200\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        columnStatistics = checkColumnStatistics(getStatisticsForColumn(tableStatistics, \"col\", format), format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testMultipleColumnTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testMultipleColumnTableStatisticsForFormat);\n+    }\n+\n+    private void testMultipleColumnTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_multiple_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 INTEGER, col3 DATE) WITH (format = '%s')\", tableName, format.name()));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1, DATE '2019-06-28')\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10, DATE '2020-01-01')\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 10), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        LocalDate lowDate = LocalDate.of(2019, 6, 28);\n+        LocalDate highDate = LocalDate.of(2020, 1, 1);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES (200, 20, DATE '2020-06-28')\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(3.0, tableStatistics.getRowCount().getValue());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 20), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        highDate = LocalDate.of(2020, 6, 28);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(21, 25)\n+                .mapToObj(i -> format(\"(200, %d, DATE '2020-07-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(26, 30)\n+                .mapToObj(i -> format(\"(NULL, %d, DATE '2020-06-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 13.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 13.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testPartitionedTableStatistics()\n+    {\n+        testPartitionedTableStatisticsForFormat(getSession(), FileFormat.ORC);\n+        //testWithAllFileFormats(this::testPartitionedTableStatisticsForFormat);\n+    }\n+\n+    private void testPartitionedTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col2'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1)\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10)\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 2.0);\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(-10, 100));\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(-1, 10));\n+\n+        ColumnHandle col2Handle = getColumnHandleFromStatistics(tableStatistics, \"col2\");\n+        TupleDomain<ColumnHandle> tupleDomain = withColumnDomains(ImmutableMap.of(col2Handle, Domain.create(ValueSet.ofRanges(Range.equal(INTEGER, 10L)), false)));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3MDEwNA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r464570104", "bodyText": "In the most recent force-push, I've used SHOW STATS FOR everyplace where it works, and I like it better.  In Iceberg, pushing constraints down doesn't work in Iceberg for SHOW STATS FOR, so I left those massaged by hand.", "author": "djsstarburst", "createdAt": "2020-08-03T17:50:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5NzQ4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5Nzk5Ng==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463797996", "bodyText": "We should also test statistics for all partition type, including non-identity (which won't allow restricting with a constraint ... but we should have a test showing how they work)", "author": "electrum", "createdAt": "2020-07-31T19:41:54Z", "path": "presto-iceberg/src/test/java/io/prestosql/plugin/iceberg/TestIcebergSmoke.java", "diffHunk": "@@ -593,6 +619,265 @@ private void testPredicating(Session session, FileFormat fileFormat)\n         dropTable(session, \"test_predicating_on_real\");\n     }\n \n+    @Test\n+    public void testBasicTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testBasicTableStatisticsForFormat);\n+    }\n+\n+    private void testBasicTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_basic_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col REAL) WITH (format = '%s')\", tableName, format.name().toLowerCase(ENGLISH)));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES -10\", 1);\n+        assertUpdate(session, insertStart + \" VALUES 100\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES 200\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        columnStatistics = checkColumnStatistics(getStatisticsForColumn(tableStatistics, \"col\", format), format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testMultipleColumnTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testMultipleColumnTableStatisticsForFormat);\n+    }\n+\n+    private void testMultipleColumnTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_multiple_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 INTEGER, col3 DATE) WITH (format = '%s')\", tableName, format.name()));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1, DATE '2019-06-28')\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10, DATE '2020-01-01')\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 10), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        LocalDate lowDate = LocalDate.of(2019, 6, 28);\n+        LocalDate highDate = LocalDate.of(2020, 1, 1);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES (200, 20, DATE '2020-06-28')\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(3.0, tableStatistics.getRowCount().getValue());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 20), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        highDate = LocalDate.of(2020, 6, 28);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(21, 25)\n+                .mapToObj(i -> format(\"(200, %d, DATE '2020-07-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(26, 30)\n+                .mapToObj(i -> format(\"(NULL, %d, DATE '2020-06-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 13.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 13.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testPartitionedTableStatistics()\n+    {\n+        testPartitionedTableStatisticsForFormat(getSession(), FileFormat.ORC);\n+        //testWithAllFileFormats(this::testPartitionedTableStatisticsForFormat);\n+    }\n+\n+    private void testPartitionedTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col2'])\", tableName, format.name()));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5ODIzOA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463798238", "bodyText": "If we can do this with SQL using SHOW STATS, we shouldn't need to manually create constraints.", "author": "electrum", "createdAt": "2020-07-31T19:42:32Z", "path": "presto-iceberg/src/test/java/io/prestosql/plugin/iceberg/TestIcebergSmoke.java", "diffHunk": "@@ -593,6 +619,265 @@ private void testPredicating(Session session, FileFormat fileFormat)\n         dropTable(session, \"test_predicating_on_real\");\n     }\n \n+    @Test\n+    public void testBasicTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testBasicTableStatisticsForFormat);\n+    }\n+\n+    private void testBasicTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_basic_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col REAL) WITH (format = '%s')\", tableName, format.name().toLowerCase(ENGLISH)));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES -10\", 1);\n+        assertUpdate(session, insertStart + \" VALUES 100\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES 200\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        columnStatistics = checkColumnStatistics(getStatisticsForColumn(tableStatistics, \"col\", format), format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testMultipleColumnTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testMultipleColumnTableStatisticsForFormat);\n+    }\n+\n+    private void testMultipleColumnTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_multiple_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 INTEGER, col3 DATE) WITH (format = '%s')\", tableName, format.name()));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1, DATE '2019-06-28')\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10, DATE '2020-01-01')\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 10), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        LocalDate lowDate = LocalDate.of(2019, 6, 28);\n+        LocalDate highDate = LocalDate.of(2020, 1, 1);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES (200, 20, DATE '2020-06-28')\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(3.0, tableStatistics.getRowCount().getValue());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 20), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        highDate = LocalDate.of(2020, 6, 28);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(21, 25)\n+                .mapToObj(i -> format(\"(200, %d, DATE '2020-07-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(26, 30)\n+                .mapToObj(i -> format(\"(NULL, %d, DATE '2020-06-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 13.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 13.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testPartitionedTableStatistics()\n+    {\n+        testPartitionedTableStatisticsForFormat(getSession(), FileFormat.ORC);\n+        //testWithAllFileFormats(this::testPartitionedTableStatisticsForFormat);\n+    }\n+\n+    private void testPartitionedTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col2'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1)\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10)\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 2.0);\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(-10, 100));\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(-1, 10));\n+\n+        ColumnHandle col2Handle = getColumnHandleFromStatistics(tableStatistics, \"col2\");\n+        TupleDomain<ColumnHandle> tupleDomain = withColumnDomains(ImmutableMap.of(col2Handle, Domain.create(ValueSet.ofRanges(Range.equal(INTEGER, 10L)), false)));\n+        tableStatistics = getTableStatistics(tableName, new Constraint(tupleDomain));\n+        assertEquals(tableStatistics.getRowCount().getValue(), 1.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(10L, 10L));\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(1, 5)\n+                .mapToObj(i -> format(\"(%d, 10)\", i + 100))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(6, 10)\n+                .mapToObj(i -> \"(NULL, 10)\")\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 12.0);\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 12.0);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(6, 10)\n+                .mapToObj(i -> \"(100, NULL)\")\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 17.0);\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 17.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testStatisticsConstraints()\n+    {\n+        testWithAllFileFormats(this::testStatisticsConstraintsForFormat);\n+    }\n+\n+    private void testStatisticsConstraintsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 BIGINT, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col1'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (1, 101), (2, 102), (3, 103), (4, 104)\", 4);\n+        TableStatistics tableStatistics = getTableStatistics(tableName, new Constraint(TupleDomain.all()));\n+\n+        Predicate<Map<ColumnHandle, NullableValue>> predicate = new TestRelationalNumberPredicate(\"col1\", 3, i -> i >= 0);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3MDQ3NQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r464570475", "bodyText": "Actually, as of now, push-down of filters into SHOW TABLE STATS doesn't work in Iceberg, so until it does, we still need this formulation of the predicate.", "author": "djsstarburst", "createdAt": "2020-08-03T17:51:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5ODIzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5ODc1MQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463798751", "bodyText": "I assume this should be IcebergOrcFileWriter", "author": "electrum", "createdAt": "2020-07-31T19:43:49Z", "path": "presto-iceberg/src/test/java/io/prestosql/plugin/iceberg/TestIcebergSmoke.java", "diffHunk": "@@ -593,6 +619,265 @@ private void testPredicating(Session session, FileFormat fileFormat)\n         dropTable(session, \"test_predicating_on_real\");\n     }\n \n+    @Test\n+    public void testBasicTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testBasicTableStatisticsForFormat);\n+    }\n+\n+    private void testBasicTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_basic_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col REAL) WITH (format = '%s')\", tableName, format.name().toLowerCase(ENGLISH)));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES -10\", 1);\n+        assertUpdate(session, insertStart + \" VALUES 100\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES 200\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        columnStatistics = checkColumnStatistics(getStatisticsForColumn(tableStatistics, \"col\", format), format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testMultipleColumnTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testMultipleColumnTableStatisticsForFormat);\n+    }\n+\n+    private void testMultipleColumnTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_multiple_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 INTEGER, col3 DATE) WITH (format = '%s')\", tableName, format.name()));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1, DATE '2019-06-28')\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10, DATE '2020-01-01')\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(2.0, tableStatistics.getRowCount().getValue());\n+\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 100), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 10), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        LocalDate lowDate = LocalDate.of(2019, 6, 28);\n+        LocalDate highDate = LocalDate.of(2020, 1, 1);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(session, insertStart + \" VALUES (200, 20, DATE '2020-06-28')\", 1);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(3.0, tableStatistics.getRowCount().getValue());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(new DoubleRange(-10, 200), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(new DoubleRange(-1, 20), columnStatistics.getRange().get());\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col3\", format);\n+        highDate = LocalDate.of(2020, 6, 28);\n+        assertEquals(new DoubleRange(lowDate.toEpochDay(), highDate.toEpochDay()), columnStatistics.getRange().get());\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(21, 25)\n+                .mapToObj(i -> format(\"(200, %d, DATE '2020-07-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(26, 30)\n+                .mapToObj(i -> format(\"(NULL, %d, DATE '2020-06-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 13.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 13.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testPartitionedTableStatistics()\n+    {\n+        testPartitionedTableStatisticsForFormat(getSession(), FileFormat.ORC);\n+        //testWithAllFileFormats(this::testPartitionedTableStatisticsForFormat);\n+    }\n+\n+    private void testPartitionedTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col2'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1)\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10)\", 1);\n+\n+        TableStatistics tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 2.0);\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(-10, 100));\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(-1, 10));\n+\n+        ColumnHandle col2Handle = getColumnHandleFromStatistics(tableStatistics, \"col2\");\n+        TupleDomain<ColumnHandle> tupleDomain = withColumnDomains(ImmutableMap.of(col2Handle, Domain.create(ValueSet.ofRanges(Range.equal(INTEGER, 10L)), false)));\n+        tableStatistics = getTableStatistics(tableName, new Constraint(tupleDomain));\n+        assertEquals(tableStatistics.getRowCount().getValue(), 1.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(10L, 10L));\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(1, 5)\n+                .mapToObj(i -> format(\"(%d, 10)\", i + 100))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(6, 10)\n+                .mapToObj(i -> \"(NULL, 10)\")\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 12.0);\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 12.0);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(6, 10)\n+                .mapToObj(i -> \"(100, NULL)\")\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        tableStatistics = getTableStatistics(tableName, Constraint.alwaysTrue());\n+        assertEquals(tableStatistics.getRowCount().getValue(), 17.0);\n+\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getNullsFraction().getValue(), 5.0 / 17.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testStatisticsConstraints()\n+    {\n+        testWithAllFileFormats(this::testStatisticsConstraintsForFormat);\n+    }\n+\n+    private void testStatisticsConstraintsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 BIGINT, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col1'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (1, 101), (2, 102), (3, 103), (4, 104)\", 4);\n+        TableStatistics tableStatistics = getTableStatistics(tableName, new Constraint(TupleDomain.all()));\n+\n+        Predicate<Map<ColumnHandle, NullableValue>> predicate = new TestRelationalNumberPredicate(\"col1\", 3, i -> i >= 0);\n+        IcebergColumnHandle col1Handle = getColumnHandleFromStatistics(tableStatistics, \"col1\");\n+        Constraint constraint = new Constraint(TupleDomain.all(), Optional.of(predicate), Optional.of(ImmutableSet.of(col1Handle)));\n+        tableStatistics = getTableStatistics(tableName, constraint);\n+        assertEquals(tableStatistics.getRowCount().getValue(), 2.0);\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(3, 4));\n+\n+        // This shows that Predicate<ColumnHandle, NullableValue> only filters rows for partitioned columns.\n+        predicate = new TestRelationalNumberPredicate(\"col2\", 102, i -> i >= 0);\n+        IcebergColumnHandle col2Handle = getColumnHandleFromStatistics(tableStatistics, \"col2\");\n+        tableStatistics = getTableStatistics(tableName, new Constraint(TupleDomain.all(), Optional.of(predicate), Optional.empty()));\n+        assertEquals(tableStatistics.getRowCount().getValue(), 4.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(101, 104));\n+    }\n+\n+    private static class TestRelationalNumberPredicate\n+            implements Predicate<Map<ColumnHandle, NullableValue>>\n+    {\n+        private final String columnName;\n+        private final Number comparand;\n+        private final Predicate<Integer> comparePredicate;\n+\n+        public TestRelationalNumberPredicate(String columnName, Number comparand, Predicate<Integer> comparePredicate)\n+        {\n+            this.columnName = columnName;\n+            this.comparand = comparand;\n+            this.comparePredicate = comparePredicate;\n+        }\n+\n+        @Override\n+        public boolean test(Map<ColumnHandle, NullableValue> nullableValues)\n+        {\n+            for (Map.Entry<ColumnHandle, NullableValue> entry : nullableValues.entrySet()) {\n+                IcebergColumnHandle handle = (IcebergColumnHandle) entry.getKey();\n+                if (columnName.equals(handle.getName())) {\n+                    Object object = entry.getValue().getValue();\n+                    if (object instanceof Long) {\n+                        return comparePredicate.test(((Long) object).compareTo(comparand.longValue()));\n+                    }\n+                    else if (object instanceof Double) {\n+                        return comparePredicate.test(((Double) object).compareTo(comparand.doubleValue()));\n+                    }\n+                    else {\n+                        throw new IllegalArgumentException(format(\"NullableValue is neither Long or Double, but %s\", object));\n+                    }\n+                }\n+            }\n+            return false;\n+        }\n+    }\n+\n+    private ColumnStatistics getStatisticsForColumn(TableStatistics tableStatistics, String columnName, FileFormat format)\n+    {\n+        for (Map.Entry<ColumnHandle, ColumnStatistics> entry : tableStatistics.getColumnStatistics().entrySet()) {\n+            IcebergColumnHandle handle = (IcebergColumnHandle) entry.getKey();\n+            if (handle.getName().equals(columnName)) {\n+                return checkColumnStatistics(entry.getValue(), format);\n+            }\n+        }\n+        throw new IllegalArgumentException(\"TableStatistics did not contain column named \" + columnName);\n+    }\n+\n+    private IcebergColumnHandle getColumnHandleFromStatistics(TableStatistics tableStatistics, String columnName)\n+    {\n+        for (ColumnHandle columnHandle : tableStatistics.getColumnStatistics().keySet()) {\n+            IcebergColumnHandle handle = (IcebergColumnHandle) columnHandle;\n+            if (handle.getName().equals(columnName)) {\n+                return handle;\n+            }\n+        }\n+        throw new IllegalArgumentException(\"TableStatistics did not contain column named \" + columnName);\n+    }\n+\n+    private ColumnStatistics checkColumnStatistics(ColumnStatistics statistics, FileFormat format)\n+    {\n+        assertNotNull(statistics, \"statistics is null\");\n+        // Sadly, statistics.getDataSize().isUnknown() for columns in ORC files. See the TODO\n+        // in IcebergOrcFileReader.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3MDc4OQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r464570789", "bodyText": "Fixed.", "author": "djsstarburst", "createdAt": "2020-08-03T17:52:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5ODc1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5OTUwMg==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463799502", "bodyText": "Using HiveUtil here is not correct, as Hive partitions are different than Iceberg partitions.\nRelated, PartitionTable.convert() returns a very Iceberg specific value. For example, floats are converted to ints using floatToIntBits(). And actually, I'm not sure why, since those values seem to be returned directly as the result of the partitions table.\nI think the right way is to pass the constraint to getTableScan() rather than TupleDomain.all() and let the Iceberg library filter the matching files. After that, I don't think we want to deal with partitions at all. We use partitions for the Hive connector since it has statistics at the partition level. But Iceberg has them at the file level, so that's actually more accurate.", "author": "electrum", "createdAt": "2020-07-31T19:45:38Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/TableStatisticsMaker.java", "diffHunk": "@@ -0,0 +1,281 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import com.google.common.collect.ImmutableMap;\n+import io.prestosql.plugin.hive.util.HiveUtil;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableHandle;\n+import io.prestosql.spi.connector.Constraint;\n+import io.prestosql.spi.predicate.Domain;\n+import io.prestosql.spi.predicate.NullableValue;\n+import io.prestosql.spi.predicate.TupleDomain;\n+import io.prestosql.spi.statistics.ColumnStatistics;\n+import io.prestosql.spi.statistics.DoubleRange;\n+import io.prestosql.spi.statistics.Estimate;\n+import io.prestosql.spi.statistics.TableStatistics;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.iceberg.PartitionField;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableScan;\n+import org.apache.iceberg.types.Comparators;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.StructLikeWrapper;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Predicate;\n+\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getColumns;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getTableScan;\n+import static io.prestosql.plugin.iceberg.TypeConverter.toPrestoType;\n+import static java.util.function.Function.identity;\n+import static java.util.stream.Collectors.toUnmodifiableMap;\n+import static org.joda.time.DateTimeZone.UTC;\n+\n+public class TableStatisticsMaker\n+{\n+    private final TypeManager typeManager;\n+    private final Table icebergTable;\n+\n+    private TableStatisticsMaker(TypeManager typeManager, Table icebergTable)\n+    {\n+        this.typeManager = typeManager;\n+        this.icebergTable = icebergTable;\n+    }\n+\n+    public static TableStatistics getTableStatistics(TypeManager typeManager, ConnectorSession session, Constraint constraint, IcebergTableHandle tableHandle, org.apache.iceberg.Table icebergTable)\n+    {\n+        return new TableStatisticsMaker(typeManager, icebergTable).makeTableStatistics(session, tableHandle, constraint);\n+    }\n+\n+    private TableStatistics makeTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        IcebergTableHandle icebergTableHandle = (IcebergTableHandle) tableHandle;\n+\n+        if (constraint.getSummary().isNone()) {\n+            return TableStatistics.empty();\n+        }\n+\n+        PartitionTable partitionTable = new PartitionTable(icebergTableHandle, typeManager, icebergTable);\n+\n+        List<PartitionField> partitionFields = icebergTable.spec().fields();\n+        List<Type> icebergPartitionTypes = partitionTable.partitionTypes(partitionFields);\n+        List<IcebergColumnHandle> columnHandles = getColumns(icebergTable.schema(), typeManager);\n+        Map<Integer, IcebergColumnHandle> idToColumnHandle = columnHandles.stream()\n+                .collect(toUnmodifiableMap(IcebergColumnHandle::getId, identity()));\n+\n+        ImmutableMap.Builder<Integer, ColumnFieldDetails> idToDetailsBuilder = ImmutableMap.builder();\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            Type type = icebergPartitionTypes.get(index);\n+            idToDetailsBuilder.put(field.sourceId(), new ColumnFieldDetails(\n+                    field,\n+                    idToColumnHandle.get(field.sourceId()),\n+                    type,\n+                    toPrestoType(type, typeManager),\n+                    type.typeId().javaClass()));\n+        }\n+        Map<Integer, ColumnFieldDetails> idToDetails = idToDetailsBuilder.build();\n+\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            TableScan tableScan = getTableScan(session, TupleDomain.all(), icebergTableHandle.getSnapshotId(), icebergTable).includeColumnStats();\n+            Map<StructLikeWrapper, Partition> partitions = partitionTable.getPartitions(tableScan);\n+\n+            Partition summary = null;\n+            for (Partition partition : partitions.values()) {\n+                if (partitionMatches(partition, constraint, partitionFields, idToDetails)) {\n+                    if (summary == null) {\n+                        summary = partition;\n+                        continue;\n+                    }\n+                    summary.incrementFileCount(partition.getFileCount());\n+                    summary.incrementRecordCount(partition.getRecordCount());\n+                    summary.incrementSize(partition.getSize());\n+                    updateSummaryMin(summary, partitionFields, partition.getMinValues(), partition.getNullCounts(), partition.getRecordCount());\n+                    updateSummaryMax(summary, partitionFields, partition.getMaxValues(), partition.getNullCounts(), partition.getRecordCount());\n+                    summary.updateNullCount(partition.getNullCounts());\n+                    updateColumnSizes(summary, partition.getColumnSizes());\n+                }\n+            }\n+\n+            if (summary == null) {\n+                return TableStatistics.empty();\n+            }\n+\n+            ImmutableMap.Builder<ColumnHandle, ColumnStatistics> columnHandleBuilder = ImmutableMap.builder();\n+            double recordCount = summary.getRecordCount();\n+            for (IcebergColumnHandle columnHandle : idToColumnHandle.values()) {\n+                int fieldId = columnHandle.getId();\n+                ColumnStatistics.Builder columnBuilder = new ColumnStatistics.Builder();\n+                Long nullCount = summary.getNullCounts().get(fieldId);\n+                if (nullCount != null) {\n+                    columnBuilder.setNullsFraction(Estimate.of(nullCount / recordCount));\n+                }\n+                if (summary.getColumnSizes() != null) {\n+                    Long columnSize = summary.getColumnSizes().get(fieldId);\n+                    if (columnSize != null) {\n+                        columnBuilder.setDataSize(Estimate.of(columnSize));\n+                    }\n+                }\n+                Object min = summary.getMinValues().get(fieldId);\n+                Object max = summary.getMaxValues().get(fieldId);\n+                if (min instanceof Number && max instanceof Number) {\n+                    columnBuilder.setRange(Optional.of(new DoubleRange(((Number) min).doubleValue(), ((Number) max).doubleValue())));\n+                }\n+                columnHandleBuilder.put(columnHandle, columnBuilder.build());\n+            }\n+            return new TableStatistics(Estimate.of(recordCount), columnHandleBuilder.build());\n+        }\n+    }\n+\n+    private boolean partitionMatches(\n+            Partition partition,\n+            Constraint constraint,\n+            List<PartitionField> partitionFields,\n+            Map<Integer, ColumnFieldDetails> fieldDetails)\n+    {\n+        TupleDomain<ColumnHandle> constraintSummary = constraint.getSummary();\n+\n+        Map<ColumnHandle, Domain> domains = constraintSummary.getDomains().get();\n+\n+        Predicate<Map<ColumnHandle, NullableValue>> predicate = constraint.predicate().orElse(value -> true);\n+\n+        ImmutableMap.Builder<ColumnHandle, NullableValue> nullableValueBuilder = ImmutableMap.builder();\n+\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            int fieldId = field.sourceId();\n+            ColumnFieldDetails details = fieldDetails.get(fieldId);\n+            IcebergColumnHandle column = details.getColumnHandle();\n+            Object value = PartitionTable.convert(partition.getValues().get(index, details.getJavaClass()), partition.getIdToTypeMapping().get(fieldId));\n+            Domain allowedDomain = domains.get(column);\n+            if (allowedDomain != null && !allowedDomain.includesNullableValue(value)) {\n+                return false;\n+            }\n+            nullableValueBuilder.put(column, value == null ? NullableValue.asNull(details.getPrestoType())\n+                    : HiveUtil.parsePartitionValue(\"unnamed\", value.toString(), details.getPrestoType(), UTC));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg3NzI4MA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r463877280", "bodyText": "I think I get this point.  I'll take a swing at it.", "author": "djsstarburst", "createdAt": "2020-07-31T22:49:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5OTUwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3MTg3Nw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r464571877", "bodyText": "I did this conversion, but ran into the problem that the Constraint predicate can't be carried in the TupleDomain passed to TableScan, so I still needed most of the machinery to create the map of per-column-per-DataFile NullableValues needed by the Constraint predicate :(", "author": "djsstarburst", "createdAt": "2020-08-03T17:54:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5OTUwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NzE3OA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467267178", "bodyText": "We should fork and simplify this code, since the Hive code will return return the wrong result for strings equaling __HIVE_DEFAULT_PARTITION__, plus the conversion logic is more lax than we need for Iceberg. For example, the Hive code handles multiple representations for boolean values, etc.\nFor this, the conversion can go directly from the value object to NullableValue. No need to round trip through a string. i.e. if the Iceberg object is a Long, we just call NullableValue.of(...) directly.\nWe want to avoid using Hive code that is \"close enough\" or that just happens to be the same (but might change in the future) for Iceberg.", "author": "electrum", "createdAt": "2020-08-07T21:02:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5OTUwMg=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NDAwMA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467264000", "bodyText": "This is fine. The constraint is simply a hint to allow the connector to optimize data retrieval. The engine still applies the filter to the returned rows.\nFrom a semantic perspective, this table returns information about partitions. There is no filter that would (or should) affect the information for a partition (only filter out non-matching partitions). This is different than retrieving statistics where we want more accurate statistics about the filtered data that will be processed.", "author": "electrum", "createdAt": "2020-08-07T20:53:55Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/PartitionTable.java", "diffHunk": "@@ -149,6 +149,7 @@ public ConnectorTableMetadata getTableMetadata()\n                 .collect(toImmutableList());\n     }\n \n+    // TODO: This method ignores the constraint.  How can that be right?", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMyMjU3Mw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467322573", "bodyText": "Got it, and thanks for the explanation.\nI removed the comment.", "author": "djsstarburst", "createdAt": "2020-08-07T23:10:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NDAwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NDU2Nw==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467264567", "bodyText": "Nit: parenthesis on lambda parameter not needed", "author": "electrum", "createdAt": "2020-08-07T20:55:14Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/TableStatisticsMaker.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.hive.util.HiveUtil;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableHandle;\n+import io.prestosql.spi.connector.Constraint;\n+import io.prestosql.spi.predicate.Domain;\n+import io.prestosql.spi.predicate.NullableValue;\n+import io.prestosql.spi.predicate.TupleDomain;\n+import io.prestosql.spi.statistics.ColumnStatistics;\n+import io.prestosql.spi.statistics.DoubleRange;\n+import io.prestosql.spi.statistics.Estimate;\n+import io.prestosql.spi.statistics.TableStatistics;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileScanTask;\n+import org.apache.iceberg.PartitionField;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableScan;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.types.Comparators;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getColumns;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getIdentityPartitions;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getTableScan;\n+import static io.prestosql.plugin.iceberg.Partition.toMap;\n+import static io.prestosql.plugin.iceberg.TypeConverter.toPrestoType;\n+import static java.util.function.Function.identity;\n+import static java.util.stream.Collectors.toSet;\n+import static java.util.stream.Collectors.toUnmodifiableMap;\n+import static org.joda.time.DateTimeZone.UTC;\n+\n+public class TableStatisticsMaker\n+{\n+    private static final Logger log = Logger.get(TableStatisticsMaker.class);\n+\n+    private final TypeManager typeManager;\n+    private final Table icebergTable;\n+\n+    private TableStatisticsMaker(TypeManager typeManager, Table icebergTable)\n+    {\n+        this.typeManager = typeManager;\n+        this.icebergTable = icebergTable;\n+    }\n+\n+    public static TableStatistics getTableStatistics(TypeManager typeManager, ConnectorSession session, Constraint constraint, IcebergTableHandle tableHandle, org.apache.iceberg.Table icebergTable)\n+    {\n+        return new TableStatisticsMaker(typeManager, icebergTable).makeTableStatistics(session, tableHandle, constraint);\n+    }\n+\n+    private TableStatistics makeTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        IcebergTableHandle icebergTableHandle = (IcebergTableHandle) tableHandle;\n+\n+        if (constraint.getSummary().isNone()) {\n+            return TableStatistics.empty();\n+        }\n+\n+        TupleDomain<IcebergColumnHandle> intersection = constraint.getSummary().transform(IcebergColumnHandle.class::cast).intersect(icebergTableHandle.getPredicate());\n+\n+        if (intersection.isNone()) {\n+            return TableStatistics.empty();\n+        }\n+\n+        List<Types.NestedField> columns = icebergTable.schema().columns();\n+\n+        Map<Integer, Type.PrimitiveType> idToTypeMapping = columns.stream()\n+                .filter(column -> column.type().isPrimitiveType())\n+                .collect(Collectors.toMap(Types.NestedField::fieldId, (column) -> column.type().asPrimitiveType()));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMyMjYwNg==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467322606", "bodyText": "Removed.", "author": "djsstarburst", "createdAt": "2020-08-07T23:10:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NDU2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NzI2MA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467267260", "bodyText": "requireNonNull", "author": "electrum", "createdAt": "2020-08-07T21:02:24Z", "path": "presto-iceberg/src/main/java/io/prestosql/plugin/iceberg/TableStatisticsMaker.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.iceberg;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.hive.util.HiveUtil;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.ConnectorTableHandle;\n+import io.prestosql.spi.connector.Constraint;\n+import io.prestosql.spi.predicate.Domain;\n+import io.prestosql.spi.predicate.NullableValue;\n+import io.prestosql.spi.predicate.TupleDomain;\n+import io.prestosql.spi.statistics.ColumnStatistics;\n+import io.prestosql.spi.statistics.DoubleRange;\n+import io.prestosql.spi.statistics.Estimate;\n+import io.prestosql.spi.statistics.TableStatistics;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileScanTask;\n+import org.apache.iceberg.PartitionField;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableScan;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.types.Comparators;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getColumns;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getIdentityPartitions;\n+import static io.prestosql.plugin.iceberg.IcebergUtil.getTableScan;\n+import static io.prestosql.plugin.iceberg.Partition.toMap;\n+import static io.prestosql.plugin.iceberg.TypeConverter.toPrestoType;\n+import static java.util.function.Function.identity;\n+import static java.util.stream.Collectors.toSet;\n+import static java.util.stream.Collectors.toUnmodifiableMap;\n+import static org.joda.time.DateTimeZone.UTC;\n+\n+public class TableStatisticsMaker\n+{\n+    private static final Logger log = Logger.get(TableStatisticsMaker.class);\n+\n+    private final TypeManager typeManager;\n+    private final Table icebergTable;\n+\n+    private TableStatisticsMaker(TypeManager typeManager, Table icebergTable)\n+    {\n+        this.typeManager = typeManager;\n+        this.icebergTable = icebergTable;\n+    }\n+\n+    public static TableStatistics getTableStatistics(TypeManager typeManager, ConnectorSession session, Constraint constraint, IcebergTableHandle tableHandle, org.apache.iceberg.Table icebergTable)\n+    {\n+        return new TableStatisticsMaker(typeManager, icebergTable).makeTableStatistics(session, tableHandle, constraint);\n+    }\n+\n+    private TableStatistics makeTableStatistics(ConnectorSession session, ConnectorTableHandle tableHandle, Constraint constraint)\n+    {\n+        IcebergTableHandle icebergTableHandle = (IcebergTableHandle) tableHandle;\n+\n+        if (constraint.getSummary().isNone()) {\n+            return TableStatistics.empty();\n+        }\n+\n+        TupleDomain<IcebergColumnHandle> intersection = constraint.getSummary().transform(IcebergColumnHandle.class::cast).intersect(icebergTableHandle.getPredicate());\n+\n+        if (intersection.isNone()) {\n+            return TableStatistics.empty();\n+        }\n+\n+        List<Types.NestedField> columns = icebergTable.schema().columns();\n+\n+        Map<Integer, Type.PrimitiveType> idToTypeMapping = columns.stream()\n+                .filter(column -> column.type().isPrimitiveType())\n+                .collect(Collectors.toMap(Types.NestedField::fieldId, (column) -> column.type().asPrimitiveType()));\n+        List<PartitionField> partitionFields = icebergTable.spec().fields();\n+\n+        Set<Integer> identityPartitionIds = getIdentityPartitions(icebergTable.spec()).keySet().stream()\n+                .map(PartitionField::sourceId)\n+                .collect(toSet());\n+\n+        List<Types.NestedField> nonPartitionPrimitiveColumns = columns.stream()\n+                .filter(column -> !identityPartitionIds.contains(column.fieldId()) && column.type().isPrimitiveType())\n+                .collect(toImmutableList());\n+\n+        List<Type> icebergPartitionTypes = partitionTypes(partitionFields, idToTypeMapping);\n+        List<IcebergColumnHandle> columnHandles = getColumns(icebergTable.schema(), typeManager);\n+        Map<Integer, IcebergColumnHandle> idToColumnHandle = columnHandles.stream()\n+                .collect(toUnmodifiableMap(IcebergColumnHandle::getId, identity()));\n+\n+        ImmutableMap.Builder<Integer, ColumnFieldDetails> idToDetailsBuilder = ImmutableMap.builder();\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            Type type = icebergPartitionTypes.get(index);\n+            idToDetailsBuilder.put(field.sourceId(), new ColumnFieldDetails(\n+                    field,\n+                    idToColumnHandle.get(field.sourceId()),\n+                    type,\n+                    toPrestoType(type, typeManager),\n+                    type.typeId().javaClass()));\n+        }\n+        Map<Integer, ColumnFieldDetails> idToDetails = idToDetailsBuilder.build();\n+\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            TableScan tableScan = getTableScan(session, intersection, icebergTableHandle.getSnapshotId(), icebergTable).includeColumnStats();\n+            Partition summary = null;\n+            try (CloseableIterable<FileScanTask> fileScanTasks = tableScan.planFiles()) {\n+                for (FileScanTask fileScanTask : fileScanTasks) {\n+                    DataFile dataFile = fileScanTask.file();\n+                    if (!dataFileMatches(\n+                            dataFile,\n+                            constraint,\n+                            idToTypeMapping,\n+                            partitionFields,\n+                            idToDetails)) {\n+                        continue;\n+                    }\n+\n+                    if (summary == null) {\n+                        summary = new Partition(\n+                                idToTypeMapping,\n+                                nonPartitionPrimitiveColumns,\n+                                dataFile.partition(),\n+                                dataFile.recordCount(),\n+                                dataFile.fileSizeInBytes(),\n+                                toMap(idToTypeMapping, dataFile.lowerBounds()),\n+                                toMap(idToTypeMapping, dataFile.upperBounds()),\n+                                dataFile.nullValueCounts(),\n+                                dataFile.columnSizes());\n+                    }\n+                    else {\n+                        summary.incrementFileCount();\n+                        summary.incrementRecordCount(dataFile.recordCount());\n+                        summary.incrementSize(dataFile.fileSizeInBytes());\n+                        updateSummaryMin(summary, partitionFields, toMap(idToTypeMapping, dataFile.lowerBounds()), dataFile.nullValueCounts(), dataFile.recordCount());\n+                        updateSummaryMax(summary, partitionFields, toMap(idToTypeMapping, dataFile.upperBounds()), dataFile.nullValueCounts(), dataFile.recordCount());\n+                        summary.updateNullCount(dataFile.nullValueCounts());\n+                        updateColumnSizes(summary, dataFile.columnSizes());\n+                    }\n+                }\n+            }\n+            catch (IOException e) {\n+                throw new UncheckedIOException(e);\n+            }\n+\n+            if (summary == null) {\n+                return TableStatistics.empty();\n+            }\n+\n+            ImmutableMap.Builder<ColumnHandle, ColumnStatistics> columnHandleBuilder = ImmutableMap.builder();\n+            double recordCount = summary.getRecordCount();\n+            for (IcebergColumnHandle columnHandle : idToColumnHandle.values()) {\n+                int fieldId = columnHandle.getId();\n+                ColumnStatistics.Builder columnBuilder = new ColumnStatistics.Builder();\n+                Long nullCount = summary.getNullCounts().get(fieldId);\n+                if (nullCount != null) {\n+                    columnBuilder.setNullsFraction(Estimate.of(nullCount / recordCount));\n+                }\n+                if (summary.getColumnSizes() != null) {\n+                    Long columnSize = summary.getColumnSizes().get(fieldId);\n+                    if (columnSize != null) {\n+                        columnBuilder.setDataSize(Estimate.of(columnSize));\n+                    }\n+                }\n+                Object min = summary.getMinValues().get(fieldId);\n+                Object max = summary.getMaxValues().get(fieldId);\n+                if (min instanceof Number && max instanceof Number) {\n+                    columnBuilder.setRange(Optional.of(new DoubleRange(((Number) min).doubleValue(), ((Number) max).doubleValue())));\n+                }\n+                columnHandleBuilder.put(columnHandle, columnBuilder.build());\n+            }\n+            return new TableStatistics(Estimate.of(recordCount), columnHandleBuilder.build());\n+        }\n+    }\n+\n+    private boolean dataFileMatches(\n+            DataFile dataFile,\n+            Constraint constraint,\n+            Map<Integer, Type.PrimitiveType> idToTypeMapping,\n+            List<PartitionField> partitionFields,\n+            Map<Integer, ColumnFieldDetails> fieldDetails)\n+    {\n+        TupleDomain<ColumnHandle> constraintSummary = constraint.getSummary();\n+\n+        Map<ColumnHandle, Domain> domains = constraintSummary.getDomains().get();\n+\n+        Predicate<Map<ColumnHandle, NullableValue>> predicate = constraint.predicate().orElse(value -> true);\n+\n+        ImmutableMap.Builder<ColumnHandle, NullableValue> nullableValueBuilder = ImmutableMap.builder();\n+\n+        for (int index = 0; index < partitionFields.size(); index++) {\n+            PartitionField field = partitionFields.get(index);\n+            int fieldId = field.sourceId();\n+            ColumnFieldDetails details = fieldDetails.get(fieldId);\n+            IcebergColumnHandle column = details.getColumnHandle();\n+            Object value = PartitionTable.convert(dataFile.partition().get(index, details.getJavaClass()), idToTypeMapping.get(fieldId));\n+            Domain allowedDomain = domains.get(column);\n+            if (allowedDomain != null && !allowedDomain.includesNullableValue(value)) {\n+                return false;\n+            }\n+            nullableValueBuilder.put(column, value == null ? NullableValue.asNull(details.getPrestoType())\n+                    : HiveUtil.parsePartitionValue(\"unnamed\", value.toString(), details.getPrestoType(), UTC));\n+        }\n+\n+        if (constraint.getPredicateColumns().isPresent()) {\n+            return predicate.test(nullableValueBuilder.build());\n+        }\n+\n+        return true;\n+    }\n+\n+    public List<Type> partitionTypes(List<PartitionField> partitionFields, Map<Integer, Type.PrimitiveType> idToTypeMapping)\n+    {\n+        ImmutableList.Builder<Type> partitionTypeBuilder = ImmutableList.builder();\n+        for (PartitionField partitionField : partitionFields) {\n+            Type.PrimitiveType sourceType = idToTypeMapping.get(partitionField.sourceId());\n+            Type type = partitionField.transform().getResultType(sourceType);\n+            partitionTypeBuilder.add(type);\n+        }\n+        return partitionTypeBuilder.build();\n+    }\n+\n+    private static class ColumnFieldDetails\n+    {\n+        private final PartitionField field;\n+        private final IcebergColumnHandle columnHandle;\n+        private final Type icebergType;\n+        private final io.prestosql.spi.type.Type prestoType;\n+        private final Class<?> javaClass;\n+\n+        public ColumnFieldDetails(PartitionField field, IcebergColumnHandle columnHandle, Type icebergType, io.prestosql.spi.type.Type prestoType, Class<?> javaClass)\n+        {\n+            this.field = field;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMyMjY1OA==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467322658", "bodyText": "Added for all args.", "author": "djsstarburst", "createdAt": "2020-08-07T23:10:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NzI2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NzUyMQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467267521", "bodyText": "Nit: else is redundant", "author": "electrum", "createdAt": "2020-08-07T21:03:03Z", "path": "presto-iceberg/src/test/java/io/prestosql/plugin/iceberg/TestIcebergSmoke.java", "diffHunk": "@@ -587,6 +612,313 @@ private void testPredicating(Session session, FileFormat fileFormat)\n         dropTable(session, \"test_predicating_on_real\");\n     }\n \n+    @Test\n+    public void testBasicTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testBasicTableStatisticsForFormat);\n+    }\n+\n+    private void testBasicTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_basic_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col REAL) WITH (format = '%s')\", tableName, format.name().toLowerCase(ENGLISH)));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES -10\", 1);\n+        assertUpdate(session, insertStart + \" VALUES 100\", 1);\n+\n+        // SHOW STATS returns rows of the form: column_name, data_size, distinct_values_count, nulls_fractions, row_count, low_value, high_value\n+\n+        MaterializedResult result = computeActual(\"SHOW STATS FOR \" + tableName);\n+        MaterializedResult expectedStatistics =\n+                resultBuilder(session, VARCHAR, DOUBLE, DOUBLE, DOUBLE, DOUBLE, VARCHAR, VARCHAR)\n+                        .row(\"col\", columnSizeForFormat(format, 96.0), null, 0.0, null, \"-10.0\", \"100.0\")\n+                        .row(null, null, null, null, 2.0, null, null)\n+                        .build();\n+        assertEquals(result, expectedStatistics);\n+\n+        assertUpdate(session, insertStart + \" VALUES 200\", 1);\n+\n+        result = computeActual(\"SHOW STATS FOR \" + tableName);\n+        expectedStatistics =\n+                resultBuilder(getSession(), VARCHAR, DOUBLE, DOUBLE, DOUBLE, DOUBLE, VARCHAR, VARCHAR)\n+                        .row(\"col\", columnSizeForFormat(format, 144.0), null, 0.0, null, \"-10.0\", \"200.0\")\n+                        .row(null, null, null, null, 3.0, null, null)\n+                        .build();\n+        assertEquals(result, expectedStatistics);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    private Double columnSizeForFormat(FileFormat format, double size)\n+    {\n+        return format == FileFormat.PARQUET ? size : null;\n+    }\n+\n+    @Test\n+    public void testMultipleColumnTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testMultipleColumnTableStatisticsForFormat);\n+    }\n+\n+    private void testMultipleColumnTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_multiple_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 INTEGER, col3 DATE) WITH (format = '%s')\", tableName, format.name()));\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1, DATE '2019-06-28')\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10, DATE '2020-01-01')\", 1);\n+\n+        MaterializedResult result = computeActual(\"SHOW STATS FOR \" + tableName);\n+\n+        MaterializedResult expectedStatistics =\n+                resultBuilder(session, VARCHAR, DOUBLE, DOUBLE, DOUBLE, DOUBLE, VARCHAR, VARCHAR)\n+                        .row(\"col1\", columnSizeForFormat(format, 96.0), null, 0.0, null, \"-10.0\", \"100.0\")\n+                        .row(\"col2\", columnSizeForFormat(format, 98.0), null, 0.0, null, \"-1\", \"10\")\n+                        .row(\"col3\", columnSizeForFormat(format, 102.0), null, 0.0, null, \"2019-06-28\", \"2020-01-01\")\n+                        .row(null, null, null, null, 2.0, null, null)\n+                        .build();\n+        assertEquals(result, expectedStatistics);\n+\n+        assertUpdate(session, insertStart + \" VALUES (200, 20, DATE '2020-06-28')\", 1);\n+        result = computeActual(\"SHOW STATS FOR \" + tableName);\n+        expectedStatistics =\n+                resultBuilder(session, VARCHAR, DOUBLE, DOUBLE, DOUBLE, DOUBLE, VARCHAR, VARCHAR)\n+                        .row(\"col1\", columnSizeForFormat(format, 144.0), null, 0.0, null, \"-10.0\", \"200.0\")\n+                        .row(\"col2\", columnSizeForFormat(format, 147), null, 0.0, null, \"-1\", \"20\")\n+                        .row(\"col3\", columnSizeForFormat(format, 153), null, 0.0, null, \"2019-06-28\", \"2020-06-28\")\n+                        .row(null, null, null, null, 3.0, null, null)\n+                        .build();\n+        assertEquals(result, expectedStatistics);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(21, 25)\n+                .mapToObj(i -> format(\"(200, %d, DATE '2020-07-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(26, 30)\n+                .mapToObj(i -> format(\"(NULL, %d, DATE '2020-06-%d')\", i, i))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        result = computeActual(\"SHOW STATS FOR \" + tableName);\n+\n+        expectedStatistics =\n+                resultBuilder(session, VARCHAR, DOUBLE, DOUBLE, DOUBLE, DOUBLE, VARCHAR, VARCHAR)\n+                        .row(\"col1\", columnSizeForFormat(format, 271.0), null, 5.0 / 13.0, null, \"-10.0\", \"200.0\")\n+                        .row(\"col2\", columnSizeForFormat(format, 251.0), null, 0.0, null, \"-1\", \"30\")\n+                        .row(\"col3\", columnSizeForFormat(format, 261), null, 0.0, null, \"2019-06-28\", \"2020-07-25\")\n+                        .row(null, null, null, null, 13.0, null, null)\n+                        .build();\n+        assertEquals(result, expectedStatistics);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testPartitionedTableStatistics()\n+    {\n+        testWithAllFileFormats(this::testPartitionedTableStatisticsForFormat);\n+    }\n+\n+    private void testPartitionedTableStatisticsForFormat(Session session, FileFormat format)\n+    {\n+        log.info(\"Starting testPartitionedTableStatistics for format \" + format);\n+\n+        String tableName = format(\"iceberg.tpch.test_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 REAL, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col2'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (-10, -1)\", 1);\n+        assertUpdate(session, insertStart + \" VALUES (100, 10)\", 1);\n+\n+        log.info(\"Starting testPartitionedTableStatistics  for format \" + format + \" before first test\");\n+\n+        MaterializedResult result = computeActual(\"SHOW STATS FOR \" + tableName);\n+        assertEquals(result.getRowCount(), 3);\n+\n+        MaterializedRow row0 = result.getMaterializedRows().get(0);\n+        org.testng.Assert.assertEquals(row0.getField(0), \"col1\");\n+        org.testng.Assert.assertEquals(row0.getField(3), 0.0);\n+        org.testng.Assert.assertEquals(row0.getField(5), \"-10.0\");\n+        org.testng.Assert.assertEquals(row0.getField(6), \"100.0\");\n+\n+        MaterializedRow row1 = result.getMaterializedRows().get(1);\n+        assertEquals(row1.getField(0), \"col2\");\n+        assertEquals(row1.getField(3), 0.0);\n+        assertEquals(row1.getField(5), \"-1\");\n+        assertEquals(row1.getField(6), \"10\");\n+\n+        MaterializedRow row2 = result.getMaterializedRows().get(2);\n+        assertEquals(row2.getField(4), 2.0);\n+\n+        log.info(\"Starting testPartitionedTableStatistics for format \" + format + \" after first test\");\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(1, 5)\n+                .mapToObj(i -> format(\"(%d, 10)\", i + 100))\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(6, 10)\n+                .mapToObj(i -> \"(NULL, 10)\")\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        result = computeActual(\"SHOW STATS FOR \" + tableName);\n+        assertEquals(result.getRowCount(), 3);\n+        row0 = result.getMaterializedRows().get(0);\n+        assertEquals(row0.getField(0), \"col1\");\n+        assertEquals(row0.getField(3), 5.0 / 12.0);\n+        assertEquals(row0.getField(5), \"-10.0\");\n+        assertEquals(row0.getField(6), \"105.0\");\n+\n+        row1 = result.getMaterializedRows().get(1);\n+        assertEquals(row1.getField(0), \"col2\");\n+        assertEquals(row1.getField(3), 0.0);\n+        assertEquals(row1.getField(5), \"-1\");\n+        assertEquals(row1.getField(6), \"10\");\n+\n+        row2 = result.getMaterializedRows().get(2);\n+        assertEquals(row2.getField(4), 12.0);\n+\n+        assertUpdate(insertStart + \" VALUES \" + IntStream.rangeClosed(6, 10)\n+                .mapToObj(i -> \"(100, NULL)\")\n+                .collect(Collectors.joining(\", \")), 5);\n+\n+        result = computeActual(\"SHOW STATS FOR \" + tableName);\n+        row0 = result.getMaterializedRows().get(0);\n+        assertEquals(row0.getField(0), \"col1\");\n+        assertEquals(row0.getField(3), 5.0 / 17.0);\n+        assertEquals(row0.getField(5), \"-10.0\");\n+        assertEquals(row0.getField(6), \"105.0\");\n+\n+        row1 = result.getMaterializedRows().get(1);\n+        assertEquals(row1.getField(0), \"col2\");\n+        assertEquals(row1.getField(3), 5.0 / 17.0);\n+        assertEquals(row1.getField(5), \"-1\");\n+        assertEquals(row1.getField(6), \"10\");\n+\n+        row2 = result.getMaterializedRows().get(2);\n+        assertEquals(row2.getField(4), 17.0);\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    @Test\n+    public void testStatisticsConstraints()\n+    {\n+        testWithAllFileFormats(this::testStatisticsConstraintsForFormat);\n+    }\n+\n+    private void testStatisticsConstraintsForFormat(Session session, FileFormat format)\n+    {\n+        String tableName = format(\"iceberg.tpch.test_simple_partitioned_%s_table_statistics\", format.name().toLowerCase(ENGLISH));\n+        assertUpdate(format(\"CREATE TABLE %s (col1 BIGINT, col2 BIGINT) WITH (format = '%s', partitioning = ARRAY['col1'])\", tableName, format.name()));\n+\n+        String insertStart = format(\"INSERT INTO %s\", tableName);\n+        assertUpdate(session, insertStart + \" VALUES (1, 101), (2, 102), (3, 103), (4, 104)\", 4);\n+        TableStatistics tableStatistics = getTableStatistics(tableName, new Constraint(TupleDomain.all()));\n+\n+        // TODO Change to use SHOW STATS FOR table_name when Iceberg applyFilter allows pushdown.\n+        // Then I can get rid of the helper methods and direct use of TableStatistics\n+\n+        Predicate<Map<ColumnHandle, NullableValue>> predicate = new TestRelationalNumberPredicate(\"col1\", 3, i -> i >= 0);\n+        IcebergColumnHandle col1Handle = getColumnHandleFromStatistics(tableStatistics, \"col1\");\n+        Constraint constraint = new Constraint(TupleDomain.all(), Optional.of(predicate), Optional.of(ImmutableSet.of(col1Handle)));\n+        tableStatistics = getTableStatistics(tableName, constraint);\n+        assertEquals(tableStatistics.getRowCount().getValue(), 2.0);\n+        ColumnStatistics columnStatistics = getStatisticsForColumn(tableStatistics, \"col1\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(3, 4));\n+\n+        // This shows that Predicate<ColumnHandle, NullableValue> only filters rows for partitioned columns.\n+        predicate = new TestRelationalNumberPredicate(\"col2\", 102, i -> i >= 0);\n+        IcebergColumnHandle col2Handle = getColumnHandleFromStatistics(tableStatistics, \"col2\");\n+        tableStatistics = getTableStatistics(tableName, new Constraint(TupleDomain.all(), Optional.of(predicate), Optional.empty()));\n+        assertEquals(tableStatistics.getRowCount().getValue(), 4.0);\n+        columnStatistics = getStatisticsForColumn(tableStatistics, \"col2\", format);\n+        assertEquals(columnStatistics.getRange().get(), new DoubleRange(101, 104));\n+\n+        dropTable(session, tableName);\n+    }\n+\n+    private static class TestRelationalNumberPredicate\n+            implements Predicate<Map<ColumnHandle, NullableValue>>\n+    {\n+        private final String columnName;\n+        private final Number comparand;\n+        private final Predicate<Integer> comparePredicate;\n+\n+        public TestRelationalNumberPredicate(String columnName, Number comparand, Predicate<Integer> comparePredicate)\n+        {\n+            this.columnName = columnName;\n+            this.comparand = comparand;\n+            this.comparePredicate = comparePredicate;\n+        }\n+\n+        @Override\n+        public boolean test(Map<ColumnHandle, NullableValue> nullableValues)\n+        {\n+            for (Map.Entry<ColumnHandle, NullableValue> entry : nullableValues.entrySet()) {\n+                IcebergColumnHandle handle = (IcebergColumnHandle) entry.getKey();\n+                if (columnName.equals(handle.getName())) {\n+                    Object object = entry.getValue().getValue();\n+                    if (object instanceof Long) {\n+                        return comparePredicate.test(((Long) object).compareTo(comparand.longValue()));\n+                    }\n+                    else if (object instanceof Double) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzMyMjY3NQ==", "url": "https://github.com/trinodb/trino/pull/4451#discussion_r467322675", "bodyText": "Removed.", "author": "djsstarburst", "createdAt": "2020-08-07T23:10:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI2NzUyMQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "b4b61cbd76c3c8788cc0cdca24ad01ae3f0f5e4a", "url": "https://github.com/trinodb/trino/commit/b4b61cbd76c3c8788cc0cdca24ad01ae3f0f5e4a", "message": "Extract class Partition from PartitionTable\n\nAs the first step in providing table statistics, this commit\nextracts class Partition from PartitionTable, and passes the\ntwo PartitionTable attributes referenced by Partition members\nas constructor parameters.", "committedDate": "2020-08-17T15:09:45Z", "type": "commit"}, {"oid": "af6b38263283819632b6ebac07ebe8729468b238", "url": "https://github.com/trinodb/trino/commit/af6b38263283819632b6ebac07ebe8729468b238", "message": "Support Iceberg table and column statistics\n\nThis commit adds support for Iceberg table and\ncolumn statistics. The commit includes tests\nfor constraints by TupleDomain as well as\nPredicate.\n\nColumn statistics include null fractions and\nmin and max column values. Column size statistics\nare available for Parquet files, but are not yet\ngenerated by the ORC column writers.", "committedDate": "2020-08-17T15:48:43Z", "type": "commit"}, {"oid": "af6b38263283819632b6ebac07ebe8729468b238", "url": "https://github.com/trinodb/trino/commit/af6b38263283819632b6ebac07ebe8729468b238", "message": "Support Iceberg table and column statistics\n\nThis commit adds support for Iceberg table and\ncolumn statistics. The commit includes tests\nfor constraints by TupleDomain as well as\nPredicate.\n\nColumn statistics include null fractions and\nmin and max column values. Column size statistics\nare available for Parquet files, but are not yet\ngenerated by the ORC column writers.", "committedDate": "2020-08-17T15:48:43Z", "type": "forcePushed"}]}