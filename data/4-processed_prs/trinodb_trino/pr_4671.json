{"pr_number": 4671, "pr_title": "Demonstrate Spark/Iceberg and Presto/Iceberg compatibility", "pr_createdAt": "2020-08-03T02:08:38Z", "pr_url": "https://github.com/trinodb/trino/pull/4671", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM2MDg3NQ==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464360875", "bodyText": "I think we should use the original name of your test (TestSparkCompatibility) or something similar.", "author": "aalbu", "createdAt": "2020-08-03T11:43:15Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/iceberg/TestIcebergBasic.java", "diffHunk": "@@ -30,30 +29,177 @@\n public class TestIcebergBasic", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU5NDY1MQ==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464594651", "bodyText": "Good point.  I'll change it back to that name.", "author": "djsstarburst", "createdAt": "2020-08-03T18:40:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM2MDg3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM2MzE2Nw==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464363167", "bodyText": "I think the equivalent Presto semantics would be to treat this as a timestamp (without timezone), so we could cast(_timestamp as TIMESTAMP).  In addition, we need non-legacy semantics to preserve wall clock time, so we'd need to execute SET SESSION legacy_timestamp=FALSE.  Though this area is tricky and I don't fully understand it.", "author": "aalbu", "createdAt": "2020-08-03T11:48:36Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/iceberg/TestIcebergBasic.java", "diffHunk": "@@ -30,30 +29,177 @@\n public class TestIcebergBasic\n         extends ProductTest\n {\n+    // TODO: Spark SQL doesn't yet support decimal.  When it does add it to the test.\n+    // TODO: Spark SQL only stores TIMESTAMP WITH TIME ZONE, and Iceberg only supports\n+    // TIMESTAMP with no time zone.  The Spark writes/Presto reads test can pass by\n+    // stripping off the UTC.  However, I haven't been able to get the\n+    // Presto writes/Spark reads test TIMESTAMPs to match.\n+\n     // see spark-defaults.conf\n     private static final String SPARK_CATALOG = \"iceberg_test\";\n     private static final String PRESTO_CATALOG = \"iceberg\";\n-    private static final String TABLE_NAME = \"test_iceberg_basic\";\n-    private static final String SPARK_TABLE_NAME = format(\"%s.default.%s\", SPARK_CATALOG, TABLE_NAME);\n-    private static final String PRESTO_TABLE_NAME = format(\"%s.default.%s\", PRESTO_CATALOG, TABLE_NAME);\n \n-    @BeforeTestWithContext\n-    @AfterTestWithContext\n-    public void dropTestTables()\n+    @Test(groups = {ICEBERG, PROFILE_SPECIFIC_TESTS})\n+    public void testPrestoReadingSparkData()\n+    {\n+        String baseTableName = \"test_presto_reading_primitive_types\";\n+        String sparkTableName = sparkTableName(baseTableName);\n+\n+        String sparkTableDefinition =\n+                \"CREATE TABLE %s (\" +\n+                        \"  _string STRING\" +\n+                        \", _bigint BIGINT\" +\n+                        \", _integer INTEGER\" +\n+                        \", _real REAL\" +\n+                        \", _double DOUBLE\" +\n+                        \", _boolean BOOLEAN\" +\n+                        \", _timestamp TIMESTAMP\" +\n+                        \", _date DATE\" +\n+                        \") USING ICEBERG\";\n+        onSpark().executeQuery(format(sparkTableDefinition, sparkTableName));\n+\n+        String values = \"VALUES (\" +\n+                \"'a_string'\" +\n+                \", 1000000000000000\" +\n+                \", 1000000000\" +\n+                \", 10000000.123\" +\n+                \", 100000000000.123\" +\n+                \", true\" +\n+                \", TIMESTAMP '2020-06-28 14:16:00.456'\" +\n+                \", DATE '1950-06-28'\" +\n+                \")\";\n+        String insert = format(\"INSERT INTO %s %s\", sparkTableName, values);\n+        onSpark().executeQuery(insert);\n+\n+        Row row = row(\n+                \"a_string\",\n+                1000000000000000L,\n+                1000000000,\n+                10000000.123F,\n+                100000000000.123,\n+                true,\n+                \"2020-06-28 14:16:00.456\",\n+                \"1950-06-28\");\n+\n+        String startOfSelect = \"SELECT _string, _bigint, _integer, _real, _double, _boolean\";\n+        QueryResult sparkSelect = onSpark().executeQuery(format(\"%s, CAST(_timestamp AS STRING), CAST(_date AS STRING) FROM %s\", startOfSelect, sparkTableName));\n+        assertThat(sparkSelect).containsOnly(row);\n+\n+        QueryResult prestoSelect = onPresto().executeQuery(format(\"%s, REPLACE(CAST(_timestamp AS VARCHAR), ' UTC'), CAST(_date AS VARCHAR) FROM %s\", startOfSelect, prestoTableName(baseTableName)));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU5NTEzNQ==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464595135", "bodyText": "Yes, @electrum and I spent a few minutes this morning trying to understand the best course.  @electrum is going to think about it and get back to me.", "author": "djsstarburst", "createdAt": "2020-08-03T18:41:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM2MzE2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTc1MDc5OQ==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r471750799", "bodyText": "@electrum, I just rebased on tip master, and re-ran the tests, and the fact Iceberg doesn't yet support TIMESTAMP WITH TIME ZONE and Spark only supports TIMESTAMP WITH TIME ZONE is still a problem, causing testSparkReadingPrestoData() to fail if the timestamp-related fields are uncommented in that test.", "author": "djsstarburst", "createdAt": "2020-08-17T20:15:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDM2MzE2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUwNDU5MA==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464504590", "bodyText": "If we use java.sql types in the expected value, we could drop the casts to STRING.", "author": "aalbu", "createdAt": "2020-08-03T15:55:11Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/iceberg/TestIcebergBasic.java", "diffHunk": "@@ -30,30 +29,177 @@\n public class TestIcebergBasic\n         extends ProductTest\n {\n+    // TODO: Spark SQL doesn't yet support decimal.  When it does add it to the test.\n+    // TODO: Spark SQL only stores TIMESTAMP WITH TIME ZONE, and Iceberg only supports\n+    // TIMESTAMP with no time zone.  The Spark writes/Presto reads test can pass by\n+    // stripping off the UTC.  However, I haven't been able to get the\n+    // Presto writes/Spark reads test TIMESTAMPs to match.\n+\n     // see spark-defaults.conf\n     private static final String SPARK_CATALOG = \"iceberg_test\";\n     private static final String PRESTO_CATALOG = \"iceberg\";\n-    private static final String TABLE_NAME = \"test_iceberg_basic\";\n-    private static final String SPARK_TABLE_NAME = format(\"%s.default.%s\", SPARK_CATALOG, TABLE_NAME);\n-    private static final String PRESTO_TABLE_NAME = format(\"%s.default.%s\", PRESTO_CATALOG, TABLE_NAME);\n \n-    @BeforeTestWithContext\n-    @AfterTestWithContext\n-    public void dropTestTables()\n+    @Test(groups = {ICEBERG, PROFILE_SPECIFIC_TESTS})\n+    public void testPrestoReadingSparkData()\n+    {\n+        String baseTableName = \"test_presto_reading_primitive_types\";\n+        String sparkTableName = sparkTableName(baseTableName);\n+\n+        String sparkTableDefinition =\n+                \"CREATE TABLE %s (\" +\n+                        \"  _string STRING\" +\n+                        \", _bigint BIGINT\" +\n+                        \", _integer INTEGER\" +\n+                        \", _real REAL\" +\n+                        \", _double DOUBLE\" +\n+                        \", _boolean BOOLEAN\" +\n+                        \", _timestamp TIMESTAMP\" +\n+                        \", _date DATE\" +\n+                        \") USING ICEBERG\";\n+        onSpark().executeQuery(format(sparkTableDefinition, sparkTableName));\n+\n+        String values = \"VALUES (\" +\n+                \"'a_string'\" +\n+                \", 1000000000000000\" +\n+                \", 1000000000\" +\n+                \", 10000000.123\" +\n+                \", 100000000000.123\" +\n+                \", true\" +\n+                \", TIMESTAMP '2020-06-28 14:16:00.456'\" +\n+                \", DATE '1950-06-28'\" +\n+                \")\";\n+        String insert = format(\"INSERT INTO %s %s\", sparkTableName, values);\n+        onSpark().executeQuery(insert);\n+\n+        Row row = row(\n+                \"a_string\",\n+                1000000000000000L,\n+                1000000000,\n+                10000000.123F,\n+                100000000000.123,\n+                true,\n+                \"2020-06-28 14:16:00.456\",\n+                \"1950-06-28\");\n+\n+        String startOfSelect = \"SELECT _string, _bigint, _integer, _real, _double, _boolean\";\n+        QueryResult sparkSelect = onSpark().executeQuery(format(\"%s, CAST(_timestamp AS STRING), CAST(_date AS STRING) FROM %s\", startOfSelect, sparkTableName));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU5NjU1OA==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464596558", "bodyText": "That's what I tried the first time but it didn't work.  Sadly, the value types returned by Spark are Hive value class instances, and the ones returned by Presto are Presto value class instances.  The agree for primitive types like Long and Double, but not for TIMESTAMP, TIME and DATE.", "author": "djsstarburst", "createdAt": "2020-08-03T18:44:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUwNDU5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUxMDI0OQ==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464510249", "bodyText": "We could use java.sql types:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"2020-06-28 14:16:00.456\",\n          \n          \n            \n                            \"1950-06-28\");\n          \n          \n            \n                            Timestamp.valueOf(\"2020-06-28 14:16:00.456\"),\n          \n          \n            \n                            Date.valueOf(\"1950-06-28\"));", "author": "aalbu", "createdAt": "2020-08-03T16:04:47Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/iceberg/TestIcebergBasic.java", "diffHunk": "@@ -30,30 +29,177 @@\n public class TestIcebergBasic\n         extends ProductTest\n {\n+    // TODO: Spark SQL doesn't yet support decimal.  When it does add it to the test.\n+    // TODO: Spark SQL only stores TIMESTAMP WITH TIME ZONE, and Iceberg only supports\n+    // TIMESTAMP with no time zone.  The Spark writes/Presto reads test can pass by\n+    // stripping off the UTC.  However, I haven't been able to get the\n+    // Presto writes/Spark reads test TIMESTAMPs to match.\n+\n     // see spark-defaults.conf\n     private static final String SPARK_CATALOG = \"iceberg_test\";\n     private static final String PRESTO_CATALOG = \"iceberg\";\n-    private static final String TABLE_NAME = \"test_iceberg_basic\";\n-    private static final String SPARK_TABLE_NAME = format(\"%s.default.%s\", SPARK_CATALOG, TABLE_NAME);\n-    private static final String PRESTO_TABLE_NAME = format(\"%s.default.%s\", PRESTO_CATALOG, TABLE_NAME);\n \n-    @BeforeTestWithContext\n-    @AfterTestWithContext\n-    public void dropTestTables()\n+    @Test(groups = {ICEBERG, PROFILE_SPECIFIC_TESTS})\n+    public void testPrestoReadingSparkData()\n+    {\n+        String baseTableName = \"test_presto_reading_primitive_types\";\n+        String sparkTableName = sparkTableName(baseTableName);\n+\n+        String sparkTableDefinition =\n+                \"CREATE TABLE %s (\" +\n+                        \"  _string STRING\" +\n+                        \", _bigint BIGINT\" +\n+                        \", _integer INTEGER\" +\n+                        \", _real REAL\" +\n+                        \", _double DOUBLE\" +\n+                        \", _boolean BOOLEAN\" +\n+                        \", _timestamp TIMESTAMP\" +\n+                        \", _date DATE\" +\n+                        \") USING ICEBERG\";\n+        onSpark().executeQuery(format(sparkTableDefinition, sparkTableName));\n+\n+        String values = \"VALUES (\" +\n+                \"'a_string'\" +\n+                \", 1000000000000000\" +\n+                \", 1000000000\" +\n+                \", 10000000.123\" +\n+                \", 100000000000.123\" +\n+                \", true\" +\n+                \", TIMESTAMP '2020-06-28 14:16:00.456'\" +\n+                \", DATE '1950-06-28'\" +\n+                \")\";\n+        String insert = format(\"INSERT INTO %s %s\", sparkTableName, values);\n+        onSpark().executeQuery(insert);\n+\n+        Row row = row(\n+                \"a_string\",\n+                1000000000000000L,\n+                1000000000,\n+                10000000.123F,\n+                100000000000.123,\n+                true,\n+                \"2020-06-28 14:16:00.456\",\n+                \"1950-06-28\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU5Njc2OA==", "url": "https://github.com/trinodb/trino/pull/4671#discussion_r464596768", "bodyText": "I wish it were true :)", "author": "djsstarburst", "createdAt": "2020-08-03T18:44:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUxMDI0OQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "8ec089f0ba6c5428d29b9429d947f32f3ccba78a", "url": "https://github.com/trinodb/trino/commit/8ec089f0ba6c5428d29b9429d947f32f3ccba78a", "message": "Demonstrate Spark/Iceberg and Presto/Iceberg compatibility\n\nThis commit adds a number of tests to ensure that Iceberg data\nwritten by Spark/SQL can be read by the Presto Iceberg connector,\nand vice versa.  Everything worked correctly except DECIMAL, which\nisn't yet supported in the Iceberg connector, and TIMESTAMP, because\nIceberg doesn't yet support TIMESTAMP WITH TIME ZONE and Spark\nonly supports TIMESTAMP WITH TIME ZONE.", "committedDate": "2020-08-17T20:10:53Z", "type": "commit"}, {"oid": "8ec089f0ba6c5428d29b9429d947f32f3ccba78a", "url": "https://github.com/trinodb/trino/commit/8ec089f0ba6c5428d29b9429d947f32f3ccba78a", "message": "Demonstrate Spark/Iceberg and Presto/Iceberg compatibility\n\nThis commit adds a number of tests to ensure that Iceberg data\nwritten by Spark/SQL can be read by the Presto Iceberg connector,\nand vice versa.  Everything worked correctly except DECIMAL, which\nisn't yet supported in the Iceberg connector, and TIMESTAMP, because\nIceberg doesn't yet support TIMESTAMP WITH TIME ZONE and Spark\nonly supports TIMESTAMP WITH TIME ZONE.", "committedDate": "2020-08-17T20:10:53Z", "type": "forcePushed"}]}