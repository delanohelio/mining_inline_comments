{"pr_number": 2538, "pr_title": "Procedure for dropping statistics", "pr_createdAt": "2020-01-17T12:21:01Z", "pr_url": "https://github.com/trinodb/trino/pull/2538", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzkxMTExNQ==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367911115", "bodyText": "redundant empty line", "author": "findepi", "createdAt": "2020-01-17T12:25:25Z", "path": "presto-docs/src/main/sphinx/connector/hive.rst", "diffHunk": "@@ -630,6 +630,18 @@ specify a subset of columns to be analyzed via the optional ``columns`` property\n This query collects statistics for columns ``col_1`` and ``col_2`` for the partition\n with keys ``p2_value1, p2_value2``.\n \n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzkxMTMzNg==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367911336", "bodyText": "that's not true, remove", "author": "findepi", "createdAt": "2020-01-17T12:26:03Z", "path": "presto-docs/src/main/sphinx/connector/hive.rst", "diffHunk": "@@ -630,6 +630,18 @@ specify a subset of columns to be analyzed via the optional ``columns`` property\n This query collects statistics for columns ``col_1`` and ``col_2`` for the partition\n with keys ``p2_value1, p2_value2``.\n \n+\n+Note that if statistics were previously collected for all columns, they need to be dropped\n+before re-analyzing just a subset::\n+\n+    CALL system.drop_stats(schema_name, table_name, ARRAY[ARRAY['p2_value1', 'p2_value2']])\n+\n+Statistics collection is supported for Hive Metastore and Amazon Glue.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzkxMTQ0Mg==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367911442", "bodyText": "Does not exist; remove", "author": "findepi", "createdAt": "2020-01-17T12:26:23Z", "path": "presto-docs/src/main/sphinx/connector/hive.rst", "diffHunk": "@@ -630,6 +630,18 @@ specify a subset of columns to be analyzed via the optional ``columns`` property\n This query collects statistics for columns ``col_1`` and ``col_2`` for the partition\n with keys ``p2_value1, p2_value2``.\n \n+\n+Note that if statistics were previously collected for all columns, they need to be dropped\n+before re-analyzing just a subset::\n+\n+    CALL system.drop_stats(schema_name, table_name, ARRAY[ARRAY['p2_value1', 'p2_value2']])\n+\n+Statistics collection is supported for Hive Metastore and Amazon Glue.\n+\n+Amazon Glue Support\n+-------------------\n+Configuring and using Presto with AWS Glue is described in the :doc:`/aws/glue` documentation section.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzk0MDQ4NQ==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367940485", "bodyText": "The partitions argument should be named partition_values. My bad.", "author": "aalbu", "createdAt": "2020-01-17T13:43:00Z", "path": "presto-docs/src/main/sphinx/connector/hive.rst", "diffHunk": "@@ -722,6 +734,13 @@ Procedures\n     * ``DROP``: drop any partitions that exist in the metastore, but not on the file system.\n     * ``FULL``: perform both ``ADD`` and ``DROP``.\n \n+* ``system.drop_stats(schema_name, table_name, partitions)``", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzkyMzQxNw==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367923417", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                .collect(ImmutableList.toImmutableList());\n          \n          \n            \n                                .collect(toImmutableList());", "author": "ebyhr", "createdAt": "2020-01-17T13:00:07Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/DropStatsProcedure.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.HiveMetastore;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.procedure.Procedure;\n+import io.prestosql.spi.procedure.Procedure.Argument;\n+import io.prestosql.spi.type.ArrayType;\n+\n+import javax.inject.Inject;\n+import javax.inject.Provider;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.spi.StandardErrorCode.INVALID_PROCEDURE_ARGUMENT;\n+import static io.prestosql.spi.block.MethodHandleUtil.methodHandle;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.utils.FileUtils.makePartName;\n+\n+/**\n+ * A procedure that drops statistics.  It can be invoked for a subset of partitions (e.g.\n+ * {@code CALL system.drop_stats('system', 'some_table', ARRAY[ARRAY['x', '7']])}) or\n+ * for the entire table ({@code CALL system.drop_stats('system', 'some_table', NULL)})).\n+ */\n+public class DropStatsProcedure\n+        implements Provider<Procedure>\n+{\n+    private static final MethodHandle DROP_STATS = methodHandle(\n+            DropStatsProcedure.class,\n+            \"dropStats\",\n+            ConnectorSession.class,\n+            String.class,\n+            String.class,\n+            List.class);\n+\n+    private final Supplier<TransactionalMetadata> hiveMetadataFactory;\n+    private final HiveMetastore metastore;\n+\n+    @Inject\n+    public DropStatsProcedure(Supplier<TransactionalMetadata> hiveMetadataFactory, HiveMetastore metastore)\n+    {\n+        this.hiveMetadataFactory = requireNonNull(hiveMetadataFactory, \"hiveMetadataFactory is null\");\n+        this.metastore = requireNonNull(metastore, \"metastore is null\");\n+    }\n+\n+    @Override\n+    public Procedure get()\n+    {\n+        return new Procedure(\n+                \"system\",\n+                \"drop_stats\",\n+                ImmutableList.of(\n+                        new Argument(\"schema_name\", VARCHAR),\n+                        new Argument(\"table_name\", VARCHAR),\n+                        new Argument(\"partition_values\", new ArrayType(new ArrayType(VARCHAR)))),\n+                DROP_STATS.bindTo(this));\n+    }\n+\n+    public void dropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            doDropStats(session, schema, table, partitionValues);\n+        }\n+    }\n+\n+    private void doDropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        TransactionalMetadata hiveMetadata = hiveMetadataFactory.get();\n+        HiveTableHandle handle = (HiveTableHandle) hiveMetadata.getTableHandle(session, new SchemaTableName(schema, table));\n+        Map<String, ColumnHandle> columns = hiveMetadata.getColumnHandles(session, handle);\n+        List<String> partitionColumns = columns.values().stream()\n+                .map(HiveColumnHandle.class::cast)\n+                .filter(HiveColumnHandle::isPartitionKey)\n+                .map(HiveColumnHandle::getName)\n+                .collect(toImmutableList());\n+\n+        if (partitionValues != null) {\n+            // drop stats for specified partitions\n+            List<List<String>> partitionStringValues = partitionValues.stream()\n+                    .map(DropStatsProcedure::validateParameterType)\n+                    .collect(ImmutableList.toImmutableList());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzkzMzUxNg==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367933516", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static List<String> validateParameterType(Object param)\n          \n          \n            \n                private static List<String> validateParameterType(Object parameter)", "author": "ebyhr", "createdAt": "2020-01-17T13:26:22Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/DropStatsProcedure.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.HiveMetastore;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.procedure.Procedure;\n+import io.prestosql.spi.procedure.Procedure.Argument;\n+import io.prestosql.spi.type.ArrayType;\n+\n+import javax.inject.Inject;\n+import javax.inject.Provider;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.spi.StandardErrorCode.INVALID_PROCEDURE_ARGUMENT;\n+import static io.prestosql.spi.block.MethodHandleUtil.methodHandle;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.utils.FileUtils.makePartName;\n+\n+/**\n+ * A procedure that drops statistics.  It can be invoked for a subset of partitions (e.g.\n+ * {@code CALL system.drop_stats('system', 'some_table', ARRAY[ARRAY['x', '7']])}) or\n+ * for the entire table ({@code CALL system.drop_stats('system', 'some_table', NULL)})).\n+ */\n+public class DropStatsProcedure\n+        implements Provider<Procedure>\n+{\n+    private static final MethodHandle DROP_STATS = methodHandle(\n+            DropStatsProcedure.class,\n+            \"dropStats\",\n+            ConnectorSession.class,\n+            String.class,\n+            String.class,\n+            List.class);\n+\n+    private final Supplier<TransactionalMetadata> hiveMetadataFactory;\n+    private final HiveMetastore metastore;\n+\n+    @Inject\n+    public DropStatsProcedure(Supplier<TransactionalMetadata> hiveMetadataFactory, HiveMetastore metastore)\n+    {\n+        this.hiveMetadataFactory = requireNonNull(hiveMetadataFactory, \"hiveMetadataFactory is null\");\n+        this.metastore = requireNonNull(metastore, \"metastore is null\");\n+    }\n+\n+    @Override\n+    public Procedure get()\n+    {\n+        return new Procedure(\n+                \"system\",\n+                \"drop_stats\",\n+                ImmutableList.of(\n+                        new Argument(\"schema_name\", VARCHAR),\n+                        new Argument(\"table_name\", VARCHAR),\n+                        new Argument(\"partition_values\", new ArrayType(new ArrayType(VARCHAR)))),\n+                DROP_STATS.bindTo(this));\n+    }\n+\n+    public void dropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            doDropStats(session, schema, table, partitionValues);\n+        }\n+    }\n+\n+    private void doDropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        TransactionalMetadata hiveMetadata = hiveMetadataFactory.get();\n+        HiveTableHandle handle = (HiveTableHandle) hiveMetadata.getTableHandle(session, new SchemaTableName(schema, table));\n+        Map<String, ColumnHandle> columns = hiveMetadata.getColumnHandles(session, handle);\n+        List<String> partitionColumns = columns.values().stream()\n+                .map(HiveColumnHandle.class::cast)\n+                .filter(HiveColumnHandle::isPartitionKey)\n+                .map(HiveColumnHandle::getName)\n+                .collect(toImmutableList());\n+\n+        if (partitionValues != null) {\n+            // drop stats for specified partitions\n+            List<List<String>> partitionStringValues = partitionValues.stream()\n+                    .map(DropStatsProcedure::validateParameterType)\n+                    .collect(ImmutableList.toImmutableList());\n+            validatePartitions(partitionStringValues, partitionColumns);\n+\n+            partitionStringValues.forEach(values -> metastore.updatePartitionStatistics(\n+                    new HiveIdentity(session.getIdentity()),\n+                    schema,\n+                    table,\n+                    makePartName(partitionColumns, values),\n+                    stats -> PartitionStatistics.empty()));\n+        }\n+        else {\n+            // no partition specified, so drop stats for the entire table\n+            if (partitionColumns.isEmpty()) {\n+                // for non-partitioned tables, just wipe table stats\n+                metastore.updateTableStatistics(\n+                        new HiveIdentity(session.getIdentity()),\n+                        schema,\n+                        table,\n+                        stats -> PartitionStatistics.empty());\n+            }\n+            else {\n+                // the table is partitioned; remove stats for every partition\n+                metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), handle.getSchemaName(), handle.getTableName())\n+                        .ifPresent(partitions -> partitions.forEach(partitionName -> metastore.updatePartitionStatistics(\n+                                new HiveIdentity(session.getIdentity()),\n+                                schema,\n+                                table,\n+                                partitionName,\n+                                stats -> PartitionStatistics.empty())));\n+            }\n+        }\n+\n+        hiveMetadata.commit();\n+    }\n+\n+    private static List<String> validateParameterType(Object param)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzkzOTM4Ng==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367939386", "bodyText": "inline?", "author": "ebyhr", "createdAt": "2020-01-17T13:40:26Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/DropStatsProcedure.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.HiveMetastore;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.procedure.Procedure;\n+import io.prestosql.spi.procedure.Procedure.Argument;\n+import io.prestosql.spi.type.ArrayType;\n+\n+import javax.inject.Inject;\n+import javax.inject.Provider;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.spi.StandardErrorCode.INVALID_PROCEDURE_ARGUMENT;\n+import static io.prestosql.spi.block.MethodHandleUtil.methodHandle;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.utils.FileUtils.makePartName;\n+\n+/**\n+ * A procedure that drops statistics.  It can be invoked for a subset of partitions (e.g.\n+ * {@code CALL system.drop_stats('system', 'some_table', ARRAY[ARRAY['x', '7']])}) or\n+ * for the entire table ({@code CALL system.drop_stats('system', 'some_table', NULL)})).\n+ */\n+public class DropStatsProcedure\n+        implements Provider<Procedure>\n+{\n+    private static final MethodHandle DROP_STATS = methodHandle(\n+            DropStatsProcedure.class,\n+            \"dropStats\",\n+            ConnectorSession.class,\n+            String.class,\n+            String.class,\n+            List.class);\n+\n+    private final Supplier<TransactionalMetadata> hiveMetadataFactory;\n+    private final HiveMetastore metastore;\n+\n+    @Inject\n+    public DropStatsProcedure(Supplier<TransactionalMetadata> hiveMetadataFactory, HiveMetastore metastore)\n+    {\n+        this.hiveMetadataFactory = requireNonNull(hiveMetadataFactory, \"hiveMetadataFactory is null\");\n+        this.metastore = requireNonNull(metastore, \"metastore is null\");\n+    }\n+\n+    @Override\n+    public Procedure get()\n+    {\n+        return new Procedure(\n+                \"system\",\n+                \"drop_stats\",\n+                ImmutableList.of(\n+                        new Argument(\"schema_name\", VARCHAR),\n+                        new Argument(\"table_name\", VARCHAR),\n+                        new Argument(\"partition_values\", new ArrayType(new ArrayType(VARCHAR)))),\n+                DROP_STATS.bindTo(this));\n+    }\n+\n+    public void dropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            doDropStats(session, schema, table, partitionValues);\n+        }\n+    }\n+\n+    private void doDropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        TransactionalMetadata hiveMetadata = hiveMetadataFactory.get();\n+        HiveTableHandle handle = (HiveTableHandle) hiveMetadata.getTableHandle(session, new SchemaTableName(schema, table));\n+        Map<String, ColumnHandle> columns = hiveMetadata.getColumnHandles(session, handle);\n+        List<String> partitionColumns = columns.values().stream()\n+                .map(HiveColumnHandle.class::cast)\n+                .filter(HiveColumnHandle::isPartitionKey)\n+                .map(HiveColumnHandle::getName)\n+                .collect(toImmutableList());\n+\n+        if (partitionValues != null) {\n+            // drop stats for specified partitions\n+            List<List<String>> partitionStringValues = partitionValues.stream()\n+                    .map(DropStatsProcedure::validateParameterType)\n+                    .collect(ImmutableList.toImmutableList());\n+            validatePartitions(partitionStringValues, partitionColumns);\n+\n+            partitionStringValues.forEach(values -> metastore.updatePartitionStatistics(\n+                    new HiveIdentity(session.getIdentity()),\n+                    schema,\n+                    table,\n+                    makePartName(partitionColumns, values),\n+                    stats -> PartitionStatistics.empty()));\n+        }\n+        else {\n+            // no partition specified, so drop stats for the entire table\n+            if (partitionColumns.isEmpty()) {\n+                // for non-partitioned tables, just wipe table stats\n+                metastore.updateTableStatistics(\n+                        new HiveIdentity(session.getIdentity()),\n+                        schema,\n+                        table,\n+                        stats -> PartitionStatistics.empty());\n+            }\n+            else {\n+                // the table is partitioned; remove stats for every partition\n+                metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), handle.getSchemaName(), handle.getTableName())\n+                        .ifPresent(partitions -> partitions.forEach(partitionName -> metastore.updatePartitionStatistics(\n+                                new HiveIdentity(session.getIdentity()),\n+                                schema,\n+                                table,\n+                                partitionName,\n+                                stats -> PartitionStatistics.empty())));\n+            }\n+        }\n+\n+        hiveMetadata.commit();\n+    }\n+\n+    private static List<String> validateParameterType(Object param)\n+    {\n+        if (param == null) {\n+            throw new PrestoException(INVALID_PROCEDURE_ARGUMENT, \"Null partition value\");\n+        }\n+        if (param instanceof List) {\n+            List<?> list = (List<?>) param;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzk0MTc0OA==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367941748", "bodyText": "typo: \"don't not\"", "author": "ebyhr", "createdAt": "2020-01-17T13:45:46Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/DropStatsProcedure.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.HiveMetastore;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.procedure.Procedure;\n+import io.prestosql.spi.procedure.Procedure.Argument;\n+import io.prestosql.spi.type.ArrayType;\n+\n+import javax.inject.Inject;\n+import javax.inject.Provider;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.spi.StandardErrorCode.INVALID_PROCEDURE_ARGUMENT;\n+import static io.prestosql.spi.block.MethodHandleUtil.methodHandle;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.utils.FileUtils.makePartName;\n+\n+/**\n+ * A procedure that drops statistics.  It can be invoked for a subset of partitions (e.g.\n+ * {@code CALL system.drop_stats('system', 'some_table', ARRAY[ARRAY['x', '7']])}) or\n+ * for the entire table ({@code CALL system.drop_stats('system', 'some_table', NULL)})).\n+ */\n+public class DropStatsProcedure\n+        implements Provider<Procedure>\n+{\n+    private static final MethodHandle DROP_STATS = methodHandle(\n+            DropStatsProcedure.class,\n+            \"dropStats\",\n+            ConnectorSession.class,\n+            String.class,\n+            String.class,\n+            List.class);\n+\n+    private final Supplier<TransactionalMetadata> hiveMetadataFactory;\n+    private final HiveMetastore metastore;\n+\n+    @Inject\n+    public DropStatsProcedure(Supplier<TransactionalMetadata> hiveMetadataFactory, HiveMetastore metastore)\n+    {\n+        this.hiveMetadataFactory = requireNonNull(hiveMetadataFactory, \"hiveMetadataFactory is null\");\n+        this.metastore = requireNonNull(metastore, \"metastore is null\");\n+    }\n+\n+    @Override\n+    public Procedure get()\n+    {\n+        return new Procedure(\n+                \"system\",\n+                \"drop_stats\",\n+                ImmutableList.of(\n+                        new Argument(\"schema_name\", VARCHAR),\n+                        new Argument(\"table_name\", VARCHAR),\n+                        new Argument(\"partition_values\", new ArrayType(new ArrayType(VARCHAR)))),\n+                DROP_STATS.bindTo(this));\n+    }\n+\n+    public void dropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            doDropStats(session, schema, table, partitionValues);\n+        }\n+    }\n+\n+    private void doDropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        TransactionalMetadata hiveMetadata = hiveMetadataFactory.get();\n+        HiveTableHandle handle = (HiveTableHandle) hiveMetadata.getTableHandle(session, new SchemaTableName(schema, table));\n+        Map<String, ColumnHandle> columns = hiveMetadata.getColumnHandles(session, handle);\n+        List<String> partitionColumns = columns.values().stream()\n+                .map(HiveColumnHandle.class::cast)\n+                .filter(HiveColumnHandle::isPartitionKey)\n+                .map(HiveColumnHandle::getName)\n+                .collect(toImmutableList());\n+\n+        if (partitionValues != null) {\n+            // drop stats for specified partitions\n+            List<List<String>> partitionStringValues = partitionValues.stream()\n+                    .map(DropStatsProcedure::validateParameterType)\n+                    .collect(ImmutableList.toImmutableList());\n+            validatePartitions(partitionStringValues, partitionColumns);\n+\n+            partitionStringValues.forEach(values -> metastore.updatePartitionStatistics(\n+                    new HiveIdentity(session.getIdentity()),\n+                    schema,\n+                    table,\n+                    makePartName(partitionColumns, values),\n+                    stats -> PartitionStatistics.empty()));\n+        }\n+        else {\n+            // no partition specified, so drop stats for the entire table\n+            if (partitionColumns.isEmpty()) {\n+                // for non-partitioned tables, just wipe table stats\n+                metastore.updateTableStatistics(\n+                        new HiveIdentity(session.getIdentity()),\n+                        schema,\n+                        table,\n+                        stats -> PartitionStatistics.empty());\n+            }\n+            else {\n+                // the table is partitioned; remove stats for every partition\n+                metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), handle.getSchemaName(), handle.getTableName())\n+                        .ifPresent(partitions -> partitions.forEach(partitionName -> metastore.updatePartitionStatistics(\n+                                new HiveIdentity(session.getIdentity()),\n+                                schema,\n+                                table,\n+                                partitionName,\n+                                stats -> PartitionStatistics.empty())));\n+            }\n+        }\n+\n+        hiveMetadata.commit();\n+    }\n+\n+    private static List<String> validateParameterType(Object param)\n+    {\n+        if (param == null) {\n+            throw new PrestoException(INVALID_PROCEDURE_ARGUMENT, \"Null partition value\");\n+        }\n+        if (param instanceof List) {\n+            List<?> list = (List<?>) param;\n+            return list.stream().map(String.class::cast).collect(Collectors.toList());\n+        }\n+        throw new PrestoException(INVALID_PROCEDURE_ARGUMENT, \"Partition value must be an array\");\n+    }\n+\n+    private static void validatePartitions(List<List<String>> partitionValues, List<String> partitionColumns)\n+    {\n+        if (partitionValues.isEmpty()) {\n+            throw new PrestoException(INVALID_PROCEDURE_ARGUMENT, \"No partitions provided\");\n+        }\n+        if (partitionColumns.isEmpty()) {\n+            throw new PrestoException(INVALID_PROCEDURE_ARGUMENT, \"Cannot specify partition values for an unpartitioned table\");\n+        }\n+        partitionValues.forEach(value -> {\n+            if (value.size() != partitionColumns.size()) {\n+                throw new PrestoException(\n+                        INVALID_PROCEDURE_ARGUMENT,\n+                        format(\"Partition values %s don't not match the number of partition columns (%s)\", value, partitionColumns.size()));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzk0MzczOA==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367943738", "bodyText": "nit: We can use + oeprator in this situation. (No need to fix)\nassertUpdate(\"DROP TABLE \" + partitionedTableName);", "author": "ebyhr", "createdAt": "2020-01-17T13:50:16Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4575,6 +4575,314 @@ public void testAnalyzeUnpartitionedTableWithColumnSubset()\n         assertUpdate(format(\"DROP TABLE %s\", tableName));\n     }\n \n+    @Test\n+    public void testDropStatsPartitionedTable()\n+    {\n+        String tableName = \"test_drop_stats_partitioned_table\";\n+        createPartitionedTableForAnalyzeTest(tableName);\n+\n+        // Run analyze on the entire table\n+        assertUpdate(\"ANALYZE \" + tableName, 16);\n+\n+        // All partitions except empty partitions have column stats\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p1' AND p_bigint = 7)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_bigint', null, 2.0, 0.5, null, '0', '1'), \" +\n+                        \"('c_double', null, 2.0, 0.5, null, '1.2', '2.2'), \" +\n+                        \"('c_timestamp', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varchar', 8.0, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varbinary', 4.0, null, 0.5, null, null, null), \" +\n+                        \"('p_varchar', 8.0, 1.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 1.0, 0.0, null, '7', '7'), \" +\n+                        \"(null, null, null, null, 4.0, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p2' AND p_bigint = 7)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_bigint', null, 2.0, 0.5, null, '1', '2'), \" +\n+                        \"('c_double', null, 2.0, 0.5, null, '2.3', '3.3'), \" +\n+                        \"('c_timestamp', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varchar', 8.0, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varbinary', 4.0, null, 0.5, null, null, null), \" +\n+                        \"('p_varchar', 8.0, 1.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 1.0, 0.0, null, '7', '7'), \" +\n+                        \"(null, null, null, null, 4.0, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar IS NULL AND p_bigint IS NULL)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 1.0, 0.0, null, null, null), \" +\n+                        \"('c_bigint', null, 4.0, 0.0, null, '4', '7'), \" +\n+                        \"('c_double', null, 4.0, 0.0, null, '4.7', '7.7'), \" +\n+                        \"('c_timestamp', null, 4.0, 0.0, null, null, null), \" +\n+                        \"('c_varchar', 16.0, 4.0, 0.0, null, null, null), \" +\n+                        \"('c_varbinary', 8.0, null, 0.0, null, null, null), \" +\n+                        \"('p_varchar', 0.0, 0.0, 1.0, null, null, null), \" +\n+                        \"('p_bigint', null, 0.0, 1.0, null, null, null), \" +\n+                        \"(null, null, null, null, 4.0, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p3' AND p_bigint = 8)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_bigint', null, 2.0, 0.5, null, '2', '3'), \" +\n+                        \"('c_double', null, 2.0, 0.5, null, '3.4', '4.4'), \" +\n+                        \"('c_timestamp', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varchar', 8.0, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varbinary', 4.0, null, 0.5, null, null, null), \" +\n+                        \"('p_varchar', 8.0, 1.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 1.0, 0.0, null, '8', '8'), \" +\n+                        \"(null, null, null, null, 4.0, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'e1' AND p_bigint = 9)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_double', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_timestamp', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varbinary', 0.0, null, 0.0, null, null, null), \" +\n+                        \"('p_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"(null, null, null, null, 0.0, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'e2' AND p_bigint = 9)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_double', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_timestamp', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varbinary', 0.0, null, 0.0, null, null, null), \" +\n+                        \"('p_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"(null, null, null, null, 0.0, null, null)\");\n+\n+        // Drop stats for 2 partitions\n+        assertUpdate(format(\"CALL system.drop_stats('%s', '%s', ARRAY[ARRAY['p2', '7'], ARRAY['p3', '8']])\", TPCH_SCHEMA, tableName));\n+\n+        // Only stats for the specified partitions should be removed\n+        // no change\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p1' AND p_bigint = 7)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_bigint', null, 2.0, 0.5, null, '0', '1'), \" +\n+                        \"('c_double', null, 2.0, 0.5, null, '1.2', '2.2'), \" +\n+                        \"('c_timestamp', null, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varchar', 8.0, 2.0, 0.5, null, null, null), \" +\n+                        \"('c_varbinary', 4.0, null, 0.5, null, null, null), \" +\n+                        \"('p_varchar', 8.0, 1.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 1.0, 0.0, null, '7', '7'), \" +\n+                        \"(null, null, null, null, 4.0, null, null)\");\n+        // [p2, 7] had stats dropped\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p2' AND p_bigint = 7)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        // no change\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar IS NULL AND p_bigint IS NULL)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 1.0, 0.0, null, null, null), \" +\n+                        \"('c_bigint', null, 4.0, 0.0, null, '4', '7'), \" +\n+                        \"('c_double', null, 4.0, 0.0, null, '4.7', '7.7'), \" +\n+                        \"('c_timestamp', null, 4.0, 0.0, null, null, null), \" +\n+                        \"('c_varchar', 16.0, 4.0, 0.0, null, null, null), \" +\n+                        \"('c_varbinary', 8.0, null, 0.0, null, null, null), \" +\n+                        \"('p_varchar', 0.0, 0.0, 1.0, null, null, null), \" +\n+                        \"('p_bigint', null, 0.0, 1.0, null, null, null), \" +\n+                        \"(null, null, null, null, 4.0, null, null)\");\n+        // [p3, 8] had stats dropped\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p3' AND p_bigint = 8)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'e1' AND p_bigint = 9)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_double', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_timestamp', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varbinary', 0.0, null, 0.0, null, null, null), \" +\n+                        \"('p_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"(null, null, null, null, 0.0, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'e2' AND p_bigint = 9)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_double', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_timestamp', null, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('c_varbinary', 0.0, null, 0.0, null, null, null), \" +\n+                        \"('p_varchar', 0.0, 0.0, 0.0, null, null, null), \" +\n+                        \"('p_bigint', null, 0.0, 0.0, null, null, null), \" +\n+                        \"(null, null, null, null, 0.0, null, null)\");\n+\n+        // Drop stats for the entire table (partition_values = NULL)\n+        assertUpdate(format(\"CALL system.drop_stats('%s', '%s', NULL)\", TPCH_SCHEMA, tableName));\n+\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p1' AND p_bigint = 7)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p2' AND p_bigint = 7)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar IS NULL AND p_bigint IS NULL)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'p3' AND p_bigint = 8)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'e1' AND p_bigint = 9)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+        assertQuery(format(\"SHOW STATS FOR (SELECT * FROM %s WHERE p_varchar = 'e2' AND p_bigint = 9)\", tableName),\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+\n+        // All table stats are gone\n+        assertQuery(\n+                \"SHOW STATS FOR \" + tableName,\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+\n+        assertUpdate(format(\"DROP TABLE %s\", tableName));\n+    }\n+\n+    @Test\n+    public void testDropStatsUnpartitionedTable()\n+    {\n+        String tableName = \"test_drop_all_stats_unpartitioned_table\";\n+        createUnpartitionedTableForAnalyzeTest(tableName);\n+\n+        // Run analyze on the whole table\n+        assertUpdate(\"ANALYZE \" + tableName, 16);\n+\n+        assertQuery(\"SHOW STATS FOR \" + tableName,\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, 2.0, 0.375, null, null, null), \" +\n+                        \"('c_bigint', null, 8.0, 0.375, null, '0', '7'), \" +\n+                        \"('c_double', null, 10.0, 0.375, null, '1.2', '7.7'), \" +\n+                        \"('c_timestamp', null, 10.0, 0.375, null, null, null), \" +\n+                        \"('c_varchar', 40.0, 10.0, 0.375, null, null, null), \" +\n+                        \"('c_varbinary', 20.0, null, 0.375, null, null, null), \" +\n+                        \"('p_varchar', 24.0, 3.0, 0.25, null, null, null), \" +\n+                        \"('p_bigint', null, 2.0, 0.25, null, '7', '8'), \" +\n+                        \"(null, null, null, null, 16.0, null, null)\");\n+\n+        // Drop stats for the entire table (partition_values = NULL)\n+        assertUpdate(format(\"CALL system.drop_stats('%s', '%s', NULL)\", TPCH_SCHEMA, tableName));\n+\n+        // All table stats are gone\n+        assertQuery(\n+                \"SHOW STATS FOR \" + tableName,\n+                \"SELECT * FROM VALUES \" +\n+                        \"('c_boolean', null, null, null, null, null, null), \" +\n+                        \"('c_bigint', null, null, null, null, null, null), \" +\n+                        \"('c_double', null, null, null, null, null, null), \" +\n+                        \"('c_timestamp', null, null, null, null, null, null), \" +\n+                        \"('c_varchar', null, null, null, null, null, null), \" +\n+                        \"('c_varbinary', null, null, null, null, null, null), \" +\n+                        \"('p_varchar', null, null, null, null, null, null), \" +\n+                        \"('p_bigint', null, null, null, null, null, null), \" +\n+                        \"(null, null, null, null, null, null, null)\");\n+\n+        assertUpdate(format(\"DROP TABLE %s\", tableName));\n+    }\n+\n+    @Test\n+    public void testInvalidDropStats()\n+    {\n+        String unpartitionedTableName = \"test_invalid_drop_all_stats_unpartitioned_table\";\n+        createUnpartitionedTableForAnalyzeTest(unpartitionedTableName);\n+        String partitionedTableName = \"test_invalid_drop_all_stats_partitioned_table\";\n+        createPartitionedTableForAnalyzeTest(partitionedTableName);\n+\n+        assertQueryFails(\n+                format(\"CALL system.drop_stats('%s', '%s', ARRAY[ARRAY['p2', '7']])\", TPCH_SCHEMA, unpartitionedTableName),\n+                \"Cannot specify partition values for an unpartitioned table\");\n+        assertQueryFails(\n+                format(\"CALL system.drop_stats('%s', '%s', ARRAY[ARRAY['p2', '7'], NULL])\", TPCH_SCHEMA, partitionedTableName),\n+                \"Null partition value\");\n+        assertQueryFails(\n+                format(\"CALL system.drop_stats('%s', '%s', ARRAY[])\", TPCH_SCHEMA, partitionedTableName),\n+                \"No partitions provided\");\n+        assertQueryFails(\n+                format(\"CALL system.drop_stats('%s', '%s', ARRAY[ARRAY['p2', '7', 'dummy']])\", TPCH_SCHEMA, partitionedTableName),\n+                \".*don't not match the number of partition columns.*\");\n+        assertQueryFails(\n+                format(\"CALL system.drop_stats('%s', '%s', ARRAY[ARRAY['WRONG', 'KEY']])\", TPCH_SCHEMA, partitionedTableName),\n+                \"Partition '.*' not found\");\n+\n+        assertUpdate(format(\"DROP TABLE %s\", unpartitionedTableName));\n+        assertUpdate(format(\"DROP TABLE %s\", partitionedTableName));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzk0MzkwMw==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367943903", "bodyText": "nit: We can suppress NPE warning by\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), handle.getSchemaName(), handle.getTableName())\n          \n          \n            \n                            metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), schema, table)", "author": "ebyhr", "createdAt": "2020-01-17T13:50:34Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/DropStatsProcedure.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.HiveMetastore;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.procedure.Procedure;\n+import io.prestosql.spi.procedure.Procedure.Argument;\n+import io.prestosql.spi.type.ArrayType;\n+\n+import javax.inject.Inject;\n+import javax.inject.Provider;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.spi.StandardErrorCode.INVALID_PROCEDURE_ARGUMENT;\n+import static io.prestosql.spi.block.MethodHandleUtil.methodHandle;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.utils.FileUtils.makePartName;\n+\n+/**\n+ * A procedure that drops statistics.  It can be invoked for a subset of partitions (e.g.\n+ * {@code CALL system.drop_stats('system', 'some_table', ARRAY[ARRAY['x', '7']])}) or\n+ * for the entire table ({@code CALL system.drop_stats('system', 'some_table', NULL)})).\n+ */\n+public class DropStatsProcedure\n+        implements Provider<Procedure>\n+{\n+    private static final MethodHandle DROP_STATS = methodHandle(\n+            DropStatsProcedure.class,\n+            \"dropStats\",\n+            ConnectorSession.class,\n+            String.class,\n+            String.class,\n+            List.class);\n+\n+    private final Supplier<TransactionalMetadata> hiveMetadataFactory;\n+    private final HiveMetastore metastore;\n+\n+    @Inject\n+    public DropStatsProcedure(Supplier<TransactionalMetadata> hiveMetadataFactory, HiveMetastore metastore)\n+    {\n+        this.hiveMetadataFactory = requireNonNull(hiveMetadataFactory, \"hiveMetadataFactory is null\");\n+        this.metastore = requireNonNull(metastore, \"metastore is null\");\n+    }\n+\n+    @Override\n+    public Procedure get()\n+    {\n+        return new Procedure(\n+                \"system\",\n+                \"drop_stats\",\n+                ImmutableList.of(\n+                        new Argument(\"schema_name\", VARCHAR),\n+                        new Argument(\"table_name\", VARCHAR),\n+                        new Argument(\"partition_values\", new ArrayType(new ArrayType(VARCHAR)))),\n+                DROP_STATS.bindTo(this));\n+    }\n+\n+    public void dropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            doDropStats(session, schema, table, partitionValues);\n+        }\n+    }\n+\n+    private void doDropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        TransactionalMetadata hiveMetadata = hiveMetadataFactory.get();\n+        HiveTableHandle handle = (HiveTableHandle) hiveMetadata.getTableHandle(session, new SchemaTableName(schema, table));\n+        Map<String, ColumnHandle> columns = hiveMetadata.getColumnHandles(session, handle);\n+        List<String> partitionColumns = columns.values().stream()\n+                .map(HiveColumnHandle.class::cast)\n+                .filter(HiveColumnHandle::isPartitionKey)\n+                .map(HiveColumnHandle::getName)\n+                .collect(toImmutableList());\n+\n+        if (partitionValues != null) {\n+            // drop stats for specified partitions\n+            List<List<String>> partitionStringValues = partitionValues.stream()\n+                    .map(DropStatsProcedure::validateParameterType)\n+                    .collect(ImmutableList.toImmutableList());\n+            validatePartitions(partitionStringValues, partitionColumns);\n+\n+            partitionStringValues.forEach(values -> metastore.updatePartitionStatistics(\n+                    new HiveIdentity(session.getIdentity()),\n+                    schema,\n+                    table,\n+                    makePartName(partitionColumns, values),\n+                    stats -> PartitionStatistics.empty()));\n+        }\n+        else {\n+            // no partition specified, so drop stats for the entire table\n+            if (partitionColumns.isEmpty()) {\n+                // for non-partitioned tables, just wipe table stats\n+                metastore.updateTableStatistics(\n+                        new HiveIdentity(session.getIdentity()),\n+                        schema,\n+                        table,\n+                        stats -> PartitionStatistics.empty());\n+            }\n+            else {\n+                // the table is partitioned; remove stats for every partition\n+                metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), handle.getSchemaName(), handle.getTableName())", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzk0OTU4Ng==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r367949586", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                CALL system.drop_stats((\n          \n          \n            \n                CALL system.drop_stats(", "author": "ebyhr", "createdAt": "2020-01-17T14:03:03Z", "path": "presto-docs/src/main/sphinx/connector/hive.rst", "diffHunk": "@@ -768,6 +787,13 @@ Add an empty partition to the ``page_views`` table::\n         partition_columns => ARRAY['ds', 'country'],\n         partition_values => ARRAY['2016-08-09', 'US']);\n \n+Drop stats for a partition of the ``page_views`` table::\n+\n+    CALL system.drop_stats((", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExNjk5NQ==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r368116995", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        return ((List<?>) param).stream().map(String.class::cast).collect(Collectors.toList());\n          \n          \n            \n                        return ((List<?>) param).stream()\n          \n          \n            \n                            .map(String.class::cast)\n          \n          \n            \n                            .collect(toImmutableList());", "author": "findepi", "createdAt": "2020-01-17T20:12:44Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/DropStatsProcedure.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.HiveMetastore;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.classloader.ThreadContextClassLoader;\n+import io.prestosql.spi.connector.ColumnHandle;\n+import io.prestosql.spi.connector.ConnectorSession;\n+import io.prestosql.spi.connector.SchemaTableName;\n+import io.prestosql.spi.procedure.Procedure;\n+import io.prestosql.spi.procedure.Procedure.Argument;\n+import io.prestosql.spi.type.ArrayType;\n+\n+import javax.inject.Inject;\n+import javax.inject.Provider;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.spi.StandardErrorCode.INVALID_PROCEDURE_ARGUMENT;\n+import static io.prestosql.spi.block.MethodHandleUtil.methodHandle;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.utils.FileUtils.makePartName;\n+\n+/**\n+ * A procedure that drops statistics.  It can be invoked for a subset of partitions (e.g.\n+ * {@code CALL system.drop_stats('system', 'some_table', ARRAY[ARRAY['x', '7']])}) or\n+ * for the entire table ({@code CALL system.drop_stats('system', 'some_table', NULL)})).\n+ */\n+public class DropStatsProcedure\n+        implements Provider<Procedure>\n+{\n+    private static final MethodHandle DROP_STATS = methodHandle(\n+            DropStatsProcedure.class,\n+            \"dropStats\",\n+            ConnectorSession.class,\n+            String.class,\n+            String.class,\n+            List.class);\n+\n+    private final Supplier<TransactionalMetadata> hiveMetadataFactory;\n+    private final HiveMetastore metastore;\n+\n+    @Inject\n+    public DropStatsProcedure(Supplier<TransactionalMetadata> hiveMetadataFactory, HiveMetastore metastore)\n+    {\n+        this.hiveMetadataFactory = requireNonNull(hiveMetadataFactory, \"hiveMetadataFactory is null\");\n+        this.metastore = requireNonNull(metastore, \"metastore is null\");\n+    }\n+\n+    @Override\n+    public Procedure get()\n+    {\n+        return new Procedure(\n+                \"system\",\n+                \"drop_stats\",\n+                ImmutableList.of(\n+                        new Argument(\"schema_name\", VARCHAR),\n+                        new Argument(\"table_name\", VARCHAR),\n+                        new Argument(\"partition_values\", new ArrayType(new ArrayType(VARCHAR)))),\n+                DROP_STATS.bindTo(this));\n+    }\n+\n+    public void dropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        try (ThreadContextClassLoader ignored = new ThreadContextClassLoader(getClass().getClassLoader())) {\n+            doDropStats(session, schema, table, partitionValues);\n+        }\n+    }\n+\n+    private void doDropStats(ConnectorSession session, String schema, String table, List<?> partitionValues)\n+    {\n+        TransactionalMetadata hiveMetadata = hiveMetadataFactory.get();\n+        HiveTableHandle handle = (HiveTableHandle) hiveMetadata.getTableHandle(session, new SchemaTableName(schema, table));\n+        Map<String, ColumnHandle> columns = hiveMetadata.getColumnHandles(session, handle);\n+        List<String> partitionColumns = columns.values().stream()\n+                .map(HiveColumnHandle.class::cast)\n+                .filter(HiveColumnHandle::isPartitionKey)\n+                .map(HiveColumnHandle::getName)\n+                .collect(toImmutableList());\n+\n+        if (partitionValues != null) {\n+            // drop stats for specified partitions\n+            List<List<String>> partitionStringValues = partitionValues.stream()\n+                    .map(DropStatsProcedure::validateParameterType)\n+                    .collect(toImmutableList());\n+            validatePartitions(partitionStringValues, partitionColumns);\n+\n+            partitionStringValues.forEach(values -> metastore.updatePartitionStatistics(\n+                    new HiveIdentity(session.getIdentity()),\n+                    schema,\n+                    table,\n+                    makePartName(partitionColumns, values),\n+                    stats -> PartitionStatistics.empty()));\n+        }\n+        else {\n+            // no partition specified, so drop stats for the entire table\n+            if (partitionColumns.isEmpty()) {\n+                // for non-partitioned tables, just wipe table stats\n+                metastore.updateTableStatistics(\n+                        new HiveIdentity(session.getIdentity()),\n+                        schema,\n+                        table,\n+                        stats -> PartitionStatistics.empty());\n+            }\n+            else {\n+                // the table is partitioned; remove stats for every partition\n+                metastore.getPartitionNames(new HiveIdentity(session.getIdentity()), handle.getSchemaName(), handle.getTableName())\n+                        .ifPresent(partitions -> partitions.forEach(partitionName -> metastore.updatePartitionStatistics(\n+                                new HiveIdentity(session.getIdentity()),\n+                                schema,\n+                                table,\n+                                partitionName,\n+                                stats -> PartitionStatistics.empty())));\n+            }\n+        }\n+\n+        hiveMetadata.commit();\n+    }\n+\n+    private static List<String> validateParameterType(Object param)\n+    {\n+        if (param == null) {\n+            throw new PrestoException(INVALID_PROCEDURE_ARGUMENT, \"Null partition value\");\n+        }\n+\n+        if (param instanceof List) {\n+            return ((List<?>) param).stream().map(String.class::cast).collect(Collectors.toList());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQ1MzM1OQ==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r368453359", "bodyText": "Done", "author": "wendigo", "createdAt": "2020-01-20T09:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExNjk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExNzM0NA==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r368117344", "bodyText": "Unrelated change, please extract to separate commit (within this PR), eg Improve formatting", "author": "findepi", "createdAt": "2020-01-17T20:13:48Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -3972,7 +3972,7 @@ public void testCollectColumnStatisticsOnCreateTable()\n                         \"('p_varchar', 0E0, 0E0, 0E0, null, null, null), \" +\n                         \"(null, null, null, null, 0E0, null, null)\");\n \n-        assertUpdate(format(\"DROP TABLE %s\", tableName));\n+        assertUpdate(\"DROP TABLE \" + tableName);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODQ1MzExNw==", "url": "https://github.com/trinodb/trino/pull/2538#discussion_r368453117", "bodyText": "Done", "author": "wendigo", "createdAt": "2020-01-20T09:48:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExNzM0NA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "827a604f1e0a3cd722b42e2ad9c6485f6fb4fd32", "url": "https://github.com/trinodb/trino/commit/827a604f1e0a3cd722b42e2ad9c6485f6fb4fd32", "message": "Procedure for dropping statistics", "committedDate": "2020-01-20T09:47:39Z", "type": "commit"}, {"oid": "951df7ee5f5bdee9a7c9cd95d99f84592f279693", "url": "https://github.com/trinodb/trino/commit/951df7ee5f5bdee9a7c9cd95d99f84592f279693", "message": "Improve formatting", "committedDate": "2020-01-20T09:47:56Z", "type": "commit"}, {"oid": "951df7ee5f5bdee9a7c9cd95d99f84592f279693", "url": "https://github.com/trinodb/trino/commit/951df7ee5f5bdee9a7c9cd95d99f84592f279693", "message": "Improve formatting", "committedDate": "2020-01-20T09:47:56Z", "type": "forcePushed"}]}