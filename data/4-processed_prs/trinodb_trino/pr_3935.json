{"pr_number": 3935, "pr_title": "Use hive column indices for parquet tuple domain creation when specified", "pr_createdAt": "2020-06-05T19:07:58Z", "pr_url": "https://github.com/trinodb/trino/pull/3935", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNzE1OQ==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436137159", "bodyText": "Why useParquetColumnNames=true in by-index flow?", "author": "findepi", "createdAt": "2020-06-05T19:59:06Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -342,4 +352,30 @@ public static ReaderPageSourceWithProjections createPageSource(\n         }\n         return null;\n     }\n+\n+    private static Map<List<String>, RichColumnDescriptor> getDescriptorsUsingIndex(List<HiveColumnHandle> hiveColumnHandles, MessageType fileSchema)\n+    {\n+        Map<List<String>, RichColumnDescriptor> descriptorsByName = new HashMap<>();\n+        Optional<ReaderProjections> readerProjections = projectBaseColumns(hiveColumnHandles);\n+        List<HiveColumnHandle> baseColumns = readerProjections.map(ReaderProjections::getReaderColumns).orElse(hiveColumnHandles);\n+\n+        List<Optional<org.apache.parquet.schema.Type>> parquetFields = baseColumns.stream()\n+                .map(column -> getParquetType(column, fileSchema, true))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE2NDE2Ng==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436164166", "bodyText": "Eek, that's a bug. Thanks.", "author": "alexjo2144", "createdAt": "2020-06-05T21:05:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNzE1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzNzk3Ng==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436137976", "bodyText": "descriptorsByName -> descriptorsByColumnName\nmove this line just before the for loop where it's being populated\nand use ImmutableList.builder", "author": "findepi", "createdAt": "2020-06-05T20:00:57Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -342,4 +352,30 @@ public static ReaderPageSourceWithProjections createPageSource(\n         }\n         return null;\n     }\n+\n+    private static Map<List<String>, RichColumnDescriptor> getDescriptorsUsingIndex(List<HiveColumnHandle> hiveColumnHandles, MessageType fileSchema)\n+    {\n+        Map<List<String>, RichColumnDescriptor> descriptorsByName = new HashMap<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzOTgwMw==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436139803", "bodyText": "new String[] {parquetField.getName()}\n\nthis seems to be correct for top-level fields; is it also correct for nested?\nif a have a top level col but also nested r.col, will this get confused?", "author": "findepi", "createdAt": "2020-06-05T20:05:34Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -342,4 +352,30 @@ public static ReaderPageSourceWithProjections createPageSource(\n         }\n         return null;\n     }\n+\n+    private static Map<List<String>, RichColumnDescriptor> getDescriptorsUsingIndex(List<HiveColumnHandle> hiveColumnHandles, MessageType fileSchema)\n+    {\n+        Map<List<String>, RichColumnDescriptor> descriptorsByName = new HashMap<>();\n+        Optional<ReaderProjections> readerProjections = projectBaseColumns(hiveColumnHandles);\n+        List<HiveColumnHandle> baseColumns = readerProjections.map(ReaderProjections::getReaderColumns).orElse(hiveColumnHandles);\n+\n+        List<Optional<org.apache.parquet.schema.Type>> parquetFields = baseColumns.stream()\n+                .map(column -> getParquetType(column, fileSchema, true))\n+                .map(Optional::ofNullable)\n+                .collect(toImmutableList());\n+\n+        for (int columnIndex = 0; columnIndex < baseColumns.size(); columnIndex++) {\n+            HiveColumnHandle column = baseColumns.get(columnIndex);\n+            if (column.getHiveType().getCategory() != PRIMITIVE) {\n+                continue;\n+            }\n+\n+            parquetFields.get(columnIndex).ifPresent(parquetField -> {\n+                descriptorsByName.put(\n+                        ImmutableList.of(fileSchema.getFields().get(column.getBaseHiveColumnIndex()).getName()),\n+                        new RichColumnDescriptor(fileSchema.getColumnDescription(new String[] {parquetField.getName()}), parquetField.asPrimitiveType()));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE2MTQ2Mg==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436161462", "bodyText": "It would be a problem, but non-base columns are filtered out of the effectivePredicate. We'll need to fix this if we want to add support for pushing down filters on nested columns.\nhttps://github.com/prestosql/presto/blob/master/presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java#L166", "author": "alexjo2144", "createdAt": "2020-06-05T20:58:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzOTgwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE2NDEzNQ==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436164135", "bodyText": "I think we will want to push down predicates on r.col.\nActually, if col is the only field being read, don't we do that already?\neven if we don't, if we have a schema:\nstruct r {\n  string col\n}\n\nstring col\n\nhere we could see r.col (primitive), we would find ColumnDescription appropriate for col, a wrong one.\n-- is that possible?", "author": "findepi", "createdAt": "2020-06-05T21:05:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzOTgwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3NDU1MQ==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436174551", "bodyText": "I don't think It's possible yet, because we're only looking up columns from this map that are in the predicate, and nested ones are removed.\nIf we have a query filtered just off of a nested column it is still filtered out right now.\nI can add a todo comment to remind us to address this when someone gets around to adding push down for nested columns, but I added an extra test with this case too.", "author": "alexjo2144", "createdAt": "2020-06-05T21:35:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEzOTgwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0MDY2NA==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436140664", "bodyText": "I think it would be more adequate to place the fix inside the getParquetTupleDomain. Did you try that?", "author": "findepi", "createdAt": "2020-06-05T20:07:40Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -200,7 +201,16 @@ public static ReaderPageSourceWithProjections createPageSource(\n             }\n \n             Map<List<String>, RichColumnDescriptor> descriptorsByPath = getDescriptors(fileSchema, requestedSchema);\n-            TupleDomain<ColumnDescriptor> parquetTupleDomain = getParquetTupleDomain(descriptorsByPath, effectivePredicate);\n+\n+            Map<List<String>, RichColumnDescriptor> descriptorForTupleDomain;\n+            if (useColumnNames) {\n+                descriptorForTupleDomain = descriptorsByPath;\n+            }\n+            else {\n+                descriptorForTupleDomain = getDescriptorsUsingIndex(columns, fileSchema);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3NDYzMg==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436174632", "bodyText": "Moved \ud83d\udc4d", "author": "alexjo2144", "createdAt": "2020-06-05T21:35:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0MDY2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0MTE4Mg==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436141182", "bodyText": "Well done!\nWhile at it, we could rename the test to make it a bit broader, and verify the behavior under parquet_use_column_names=true too.", "author": "findepi", "createdAt": "2020-06-05T20:09:03Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4292,6 +4292,58 @@ public void testSubfieldReordering()\n         }\n     }\n \n+    @Test\n+    public void testParquetByColumnIndex()\n+    {\n+        Session session = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"false\")\n+                .build();\n+\n+        String tableName = \"test_parquet_by_column_index\";\n+\n+        assertUpdate(session, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  a varchar, \" +\n+                        \"  b varchar) \" +\n+                        \"WITH (format='PARQUET')\",\n+                tableName));\n+        assertUpdate(session, \"INSERT INTO \" + tableName + \" VALUES ('a', 'b')\", 1);\n+\n+        assertQuery(\n+                session,\n+                \"SELECT a, b FROM \" + tableName,\n+                \"VALUES ('a', 'b')\");\n+        assertQuery(\n+                session,\n+                \"SELECT a FROM \" + tableName + \" WHERE b = 'b'\",\n+                \"VALUES ('a')\");\n+\n+        String tableLocation = (String) computeActual(\"SELECT DISTINCT regexp_replace(\\\"$path\\\", '/[^/]*$', '') FROM \" + tableName).getOnlyValue();\n+\n+        // Reverse the table so that the Hive column ordering does not match the Parquet column ordering\n+        String reversedTableName = \"test_parquet_by_column_index_reversed\";\n+        assertUpdate(session, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  b varchar, \" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET', external_location='%s')\",\n+                reversedTableName,\n+                tableLocation));\n+\n+        assertQuery(\n+                session,\n+                \"SELECT a, b FROM \" + reversedTableName,\n+                \"VALUES ('b', 'a')\");\n+        assertQuery(\n+                session,\n+                \"SELECT a FROM \" + reversedTableName + \" WHERE b = 'a'\",\n+                \"VALUES ('b')\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjgwNTAzMg==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r436805032", "bodyText": "Would this work?\nRichColumnDescriptor descriptor;\nif (useColumnNames) {\n    descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n}\nelse {\n    org.apache.parquet.schema.Type parquetField = fileSchema.getType(columnHandle.getBaseHiveColumnIndex());\n    if (!parquetField.isPrimitive()) {\n        // obvious mismatch\n        continue;\n    }\n    descriptor = descriptorsByPath.get(ImmutableList.of(parquetField.getName()));\n}", "author": "findepi", "createdAt": "2020-06-08T15:42:04Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -323,7 +334,7 @@ public static ReaderPageSourceWithProjections createPageSource(\n                 continue;\n             }\n \n-            RichColumnDescriptor descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n+            RichColumnDescriptor descriptor = columnDescriptors.get(ImmutableList.of(columnHandle.getName()));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU2MDU3OA==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r437560578", "bodyText": "That's much simpler, thanks.", "author": "alexjo2144", "createdAt": "2020-06-09T16:24:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjgwNTAzMg=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc0NDYzOQ==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r437744639", "bodyText": "unwrap ifs:\nif (parquetField == null) {\n  // Parquet file has fewer column than partition\n  continue;\n}\nif(!parquetField.isPrimitive()) {\n  ....", "author": "findepi", "createdAt": "2020-06-09T21:55:23Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -319,11 +324,27 @@ public static ReaderPageSourceWithProjections createPageSource(\n         for (Entry<HiveColumnHandle, Domain> entry : effectivePredicate.getDomains().get().entrySet()) {\n             HiveColumnHandle columnHandle = entry.getKey();\n             // skip looking up predicates for complex types as Parquet only stores stats for primitives\n-            if (columnHandle.getHiveType().getCategory() != PRIMITIVE) {\n+            if (columnHandle.getHiveType().getCategory() != PRIMITIVE || columnHandle.getColumnType() != REGULAR) {\n                 continue;\n             }\n \n-            RichColumnDescriptor descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n+            RichColumnDescriptor descriptor;\n+            if (useColumnNames) {\n+                descriptor = descriptorsByPath.get(ImmutableList.of(columnHandle.getName()));\n+            }\n+            else {\n+                org.apache.parquet.schema.Type parquetField = getParquetType(columnHandle, fileSchema, false);\n+                if (parquetField != null) {\n+                    if(!parquetField.isPrimitive()) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI1NjU4OQ==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r438256589", "bodyText": "Cleaned up, thanks.", "author": "alexjo2144", "createdAt": "2020-06-10T16:28:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc0NDYzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc0NDcyMA==", "url": "https://github.com/trinodb/trino/pull/3935#discussion_r437744720", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n      \n    \n    \n  \n\nnit", "author": "findepi", "createdAt": "2020-06-09T21:55:34Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4294,6 +4294,148 @@ public void testSubfieldReordering()\n         }\n     }\n \n+    @Test\n+    public void testParquetColumnNameMappings()\n+    {\n+        Session sessionUsingColumnIndex = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"false\")\n+                .build();\n+        Session sessionUsingColumnName = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"true\")\n+                .build();\n+\n+        String tableName = \"test_parquet_by_column_index\";\n+\n+        assertUpdate(sessionUsingColumnIndex, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  a varchar, \" +\n+                        \"  b varchar) \" +\n+                        \"WITH (format='PARQUET')\",\n+                tableName));\n+        assertUpdate(sessionUsingColumnIndex, \"INSERT INTO \" + tableName + \" VALUES ('a', 'b')\", 1);\n+\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a, b FROM \" + tableName,\n+                \"VALUES ('a', 'b')\");\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a FROM \" + tableName + \" WHERE b = 'b'\",\n+                \"VALUES ('a')\");\n+\n+        String tableLocation = (String) computeActual(\"SELECT DISTINCT regexp_replace(\\\"$path\\\", '/[^/]*$', '') FROM \" + tableName).getOnlyValue();\n+\n+        // Reverse the table so that the Hive column ordering does not match the Parquet column ordering\n+        String reversedTableName = \"test_parquet_by_column_index_reversed\";\n+        assertUpdate(sessionUsingColumnIndex, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  b varchar, \" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET', external_location='%s')\",\n+                reversedTableName,\n+                tableLocation));\n+\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a, b FROM \" + reversedTableName,\n+                \"VALUES ('b', 'a')\");\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT a FROM \" + reversedTableName + \" WHERE b = 'a'\",\n+                \"VALUES ('b')\");\n+\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a, b FROM \" + reversedTableName,\n+                \"VALUES ('a', 'b')\");\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a FROM \" + reversedTableName + \" WHERE b = 'b'\",\n+                \"VALUES ('a')\");\n+\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + reversedTableName);\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + tableName);\n+    }\n+\n+    @Test\n+    public void testParquetWithMissingColumns()\n+    {\n+        Session sessionUsingColumnIndex = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"false\")\n+                .build();\n+        Session sessionUsingColumnName = Session.builder(getSession())\n+                .setCatalogSessionProperty(catalog, \"parquet_use_column_names\", \"true\")\n+                .build();\n+\n+        String singleColumnTableName = \"test_parquet_with_missing_columns_one\";\n+\n+        assertUpdate(format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET')\",\n+                singleColumnTableName));\n+        assertUpdate(sessionUsingColumnIndex, \"INSERT INTO \" + singleColumnTableName + \" VALUES ('a')\", 1);\n+\n+        String tableLocation = (String) computeActual(\"SELECT DISTINCT regexp_replace(\\\"$path\\\", '/[^/]*$', '') FROM \" + singleColumnTableName).getOnlyValue();\n+        String multiColumnTableName = \"test_parquet_missing_columns_two\";\n+        assertUpdate(sessionUsingColumnIndex, format(\n+                \"CREATE TABLE %s(\" +\n+                        \"  b varchar, \" +\n+                        \"  a varchar) \" +\n+                        \"WITH (format='PARQUET', external_location='%s')\",\n+                multiColumnTableName,\n+                tableLocation));\n+\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a FROM \" + multiColumnTableName + \" WHERE b IS NULL\",\n+                \"VALUES ('a')\");\n+        assertQuery(\n+                sessionUsingColumnName,\n+                \"SELECT a FROM \" + multiColumnTableName + \" WHERE a = 'a'\",\n+                \"VALUES ('a')\");\n+\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT b FROM \" + multiColumnTableName + \" WHERE b = 'a'\",\n+                \"VALUES ('a')\");\n+        assertQuery(\n+                sessionUsingColumnIndex,\n+                \"SELECT b FROM \" + multiColumnTableName + \" WHERE a IS NULL\",\n+                \"VALUES ('a')\");\n+\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + singleColumnTableName);\n+        assertUpdate(sessionUsingColumnIndex, \"DROP TABLE \" + multiColumnTableName);\n+\n+", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "d81ae6a28c6713187ba0b4e92875e8f614cbca78", "url": "https://github.com/trinodb/trino/commit/d81ae6a28c6713187ba0b4e92875e8f614cbca78", "message": "Use hive column indices for parquet tuple domain creation when specified\n\nFixes a bug in Parquet predicate pushdown when the column ordering\nof the Hive schema does not match the column ordering in the Parquet\nfile. The use of column indices vs column names was inconsistent.", "committedDate": "2020-06-15T14:15:22Z", "type": "commit"}, {"oid": "d81ae6a28c6713187ba0b4e92875e8f614cbca78", "url": "https://github.com/trinodb/trino/commit/d81ae6a28c6713187ba0b4e92875e8f614cbca78", "message": "Use hive column indices for parquet tuple domain creation when specified\n\nFixes a bug in Parquet predicate pushdown when the column ordering\nof the Hive schema does not match the column ordering in the Parquet\nfile. The use of column indices vs column names was inconsistent.", "committedDate": "2020-06-15T14:15:22Z", "type": "forcePushed"}]}