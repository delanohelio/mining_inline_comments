{"pr_number": 6012, "pr_title": "Validate Hive bucketing on read", "pr_createdAt": "2020-11-19T06:56:55Z", "pr_url": "https://github.com/trinodb/trino/pull/6012", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0NzE4Nw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531147187", "bodyText": "ImmutableList.copyOf", "author": "losipiuk", "createdAt": "2020-11-26T16:54:28Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveSplit.java", "diffHunk": "@@ -318,4 +328,40 @@ public int hashCode()\n             return Objects.hash(tableBucketCount, partitionBucketCount, bucketColumnNames);\n         }\n     }\n+\n+    public static class BucketValidation\n+    {\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final List<HiveColumnHandle> bucketColumns;\n+\n+        @JsonCreator\n+        public BucketValidation(\n+                @JsonProperty(\"bucketingVersion\") BucketingVersion bucketingVersion,\n+                @JsonProperty(\"bucketCount\") int bucketCount,\n+                @JsonProperty(\"bucketColumns\") List<HiveColumnHandle> bucketColumns)\n+        {\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.bucketColumns = requireNonNull(bucketColumns, \"bucketColumns is null\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0ODI3OQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531148279", "bodyText": "consider using dataProvider to increase tests isolation", "author": "losipiuk", "createdAt": "2020-11-26T16:56:51Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -1722,6 +1724,71 @@ private static void assertBucketTableEvolutionResult(MaterializedResult result,\n         assertEquals(idCount.keySet(), expectedIds);\n     }\n \n+    @Test\n+    public void testBucketedTableValidation()\n+            throws Exception\n+    {\n+        for (HiveStorageFormat storageFormat : createTableFormats) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE5OTgyMw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531199823", "bodyText": "This is a good idea, but I'll leave it like this to match the existing tests.", "author": "electrum", "createdAt": "2020-11-26T19:28:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0ODI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0OTg3Nw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531149877", "bodyText": "Add test validation that validation does not happen if it is disabled.", "author": "losipiuk", "createdAt": "2020-11-26T17:00:19Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -1722,6 +1724,71 @@ private static void assertBucketTableEvolutionResult(MaterializedResult result,\n         assertEquals(idCount.keySet(), expectedIds);\n     }\n \n+    @Test\n+    public void testBucketedTableValidation()\n+            throws Exception\n+    {\n+        for (HiveStorageFormat storageFormat : createTableFormats) {\n+            SchemaTableName table = temporaryTable(\"bucket_validation\");\n+            try {\n+                doTestBucketedTableValidation(storageFormat, table);\n+            }\n+            finally {\n+                dropTable(table);\n+            }\n+        }\n+    }\n+\n+    private void doTestBucketedTableValidation(HiveStorageFormat storageFormat, SchemaTableName tableName)\n+            throws Exception\n+    {\n+        createEmptyTable(\n+                tableName,\n+                storageFormat,\n+                ImmutableList.of(\n+                        new Column(\"id\", HIVE_LONG, Optional.empty()),\n+                        new Column(\"name\", HIVE_STRING, Optional.empty())),\n+                ImmutableList.of(),\n+                Optional.of(new HiveBucketProperty(ImmutableList.of(\"id\"), BUCKETING_V1, 8, ImmutableList.of())));\n+\n+        MaterializedResult.Builder dataBuilder = MaterializedResult.resultBuilder(SESSION, BIGINT, VARCHAR);\n+        for (long id = 0; id < 100; id++) {\n+            dataBuilder.row(id, String.valueOf(id));\n+        }\n+        insertData(tableName, dataBuilder.build());\n+\n+        try (Transaction transaction = newTransaction()) {\n+            Set<String> files = listAllDataFiles(transaction, tableName.getSchemaName(), tableName.getTableName());\n+\n+            Path bucket2 = files.stream()\n+                    .map(Path::new)\n+                    .filter(path -> path.getName().startsWith(\"000002_0_\"))\n+                    .collect(onlyElement());\n+\n+            Path bucket5 = files.stream()\n+                    .map(Path::new)\n+                    .filter(path -> path.getName().startsWith(\"000005_0_\"))\n+                    .collect(onlyElement());\n+\n+            HdfsContext context = new HdfsContext(newSession(), tableName.getSchemaName(), tableName.getTableName());\n+            FileSystem fileSystem = hdfsEnvironment.getFileSystem(context, bucket2);\n+            fileSystem.delete(bucket2, false);\n+            fileSystem.rename(bucket5, bucket2);\n+        }\n+\n+        try (Transaction transaction = newTransaction()) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTIwMTYxMQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531201611", "bodyText": "Done", "author": "electrum", "createdAt": "2020-11-26T19:35:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE0OTg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1MjEzMA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531152130", "bodyText": "when is that possible? Can you add a comment?", "author": "losipiuk", "createdAt": "2020-11-26T17:05:10Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSourceProvider.java", "diffHunk": "@@ -678,6 +691,36 @@ public int getBucketToKeep()\n         }\n     }\n \n+    private static Optional<BucketValidator> createBucketValidator(Path path, Optional<BucketValidation> bucketValidation, OptionalInt bucketNumber, List<ColumnMapping> columnMappings)\n+    {\n+        return bucketValidation.flatMap(validation -> {\n+            Map<Integer, ColumnMapping> baseHiveColumnToBlockIndex = columnMappings.stream()\n+                    .filter(mapping -> mapping.getHiveColumnHandle().isBaseColumn())\n+                    .collect(toImmutableMap(mapping -> mapping.getHiveColumnHandle().getBaseHiveColumnIndex(), identity()));\n+\n+            int[] bucketColumnIndices = new int[validation.getBucketColumns().size()];\n+\n+            List<TypeInfo> bucketColumnTypes = new ArrayList<>();\n+            for (int i = 0; i < validation.getBucketColumns().size(); i++) {\n+                HiveColumnHandle column = validation.getBucketColumns().get(i);\n+                ColumnMapping mapping = baseHiveColumnToBlockIndex.get(column.getBaseHiveColumnIndex());\n+                if (mapping == null) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE5ODYxOQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531198619", "bodyText": "This happens when we are not reading a bucket column (in which case we don't need to bother with validation since it can't affect the query results). I'll add a comment.", "author": "electrum", "createdAt": "2020-11-26T19:25:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1MjEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1NDE1Nw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531154157", "bodyText": "check length of bucketColumnIndices and length of bucketColumnTypes are the same", "author": "losipiuk", "createdAt": "2020-11-26T17:10:06Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +644,57 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTIwMjU5Nw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531202597", "bodyText": "Done", "author": "electrum", "createdAt": "2020-11-26T19:39:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1NDE1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1NjcyMA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531156720", "bodyText": "Do we need to handle LongTimestamp.class here? Maybe others?", "author": "losipiuk", "createdAt": "2020-11-26T17:15:46Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;\n+\n+    public HiveBucketValidationRecordCursor(\n+            Path path,\n+            int[] bucketColumnIndices,\n+            List<HiveType> bucketColumnTypes,\n+            BucketingVersion bucketingVersion,\n+            int bucketCount,\n+            int expectedBucket,\n+            TypeManager typeManager,\n+            RecordCursor delegate)\n+    {\n+        this.path = requireNonNull(path, \"path is null\");\n+        this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+        requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+        this.javaTypeList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeSignature)\n+                .map(typeManager::getType)\n+                .map(Type::getJavaType)\n+                .collect(toImmutableList());\n+        this.typeInfoList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeInfo)\n+                .collect(toImmutableList());\n+        this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+        this.bucketCount = bucketCount;\n+        this.expectedBucket = expectedBucket;\n+        this.delegate = requireNonNull(delegate, \"delegate is null\");\n+\n+        this.scratch = new Object[bucketColumnTypes.size()];\n+    }\n+\n+    @VisibleForTesting\n+    @Override\n+    public RecordCursor delegate()\n+    {\n+        return delegate;\n+    }\n+\n+    @Override\n+    public boolean advanceNextPosition()\n+    {\n+        if (!delegate.advanceNextPosition()) {\n+            return false;\n+        }\n+\n+        for (int i = 0; i < scratch.length; i++) {\n+            int index = bucketColumnIndices[i];\n+            if (delegate.isNull(index)) {\n+                scratch[i] = null;\n+                continue;\n+            }\n+            Class<?> javaType = javaTypeList.get(i);\n+            if (javaType == boolean.class) {\n+                scratch[i] = delegate.getBoolean(index);\n+            }\n+            else if (javaType == long.class) {\n+                scratch[i] = delegate.getLong(index);\n+            }\n+            else if (javaType == double.class) {\n+                scratch[i] = delegate.getDouble(index);\n+            }\n+            else if (javaType == Slice.class) {\n+                scratch[i] = delegate.getSlice(index);\n+            }\n+            else if (javaType == Block.class) {\n+                scratch[i] = delegate.getObject(index);\n+            }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE5ODE0MQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531198141", "bodyText": "No, timestamp is not supported for bucketing. All the allowed types are handled here. This code is very similar to the existing HiveBucketAdapterRecordCursor.", "author": "electrum", "createdAt": "2020-11-26T19:23:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE1NjcyMA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMDYyOQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531600629", "bodyText": "maybe add a comment what this is & what is for, as the name is not fully self-describing", "author": "findepi", "createdAt": "2020-11-27T13:25:25Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTc5OTI5Mw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531799293", "bodyText": "This is copied from HiveBucketAdapterRecordCursor. If you look at the only method in this class (other than the constructor), the usage seems obvious.", "author": "electrum", "createdAt": "2020-11-27T22:29:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMDYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMTY2NQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531601665", "bodyText": "nit: fmt each arg on separate line", "author": "findepi", "createdAt": "2020-11-27T13:27:28Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;\n+\n+    public HiveBucketValidationRecordCursor(\n+            Path path,\n+            int[] bucketColumnIndices,\n+            List<HiveType> bucketColumnTypes,\n+            BucketingVersion bucketingVersion,\n+            int bucketCount,\n+            int expectedBucket,\n+            TypeManager typeManager,\n+            RecordCursor delegate)\n+    {\n+        this.path = requireNonNull(path, \"path is null\");\n+        this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+        requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+        this.javaTypeList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeSignature)\n+                .map(typeManager::getType)\n+                .map(Type::getJavaType)\n+                .collect(toImmutableList());\n+        this.typeInfoList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeInfo)\n+                .collect(toImmutableList());\n+        this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+        this.bucketCount = bucketCount;\n+        this.expectedBucket = expectedBucket;\n+        this.delegate = requireNonNull(delegate, \"delegate is null\");\n+\n+        this.scratch = new Object[bucketColumnTypes.size()];\n+    }\n+\n+    @VisibleForTesting\n+    @Override\n+    public RecordCursor delegate()\n+    {\n+        return delegate;\n+    }\n+\n+    @Override\n+    public boolean advanceNextPosition()\n+    {\n+        if (!delegate.advanceNextPosition()) {\n+            return false;\n+        }\n+\n+        for (int i = 0; i < scratch.length; i++) {\n+            int index = bucketColumnIndices[i];\n+            if (delegate.isNull(index)) {\n+                scratch[i] = null;\n+                continue;\n+            }\n+            Class<?> javaType = javaTypeList.get(i);\n+            if (javaType == boolean.class) {\n+                scratch[i] = delegate.getBoolean(index);\n+            }\n+            else if (javaType == long.class) {\n+                scratch[i] = delegate.getLong(index);\n+            }\n+            else if (javaType == double.class) {\n+                scratch[i] = delegate.getDouble(index);\n+            }\n+            else if (javaType == Slice.class) {\n+                scratch[i] = delegate.getSlice(index);\n+            }\n+            else if (javaType == Block.class) {\n+                scratch[i] = delegate.getObject(index);\n+            }\n+            else {\n+                throw new VerifyException(\"Unknown Java type: \" + javaType);\n+            }\n+        }\n+\n+        int bucket = getHiveBucket(bucketingVersion, bucketCount, typeInfoList, scratch);\n+        if (bucket != expectedBucket) {\n+            throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                    \"Hive table is corrupt. File '%s' is for bucket %s, but contains a row for bucket %s.\", path, expectedBucket, bucket));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMjE0MQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531602141", "bodyText": "Should i be concerned about overhead of this?\nwould it be enough to do this very other row?\nor eg first 100 rows, and then every 10th row?", "author": "findepi", "createdAt": "2020-11-27T13:28:31Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveBucketValidationRecordCursor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.VerifyException;\n+import io.airlift.slice.Slice;\n+import io.prestosql.plugin.hive.util.ForwardingRecordCursor;\n+import io.prestosql.plugin.hive.util.HiveBucketing.BucketingVersion;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.connector.RecordCursor;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hive.serde2.typeinfo.TypeInfo;\n+\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static io.prestosql.plugin.hive.util.HiveBucketing.getHiveBucket;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveBucketValidationRecordCursor\n+        extends ForwardingRecordCursor\n+{\n+    private final RecordCursor delegate;\n+    private final Path path;\n+    private final int[] bucketColumnIndices;\n+    private final List<Class<?>> javaTypeList;\n+    private final List<TypeInfo> typeInfoList;\n+    private final BucketingVersion bucketingVersion;\n+    private final int bucketCount;\n+    private final int expectedBucket;\n+\n+    private final Object[] scratch;\n+\n+    public HiveBucketValidationRecordCursor(\n+            Path path,\n+            int[] bucketColumnIndices,\n+            List<HiveType> bucketColumnTypes,\n+            BucketingVersion bucketingVersion,\n+            int bucketCount,\n+            int expectedBucket,\n+            TypeManager typeManager,\n+            RecordCursor delegate)\n+    {\n+        this.path = requireNonNull(path, \"path is null\");\n+        this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+        requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+        this.javaTypeList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeSignature)\n+                .map(typeManager::getType)\n+                .map(Type::getJavaType)\n+                .collect(toImmutableList());\n+        this.typeInfoList = bucketColumnTypes.stream()\n+                .map(HiveType::getTypeInfo)\n+                .collect(toImmutableList());\n+        this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+        this.bucketCount = bucketCount;\n+        this.expectedBucket = expectedBucket;\n+        this.delegate = requireNonNull(delegate, \"delegate is null\");\n+\n+        this.scratch = new Object[bucketColumnTypes.size()];\n+    }\n+\n+    @VisibleForTesting\n+    @Override\n+    public RecordCursor delegate()\n+    {\n+        return delegate;\n+    }\n+\n+    @Override\n+    public boolean advanceNextPosition()\n+    {\n+        if (!delegate.advanceNextPosition()) {\n+            return false;\n+        }\n+\n+        for (int i = 0; i < scratch.length; i++) {\n+            int index = bucketColumnIndices[i];\n+            if (delegate.isNull(index)) {\n+                scratch[i] = null;\n+                continue;\n+            }\n+            Class<?> javaType = javaTypeList.get(i);\n+            if (javaType == boolean.class) {\n+                scratch[i] = delegate.getBoolean(index);\n+            }\n+            else if (javaType == long.class) {\n+                scratch[i] = delegate.getLong(index);\n+            }\n+            else if (javaType == double.class) {\n+                scratch[i] = delegate.getDouble(index);\n+            }\n+            else if (javaType == Slice.class) {\n+                scratch[i] = delegate.getSlice(index);\n+            }\n+            else if (javaType == Block.class) {\n+                scratch[i] = delegate.getObject(index);\n+            }\n+            else {\n+                throw new VerifyException(\"Unknown Java type: \" + javaType);\n+            }\n+        }\n+\n+        int bucket = getHiveBucket(bucketingVersion, bucketCount, typeInfoList, scratch);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMjk4OQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531602989", "bodyText": "nit: ftm", "author": "findepi", "createdAt": "2020-11-27T13:30:04Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +645,58 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");\n+            this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+            this.bucketColumnTypes = requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.expectedBucket = expectedBucket;\n+            checkArgument(bucketColumnIndices.length == bucketColumnTypes.size(), \"indices and types counts mismatch\");\n+        }\n+\n+        public void validate(Page page)\n+        {\n+            Page bucketColumnsPage = page.getColumns(bucketColumnIndices);\n+            for (int position = 0; position < page.getPositionCount(); position++) {\n+                int bucket = getHiveBucket(bucketingVersion, bucketCount, bucketColumnTypes, bucketColumnsPage, position);\n+                if (bucket != expectedBucket) {\n+                    throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                            \"Hive table is corrupt. File '%s' is for bucket %s, but contains a row for bucket %s.\", path, expectedBucket, bucket));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMzIwNQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531603205", "bodyText": "same here, i would expect this to be not necesarily for every row", "author": "findepi", "createdAt": "2020-11-27T13:30:25Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +645,58 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");\n+            this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+            this.bucketColumnTypes = requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.expectedBucket = expectedBucket;\n+            checkArgument(bucketColumnIndices.length == bucketColumnTypes.size(), \"indices and types counts mismatch\");\n+        }\n+\n+        public void validate(Page page)\n+        {\n+            Page bucketColumnsPage = page.getColumns(bucketColumnIndices);\n+            for (int position = 0; position < page.getPositionCount(); position++) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwMzY5Mw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531603693", "bodyText": "wrapRecordCursor or validatingRecordCursor", "author": "findepi", "createdAt": "2020-11-27T13:31:21Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSource.java", "diffHunk": "@@ -632,4 +645,58 @@ public Page filterPageToEligibleRowsOrDiscard(Page page)\n             return page.getPositions(ids.elements(), 0, retainedRowCount);\n         }\n     }\n+\n+    public static class BucketValidator\n+    {\n+        private final Path path;\n+        private final int[] bucketColumnIndices;\n+        private final List<TypeInfo> bucketColumnTypes;\n+        private final BucketingVersion bucketingVersion;\n+        private final int bucketCount;\n+        private final int expectedBucket;\n+\n+        public BucketValidator(\n+                Path path,\n+                int[] bucketColumnIndices,\n+                List<TypeInfo> bucketColumnTypes,\n+                BucketingVersion bucketingVersion,\n+                int bucketCount,\n+                int expectedBucket)\n+        {\n+            this.path = requireNonNull(path, \"path is null\");\n+            this.bucketColumnIndices = requireNonNull(bucketColumnIndices, \"bucketColumnIndices is null\");\n+            this.bucketColumnTypes = requireNonNull(bucketColumnTypes, \"bucketColumnTypes is null\");\n+            this.bucketingVersion = requireNonNull(bucketingVersion, \"bucketingVersion is null\");\n+            this.bucketCount = bucketCount;\n+            this.expectedBucket = expectedBucket;\n+            checkArgument(bucketColumnIndices.length == bucketColumnTypes.size(), \"indices and types counts mismatch\");\n+        }\n+\n+        public void validate(Page page)\n+        {\n+            Page bucketColumnsPage = page.getColumns(bucketColumnIndices);\n+            for (int position = 0; position < page.getPositionCount(); position++) {\n+                int bucket = getHiveBucket(bucketingVersion, bucketCount, bucketColumnTypes, bucketColumnsPage, position);\n+                if (bucket != expectedBucket) {\n+                    throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                            \"Hive table is corrupt. File '%s' is for bucket %s, but contains a row for bucket %s.\", path, expectedBucket, bucket));\n+                }\n+            }\n+        }\n+\n+        public RecordCursor toRecordCursor(RecordCursor delegate, TypeManager typeManager)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDI0MA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531604240", "bodyText": "Maybe add a comment why this is only when bucketAdaptation.isEmpty()\nalso, even in case of bucketAdaptation.isEmpty() we should be able to do some validation. How hard would it be? A followup issue?", "author": "findepi", "createdAt": "2020-11-27T13:32:26Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSourceProvider.java", "diffHunk": "@@ -323,6 +332,10 @@ public ConnectorPageSource createPageSource(\n                     delegate = new HiveCoercionRecordCursor(regularAndInterimColumnMappings, typeManager, delegate);\n                 }\n \n+                if (bucketAdaptation.isEmpty() && bucketValidator.isPresent()) {\n+                    delegate = bucketValidator.get().toRecordCursor(delegate, typeManager);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTc4ODUxNw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531788517", "bodyText": "It's not needed because the adapter already does the same validation.", "author": "electrum", "createdAt": "2020-11-27T21:22:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDI0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTc5MDUyNg==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531790526", "bodyText": "please add this as a code comment maybe", "author": "findepi", "createdAt": "2020-11-27T21:34:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDI0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTc5OTcyNQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531799725", "bodyText": "Done", "author": "electrum", "createdAt": "2020-11-27T22:33:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDkzMw==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531604933", "bodyText": "add something from your comment above:\n\nwe don't need to bother with validation since it can't affect the query results\n\nHowever, is it true actually?\nwhat about filters on $bucket?", "author": "findepi", "createdAt": "2020-11-27T13:33:51Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HivePageSourceProvider.java", "diffHunk": "@@ -678,6 +691,37 @@ public int getBucketToKeep()\n         }\n     }\n \n+    private static Optional<BucketValidator> createBucketValidator(Path path, Optional<BucketValidation> bucketValidation, OptionalInt bucketNumber, List<ColumnMapping> columnMappings)\n+    {\n+        return bucketValidation.flatMap(validation -> {\n+            Map<Integer, ColumnMapping> baseHiveColumnToBlockIndex = columnMappings.stream()\n+                    .filter(mapping -> mapping.getHiveColumnHandle().isBaseColumn())\n+                    .collect(toImmutableMap(mapping -> mapping.getHiveColumnHandle().getBaseHiveColumnIndex(), identity()));\n+\n+            int[] bucketColumnIndices = new int[validation.getBucketColumns().size()];\n+\n+            List<TypeInfo> bucketColumnTypes = new ArrayList<>();\n+            for (int i = 0; i < validation.getBucketColumns().size(); i++) {\n+                HiveColumnHandle column = validation.getBucketColumns().get(i);\n+                ColumnMapping mapping = baseHiveColumnToBlockIndex.get(column.getBaseHiveColumnIndex());\n+                if (mapping == null) {\n+                    // the bucket column is not read by the query", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTc5NDk0MQ==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531794941", "bodyText": "That's an interesting scenario, though technically the bucket filtering is working, as we will only return data in that bucket. If you are using the bucket filter to efficiently read part of the table in different queries, then it will return the correct result. Without reading the bucketing column(s), you can't actually tell that the data is in the wrong bucket. I can't think of such a scenario that would visibly return wrong results.", "author": "electrum", "createdAt": "2020-11-27T22:00:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDkzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjIyODY1OA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r532228658", "bodyText": "Please maybe capture this as a code comment then.", "author": "findepi", "createdAt": "2020-11-29T15:54:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDkzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjI3MzY1NA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r532273654", "bodyText": "Done", "author": "electrum", "createdAt": "2020-11-29T21:50:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNDkzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNzEwOA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531607108", "bodyText": "How does HiveBucketValidationRecordCursor play with HiveCoercionRecordCursor?\nare they applied in the right order? would be good to have a test\nsame applies to the case when reading with a page source", "author": "findepi", "createdAt": "2020-11-27T13:38:09Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/AbstractTestHive.java", "diffHunk": "@@ -4552,6 +4631,9 @@ protected static void assertPageSourceType(ConnectorPageSource pageSource, HiveS\n         if (pageSource instanceof RecordPageSource) {\n             RecordCursor hiveRecordCursor = ((RecordPageSource) pageSource).getCursor();\n             hiveRecordCursor = ((HiveRecordCursor) hiveRecordCursor).getRegularColumnRecordCursor();\n+            if (hiveRecordCursor instanceof HiveBucketValidationRecordCursor) {\n+                hiveRecordCursor = ((HiveBucketValidationRecordCursor) hiveRecordCursor).delegate();\n+            }", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTc5NzYzOA==", "url": "https://github.com/trinodb/trino/pull/6012#discussion_r531797638", "bodyText": "It shouldn't matter, since the code in HiveSplitManager already validates that the partition bucketing is compatible:\n\nsame = no coercion\ncompatible = adaptation (does validation itself)\nincompatible = query fails\n\nAny coercion would be for non-bucketing columns.", "author": "electrum", "createdAt": "2020-11-27T22:17:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTYwNzEwOA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "f27b4847feac9790220d7f5e7046df0aec18f275", "url": "https://github.com/trinodb/trino/commit/f27b4847feac9790220d7f5e7046df0aec18f275", "message": "Extract ForwardingRecordCursor", "committedDate": "2020-11-29T21:43:32Z", "type": "commit"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "8fdf2be613912592da4d067f158a14b4065b540c", "url": "https://github.com/trinodb/trino/commit/8fdf2be613912592da4d067f158a14b4065b540c", "message": "Validate Hive bucketing on read", "committedDate": "2020-11-29T21:49:59Z", "type": "commit"}, {"oid": "8fdf2be613912592da4d067f158a14b4065b540c", "url": "https://github.com/trinodb/trino/commit/8fdf2be613912592da4d067f158a14b4065b540c", "message": "Validate Hive bucketing on read", "committedDate": "2020-11-29T21:49:59Z", "type": "forcePushed"}]}