{"pr_number": 6415, "pr_title": "Handle Kafka Schema Registry unsupported formats", "pr_createdAt": "2020-12-21T21:33:11Z", "pr_url": "https://github.com/trinodb/trino/pull/6415", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzA4NzU3OA==", "url": "https://github.com/trinodb/trino/pull/6415#discussion_r547087578", "bodyText": "Once we move to latest schema registry can we handle them based on SchemaProvider#getSchemaType ? I will raising a PR to bind SchemaProvider and I guess we can inject it here also to validate here", "author": "Praveen2112", "createdAt": "2020-12-22T06:10:29Z", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/schema/confluent/ConfluentSchemaRegistryTableDescriptionSupplier.java", "diffHunk": "@@ -187,7 +190,11 @@ private String resolveSubject(String candidate)\n     private KafkaTopicFieldGroup getFieldGroup(AvroSchemaConverter avroSchemaConverter, String subject)\n     {\n         try {\n-            Schema schema = new Schema.Parser().parse(schemaRegistryClient.getLatestSchemaMetadata(subject).getSchema());\n+            SchemaMetadata schemaMetadata = schemaRegistryClient.getLatestSchemaMetadata(subject);\n+            if (schemaMetadata.getSchemaType() != \"AVRO\") {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMxNDcxMg==", "url": "https://github.com/trinodb/trino/pull/6415#discussion_r547314712", "bodyText": "We don't have to bind them separately, SchemaRegistryClient#getSchemaProviders would give a Map<String, SchemaParser>", "author": "Praveen2112", "createdAt": "2020-12-22T14:40:58Z", "path": "presto-kafka/src/main/java/io/prestosql/plugin/kafka/schema/confluent/ConfluentModule.java", "diffHunk": "@@ -64,6 +64,7 @@ protected void setup(Binder binder)\n         newSetBinder(binder, SchemaProvider.class).addBinding().to(AvroSchemaProvider.class).in(Scopes.SINGLETON);\n         newSetBinder(binder, SessionPropertiesProvider.class).addBinding().to(ConfluentSessionProperties.class).in(Scopes.SINGLETON);\n         binder.bind(TableDescriptionSupplier.class).toProvider(ConfluentSchemaRegistryTableDescriptionSupplier.Factory.class).in(Scopes.SINGLETON);\n+        newMapBinder(binder, String.class, SchemaParser.class).addBinding(\"AVRO\").to(AvroSchemaParser.class).in(Scopes.SINGLETON);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMxNzEyOA==", "url": "https://github.com/trinodb/trino/pull/6415#discussion_r547317128", "bodyText": "This method is defined in io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient#getSchemaProviders.\nAlso we need to still to parse the schema into an object that Presto Kafka Connector understands so it could create a Presto table etc.", "author": "kokosing", "createdAt": "2020-12-22T14:45:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzMxNDcxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM4NjgxMA==", "url": "https://github.com/trinodb/trino/pull/6415#discussion_r547386810", "bodyText": "Is there is any plugin that could fail if such libraries are added ?", "author": "Praveen2112", "createdAt": "2020-12-22T16:51:52Z", "path": "pom.xml", "diffHunk": "@@ -1113,6 +1113,27 @@\n                 </exclusions>\n             </dependency>\n \n+            <dependency>\n+                <!-- This is under Confluence Community License and it should not be used in compile scope -->", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ3MzQ2OQ==", "url": "https://github.com/trinodb/trino/pull/6415#discussion_r547473469", "bodyText": "I am not aware of this. I tried to find such, but with no lock. I will define test scope in master pom.xml, so it will force to explicit overwrite and so there is high chance that someone would read the comment.", "author": "kokosing", "createdAt": "2020-12-22T19:42:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM4NjgxMA=="}], "type": "inlineReview"}, {"oid": "353beda80e91733b42f6500e9b7a57d00d51cfc4", "url": "https://github.com/trinodb/trino/commit/353beda80e91733b42f6500e9b7a57d00d51cfc4", "message": "Cleanup in ConfluentSchemaRegistryTableDescriptionSupplier\n\nOrder fields, constructor parameters and initialization statements\nso they are in the same order.\nAlso cleanup requireNonNull usage.", "committedDate": "2020-12-22T19:44:15Z", "type": "commit"}, {"oid": "5d5464a230408fad2bb080a2b3f93a4d7f01903a", "url": "https://github.com/trinodb/trino/commit/5d5464a230408fad2bb080a2b3f93a4d7f01903a", "message": "Use Optional.isEmpty() instead of negated isPresent()", "committedDate": "2020-12-22T19:44:15Z", "type": "commit"}, {"oid": "01ae8c61025f74efd1aea6b7eb9a9885ab3e98c6", "url": "https://github.com/trinodb/trino/commit/01ae8c61025f74efd1aea6b7eb9a9885ab3e98c6", "message": "Extract SchemaParser in Kafka Schema Registry", "committedDate": "2020-12-22T19:44:15Z", "type": "commit"}, {"oid": "4a7c7bdc27d33bfe0e29e5c087506193e7ac4911", "url": "https://github.com/trinodb/trino/commit/4a7c7bdc27d33bfe0e29e5c087506193e7ac4911", "message": "Fail fast Kafka Schema Registry on unsupported format", "committedDate": "2020-12-22T19:44:15Z", "type": "commit"}, {"oid": "4a7c7bdc27d33bfe0e29e5c087506193e7ac4911", "url": "https://github.com/trinodb/trino/commit/4a7c7bdc27d33bfe0e29e5c087506193e7ac4911", "message": "Fail fast Kafka Schema Registry on unsupported format", "committedDate": "2020-12-22T19:44:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzgxNDc4Ng==", "url": "https://github.com/trinodb/trino/pull/6415#discussion_r547814786", "bodyText": "send -> sent", "author": "skrzypo987", "createdAt": "2020-12-23T08:44:27Z", "path": "presto-kafka/src/test/java/io/prestosql/plugin/kafka/schema/confluent/TestKafkaWithConfluentSchemaRegistryMinimalFunctionality.java", "diffHunk": "@@ -137,6 +148,35 @@ public void testUnsupportedInsert()\n         assertQueryFails(format(\"INSERT INTO \\\"%s\\\" VALUES (0, 0, '')\", topicName), \"Insert not supported\");\n     }\n \n+    @Test\n+    public void testUnsupportedFormat()\n+            throws Exception\n+    {\n+        String topicName = \"topic-unsupported-format\";\n+        testingKafkaWithSchemaRegistry.createTopic(topicName);\n+\n+        assertNotExists(topicName);\n+\n+        Future<RecordMetadata> lastSendFuture = Futures.immediateFuture(null);", "originalCommit": "4a7c7bdc27d33bfe0e29e5c087506193e7ac4911", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}