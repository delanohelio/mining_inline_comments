{"pr_number": 6072, "pr_title": "Rewrite GroupedTopNBuilder with flat data structures", "pr_createdAt": "2020-11-24T12:20:05Z", "pr_url": "https://github.com/trinodb/trino/pull/6072", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTk1Nw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533631957", "bodyText": "I suggest we make the rest of the fields package protected until we need them to be public.", "author": "dain", "createdAt": "2020-12-01T18:30:43Z", "path": "presto-array/src/main/java/io/prestosql/array/BigArrays.java", "diffHunk": "@@ -15,7 +15,7 @@\n \n // Note: this code was forked from fastutil (http://fastutil.di.unimi.it/)\n // Copyright (C) 2010-2013 Sebastiano Vigna\n-final class BigArrays\n+public final class BigArrays", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc4MjM3OA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533782378", "bodyText": "The main reason for making this public was to expose the SEGMENT SIZE, which opens the door to interesting data structure performance optimizations once you know what this size is. However, theoretically speaking we don't need it to be technically correct. It's just an optimization that we could do if the internals of this were known in this way. So I guess there is that point of discussion if we should even be making any of this public at all. But I can go ahead and limit scope for the other fields for sure.", "author": "erichwang", "createdAt": "2020-12-01T23:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzMTk1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzOTk4NQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533639985", "bodyText": "Maybe add a comment that the code style is close to the original, so diffs work better... OR maybe clean this up more", "author": "dain", "createdAt": "2020-12-01T18:43:55Z", "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomHashMap.java", "diffHunk": "@@ -0,0 +1,1617 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.util;\n+\n+import it.unimi.dsi.fastutil.Hash;\n+import it.unimi.dsi.fastutil.HashCommon;\n+import it.unimi.dsi.fastutil.longs.AbstractLong2LongMap;\n+import it.unimi.dsi.fastutil.longs.AbstractLongCollection;\n+import it.unimi.dsi.fastutil.longs.AbstractLongSet;\n+import it.unimi.dsi.fastutil.longs.Long2LongMap;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongCollection;\n+import it.unimi.dsi.fastutil.longs.LongIterator;\n+import it.unimi.dsi.fastutil.longs.LongSet;\n+import it.unimi.dsi.fastutil.objects.AbstractObjectSet;\n+import it.unimi.dsi.fastutil.objects.ObjectIterator;\n+\n+import java.util.Arrays;\n+import java.util.Map;\n+import java.util.NoSuchElementException;\n+import java.util.function.Consumer;\n+\n+import static it.unimi.dsi.fastutil.HashCommon.arraySize;\n+import static it.unimi.dsi.fastutil.HashCommon.maxFill;\n+import static java.util.Objects.requireNonNull;\n+\n+// Note: this code was forked from fastutil (http://fastutil.di.unimi.it/) Long2LongOpenCustomHashMap\n+// Copyright (C) 2002-2019 Sebastiano Vigna\n+public class LongLong2LongOpenCustomHashMap", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY2MjAyMQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533662021", "bodyText": "Maybe write a test with a really bad hash like return 42, so everything ends up clumped together.", "author": "dain", "createdAt": "2020-12-01T19:20:29Z", "path": "presto-main/src/test/java/io/prestosql/util/TestLongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.util;\n+\n+import it.unimi.dsi.fastutil.HashCommon;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestLongLong2LongOpenCustomBigHashMap\n+{\n+    private static final LongLong2LongOpenCustomBigHashMap.HashStrategy DEFAULT_STRATEGY = new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+    {\n+        @Override\n+        public long hashCode(long e1, long e2)\n+        {\n+            return HashCommon.mix(e1) * 31 + HashCommon.mix(e2);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY2MzkxMA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533663910", "bodyText": "Maybe add a second loop to verify \"replace\"", "author": "dain", "createdAt": "2020-12-01T19:23:43Z", "path": "presto-main/src/test/java/io/prestosql/util/TestLongLong2LongOpenCustomBigHashMap.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.util;\n+\n+import it.unimi.dsi.fastutil.HashCommon;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestLongLong2LongOpenCustomBigHashMap\n+{\n+    private static final LongLong2LongOpenCustomBigHashMap.HashStrategy DEFAULT_STRATEGY = new LongLong2LongOpenCustomBigHashMap.HashStrategy()\n+    {\n+        @Override\n+        public long hashCode(long e1, long e2)\n+        {\n+            return HashCommon.mix(e1) * 31 + HashCommon.mix(e2);\n+        }\n+\n+        @Override\n+        public boolean equals(long a1, long a2, long b1, long b2)\n+        {\n+            return a1 == b1 && a2 == b2;\n+        }\n+    };\n+\n+    @Test\n+    public void testBasicOps()\n+    {\n+        int expected = 100_000;\n+        LongLong2LongOpenCustomBigHashMap map = new LongLong2LongOpenCustomBigHashMap(expected, DEFAULT_STRATEGY);\n+        map.defaultReturnValue(-1);\n+\n+        assertTrue(map.isEmpty());\n+        assertEquals(map.size(), 0);\n+        assertEquals(map.get(0, 0), -1);\n+        assertEquals(map.get(1, -1), -1);\n+\n+        List<Long> values = Arrays.asList(Long.MIN_VALUE, -10L, 0L, 10L, Long.MAX_VALUE);\n+\n+        // Put\n+        int count = 0;\n+        for (long key1 : values) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NTIyOA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533675228", "bodyText": "Maybe remove these in the original fork commit", "author": "dain", "createdAt": "2020-12-01T19:43:14Z", "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomHashMap.java", "diffHunk": "@@ -563,68 +517,56 @@ public boolean containsValue(final long v)\n             return true;\n         }\n         for (int i = n; i-- != 0; ) {\n-            if (!((key[i]) == (0)) && ((value[i]) == (v))) {\n+            if (!((key[i * 2]) == (0) && (key[i * 2 + 1]) == (0)) && ((value[i]) == (v))) {\n                 return true;\n             }\n         }\n         return false;\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-\n-    public long getOrDefault(final long k, final long defaultValue)\n+    public long getOrDefault(final long k1, final long k2, final long defaultValue)\n     {\n-        if ((strategy.equals((k), (0)))) {\n+        if ((strategy.equals((k1), (k2), (0), (0)))) {\n             return containsNullKey ? value[n] : defaultValue;\n         }\n         final long[] key = this.key;\n         // The starting point.\n-        int pos = (it.unimi.dsi.fastutil.HashCommon.mix(strategy.hashCode(k))) & mask;\n-        long curr = key[pos];\n-        if (((curr) == (0))) {\n+        int pos = (it.unimi.dsi.fastutil.HashCommon.mix(strategy.hashCode(k1, k2))) & mask;\n+        long curr1 = key[pos * 2];\n+        long curr2 = key[pos * 2 + 1];\n+        if (((curr1) == (0)) && ((curr2) == (0))) {\n             return defaultValue;\n         }\n-        if ((strategy.equals((k), (curr)))) {\n+        if ((strategy.equals((k1), (k2), (curr1), (curr2)))) {\n             return value[pos];\n         }\n         // There's always an unused entry.\n         while (true) {\n             pos = (pos + 1) & mask;\n-            curr = key[pos];\n-            if (((curr) == (0))) {\n+            curr1 = key[pos * 2];\n+            curr2 = key[pos * 2 + 1];\n+            if (((curr1) == (0)) && ((curr2) == (0))) {\n                 return defaultValue;\n             }\n-            if ((strategy.equals((k), (curr)))) {\n+            if ((strategy.equals((k1), (k2), (curr1), (curr2)))) {\n                 return value[pos];\n             }\n         }\n     }\n \n-    /**\n-     * {@inheritDoc}\n-     */\n-    @Override\n-    public long putIfAbsent(final long k, final long v)\n+    public long putIfAbsent(final long k1, final long k2, final long v)\n     {\n-        final int pos = find(k);\n+        final int pos = find(k1, k2);\n         if (pos >= 0) {\n             return value[pos];\n         }\n-        insert(-pos - 1, k, v);\n+        insert(-pos - 1, k1, k2, v);\n         return defRetValue;\n     }\n \n-    /**\n-     * {@inheritDoc}", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc5NTUwNw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533795507", "bodyText": "@dain, are we sure we want to remove these in the original fork? The reason I have them removed here is because this is the actual commit that actually removes the interface and override (and thus the doc linkage).", "author": "erichwang", "createdAt": "2020-12-01T23:39:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NTIyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NzUzMg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533677532", "bodyText": "Maybe move the removal of all the unused stuff to another commit.", "author": "dain", "createdAt": "2020-12-01T19:47:16Z", "path": "presto-main/src/main/java/io/prestosql/util/LongLong2LongOpenCustomHashMap.java", "diffHunk": "@@ -822,619 +672,16 @@ public void clear()\n         Arrays.fill(key, (0));\n     }\n \n-    @Override\n     public int size()\n     {\n         return size;\n     }\n \n-    @Override\n     public boolean isEmpty()\n     {\n         return size == 0;\n     }\n \n-    /**", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxNTA5Mg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533815092", "bodyText": "How strongly do you feel about this? This sounds a bit on the annoying execution side of things without huge benefits to the commit history, but if I'll do it if you really prefer.", "author": "erichwang", "createdAt": "2020-12-02T00:33:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY3NzUzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4MjA1MA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533682050", "bodyText": "Remove Serializable from this, and drop transient below and make any fields final if possible", "author": "dain", "createdAt": "2020-12-01T19:55:16Z", "path": "presto-main/src/main/java/io/prestosql/util/Long2LongOpenBigHashMap.java", "diffHunk": "@@ -13,68 +13,71 @@\n  */\n package io.prestosql.util;\n \n+import io.prestosql.array.BigArrays;\n+import io.prestosql.array.LongBigArray;\n import it.unimi.dsi.fastutil.Hash;\n-import it.unimi.dsi.fastutil.HashCommon;\n import it.unimi.dsi.fastutil.longs.AbstractLong2LongMap;\n import it.unimi.dsi.fastutil.longs.AbstractLongCollection;\n import it.unimi.dsi.fastutil.longs.AbstractLongSet;\n import it.unimi.dsi.fastutil.longs.Long2LongMap;\n-import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongBigArrayBigList;\n import it.unimi.dsi.fastutil.longs.LongCollection;\n import it.unimi.dsi.fastutil.longs.LongIterator;\n import it.unimi.dsi.fastutil.longs.LongSet;\n import it.unimi.dsi.fastutil.objects.AbstractObjectSet;\n import it.unimi.dsi.fastutil.objects.ObjectIterator;\n+import org.openjdk.jol.info.ClassLayout;\n \n-import java.util.Arrays;\n import java.util.Map;\n import java.util.NoSuchElementException;\n import java.util.function.Consumer;\n \n-import static it.unimi.dsi.fastutil.HashCommon.arraySize;\n+import static it.unimi.dsi.fastutil.HashCommon.bigArraySize;\n import static it.unimi.dsi.fastutil.HashCommon.maxFill;\n+import static java.lang.Math.toIntExact;\n import static java.util.Objects.requireNonNull;\n \n // Note: this code was forked from fastutil (http://fastutil.di.unimi.it/) Long2LongOpenHashMap\n // Copyright (C) 2002-2019 Sebastiano Vigna\n public class Long2LongOpenBigHashMap\n         extends AbstractLong2LongMap\n-        implements java.io.Serializable, Cloneable, Hash\n+        implements java.io.Serializable, Hash", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY4MjY0MA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533682640", "bodyText": "remove these", "author": "dain", "createdAt": "2020-12-01T19:56:12Z", "path": "presto-main/src/main/java/io/prestosql/util/Long2LongOpenBigHashMap.java", "diffHunk": "@@ -1457,108 +1436,83 @@ public boolean trim(final int n)\n      *\n      * @param newN the new size\n      */\n-    protected void rehash(final int newN)\n+    protected void rehash(final long newN)\n     {\n-        final long[] key = this.key;\n-        final long[] value = this.value;\n-        final int mask = newN - 1; // Note that this is used by the hashing macro\n-        final long[] newKey = new long[newN + 1];\n-        final long[] newValue = new long[newN + 1];\n-        int i = n;\n-        int pos;\n-        for (int j = realSize(); j-- != 0; ) {\n-            while (((key[--i]) == (0))) {\n+        final LongBigArray key = this.key;\n+        final LongBigArray value = this.value;\n+        final long mask = newN - 1; // Note that this is used by the hashing macro\n+        final LongBigArray newKey = new LongBigArray();\n+        newKey.ensureCapacity(newN + 1);\n+        final LongBigArray newValue = new LongBigArray();\n+        newValue.ensureCapacity(newN + 1);\n+        long i = n;\n+        long pos;\n+        for (long j = realSize(); j-- != 0; ) {\n+            while (((key.get(--i)) == (0))) {\n                 // Skip\n             }\n-            pos = (int) it.unimi.dsi.fastutil.HashCommon.mix((key[i])) & mask;\n-            if (!((newKey[pos]) == (0))) {\n+            pos = it.unimi.dsi.fastutil.HashCommon.mix((key.get(i))) & mask;\n+            if (!((newKey.get(pos)) == (0))) {\n                 pos = (pos + 1) & mask;\n-                while (!((newKey[pos]) == (0))) {\n+                while (!((newKey.get(pos)) == (0))) {\n                     pos = (pos + 1) & mask;\n                 }\n             }\n-            newKey[pos] = key[i];\n-            newValue[pos] = value[i];\n+            newKey.set(pos, key.get(i));\n+            newValue.set(pos, value.get(i));\n         }\n-        newValue[newN] = value[n];\n+        newValue.set(newN, value.get(n));\n         n = newN;\n         this.mask = mask;\n         maxFill = maxFill(n, f);\n         this.key = newKey;\n         this.value = newValue;\n     }\n \n-    /**\n-     * Returns a deep copy of this map.\n-     *\n-     * <p>\n-     * This method performs a deep copy of this hash map; the data stored in the\n-     * map, however, is not cloned. Note that this makes a difference only for\n-     * object keys.\n-     *\n-     * @return a deep copy of this map.\n-     */\n-    @Override\n-    public Long2LongOpenBigHashMap clone()\n-    {\n-        Long2LongOpenBigHashMap c;\n-        try {\n-            c = (Long2LongOpenBigHashMap) super.clone();\n-        }\n-        catch (CloneNotSupportedException cantHappen) {\n-            throw new InternalError();\n-        }\n-        c.keys = null;\n-        c.values = null;\n-        c.entries = null;\n-        c.containsNullKey = containsNullKey;\n-        c.key = key.clone();\n-        c.value = value.clone();\n-        return c;\n-    }\n-\n     private void writeObject(java.io.ObjectOutputStream s)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5ODg3Mw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533698873", "bodyText": "Did you mean to put this in main instead of test?", "author": "dain", "createdAt": "2020-12-01T20:25:09Z", "path": "presto-main/src/main/java/io/prestosql/operator/CyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.Type;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * GroupByHash that provides a round robin group ID assignment.\n+ */\n+public class CyclingGroupByHash", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxMjU5OQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533812599", "bodyText": "Well it's used for the benchmark classes which aren't in test. I assume that rules out test then?", "author": "erichwang", "createdAt": "2020-12-02T00:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5ODg3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5OTQ1MA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533699450", "bodyText": "For benchmarking I think you can use a JMH Blackhole for the sink", "author": "dain", "createdAt": "2020-12-01T20:26:09Z", "path": "presto-main/src/main/java/io/prestosql/operator/CyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.type.Type;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.List;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * GroupByHash that provides a round robin group ID assignment.\n+ */\n+public class CyclingGroupByHash\n+        implements GroupByHash\n+{\n+    private static final int INSTANCE_SIZE = ClassLayout.parseClass(CyclingGroupByHash.class).instanceSize();\n+\n+    private final int totalGroupCount;\n+    private int maxGroupId;\n+    private int currentGroupId;\n+\n+    public CyclingGroupByHash(int totalGroupCount)\n+    {\n+        this.totalGroupCount = totalGroupCount;\n+    }\n+\n+    @Override\n+    public long getEstimatedSize()\n+    {\n+        return INSTANCE_SIZE;\n+    }\n+\n+    @Override\n+    public long getHashCollisions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public double getExpectedHashCollisions()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public List<Type> getTypes()\n+    {\n+        return ImmutableList.of();\n+    }\n+\n+    @Override\n+    public int getGroupCount()\n+    {\n+        return maxGroupId;\n+    }\n+\n+    @Override\n+    public void appendValuesTo(int groupId, PageBuilder pageBuilder, int outputChannelOffset)\n+    {\n+        throw new UnsupportedOperationException(\"CyclingGroupByHash does not support appendValuesTo\");\n+    }\n+\n+    @Override\n+    public Work<?> addPage(Page page)\n+    {\n+        // Create a dump work whose result is never used.\n+        return new CompletedWork<>(0);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgxNDEzNA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533814134", "bodyText": "@dain, can you clarify this? doesn't returning the value from a benchmarked method effectively act as a blackhole? It might just be that I'm not understanding the connection to this method, which is similar to the one from NoChannelGroupByHash.", "author": "erichwang", "createdAt": "2020-12-02T00:31:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5OTQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg2MTUwMQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537861501", "bodyText": "You have a comment // Create a dump work whose result is never used.,  If you want to dump a result that is not used in a benchmark, Blackhole can be used.  Also this constructs an object which has some cost... Anyway, it was just a suggestion based on the comment; there is no need to change anything", "author": "dain", "createdAt": "2020-12-07T21:55:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5OTQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzkxMzMxNw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537913317", "bodyText": "// Create a dump work whose result is never used.\n\nOh, this comes from NoChannelGroupByHash (which I copied). I never call this, so I can just throw an UnsupportedOperationException if you think that would be better", "author": "erichwang", "createdAt": "2020-12-07T23:27:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY5OTQ1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwMjkwOA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533702908", "bodyText": "I think there already is a page equals somewhere, but it might be page equals page.  Maybe you could create a page from the longs and then use the existing page equals page... just an idea", "author": "dain", "createdAt": "2020-12-01T20:32:22Z", "path": "presto-main/src/test/java/io/prestosql/operator/TestCyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static org.testng.Assert.assertEquals;\n+\n+public class TestCyclingGroupByHash\n+{\n+    @Test\n+    public void testSingleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(1);\n+        Page page = createPage(1);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 0L);\n+    }\n+\n+    @Test\n+    public void testMultipleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(2);\n+        Page page = createPage(3);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 1L, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 1L, 0L);\n+    }\n+\n+    private static void assertContentsEqual(GroupByIdBlock groupByIdBlock, long... groupIds)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyNjQzNg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533826436", "bodyText": "Yea, in PageAssertions we have assertPageEquals(). To use this we would have to create a page out of the GroupByIdBlock (since it is a block and not a page) as well as the expected group ids, just to do a page comparison. It feels a bit simpler here just to read out the groupIds as longs directly? But might be missing something.", "author": "erichwang", "createdAt": "2020-12-02T01:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwMjkwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg2MzI1Nw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537863257", "bodyText": "No need to change, but for future reference, I think you can do:\nnew GroupIdBlock(maxGroup, new IntArrayBlock(groupIds.length, Optional.empty(), groupIds));", "author": "dain", "createdAt": "2020-12-07T21:57:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwMjkwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNDE2OQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533704169", "bodyText": "verify the group count also... some tests should verify the group cout is accurate when the count is less than the max count", "author": "dain", "createdAt": "2020-12-01T20:34:45Z", "path": "presto-main/src/test/java/io/prestosql/operator/TestCyclingGroupByHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import org.testng.annotations.Test;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static org.testng.Assert.assertEquals;\n+\n+public class TestCyclingGroupByHash\n+{\n+    @Test\n+    public void testSingleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(1);\n+        Page page = createPage(1);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 0L);\n+    }\n+\n+    @Test\n+    public void testMultipleGroup()\n+    {\n+        CyclingGroupByHash groupByHash = new CyclingGroupByHash(2);\n+        Page page = createPage(3);\n+        GroupByIdBlock groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 0L, 1L, 0L);\n+\n+        page = createPage(2);\n+        groupByIdBlock = computeGroupByIdBlock(groupByHash, page);\n+        assertContentsEqual(groupByIdBlock, 1L, 0L);\n+    }\n+\n+    private static void assertContentsEqual(GroupByIdBlock groupByIdBlock, long... groupIds)\n+    {\n+        assertEquals(groupByIdBlock.getPositionCount(), groupIds.length);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyNTAxNQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r533825015", "bodyText": "good catch, there was actually a bug there", "author": "erichwang", "createdAt": "2020-12-02T01:01:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzcwNDE2OQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNDgzNg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535524836", "bodyText": "drop the empty javadoc", "author": "dain", "createdAt": "2020-12-03T19:32:19Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjk2Mw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535526963", "bodyText": "Can we combine with the above call to save an extra traversal? I'm thinking something like addIfNotPresent", "author": "dain", "createdAt": "2020-12-03T19:34:43Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5NzM5MQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535697391", "bodyText": "Which extra traversal are you referring to? AllocateGroupIfNeeded maps to ensureCapacity which returns immediately in 99.9% of the calls to it. Or do you mean just to put some syntactic wrappers around these two calls?", "author": "erichwang", "createdAt": "2020-12-03T22:42:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjk2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg2NDE3OA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537864178", "bodyText": "Oh, I thought allocateGroupIfNeeded had to find a spot in the tree.  Just ignore my comment.", "author": "dain", "createdAt": "2020-12-07T21:59:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyNjk2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUyODk0Ng==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535528946", "bodyText": "Maybe mention that after this call, the accumulator will be empty.", "author": "dain", "createdAt": "2020-12-03T19:36:52Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU2NDUzMg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535564532", "bodyText": "Why use checkArgument here and verify  in other checks?", "author": "dain", "createdAt": "2020-12-03T20:21:47Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5OTA1Mg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535699052", "bodyText": "checkArgument because you are not allowed to call the heapPop() on an empty group, which indicates an invalid argument passed given the preconditions of this method. Versus verify in other places where local and class-wide invariants are violated. Is that the standard you guys are also using?", "author": "erichwang", "createdAt": "2020-12-03T22:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU2NDUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczNDQ0OQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535734449", "bodyText": "I asked because in peekRootRowId you have the same check, but it is verify.  I would assume the two would be the same.", "author": "dain", "createdAt": "2020-12-03T23:58:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU2NDUzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3MjEzNw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535572137", "bodyText": "If it doesn't hurt perf, I would use Optional instead of Nullable", "author": "dain", "createdAt": "2020-12-03T20:28:55Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY5Nzg1NA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535697854", "bodyText": "Yap, so this could hurt performance since it gets passed for each add call for each row", "author": "erichwang", "createdAt": "2020-12-03T22:43:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3MjEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NDk3Ng==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535574976", "bodyText": "Is root the right term here?", "author": "dain", "createdAt": "2020-12-03T20:31:35Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwMDUzMg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535700532", "bodyText": "I believe so, it's referred to as the root on wikipedia anyways (since a heap is also a binary tree)", "author": "erichwang", "createdAt": "2020-12-03T22:47:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NDk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTczNDAyNQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535734025", "bodyText": "Oh I see.  I read this wrong.", "author": "dain", "createdAt": "2020-12-03T23:56:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3NDk3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTU3ODE4Mg==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535578182", "bodyText": "I assume this is used to \"prune\" the heap down to size.  Maybe explicitly mention that", "author": "dain", "createdAt": "2020-12-03T20:34:29Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastRowId, contextEvictionListener);\n+        }\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYyNzUwMQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535627501", "bodyText": "I'm not sure what this means", "author": "dain", "createdAt": "2020-12-03T21:15:07Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,483 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.util.HeapTraversal;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.function.LongConsumer;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.util.Objects.requireNonNull;\n+\n+public class GroupedTopNRowNumberAccumulator\n+{\n+    /**\n+     * Reference to an input row.\n+     * <p>\n+     * Note: RowReference gives us the ability to defer row ID generation (which can be expensive in tight loops).\n+     */\n+    public interface RowReference\n+    {\n+        /**\n+         * Compares the referenced row to the specified row ID using the provided row ID comparator.\n+         */\n+        int compareTo(LongComparator rowIdComparator, long rowId);\n+\n+        /**\n+         * Extract a stable row ID that can be used to reference this row at a future point.\n+         * <p>\n+         * This accumulator will not retain any references to the RowReference object.\n+         */\n+        long extractRowId();\n+    }\n+\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupedTopNRowNumberAccumulator.class).instanceSize();\n+    private static final long UNKNOWN_INDEX = -1;\n+\n+    private final GroupIdToHeapBuffer groupIdToHeapBuffer = new GroupIdToHeapBuffer();\n+    private final HeapNodeBuffer heapNodeBuffer = new HeapNodeBuffer();\n+    private final HeapTraversal heapTraversal = new HeapTraversal();\n+\n+    private final LongComparator rowComparator;\n+    private final int topN;\n+    private final LongConsumer rowIdEvictionListener;\n+\n+    public GroupedTopNRowNumberAccumulator(LongComparator rowIdComparator, int topN, LongConsumer rowIdEvictionListener)\n+    {\n+        this.rowComparator = requireNonNull(rowIdComparator, \"addressComparator is null\");\n+        checkArgument(topN > 0, \"topN must be greater than zero\");\n+        this.topN = topN;\n+        this.rowIdEvictionListener = requireNonNull(rowIdEvictionListener, \"rowIdEvictionListener is null\");\n+    }\n+\n+    public long sizeOf()\n+    {\n+        return INSTANCE_SIZE + groupIdToHeapBuffer.sizeOf() + heapNodeBuffer.sizeOf() + heapTraversal.sizeOf();\n+    }\n+\n+    private long calculateRootRowNumber(long groupId)\n+    {\n+        return groupIdToHeapBuffer.getHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Add the specified row to this accumulator.\n+     * <p>\n+     * This may trigger row eviction callbacks if other rows have to be evicted to make space.\n+     *\n+     * @param groupId\n+     * @param rowReference\n+     * @return true if this row was incorporated, false otherwise\n+     */\n+    public boolean add(long groupId, RowReference rowReference)\n+    {\n+        groupIdToHeapBuffer.allocateGroupIfNeeded(groupId);\n+\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX || calculateRootRowNumber(groupId) < topN) {\n+            heapInsert(groupId, rowReference.extractRowId());\n+            return true;\n+        }\n+        else if (rowReference.compareTo(rowComparator, heapNodeBuffer.getRowId(heapRootNodeIndex)) < 0) {\n+            heapPopAndInsert(groupId, rowReference.extractRowId(), rowIdEvictionListener);\n+            return true;\n+        }\n+        else {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Drain the contents of this accumulator to the provided output row ID buffer.\n+     * <p>\n+     * Rows will be presented in increasing rank order. Draining will not trigger any row eviction callbacks.\n+     *\n+     * @param groupId\n+     * @param rowIdOutput\n+     * @return number of rows deposited to the output buffer\n+     */\n+    public long drainTo(long groupId, LongBigArray rowIdOutput)\n+    {\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+        rowIdOutput.ensureCapacity(heapSize);\n+        // Heap is inverted to output order, so insert back to front\n+        for (long i = heapSize - 1; i >= 0; i--) {\n+            rowIdOutput.set(i, peekRootRowId(groupId));\n+            // No eviction listener needed because this is an explicit caller directive to extract data\n+            heapPop(groupId, null);\n+        }\n+        return heapSize;\n+    }\n+\n+    private long peekRootRowId(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        verify(heapRootNodeIndex != UNKNOWN_INDEX, \"No root to peek\");\n+        return heapNodeBuffer.getRowId(heapRootNodeIndex);\n+    }\n+\n+    private long getChildIndex(long heapNodeIndex, HeapTraversal.Child child)\n+    {\n+        return child == HeapTraversal.Child.LEFT\n+                ? heapNodeBuffer.getLeftChildHeapIndex(heapNodeIndex)\n+                : heapNodeBuffer.getRightChildHeapIndex(heapNodeIndex);\n+    }\n+\n+    private void setChildIndex(long heapNodeIndex, HeapTraversal.Child child, long newChildIndex)\n+    {\n+        if (child == HeapTraversal.Child.LEFT) {\n+            heapNodeBuffer.setLeftChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+        else {\n+            heapNodeBuffer.setRightChildHeapIndex(heapNodeIndex, newChildIndex);\n+        }\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap.\n+     *\n+     * @param groupId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPop(long groupId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkArgument(heapRootNodeIndex != UNKNOWN_INDEX, \"Group ID has an empty heap\");\n+\n+        long lastNodeIndex = heapDetachLastInsertionLeaf(groupId);\n+        long lastRowId = heapNodeBuffer.getRowId(lastNodeIndex);\n+        heapNodeBuffer.deallocate(lastNodeIndex);\n+\n+        if (lastNodeIndex == heapRootNodeIndex) {\n+            // The root is the last node remaining\n+            if (contextEvictionListener != null) {\n+                contextEvictionListener.accept(lastRowId);\n+            }\n+        }\n+        else {\n+            // Pop the root and insert lastRowId back into the heap to ensure a balanced tree\n+            heapPopAndInsert(groupId, lastRowId, contextEvictionListener);\n+        }\n+    }\n+\n+    /**\n+     * Detaches (but does not deallocate) the leaf in the bottom right-most position in the heap.\n+     * <p>\n+     * Given the fixed insertion order, the bottom right-most leaf will correspond to the last leaf node inserted into\n+     * the balanced heap.\n+     *\n+     * @param groupId\n+     * @return leaf node index that was deatched from the heap\n+     */\n+    private long heapDetachLastInsertionLeaf(long groupId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        long heapSize = groupIdToHeapBuffer.getHeapSize(groupId);\n+\n+        long previousNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(heapSize);\n+        while (!heapTraversal.isTarget()) {\n+            previousNodeIndex = currentNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentNodeIndex = getChildIndex(currentNodeIndex, childPosition);\n+            verify(currentNodeIndex != UNKNOWN_INDEX, \"Target node must exist\");\n+        }\n+\n+        // Detach the last insertion leaf node, but do not deallocate yet\n+        if (previousNodeIndex == UNKNOWN_INDEX) {\n+            // Last insertion leaf was the root node\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 0);\n+        }\n+        else {\n+            setChildIndex(previousNodeIndex, childPosition, UNKNOWN_INDEX);\n+            groupIdToHeapBuffer.addHeapSize(groupId, -1);\n+        }\n+\n+        return currentNodeIndex;\n+    }\n+\n+    /**\n+     * Inserts a new row into the heap for the specified group ID.\n+     * <p>\n+     * The technique involves traversing the heap from the root to a new bottom left-priority leaf position,\n+     * potentially swapping heap nodes along the way to find the proper insertion position for the new row.\n+     * Insertions always fill the left child before the right, and fill up an entire heap level before moving to the\n+     * next level.\n+     *\n+     * @param groupId\n+     * @param newRowId\n+     */\n+    private void heapInsert(long groupId, long newRowId)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        if (heapRootNodeIndex == UNKNOWN_INDEX) {\n+            // Heap is currently empty, so this will be the first node\n+            heapRootNodeIndex = heapNodeBuffer.allocateNewNode(newRowId);\n+\n+            groupIdToHeapBuffer.setHeapRootNodeIndex(groupId, heapRootNodeIndex);\n+            groupIdToHeapBuffer.setHeapSize(groupId, 1);\n+            return;\n+        }\n+\n+        long previousHeapNodeIndex = UNKNOWN_INDEX;\n+        HeapTraversal.Child childPosition = null;\n+        long currentHeapNodeIndex = heapRootNodeIndex;\n+\n+        heapTraversal.resetWithPathTo(groupIdToHeapBuffer.getHeapSize(groupId) + 1);\n+        while (!heapTraversal.isTarget()) {\n+            long currentRowId = heapNodeBuffer.getRowId(currentHeapNodeIndex);\n+            if (rowComparator.compare(newRowId, currentRowId) > 0) {\n+                // Swap the row values\n+                heapNodeBuffer.setRowId(currentHeapNodeIndex, newRowId);\n+\n+                newRowId = currentRowId;\n+            }\n+\n+            previousHeapNodeIndex = currentHeapNodeIndex;\n+            childPosition = heapTraversal.nextChild();\n+            currentHeapNodeIndex = getChildIndex(currentHeapNodeIndex, childPosition);\n+        }\n+\n+        verify(previousHeapNodeIndex != UNKNOWN_INDEX && childPosition != null, \"heap must have at least one node before starting traversal\");\n+        verify(currentHeapNodeIndex == UNKNOWN_INDEX, \"New child shouldn't exist yet\");\n+\n+        long newHeapNodeIndex = heapNodeBuffer.allocateNewNode(newRowId);\n+\n+        //  Link the new child to the parent\n+        setChildIndex(previousHeapNodeIndex, childPosition, newHeapNodeIndex);\n+\n+        groupIdToHeapBuffer.incrementHeapSize(groupId);\n+    }\n+\n+    /**\n+     * Pop the root node off the group ID's max heap and insert the newRowId.\n+     * <p>\n+     * These two operations are more efficient if performed together. The technique involves swapping the new row into\n+     * the root position, and applying a heap down bubbling operation to heap-ify.\n+     *\n+     * @param groupId\n+     * @param newRowId\n+     * @param contextEvictionListener optional callback for the root node that gets popped off\n+     */\n+    private void heapPopAndInsert(long groupId, long newRowId, @Nullable LongConsumer contextEvictionListener)\n+    {\n+        long heapRootNodeIndex = groupIdToHeapBuffer.getHeapRootNodeIndex(groupId);\n+        checkState(heapRootNodeIndex != UNKNOWN_INDEX, \"popAndInsert() requires at least a root node\");\n+\n+        // Clear contents of the root node to create a vacancy for another row\n+        long poppedRowId = heapNodeBuffer.getRowId(heapRootNodeIndex);\n+\n+        long currentNodeIndex = heapRootNodeIndex;\n+        while (true) {\n+            long maxChildNodeIndex = heapNodeBuffer.getLeftChildHeapIndex(currentNodeIndex);\n+            if (maxChildNodeIndex == UNKNOWN_INDEX) {\n+                // Left is always inserted before right, so a missing left child means there can't be a right child,\n+                // which means this must already be a leaf position.\n+                break;\n+            }\n+            long maxChildRowId = heapNodeBuffer.getRowId(maxChildNodeIndex);\n+\n+            long rightChildNodeIndex = heapNodeBuffer.getRightChildHeapIndex(currentNodeIndex);\n+            if (rightChildNodeIndex != UNKNOWN_INDEX) {\n+                long rightRowId = heapNodeBuffer.getRowId(rightChildNodeIndex);\n+                if (rowComparator.compare(rightRowId, maxChildRowId) > 0) {\n+                    maxChildNodeIndex = rightChildNodeIndex;\n+                    maxChildRowId = rightRowId;\n+                }\n+            }\n+\n+            if (rowComparator.compare(newRowId, maxChildRowId) >= 0) {\n+                // New row is greater than or equal to both children, so the heap invariant is satisfied by inserting the\n+                // new row at this position\n+                break;\n+            }\n+\n+            // Swap the max child row value into the current node\n+            heapNodeBuffer.setRowId(currentNodeIndex, maxChildRowId);\n+\n+            // Max child now has an unfilled vacancy, so continue processing with that as the current node\n+            currentNodeIndex = maxChildNodeIndex;\n+        }\n+\n+        heapNodeBuffer.setRowId(currentNodeIndex, newRowId);\n+\n+        if (contextEvictionListener != null) {\n+            contextEvictionListener.accept(poppedRowId);\n+        }\n+    }\n+\n+    /**\n+     * Buffer abstracting a mapping from group ID to a heap. The group ID provides the index for all operations.\n+     */\n+    private static class GroupIdToHeapBuffer\n+    {\n+        private static final long INSTANCE_SIZE = ClassLayout.parseClass(GroupIdToHeapBuffer.class).instanceSize();\n+\n+        /*\n+         *  Memory layout:\n+         *  [LONG] heapNodeIndex G1,\n+         *  [LONG] heapNodeIndex G2,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYzMDQyMw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535630423", "bodyText": "I don't think the layout is important.  This is a index of heap buffer for each group.  The array is indexed on the group id.... maybe stated more cleanly", "author": "dain", "createdAt": "2020-12-03T21:18:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYyNzUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwMjgyMA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535702820", "bodyText": "I wrote it this way because the rank and dense rank versions look similar but have more complex layouts -- and was intending to show the symmetry this way. Any suggestions on how to connect those that way?", "author": "erichwang", "createdAt": "2020-12-03T22:50:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTYyNzUwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0MTI3Nw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535641277", "bodyText": "Do you get full coverage with these tests?", "author": "dain", "createdAt": "2020-12-03T21:28:42Z", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRowNumberAccumulator.RowReference;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongArraySet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRowNumberAccumulator", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNzQ1Ng==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535717456", "bodyText": "technically 96%, but the 5 lines that aren't covered aren't very critical imo.", "author": "erichwang", "createdAt": "2020-12-03T23:18:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0MTI3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0NDAyNQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535644025", "bodyText": "maybe add a comment like: add with same group id and larger value, which should be ignored because max is 1.  Same for others", "author": "dain", "createdAt": "2020-12-03T21:31:58Z", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRowNumberAccumulator.RowReference;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongArraySet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRowNumberAccumulator\n+{\n+    @Test\n+    public void testSingleGroupTopN1()\n+    {\n+        int topN = 1;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        TestingRowReference rowReference = new TestingRowReference();\n+        rowReference.setRowId(0);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(1);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY0NTk5NQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535645995", "bodyText": "I feel like 1 could be a special case... maybe do a top of 4 and fill 2", "author": "dain", "createdAt": "2020-12-03T21:34:08Z", "path": "presto-main/src/test/java/io/prestosql/operator/TestGroupedTopNRowNumberAccumulator.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.array.LongBigArray;\n+import io.prestosql.operator.GroupedTopNRowNumberAccumulator.RowReference;\n+import it.unimi.dsi.fastutil.longs.LongArrayList;\n+import it.unimi.dsi.fastutil.longs.LongArraySet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestGroupedTopNRowNumberAccumulator\n+{\n+    @Test\n+    public void testSingleGroupTopN1()\n+    {\n+        int topN = 1;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        TestingRowReference rowReference = new TestingRowReference();\n+        rowReference.setRowId(0);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(1);\n+        assertFalse(accumulator.add(0, rowReference));\n+        assertFalse(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(-1);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertEquals(evicted, Arrays.asList(0L));\n+\n+        LongBigArray rowIdOutput = new LongBigArray();\n+        assertEquals(accumulator.drainTo(0, rowIdOutput), 1);\n+        assertEquals(rowIdOutput.get(0), -1);\n+    }\n+\n+    @Test\n+    public void testSingleGroupTopN2()\n+    {\n+        int topN = 2;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        TestingRowReference rowReference = new TestingRowReference();\n+        rowReference.setRowId(0);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(1);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(2);\n+        assertFalse(accumulator.add(0, rowReference));\n+        assertFalse(rowReference.isRowIdExtracted());\n+        assertTrue(evicted.isEmpty());\n+\n+        rowReference.setRowId(-2);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertEquals(evicted, Arrays.asList(1L));\n+\n+        rowReference.setRowId(-1);\n+        assertTrue(accumulator.add(0, rowReference));\n+        assertTrue(rowReference.isRowIdExtracted());\n+        assertEquals(evicted, Arrays.asList(1L, 0L));\n+\n+        LongBigArray rowIdOutput = new LongBigArray();\n+        assertEquals(accumulator.drainTo(0, rowIdOutput), 2);\n+        assertEquals(rowIdOutput.get(0), -2);\n+        assertEquals(rowIdOutput.get(1), -1);\n+    }\n+\n+    @Test\n+    public void testSingleGroupTopN2PartialFill()\n+    {\n+        int topN = 2;\n+        List<Long> evicted = new LongArrayList();\n+        GroupedTopNRowNumberAccumulator accumulator = new GroupedTopNRowNumberAccumulator(Long::compare, topN, evicted::add);\n+\n+        // Only fill to a part of topN before draining", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY1MTcyNw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535651727", "bodyText": "Normally we name stuff like \"leftPage\" and \"righttPage\". The actual left and right just argument order but it doesn't really matter, but it make it easier to see than a single number.  The is especially true when the argument names get longer.", "author": "dain", "createdAt": "2020-12-03T21:39:49Z", "path": "presto-main/src/main/java/io/prestosql/operator/GroupedTopNBuilder.java", "diffHunk": "@@ -78,17 +53,20 @@ public GroupedTopNBuilder(\n     {\n         this.sourceTypes = requireNonNull(sourceTypes, \"sourceTypes is null\");\n         checkArgument(topN > 0, \"topN must be > 0\");\n-        this.topN = topN;\n         this.produceRowNumber = produceRowNumber;\n         this.groupByHash = requireNonNull(groupByHash, \"groupByHash is not null\");\n \n         requireNonNull(comparator, \"comparator is null\");\n-        this.comparator = (left, right) -> comparator.compareTo(\n-                pageReferences.get(left.getPageId()).getPage(),\n-                left.getPosition(),\n-                pageReferences.get(right.getPageId()).getPage(),\n-                right.getPosition());\n-        this.emptyPageReferenceSlots = new IntFIFOQueue();\n+        groupedTopNRowNumberAccumulator = new GroupedTopNRowNumberAccumulator(\n+                (rowId1, rowId2) -> {\n+                    Page page1 = pageManager.getPage(rowId1);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTY3OTM5OA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535679398", "bodyText": "I think the important part is this has a freelist for tracking.  I think that is important to mention and that the IDs of removed items can be reused.", "author": "dain", "createdAt": "2020-12-03T22:08:19Z", "path": "presto-main/src/main/java/io/prestosql/operator/IdRegistry.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.airlift.slice.SizeOf;\n+import it.unimi.dsi.fastutil.ints.IntArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.objects.ObjectArrayList;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+/**\n+ * Object registration system that allows looking up objects via stable IDs.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwNzY3OQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535707679", "bodyText": "consider adding a method int IdRegistry.add(IntFunction<T>. Then this can be int pageId = pages.add(id -> new PageAccounting(id, page))", "author": "dain", "createdAt": "2020-12-03T22:57:28Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NjA2OA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r536446068", "bodyText": "What do you think should be the return value in that case?\nFor this to work, it needs to replace the id allocation step -- which suggests the return value should be the id value to reinforce that the value should be symmetrically deallocated. But then again, that also means to use the value as you need here, you would have to then take an extra step to fetch the value out again. We can return a pair object, but personally that feels a bit overkill given the context. Thoughts? Preferences?", "author": "erichwang", "createdAt": "2020-12-04T23:37:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwNzY3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg2OTA4OQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537869089", "bodyText": "This wouldn't be for the \"replace case\", but only \"add new\", so it would only have the one ID.  I'm thinking of something like Map.computeIfAbsent, but for adding new items", "author": "dain", "createdAt": "2020-12-07T22:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcwNzY3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxMjg1NA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535712854", "bodyText": "Maybe add method isCursorId, then all of the negative stuff will be encapsulated.", "author": "dain", "createdAt": "2020-12-03T23:07:38Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTI1NA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715254", "bodyText": "I don't think this comment helps", "author": "dain", "createdAt": "2020-12-03T23:13:12Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));\n+            return loadCursor.getPage();\n+        }\n+        else {\n+            int pageId = rowIdBuffer.getPageId(rowId);\n+            return pages.get(pageId).getPage();\n+        }\n+    }\n+\n+    public int getPosition(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTQ3MQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715471", "bodyText": "I don't think this will be needed if you add an isCursorId method", "author": "dain", "createdAt": "2020-12-03T23:13:47Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));\n+            return loadCursor.getPage();\n+        }\n+        else {\n+            int pageId = rowIdBuffer.getPageId(rowId);\n+            return pages.get(pageId).getPage();\n+        }\n+    }\n+\n+    public int getPosition(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTYxNQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715615", "bodyText": "I'd just inline this variable.", "author": "dain", "createdAt": "2020-12-03T23:14:11Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));\n+            return loadCursor.getPage();\n+        }\n+        else {\n+            int pageId = rowIdBuffer.getPageId(rowId);\n+            return pages.get(pageId).getPage();\n+        }\n+    }\n+\n+    public int getPosition(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTcxNTgwNA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535715804", "bodyText": "I'd just inline this variable", "author": "dain", "createdAt": "2020-12-03T23:14:32Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntList lazyLoadCandidates = new IntList();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        int cursorId = cursors.allocateId();\n+        LoadCursor cursor = new LoadCursor(cursorId, pageAccounting);\n+        cursors.set(cursorId, cursor);\n+\n+        // Memory accounting will be deferred to after lazy loading\n+        lazyLoadCandidates.add(pageId);\n+        return cursor;\n+    }\n+\n+    public void dereference(long rowId)\n+    {\n+        PageAccounting pageAccounting = pages.get(rowIdBuffer.getPageId(rowId));\n+        pageAccounting.dereference(rowId);\n+        checkPageMaintenance(pageAccounting);\n+    }\n+\n+    private void checkPageMaintenance(PageAccounting pageAccounting)\n+    {\n+        int pageId = pageAccounting.getPageId();\n+        if (pageAccounting.isPruneEligible()) {\n+            lazyLoadCandidates.rem(pageId);\n+            compactionCandidates.remove(pageId);\n+            pages.deallocate(pageId);\n+        }\n+        else if (pageAccounting.isCompactionEligible()) {\n+            compactionCandidates.add(pageId);\n+        }\n+    }\n+\n+    public Page getPage(long rowId)\n+    {\n+        // We want to allow operations from LoadCursors as well as buffered pages with stable row IDs.\n+        if (rowId < 0) {\n+            // Negative row IDs are reserved for cursors\n+            LoadCursor loadCursor = cursors.get(rowIdToCursorId(rowId));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc0OTA1Nw==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535749057", "bodyText": "Is there a way to test if the there are no pages now?", "author": "dain", "createdAt": "2020-12-04T00:35:48Z", "path": "presto-main/src/test/java/io/prestosql/operator/TestRowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.BlockBuilder;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static java.lang.Math.toIntExact;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertFalse;\n+import static org.testng.Assert.assertTrue;\n+import static org.testng.Assert.fail;\n+\n+public class TestRowReferencePageManager\n+{\n+    @Test\n+    public void testEmptyPage()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+        Page page = createBigIntSingleBlockPage(0, 0);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertFalse(cursor.advance());\n+            try {\n+                cursor.allocateRowId();\n+                fail();\n+            }\n+            catch (IllegalStateException e) {\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testSinglePageRowIds()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        LongComparator rowIdComparator = (rowId1, rowId2) -> {\n+            long value1 = extractValue(pageManager, rowId1);\n+            long value2 = extractValue(pageManager, rowId2);\n+            return Long.compare(value1, value2);\n+        };\n+\n+        long id0;\n+        long id1;\n+        long id3;\n+        Page page = createBigIntSingleBlockPage(0, 4);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            id1 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id1), 1L);\n+\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            assertTrue(cursor.compareTo(rowIdComparator, id1) > 0);\n+            // Skip this row by not allocating an ID\n+\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            assertTrue(cursor.compareTo(rowIdComparator, id1) > 0);\n+            id3 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id3), 3L);\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scope\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+        assertEquals(extractValue(pageManager, id1), 1L);\n+        assertEquals(extractValue(pageManager, id3), 3L);\n+    }\n+\n+    @Test\n+    public void testMultiplePageRowIds()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        LongComparator rowIdComparator = (rowId1, rowId2) -> {\n+            long value1 = extractValue(pageManager, rowId1);\n+            long value2 = extractValue(pageManager, rowId2);\n+            return Long.compare(value1, value2);\n+        };\n+\n+        long id0;\n+        Page page = createBigIntSingleBlockPage(0, 1);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            assertFalse(cursor.advance());\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scope\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+\n+        long id1;\n+        page = createBigIntSingleBlockPage(1, 2);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            assertTrue(cursor.compareTo(rowIdComparator, id0) > 0);\n+            id1 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id1), 1L);\n+            assertFalse(cursor.advance());\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scopes\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+        assertEquals(extractValue(pageManager, id1), 1L);\n+    }\n+\n+    @Test\n+    public void testSkipCompaction()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        long id0;\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            // No compaction candidates until after the cursor is closed\n+            assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+            // Ignore the remaining positions, which means they should remain unreferenced\n+        }\n+\n+        // Should still be able to extract values for allocated IDs outside of cursor scope\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+\n+        // With a 1% fill, this page will certainly require compaction\n+        assertEquals(pageManager.getCompactionCandidateCount(), 1);\n+        pageManager.loadAndCompactIfNeeded();\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+        // Should still be able to extract same value after compaction\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+    }\n+\n+    @Test\n+    public void testDereferenceCompaction()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        long id0;\n+        List<Long> rowIdsToDereference = new ArrayList<>();\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            assertTrue(cursor.advance());\n+            id0 = cursor.allocateRowId();\n+            assertEquals(extractValue(pageManager, id0), 0L);\n+\n+            // Collect the remaining rowIds\n+            while (cursor.advance()) {\n+                rowIdsToDereference.add(cursor.allocateRowId());\n+            }\n+        }\n+\n+        // No compaction candidates since all rows should be referenced\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+        // Dereference 99% of row IDs\n+        for (long rowId : rowIdsToDereference) {\n+            pageManager.dereference(rowId);\n+        }\n+\n+        // With a 1% fill, this page will certainly require compaction\n+        assertEquals(pageManager.getCompactionCandidateCount(), 1);\n+        pageManager.loadAndCompactIfNeeded();\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+\n+        // Should still be able to extract same value after compaction\n+        assertEquals(extractValue(pageManager, id0), 0L);\n+    }\n+\n+    @Test\n+    public void testSkipFullPage()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            // Close the cursor without any row ID allocations\n+        }\n+\n+        // No compaction candidates since page is no longer needed\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);\n+    }\n+\n+    @Test\n+    public void testDereferenceFullPage()\n+    {\n+        RowReferencePageManager pageManager = new RowReferencePageManager();\n+\n+        List<Long> rowIdsToDereference = new ArrayList<>();\n+        Page page = createBigIntSingleBlockPage(0, 100);\n+        try (RowReferencePageManager.LoadCursor cursor = pageManager.add(page)) {\n+            while (cursor.advance()) {\n+                rowIdsToDereference.add(cursor.allocateRowId());\n+            }\n+        }\n+\n+        // Dereference all row IDs\n+        for (long rowId : rowIdsToDereference) {\n+            pageManager.dereference(rowId);\n+        }\n+\n+        // No compaction candidates since page is no longer needed\n+        assertEquals(pageManager.getCompactionCandidateCount(), 0);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTgyMzQ5NQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r535823495", "bodyText": "Only one cursor can be open at a time due to how lazy blocks work, so I think we can just make this a single field", "author": "dain", "createdAt": "2020-12-04T04:15:02Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,457 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+import static java.lang.Math.toIntExact;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final IdRegistry<LoadCursor> cursors = new IdRegistry<>();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg4MzYxOQ==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537883619", "bodyText": "I think this need a comment on why this is here and not when the LoadCursor is created.  Also, I was expecting that we would track the bytes of the page that is being loaded.", "author": "dain", "createdAt": "2020-12-07T22:32:20Z", "path": "presto-main/src/main/java/io/prestosql/operator/RowReferencePageManager.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.operator;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.airlift.slice.SizeOf;\n+import io.prestosql.array.IntBigArray;\n+import io.prestosql.spi.Page;\n+import io.prestosql.util.LongBigArrayFIFOQueue;\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n+import it.unimi.dsi.fastutil.longs.LongComparator;\n+import org.openjdk.jol.info.ClassLayout;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Arrays;\n+\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.base.Verify.verify;\n+\n+/**\n+ * Page buffering manager that enables access to individual rows via stable row IDs. This allows computation to be\n+ * built against these row IDs, while still enabling bulk memory optimizations such as compaction and lazy loading\n+ * behind the scenes. Callers are responsible for explicitly de-referencing any rows that are no longer needed.\n+ */\n+public class RowReferencePageManager\n+{\n+    private static final long INSTANCE_SIZE = ClassLayout.parseClass(RowReferencePageManager.class).instanceSize();\n+    private static final long PAGE_ACCOUNTING_INSTANCE_SIZE = ClassLayout.parseClass(PageAccounting.class).instanceSize();\n+    private static final int RESERVED_ROW_ID_FOR_CURSOR = -1;\n+\n+    private final IdRegistry<PageAccounting> pages = new IdRegistry<>();\n+    private final RowIdBuffer rowIdBuffer = new RowIdBuffer();\n+    private final IntHashSet compactionCandidates = new IntHashSet();\n+\n+    @Nullable\n+    private LoadCursor currentCursor;\n+    private long pageBytes;\n+\n+    public LoadCursor add(Page page)\n+    {\n+        checkState(currentCursor == null, \"Cursor still active\");\n+\n+        int pageId = pages.allocateId();\n+        PageAccounting pageAccounting = new PageAccounting(pageId, page);\n+        pages.set(pageId, pageAccounting);\n+\n+        pageAccounting.lockPage();\n+        currentCursor = new LoadCursor(pageAccounting, () -> {\n+            // Defer certain actions until this close callback\n+            checkState(currentCursor != null);\n+            pageAccounting.unlockPage();\n+            pageAccounting.loadPageLoadIfNeeded();\n+            pageBytes += pageAccounting.sizeOf();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk2MDgxOA==", "url": "https://github.com/trinodb/trino/pull/6072#discussion_r537960818", "bodyText": "Yep, good point on the comment. At this point, the assumption is that pageAccounting owns the page entity (since it is handling compaction and lazy loading). So by tracking the pageAccounting size, this should follow whatever size the underlying page is stored inside. Is that what you were asking?", "author": "erichwang", "createdAt": "2020-12-08T01:25:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg4MzYxOQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "b5d1e1ba2ed4cfbbe653020734bd9ebe71c88a43", "url": "https://github.com/trinodb/trino/commit/b5d1e1ba2ed4cfbbe653020734bd9ebe71c88a43", "message": "Add fill method to BigArray collections\n\nCopying the one that was already implemented for IntBigArray.", "committedDate": "2020-12-08T03:40:49Z", "type": "commit"}, {"oid": "2024120a924bf29c8fbd17ad48fb3a66b8eb1e91", "url": "https://github.com/trinodb/trino/commit/2024120a924bf29c8fbd17ad48fb3a66b8eb1e91", "message": "Add copyTo methods to presto BigArray collections", "committedDate": "2020-12-08T03:40:49Z", "type": "commit"}, {"oid": "bd8a7ca6a7b4ee61696b558cd3c1550b1422e3e3", "url": "https://github.com/trinodb/trino/commit/bd8a7ca6a7b4ee61696b558cd3c1550b1422e3e3", "message": "Make BigArrays.SEGMENT_SIZE publicly accessible for optimizations", "committedDate": "2020-12-08T03:40:49Z", "type": "commit"}, {"oid": "0fddc9539f557609135521cf33ad8bafb8f41c6d", "url": "https://github.com/trinodb/trino/commit/0fddc9539f557609135521cf33ad8bafb8f41c6d", "message": "Fork a local copy of fastutil Long2LongOpenCustomHashMap\n\nFork a copy of fastutil Long2LongOpenCustomHashMap to a new\nLongLong2LongOpenCustomHashMap stub", "committedDate": "2020-12-08T03:40:49Z", "type": "commit"}, {"oid": "41da3774ab6acea1e8e5ba8a0a6bb0476127c59b", "url": "https://github.com/trinodb/trino/commit/41da3774ab6acea1e8e5ba8a0a6bb0476127c59b", "message": "Properly implement LongLong2LongOpenCustomHashMap within stub", "committedDate": "2020-12-08T03:40:49Z", "type": "commit"}, {"oid": "83847a0fa3f4262604abfa3f010fcc8c00af9197", "url": "https://github.com/trinodb/trino/commit/83847a0fa3f4262604abfa3f010fcc8c00af9197", "message": "Rename LongLong2LongOpenCustomHashMap into new big variant stub", "committedDate": "2020-12-08T03:40:49Z", "type": "commit"}, {"oid": "3774ff64075d1f56efea262ce703070e3e13334e", "url": "https://github.com/trinodb/trino/commit/3774ff64075d1f56efea262ce703070e3e13334e", "message": "Properly implement LongLong2LongOpenCustomBigHashMap within stub", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "9829fbb04705e378280b82ea1f916675eabb9acb", "url": "https://github.com/trinodb/trino/commit/9829fbb04705e378280b82ea1f916675eabb9acb", "message": "Fork a local copy of fastutil Long2LongOpenHashMap\n\nFork a copy of fastutil Long2LongOpenHashMap to new\nLong2LongOpenBigHashMap stub", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "7544842c9c9d6fb9a5cc2d6b9aed57ce1efa0be9", "url": "https://github.com/trinodb/trino/commit/7544842c9c9d6fb9a5cc2d6b9aed57ce1efa0be9", "message": "Properly implement Long2LongOpenBigHashMap within stub", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "734b99dee6b9e2120d1f8a0972a7051967bab97f", "url": "https://github.com/trinodb/trino/commit/734b99dee6b9e2120d1f8a0972a7051967bab97f", "message": "Fork a local copy of fastutil LongArrayFIFOQueue\n\nFork a copy of fastutil LongArrayFIFOQueue to new LongBigArrayFIFOQueue\nstub", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "cc8d8758b14f57d42f1a2afc0daeb7d92a197f30", "url": "https://github.com/trinodb/trino/commit/cc8d8758b14f57d42f1a2afc0daeb7d92a197f30", "message": "Properly implement LongBigArrayFIFOQueue within stub", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "aa865043602f84e330afbb7068cb08554a437c4a", "url": "https://github.com/trinodb/trino/commit/aa865043602f84e330afbb7068cb08554a437c4a", "message": "Update BenchmarkGroupedTopNBuilder with more realistic paramters\n\n- Update benchmark to actually run over multiple groups\n- Reduce TopN to most common sizes\n- Fix benchmark scoping so that it doesn't bleed the same instance\nacross iterations (GroupedTopNBuilder is only supposed to be used for\nadd/drain pass per instance).", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "126b156acb23a5d89d76b9b6f4cfb63080906a11", "url": "https://github.com/trinodb/trino/commit/126b156acb23a5d89d76b9b6f4cfb63080906a11", "message": "Add heap data structure utility for locating path from root to a node", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": "faed11387f999579f8daa44e3a52038a274c36b5", "url": "https://github.com/trinodb/trino/commit/faed11387f999579f8daa44e3a52038a274c36b5", "message": "Add GroupedTopNRowNumberAccumulator\n\nThis is a flat data structure for managing multiple top N row number\ngroup calculations that doesn't require per-row or per-group object\nallocations.  The main idea is that a heap (while classically\nrepresented as an array), can be also represented as a tree with node\npointers. These nodes (even across groups) can be efficiently compacted\ninto a single data structure.", "committedDate": "2020-12-08T03:40:50Z", "type": "commit"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "621003602879dcf2484eea15cc77df6ad05acf00", "url": "https://github.com/trinodb/trino/commit/621003602879dcf2484eea15cc77df6ad05acf00", "message": "Refactor GroupedTopNBuilder for better performance and memory\n\n- Introduce RowReferencePageManager to handle the generation of stable\nrow IDs across compaction events\n- Refactor GroupedTopNBuilder to use\nRowReferencePageManager as well as new GroupedTopNRowNumberAccumulator\n\nImproved characteristics\n- Vastly improved GC characteristics:\nNegligible object allocations regardless of row count or group count\n- Performance benchmarks upwards of 4x performance improvements when\nworking with large numbers of groups, and parity with the existing\nsolution in the worst case\n- Requires up to 20% less memory than the current solution when there\nare many groups, but does have a increased constant memory overhead when\ndealing with tiny data sets.", "committedDate": "2020-12-08T04:07:25Z", "type": "commit"}, {"oid": "621003602879dcf2484eea15cc77df6ad05acf00", "url": "https://github.com/trinodb/trino/commit/621003602879dcf2484eea15cc77df6ad05acf00", "message": "Refactor GroupedTopNBuilder for better performance and memory\n\n- Introduce RowReferencePageManager to handle the generation of stable\nrow IDs across compaction events\n- Refactor GroupedTopNBuilder to use\nRowReferencePageManager as well as new GroupedTopNRowNumberAccumulator\n\nImproved characteristics\n- Vastly improved GC characteristics:\nNegligible object allocations regardless of row count or group count\n- Performance benchmarks upwards of 4x performance improvements when\nworking with large numbers of groups, and parity with the existing\nsolution in the worst case\n- Requires up to 20% less memory than the current solution when there\nare many groups, but does have a increased constant memory overhead when\ndealing with tiny data sets.", "committedDate": "2020-12-08T04:07:25Z", "type": "forcePushed"}, {"oid": "622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "url": "https://github.com/trinodb/trino/commit/622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "message": "Add structural sanity check method to GroupedTopNRowNumberAccumulator\n\nThe structure has a lot of invariants that can be easily verified, and\nit is quite easy for developers to make mistakes when modifying this\ncode.", "committedDate": "2020-12-09T03:52:29Z", "type": "commit"}, {"oid": "622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "url": "https://github.com/trinodb/trino/commit/622be17edc76f48d688e9bbf6eb52b44ee50ab4b", "message": "Add structural sanity check method to GroupedTopNRowNumberAccumulator\n\nThe structure has a lot of invariants that can be easily verified, and\nit is quite easy for developers to make mistakes when modifying this\ncode.", "committedDate": "2020-12-09T03:52:29Z", "type": "forcePushed"}]}