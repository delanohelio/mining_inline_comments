{"pr_number": 5283, "pr_title": "Variable precision timestamp support for Hive write operations", "pr_createdAt": "2020-09-24T04:47:02Z", "pr_url": "https://github.com/trinodb/trino/pull/5283", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "83da8532cace3eee3bb5db13e6495e381240c0e5", "url": "https://github.com/trinodb/trino/commit/83da8532cace3eee3bb5db13e6495e381240c0e5", "message": "Variable precision timestamp support for Hive write operations", "committedDate": "2020-09-25T13:20:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAwODEzMg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495008132", "bodyText": "compare with TIMESTAMP_MILLIS using ==\n(this is intentionally supported; reads better)", "author": "findepi", "createdAt": "2020-09-25T14:00:42Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2377,11 +2375,12 @@ public TableStatisticsMetadata getStatisticsCollectionMetadata(ConnectorSession\n \n     private TableStatisticsMetadata getStatisticsCollectionMetadata(List<ColumnMetadata> columns, List<String> partitionedBy, Optional<Set<String>> analyzeColumns, boolean includeRowCount)\n     {\n-        validateTimestampColumns(columns);\n         Set<ColumnStatisticMetadata> columnStatistics = columns.stream()\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n+                // we only support stats collection at default precision for now\n+                .filter(column -> !(column.getType() instanceof TimestampType) || column.getType().equals(TIMESTAMP_MILLIS))", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAwOTA2NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495009065", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            // we only support stats collection at default precision for now\n          \n          \n            \n                            // TODO we only support stats collection at default precision for now", "author": "findepi", "createdAt": "2020-09-25T14:02:07Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2377,11 +2375,12 @@ public TableStatisticsMetadata getStatisticsCollectionMetadata(ConnectorSession\n \n     private TableStatisticsMetadata getStatisticsCollectionMetadata(List<ColumnMetadata> columns, List<String> partitionedBy, Optional<Set<String>> analyzeColumns, boolean includeRowCount)\n     {\n-        validateTimestampColumns(columns);\n         Set<ColumnStatisticMetadata> columnStatistics = columns.stream()\n                 .filter(column -> !partitionedBy.contains(column.getName()))\n                 .filter(column -> !column.isHidden())\n                 .filter(column -> analyzeColumns.isEmpty() || analyzeColumns.get().contains(column.getName()))\n+                // we only support stats collection at default precision for now", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNjg4MA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495016880", "bodyText": "IntSupplier -> int", "author": "findepi", "createdAt": "2020-09-25T14:13:20Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxNzkwNw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495017907", "bodyText": "This should be using actual type, not \"best type\"\npass the type from io.prestosql.plugin.hive.util.FieldSetterFactory#create here and use it", "author": "findepi", "createdAt": "2020-09-25T14:14:48Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n+            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n+        }\n+    }\n+\n+    private static class ShortTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n+        @Override\n+        public void setField(Block block, int position)\n+        {\n+            long micros = TIMESTAMP_MICROS.getLong(block, position);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxOTcxOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495019719", "bodyText": "up to millis precision is covered by epochMillis parameter, so\nmod MICROSECONDS_PER_SECOND should probably be mod MICROSECONDS_PER_MILLISECOND", "author": "findepi", "createdAt": "2020-09-25T14:17:32Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTA0NjE1Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495046152", "bodyText": "It's definitely no clear what's happening here, but the Timestamp we are returning is constructed from epoch millis and nanos of second (since it's using a java.time.LocalDateTime under the covers).  Pretty intuitive API, right?  I'll try to make this explicit.", "author": "aalbu", "createdAt": "2020-09-25T14:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAxOTcxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMjg4Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495022883", "bodyText": "This should be using actual type, not \"best type\"", "author": "findepi", "createdAt": "2020-09-25T14:22:17Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);\n+            return Timestamp.ofEpochMilli(epochMillis, nanosFromMicros + nanosFromPicos);\n+        }\n+    }\n+\n+    private static class ShortTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n+        @Override\n+        public void setField(Block block, int position)\n+        {\n+            long micros = TIMESTAMP_MICROS.getLong(block, position);\n+            Timestamp timestamp = getTimestamp(micros, () -> 0);\n+            value.set(timestamp);\n+            rowInspector.setStructFieldData(row, field, value);\n+        }\n+    }\n+\n+    private static class LongTimestampFieldSetter\n+            extends TimestampFieldSetter\n+    {\n+        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        {\n+            super(rowInspector, row, field, timeZone);\n+        }\n+\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMzUwNg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495023506", "bodyText": "should we have this for other formats in this class?", "author": "findepi", "createdAt": "2020-09-25T14:23:14Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java", "diffHunk": "@@ -291,16 +294,15 @@ public void testRcBinaryOptimizedWriter(int rowCount)\n     public void testOrc(int rowCount, long fileSizePadding)\n             throws Exception\n     {\n-        // Hive binary writers are broken for timestamps\n-        List<TestColumn> testColumns = TEST_COLUMNS.stream()\n-                .filter(TestHiveFileFormats::withoutTimestamps)\n-                .collect(toImmutableList());\n-\n-        assertThatFileFormat(ORC)\n-                .withColumns(testColumns)\n-                .withRowsCount(rowCount)\n-                .withFileSizePadding(fileSizePadding)\n-                .isReadableByPageSource(new OrcPageSourceFactory(new OrcReaderOptions(), HDFS_ENVIRONMENT, STATS, UTC));\n+        for (HiveTimestampPrecision timestampPrecision : List.of(MILLISECONDS, MICROSECONDS, NANOSECONDS)) {", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNzQxMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495037410", "bodyText": "I'll add more.", "author": "aalbu", "createdAt": "2020-09-25T14:44:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyMzUwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDA0OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495024048", "bodyText": "Is this relevant? or did you disable stats collection for timestamp != 3 for now?", "author": "findepi", "createdAt": "2020-09-25T14:24:04Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7238,6 +7261,8 @@ private Session withTimestampPrecision(Session session, String precision)\n     {\n         return Session.builder(session)\n                 .setCatalogSessionProperty(catalog, \"timestamp_precision\", precision)\n+                // TODO: remove when implementing https://github.com/prestosql/presto/issues/5170\n+                .setCatalogSessionProperty(catalog, \"collect_column_statistics_on_write\", \"false\")", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNTM4OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495035389", "bodyText": "Shouldn't be needed.  I missed it when I was cleaning up my code.", "author": "aalbu", "createdAt": "2020-09-25T14:40:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDA0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNDIyOA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495024228", "bodyText": "debug?", "author": "findepi", "createdAt": "2020-09-25T14:24:19Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -332,46 +332,269 @@ public void testSnappyCompressedParquetTableCreatedInHive()\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestamp(StorageFormat storageFormat)\n+    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n             throws Exception\n     {\n-        // only admin user is allowed to change session properties\n-        Connection connection = onPresto().getConnection();\n-        setAdminRole(connection);\n-        setSessionProperties(connection, storageFormat);\n-\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n-\n-        onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n+        setupTimestampData(tableName, storageFormat);\n+        // write precision is not relevant here, as Hive always uses nanos\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n-                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n-                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n \n         // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n         // (which only works when the value range has a min = max)\n         for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n         }\n \n+        runTimestampQueries(tableName, data);\n+    }\n+\n+    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n+    public void testTimestampCreatedFromPresto(StorageFormat storageFormat)\n+            throws Exception\n+    {\n+        String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n+        setupTimestampData(tableName, storageFormat);\n+\n+        // commenting out pre-epoch timestamps until https://github.com/prestosql/presto-hive-apache/pull/17 becomes available\n+        List<TimestampAndPrecision> data = ImmutableList.of(\n+//                new TimestampAndPrecision(\n+//                        \"MILLISECONDS\",\n+//                        \"1967-01-02 12:34:56.123\",\n+//                        ImmutableMap.of(", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNTczMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495025733", "bodyText": "Avoid java.time's objectful representation.\nCan we use LongTimestamp or something like DecodedTimestamp (rename to HiveTimestamp?)", "author": "findepi", "createdAt": "2020-09-25T14:26:30Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAzNjk5OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495036999", "bodyText": "I use this to format a timestamp with precision > milliseconds.  Since Joda only supports millisecond precision, I have to use java.time.", "author": "aalbu", "createdAt": "2020-09-25T14:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNTczMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNjEzNA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495026134", "bodyText": "micros floorMod  MICROSECONDS_PER_SECOND ?", "author": "findepi", "createdAt": "2020-09-25T14:27:07Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (type.isShort()) {\n+            long micros = type.getLong(block, position);\n+            long epochSeconds = floorDiv(micros, MICROSECONDS_PER_SECOND);\n+            // we know this fits in an int\n+            int nanosFraction = (int) ((micros - epochSeconds * MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTA3MTA0Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495071047", "bodyText": "I was just trying to avoid re-executing floorDiv(micros, MICROSECONDS_PER_SECOND), but it's the second or third time I'm getting a similar review comment, so I'll stop trying to micro-optimize \ud83d\ude09", "author": "aalbu", "createdAt": "2020-09-25T15:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyNjEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTAyODA4Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495028087", "bodyText": "nit: we could add int roundDiv(int,long) overload for cases iike this one\nyou can take https://github.com/findepi/presto/commits/round-div is you want to", "author": "findepi", "createdAt": "2020-09-25T14:29:54Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -361,24 +375,60 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private static class TimestampFieldSetter\n+    private abstract static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        private final DateTimeZone timeZone;\n-        private final TimestampWritableV2 value = new TimestampWritableV2();\n+        protected final DateTimeZone timeZone;\n+        protected final TimestampWritableV2 value = new TimestampWritableV2();\n \n         public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n+        protected Timestamp getTimestamp(long micros, IntSupplier picosSupplier)\n+        {\n+            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = (int) roundDiv(picosSupplier.getAsInt(), PICOSECONDS_PER_NANOSECOND);", "originalCommit": "83da8532cace3eee3bb5db13e6495e381240c0e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgzNDk3MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495834971", "bodyText": "PrestoTimestampEncoder is more complex than needed here. Since this is test code, let's keep it less coupled with the code under test. I think this should do\nlong micros = ((SqlTimestamp) value).getEpochMicros();\nif (((TimestampType) type).getPrecision() <= TimestampType.MAX_SHORT_PRECISION) {\n    type.writeLong(blockBuilder, micros);\n}\nelse {\n    type.writeObject(blockBuilder, new LongTimestamp(micros, ((SqlTimestamp) value).getPicosOfMicros()));\n}", "author": "findepi", "createdAt": "2020-09-28T10:18:11Z", "path": "presto-main/src/main/java/io/prestosql/testing/MaterializedResult.java", "diffHunk": "@@ -295,9 +303,8 @@ else if (type instanceof TimeWithTimeZoneType) {\n             type.writeLong(blockBuilder, packTimeWithTimeZone(nanos, offsetMinutes));\n         }\n         else if (type instanceof TimestampType) {\n-            long micros = ((SqlTimestamp) value).getEpochMicros();\n-            int precision = ((TimestampType) type).getPrecision();\n-            type.writeLong(blockBuilder, micros);\n+            PrestoTimestampEncoder<? extends Comparable<?>> timestampEncoder = PrestoTimestampEncoderFactory.createTimestampEncoder((TimestampType) type, DateTimeZone.UTC);\n+            timestampEncoder.write(toDecodedTimestamp((SqlTimestamp) value), blockBuilder);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDQwMg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497484402", "bodyText": "Bump. This seems not applied (at least not in Handle variable precision timestamps in MaterializedResult commit)", "author": "findepi", "createdAt": "2020-09-30T12:52:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgzNDk3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgzNTI0Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495835243", "bodyText": "this will become obsolete if you follow my recommendation above", "author": "findepi", "createdAt": "2020-09-28T10:18:46Z", "path": "presto-main/src/main/java/io/prestosql/testing/MaterializedResult.java", "diffHunk": "@@ -338,6 +345,13 @@ else if (type instanceof RowType) {\n         }\n     }\n \n+    private static DecodedTimestamp toDecodedTimestamp(SqlTimestamp sqlTimestamp)\n+    {\n+        long epochSeconds = floorDiv(sqlTimestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n+        int nanosOfSecond = floorMod(sqlTimestamp.getEpochMicros(), MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND + roundDiv(sqlTimestamp.getPicosOfMicros(), PICOSECONDS_PER_NANOSECOND);\n+        return new DecodedTimestamp(epochSeconds, nanosOfSecond);\n+    }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTgzNTg0MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495835841", "bodyText": "microsOfEpoch -> epochMicros", "author": "findepi", "createdAt": "2020-09-28T10:19:56Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -374,60 +368,31 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final Type type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, Type type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, int picosOfMicro)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosOfSecondFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = roundDiv(picosOfMicro, PICOSECONDS_PER_NANOSECOND);\n-            // note that the nanos argument represents the nanos of second fraction, not nanos of millis, as one might expect\n-            return Timestamp.ofEpochMilli(epochMillis, nanosOfSecondFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, 0);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n-        }\n-    }\n-\n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp.getPicosOfMicro());\n+            LongTimestamp longTimestamp = longTimestampRepresentation(block, position, (TimestampType) type);\n+            long microsOfEpoch = longTimestamp.getEpochMicros();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0MjE0MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495842141", "bodyText": "Since the millis part is passed twice (\ud83d\ude31  i know), we actually assume that timeZone.convertLocalToUTC(epochMillis, false) will not change the miilis part of the epochMillis (reasonable assumption). So we can simplify the code greatly by replacing epochMillis with epochSeconds.\nMaybe sth along\n        @Override\n        public void setField(Block block, int position)\n        {\n            LongTimestamp longTimestamp = longTimestampRepresentation(block, position, (TimestampType) type);\n\n            long epochSeconds = floorDiv(longTimestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n            long picosOfSecond = (long) floorMod(longTimestamp.getEpochMicros(), MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n                    longTimestamp.getPicosOfMicro();\n\n            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n\n            int nanosOfSecond = toIntExact(roundDiv(picosOfSecond, PICOSECONDS_PER_NANOSECOND));\n            if (nanosOfSecond == NANOSECONDS_PER_SECOND) {\n                // TODO add a test case for second overflow when rounding picos to nanos\n                epochSeconds++;\n                nanosOfSecond = 0;\n            }\n\n            Timestamp timestamp = Timestamp.ofEpochMilli(epochSeconds * MILLISECONDS_PER_SECOND, nanosOfSecond);\n            value.set(timestamp);\n            rowInspector.setStructFieldData(row, field, value);\n        }\n\n        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n        {\n            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n            verify(epochMillis % MILLISECONDS_PER_SECOND == 0, \"Invalid epochMillis after converting epochSeconds %s with zone %s: %s\", epochSeconds, timeZone, epochMillis);\n            return epochMillis / MILLISECONDS_PER_SECOND;\n        }", "author": "findepi", "createdAt": "2020-09-28T10:32:08Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -374,60 +368,31 @@ public void setField(Block block, int position)\n         }\n     }\n \n-    private abstract static class TimestampFieldSetter\n+    private static class TimestampFieldSetter\n             extends FieldSetter\n     {\n-        protected final DateTimeZone timeZone;\n-        protected final TimestampWritableV2 value = new TimestampWritableV2();\n+        private final DateTimeZone timeZone;\n+        private final Type type;\n+        private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, Type type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n-        protected Timestamp getTimestamp(long micros, int picosOfMicro)\n-        {\n-            long epochMillis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n-            int nanosOfSecondFromMicros = floorMod(micros, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n-            int nanosFromPicos = roundDiv(picosOfMicro, PICOSECONDS_PER_NANOSECOND);\n-            // note that the nanos argument represents the nanos of second fraction, not nanos of millis, as one might expect\n-            return Timestamp.ofEpochMilli(epochMillis, nanosOfSecondFromMicros + nanosFromPicos);\n-        }\n-    }\n-\n-    private static class ShortTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public ShortTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n         @Override\n         public void setField(Block block, int position)\n         {\n-            long micros = TIMESTAMP_MICROS.getLong(block, position);\n-            Timestamp timestamp = getTimestamp(micros, 0);\n-            value.set(timestamp);\n-            rowInspector.setStructFieldData(row, field, value);\n-        }\n-    }\n-\n-    private static class LongTimestampFieldSetter\n-            extends TimestampFieldSetter\n-    {\n-        public LongTimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n-        {\n-            super(rowInspector, row, field, timeZone);\n-        }\n-\n-        @Override\n-        public void setField(Block block, int position)\n-        {\n-            LongTimestamp longTimestamp = (LongTimestamp) TIMESTAMP_NANOS.getObject(block, position);\n-            Timestamp timestamp = getTimestamp(longTimestamp.getEpochMicros(), longTimestamp.getPicosOfMicro());\n+            LongTimestamp longTimestamp = longTimestampRepresentation(block, position, (TimestampType) type);\n+            long microsOfEpoch = longTimestamp.getEpochMicros();\n+            long epochMillis = floorDiv(microsOfEpoch, MICROSECONDS_PER_MILLISECOND);\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            int nanosOfSecondFromMicros = floorMod(microsOfEpoch, MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND;\n+            int nanosFromPicos = roundDiv(longTimestamp.getPicosOfMicro(), PICOSECONDS_PER_NANOSECOND);\n+            // note that the nanos argument represents the nanos of second fraction, not nanos of millis, as one might expect\n+            Timestamp timestamp = Timestamp.ofEpochMilli(epochMillis, nanosOfSecondFromMicros + nanosFromPicos);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0MjQzOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495842439", "bodyText": "is it a TODO ?\n(same in other places with thgis comment)", "author": "findepi", "createdAt": "2020-09-28T10:32:37Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java", "diffHunk": "@@ -240,12 +240,17 @@ public void testRcTextOptimizedWriter(int rowCount)\n                 .filter(TestHiveFileFormats::withoutNullMapKeyTests)\n                 .collect(toImmutableList());\n \n-        assertThatFileFormat(RCTEXT)\n-                .withColumns(testColumns)\n-                .withRowsCount(rowCount)\n-                .withFileWriterFactory(new RcFileFileWriterFactory(HDFS_ENVIRONMENT, TYPE_MANAGER, new NodeVersion(\"test\"), HIVE_STORAGE_TIME_ZONE, STATS))\n-                .isReadableByRecordCursor(createGenericHiveRecordCursorProvider(HDFS_ENVIRONMENT))\n-                .isReadableByPageSource(new RcFilePageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HiveConfig()));\n+        // the test writes longs, so we can't use nanos precision", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg3OTkzMg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495879932", "bodyText": "No, it's an explanation for why we're not testing nanosecond precision.  This test generates a bunch of longs and uses them to populate columns of various types.  For timestamps, the test data can only become a short timestamp.", "author": "aalbu", "createdAt": "2020-09-28T11:49:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0MjQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0Mjg0OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495842848", "bodyText": "?", "author": "findepi", "createdAt": "2020-09-28T10:33:29Z", "path": "presto-orc/src/main/java/io/prestosql/orc/writer/TimestampColumnWriter.java", "diffHunk": "@@ -191,10 +194,10 @@ public void writeBlock(Block block)\n         switch (timestampKind) {\n             case TIMESTAMP_MILLIS:\n             case TIMESTAMP_MICROS:\n-                writeTimestampMicros(block);\n-                break;\n+//                writeTimestampMicros(block);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MTQ4OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495891488", "bodyText": "I'll clean up.", "author": "aalbu", "createdAt": "2020-09-28T12:12:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0Mjg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0Mzc2OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495843768", "bodyText": "@electrum this was not intentional?", "author": "findepi", "createdAt": "2020-09-28T10:35:22Z", "path": "presto-orc/src/main/java/io/prestosql/orc/writer/TimestampColumnWriter.java", "diffHunk": "@@ -316,36 +319,17 @@ public void reset()\n         statisticsBuilder = statisticsBuilderSupplier.get();\n     }\n \n-    private void writeTimestampMicros(Block block)\n-    {\n-        for (int i = 0; i < block.getPositionCount(); i++) {\n-            if (!block.isNull(i)) {\n-                long micros = type.getLong(block, i);\n-\n-                // ORC erroneously uses normal division for seconds\n-                long seconds = micros / MICROSECONDS_PER_SECOND;\n-                long microsFraction = floorMod(micros, MICROSECONDS_PER_SECOND);\n-                long nanosFraction = microsFraction * NANOSECONDS_PER_MICROSECOND;\n-\n-                long millis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-\n-                writeValues(seconds, nanosFraction);\n-                statisticsBuilder.addValue(millis);\n-            }\n-        }\n-    }\n-\n-    private void writeTimestampNanos(Block block)\n+    private void writeTimestamp(Block block)\n     {\n         for (int i = 0; i < block.getPositionCount(); i++) {\n             if (!block.isNull(i)) {\n-                LongTimestamp timestamp = (LongTimestamp) type.getObject(block, i);\n+                LongTimestamp timestamp = longTimestampRepresentation(block, i, (TimestampType) type);\n \n                 // ORC erroneously uses normal division for seconds\n                 long seconds = timestamp.getEpochMicros() / MICROSECONDS_PER_SECOND;\n                 long microsFraction = floorMod(timestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n                 long nanosFraction = (microsFraction * NANOSECONDS_PER_MICROSECOND) +\n-                        (timestamp.getPicosOfMicro() / PICOSECONDS_PER_NANOSECOND);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2ODM4NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496868385", "bodyText": "This change is not needed, since this code is specifically for timestamp(9) and thus there is no difference between truncation and rounding. Please remove the roundDiv and if as it's not needed.", "author": "electrum", "createdAt": "2020-09-29T16:19:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0Mzc2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NDI5MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495844291", "bodyText": "i am concerned about perf overhead of using LongTimestamp always.\n@dain ?", "author": "findepi", "createdAt": "2020-09-28T10:36:26Z", "path": "presto-orc/src/main/java/io/prestosql/orc/writer/TimestampColumnWriter.java", "diffHunk": "@@ -316,36 +319,17 @@ public void reset()\n         statisticsBuilder = statisticsBuilderSupplier.get();\n     }\n \n-    private void writeTimestampMicros(Block block)\n-    {\n-        for (int i = 0; i < block.getPositionCount(); i++) {\n-            if (!block.isNull(i)) {\n-                long micros = type.getLong(block, i);\n-\n-                // ORC erroneously uses normal division for seconds\n-                long seconds = micros / MICROSECONDS_PER_SECOND;\n-                long microsFraction = floorMod(micros, MICROSECONDS_PER_SECOND);\n-                long nanosFraction = microsFraction * NANOSECONDS_PER_MICROSECOND;\n-\n-                long millis = floorDiv(micros, MICROSECONDS_PER_MILLISECOND);\n-\n-                writeValues(seconds, nanosFraction);\n-                statisticsBuilder.addValue(millis);\n-            }\n-        }\n-    }\n-\n-    private void writeTimestampNanos(Block block)\n+    private void writeTimestamp(Block block)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NDgwOA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495844808", "bodyText": "the conditions should be based on type.precision\nthe actual block representation can be many different things (like RLEBlock, DictionaryBlock, LazyBlock, etc)", "author": "findepi", "createdAt": "2020-09-28T10:37:33Z", "path": "presto-plugin-toolkit/src/main/java/io/prestosql/plugin/base/type/TimestampRepresentations.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.base.type;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.Int96ArrayBlock;\n+import io.prestosql.spi.block.LongArrayBlock;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+import org.joda.time.DateTimeZone;\n+\n+import static io.prestosql.spi.type.TimestampType.MAX_SHORT_PRECISION;\n+import static io.prestosql.spi.type.TimestampType.TIMESTAMP_MICROS;\n+import static io.prestosql.spi.type.TimestampType.TIMESTAMP_MILLIS;\n+import static io.prestosql.spi.type.TimestampType.TIMESTAMP_NANOS;\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_MILLISECOND;\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.epochMicrosToMillisWithRounding;\n+import static io.prestosql.spi.type.Timestamps.round;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.multiplyExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public final class TimestampRepresentations\n+{\n+    private TimestampRepresentations() {}\n+\n+    public static PrestoTimestampEncoder<? extends Comparable<?>> createTimestampEncoder(TimestampType type, DateTimeZone timeZone)\n+    {\n+        requireNonNull(type, \"type is null\");\n+        requireNonNull(timeZone, \"timeZoneKey is null\");\n+\n+        if (type.isShort()) {\n+            return new ShortTimestampEncoder(type, timeZone);\n+        }\n+        return new LongTimestampEncoder(type, timeZone);\n+    }\n+\n+    // copied from io.prestosql.type.DateTimes\n+    static LongTimestamp longTimestamp(long epochSecond, long fractionInPicos)\n+    {\n+        return new LongTimestamp(\n+                multiplyExact(epochSecond, MICROSECONDS_PER_SECOND) + fractionInPicos / PICOSECONDS_PER_MICROSECOND,\n+                (int) (fractionInPicos % PICOSECONDS_PER_MICROSECOND));\n+    }\n+\n+    /**\n+     * Provide a canonical representation of the timestamp at the given position in the block with the precision\n+     * of the target type.  Uses {@link LongTimestamp}, since it can represent any valid precision.  This is\n+     * effectively a cast to a different precision timestamp and is useful in CTAS, when the engine won't do the\n+     * cast for us.\n+     */\n+    public static LongTimestamp longTimestampRepresentation(Block block, int position, TimestampType type)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+\n+        if (block instanceof LongArrayBlock) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MDIxNQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495890215", "bodyText": "type represents the destination.  That does not tell us anything about the source precision.  What's a good mechanism to figure out whether we're dealing with long or short timestamps?", "author": "aalbu", "createdAt": "2020-09-28T12:10:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NDgwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjE2Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495846166", "bodyText": "if the type == TIMESTAMP_MILLIS the data coming in should have zeroed out micros part, so the rounding should not be necessary. Is it necessary due to CTAS flow? At least a comment, but we should talk this through.", "author": "findepi", "createdAt": "2020-09-28T10:39:54Z", "path": "presto-plugin-toolkit/src/main/java/io/prestosql/plugin/base/type/TimestampRepresentations.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.base.type;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.block.Int96ArrayBlock;\n+import io.prestosql.spi.block.LongArrayBlock;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+import org.joda.time.DateTimeZone;\n+\n+import static io.prestosql.spi.type.TimestampType.MAX_SHORT_PRECISION;\n+import static io.prestosql.spi.type.TimestampType.TIMESTAMP_MICROS;\n+import static io.prestosql.spi.type.TimestampType.TIMESTAMP_MILLIS;\n+import static io.prestosql.spi.type.TimestampType.TIMESTAMP_NANOS;\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_MILLISECOND;\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.epochMicrosToMillisWithRounding;\n+import static io.prestosql.spi.type.Timestamps.round;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.multiplyExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public final class TimestampRepresentations\n+{\n+    private TimestampRepresentations() {}\n+\n+    public static PrestoTimestampEncoder<? extends Comparable<?>> createTimestampEncoder(TimestampType type, DateTimeZone timeZone)\n+    {\n+        requireNonNull(type, \"type is null\");\n+        requireNonNull(timeZone, \"timeZoneKey is null\");\n+\n+        if (type.isShort()) {\n+            return new ShortTimestampEncoder(type, timeZone);\n+        }\n+        return new LongTimestampEncoder(type, timeZone);\n+    }\n+\n+    // copied from io.prestosql.type.DateTimes\n+    static LongTimestamp longTimestamp(long epochSecond, long fractionInPicos)\n+    {\n+        return new LongTimestamp(\n+                multiplyExact(epochSecond, MICROSECONDS_PER_SECOND) + fractionInPicos / PICOSECONDS_PER_MICROSECOND,\n+                (int) (fractionInPicos % PICOSECONDS_PER_MICROSECOND));\n+    }\n+\n+    /**\n+     * Provide a canonical representation of the timestamp at the given position in the block with the precision\n+     * of the target type.  Uses {@link LongTimestamp}, since it can represent any valid precision.  This is\n+     * effectively a cast to a different precision timestamp and is useful in CTAS, when the engine won't do the\n+     * cast for us.\n+     */\n+    public static LongTimestamp longTimestampRepresentation(Block block, int position, TimestampType type)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+\n+        if (block instanceof LongArrayBlock) {\n+            long epochMicros = TIMESTAMP_MICROS.getLong(block, position);\n+            if (type == TIMESTAMP_MILLIS) {\n+                epochMicros = epochMicrosToMillisWithRounding(epochMicros) * MICROSECONDS_PER_MILLISECOND;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MDM5OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495890399", "bodyText": "See comment above.", "author": "aalbu", "createdAt": "2020-09-28T12:10:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjE2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjM5Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495846392", "bodyText": "what are these cases going away now?", "author": "findepi", "createdAt": "2020-09-28T10:40:19Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -454,99 +454,49 @@ public void testTimestampCreatedFromPresto(StorageFormat storageFormat)\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n         setupTimestampData(tableName, storageFormat);\n \n-        // commenting out pre-epoch timestamps until https://github.com/prestosql/presto-hive-apache/pull/17 becomes available\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-//                new TimestampAndPrecision(\n-//                        \"MILLISECONDS\",\n-//                        \"1967-01-02 12:34:56.123\",\n-//                        ImmutableMap.of(\n-//                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n-//                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n-//                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n                 new TimestampAndPrecision(\n                         \"MILLISECONDS\",\n                         \"2020-01-02 12:34:56.123\",\n                         ImmutableMap.of(\n                                 \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n                                 \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n                                 \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n-//                new TimestampAndPrecision(\n-//                        \"MILLISECONDS\",\n-//                        \"1967-01-02 12:34:56.1234\",\n-//                        ImmutableMap.of(\n-//                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQzMDc4Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496430783", "bodyText": "These are waiting for trinodb/trino-hive-apache#17", "author": "aalbu", "createdAt": "2020-09-29T05:43:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjM5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4MTAwMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497481001", "bodyText": "Seems has been released ( 3.1.2-4)", "author": "findepi", "createdAt": "2020-09-30T12:47:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjM5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjUxMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495846510", "bodyText": "?", "author": "findepi", "createdAt": "2020-09-28T10:40:35Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -33,20 +34,32 @@ private TimestampUtils() {}\n \n     public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n     {\n-        if (type.isShort()) {\n-            long micros = type.getLong(block, position);\n-            long epochSeconds = floorDiv(micros, MICROSECONDS_PER_SECOND);\n-            // we know this fits in an int\n-            int nanosFraction = (int) ((micros - epochSeconds * MICROSECONDS_PER_SECOND) * NANOSECONDS_PER_MICROSECOND);\n-            return LocalDateTime.ofEpochSecond(epochSeconds, nanosFraction, ZoneOffset.UTC);\n-        }\n-        else {\n-            LongTimestamp timestamp = (LongTimestamp) type.getObject(block, position);\n-            long epochSeconds = floorDiv(timestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n-            long microsFraction = floorMod(timestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n-            // we know this fits in an int\n-            int nanosFraction = (int) (microsFraction * NANOSECONDS_PER_MICROSECOND + roundDiv(timestamp.getPicosOfMicro(), PICOSECONDS_PER_NANOSECOND));\n-            return LocalDateTime.ofEpochSecond(epochSeconds, nanosFraction, ZoneOffset.UTC);\n+        LongTimestamp timestamp = longTimestampRepresentation(block, position, type);\n+        if (timestamp == null) {\n+            return null;\n         }\n+        long epochSeconds = floorDiv(timestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n+        long microsFraction = floorMod(timestamp.getEpochMicros(), MICROSECONDS_PER_SECOND);\n+        // we know this fits in an int\n+        int nanosFraction = (int) (microsFraction * NANOSECONDS_PER_MICROSECOND + roundDiv(timestamp.getPicosOfMicro(), PICOSECONDS_PER_NANOSECOND));\n+\n+        return LocalDateTime.ofEpochSecond(epochSeconds, nanosFraction, ZoneOffset.UTC);\n+//        if (type.isShort()) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg5MjM4NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495892385", "bodyText": "Ugh, sorry.", "author": "aalbu", "createdAt": "2020-09-28T12:14:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NjUxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NzMwOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495847309", "bodyText": "is NANOSECONDS covered elsewhere?\nalso, why testRcTextOptimizedWriter loops over precisions and eg testOrc does not?", "author": "findepi", "createdAt": "2020-09-28T10:42:17Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveFileFormats.java", "diffHunk": "@@ -240,12 +240,17 @@ public void testRcTextOptimizedWriter(int rowCount)\n                 .filter(TestHiveFileFormats::withoutNullMapKeyTests)\n                 .collect(toImmutableList());\n \n-        assertThatFileFormat(RCTEXT)\n-                .withColumns(testColumns)\n-                .withRowsCount(rowCount)\n-                .withFileWriterFactory(new RcFileFileWriterFactory(HDFS_ENVIRONMENT, TYPE_MANAGER, new NodeVersion(\"test\"), HIVE_STORAGE_TIME_ZONE, STATS))\n-                .isReadableByRecordCursor(createGenericHiveRecordCursorProvider(HDFS_ENVIRONMENT))\n-                .isReadableByPageSource(new RcFilePageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HiveConfig()));\n+        // the test writes longs, so we can't use nanos precision\n+        for (HiveTimestampPrecision timestampPrecision : List.of(MILLISECONDS, MICROSECONDS)) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4Mzg4Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r495883887", "bodyText": "TestHiveIntegrationSmokeTest and TestHiveStorageFormats cover all timestamp precisions.\ntestOrc writes to the table using RecordWriter.  testOrcOptimizedWriter loops over precisions.\nThe tests in TestHiveIntegrationSmokeTest are more comprehensive, so if these are confusing, I might just get rid of them.", "author": "aalbu", "createdAt": "2020-09-28T11:57:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg0NzMwOQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg2Nzg5NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496867895", "bodyText": "Good catch on the unused method, but please remove in a separate commit, since it's unrelated to adding precision support.", "author": "electrum", "createdAt": "2020-09-29T16:19:11Z", "path": "presto-orc/src/main/java/io/prestosql/orc/writer/TimestampColumnWriter.java", "diffHunk": "@@ -316,15 +318,6 @@ public void reset()\n         statisticsBuilder = statisticsBuilderSupplier.get();\n     }\n \n-    private void writeTimestampMillis(Block block)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3MDQyOA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496870428", "bodyText": "This looks like an unrelated cleanup, please move to separate commit.", "author": "electrum", "createdAt": "2020-09-29T16:21:35Z", "path": "presto-orc/src/test/java/io/prestosql/orc/OrcTester.java", "diffHunk": "@@ -1041,7 +1041,7 @@ private static Object preprocessWriteValueHive(Type type, Object value)\n         }\n         if (type.equals(TIMESTAMP_TZ_MILLIS) || type.equals(TIMESTAMP_TZ_MICROS) || type.equals(TIMESTAMP_TZ_NANOS)) {\n             SqlTimestampWithTimeZone timestamp = (SqlTimestampWithTimeZone) value;\n-            int nanosOfMilli = toIntExact(roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3NDAxOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496874019", "bodyText": "Either move this into the Hive connector or revert this change -- we shouldn't have a Hive specific class name in the plugin-toolkit module.", "author": "electrum", "createdAt": "2020-09-29T16:25:05Z", "path": "presto-plugin-toolkit/src/main/java/io/prestosql/plugin/base/type/HiveFileTimestamp.java", "diffHunk": "@@ -16,14 +16,14 @@\n import static com.google.common.base.Preconditions.checkArgument;\n import static java.util.concurrent.TimeUnit.SECONDS;\n \n-public class DecodedTimestamp\n+public class HiveFileTimestamp", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3OTAwNA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496879004", "bodyText": "This type of rename should be done as a separate commit, as that makes it easier to review.", "author": "electrum", "createdAt": "2020-09-29T16:31:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3NDAxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3NDkyMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496874920", "bodyText": "Don't wrap here arbitrarily.", "author": "electrum", "createdAt": "2020-09-29T16:25:56Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+        long epochMicros;\n+        long picosOfSecond;\n+        if (type.isShort()) {\n+            epochMicros = type.getLong(block, position);\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+        }\n+        else {\n+            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+            epochMicros = longTimestamp.getEpochMicros();\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                    longTimestamp.getPicosOfMicro();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3NTczMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496875733", "bodyText": "This rounding is not needed since we don't support picosecond precision and thus will never have fractional nanos.", "author": "electrum", "createdAt": "2020-09-29T16:26:46Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.NANOSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static io.prestosql.spi.type.Timestamps.roundDiv;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+        long epochMicros;\n+        long picosOfSecond;\n+        if (type.isShort()) {\n+            epochMicros = type.getLong(block, position);\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+        }\n+        else {\n+            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+            epochMicros = longTimestamp.getEpochMicros();\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                    longTimestamp.getPicosOfMicro();\n+        }\n+        long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+        int nanosOfSecond = toIntExact(roundDiv(picosOfSecond, PICOSECONDS_PER_NANOSECOND));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3NjQ0Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496876446", "bodyText": "Do this change (along with updating callers) in a separate commit.", "author": "electrum", "createdAt": "2020-09-29T16:27:47Z", "path": "presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java", "diffHunk": "@@ -102,6 +102,11 @@ private static long scaleFactor(int fromPrecision, int toPrecision)\n         return POWERS_OF_TEN[toPrecision - fromPrecision];\n     }\n \n+    public static int roundDiv(int value, long factor)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3NjkzMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496876930", "bodyText": "These variables can be inlined", "author": "electrum", "createdAt": "2020-09-29T16:28:31Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/binary/TimestampEncoding.java", "diffHunk": "@@ -55,7 +58,8 @@ public void encodeColumn(Block block, SliceOutput output, EncodeOutput encodeOut\n     {\n         for (int position = 0; position < block.getPositionCount(); position++) {\n             if (!block.isNull(position)) {\n-                writeTimestamp(output, floorDiv(type.getLong(block, position), MICROSECONDS_PER_MILLISECOND));\n+                LocalDateTime localDateTime = getLocalDateTime(type, block, position);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg3OTI4Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496879282", "bodyText": "This rounding is not necessary", "author": "electrum", "createdAt": "2020-09-29T16:31:57Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -365,22 +373,51 @@ public void setField(Block block, int position)\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n+        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            int nanosOfSecond = toIntExact(roundDiv(picosOfSecond, PICOSECONDS_PER_NANOSECOND));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDY1NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r496880655", "bodyText": "We don't need this check as time zones have second precision at most. This would be a major bug in Joda-Time that we shouldn't need to verify for every call.", "author": "electrum", "createdAt": "2020-09-29T16:33:53Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -365,22 +373,51 @@ public void setField(Block block, int position)\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n+        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            long epochMicros;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +\n+                        longTimestamp.getPicosOfMicro();\n+            }\n+            long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            epochSeconds = convertLocalEpochSecondsToUtc(epochSeconds);\n+            int nanosOfSecond = toIntExact(roundDiv(picosOfSecond, PICOSECONDS_PER_NANOSECOND));\n+            if (nanosOfSecond == NANOSECONDS_PER_SECOND) {\n+                epochSeconds++;\n+                nanosOfSecond = 0;\n+            }\n+\n+            Timestamp timestamp = Timestamp.ofEpochSecond(epochSeconds, nanosOfSecond);\n+            value.set(timestamp);\n             rowInspector.setStructFieldData(row, field, value);\n         }\n+\n+        private long convertLocalEpochSecondsToUtc(long epochSeconds)\n+        {\n+            long epochMillis = epochSeconds * MILLISECONDS_PER_SECOND;\n+            epochMillis = timeZone.convertLocalToUTC(epochMillis, false);\n+            verify(epochMillis % MILLISECONDS_PER_SECOND == 0, \"Invalid epochMillis after converting epochSeconds %s with zone %s: %s\", epochSeconds, timeZone, epochMillis);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4MjI1OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497482259", "bodyText": "@electrum see #5283 (comment)", "author": "findepi", "createdAt": "2020-09-30T12:49:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDY1NQ=="}], "type": "inlineReview"}, {"oid": "1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "url": "https://github.com/trinodb/trino/commit/1fc9aa8a1e5457407766a5c3bf37031e1857ec66", "message": "Minor ORC cleanup", "committedDate": "2020-09-30T00:37:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDkxMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497484911", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return (int) roundDiv((long) value, factor);\n          \n          \n            \n                    //noinspection NumericCastThatLosesPrecision\n          \n          \n            \n                    return (int) roundDiv((long) value, factor);", "author": "findepi", "createdAt": "2020-09-30T12:53:22Z", "path": "presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java", "diffHunk": "@@ -102,6 +102,11 @@ private static long scaleFactor(int fromPrecision, int toPrecision)\n         return POWERS_OF_TEN[toPrecision - fromPrecision];\n     }\n \n+    public static int roundDiv(int value, long factor)\n+    {\n+        return (int) roundDiv((long) value, factor);", "originalCommit": "c5ac163b6c06959713acfbe6c88bcaa4596d14eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzgxMzYyMw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497813623", "bodyText": "I've added the inspection to my IDE \ud83d\ude00", "author": "aalbu", "createdAt": "2020-09-30T21:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NDkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4NjI0MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497486241", "bodyText": "Add a\n// TODO validate timestamps in structural types\n\n+ issue", "author": "findepi", "createdAt": "2020-09-30T12:55:19Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2596,13 +2597,13 @@ private static void validateColumns(ConnectorTableMetadata tableMetadata)\n     }\n \n     // temporary, until variable precision timestamps are supported on write\n-    private static void validateTimestampColumns(List<ColumnMetadata> columns)\n+    private static void validateTimestampColumns(List<ColumnMetadata> columns, HiveTimestampPrecision timestampPrecision)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQ4ODA3NA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497488074", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        long epochMicros;\n          \n          \n            \n                        long epochSeconds;\n          \n      \n    \n    \n  \n\ndeclare epochSeconds and picosOfSecond outside and declare epochMicros separately inside of both branches\nthis will make the conversion easier to follow and verify correctness (micros, picosOfMicro, picosOfSecond), at the cost of writing epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND); twice", "author": "findepi", "createdAt": "2020-09-30T12:58:05Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -365,22 +370,47 @@ public void setField(Block block, int position)\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n+        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            long epochMicros;", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU0ODk0OQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497548949", "bodyText": "since it's always used together with TIMESTAMP '%s', it would be more convenient to define\nprivate static String formatTimestamp(LocalDateTime) \n\nthe formatter can be inline in that method (or a const) -- perf doesnt matter", "author": "findepi", "createdAt": "2020-09-30T14:20:43Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -161,6 +160,7 @@\n public class TestHiveIntegrationSmokeTest\n         extends AbstractTestIntegrationSmokeTest\n {\n+    private static final DateTimeFormatter TIMESTAMP_FORMATTER = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss.SSSSSSSSS\");", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MDU1Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497550556", "bodyText": "co we have correctness tests ensure\nWHERE col < actual_value + 1 nanosecond\n\ndoesn't filter out col = actual_value (for col being full millis .... h:m:s.001000000 or not: .... h:m:s.001000001)", "author": "findepi", "createdAt": "2020-09-30T14:22:47Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4209,7 +4206,44 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+            sleeper.sleep();\n+            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n+        });\n+    }\n+\n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MDgyOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497550829", "bodyText": "link to gh issue about that (#5172 right?)", "author": "findepi", "createdAt": "2020-09-30T14:23:08Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4209,7 +4206,44 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value)));\n+            sleeper.sleep();\n+            assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n+        });\n+    }\n+\n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (TIMESTAMP '%s')\", TIMESTAMP_FORMATTER.format(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning\n+        DistributedQueryRunner queryRunner = (DistributedQueryRunner) getQueryRunner();\n+        ResultWithQueryId<MaterializedResult> queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.minusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t > TIMESTAMP '%s'\", TIMESTAMP_FORMATTER.format(value.plusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        // TODO: replace this with a simple query stats check once we find a way to wait until all pending updates to query stats have been applied", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MTYzMQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497551631", "bodyText": "nit \"\\\\E\" is probably redundant", "author": "findepi", "createdAt": "2020-09-30T14:24:07Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7078,6 +7092,148 @@ public void testUnsupportedCsvTable()\n                 \"\\\\QHive CSV storage format only supports VARCHAR (unbounded). Unsupported columns: i integer, bound varchar(10)\\\\E\");\n     }\n \n+    @Test\n+    public void testWriteInvalidPrecisionTimestamp()\n+    {\n+        Session session = withTimestampPrecision(getSession(), HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123456789'\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS + \"\\\\E\");", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1MzA4Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497553086", "bodyText": "i like the change but it belongs to the prep commit, not Variable precision timestamp support for Hive write operations", "author": "findepi", "createdAt": "2020-09-30T14:25:56Z", "path": "presto-main/src/main/java/io/prestosql/testing/MaterializedResult.java", "diffHunk": "@@ -345,13 +343,6 @@ else if (type instanceof RowType) {\n         }\n     }\n \n-    private static DecodedTimestamp toDecodedTimestamp(SqlTimestamp sqlTimestamp)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1Mzg1Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497553853", "bodyText": "why did we gain toIntExact here?", "author": "findepi", "createdAt": "2020-09-30T14:26:53Z", "path": "presto-orc/src/test/java/io/prestosql/orc/OrcTester.java", "diffHunk": "@@ -1041,7 +1041,7 @@ private static Object preprocessWriteValueHive(Type type, Object value)\n         }\n         if (type.equals(TIMESTAMP_TZ_MILLIS) || type.equals(TIMESTAMP_TZ_MICROS) || type.equals(TIMESTAMP_TZ_NANOS)) {\n             SqlTimestampWithTimeZone timestamp = (SqlTimestampWithTimeZone) value;\n-            int nanosOfMilli = roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND);\n+            int nanosOfMilli = toIntExact(roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND));", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU3OTg4Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497579882", "bodyText": "I messed up during a merge while trying to move this change to its own commit (per David's suggestion).  I'll clean up.", "author": "aalbu", "createdAt": "2020-09-30T14:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1Mzg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1NjI0Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497556247", "bodyText": "storage_formats tests are run multiple times, on many different environments, since file format behavior may interact with things like kerberos, impersonation\nthese tests do not need to run multiple times, and i guess they take quite some time (correct?)\nwe can move them to separate group\nor, we can have them without a group (then will be run in suite-1, on multine)\n-- in any case it'd be good to document the reason for this in a code comment\nor move the tests to a spearate class", "author": "findepi", "createdAt": "2020-09-30T14:29:29Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -332,46 +332,219 @@ public void testSnappyCompressedParquetTableCreatedInHive()\n     }\n \n     @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)\n-    public void testTimestamp(StorageFormat storageFormat)\n+    public void testTimestampCreatedFromHive(StorageFormat storageFormat)\n             throws Exception\n     {\n-        // only admin user is allowed to change session properties\n-        Connection connection = onPresto().getConnection();\n-        setAdminRole(connection);\n-        setSessionProperties(connection, storageFormat);\n-\n         String tableName = \"test_timestamp_\" + storageFormat.getName().toLowerCase(Locale.ENGLISH);\n-        onPresto().executeQuery(\"DROP TABLE IF EXISTS \" + tableName);\n-\n-        onPresto().executeQuery(format(\"CREATE TABLE %s (id BIGINT, ts TIMESTAMP) WITH (%s)\", tableName, storageFormat.getStoragePropertiesAsSql()));\n+        setupTimestampData(tableName, storageFormat);\n+        // write precision is not relevant here, as Hive always uses nanos\n         List<TimestampAndPrecision> data = ImmutableList.of(\n-                new TimestampAndPrecision(1, \"MILLISECONDS\", \"2020-01-02 12:34:56.123\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(2, \"MILLISECONDS\", \"2020-01-02 12:34:56.1234\", \"2020-01-02 12:34:56.123\"),\n-                new TimestampAndPrecision(3, \"MILLISECONDS\", \"2020-01-02 12:34:56.1236\", \"2020-01-02 12:34:56.124\"),\n-                new TimestampAndPrecision(4, \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(5, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234564\", \"2020-01-02 12:34:56.123456\"),\n-                new TimestampAndPrecision(6, \"MICROSECONDS\", \"2020-01-02 12:34:56.1234567\", \"2020-01-02 12:34:56.123457\"),\n-                new TimestampAndPrecision(7, \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\", \"2020-01-02 12:34:56.123456789\"));\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1234\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1236\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.124\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.1236\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1236\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234564\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123456\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234564\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.1234567\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.1234567\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"1967-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"1967-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"1967-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"1967-01-02 12:34:56.123456789\")),\n+                new TimestampAndPrecision(\n+                        \"NANOSECONDS\",\n+                        \"2020-01-02 12:34:56.123456789\",\n+                        ImmutableMap.of(\n+                                \"MILLISECONDS\", \"2020-01-02 12:34:56.123\",\n+                                \"MICROSECONDS\", \"2020-01-02 12:34:56.123457\",\n+                                \"NANOSECONDS\", \"2020-01-02 12:34:56.123456789\")));\n \n         // insert records one by one so that we have one file per record, which allows us to exercise predicate push-down in Parquet\n         // (which only works when the value range has a min = max)\n         for (TimestampAndPrecision entry : data) {\n-            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getValue()));\n+            onHive().executeQuery(format(\"INSERT INTO %s VALUES (%s, '%s')\", tableName, entry.getId(), entry.getWriteValue()));\n         }\n \n+        runTimestampQueries(tableName, data);\n+    }\n+\n+    @Test(dataProvider = \"storageFormatsWithNanosecondPrecision\", groups = STORAGE_FORMATS)", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzU1NzE1OA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r497557158", "bodyText": "here as elswhere: confine epochMicros to each of if/else blocks and have epochSeconds and picosOfSecond as the only things common", "author": "findepi", "createdAt": "2020-09-30T14:30:38Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+        long epochMicros;\n+        long picosOfSecond;\n+        if (type.isShort()) {\n+            epochMicros = type.getLong(block, position);\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+        }\n+        else {\n+            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+            epochMicros = longTimestamp.getEpochMicros();\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND + longTimestamp.getPicosOfMicro();\n+        }\n+        long epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);", "originalCommit": "14ffa79a505a21b3f610a1ab8b067bcd695e0f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyMDI1NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500920255", "bodyText": "This belongs to Add roundDiv overload in Timestamps commit (now it's part of Minor ORC cleanup).\nAfter you move this change, rename Minor ORC cleanup commit to eg Remove unused method", "author": "findepi", "createdAt": "2020-10-07T10:56:20Z", "path": "presto-orc/src/test/java/io/prestosql/orc/OrcTester.java", "diffHunk": "@@ -1041,7 +1041,7 @@ private static Object preprocessWriteValueHive(Type type, Object value)\n         }\n         if (type.equals(TIMESTAMP_TZ_MILLIS) || type.equals(TIMESTAMP_TZ_MICROS) || type.equals(TIMESTAMP_TZ_NANOS)) {\n             SqlTimestampWithTimeZone timestamp = (SqlTimestampWithTimeZone) value;\n-            int nanosOfMilli = toIntExact(roundDiv(timestamp.getPicosOfMilli(), PICOSECONDS_PER_NANOSECOND));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyMTU3NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500921575", "bodyText": "This is no longer correct. We unblock write path with nano precision, but we create column handles with millis.\nInstead, we should filter out timestamp columns, if current precision != default precision.\nOTOH, since we do  filtering in getStatisticsCollectionMetadata (correct),\ni think it could be enough to use getTimestampPrecision(session) here, instead of DEFAULT_PRECISION\nand update getType(TypeManager) call 2 lines below", "author": "findepi", "createdAt": "2020-10-07T10:58:48Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -1214,7 +1214,7 @@ public void finishStatisticsCollection(ConnectorSession session, ConnectorTableH\n         List<String> partitionColumnNames = partitionColumns.stream()\n                 .map(Column::getName)\n                 .collect(toImmutableList());\n-        // TODO: revisit when handling write path\n+        // TODO: https://github.com/prestosql/presto/issues/5170\n         List<HiveColumnHandle> hiveColumnHandles = hiveColumnHandles(table, typeManager, TimestampType.DEFAULT_PRECISION);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTAxNTkzNQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r501015935", "bodyText": "Thanks, good point.", "author": "aalbu", "createdAt": "2020-10-07T13:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyMTU3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyNDg2NA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500924864", "bodyText": "getType(TypeManager) overload is still used; for example io.prestosql.plugin.hive.HiveMetadata#finishCreateTable, io.prestosql.plugin.hive.HiveMetadata#finishInsert call sites look relevant\nplease make sure there is an issue covering cleanup of the other ones", "author": "findepi", "createdAt": "2020-10-07T11:05:04Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveWriterFactory.java", "diffHunk": "@@ -522,7 +523,7 @@ else if (insertExistingPartitionsBehavior == InsertExistingPartitionsBehavior.ER\n             }\n \n             List<Type> types = dataColumns.stream()\n-                    .map(column -> column.getHiveType().getType(typeManager))\n+                    .map(column -> column.getHiveType().getType(typeManager, getTimestampPrecision(session).getPrecision()))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyNjQ3Nw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500926477", "bodyText": "we could have a short-cut hiveType.getType(typeManager, session) overload (a potential followup cleanup)", "author": "findepi", "createdAt": "2020-10-07T11:08:01Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/orc/OrcFileWriterFactory.java", "diffHunk": "@@ -140,7 +141,7 @@ public OrcWriterStats getStats()\n         // an index to rearrange columns in the proper order\n         List<String> fileColumnNames = getColumnNames(schema);\n         List<Type> fileColumnTypes = getColumnTypes(schema).stream()\n-                .map(hiveType -> hiveType.getType(typeManager))\n+                .map(hiveType -> hiveType.getType(typeManager, getTimestampPrecision(session).getPrecision()))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkyOTY1Ng==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500929656", "bodyText": "i pushed a fixup for this code", "author": "findepi", "createdAt": "2020-10-07T11:14:03Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/util/FieldSetterFactory.java", "diffHunk": "@@ -365,22 +370,48 @@ public void setField(Block block, int position)\n             extends FieldSetter\n     {\n         private final DateTimeZone timeZone;\n+        private final TimestampType type;\n         private final TimestampWritableV2 value = new TimestampWritableV2();\n \n-        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, DateTimeZone timeZone)\n+        public TimestampFieldSetter(SettableStructObjectInspector rowInspector, Object row, StructField field, TimestampType type, DateTimeZone timeZone)\n         {\n             super(rowInspector, row, field);\n+            this.type = requireNonNull(type, \"type is null\");\n             this.timeZone = requireNonNull(timeZone, \"timeZone is null\");\n         }\n \n         @Override\n         public void setField(Block block, int position)\n         {\n-            long epochMilli = floorDiv(TIMESTAMP_MILLIS.getLong(block, position), MICROSECONDS_PER_MILLISECOND);\n-            epochMilli = timeZone.convertLocalToUTC(epochMilli, false);\n-            value.set(Timestamp.ofEpochMilli(epochMilli));\n+            long epochSeconds;\n+            long picosOfSecond;\n+            if (type.isShort()) {\n+                long epochMicros = type.getLong(block, position);\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+                epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+            }\n+            else {\n+                LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+                long epochMicros = longTimestamp.getEpochMicros();\n+                picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND +", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkzMDYyOQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500930629", "bodyText": "put those comments before\n// comment\nfield declaration", "author": "findepi", "createdAt": "2020-10-07T11:15:53Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveStorageFormats.java", "diffHunk": "@@ -503,17 +676,18 @@ public String toString()\n \n     private static class TimestampAndPrecision\n     {\n+        private static int counter;\n         private final int id;\n-        private final String precision;\n-        private final String value;\n-        private final String roundedValue;\n+        private final String precision; // precision used when writing the data\n+        private final String writeValue; // inserted value\n+        private final Map<String, String> readValues; // expected values to be read back at various precisions", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkzMTAxMA==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r500931010", "bodyText": "i pushed a fixup for this code", "author": "findepi", "createdAt": "2020-10-07T11:16:40Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)\n+    {\n+        if (block.isNull(position)) {\n+            return null;\n+        }\n+        long epochSeconds;\n+        long picosOfSecond;\n+        if (type.isShort()) {\n+            long epochMicros = type.getLong(block, position);\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND;\n+            epochSeconds = floorDiv(epochMicros, MICROSECONDS_PER_SECOND);\n+        }\n+        else {\n+            LongTimestamp longTimestamp = (LongTimestamp) type.getObject(block, position);\n+            long epochMicros = longTimestamp.getEpochMicros();\n+            picosOfSecond = (long) floorMod(epochMicros, MICROSECONDS_PER_SECOND) * PICOSECONDS_PER_MICROSECOND + longTimestamp.getPicosOfMicro();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyMjk4Mg==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r515322982", "bodyText": "Use @SuppressWarnings rather than a comment", "author": "electrum", "createdAt": "2020-10-30T19:16:58Z", "path": "presto-spi/src/main/java/io/prestosql/spi/type/Timestamps.java", "diffHunk": "@@ -102,6 +102,12 @@ private static long scaleFactor(int fromPrecision, int toPrecision)\n         return POWERS_OF_TEN[toPrecision - fromPrecision];\n     }\n \n+    public static int roundDiv(int value, long factor)\n+    {\n+        //noinspection NumericCastThatLosesPrecision", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMyNTQ4Mw==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r515325483", "bodyText": "Use format for readability\nAlso, remove : since saying is 123 reads more naturally than is: 123", "author": "electrum", "createdAt": "2020-10-30T19:22:43Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -2719,14 +2720,14 @@ private static void validateColumns(ConnectorTableMetadata tableMetadata)\n         }\n     }\n \n-    // temporary, until variable precision timestamps are supported on write\n-    private static void validateTimestampColumns(List<ColumnMetadata> columns)\n+    // TODO validate timestamps in structural types (https://github.com/prestosql/presto/issues/5195)\n+    private static void validateTimestampColumns(List<ColumnMetadata> columns, HiveTimestampPrecision timestampPrecision)\n     {\n         for (ColumnMetadata column : columns) {\n             Type type = column.getType();\n             if (type instanceof TimestampType) {\n-                if (type != TIMESTAMP_MILLIS) {\n-                    throw new PrestoException(NOT_SUPPORTED, \"CREATE TABLE, INSERT and ANALYZE are not supported with requested timestamp precision: \" + type);\n+                if (((TimestampType) type).getPrecision() != timestampPrecision.getPrecision()) {\n+                    throw new PrestoException(NOT_SUPPORTED, \"Incorrect timestamp precision for \" + type + \"; the configured precision is: \" + timestampPrecision);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM0MjI1NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r515342255", "bodyText": "I don't think this is a good abstraction. LocalDateTime seems fairly expensive in terms of object allocation and encoding (there's a reason we don't use it everywhere and continue to use Joda-Time). We're also doing the type switching for every value, rather than once for the block or writer instance.\nInstead, for the binary encoding, we could inline this into the timestamp writing code (pulling the type switch outside of the block encoding loop). For text encoding, performance is less important, since it's already expensive.\nIt's possible that this doesn't actually have a performance impact, or that we don't care about RCFile anymore, but since we seem to be introducing a regression to the existing code for millis precision, I'd like to make sure this is an explicit decision (possibly based on data) rather than accidental. @dain probably has more thoughts here.", "author": "electrum", "createdAt": "2020-10-30T19:48:34Z", "path": "presto-rcfile/src/main/java/io/prestosql/rcfile/TimestampUtils.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.rcfile;\n+\n+import io.prestosql.spi.block.Block;\n+import io.prestosql.spi.type.LongTimestamp;\n+import io.prestosql.spi.type.TimestampType;\n+\n+import java.time.LocalDateTime;\n+import java.time.ZoneOffset;\n+\n+import static io.prestosql.spi.type.Timestamps.MICROSECONDS_PER_SECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_MICROSECOND;\n+import static io.prestosql.spi.type.Timestamps.PICOSECONDS_PER_NANOSECOND;\n+import static java.lang.Math.floorDiv;\n+import static java.lang.Math.floorMod;\n+import static java.lang.Math.toIntExact;\n+\n+public final class TimestampUtils\n+{\n+    private TimestampUtils() {}\n+\n+    public static LocalDateTime getLocalDateTime(TimestampType type, Block block, int position)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM0NDM4MQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r515344381", "bodyText": "Can you introduce a method for this? Or default constructor?", "author": "electrum", "createdAt": "2020-10-30T19:52:52Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4212,12 +4214,57 @@ public void testParquetTimestampPredicatePushdown(HiveTimestampPrecision timesta\n         assertEventually(new Duration(30, SECONDS), () -> {\n             ResultWithQueryId<MaterializedResult> result = queryRunner.executeWithQueryId(\n                     session,\n-                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = TIMESTAMP '%s'\", value));\n+                    format(\"SELECT * FROM test_parquet_timestamp_predicate_pushdown WHERE t = %s\", formatTimestamp(value)));\n             sleeper.sleep();\n             assertThat(getQueryInfo(queryRunner, result).getQueryStats().getProcessedInputDataSize().toBytes()).isGreaterThan(0);\n         });\n     }\n \n+    @Test(dataProvider = \"timestampPrecisionAndValues\")\n+    public void testOrcTimestampPredicatePushdown(HiveTimestampPrecision timestampPrecision, LocalDateTime value)\n+    {\n+        Session session = withTimestampPrecision(getSession(), timestampPrecision);\n+        assertUpdate(\"DROP TABLE IF EXISTS test_orc_timestamp_predicate_pushdown\");\n+        assertUpdate(\"CREATE TABLE test_orc_timestamp_predicate_pushdown (t TIMESTAMP) WITH (format = 'ORC')\");\n+        assertUpdate(session, format(\"INSERT INTO test_orc_timestamp_predicate_pushdown VALUES (%s)\", formatTimestamp(value)), 1);\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown\", format(\"VALUES (%s)\", formatTimestamp(value)));\n+\n+        // to account for the fact that ORC stats are stored at millisecond precision and Presto rounds timestamps,\n+        // we filter by timestamps that differ from the actual value by at least 1ms, to observe pruning\n+        DistributedQueryRunner queryRunner = (DistributedQueryRunner) getQueryRunner();\n+        ResultWithQueryId<MaterializedResult> queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < %s\", formatTimestamp(value.minusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        queryResult = queryRunner.executeWithQueryId(\n+                session,\n+                format(\"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t > %s\", formatTimestamp(value.plusNanos(MILLISECONDS.toNanos(1)))));\n+        assertEquals(getQueryInfo(queryRunner, queryResult).getQueryStats().getProcessedInputDataSize().toBytes(), 0);\n+\n+        assertQuery(session, \"SELECT * FROM test_orc_timestamp_predicate_pushdown WHERE t < \" + formatTimestamp(value.plusNanos(1)), format(\"VALUES (%s)\", formatTimestamp(value)));\n+\n+        // TODO: replace this with a simple query stats check once we find a way to wait until all pending updates to query stats have been applied\n+        // (might be fixed by https://github.com/prestosql/presto/issues/5172)\n+        ExponentialSleeper sleeper = new ExponentialSleeper(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM0NTY5NQ==", "url": "https://github.com/trinodb/trino/pull/5283#discussion_r515345695", "bodyText": "These would be easier to read without wrapping, since it will put the values next to each other\nassertQuery(withTimestampPrecision(session, HiveTimestampPrecision.MILLISECONDS), sql, \"VALUES ('2019-02-03 18:30:00.123')\");\nassertQuery(withTimestampPrecision(session, HiveTimestampPrecision.MICROSECONDS), sql, \"VALUES ('2019-02-03 18:30:00.123')\");\nassertQuery(withTimestampPrecision(session, HiveTimestampPrecision.NANOSECONDS), sql, \"VALUES ('2019-02-03 18:30:00.123')\");", "author": "electrum", "createdAt": "2020-10-30T19:55:56Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -7081,6 +7108,148 @@ public void testUnsupportedCsvTable()\n                 \"\\\\QHive CSV storage format only supports VARCHAR (unbounded). Unsupported columns: i integer, bound varchar(10)\\\\E\");\n     }\n \n+    @Test\n+    public void testWriteInvalidPrecisionTimestamp()\n+    {\n+        Session session = withTimestampPrecision(getSession(), HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123456789'\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp (ts TIMESTAMP(9))\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(9); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp(ts) AS SELECT TIMESTAMP '2001-02-03 11:22:33.123'\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(3); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS);\n+        assertQueryFails(\n+                session,\n+                \"CREATE TABLE test_invalid_precision_timestamp (ts TIMESTAMP(3))\",\n+                \"\\\\QIncorrect timestamp precision for timestamp(3); the configured precision is: \" + HiveTimestampPrecision.MICROSECONDS);\n+    }\n+\n+    @Test\n+    public void testTimestampPrecisionInsert()\n+    {\n+        testWithAllStorageFormats(this::testTimestampPrecisionInsert);\n+    }\n+\n+    private void testTimestampPrecisionInsert(Session session, HiveStorageFormat storageFormat)\n+    {\n+        if (storageFormat == HiveStorageFormat.AVRO) {\n+            // Avro timestamps are stored with millisecond precision\n+            return;\n+        }\n+\n+        String createTable = \"CREATE TABLE test_timestamp_precision (ts TIMESTAMP) WITH (format = '%s')\";\n+        @Language(\"SQL\") String insert = \"INSERT INTO test_timestamp_precision VALUES (TIMESTAMP '%s')\";\n+\n+        testTimestampPrecisionWrites(\n+                session,\n+                (ts, precision) -> {\n+                    assertUpdate(\"DROP TABLE IF EXISTS test_timestamp_precision\");\n+                    assertUpdate(format(createTable, storageFormat));\n+                    assertUpdate(withTimestampPrecision(session, precision), format(insert, ts), 1);\n+                });\n+    }\n+\n+    @Test\n+    public void testTimestampPrecisionCtas()\n+    {\n+        testWithAllStorageFormats(this::testTimestampPrecisionCtas);\n+    }\n+\n+    private void testTimestampPrecisionCtas(Session session, HiveStorageFormat storageFormat)\n+    {\n+        if (storageFormat == HiveStorageFormat.AVRO) {\n+            // Avro timestamps are stored with millisecond precision\n+            return;\n+        }\n+\n+        String createTableAs = \"CREATE TABLE test_timestamp_precision WITH (format = '%s') AS SELECT TIMESTAMP '%s' ts\";\n+\n+        testTimestampPrecisionWrites(\n+                session,\n+                (ts, precision) -> {\n+                    assertUpdate(\"DROP TABLE IF EXISTS test_timestamp_precision\");\n+                    assertUpdate(withTimestampPrecision(session, precision), format(createTableAs, storageFormat, ts), 1);\n+                });\n+    }\n+\n+    private void testTimestampPrecisionWrites(Session session, BiConsumer<String, HiveTimestampPrecision> populateData)\n+    {\n+        populateData.accept(\"2019-02-03 18:30:00.123\", HiveTimestampPrecision.MILLISECONDS);\n+        @Language(\"SQL\") String sql = \"SELECT ts FROM test_timestamp_precision\";\n+        assertQuery(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "58817be6cb8344ce7c1e83ca005711584e34e7a3", "url": "https://github.com/trinodb/trino/commit/58817be6cb8344ce7c1e83ca005711584e34e7a3", "message": "Add roundDiv overload in Timestamps", "committedDate": "2020-11-02T23:31:23Z", "type": "commit"}, {"oid": "4cb7d74347385117166b0579ee36f0476ed753af", "url": "https://github.com/trinodb/trino/commit/4cb7d74347385117166b0579ee36f0476ed753af", "message": "Construct session correctly when finishing stats collection", "committedDate": "2020-11-02T23:31:23Z", "type": "commit"}, {"oid": "8904475bbb3b6de2fcf77cc30f597c9c2bc2ad80", "url": "https://github.com/trinodb/trino/commit/8904475bbb3b6de2fcf77cc30f597c9c2bc2ad80", "message": "Handle variable precision timestamps in MaterializedResult", "committedDate": "2020-11-02T23:31:24Z", "type": "commit"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "04b45b1c27c622b087e2040648bd074d77142055", "url": "https://github.com/trinodb/trino/commit/04b45b1c27c622b087e2040648bd074d77142055", "message": "Variable precision timestamp support for Hive write operations", "committedDate": "2020-11-03T03:15:14Z", "type": "commit"}, {"oid": "d3fde11bc72f06a3bfb7a9159d424f7ef588d3e4", "url": "https://github.com/trinodb/trino/commit/d3fde11bc72f06a3bfb7a9159d424f7ef588d3e4", "message": "Remove unused method", "committedDate": "2020-11-03T03:15:15Z", "type": "commit"}, {"oid": "26beb0e02d069b0ab269bb9e5436f8d65578a48a", "url": "https://github.com/trinodb/trino/commit/26beb0e02d069b0ab269bb9e5436f8d65578a48a", "message": "Change signature for HiveType#getType overload", "committedDate": "2020-11-03T03:15:15Z", "type": "commit"}, {"oid": "26beb0e02d069b0ab269bb9e5436f8d65578a48a", "url": "https://github.com/trinodb/trino/commit/26beb0e02d069b0ab269bb9e5436f8d65578a48a", "message": "Change signature for HiveType#getType overload", "committedDate": "2020-11-03T03:15:15Z", "type": "forcePushed"}]}