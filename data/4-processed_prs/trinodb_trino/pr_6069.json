{"pr_number": 6069, "pr_title": "Implement aggregation pushdown in Pinot", "pr_createdAt": "2020-11-24T08:59:27Z", "pr_url": "https://github.com/trinodb/trino/pull/6069", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjg0MDM1Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r562840356", "bodyText": "This should be enabled by default. It should exist as a fallback only until we're confident the feature works as expected, and then we should remove it entirely.", "author": "martint", "createdAt": "2021-01-22T18:53:27Z", "path": "presto-pinot/src/main/java/io/prestosql/pinot/PinotConfig.java", "diffHunk": "@@ -50,6 +50,7 @@\n     private int fetchRetryCount = 2;\n     private int nonAggregateLimitForBrokerQueries = 25_000;\n     private int maxRowsPerSplitForSegmentQueries = 50_000;\n+    private boolean aggregationPushdownEnabled;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjg0MTI5MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r562841291", "bodyText": "Why?", "author": "martint", "createdAt": "2021-01-22T18:55:12Z", "path": "presto-pinot/src/main/java/io/prestosql/pinot/PinotMetadata.java", "diffHunk": "@@ -267,6 +278,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary()));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+\n+        if (tableHandle.getQuery().isPresent()) {\n+            return Optional.empty();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzY4MzU2MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r587683560", "bodyText": "If the query is already a broker query that means that either aggregation pushdown was already done or it's a \"passthrough\" query. In a subsequent pr the \"passthrough\" query feature will be disabled.", "author": "elonazoulay", "createdAt": "2021-03-04T17:44:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjg0MTI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NTAyMjc1Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r645022756", "bodyText": "This is now handled. All cases except aggregations for aggregate queries, as pinot cannot do subqueries.", "author": "elonazoulay", "createdAt": "2021-06-03T18:09:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjg0MTI5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5NTU4OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r562995588", "bodyText": "I'm not sure I understand this comment. What do you mean by \"aggregation expressions\"?", "author": "martint", "createdAt": "2021-01-23T01:23:14Z", "path": "presto-pinot/src/main/java/io/prestosql/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,32 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/prestosql/presto/issues/4171\n+                // Until then this branch will never be executed", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzY4NDQzNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r587684436", "bodyText": "Using an aggregate function on an expression, not just a single column, ex. sum(x + y) vs sum(x).", "author": "elonazoulay", "createdAt": "2021-03-04T17:45:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5NTU4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjU1MzkxNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616553916", "bodyText": "Removed, since it would never be executed anyway.", "author": "elonazoulay", "createdAt": "2021-04-20T10:25:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5NTU4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5NTIzMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r564895232", "bodyText": "This is hard to read, especially with the optional and lambda in the middle. I'd break it up into multiple parts and make the check more explicit.", "author": "martint", "createdAt": "2021-01-26T23:01:16Z", "path": "presto-pinot/src/main/java/io/prestosql/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,32 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/prestosql/presto/issues/4171\n+                // Until then this branch will never be executed\n+                return Optional.of(\"distinctcount\");\n+            }\n+            return Optional.empty();\n+        }\n+        return Optional.of(aggregateFunction.getFunctionName());\n+    }\n+\n+    public static String getInputExpresion(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        // Pinot converts count(column_name) to count(*)\n+        if (aggregateFunction.getInputs().isEmpty() || getAggregationFunctionName(aggregateFunction).map(functionName -> functionName.equalsIgnoreCase(\"count\")).orElse(false)) {\n+            return \"*\";", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5NTkxOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r564895919", "bodyText": "This seems unrelated to this change, so move to a separate commit", "author": "martint", "createdAt": "2021-01-26T23:01:54Z", "path": "presto-pinot/src/test/java/io/prestosql/pinot/PinotQueryRunner.java", "diffHunk": "@@ -36,19 +39,26 @@ public static DistributedQueryRunner createPinotQueryRunner(Map<String, String>\n             throws Exception\n     {\n         DistributedQueryRunner queryRunner = DistributedQueryRunner.builder(createSession(\"default\"))\n-                .setNodeCount(2)\n+                .setNodeCount(3)\n                 .setExtraProperties(extraProperties)\n                 .build();\n         queryRunner.installPlugin(new PinotPlugin(extension));\n-        queryRunner.createCatalog(\"pinot\", \"pinot\", extraPinotProperties);\n+        queryRunner.createCatalog(PINOT_CATALOG, PINOT_CATALOG, extraPinotProperties);\n         return queryRunner;\n     }\n \n     public static Session createSession(String schema)\n+    {\n+        return createSession(schema, new PinotConfig());\n+    }\n+\n+    public static Session createSession(String schema, PinotConfig config)\n     {\n         SessionPropertyManager sessionPropertyManager = new SessionPropertyManager();\n+        PinotSessionProperties pinotSessionProperties = new PinotSessionProperties(config);\n+        sessionPropertyManager.addConnectorSessionProperties(new CatalogName(PINOT_CATALOG), pinotSessionProperties.getSessionProperties());\n         return testSessionBuilder(sessionPropertyManager)\n-                .setCatalog(\"pinot\")\n+                .setCatalog(PINOT_CATALOG)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5OTA1OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r564899058", "bodyText": "What role does this column name have? Will it be an issue if it contains characters like parentheses?", "author": "martint", "createdAt": "2021-01-26T23:05:16Z", "path": "presto-pinot/src/main/java/io/prestosql/pinot/PinotMetadata.java", "diffHunk": "@@ -267,6 +278,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary()));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+\n+        if (tableHandle.getQuery().isPresent()) {\n+            return Optional.empty();\n+        }\n+        if (tableHandle.getLimit().isPresent()) {\n+            // handle's limit is applied after aggregations, so we cannot apply aggregations if limit is already set\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            String inputExpression = getInputExpresion(aggregate);\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (!aggregateFunctionName.isPresent()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc0NzA2Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588747063", "bodyText": "It's used to build the aggregate expression, pinot names the output column as \"functionName(columnName)\". Currently inputExpression is a single column name, even if it contains parens it would not be an issue.", "author": "elonazoulay", "createdAt": "2021-03-05T22:07:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5OTA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjAzNjA5MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616036090", "bodyText": "Added tests to ensure we capture all the behavior from pinot. Found some surprising things like pinot lower cases mixed case columns when there is an aggregate function used, and there is no min(string_type) function.", "author": "elonazoulay", "createdAt": "2021-04-19T17:21:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg5OTA1OA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg0OTY0MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r587849641", "bodyText": "nit: here & elsewhere, update the link please", "author": "findepi", "createdAt": "2021-03-04T21:46:59Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,34 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/prestosql/presto/issues/4171", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588939119", "bodyText": "The two are not equivalent. in SQL, count(column_name) counts how many non-null values there are", "author": "findepi", "createdAt": "2021-03-06T22:28:12Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -122,6 +125,34 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n     }\n \n+    public static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (aggregateFunction.isDistinct()) {\n+            if (aggregateFunction.getFunctionName().equalsIgnoreCase(\"count\")) {\n+                // When aggregation expressions push down is implemented,\n+                // count(distinct <expression>) will be mapped to distinctcount(expression)\n+                // See https://github.com/trinodb/trino/issues/4171\n+                // Until then this branch will never be executed\n+                return Optional.of(\"distinctcount\");\n+            }\n+            return Optional.empty();\n+        }\n+        return Optional.of(aggregateFunction.getFunctionName());\n+    }\n+\n+    public static String getInputExpresion(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        Optional<String> aggregationFunctionName = getAggregationFunctionName(aggregateFunction);\n+        boolean isCountFunction = aggregationFunctionName.map(name -> name.equalsIgnoreCase(\"count\")).orElse(false);\n+        // Pinot converts count(column_name) to count(*)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MzUzMjczOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r593532739", "bodyText": "Thanks! I will add the is not null filter for that case.", "author": "elonazoulay", "createdAt": "2021-03-13T01:01:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNDUzNDE0MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r614534140", "bodyText": "Changed to preserve the column name. Null value support will then be handled by pinot (still in progress): https://docs.pinot.apache.org/developers/advanced/null-value-support.", "author": "elonazoulay", "createdAt": "2021-04-16T03:21:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNDg3MDQ1MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r614870451", "bodyText": "Update: pinot converts count(<column name>) to count(*). Changed behavior to enforce that only count(*) is used to avoid result set column mapping mismatches. When count(<column name>) is supported in pinot I will update the code.", "author": "elonazoulay", "createdAt": "2021-04-16T14:12:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNDg4MDc1Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r614880756", "bodyText": "Update: pinot converts count(<column name>) to count(*).\n\nWe should have a correctness-ensuring, reusable connector test for count(a) over nullable data.\nCan you please ensure we have one, or add?", "author": "findepi", "createdAt": "2021-04-16T14:26:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNTQwNjAwMQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r615406001", "bodyText": "I added tests to ensure count(*) is used, and enabled the \"null handling\" pinot config on the test table. There is no null value in pinot, i.e. string null is 'null', long null becomes Long.MIN_VALUE, int null -> Integer.MIN_VALUE.", "author": "elonazoulay", "createdAt": "2021-04-18T14:23:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjAzNTA3MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616035070", "bodyText": "Added thorough null tests and other behavior. Also extracted the first 2 commits to #7627", "author": "elonazoulay", "createdAt": "2021-04-19T17:19:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTMxNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588939315", "bodyText": "Can this be modelled with io.trino.plugin.pinot.query.DynamicTable#query as a nested query?\nSee \n  \n    \n      trino/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/JdbcMetadata.java\n    \n    \n         Line 248\n      in\n      6e3bc78\n    \n    \n    \n    \n\n        \n          \n           handle = flushAttributesAsQuery(session, handle); \n        \n    \n  \n\n\nand the test\n\n  \n    \n      trino/plugin/trino-postgresql/src/test/java/io/trino/plugin/postgresql/TestPostgreSqlConnectorTest.java\n    \n    \n         Line 520\n      in\n      f2582d1\n    \n    \n    \n    \n\n        \n          \n           .isFullyPushedDown();", "author": "findepi", "createdAt": "2021-03-06T22:30:07Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -267,6 +278,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary()));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+\n+        if (tableHandle.getQuery().isPresent()) {\n+            return Optional.empty();\n+        }\n+        if (tableHandle.getLimit().isPresent()) {\n+            // handle's limit is applied after aggregations, so we cannot apply aggregations if limit is already set\n+            return Optional.empty();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NTAyMzE1OQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r645023159", "bodyText": "Updated - did not completely remove the dynamic table class, but now filters and limits can be applied multiple times and there are tests to verify pushdown.", "author": "elonazoulay", "createdAt": "2021-06-03T18:09:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTMxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NTAyMzMzNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r645023335", "bodyText": "Will update the interface in a subsequent pr", "author": "elonazoulay", "createdAt": "2021-06-03T18:10:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTMxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTQ5MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r588939490", "bodyText": "Can you update the test cases to use io.trino.sql.query.QueryAssertions.QueryAssert#isFullyPushedDown to verify that pushdown actually takes places?\nThis has the added benefit that it automatically verifies correctness, by comparing results with pushdown and without.", "author": "findepi", "createdAt": "2021-03-06T22:32:04Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestMinimalFunctionality.java", "diffHunk": "@@ -184,6 +187,31 @@ public void testLimitForSegmentQueries()\n         assertQueryFails(\"SELECT * FROM \" + TOPIC_AND_TABLE, \"Segment query returned.*\");\n     }\n \n+    @Test\n+    public void testAggregationPushdown()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5MzUyOTU1Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r593529556", "bodyText": "Sure will do", "author": "elonazoulay", "createdAt": "2021-03-13T00:46:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTQ5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1OTgyNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616159826", "bodyText": "BTW Maybe  you can  copy TestPostgreSqlConnectorTest.test*AggregationPushdown methods into Pinot tests (of course, the relevant ones?)\nThis would give you isFullyPushedDown usage and many test cases out of the box", "author": "findepi", "createdAt": "2021-04-19T20:35:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTQ5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NTAyMzUwNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r645023507", "bodyText": "Updated.", "author": "elonazoulay", "createdAt": "2021-06-03T18:10:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzOTQ5MA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1NjEzNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616156136", "bodyText": "pinot.aggregation-pushdown.enabled", "author": "findepi", "createdAt": "2021-04-19T20:29:26Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -257,4 +258,16 @@ public PinotConfig setMaxRowsPerSplitForSegmentQueries(int maxRowsPerSplitForSeg\n         this.maxRowsPerSplitForSegmentQueries = maxRowsPerSplitForSegmentQueries;\n         return this;\n     }\n+\n+    public boolean isAggregationPushdownEnabled()\n+    {\n+        return aggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.enable-aggregation-pushdown\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1NjQ5OQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616156499", "bodyText": "aggregation_pushdown_enabled", "author": "findepi", "createdAt": "2021-04-19T20:29:59Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotSessionProperties.java", "diffHunk": "@@ -34,6 +34,7 @@\n     private static final String PREFER_BROKER_QUERIES = \"prefer_broker_queries\";\n     private static final String RETRY_COUNT = \"retry_count\";\n     private static final String NON_AGGREGATE_LIMIT_FOR_BROKER_QUERIES = \"non_aggregate_limit_for_broker_queries\";\n+    private static final String ENABLE_AGGREGATION_PUSHDOWN = \"enable_aggregation_pushdown\";", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE1OTMzNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616159335", "bodyText": "Maybe call it TestPinotMetadata since this looks like a unit test of that class", "author": "findepi", "createdAt": "2021-04-19T20:35:05Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestAggregationPushdown.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.trino.plugin.pinot.client.PinotClient;\n+import io.trino.plugin.pinot.query.AggregationExpression;\n+import io.trino.plugin.pinot.query.DynamicTable;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.connector.AggregationApplicationResult;\n+import io.trino.spi.connector.ColumnHandle;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.predicate.TupleDomain;\n+import org.testng.annotations.Test;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalLong;\n+\n+import static io.airlift.concurrent.Threads.threadsNamed;\n+import static io.trino.plugin.pinot.PinotQueryRunner.createSession;\n+import static io.trino.plugin.pinot.TestPinotQueryBase.getTestingMetadata;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static io.trino.spi.type.DoubleType.DOUBLE;\n+import static java.util.concurrent.Executors.newCachedThreadPool;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+public class TestAggregationPushdown", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MDMwNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616160306", "bodyText": "Why this is expected to fail? please add explanation.\n(same below)", "author": "findepi", "createdAt": "2021-04-19T20:36:41Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestMinimalFunctionality.java", "diffHunk": "@@ -184,6 +187,31 @@ public void testLimitForSegmentQueries()\n         assertQueryFails(\"SELECT * FROM \" + TOPIC_AND_TABLE, \"Segment query returned.*\");\n     }\n \n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        Session aggregationPushdownEnabledSession = Session.builder(getDistributedQueryRunner().getDefaultSession())\n+                .setCatalogSessionProperty(\"pinot\", \"enable_aggregation_pushdown\", \"true\")\n+                .build();\n+        String noGroupingsQueryTemplate = \"SELECT COUNT(*), SUM(%1$s), AVG(%1$s), MIN(%1$s), MAX(%1$s) FROM \" + TOPIC_AND_TABLE;\n+        assertQueryFails(format(noGroupingsQueryTemplate, \"long_number\"), \"Segment query returned.*\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjQ4NzIzNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616487237", "bodyText": "Without aggregation pushdown enabled, the connector will query the servers directly. This is a way to test the limit for segment queries. A limit is enforced to avoid pinot servers crashing when too many large selects are run.", "author": "elonazoulay", "createdAt": "2021-04-20T08:58:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MDMwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MTY0MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616161641", "bodyText": "seems like there is some overlap between this test and TestMinimalFunctionality.\nMaybe having one would be enough?\nI'd prefer having tests here, and trying to migrate away of \"test minimal functionality\" classes (they are lightweight, but then it's unclear which tests should be added there and which ones here, etc.)", "author": "findepi", "createdAt": "2021-04-19T20:38:54Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -0,0 +1,357 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import io.confluent.kafka.serializers.KafkaAvroSerializer;\n+import io.trino.plugin.pinot.client.PinotHostMapper;\n+import io.trino.sql.planner.plan.AggregationNode;\n+import io.trino.sql.planner.plan.ExchangeNode;\n+import io.trino.sql.planner.plan.LimitNode;\n+import io.trino.sql.planner.plan.ProjectNode;\n+import io.trino.testing.AbstractTestQueryFramework;\n+import io.trino.testing.QueryRunner;\n+import io.trino.testing.kafka.TestingKafka;\n+import org.apache.avro.Schema;\n+import org.apache.avro.SchemaBuilder;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.shaded.org.bouncycastle.util.encoders.Hex;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.nio.charset.StandardCharsets;\n+import java.time.Instant;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.stream.IntStream;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.inject.multibindings.OptionalBinder.newOptionalBinder;\n+import static io.airlift.testing.Closeables.closeAllRuntimeException;\n+import static io.confluent.kafka.serializers.AbstractKafkaSchemaSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG;\n+import static java.lang.Math.abs;\n+import static java.lang.String.join;\n+import static java.util.stream.Collectors.toList;\n+import static org.apache.kafka.clients.producer.ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG;\n+import static org.apache.kafka.clients.producer.ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Test(singleThreaded = true)\n+public class TestPinotIntegrationSmokeTest\n+        extends AbstractTestQueryFramework\n+{\n+    // TODO extend BaseConnectorTest\n+    private static final String ALL_TYPES = \"alltypes\";\n+    private static final int DEFAULT_PINOT_LIMIT_FOR_BROKER_QUERIES = 10;\n+    private static final int COUNT = 1000;\n+    private static final int NULL_COUNT = 17;\n+    private static final int ARRAY_NULL_COUNT = 13;\n+    private TestingPinotCluster pinot;\n+    private TestingKafka kafka;\n+    private Random random;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        random = new Random(22);\n+        kafka = TestingKafka.createWithSchemaRegistry();\n+        kafka.start();\n+        pinot = new TestingPinotCluster(kafka.getNetwork());\n+        pinot.start();\n+\n+        kafka.createTopic(ALL_TYPES);\n+\n+        int step = 3;\n+        int offset = 1;\n+        checkState(COUNT > NULL_COUNT, \"COUNT must be greater than NULL_COUNT\");\n+        checkState(NULL_COUNT > ARRAY_NULL_COUNT, \"NULL_COUNT must be greater than ARRAY_NULL_COUNT\");\n+        ImmutableList.Builder<ProducerRecord<String, GenericRecord>> builder = ImmutableList.builder();\n+        for (long i = 0; i < COUNT - NULL_COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, \"key\" + i * step, createRandomRecord(offset + i * step)));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        builder = ImmutableList.builder();\n+        for (int i = COUNT - NULL_COUNT; i < COUNT - ARRAY_NULL_COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, null, createNullRecord()));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        builder = ImmutableList.builder();\n+        for (int i = COUNT - ARRAY_NULL_COUNT; i < COUNT; i++) {\n+            builder.add(new ProducerRecord<>(ALL_TYPES, null, createArrayNullRecord()));\n+        }\n+        kafka.sendMessages(builder.build().stream(), schemaRegistryAwareProducer(kafka).build());\n+        pinot.createSchema(getClass().getClassLoader().getResourceAsStream(\"alltypes_schema.json\"), ALL_TYPES);\n+        pinot.addRealTimeTable(getClass().getClassLoader().getResourceAsStream(\"alltypes_realtimeSpec.json\"), ALL_TYPES);\n+\n+        Map<String, String> pinotProperties = ImmutableMap.<String, String>builder()\n+                .put(\"pinot.controller-urls\", pinot.getControllerConnectString())\n+                .build();\n+\n+        return PinotQueryRunner.createPinotQueryRunner(\n+                ImmutableMap.of(),\n+                pinotProperties,\n+                Optional.of(binder -> newOptionalBinder(binder, PinotHostMapper.class).setBinding()\n+                        .toInstance(new TestingPinotHostMapper(pinot.getBrokerHostAndPort(), pinot.getServerHostAndPort()))));\n+    }\n+\n+    private static ImmutableMap.Builder<String, String> schemaRegistryAwareProducer(TestingKafka testingKafka)\n+    {\n+        return ImmutableMap.<String, String>builder()\n+                .put(SCHEMA_REGISTRY_URL_CONFIG, testingKafka.getSchemaRegistryConnectString())\n+                .put(KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName())\n+                .put(VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void tearDown()\n+    {\n+        closeAllRuntimeException(pinot, kafka);\n+    }\n+\n+    private GenericRecord createRandomRecord(long offset)\n+    {\n+        return createTestRecord(\n+                random.ints(3, 0, 10001).limit(3).mapToObj(val -> \"string_\" + val).collect(toList()),\n+                Arrays.asList(random.nextBoolean(), random.nextBoolean(), random.nextBoolean()),\n+                random.ints().limit(3).boxed().collect(toList()),\n+                random.ints(3, -10000, 10001).asDoubleStream().map(d -> d / 10000).boxed().map(Double::floatValue).collect(toList()),\n+                random.ints(3, -10000, 10001).asDoubleStream().map(d -> d / 10000).boxed().collect(toList()),\n+                random.longs(3, ((long) Integer.MIN_VALUE) * 2, ((long) Integer.MAX_VALUE) * 2).boxed().collect(toList()),\n+                Instant.now().truncatedTo(ChronoUnit.DAYS).plusMillis(offset).toEpochMilli());\n+    }\n+\n+    private GenericRecord createArrayNullRecord()\n+    {\n+        Schema schema = getAvroSchema();\n+        List<String> stringList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                stringList.add(\"string_\" + abs(random.nextInt(10001)));\n+            }\n+            else {\n+                stringList.add(null);\n+            }\n+        }\n+        List<Boolean> booleanList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                booleanList.add(random.nextBoolean());\n+            }\n+            else {\n+                booleanList.add(null);\n+            }\n+        }\n+\n+        List<Integer> integerList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            integerList.add(null);\n+        }\n+\n+        List<Integer> integerWithDefaultList = new ArrayList<>();\n+        for (int i = 0; i < 5; i++) {\n+            if (i % 2 == 0) {\n+                integerWithDefaultList.add(random.nextInt(10000));\n+            }\n+            else {\n+                integerWithDefaultList.add(null);\n+            }\n+        }\n+\n+        List<Float> floatList = new ArrayList<>();\n+        floatList.add(null);\n+\n+        List<Integer> doubleList = new ArrayList<>();\n+        doubleList.add(null);\n+\n+        return new GenericRecordBuilder(schema)\n+                .set(\"string_array_col\", stringList)\n+                .set(\"bool_array_col\", booleanList)\n+                .set(\"int_array_col\", integerList)\n+                .set(\"int_array_col_with_pinot_default\", integerWithDefaultList)\n+                .set(\"float_array_col\", floatList)\n+                .set(\"double_array_col\", doubleList)\n+                .set(\"long_array_col\", new ArrayList<>())\n+                .build();\n+    }\n+\n+    private static GenericRecord createTestRecord(\n+            List<String> stringArrayColumn,\n+            List<Boolean> booleanArrayColumn,\n+            List<Integer> intArrayColumn,\n+            List<Float> floatArrayColumn,\n+            List<Double> doubleArrayColumn,\n+            List<Long> longArrayColumn,\n+            long updatedAtMillis)\n+    {\n+        Schema schema = getAvroSchema();\n+\n+        return new GenericRecordBuilder(schema)\n+                .set(\"string_CoL\", stringArrayColumn.get(0))\n+                .set(\"bool_COL\", booleanArrayColumn.get(0))\n+                .set(\"bytes_col\", Hex.toHexString(stringArrayColumn.get(0).getBytes(StandardCharsets.UTF_8)))\n+                .set(\"string_array_col\", stringArrayColumn)\n+                .set(\"bool_array_col\", booleanArrayColumn)\n+                .set(\"int_array_col\", intArrayColumn)\n+                .set(\"int_array_col_with_pinot_default\", intArrayColumn)\n+                .set(\"float_array_col\", floatArrayColumn)\n+                .set(\"double_array_col\", doubleArrayColumn)\n+                .set(\"long_array_col\", longArrayColumn)\n+                .set(\"int_CoL\", intArrayColumn.get(0))\n+                .set(\"float_col\", floatArrayColumn.get(0))\n+                .set(\"double_col\", doubleArrayColumn.get(0))\n+                .set(\"long_CoL\", longArrayColumn.get(0))\n+                .set(\"updated_at\", updatedAtMillis)\n+                .build();\n+    }\n+\n+    private static GenericRecord createNullRecord()\n+    {\n+        Schema schema = getAvroSchema();\n+        return new GenericRecordBuilder(schema).build();\n+    }\n+\n+    private static Schema getAvroSchema()\n+    {\n+        // Note:\n+        // The reason optional() is used is because the avro record can omit those fields.\n+        // Fields with nullable type are required to be included or have a default value.\n+        // ex. if \"string_col\" is set to type().nullable().stringType().noDefault()\n+        // the following error is returned: Field string_col type:UNION pos:0 not set and has no default value\n+\n+        return SchemaBuilder.record(\"alltypes\")\n+                .fields()\n+                .name(\"string_CoL\").type().optional().stringType()\n+                .name(\"bool_COL\").type().optional().booleanType()\n+                .name(\"bytes_col\").type().optional().stringType()\n+                .name(\"string_array_col\").type().optional().array().items().nullable().stringType()\n+                .name(\"bool_array_col\").type().optional().array().items().nullable().booleanType()\n+                .name(\"int_array_col\").type().optional().array().items().nullable().intType()\n+                .name(\"int_array_col_with_pinot_default\").type().optional().array().items().nullable().intType()\n+                .name(\"float_array_col\").type().optional().array().items().nullable().floatType()\n+                .name(\"double_array_col\").type().optional().array().items().nullable().doubleType()\n+                .name(\"long_array_col\").type().optional().array().items().nullable().longType()\n+                .name(\"int_CoL\").type().optional().intType()\n+                .name(\"float_col\").type().optional().floatType()\n+                .name(\"double_col\").type().optional().doubleType()\n+                .name(\"long_CoL\").type().optional().longType()\n+                .name(\"updated_at\").type().optional().longType()\n+                .endRecord();\n+    }\n+\n+    @Test\n+    public void testCount()\n+    {\n+        assertQuery(\"SELECT \\\"count(*)\\\" FROM \\\"SELECT COUNT(*) FROM \" + ALL_TYPES + \"\\\"\", \"VALUES(\" + COUNT + \")\");\n+        // If no limit is supplied to a broker query, 10 rows will be returned. Verify this behavior:\n+        assertQuery(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES + \"\\\"\", \"VALUES (\" + DEFAULT_PINOT_LIMIT_FOR_BROKER_QUERIES + \")\");\n+    }\n+\n+    @Test\n+    public void testNullBehavior()\n+    {\n+        // Verify the null behavior of pinot:\n+        // Default null value for varbinary (BYtES in pinot) is X''\n+        // Arrays of varbinary are not supported in pinot\n+        // Default null value for long single value columns is 0\n+        // Default null value for long array values is Long.MIN_VALUE,\n+        // Default null value for int single value columns is 0\n+        // Default null value for int array values is Integer.MIN_VALUE,\n+        // Default null value for float single value columns is 0.0F\n+        // Default null value for float array values is -INFINITY,\n+        // Default null value for double single value columns is 0.0D\n+        // Default null value for double array values is -INFINITY,\n+\n+        assertQuery(\"SELECT MIN(long_col), MIN(element_at(long_array_col, 1)),\" +\n+                        \"  MIN(int_col), MIN(element_at(int_array_col, 1)), MIN(element_at(int_array_col_with_pinot_default, 1)),\" +\n+                        \"  MIN(float_col), MIN(element_at(float_array_col, 1)),\" +\n+                        \"  MIN(double_col), MIN(element_at(double_array_col, 1))\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X''\",\n+                \"VALUES(0, \" + Long.MIN_VALUE + \", \" +\n+                        \"  0, \" + Integer.MIN_VALUE + \", 7,\" +\n+                        \"  0.0, -POWER(0, -1),\" +\n+                        \"  0.0, -POWER(0, -1)\" +\n+                        \")\");\n+\n+        // Default null value for strings is the string 'null'\n+        // Default null value for booleans is the string 'null', boolean is treated as a string\n+        assertQuery(\"SELECT DISTINCT string_col, element_at(string_array_col, 1), bool_col, element_at(bool_array_col, 1)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(int_array_col_with_pinot_default, 1) = 7\",\n+                \"VALUES ('null', 'null', 'null', 'null')\");\n+\n+        // Null behavior for arrays:\n+        // Default value for a \"null\" array is 1 element with default null array value,\n+        // ex.\n+        // Null string or boolean arrays will have ['null'] as the default,\n+        // Null integer arrays will have [Integer.MIN_VALUE] as the default\n+        // Null long arrays will have [Long.MIN_VALUE] as the default,\n+        // Null float arrays will have [-INFINITY] as the default\n+        // Null double arrays will have [-INFINITY] as the default\n+        // As mentioned above, arrays of varbinary are not supported\n+        assertQuery(\"SELECT CARDINALITY(string_array_col), CARDINALITY(bool_array_col), CARDINALITY(int_array_col),  CARDINALITY(int_array_col_with_pinot_default),\" +\n+                        \"  CARDINALITY(float_array_col),  CARDINALITY(long_array_col),  CARDINALITY(long_array_col)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(int_array_col_with_pinot_default, 1) = 7\",\n+                \"VALUES \" + join(\", \", IntStream.range(0, NULL_COUNT - ARRAY_NULL_COUNT).mapToObj(i -> \"(1, 1, 1, 1, 1, 1, 1)\").collect(toList())));\n+\n+        // If an array contains both null and non-null values, the null values are omitted:\n+        // There are 5 values in the avro records, but only the 3 non-null values are in pinot\n+        assertQuery(\"SELECT CARDINALITY(string_array_col), CARDINALITY(bool_array_col), CARDINALITY(int_array_col),  CARDINALITY(int_array_col_with_pinot_default),\" +\n+                        \"  CARDINALITY(float_array_col),  CARDINALITY(long_array_col),  CARDINALITY(long_array_col)\" +\n+                        \"  FROM \" + ALL_TYPES +\n+                        \"  WHERE bytes_col = X'' and element_at(bool_array_col, 1) != 'null'\",\n+                \"VALUES \" + join(\", \", IntStream.range(0, ARRAY_NULL_COUNT).mapToObj(i -> \"(3, 3, 1, 3, 1, 1, 1)\").collect(toList())));\n+    }\n+\n+    @Test\n+    public void testAggregationPushdown()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NTAyMzg4NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r645023885", "bodyText": "Removed TestMinimalFunctionality, all the tests were merged into the smoke test.", "author": "elonazoulay", "createdAt": "2021-06-03T18:10:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MTY0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyNjg4MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671226881", "bodyText": "Could Pinot reuse io.trino.plugin.jdbc.BaseJdbcConnectorTest#testAggregationPushdown?", "author": "findepi", "createdAt": "2021-07-16T12:51:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MTY0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MjEwMw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616162103", "bodyText": "sum is defined for doubles, but also for bigint, decimal. is it an issue?", "author": "findepi", "createdAt": "2021-04-19T20:39:35Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -41,7 +41,7 @@\n     private static final CalciteSqlCompiler REQUEST_COMPILER = new CalciteSqlCompiler();\n     private static final String COLUMN_KEY = \"column\";\n     private static final String WILDCARD = \"*\";\n-    public static final Set<String> DOUBLE_AGGREGATIONS = ImmutableSet.of(\"distinctcounthll\", \"avg\");\n+    public static final Set<String> DOUBLE_AGGREGATIONS = ImmutableSet.of(\"sum\", \"distinctcounthll\", \"avg\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjQ4NTkxNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r616485914", "bodyText": "Pinot client returns sum() as double regardless of it's type.", "author": "elonazoulay", "createdAt": "2021-04-20T08:56:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNjE2MjEwMw=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyMTgzNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648121837", "bodyText": "Second argument is connectorName, so we should pass \"pinot\" here, not PINOT_CATALOG", "author": "findepi", "createdAt": "2021-06-09T09:16:49Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/PinotQueryRunner.java", "diffHunk": "@@ -40,15 +42,15 @@ public static DistributedQueryRunner createPinotQueryRunner(Map<String, String>\n                 .setExtraProperties(extraProperties)\n                 .build();\n         queryRunner.installPlugin(new PinotPlugin(extension));\n-        queryRunner.createCatalog(\"pinot\", \"pinot\", extraPinotProperties);\n+        queryRunner.createCatalog(PINOT_CATALOG, PINOT_CATALOG, extraPinotProperties);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyNjIzNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648126236", "bodyText": "This should be either handled by the caller of getColumnIndices method, or reflected in the name.\nOtherwise getColumnIndices([\"Something\"]).get(\"Something\") returns null, instead of 0.\nBTW since getColumnIndices is called in one place only, I would just make it more fluent and inline:\nMap<String, Integer> columnIndices = IntStream.range(0, columnNames.length)\n        .boxed()\n        // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n        .collect(toImmutableMap(i -> columnNames[i].toLowerCase(ENGLISH), identity()));\n\nThen toLowerCase use when building the Map, and when querying it will be in the same method, which ensures the map is used correctly.", "author": "findepi", "createdAt": "2021-06-09T09:22:40Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -419,9 +420,12 @@ protected BrokerResultRow computeNext()\n \n     private static Map<String, Integer> getColumnIndices(String[] columnNames)\n     {\n+        // Note:\n+        // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n+        // To avoid mismatches, lower case all column names\n         ImmutableMap.Builder<String, Integer> columnIndicesBuilder = ImmutableMap.builder();\n         for (int index = 0; index < columnNames.length; index++) {\n-            columnIndicesBuilder.put(columnNames[index], index);\n+            columnIndicesBuilder.put(columnNames[index].toLowerCase(ENGLISH), index);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyNzkyOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648127929", "bodyText": "Fix filter pushdown for segment queries\n\ncall it \"Remove enforced filter for Pinot segment queries\"", "author": "findepi", "createdAt": "2021-06-09T09:24:48Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -267,7 +291,7 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n                 newDomain,\n                 handle.getLimit(),\n                 handle.getQuery());\n-        return Optional.of(new ConstraintApplicationResult<>(handle, constraint.getSummary(), false));\n+        return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEyODM4OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648128388", "bodyText": "I don't think it's helpful, especially given that the code below is different than the DefaultJdbcMetadata's.\nRemove comment", "author": "findepi", "createdAt": "2021-06-09T09:25:23Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -254,9 +256,31 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n     {\n         PinotTableHandle handle = (PinotTableHandle) table;\n         TupleDomain<ColumnHandle> oldDomain = handle.getConstraint();\n-        // Pinot does not support array literals\n-        TupleDomain<ColumnHandle> newDomain = oldDomain.intersect(constraint.getSummary())\n-                .filter((columnHandle, domain) -> !(((PinotColumnHandle) columnHandle).getDataType() instanceof ArrayType));\n+\n+        // Extracted from DefaultJdbcMetadata", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMTE0NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648131145", "bodyText": "Is every other (non-array) filter enforced strictly, including varchar predicates (potentnial case (in)sensitivity issues)?\nWe apparently do not run io.trino.testing.AbstractTestDistributedQueries#testDataMappingSmokeTest and io.trino.testing.AbstractTestDistributedQueries#testCaseSensitiveDataMapping for Pinot yet. This is important.", "author": "findepi", "createdAt": "2021-06-09T09:28:59Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -254,9 +256,31 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n     {\n         PinotTableHandle handle = (PinotTableHandle) table;\n         TupleDomain<ColumnHandle> oldDomain = handle.getConstraint();\n-        // Pinot does not support array literals\n-        TupleDomain<ColumnHandle> newDomain = oldDomain.intersect(constraint.getSummary())\n-                .filter((columnHandle, domain) -> !(((PinotColumnHandle) columnHandle).getDataType() instanceof ArrayType));\n+\n+        // Extracted from DefaultJdbcMetadata\n+        TupleDomain<ColumnHandle> newDomain = oldDomain.intersect(constraint.getSummary());\n+        TupleDomain<ColumnHandle> remainingFilter;\n+        if (newDomain.isNone()) {\n+            remainingFilter = TupleDomain.all();\n+        }\n+        else {\n+            Map<ColumnHandle, Domain> domains = newDomain.getDomains().orElseThrow();\n+\n+            Map<ColumnHandle, Domain> supported = new HashMap<>();\n+            Map<ColumnHandle, Domain> unsupported = new HashMap<>();\n+            for (Map.Entry<ColumnHandle, Domain> entry : domains.entrySet()) {\n+                // Pinot does not support array literals\n+                if (((PinotColumnHandle) entry.getKey()).getDataType() instanceof ArrayType) {\n+                    unsupported.put(entry.getKey(), entry.getValue());\n+                }\n+                else {\n+                    supported.put(entry.getKey(), entry.getValue());", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1MDU2MTE2OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r650561168", "bodyText": "Yes, there are tests. Case sensitivity is not an issue. Recently boolean and timestamp types were implemented in pinot. In a subsequent pr I will update to use those tests since the types required (boolean and date/timestamp) will be supported.", "author": "elonazoulay", "createdAt": "2021-06-13T18:31:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMTE0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMTg1OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648131858", "bodyText": "This looks like a refactor. Let's move it out of \"Fix filter pushdown for segment queries\" commit.", "author": "findepi", "createdAt": "2021-06-09T09:29:51Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/PinotQueryBuilder.java", "diffHunk": "@@ -100,11 +101,9 @@ private static void generateFilterPql(StringBuilder pqlBuilder, PinotTableHandle\n         ImmutableList.Builder<String> conjunctsBuilder = ImmutableList.builder();\n         timePredicate.ifPresent(conjunctsBuilder::add);\n         if (!tupleDomain.equals(TupleDomain.all())) {\n-            for (PinotColumnHandle columnHandle : columnHandles) {\n-                Domain domain = tupleDomain.getDomains().get().get(columnHandle);\n-                if (domain != null) {\n-                    conjunctsBuilder.add(toPredicate(columnHandle.getColumnName(), domain));\n-                }\n+            Map<ColumnHandle, Domain> domains = tupleDomain.getDomains().orElseThrow();\n+            for (Map.Entry<ColumnHandle, Domain> entry : domains.entrySet()) {\n+                conjunctsBuilder.add(toPredicate(((PinotColumnHandle) entry.getKey()).getColumnName(), entry.getValue()));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzMzY2MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648133660", "bodyText": "The intent of QueryAssert (assertThat(query(...))) is to avoid methods with many overloads, or abstractions that make it harder to add more assertions. I.e. the assertThat(query(...)) should typically be used directly. If there is something preventing us from doing that (e.g. so verbose that it's unreadable) we should think how to improve.\nPlease inline these.", "author": "findepi", "createdAt": "2021-06-09T09:32:13Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -417,6 +419,16 @@ public static Object of(\n         }\n     }\n \n+    private void checkResultMatchesAndIsPushedDown(@Language(\"SQL\") String query, @Language(\"SQL\") String expected)\n+    {\n+        assertThat(query(query)).matches(expected).isFullyPushedDown();\n+    }\n+\n+    private void checkResultMatchesAndIsNotPushedDown(@Language(\"SQL\") String query, @Language(\"SQL\") String expected, Class<? extends PlanNode>... retainedNodes)\n+    {\n+        assertThat(query(query)).matches(expected).isNotFullyPushedDown(retainedNodes);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNDE5Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648134192", "bodyText": "'string_3' and VARCHAR 'string_3' is the same value and same type. Please remove VARCHAR.\nWhy the third value changed its type from varchar to BIGINT?", "author": "findepi", "createdAt": "2021-06-09T09:32:55Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -520,16 +530,16 @@ public void testNonLowerCaseColumnNames()\n                         \"  FROM  \\\"SELECT updatedatseconds, longcol, stringcol FROM \" + MIXED_CASE_COLUMN_NAMES_TABLE + \"\\\"\",\n                 mixedCaseColumnNamesTableValues);\n \n-        String singleRowValues = \"VALUES ('string_3', '3', '1620604803')\";\n+        String singleRowValues = \"VALUES (VARCHAR 'string_3', BIGINT '3', BIGINT '1620604803')\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1MDU2MTgxMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r650561810", "bodyText": "Generally time columns use long in pinot, as Integer.MAX_VALUE epoch seconds can only go up to 1/19/2038.  I can always switch it back... lmk", "author": "elonazoulay", "createdAt": "2021-06-13T18:36:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNDE5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNTEyNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648135126", "bodyText": "VARCHAR is redundant here", "author": "findepi", "createdAt": "2021-06-09T09:34:09Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -732,33 +742,33 @@ public void testBrokerQueriesWithCaseStatementsInFilter()\n     @Test\n     public void testFilterWithRealLiteral()\n     {\n-        String expectedSingleValue = \"VALUES ('3.5', 'vendor1')\";\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price = 3.5\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price <= 3.5\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price BETWEEN 3 AND 4\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price > 3 AND price < 4\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price >= 3.5 AND price <= 4\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price < 3.6\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5)\", expectedSingleValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5, 4)\", expectedSingleValue);\n+        String expectedSingleValue = \"VALUES (REAL '3.5', VARCHAR 'vendor1')\";\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price = 3.5\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price <= 3.5\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price BETWEEN 3 AND 4\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price > 3 AND price < 4\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price >= 3.5 AND price <= 4\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price < 3.6\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5)\", expectedSingleValue);\n+        checkResultMatchesAndIsPushedDown(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price IN (3.5, 4)\", expectedSingleValue);\n         // NOT IN is not pushed down\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price NOT IN (4.5, 5.5, 6.5, 7.5, 8.5, 9.5)\")).isNotFullyPushedDown(FilterNode.class);\n \n         String expectedMultipleValues = \"VALUES\" +\n-                \"  ('3.5', 'vendor1'),\" +\n-                \"  ('4.5', 'vendor2')\";\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price < 4.6\", expectedMultipleValues);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price BETWEEN 3.5 AND 4.5\", expectedMultipleValues);\n-\n-        String expectedMaxValue = \"VALUES ('9.5', 'vendor7')\";\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price > 9\", expectedMaxValue);\n-        assertQuery(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE price >= 9\", expectedMaxValue);\n+                \"  (REAL '3.5', VARCHAR 'vendor1'),\" +\n+                \"  (REAL '4.5', VARCHAR 'vendor2')\";", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1MDU2MTk2Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r650561966", "bodyText": "It would be varchar(7) which causes the types check to fail:\norg.junit.ComparisonFailure: [Output types] \nExpected :[real, varchar(7)]\nActual   :[real, varchar]", "author": "elonazoulay", "createdAt": "2021-06-13T18:37:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1MDgzNDY0MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r650834641", "bodyText": "I was totally unaware and would write lengthy CAST('...' AS varchar) to achieve the unbounded varchar type.\nhttps://trinodb.slack.com/archives/CP1MUNEUX/p1623666956326300\nwe can simplify some other tests using your version.", "author": "findepi", "createdAt": "2021-06-14T10:37:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNTEyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzNzYzMw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648137633", "bodyText": "Maybe add sth like\nLimit is guaranteed when dynamicTable is present, because broker query has one split.\n\nor even better:\nboolean singleSplit = dynamicTable.isPresent();\nreturn Optional.of(new LimitApplicationResult<>(handle, singleSplit, false));", "author": "findepi", "createdAt": "2021-06-09T09:37:33Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -248,7 +248,7 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n                 handle.getConstraint(),\n                 OptionalLong.of(limit),\n                 dynamicTable);\n-        return Optional.of(new LimitApplicationResult<>(handle, false, false));\n+        return Optional.of(new LimitApplicationResult<>(handle, dynamicTable.isPresent(), false));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTAxNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648139015", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +\n          \n          \n            \n            \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\" \" +", "author": "findepi", "createdAt": "2021-06-09T09:39:20Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()\n+    {\n+        assertThat(query(\"SELECT string_col, long_col FROM \" +\n+                \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTQ1Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648139453", "bodyText": "fmt:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n          \n          \n            \n                            \"  WHERE int_col > 0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n          \n          \n            \n            Write", "author": "findepi", "createdAt": "2021-06-09T09:39:54Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()\n+    {\n+        assertThat(query(\"SELECT string_col, long_col FROM \" +\n+                \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +\n+                \"  WHERE bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE +\n+                \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTg0MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648139840", "bodyText": "Why false is in quotes?", "author": "findepi", "createdAt": "2021-06-09T09:40:23Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()\n+    {\n+        assertThat(query(\"SELECT string_col, long_col FROM \" +\n+                \"\\\"SELECT string_col, long_col, bool_col FROM \" + ALL_TYPES_TABLE + \" WHERE int_col > 0\\\"\" +\n+                \"  WHERE bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE +\n+                \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY1MDU2ODkxMQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r650568911", "bodyText": "Currently boolean is treated as string, but in an upcoming release Pinot will support boolean type.", "author": "elonazoulay", "createdAt": "2021-06-13T19:43:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODEzOTg0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0MDAwMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648140002", "bodyText": "copy naming and test cases from io.trino.plugin.jdbc.BaseJdbcConnectorTest#testLimitPushdown", "author": "findepi", "createdAt": "2021-06-09T09:40:37Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -773,4 +774,16 @@ public void testArrayFilter()\n         // Array filters are not pushed down, as there are no array literals in pinot\n         assertThat(query(\"SELECT price, vendor FROM \" + JSON_TABLE + \" WHERE prices = ARRAY[3.5, 5.5]\")).isNotFullyPushedDown(FilterNode.class);\n     }\n+\n+    @Test\n+    public void testFilterPushdownWithLimit()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0MTY5NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648141695", "bodyText": "maybe something \"approximate-count-distinct\"\nbut i am not convinced we want this at all. Instead, we should support pushdown for approx_distinct.", "author": "findepi", "createdAt": "2021-06-09T09:42:48Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -257,4 +260,38 @@ public PinotConfig setMaxRowsPerSplitForSegmentQueries(int maxRowsPerSplitForSeg\n         this.maxRowsPerSplitForSegmentQueries = maxRowsPerSplitForSegmentQueries;\n         return this;\n     }\n+\n+    public boolean isAggregationPushdownEnabled()\n+    {\n+        return aggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.aggregation-pushdown.enabled\")\n+    public PinotConfig setAggregationPushdownEnabled(boolean aggregationPushdownEnabled)\n+    {\n+        this.aggregationPushdownEnabled = aggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isDistinctCountHllEnabled()\n+    {\n+        return distinctCountHllEnabled;\n+    }\n+\n+    /**\n+     * Pinot distinctcounthll benefits from the star tree index.\n+     * For performance reasons this may be desirable.\n+     * The default behavior is to group by the grouping columns\n+     * and the distinct count column, and use trino to do the\n+     * final aggregation.\n+     * @param distinctCountHllEnabled\n+     * @return\n+     */\n+    @Config(\"pinot.distinct-count-hll.enabled\")", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0MzE3OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648143178", "bodyText": ".orElseThrow(() -> ...) since you assume below the expression must be present", "author": "findepi", "createdAt": "2021-06-09T09:44:40Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {\n+            return Optional.empty();\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0NTA1NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648145055", "bodyText": "Add explanation", "author": "findepi", "createdAt": "2021-06-09T09:47:11Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0NTE3Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648145177", "bodyText": "Explain why.", "author": "findepi", "createdAt": "2021-06-09T09:47:19Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE0NjYxMw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648146613", "bodyText": "The input validation is not spread across two methods.\nInline.", "author": "findepi", "createdAt": "2021-06-09T09:49:14Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE1MDU4NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648150584", "bodyText": "SUPPORTED_AGGREGATIONS should contain names of Trino aggregate functions.\nremove distinctcounthll  from it.", "author": "findepi", "createdAt": "2021-06-09T09:54:20Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {\n+            return Optional.empty();\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+        String outputColumnName = format(\"distinctcounthll(%s)\", inputExpression.get());\n+        aggregationExpressions.add(new AggregationExpression(\n+                outputColumnName,\n+                inputExpression.get(),\n+                \"distinctcounthll\"));\n+        PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, DOUBLE);\n+        projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+        resultAssignments.add(new Assignment(outputColumnName, newColumn, DOUBLE));\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (!SUPPORTED_AGGREGATIONS.contains(aggregateFunction.getFunctionName()) ||", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE1NjM3NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648156374", "bodyText": "sort items don't matter for count function", "author": "findepi", "createdAt": "2021-06-09T10:02:33Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static boolean useDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments)\n+    {\n+        if (!isDistinctCountHllEnabled(session)) {\n+            return false;\n+        }\n+        if (tableHandle.getQuery().isEmpty()) {\n+            return false;\n+        }\n+        DynamicTable dynamicTable = tableHandle.getQuery().get();\n+\n+        if (aggregateFunctions.size() != 1) {\n+            return false;\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        // The first applyAggregation call will populate the grouping columns\n+        // and add the distinct column as well.\n+        // The second call contains a single count aggregate function which is not\n+        // distinct.\n+        if (!isCountFunction(aggregateFunction) ||\n+                isCountStarFunction(aggregateFunction) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent() ||\n+                !aggregateFunction.getSortItems().isEmpty()) {\n+            return false;\n+        }\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+        if (inputExpression.isEmpty() || inputExpression.get().equals(\"*\")) {\n+            return false;\n+        }\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) assignments.get(inputExpression.get());\n+        // The grouping columns should contain the distinct column from the previous applyAggregation call\n+        if (!dynamicTable.getGroupingColumns().contains(pinotColumnHandle.getColumnName())) {\n+            return false;\n+        }\n+\n+        return true;\n+    }\n+\n+    private Optional<AggregationApplicationResult<ConnectorTableHandle>> applyDistinctCountHll(ConnectorSession session,\n+            PinotTableHandle tableHandle,\n+            List<AggregateFunction> aggregateFunctions,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!useDistinctCountHll(session, tableHandle, aggregateFunctions, assignments)) {\n+            return Optional.empty();\n+        }\n+        AggregateFunction aggregateFunction = getOnlyElement(aggregateFunctions);\n+        Optional<String> inputExpression = getInputExpression(aggregateFunction, assignments);\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+        String outputColumnName = format(\"distinctcounthll(%s)\", inputExpression.get());\n+        aggregationExpressions.add(new AggregationExpression(\n+                outputColumnName,\n+                inputExpression.get(),\n+                \"distinctcounthll\"));\n+        PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, DOUBLE);\n+        projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+        resultAssignments.add(new Assignment(outputColumnName, newColumn, DOUBLE));\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                OptionalLong.empty(),\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private static Optional<String> getAggregationFunctionName(AggregateFunction aggregateFunction)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        if (!SUPPORTED_AGGREGATIONS.contains(aggregateFunction.getFunctionName()) ||\n+                aggregateFunction.isDistinct() ||\n+                aggregateFunction.getFilter().isPresent()) {\n+            return Optional.empty();\n+        }\n+        return Optional.of(aggregateFunction.getFunctionName());\n+    }\n+\n+    public static Optional<String> getInputExpression(AggregateFunction aggregateFunction, Map<String, ColumnHandle> columnHandles)\n+    {\n+        requireNonNull(aggregateFunction, \"aggregateFunction is null\");\n+        // Pinot converts count(column_name) to count(*)\n+        if (isCountStarFunction(aggregateFunction)) {\n+            return Optional.of(\"*\");\n+        }\n+        if (aggregateFunction.getInputs().size() != 1) {\n+            return Optional.empty();\n+        }\n+        String inputColumnName = ((Variable) getOnlyElement(aggregateFunction.getInputs())).getName();\n+        PinotColumnHandle pinotColumnHandle = (PinotColumnHandle) columnHandles.get(inputColumnName);\n+        if (pinotColumnHandle != null && SUPPORTED_INPUT_TYPES.contains(pinotColumnHandle.getDataType())) {\n+            return Optional.of(pinotColumnHandle.getColumnName());\n+        }\n+        return Optional.empty();\n+    }\n+\n+    private static boolean isCountFunction(AggregateFunction aggregateFunction)\n+    {\n+        Optional<String> aggregationFunctionName = getAggregationFunctionName(aggregateFunction);\n+        return aggregationFunctionName.map(name -> name.equalsIgnoreCase(\"count\")).orElse(false);\n+    }\n+\n+    private static boolean isCountStarFunction(AggregateFunction aggregateFunction)\n+    {\n+        Optional<String> aggregationFunctionName = getAggregationFunctionName(aggregateFunction);\n+        return aggregationFunctionName.map(name -> name.equalsIgnoreCase(\"count\")).orElse(false) &&\n+                aggregateFunction.getInputs().isEmpty() &&\n+                !aggregateFunction.isDistinct() &&\n+                aggregateFunction.getFilter().isEmpty() &&\n+                aggregateFunction.getSortItems().isEmpty();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE1ODY1NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648158655", "bodyText": "This should be handled for individual functions separately. What would it take to use AggregateFunctionRewriter here?\nAlso, checking isDistinct is not enough.\nSee io.trino.plugin.jdbc.expression.AggregateFunctionPatterns#basicAggregation which matches only \"basic\" aggregation functions, without features that are both:  easy to forget about and hard to implement in the remote system.", "author": "findepi", "createdAt": "2021-06-09T10:05:52Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE2MjM4NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r648162385", "bodyText": "in DynamicTable what are the semantics of filters, aggregations, sorting, etc?\nWhich is applied first, which is second, etc.?\nCurrent ordering of fields suggest that aggregation comes before filter, so this line looks incorrect -- you are transposing pre-existing filter with an aggregation.\nIf this is \"just\" a matter of field ordering in DynamicTable, please update it and add commentary like here:\n\n  \n    \n      trino/presto-base-jdbc/src/main/java/io/prestosql/plugin/jdbc/JdbcTableHandle.java\n    \n    \n        Lines 47 to 56\n      in\n      b52bcd7\n    \n    \n    \n    \n\n        \n          \n           private final TupleDomain<ColumnHandle> constraint; \n        \n\n        \n          \n            \n        \n\n        \n          \n           // semantically aggregation is applied after constraint \n        \n\n        \n          \n           private final Optional<List<List<JdbcColumnHandle>>> groupingSets; \n        \n\n        \n          \n            \n        \n\n        \n          \n           // semantically limit is applied after aggregation \n        \n\n        \n          \n           private final OptionalLong limit; \n        \n\n        \n          \n            \n        \n\n        \n          \n           // columns of the relation described by this handle, after projections, aggregations, etc. \n        \n\n        \n          \n           private final Optional<List<JdbcColumnHandle>> columns; \n        \n    \n  \n\n\nWhen doing that, sure the ordering of fields matches that of constructor arguments, they are equally important!", "author": "findepi", "createdAt": "2021-06-09T10:11:22Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +306,211 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        Optional<AggregationApplicationResult<ConnectorTableHandle>> distinctCountHllResult = applyDistinctCountHll(session, tableHandle, aggregates, assignments, groupingSets);\n+        if (distinctCountHllResult.isPresent()) {\n+            return distinctCountHllResult;\n+        }\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<String> inputExpression = getInputExpression(aggregate, assignments);\n+            // Do not push COUNT(<column>) into pinot as it converts to COUNT(*)\n+            // This will count null values.\n+            if (inputExpression.isEmpty() || (isCountFunction(aggregate) && !isCountStarFunction(aggregate))) {\n+                return Optional.empty();\n+            }\n+            // Distinct aggregations other than distinctcounthll are not supported\n+            if (aggregate.isDistinct()) {\n+                return Optional.empty();\n+            }\n+            Optional<String> aggregateFunctionName = getAggregationFunctionName(aggregate);\n+            if (aggregateFunctionName.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            String outputColumnName = format(\"%s(%s)\", aggregateFunctionName.get(), inputExpression.get());\n+            aggregationExpressions.add(new AggregationExpression(\n+                    outputColumnName,\n+                    inputExpression.get(),\n+                    aggregateFunctionName.get()));\n+            PinotColumnHandle newColumn = new PinotColumnHandle(outputColumnName, aggregate.getOutputType());\n+            projections.add(new Variable(newColumn.getColumnName(), newColumn.getDataType()));\n+            resultAssignments.add(new Assignment(outputColumnName, newColumn, aggregate.getOutputType()));\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                getOnlyElement(groupingSets).stream()\n+                        .map(PinotColumnHandle.class::cast)\n+                        .map(PinotColumnHandle::getColumnName)\n+                        .collect(toImmutableList()),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzU1NjU1Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663556553", "bodyText": "Removed AggregationExpression and now the connector returns the exact pinot data type for aggregations. Also implemented approx_distinct pushdown.", "author": "elonazoulay", "createdAt": "2021-07-04T21:05:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0ODE2MjM4NQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Mzg3OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663163878", "bodyText": "Where does this number come from? What are the implications of using a smaller or larger number?", "author": "martint", "createdAt": "2021-07-02T17:39:07Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +317,74 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate and grouping columns are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<AggregationExpression> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<AggregationFunctionRewriteResult> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            aggregationExpressions.add(rewriteResult.get().getAggregationExpression());\n+            projections.add(rewriteResult.get().getProjection());\n+            resultAssignments.add(rewriteResult.get().getAssignment());\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()\n+                .map(PinotColumnHandle.class::cast)\n+                .map(PinotColumnHandle::getColumnName)\n+                .collect(toImmutableList());\n+        OptionalLong limitForDynamicTable = OptionalLong.empty();\n+        // Ensure that pinot default limit of 10 rows is not used\n+        // Currently pinot has a max limit of Integer.MAX_VALUE\n+        if (tableHandle.getLimit().isEmpty() && !groupingColumns.isEmpty()) {\n+            limitForDynamicTable = OptionalLong.of(1_000_000);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyMzY4NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663423684", "bodyText": "Reordered the commits and set to the configured value of pinot.max-rows-for-broker-queries.\nThe number should be on the smaller side until the connector uses a pinot release version where this is fixed (should be in 0.8.0):\napache/pinot#7110", "author": "elonazoulay", "createdAt": "2021-07-03T23:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Mzg3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NDYyOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663164629", "bodyText": "This might be easier to read as:\n if (tableHandle.getQuery().isPresent() &&\n    (!tableHandle.getQuery().get().getAggregateColumns().isEmpty() || !tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {\nBasically, \"if the query is present and either aggregate columns or grouping columns are non-empty...\"", "author": "martint", "createdAt": "2021-07-02T17:40:52Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +317,74 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate and grouping columns are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !(tableHandle.getQuery().get().getAggregateColumns().isEmpty() &&\n+                        tableHandle.getQuery().get().getGroupingColumns().isEmpty())) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzAzMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167030", "bodyText": "Is this a reliable way to tell if it's count(*)? Maybe we should encode that in the column handle and tag them when the operation is pushed down.", "author": "martint", "createdAt": "2021-07-02T17:45:47Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -479,7 +480,20 @@ public static ResultsIterator fromResultTable(ResultTable resultTable, List<Pino\n         for (int i = 0; i < columnHandles.size(); i++) {\n             indices[i] = columnIndices.get(columnHandles.get(i).getColumnName().toLowerCase(ENGLISH));\n         }\n-        return new ResultsIterator(resultTable, indices);\n+        List<Object[]> rows = resultTable.getRows();\n+        // If returning from an aggregate with no grouping columns, make sure all non-count columns are null\n+        if (brokerResponse.getNumDocsScanned() == 0 && resultTable.getRows().size() == 1) {\n+            Object[] originalRow = getOnlyElement(resultTable.getRows());\n+            Object[] newRow = new Object[originalRow.length];\n+            for (int i = 0; i < originalRow.length; i++) {\n+                if (resultTable.getDataSchema().getColumnName(i).equals(\"count(*)\")) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDIwNTYxMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r664205612", "bodyText": "Updated: information is encoded in the column handle.", "author": "elonazoulay", "createdAt": "2021-07-06T03:07:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzAzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzY2OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167668", "bodyText": "Unrelated formatting changes", "author": "martint", "createdAt": "2021-07-02T17:46:48Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,34 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n+\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n+\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyMjk4Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663422982", "bodyText": "This was suggested by @findepi above, did I interpret his suggestion incorrectly or did you mean to put it in a different commit?", "author": "elonazoulay", "createdAt": "2021-07-03T23:48:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzY2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyNTk0Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663425946", "bodyText": "That's ok, but move it to a separate commit.", "author": "martint", "createdAt": "2021-07-04T00:27:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzY2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzgzNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167837", "bodyText": "Why did this change position?", "author": "martint", "createdAt": "2021-07-02T17:47:08Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,34 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n+\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n+\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;\n \n     @JsonCreator\n     public DynamicTable(\n             @JsonProperty(\"tableName\") String tableName,\n             @JsonProperty(\"suffix\") Optional<String> suffix,\n             @JsonProperty(\"selections\") List<String> selections,\n-            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n             @JsonProperty(\"filter\") Optional<String> filter,\n+            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyMzA1OQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663423059", "bodyText": "This was suggested by @findepi - if I interpreted correctly.", "author": "elonazoulay", "createdAt": "2021-07-03T23:49:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzgzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NDkwNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665684904", "bodyText": "This change should go in the first commit.", "author": "martint", "createdAt": "2021-07-07T20:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2NzgzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Nzk4Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663167983", "bodyText": "Why did this change position?", "author": "martint", "createdAt": "2021-07-02T17:47:24Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -54,8 +65,8 @@ public DynamicTable(\n         this.tableName = requireNonNull(tableName, \"tableName is null\");\n         this.suffix = requireNonNull(suffix, \"suffix is null\");\n         this.selections = ImmutableList.copyOf(requireNonNull(selections, \"selections is null\"));\n-        this.groupingColumns = ImmutableList.copyOf(requireNonNull(groupingColumns, \"groupingColumns is null\"));\n         this.filter = requireNonNull(filter, \"filter is null\");\n+        this.groupingColumns = ImmutableList.copyOf(requireNonNull(groupingColumns, \"groupingColumns is null\"));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyMzA2NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663423065", "bodyText": "Same - suggested by @findepi - if I interpreted correctly:)", "author": "elonazoulay", "createdAt": "2021-07-03T23:49:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Nzk4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyNTg1Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663425853", "bodyText": "That's ok, but do it in a separate commit to keep the logical changes independent.", "author": "martint", "createdAt": "2021-07-04T00:26:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2Nzk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODQ2OQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663168469", "bodyText": "Unrelated change (i.e., reordering of methods). If it's warranted, move it to a separate commit.", "author": "martint", "createdAt": "2021-07-02T17:48:27Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -76,9 +87,9 @@ public String getTableName()\n     }\n \n     @JsonProperty\n-    public List<String> getGroupingColumns()\n+    public List<String> getSelections()\n     {\n-        return groupingColumns;\n+        return selections;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NTQ2NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665685465", "bodyText": "I looks like this is still not resolved. Move the change to the first commit.", "author": "martint", "createdAt": "2021-07-07T20:29:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODQ2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODc2Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663168763", "bodyText": "What happened to distinctcounthll?", "author": "martint", "createdAt": "2021-07-02T17:49:05Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -42,8 +47,9 @@\n     private static final CalciteSqlCompiler REQUEST_COMPILER = new CalciteSqlCompiler();\n     private static final String COLUMN_KEY = \"column\";\n     private static final String WILDCARD = \"*\";\n-    public static final Set<String> DOUBLE_AGGREGATIONS = ImmutableSet.of(\"distinctcounthll\", \"avg\");", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyMzE1NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663423155", "bodyText": "This was suggested by @findepi above as well (if I interpreted correctly) - I can add it back, lmk.", "author": "elonazoulay", "createdAt": "2021-07-03T23:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQyNjIxMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663426212", "bodyText": "I'm ok either way, but I'm curious about why it was removed?", "author": "martint", "createdAt": "2021-07-04T00:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzQ1OTE2Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663459163", "bodyText": "@findepi suggested it's better to add as projection for approximate count which makes sense (I can do it in another pr). And for distinct count: if it's fully pushed to pinot it can crash a broker on a large table, but if the \"select col1, col2... group by col1, col2\" is pushed down and then trino does the \"select col1, count(col2)...\" it doesn't crash (tried this on large tables).", "author": "elonazoulay", "createdAt": "2021-07-04T07:15:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODc2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzU3OTEzNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663579134", "bodyText": "Update: pushed down approx_distinct -> distinctcounthll in pinot.", "author": "elonazoulay", "createdAt": "2021-07-05T00:34:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE2ODc2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE3MzE2OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663173168", "bodyText": "Why is this not part of the pattern?", "author": "martint", "createdAt": "2021-07-02T17:59:02Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementMinMax.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+/**\n+ * Implements {@code min(x)}, {@code max(x)}.\n+ */\n+public class ImplementMinMax\n+        implements AggregateFunctionRule\n+{\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().matching(Set.of(\"min\", \"max\")::contains))\n+                .with(singleInput().matching(variable().capturedAs(INPUT)));\n+    }\n+\n+    @Override\n+    public Optional<AggregationFunctionRewriteResult> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        if (!isSupportedSingleColumnAggregateFunction(aggregateFunction, context)) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2MzE3NjY5Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r663176697", "bodyText": "Remove commented out code", "author": "martint", "createdAt": "2021-07-02T18:07:34Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementSum.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+/**\n+ * Implements {@code sum(x)}\n+ */\n+public class ImplementSum\n+        implements AggregateFunctionRule\n+{\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    //public ImplementSum(Function<DecimalType, Optional<JdbcTypeHandle>> decimalTypeHandle)\n+    public ImplementSum()\n+    {\n+        //this.decimalTypeHandle = requireNonNull(decimalTypeHandle, \"decimalTypeHandle is null\");\n+    }", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4MzQ5Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665683497", "bodyText": "This should go in the first commit", "author": "martint", "createdAt": "2021-07-07T20:25:49Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -233,8 +251,8 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n             dynamicTable = Optional.of(new DynamicTable(dynamicTable.get().getTableName(),\n                     dynamicTable.get().getSuffix(),\n                     dynamicTable.get().getSelections(),\n-                    dynamicTable.get().getGroupingColumns(),\n                     dynamicTable.get().getFilter(),\n+                    dynamicTable.get().getGroupingColumns(),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NTE5OQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665685199", "bodyText": "This change should go in the first commit", "author": "martint", "createdAt": "2021-07-07T20:28:49Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,24 +29,33 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n-    private final List<AggregationExpression> aggregateColumns;\n+    private final List<PinotColumnHandle> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;\n \n     @JsonCreator\n     public DynamicTable(\n             @JsonProperty(\"tableName\") String tableName,\n             @JsonProperty(\"suffix\") Optional<String> suffix,\n             @JsonProperty(\"selections\") List<String> selections,\n-            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n             @JsonProperty(\"filter\") Optional<String> filter,\n-            @JsonProperty(\"aggregateColumns\") List<AggregationExpression> aggregateColumns,\n+            @JsonProperty(\"groupingColumns\") List<String> groupingColumns,\n+            @JsonProperty(\"aggregateColumns\") List<PinotColumnHandle> aggregateColumns,", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NjIxMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665686210", "bodyText": "Place one argument per line when splitting arguments across lines. So, format it like this:\naggregateColumnsBuilder.add(new PinotColumnHandle(\n        aggregationFunction.getResultColumnName(),\n        getTrinoTypeFromColumnDataType(aggregationFunction.getFinalResultColumnType())));", "author": "martint", "createdAt": "2021-07-07T20:30:42Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -93,33 +105,47 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         else {\n             filter = Optional.empty();\n         }\n-\n-        ImmutableList.Builder<AggregationExpression> aggregationExpressionBuilder = ImmutableList.builder();\n+        QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(request);\n+        ImmutableList.Builder<PinotColumnHandle> aggregateColumnsBuilder = ImmutableList.builder();\n         if (request.getAggregationsInfo() != null) {\n-            for (AggregationInfo aggregationInfo : request.getAggregationsInfo()) {\n-                String baseColumnName = aggregationInfo.getAggregationParams().get(COLUMN_KEY);\n-                AggregationExpression aggregationExpression;\n-                if (baseColumnName.equals(WILDCARD)) {\n-                    aggregationExpression = new AggregationExpression(getOutputColumnName(aggregationInfo, baseColumnName),\n-                            baseColumnName,\n-                            aggregationInfo.getAggregationType());\n-                }\n-                else {\n-                    PinotColumnHandle columnHandle = (PinotColumnHandle) columnHandles.get(baseColumnName);\n-                    if (columnHandle == null) {\n-                        throw new ColumnNotFoundException(schemaTableName, aggregationInfo.getAggregationParams().get(COLUMN_KEY));\n-                    }\n-                    aggregationExpression = new AggregationExpression(\n-                            getOutputColumnName(aggregationInfo, columnHandle.getColumnName()),\n-                            columnHandle.getColumnName(),\n-                            aggregationInfo.getAggregationType());\n-                }\n-\n-                aggregationExpressionBuilder.add(aggregationExpression);\n+            for (AggregationFunction aggregationFunction : queryContext.getAggregationFunctions()) {\n+                aggregationFunction.getResultColumnName();\n+                aggregationFunction.getType().getName();\n+                aggregateColumnsBuilder.add(new PinotColumnHandle(aggregationFunction.getResultColumnName(),\n+                        getTrinoTypeFromColumnDataType(aggregationFunction.getFinalResultColumnType())));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4NjU1MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665686550", "bodyText": "I'd just call this toTrinoType", "author": "martint", "createdAt": "2021-07-07T20:31:20Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -93,33 +105,47 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         else {\n             filter = Optional.empty();\n         }\n-\n-        ImmutableList.Builder<AggregationExpression> aggregationExpressionBuilder = ImmutableList.builder();\n+        QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(request);\n+        ImmutableList.Builder<PinotColumnHandle> aggregateColumnsBuilder = ImmutableList.builder();\n         if (request.getAggregationsInfo() != null) {\n-            for (AggregationInfo aggregationInfo : request.getAggregationsInfo()) {\n-                String baseColumnName = aggregationInfo.getAggregationParams().get(COLUMN_KEY);\n-                AggregationExpression aggregationExpression;\n-                if (baseColumnName.equals(WILDCARD)) {\n-                    aggregationExpression = new AggregationExpression(getOutputColumnName(aggregationInfo, baseColumnName),\n-                            baseColumnName,\n-                            aggregationInfo.getAggregationType());\n-                }\n-                else {\n-                    PinotColumnHandle columnHandle = (PinotColumnHandle) columnHandles.get(baseColumnName);\n-                    if (columnHandle == null) {\n-                        throw new ColumnNotFoundException(schemaTableName, aggregationInfo.getAggregationParams().get(COLUMN_KEY));\n-                    }\n-                    aggregationExpression = new AggregationExpression(\n-                            getOutputColumnName(aggregationInfo, columnHandle.getColumnName()),\n-                            columnHandle.getColumnName(),\n-                            aggregationInfo.getAggregationType());\n-                }\n-\n-                aggregationExpressionBuilder.add(aggregationExpression);\n+            for (AggregationFunction aggregationFunction : queryContext.getAggregationFunctions()) {\n+                aggregationFunction.getResultColumnName();\n+                aggregationFunction.getType().getName();\n+                aggregateColumnsBuilder.add(new PinotColumnHandle(aggregationFunction.getResultColumnName(),\n+                        getTrinoTypeFromColumnDataType(aggregationFunction.getFinalResultColumnType())));\n             }\n         }\n \n-        return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+        return new DynamicTable(pinotTableName, suffix, selectionColumns, filter, groupByColumns, aggregateColumnsBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+    }\n+\n+    private static Type getTrinoTypeFromColumnDataType(DataSchema.ColumnDataType columnDataType)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTY4ODk5MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665688990", "bodyText": "It's not very clear what this means. I would call this \"returnNullOnEmptyGroup\" and adjust the code accordingly.", "author": "martint", "createdAt": "2021-07-07T20:35:20Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotColumnHandle.java", "diffHunk": "@@ -56,6 +64,12 @@ public ColumnMetadata getColumnMetadata()\n         return new ColumnMetadata(getColumnName(), getDataType());\n     }\n \n+    @JsonProperty\n+    public boolean isPreservePinotEmptyAggregateValue()", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDkxMzk5Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r664913996", "bodyText": "so we need to register here whenever we implement a new pushdown? Can we make this to something using  Reflectionor or Annotation?", "author": "xiangfu0", "createdAt": "2021-07-06T22:21:44Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -100,6 +114,14 @@ public PinotMetadata(\n                         }, executor));\n \n         executor.execute(() -> this.allTablesCache.refresh(ALL_TABLES_CACHE_KEY));\n+        this.maxRowsPerBrokerQuery = pinotConfig.getMaxRowsForBrokerQueries();\n+        this.aggregateFunctionRewriter = new AggregateFunctionRewriter(identity(), ImmutableSet.<AggregateFunctionRule>builder()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzQ2NTIzNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r667465237", "bodyText": "This was suggested above in this pr, the reasons being that it is easier to reason about and customize, and simplifies the implementation using common patterns which also reduce the chances of mistakes i.e. return null on empty set, different names for aggregations between pinot and trino, basic aggregation patterns, etc.\nThis is similar to the jdbc plugin, code was extracted from that plugin - suggested by @findepi above.\nlmk if that sounds correct @findepi , @xiangfu0", "author": "elonazoulay", "createdAt": "2021-07-11T11:18:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDkxMzk5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDkyNTMyNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r664925324", "bodyText": "Do we need this limitForBrokerQueries in PinotBrokerPageSource? I feel we should leverage this in the planning phase, if it's large than this number, then we can fall back to segment-level query without broker pushdown?", "author": "xiangfu0", "createdAt": "2021-07-06T22:50:44Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotBrokerPageSource.java", "diffHunk": "@@ -45,20 +49,24 @@\n     private boolean finished;\n     private long readTimeNanos;\n     private long completedBytes;\n+    private final AtomicLong currentRowCount = new AtomicLong();\n+    private final int limitForBrokerQueries;\n \n     private Iterator<BrokerResultRow> resultIterator;\n \n     public PinotBrokerPageSource(\n             ConnectorSession session,\n             PinotQuery query,\n             List<PinotColumnHandle> columnHandles,\n-            PinotClient pinotClient)\n+            PinotClient pinotClient,\n+            int limitForBrokerQueries)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzQ2NTY1OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r667465658", "bodyText": "I don't see how it's possible to do it in planning as you do not know how many rows will be returned ahead of time.\nThis is similar to how the segment queries handle rows exceeded, it was extracted from the elastic search connector, suggested by @martint - @martint , @xiangfu0 , lmk if this sounds correct.", "author": "elonazoulay", "createdAt": "2021-07-11T11:21:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NDkyNTMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTcxODQyOA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665718428", "bodyText": "Can you add some comments on this, why we need it?", "author": "xiangfu0", "createdAt": "2021-07-07T21:29:24Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotColumnHandle.java", "diffHunk": "@@ -29,14 +29,22 @@\n {\n     private final String columnName;\n     private final Type dataType;\n+    private final boolean preservePinotEmptyAggregateValue;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTg4MTk0Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665881942", "bodyText": "Yep will do: it's because pinot will return 0 for count() and distinctcount() on an empty set but the other aggregation functions will return -infinity (or default null value) when trino would return null, ex. for avg, sum, min and max.", "author": "elonazoulay", "createdAt": "2021-07-08T05:33:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTcxODQyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665740555", "bodyText": "Also, do you have any idea how we can push down count(distinct A) to Pinot as distinctCount(A)  or  count(distinct A) ?\nNote, Pinot internal will rewrite count(distinct A)  to distinctCount(A) as well.", "author": "xiangfu0", "createdAt": "2021-07-07T22:16:22Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -100,6 +114,14 @@ public PinotMetadata(\n                         }, executor));\n \n         executor.execute(() -> this.allTablesCache.refresh(ALL_TABLES_CACHE_KEY));\n+        this.maxRowsPerBrokerQuery = pinotConfig.getMaxRowsForBrokerQueries();\n+        this.aggregateFunctionRewriter = new AggregateFunctionRewriter(identity(), ImmutableSet.<AggregateFunctionRule>builder()\n+                .add(new ImplementCountAll())\n+                .add(new ImplementAvg())\n+                .add(new ImplementMinMax())\n+                .add(new ImplementSum())\n+                .add(new ImplementApproxDistinct())", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTg4MDE1NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665880154", "bodyText": "I have code I can put back as an additional commit - so the broker request should use count(distinct A) and not distinctCount(A)?", "author": "elonazoulay", "createdAt": "2021-07-08T05:28:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTg4OTQ3MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665889471", "bodyText": "Had a concern that it can use a lot of resources on the pinot servers though since it would have to scan all the segments that passed the filter and it would be done on a single broker vs many trino workers. wdyt?", "author": "elonazoulay", "createdAt": "2021-07-08T05:53:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTk1NzE3MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r665957170", "bodyText": "hmm, this is a good point.\nI still feel that the Pinot side should handle the count(distinct ) queries since it would be much cheaper computation comparing to stream data to trino workers. Also pinot side has done many optimization for this type of query.\nAlso, we can add server and session configs to allow users disable pushdown for distinct count queries. So they can skip pushdown if the intermediate data are too large.", "author": "xiangfu0", "createdAt": "2021-07-08T07:53:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzUxNDk0NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r667514944", "bodyText": "Update: added a session property to control whether distinct count is pushed down, implemented distinct count pushdown and added tests. Default behavior is to enable distinct count pushdown.", "author": "elonazoulay", "createdAt": "2021-07-11T17:53:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NzU0MjAzNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r667542035", "bodyText": "Last commit can be squashed into the \"Implement aggregation pushdown\" - kept it separate for now, hopefully easier to review. @martint, @findepi , @xiangfu0  - thanks so much for all the suggestions, ideas and learning!", "author": "elonazoulay", "createdAt": "2021-07-11T22:09:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTc0MDU1NQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NTgxMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671185810", "bodyText": "preservePinotEmptyAggregateValue -> returnNullOnEmptyGroup", "author": "findepi", "createdAt": "2021-07-16T11:55:27Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotColumnHandle.java", "diffHunk": "@@ -83,6 +99,7 @@ public String toString()\n         return toStringHelper(this)\n                 .add(\"columnName\", columnName)\n                 .add(\"dataType\", dataType)\n+                .add(\"preservePinotEmptyAggregateValue\", returnNullOnEmptyGroup)", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDI4MDM5MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r680280390", "bodyText": "Thanks:)", "author": "elonazoulay", "createdAt": "2021-07-31T00:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NTgxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NjM2MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671186360", "bodyText": "\"after sorting\"", "author": "findepi", "createdAt": "2021-07-16T11:56:34Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NjUxNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671186516", "bodyText": "add // semantically sorting is applied after aggregation", "author": "findepi", "createdAt": "2021-07-16T11:56:51Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzAwMw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671187003", "bodyText": "should query be moved before filter, aggregations, sorting and limit?\nie are filter, aggregations, sorting and limit applied on top of a query?", "author": "findepi", "createdAt": "2021-07-16T11:57:45Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTable.java", "diffHunk": "@@ -28,23 +28,32 @@\n public final class DynamicTable\n {\n     private final String tableName;\n+\n     private final Optional<String> suffix;\n+\n     private final List<String> selections;\n+\n+    private final Optional<String> filter;\n+\n+    // semantically aggregation is applied after constraint\n     private final List<String> groupingColumns;\n     private final List<AggregationExpression> aggregateColumns;\n+\n     private final List<OrderByExpression> orderBy;\n+\n+    // semantically limit is applied after aggregation\n     private final OptionalLong limit;\n     private final OptionalLong offset;\n-    private final Optional<String> filter;\n+\n     private final String query;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzA5Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671187092", "bodyText": "what about selections?", "author": "findepi", "createdAt": "2021-07-16T11:57:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDI4MTUwOA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r680281508", "bodyText": "The query, if present, is the \"passthrough\" query - which is then parsed by pinot. The result will only contain selections if there are no aggregations.\nIf there are pushdowns, then the query will be empty.", "author": "elonazoulay", "createdAt": "2021-07-31T00:51:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzAwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mjc3MDQ2Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r682770466", "bodyText": "A little more context: for passthrough queries, DynamicTableBuilder takes the query, parses it with the pinot broker request parser and the other fields in DynamicTable (selections, filter, grouping columns, limit) are created based on the parsed query.\nIf the DynamicTable was created via pushdown then the query will be empty and the other fields will be based on the result of the pushdown.", "author": "elonazoulay", "createdAt": "2021-08-04T16:22:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE4NzAwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671191263", "bodyText": "I understand limitForBrokerQueries is a temporary workaround until fix for apache/pinot#7110 is widespread. Let's add a TODO comment here so that we can remove this.\nAnyway, i don't quite understand why we want to do this.\nWe apply limit after the fact. We already know Pinot didn't crash and handled our query correctly.\nPlease store the explanation as a code comment.", "author": "findepi", "createdAt": "2021-07-16T12:05:37Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotBrokerPageSource.java", "diffHunk": "@@ -113,6 +121,9 @@ public Page getNextPage()\n         int rowCount = 0;\n         while (size < PageBuilderStatus.DEFAULT_MAX_PAGE_SIZE_IN_BYTES && resultIterator.hasNext()) {\n             rowCount++;\n+            if (currentRowCount.incrementAndGet() > limitForBrokerQueries) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDI4MzU3NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r680283574", "bodyText": "The limit could be applied manually in the passthrough query also, I'll add a comment and TODO.", "author": "elonazoulay", "createdAt": "2021-07-31T01:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDU3MTE1Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r680571152", "bodyText": "The other time a limit would be needed is during pushdown: no limit will only return 10 rows from pinot by default. If the limit is Integer.MAX_VALUE (limit is an integer in pinot) this can cause oom's in pinot (pinot#7110) -so it is set to the limit for broker queries config, and if there are more results an error is thrown.", "author": "elonazoulay", "createdAt": "2021-08-01T21:54:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2MDE0Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683960146", "bodyText": "I'm a bit confused? Does Pinot stream results back as soon as they are available? i.e. does Pinot run into an OOM after some results have been returned? If not and Pinot OOMs early then what I think Piotr is saying is that this may be dead code since the Pinot query would've failed already and we'd not have reached here in the first place.\nCan you share what Pinot's behaviour is?", "author": "hashhar", "createdAt": "2021-08-06T05:36:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5Mzc2NzYxOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r693767619", "bodyText": "@elonazoulay Bump.", "author": "hashhar", "createdAt": "2021-08-23T08:29:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTI2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MTk1Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671191956", "bodyText": "Looks like TestBrokerQueries could benefit from a test that shows that the broker queries limit gets applied.", "author": "findepi", "createdAt": "2021-07-16T12:06:50Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestBrokerQueries.java", "diffHunk": "@@ -46,6 +46,7 @@\n     private static final DataSchema DATA_SCHEMA;\n     private static final List<Object[]> TEST_DATA;\n     private static final ResultTable RESULT_TABLE;\n+    private static final int LIMIT_FOR_BROKER_QUERIES = 2;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5MzYxNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671193614", "bodyText": "where does -2147483648 come from? it's an integer overflow on the Pinot side, right?\nplease add a link to a Pinot issue here for clarify\n// Note that -2147483648 is due to an integer overflow in Pinot, see https://.....", "author": "findepi", "createdAt": "2021-07-16T12:09:02Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -578,6 +599,44 @@ public void testBrokerQueryWithTooManyRowsForSegmentQuery()\n                 tooManyRowsTableValues);\n     }\n \n+    @Test\n+    public void testMaxLimitForPassthroughQueries()\n+            throws InterruptedException\n+    {\n+        assertQueryFails(\"SELECT string_col, updated_at_seconds\" +\n+                        \"  FROM  \\\"SELECT updated_at_seconds, string_col FROM \" + TOO_MANY_BROKER_ROWS_TABLE +\n+                        \"  LIMIT \" + (MAX_ROWS_PER_SPLIT_FOR_BROKER_QUERIES + 1) + \"\\\"\",\n+                \"Broker query returned '13' rows, maximum allowed is '12' rows. with query \\\"select updated_at_seconds, string_col from too_many_broker_rows limit 13\\\"\");\n+\n+        // Pinot issue preventing Integer.MAX_VALUE from being a limit: https://github.com/apache/incubator-pinot/issues/7110\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + Integer.MAX_VALUE + \"\\\"\",\n+                \"Unexpected response status: 500 for request \\\\{\\\"sql\\\" : \\\"select string_col, long_col from alltypes limit 2147483647\\\" \\\\} to url http://localhost:\\\\d+/query/sql, with headers \\\\{Accept=\\\\[application/json\\\\], Content-Type=\\\\[application/json\\\\]\\\\}, full response null\");\n+\n+        // Pinot broker requests do not handle limits greater than Integer.MAX_VALUE\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + ((long) Integer.MAX_VALUE + 1) + \"\\\"\",\n+                \"Query select string_col, long_col from alltypes limit -2147483648 encountered exception org.apache.pinot.common.response.broker.QueryProcessingException@\\\\w+ with query \\\"select string_col, long_col from alltypes limit -2147483648\\\"\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5OTU0Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671199543", "bodyText": "// If returning from a global aggregation (no grouping columns) over an empty table, NULL-out all aggregation function results except for `count()`\n\nSome questions\n\nIs brokerResponse.getNumDocsScanned() == 0 equivalent to saying \"table is empty\"? Can a document hold no rows? What if there were documents scanned, but data was filtered out (SELECT max(x) FROM non_empty_table WHERE y = non_existent_value)?\nresultTable.getRows().size() == 1  combined with \"no data\" is a tricky way saying \"global aggregation\". Would checking query.getGroupByClauses()==0 be sufficient? (assuming getGroupByClauses is populated correctly, which i didn't check)", "author": "findepi", "createdAt": "2021-07-16T12:17:38Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -462,24 +462,39 @@ private BrokerResponseNative submitBrokerQueryJson(ConnectorSession session, Pin\n     public Iterator<BrokerResultRow> createResultIterator(ConnectorSession session, PinotQuery query, List<PinotColumnHandle> columnHandles)\n     {\n         BrokerResponseNative response = submitBrokerQueryJson(session, query);\n-        return fromResultTable(response.getResultTable(), columnHandles);\n+        return fromResultTable(response, columnHandles);\n     }\n \n     @VisibleForTesting\n-    public static ResultsIterator fromResultTable(ResultTable resultTable, List<PinotColumnHandle> columnHandles)\n+    public static ResultsIterator fromResultTable(BrokerResponseNative brokerResponse, List<PinotColumnHandle> columnHandles)\n     {\n-        requireNonNull(resultTable, \"resultTable is null\");\n+        requireNonNull(brokerResponse, \"brokerResponse is null\");\n         requireNonNull(columnHandles, \"columnHandles is null\");\n+        ResultTable resultTable = brokerResponse.getResultTable();\n         String[] columnNames = resultTable.getDataSchema().getColumnNames();\n         Map<String, Integer> columnIndices = IntStream.range(0, columnNames.length)\n                 .boxed()\n                 // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n                 .collect(toImmutableMap(i -> columnNames[i].toLowerCase(ENGLISH), identity()));\n         int[] indices = new int[columnNames.length];\n+        int[] inverseIndices = new int[columnNames.length];\n         for (int i = 0; i < columnHandles.size(); i++) {\n             indices[i] = columnIndices.get(columnHandles.get(i).getColumnName().toLowerCase(ENGLISH));\n+            inverseIndices[indices[i]] = i;\n         }\n-        return new ResultsIterator(resultTable, indices);\n+        List<Object[]> rows = resultTable.getRows();\n+        // If returning from an aggregate with no grouping columns, make sure all non-count columns are null\n+        if (brokerResponse.getNumDocsScanned() == 0 && resultTable.getRows().size() == 1) {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MTk3NjU2NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r681976565", "bodyText": "The numDocsScanned in the response will be set to 0 if the result set is empty even if the dataset before the filter is non-empty. The numSegmentsScanned in the response will be > 0 if the data set was not empty, i.e. it scanned over rows but the filter removed them.\nGood point: I added groupingColumns as an extra verification.\nThere is a test to verify this behavior in testAggregationPushdown - the one with the comment: // Test single row from pinot where filter results in an empty result set.", "author": "elonazoulay", "createdAt": "2021-08-03T17:50:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTE5OTU0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwMjkyMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671202920", "bodyText": "looks like unrelated to aggregations, is it?\nSeems like you're fixing reading of array type when the array itself is null?", "author": "findepi", "createdAt": "2021-07-16T12:22:16Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/decoders/ArrayDecoder.java", "diffHunk": "@@ -42,11 +42,16 @@ public ArrayDecoder(Type type)\n     public void decode(Supplier<Object> getter, BlockBuilder output)\n     {\n         List<?> value = (List<?>) getter.get();\n-        BlockBuilder elementBlockBuilder = type.getElementType().createBlockBuilder(null, 1);\n-        for (int i = 0; i < value.size(); i++) {\n-            int index = i;\n-            elementDecoder.decode(() -> value.get(index), elementBlockBuilder);\n+        if (value == null) {\n+            output.appendNull();\n+        }\n+        else {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDI2OTg1NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r680269854", "bodyText": "The only time it could be null is when it's set during a single row aggregation (no grouping columns) over an empty set, depending on the aggregate function. Counting functions return 0 for empty set and everything else returns null. Pinot does not return null values, the connector sets them to null in this case.", "author": "elonazoulay", "createdAt": "2021-07-30T23:46:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwMjkyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwMzI1Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671203253", "bodyText": "looks like unrelated to aggregations, is it?\n(same for other decoders)", "author": "findepi", "createdAt": "2021-07-16T12:22:48Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/decoders/BigintDecoder.java", "diffHunk": "@@ -25,6 +25,12 @@\n     @Override\n     public void decode(Supplier<Object> getter, BlockBuilder output)\n     {\n-        BIGINT.writeLong(output, ((Number) getter.get()).longValue());\n+        Object value = getter.get();\n+        if (value == null) {\n+            output.appendNull();\n+        }\n+        else {", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3OTQwMTU2NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r679401564", "bodyText": "This is due to a change related to aggregation: for queries with aggregates and no grouping columns, if the data is empty pinot returns \"-infinity\" for  numeric columns (even integer and long), so there is code to manually set these to null.\nPinot never returns null, this was done in the connector so the behavior matches what is expected, i.e. count, count distinct over no data returns 0, all other implemented aggregations return null.", "author": "elonazoulay", "createdAt": "2021-07-29T18:45:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwMzI1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671205418", "bodyText": "Let's move AggregateFunctionPatterns to plugin-toolkit instead of copying it.", "author": "findepi", "createdAt": "2021-07-16T12:25:42Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionPatterns.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Match;\n+import io.trino.matching.Pattern;\n+import io.trino.matching.PatternVisitor;\n+import io.trino.matching.Property;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.ConnectorExpression;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.type.Type;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Predicate;\n+import java.util.stream.Stream;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public final class AggregateFunctionPatterns\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionPatterns", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIxOTE4NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671219184", "bodyText": "#8578", "author": "findepi", "createdAt": "2021-07-16T12:42:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2NzQ2Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683967466", "bodyText": "@elonazoulay Was there any conclusion here? I agree it'd be much nicer to avoid a copy to prevent code from drifting away.", "author": "hashhar", "createdAt": "2021-08-06T05:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5NDc3Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684594777", "bodyText": "I was wondering if I could make RewriteContext extendible, or add the groupingColumns to it. Count distinct in pinot needs to verify that the input column is contained in the grouping columns if there is a passthrough query. Let me know what you think.", "author": "elonazoulay", "createdAt": "2021-08-07T06:50:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5NDgxNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684594817", "bodyText": "Agreed, would be much better to use #8578 .", "author": "elonazoulay", "createdAt": "2021-08-07T06:50:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIwNTQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIxOTMyNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671219324", "bodyText": "#8578", "author": "findepi", "createdAt": "2021-07-16T12:43:09Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionRewriter.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableSet;\n+import io.trino.matching.Match;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.connector.ColumnHandle;\n+import io.trino.spi.connector.ConnectorSession;\n+\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public final class AggregateFunctionRewriter\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionRewriter", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIxOTQwNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671219406", "bodyText": "#8578", "author": "findepi", "createdAt": "2021-07-16T12:43:14Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/AggregateFunctionRule.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.connector.ColumnHandle;\n+import io.trino.spi.connector.ConnectorSession;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.Function;\n+\n+import static com.google.common.base.Verify.verifyNotNull;\n+import static java.util.Objects.requireNonNull;\n+\n+public interface AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.AggregateFunctionRule", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMDY4Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671220683", "bodyText": "SUPPORTED_INPUT_TYPES doesn't look like specific to averages, so reuse here looks wrong.\ni suggest defining supported types directly here, in ImplementAvg\n(some for other cases)", "author": "findepi", "createdAt": "2021-07-16T12:44:50Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementAvg.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.DynamicTableBuilder.SUPPORTED_INPUT_TYPES;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.expressionType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+public class ImplementAvg\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"avg\"))\n+                .with(singleInput().matching(\n+                        variable()\n+                                .with(expressionType().matching(SUPPORTED_INPUT_TYPES::contains))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODk3Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683968973", "bodyText": "@elonazoulay bumping this up again", "author": "hashhar", "createdAt": "2021-08-06T06:01:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMDY4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5NTAxMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684595012", "bodyText": "I moved SUPPORTED_INPUT_TYPES to ImplementAvg, I think that line is unchanged, but above it's declared private static, no longer imported.", "author": "elonazoulay", "createdAt": "2021-08-07T06:52:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMDY4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMjY1Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671222657", "bodyText": "the intention of \n  \n    \n      trino/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/expression/ImplementCountAll.java\n    \n    \n         Line 61\n      in\n      d649dca\n    \n    \n    \n    \n\n        \n          \n           verify(aggregateFunction.getOutputType() == BIGINT); \n        \n    \n  \n\n is \"make sure this code gets updated, should return type of count(*) change to whatever else\"\nremove .with(outputType().equalTo(BIGINT)); from the pattern above, to achieve the same (otherwise this line would be redundant)", "author": "findepi", "createdAt": "2021-07-16T12:47:08Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementCountAll.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.inputs;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * Implements {@code count(*)}.\n+ */\n+public class ImplementCountAll\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.ImplementCountAll\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"count\"))\n+                .with(inputs().equalTo(List.of()))\n+                .with(outputType().equalTo(BIGINT));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        verify(aggregateFunction.getOutputType() == BIGINT);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyMzQ2MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671223460", "bodyText": "inline outputColumnHandle\n(same in others)", "author": "findepi", "createdAt": "2021-07-16T12:47:58Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementCountAll.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.inputs;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+\n+/**\n+ * Implements {@code count(*)}.\n+ */\n+public class ImplementCountAll\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.ImplementCountAll\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"count\"))\n+                .with(inputs().equalTo(List.of()))\n+                .with(outputType().equalTo(BIGINT));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        verify(aggregateFunction.getOutputType() == BIGINT);\n+        PinotColumnHandle outputColumnHandle = new PinotColumnHandle(\"count(*)\", aggregateFunction.getOutputType(), false);\n+        return Optional.of(outputColumnHandle);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MTIyNTA2NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r671225065", "bodyText": "SUPPORTED_INPUT_TYPES doesn't look specific to min or max (to comparisons).\ni would suggest defining supported data types directly here, in ImplementMinMax", "author": "findepi", "createdAt": "2021-07-16T12:49:39Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementMinMax.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.DynamicTableBuilder.SUPPORTED_INPUT_TYPES;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.expressionType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static java.lang.String.format;\n+\n+/**\n+ * Implements {@code min(x)}, {@code max(x)}.\n+ */\n+public class ImplementMinMax\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression.ImplementMinMax\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().matching(Set.of(\"min\", \"max\")::contains))\n+                .with(singleInput().matching(\n+                        variable()\n+                                .with(expressionType().matching(SUPPORTED_INPUT_TYPES::contains))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjE4OTI0Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676189243", "bodyText": "What is this about?", "author": "findepi", "createdAt": "2021-07-25T19:07:47Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementCountDistinct.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.PinotSessionProperties.isDistinctCountPushdownEnabled;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static java.lang.String.format;\n+\n+public class ImplementCountDistinct\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"count\"))\n+                .with(outputType().equalTo(BIGINT))\n+                .with(singleInput().matching(variable().capturedAs(INPUT)));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        if (!isDistinctCountPushdownEnabled(context.getSession())) {\n+            return Optional.empty();\n+        }\n+        Variable input = captures.get(INPUT);\n+        verify(aggregateFunction.getOutputType() == BIGINT);\n+        if (context.getExistingGroupingColumns().isEmpty() || !context.getExistingGroupingColumns().get().contains(input.getName())) {\n+            return Optional.empty();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3OTM4MTIzOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r679381239", "bodyText": "This is to verify that the grouping columns in the table handle contain the column that is in the count distinct:", "author": "elonazoulay", "createdAt": "2021-07-29T18:14:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjE4OTI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2OTg3MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683969871", "bodyText": "@elonazoulay Wouldn't Trino ensure that? Otherwise the query would fail analysis?\nEDIT: I guess this is needed because of dynamic tables?", "author": "hashhar", "createdAt": "2021-08-06T06:03:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjE4OTI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5MTcwNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684591704", "bodyText": "Yes, if you do a passthrough query this is the only way to verify that the grouping columns contain the input column.", "author": "elonazoulay", "createdAt": "2021-08-07T06:18:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjE4OTI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNDcyNA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676314724", "bodyText": "nit: distinctCountPushdownEnabled -> countDistinctPushdownEnabled (since that's what the optimizer calls it)", "author": "hashhar", "createdAt": "2021-07-26T06:06:34Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -50,6 +51,9 @@\n     private int fetchRetryCount = 2;\n     private int nonAggregateLimitForBrokerQueries = 25_000;\n     private int maxRowsPerSplitForSegmentQueries = 50_000;\n+    private int maxRowsForBrokerQueries = 50_000;\n+    private boolean aggregationPushdownEnabled = true;\n+    private boolean distinctCountPushdownEnabled = true;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNTY4Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676315682", "bodyText": "Add validation to disallow setting this without also setting pinot.aggregation-pushdown.enabled.\nBtw why do we need this? If we don't pushdown COUNT(DISTINCT) then also we might end up with a full-scan? Or is that not true? i.e. why can't we have just pinot.aggregation-pushdown.enabled?", "author": "hashhar", "createdAt": "2021-07-26T06:08:53Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotConfig.java", "diffHunk": "@@ -257,4 +261,41 @@ public PinotConfig setMaxRowsPerSplitForSegmentQueries(int maxRowsPerSplitForSeg\n         this.maxRowsPerSplitForSegmentQueries = maxRowsPerSplitForSegmentQueries;\n         return this;\n     }\n+\n+    public int getMaxRowsForBrokerQueries()\n+    {\n+        return maxRowsForBrokerQueries;\n+    }\n+\n+    @Config(\"pinot.max-rows-for-broker-queries\")\n+    public PinotConfig setMaxRowsForBrokerQueries(int maxRowsForBrokerQueries)\n+    {\n+        this.maxRowsForBrokerQueries = maxRowsForBrokerQueries;\n+        return this;\n+    }\n+\n+    public boolean isAggregationPushdownEnabled()\n+    {\n+        return aggregationPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.aggregation-pushdown.enabled\")\n+    public PinotConfig setAggregationPushdownEnabled(boolean aggregationPushdownEnabled)\n+    {\n+        this.aggregationPushdownEnabled = aggregationPushdownEnabled;\n+        return this;\n+    }\n+\n+    public boolean isDistinctCountPushdownEnabled()\n+    {\n+        return distinctCountPushdownEnabled;\n+    }\n+\n+    @Config(\"pinot.distinct-count-pushdown.enabled\")\n+    @ConfigDescription(\"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.\")", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MDI3NTgyNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r680275825", "bodyText": "If count-distinct-pushdown is enabled it may crash pinot servers due to full scan. If it is disabled and there are more trino workers then it could actually return faster since the workers will do the count and the results will stream from pinot.", "author": "elonazoulay", "createdAt": "2021-07-31T00:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNTY4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2MDU0OQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683960549", "bodyText": "Can you add a @PostConstruct public void validate() to validate that this is not set without also setting pinot.aggregation-pushdown.enabled?", "author": "hashhar", "createdAt": "2021-08-06T05:37:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNTY4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5Mjc1NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684592755", "bodyText": "Oh nice, thanks!", "author": "elonazoulay", "createdAt": "2021-08-07T06:29:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNTY4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNzE0MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676317140", "bodyText": "Add validation to ensure this cannot be set without setting pinot.aggregation-pushdown.enabled too.", "author": "hashhar", "createdAt": "2021-07-26T06:12:17Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotSessionProperties.java", "diffHunk": "@@ -108,6 +120,16 @@ public PinotSessionProperties(PinotConfig pinotConfig)\n                         \"Number of segments of the same host per split\",\n                         pinotConfig.getSegmentsPerSplit(),\n                         value -> checkArgument(value > 0, \"Number of segments per split must be more than zero\"),\n+                        false),\n+                booleanProperty(\n+                        AGGREGATION_PUSHDOWN_ENABLED,\n+                        \"Enable aggregation pushdown\",\n+                        pinotConfig.isAggregationPushdownEnabled(),\n+                        false),\n+                booleanProperty(\n+                        DISTINCT_COUNT_PUSHDOWN_ENABLED,\n+                        \"Enable distinct count pushdown\",\n+                        pinotConfig.isDistinctCountPushdownEnabled(),", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mjc5NTgyOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r682795829", "bodyText": "Without passing the session into the validator I do not see a way to do this. Instead I added the check for aggregation pushdown being enabled to isCountDistinctPushdownEnabled.", "author": "elonazoulay", "createdAt": "2021-08-04T16:56:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNzE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3NjQ3Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683976473", "bodyText": "@martint Is there any to way validate session properties based on other session properties? The only examples I could find do it in the getter for the session property (\n  \n    \n      trino/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveSessionProperties.java\n    \n    \n         Line 492\n      in\n      d27254d\n    \n    \n    \n    \n\n        \n          \n           public static boolean isOrcOptimizedWriterValidate(ConnectorSession session) \n        \n    \n  \n\n).", "author": "hashhar", "createdAt": "2021-08-06T06:19:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNzE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5MzcyNw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684593727", "bodyText": "Thanks! I added a verify as the PinotSessionProperties.isCountDistinctPushdownEnabled() method would never be called unless aggregation pushdown is enabled.", "author": "elonazoulay", "createdAt": "2021-08-07T06:39:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxNzE0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxODEyOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676318129", "bodyText": "Maybe fall-through instead?", "author": "hashhar", "createdAt": "2021-07-26T06:14:47Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/DynamicTableBuilder.java", "diffHunk": "@@ -93,33 +105,48 @@ public static DynamicTable buildFromPql(PinotMetadata pinotMetadata, SchemaTable\n         else {\n             filter = Optional.empty();\n         }\n-\n-        ImmutableList.Builder<AggregationExpression> aggregationExpressionBuilder = ImmutableList.builder();\n+        QueryContext queryContext = BrokerRequestToQueryContextConverter.convert(request);\n+        ImmutableList.Builder<PinotColumnHandle> aggregateColumnsBuilder = ImmutableList.builder();\n         if (request.getAggregationsInfo() != null) {\n-            for (AggregationInfo aggregationInfo : request.getAggregationsInfo()) {\n-                String baseColumnName = aggregationInfo.getAggregationParams().get(COLUMN_KEY);\n-                AggregationExpression aggregationExpression;\n-                if (baseColumnName.equals(WILDCARD)) {\n-                    aggregationExpression = new AggregationExpression(getOutputColumnName(aggregationInfo, baseColumnName),\n-                            baseColumnName,\n-                            aggregationInfo.getAggregationType());\n-                }\n-                else {\n-                    PinotColumnHandle columnHandle = (PinotColumnHandle) columnHandles.get(baseColumnName);\n-                    if (columnHandle == null) {\n-                        throw new ColumnNotFoundException(schemaTableName, aggregationInfo.getAggregationParams().get(COLUMN_KEY));\n-                    }\n-                    aggregationExpression = new AggregationExpression(\n-                            getOutputColumnName(aggregationInfo, columnHandle.getColumnName()),\n-                            columnHandle.getColumnName(),\n-                            aggregationInfo.getAggregationType());\n-                }\n-\n-                aggregationExpressionBuilder.add(aggregationExpression);\n+            for (AggregationFunction aggregationFunction : queryContext.getAggregationFunctions()) {\n+                aggregationFunction.getResultColumnName();\n+                aggregationFunction.getType().getName();\n+                aggregateColumnsBuilder.add(new PinotColumnHandle(\n+                        aggregationFunction.getResultColumnName(),\n+                        toTrinoType(aggregationFunction.getFinalResultColumnType())));\n             }\n         }\n \n-        return new DynamicTable(pinotTableName, suffix, selectionColumns, groupByColumns, filter, aggregationExpressionBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+        return new DynamicTable(pinotTableName, suffix, selectionColumns, filter, groupByColumns, aggregateColumnsBuilder.build(), orderBy, getTopNOrLimit(request), getOffset(request), query);\n+    }\n+\n+    private static Type toTrinoType(DataSchema.ColumnDataType columnDataType)\n+    {\n+        switch (columnDataType) {\n+            case INT:\n+                return INTEGER;\n+            case LONG:\n+                return BIGINT;\n+            case FLOAT:\n+                return REAL;\n+            case DOUBLE:\n+                return DOUBLE;\n+            case STRING:\n+                return VARCHAR;\n+            case BYTES:\n+                return VARBINARY;\n+            case INT_ARRAY:\n+                return new ArrayType(INTEGER);\n+            case LONG_ARRAY:\n+                return new ArrayType(BIGINT);\n+            case DOUBLE_ARRAY:\n+                return new ArrayType(DOUBLE);\n+            case STRING_ARRAY:\n+                return new ArrayType(VARCHAR);\n+            default:\n+                break;", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MjkyNjE4Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r682926182", "bodyText": "I just removed the default block, left conversation unresolved so you can take a look.", "author": "elonazoulay", "createdAt": "2021-08-04T20:12:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxODEyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzc4MzA5MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683783090", "bodyText": "Got an errorprone warning, will try a few other things out and update shortly.", "author": "elonazoulay", "createdAt": "2021-08-05T20:58:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxODEyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2NjU0Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683966547", "bodyText": "ErrorProne might complain if you don't have a case for each of the possible enumerations.\nIf we already cover all values of the enum then removing default and letting fall-through would've worked but it seems we're missing a case for OBJECT.\nLet's keep as is (otherwise you'd need to add a case for OBJECT and throw from there instead of outside the switch).", "author": "hashhar", "createdAt": "2021-08-06T05:54:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxODEyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxOTgxOA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676319818", "bodyText": "Remove to make the verify in rewrite actually work. This pattern will not match any query shapes that would fail the verify.", "author": "hashhar", "createdAt": "2021-07-26T06:18:44Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementApproxDistinct.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static java.lang.String.format;\n+\n+public class ImplementApproxDistinct\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"approx_distinct\"))\n+                .with(outputType().equalTo(BIGINT))", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mjc4MTk3OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r682781978", "bodyText": "I opted to remove the verify, since this only works when the output type is BIGINT. lmk what you think.", "author": "elonazoulay", "createdAt": "2021-08-04T16:37:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxOTgxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODI3NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683968275", "bodyText": "Makes sense.", "author": "hashhar", "createdAt": "2021-08-06T05:59:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMxOTgxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMyMTg0MQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r676321841", "bodyText": "Take a look at BaseJdbcConnectorTest#testAggregationPushdown (and similarly named methods) for some other useful tests.", "author": "hashhar", "createdAt": "2021-07-26T06:23:24Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +860,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MjkyNjc5OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r682926798", "bodyText": "Sounds good! I will use the base connector tests as soon as pinot supports varbinary and boolean types, which will be in the next release.", "author": "elonazoulay", "createdAt": "2021-08-04T20:13:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMyMTg0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4MjkyNjg3Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r682926872", "bodyText": "Sounds good! I will use the base connector tests as soon as pinot supports varbinary and boolean types, which will be in the next release.", "author": "elonazoulay", "createdAt": "2021-08-04T20:13:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3NjMyMTg0MQ=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2MjEyOA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683962128", "bodyText": "Why the +1? Deserves a comment in my opinion since it's not obvious (to me at least).", "author": "hashhar", "createdAt": "2021-08-06T05:42:13Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +314,73 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !tableHandle.getQuery().get().getAggregateColumns().isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<PinotColumnHandle> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<PinotColumnHandle> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments, tableHandle);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            PinotColumnHandle pinotColumnHandle = rewriteResult.get();\n+            aggregationExpressions.add(pinotColumnHandle);\n+            projections.add(new Variable(pinotColumnHandle.getColumnName(), pinotColumnHandle.getDataType()));\n+            resultAssignments.add(new Assignment(pinotColumnHandle.getColumnName(), pinotColumnHandle, pinotColumnHandle.getDataType()));\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()\n+                .map(PinotColumnHandle.class::cast)\n+                .map(PinotColumnHandle::getColumnName)\n+                .collect(toImmutableList());\n+        OptionalLong limitForDynamicTable = OptionalLong.empty();\n+        // Ensure that pinot default limit of 10 rows is not used\n+        if (tableHandle.getLimit().isEmpty() && !groupingColumns.isEmpty()) {\n+            limitForDynamicTable = OptionalLong.of(maxRowsPerBrokerQuery + 1);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU0NDg5OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684544898", "bodyText": "Sure will add one. Just for context: this is similar to the limit for segment queries which was done like the elastic search connector, @martint pointed me to that code: if the limit is + 1 then the connector will know when too many rows are returned and throw an exception.", "author": "elonazoulay", "createdAt": "2021-08-06T23:18:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2MjEyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2NDQ5NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683964495", "bodyText": "cc: @martint This looks correct to me (I looked at most aggregation functions) but I'd appreciate your view if there are any other functions that behave like count?", "author": "hashhar", "createdAt": "2021-08-06T05:48:50Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/client/PinotClient.java", "diffHunk": "@@ -462,24 +462,39 @@ private BrokerResponseNative submitBrokerQueryJson(ConnectorSession session, Pin\n     public Iterator<BrokerResultRow> createResultIterator(ConnectorSession session, PinotQuery query, List<PinotColumnHandle> columnHandles)\n     {\n         BrokerResponseNative response = submitBrokerQueryJson(session, query);\n-        return fromResultTable(response.getResultTable(), columnHandles);\n+        return fromResultTable(response, columnHandles, query.getGroupByClauses());\n     }\n \n     @VisibleForTesting\n-    public static ResultsIterator fromResultTable(ResultTable resultTable, List<PinotColumnHandle> columnHandles)\n+    public static ResultsIterator fromResultTable(BrokerResponseNative brokerResponse, List<PinotColumnHandle> columnHandles, int groupByClauses)\n     {\n-        requireNonNull(resultTable, \"resultTable is null\");\n+        requireNonNull(brokerResponse, \"brokerResponse is null\");\n         requireNonNull(columnHandles, \"columnHandles is null\");\n+        ResultTable resultTable = brokerResponse.getResultTable();\n         String[] columnNames = resultTable.getDataSchema().getColumnNames();\n         Map<String, Integer> columnIndices = IntStream.range(0, columnNames.length)\n                 .boxed()\n                 // Pinot lower cases column names which use aggregate functions, ex. min(my_Col) becomes min(my_col)\n                 .collect(toImmutableMap(i -> columnNames[i].toLowerCase(ENGLISH), identity()));\n         int[] indices = new int[columnNames.length];\n+        int[] inverseIndices = new int[columnNames.length];\n         for (int i = 0; i < columnHandles.size(); i++) {\n             indices[i] = columnIndices.get(columnHandles.get(i).getColumnName().toLowerCase(ENGLISH));\n+            inverseIndices[indices[i]] = i;\n         }\n-        return new ResultsIterator(resultTable, indices);\n+        List<Object[]> rows = resultTable.getRows();\n+        // If returning from a global aggregation (no grouping columns) over an empty table, NULL-out all aggregation function results except for `count()`", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDUyNjM2Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684526363", "bodyText": "No, count is the only function defined in the SQL spec that has that behavior.", "author": "martint", "createdAt": "2021-08-06T22:08:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2NDQ5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODQzMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683968432", "bodyText": "I think you forgot to remove this (or maybe push the commit?)", "author": "hashhar", "createdAt": "2021-08-06T05:59:41Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementApproxDistinct.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.outputType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static java.lang.String.format;\n+\n+public class ImplementApproxDistinct\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression\n+    private static final Capture<Variable> INPUT = newCapture();\n+\n+    @Override\n+    public Pattern<AggregateFunction> getPattern()\n+    {\n+        return basicAggregation()\n+                .with(functionName().equalTo(\"approx_distinct\"))\n+                .with(outputType().equalTo(BIGINT))\n+                .with(singleInput().matching(variable().capturedAs(INPUT)));\n+    }\n+\n+    @Override\n+    public Optional<PinotColumnHandle> rewrite(AggregateFunction aggregateFunction, Captures captures, RewriteContext context)\n+    {\n+        Variable input = captures.get(INPUT);\n+        verify(aggregateFunction.getOutputType() == BIGINT);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU0NTAzMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684545030", "bodyText": "Thanks:) Will do.", "author": "elonazoulay", "createdAt": "2021-08-06T23:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODQzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODc4MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683968780", "bodyText": "Remove the comment since it's normal for each datasource to have their own aggregation function semantics and hence the rewrite rules need to be different too.", "author": "hashhar", "createdAt": "2021-08-06T06:00:33Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/query/expression/ImplementAvg.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.pinot.query.expression;\n+\n+import com.google.common.collect.ImmutableSet;\n+import io.trino.matching.Capture;\n+import io.trino.matching.Captures;\n+import io.trino.matching.Pattern;\n+import io.trino.plugin.pinot.PinotColumnHandle;\n+import io.trino.spi.connector.AggregateFunction;\n+import io.trino.spi.expression.Variable;\n+import io.trino.spi.type.Type;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static io.trino.matching.Capture.newCapture;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.basicAggregation;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.expressionType;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.functionName;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.singleInput;\n+import static io.trino.plugin.pinot.query.expression.AggregateFunctionPatterns.variable;\n+import static io.trino.spi.type.BigintType.BIGINT;\n+import static io.trino.spi.type.DoubleType.DOUBLE;\n+import static io.trino.spi.type.IntegerType.INTEGER;\n+import static io.trino.spi.type.RealType.REAL;\n+import static java.lang.String.format;\n+\n+public class ImplementAvg\n+        implements AggregateFunctionRule\n+{\n+    // Extracted from io.trino.plugin.jdbc.expression", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2OTQ1Mw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683969453", "bodyText": "Same for other rewrites too IMO. (But yeah, I would like to use the changes in #8578 if possible).", "author": "hashhar", "createdAt": "2021-08-06T06:02:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk2ODc4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MTgxMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683971810", "bodyText": "Can we add validation on our end to disallow such queries? Or is this not easy to do due to dynamic tables?\nOverflows can turn into unsigned values again if the value is sufficiently large (which is easy to do with typos).", "author": "hashhar", "createdAt": "2021-08-06T06:07:53Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -578,12 +603,52 @@ public void testBrokerQueryWithTooManyRowsForSegmentQuery()\n                 tooManyRowsTableValues);\n     }\n \n+    @Test\n+    public void testMaxLimitForPassthroughQueries()\n+            throws InterruptedException\n+    {\n+        assertQueryFails(\"SELECT string_col, updated_at_seconds\" +\n+                        \"  FROM  \\\"SELECT updated_at_seconds, string_col FROM \" + TOO_MANY_BROKER_ROWS_TABLE +\n+                        \"  LIMIT \" + (MAX_ROWS_PER_SPLIT_FOR_BROKER_QUERIES + 1) + \"\\\"\",\n+                \"Broker query returned '13' rows, maximum allowed is '12' rows. with query \\\"select updated_at_seconds, string_col from too_many_broker_rows limit 13\\\"\");\n+\n+        // Pinot issue preventing Integer.MAX_VALUE from being a limit: https://github.com/apache/incubator-pinot/issues/7110\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + Integer.MAX_VALUE + \"\\\"\",\n+                \"Unexpected response status: 500 for request \\\\{\\\"sql\\\" : \\\"select string_col, long_col from alltypes limit 2147483647\\\" \\\\} to url http://localhost:\\\\d+/query/sql, with headers \\\\{Accept=\\\\[application/json\\\\], Content-Type=\\\\[application/json\\\\]\\\\}, full response null\");\n+\n+        // Pinot broker requests do not handle limits greater than Integer.MAX_VALUE\n+        // Note that -2147483648 is due to an integer overflow in Pinot: https://github.com/apache/pinot/issues/7242", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5NDI5OA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684594298", "bodyText": "There is no easy way: the pinot request compiler will throw this error for dynamic tables when it parses the passthrough query.", "author": "elonazoulay", "createdAt": "2021-08-07T06:44:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MTgxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjMwMQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683972301", "bodyText": "This behaviour might be very surprising for people looking at this from the Trino side. Not sure if we can do anything about this though?", "author": "hashhar", "createdAt": "2021-08-06T06:08:56Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -578,12 +603,52 @@ public void testBrokerQueryWithTooManyRowsForSegmentQuery()\n                 tooManyRowsTableValues);\n     }\n \n+    @Test\n+    public void testMaxLimitForPassthroughQueries()\n+            throws InterruptedException\n+    {\n+        assertQueryFails(\"SELECT string_col, updated_at_seconds\" +\n+                        \"  FROM  \\\"SELECT updated_at_seconds, string_col FROM \" + TOO_MANY_BROKER_ROWS_TABLE +\n+                        \"  LIMIT \" + (MAX_ROWS_PER_SPLIT_FOR_BROKER_QUERIES + 1) + \"\\\"\",\n+                \"Broker query returned '13' rows, maximum allowed is '12' rows. with query \\\"select updated_at_seconds, string_col from too_many_broker_rows limit 13\\\"\");\n+\n+        // Pinot issue preventing Integer.MAX_VALUE from being a limit: https://github.com/apache/incubator-pinot/issues/7110\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + Integer.MAX_VALUE + \"\\\"\",\n+                \"Unexpected response status: 500 for request \\\\{\\\"sql\\\" : \\\"select string_col, long_col from alltypes limit 2147483647\\\" \\\\} to url http://localhost:\\\\d+/query/sql, with headers \\\\{Accept=\\\\[application/json\\\\], Content-Type=\\\\[application/json\\\\]\\\\}, full response null\");\n+\n+        // Pinot broker requests do not handle limits greater than Integer.MAX_VALUE\n+        // Note that -2147483648 is due to an integer overflow in Pinot: https://github.com/apache/pinot/issues/7242\n+        assertQueryFails(\"SELECT * FROM \\\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + ((long) Integer.MAX_VALUE + 1) + \"\\\"\",\n+                \"Query select string_col, long_col from alltypes limit -2147483648 encountered exception org.apache.pinot.common.response.broker.QueryProcessingException@\\\\w+ with query \\\"select string_col, long_col from alltypes limit -2147483648\\\"\");\n+\n+        String tooManyBrokerRowsTableValues = \"VALUES ('string_0', '1620604800'),\" +\n+                \"  ('string_1', '1620604801'),\" +\n+                \"  ('string_2', '1620604802'),\" +\n+                \"  ('string_3', '1620604803'),\" +\n+                \"  ('string_4', '1620604804'),\" +\n+                \"  ('string_5', '1620604805'),\" +\n+                \"  ('string_6', '1620604806'),\" +\n+                \"  ('string_7', '1620604807'),\" +\n+                \"  ('string_8', '1620604808'),\" +\n+                \"  ('string_9', '1620604809'),\" +\n+                \"  ('string_10', '1620604810'),\" +\n+                \"  ('string_11', '1620604811')\";\n+\n+        // Explicit limit is necessary otherwise pinot returns 10 rows.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU0NTk1NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684545954", "bodyText": "Yep, I think it was done in pinot to make data exploration easier, but it was not obvious until I actually ran tests and found that out.", "author": "elonazoulay", "createdAt": "2021-08-06T23:22:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjMwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5MTQ5Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684591492", "bodyText": "The broker limit helps with this: if no limit is supplied then the default broker limit is applied.", "author": "elonazoulay", "createdAt": "2021-08-07T06:15:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjMwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjkwOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683972909", "bodyText": "Is the filter on long_col pushed down? We should have tests with both cases where the predicate gets pushed down and where the filtering is done by the engine.", "author": "hashhar", "createdAt": "2021-08-06T06:10:19Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU4MjY1NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684582654", "bodyText": "I thought this test compares the results with and without pushdown, verifies types and rows match. Let me know if you meant something else.", "author": "elonazoulay", "createdAt": "2021-08-07T04:37:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjkwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU4MjY2NA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684582664", "bodyText": "I thought this test compares the results with and without pushdown, verifies types and rows match. Let me know if you meant something else.", "author": "elonazoulay", "createdAt": "2021-08-07T04:37:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjkwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzExMjY2Nw==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r687112667", "bodyText": "@elonazoulay The test disables ALL pushdowns. I meant a test where the predicate cannot be pushed down but the aggregation could be. The reasoning is that if the predicates are applied incorrectly or at the wrong time the aggregation would return different results.", "author": "hashhar", "createdAt": "2021-08-11T19:26:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MjkwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzExNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973115", "bodyText": "https://github.com/trinodb/trino/pull/6069/files#r683972909", "author": "hashhar", "createdAt": "2021-08-06T06:10:47Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU4MjcwOQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684582709", "bodyText": "Same as above. Let me know.", "author": "elonazoulay", "createdAt": "2021-08-07T04:38:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzIyMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973220", "bodyText": "https://github.com/trinodb/trino/pull/6069/files#r683972909", "author": "hashhar", "createdAt": "2021-08-06T06:11:06Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a filter", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU4Mjc0MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684582740", "bodyText": "Same as above, let me know.", "author": "elonazoulay", "createdAt": "2021-08-07T04:39:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzIyMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU4Mjc2Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684582766", "bodyText": "Same as above, let me know.", "author": "elonazoulay", "createdAt": "2021-08-07T04:39:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzIyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzI1MA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973250", "bodyText": "https://github.com/trinodb/trino/pull/6069/files#r683972909", "author": "hashhar", "createdAt": "2021-08-06T06:11:10Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a filter\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649 GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column, a filter and a limit", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzUyMg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683973522", "bodyText": "Also, can we tests for MAX/MIN over text types? This is related to #8551.\nSee the test added in that PR for an example.\nEDIT: I see there are explicit tests verifying MIN/MAX aren't pushed down but distinct is getting pushed down. Can you add a test case similar to the one in linked PR for correctness of distinct over VARCHAR?", "author": "hashhar", "createdAt": "2021-08-06T06:11:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzI1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU4Mjk1Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684582956", "bodyText": "Pinot does not support min/max for varchar or boolean using this version of the pinot libraries (0.6.0). Will upgrade soon and retest. The min/max aggregations are not pushed down: see SUPPORTED_TYPES in the ImplementMinMax.", "author": "elonazoulay", "createdAt": "2021-08-07T04:41:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzI1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NDU5MDkxNg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r684590916", "bodyText": "Added some tests for mixed case values with distinct, count distinct and approx_distinct.", "author": "elonazoulay", "createdAt": "2021-08-07T06:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3MzI1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4Mzk3NDc1Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r683974752", "bodyText": "nit: extra space after SELECT", "author": "hashhar", "createdAt": "2021-08-06T06:15:06Z", "path": "plugin/trino-pinot/src/test/java/io/trino/plugin/pinot/TestPinotIntegrationSmokeTest.java", "diffHunk": "@@ -796,4 +861,264 @@ public void testLimitPushdown()\n         assertThat(query(\"SELECT string_col, long_col FROM \" + ALL_TYPES_TABLE + \"  WHERE int_col >0 AND bool_col = 'false' LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n                 .isNotFullyPushedDown(LimitNode.class);\n     }\n+\n+    @Test\n+    public void testAggregationPushdown()\n+    {\n+        // Without the limit inside the passthrough query, pinot will only return 10 rows\n+        assertThat(query(\"SELECT COUNT(*) FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with no grouping columns with a filter and limit\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column and a filter\n+        assertThat(query(\"SELECT bool_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649 GROUP BY bool_col\"))\n+                .isFullyPushedDown();\n+\n+        // Test aggregates with one grouping column, a filter and a limit\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col < 4147483649 GROUP BY string_col\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // Test single row from pinot where filter results in an empty result set.\n+        // A direct pinot query would return 1 row with default values, not null values.\n+        assertThat(query(\"SELECT COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" WHERE long_col > 4147483649\")).isFullyPushedDown();\n+\n+        // Test passthrough queries with no aggregates\n+        assertThat(query(\"SELECT string_col, COUNT(*),\" +\n+                \"  MIN(int_col), MAX(int_col),\" +\n+                \"  MIN(long_col), MAX(long_col), AVG(long_col), SUM(long_col),\" +\n+                \"  MIN(float_col), MAX(float_col), AVG(float_col), SUM(float_col),\" +\n+                \"  MIN(double_col), MAX(double_col), AVG(double_col), SUM(double_col)\" +\n+                \"  FROM \\\"SELECT * FROM \" + ALL_TYPES_TABLE + \" WHERE long_col > 4147483649\" +\n+                \"  LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES + \"\\\"  GROUP BY string_col\"))\n+                .isFullyPushedDown();\n+\n+        // Passthrough queries with aggregates will not push down more aggregations.\n+        assertThat(query(\"SELECT bool_col, \\\"count(*)\\\", COUNT(*) FROM \\\"SELECT bool_col, count(*) FROM \" +\n+                ALL_TYPES_TABLE + \" GROUP BY bool_col\\\" GROUP BY bool_col, \\\"count(*)\\\"\"))\n+                .isNotFullyPushedDown(ExchangeNode.class, ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        assertThat(query(\"SELECT bool_col, \\\"max(long_col)\\\", COUNT(*) FROM \\\"SELECT bool_col, max(long_col) FROM \" +\n+                ALL_TYPES_TABLE + \" GROUP BY bool_col\\\" GROUP BY bool_col, \\\"max(long_col)\\\"\"))\n+                .isNotFullyPushedDown(ExchangeNode.class, ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        assertThat(query(\"SELECT int_col, COUNT(*) FROM \" + ALL_TYPES_TABLE + \" GROUP BY int_col LIMIT \" + MAX_ROWS_PER_SPLIT_FOR_SEGMENT_QUERIES))\n+                .isFullyPushedDown();\n+\n+        // count(<column>) should not be pushed down, as pinot currently only implements count(*)\n+        assertThat(query(\"SELECT bool_col, COUNT(long_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // AVG on INTEGER columns is not pushed down\n+        assertThat(query(\"SELECT string_col, AVG(int_col) FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // SUM on INTEGER columns is not pushed down\n+        assertThat(query(\"SELECT string_col, SUM(int_col) FROM \" + ALL_TYPES_TABLE + \" GROUP BY string_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // MIN on VARCHAR columns is not pushed down\n+        assertThat(query(\"SELECT bool_col, MIN(string_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // MAX on VARCHAR columns is not pushed down\n+        assertThat(query(\"SELECT bool_col, MAX(string_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // COUNT on VARCHAR columns is not pushed down\n+        assertThat(query(\"SELECT bool_col, COUNT(string_col)\" +\n+                \"  FROM \" + ALL_TYPES_TABLE + \" GROUP BY bool_col\"))\n+                .isNotFullyPushedDown(ProjectNode.class, AggregationNode.class, ExchangeNode.class, ExchangeNode.class, AggregationNode.class, ProjectNode.class);\n+\n+        // Distinct on varchar is pushed down\n+        assertThat(query(\"SELECT DISTINCT string_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on bool is pushed down\n+        assertThat(query(\"SELECT DISTINCT bool_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on double is pushed down\n+        assertThat(query(\"SELECT DISTINCT double_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on float is pushed down\n+        assertThat(query(\"SELECT DISTINCT float_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on long is pushed down\n+        assertThat(query(\"SELECT DISTINCT long_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        // Distinct on int is partially pushed down\n+        assertThat(query(\"SELECT DISTINCT int_col FROM \" + ALL_TYPES_TABLE))\n+                .isNotFullyPushedDown(ExchangeNode.class);\n+\n+        // Distinct on 2 columns for supported types:\n+        assertThat(query(\"SELECT DISTINCT bool_col, string_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, double_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, float_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, long_col FROM \" + ALL_TYPES_TABLE))\n+                .isFullyPushedDown();\n+        assertThat(query(\"SELECT DISTINCT bool_col, int_col FROM \" + ALL_TYPES_TABLE))\n+                .isNotFullyPushedDown(ExchangeNode.class);\n+\n+        // Approx distinct on varchar is pushed down\n+        assertThat(query(\"SELECT  approx_distinct(string_col) FROM \" + ALL_TYPES_TABLE))", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r687121892", "bodyText": "@elonazoulay IIUC the grouping columns in rewrite context are only needed to verify that the grouping columns are part of the SELECT clause. If so, can we instead do that validation here after the rewrite is done?\nYes, the connector will end up doing work that gets discarded but that seems cleaner because even if we add grouping columns to RewriteContext I don't see an easy way to populate them for other connectors so we won't be able to provide a sane impl. which doesn't return null for that method.\nI think this is possible to do because here we have tableHandle available from which we can get the grouping columns in case of DynamicTable.", "author": "hashhar", "createdAt": "2021-08-11T19:41:54Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -294,6 +314,75 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !tableHandle.getQuery().get().getAggregateColumns().isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<PinotColumnHandle> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<PinotColumnHandle> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments, tableHandle);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            PinotColumnHandle pinotColumnHandle = rewriteResult.get();\n+            aggregationExpressions.add(pinotColumnHandle);\n+            projections.add(new Variable(pinotColumnHandle.getColumnName(), pinotColumnHandle.getDataType()));\n+            resultAssignments.add(new Assignment(pinotColumnHandle.getColumnName(), pinotColumnHandle, pinotColumnHandle.getDataType()));\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzU0NjY0Mg==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r687546642", "bodyText": "Yep, in a previous version of this pr it was done before the rewrite rules, I can add it back. Another idea: can RewriteContext.getGroupingColumns() return an Optional<List> as a default method?", "author": "elonazoulay", "createdAt": "2021-08-12T09:29:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzU2NDE4NQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r687564185", "bodyText": "Was there some specific reason to change from the old implementation? Maybe I'm missing something. If it's feasible to do I'd like that.\nAs for the RewriteContext changes I'll defer to @martint (and Piotr once he's back). IMO if we have alternatives which are cleaner then I'd like to avoid the change. IMO the validation that grouping columns are part of select isn't exclusive to just count_distinct and makes sense to do before any rewrite.", "author": "hashhar", "createdAt": "2021-08-12T09:53:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4ODA2NzQxNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r688067415", "bodyText": "Sounds good. Would another option be to pass the table handle into the rewrite context? I can get the grouping columns there also.", "author": "elonazoulay", "createdAt": "2021-08-12T20:37:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5MDIwNjcxNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r690206715", "bodyText": "@hashhar - I extracted the check for grouping columns and reverted the changes for AggregateFunctionRewriter and RewriteContext. What do you think about adding TableHandle to the RewriteContext instead of this approach?\nJust in case I saved the previous version.", "author": "elonazoulay", "createdAt": "2021-08-17T09:41:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5MTE4MTE4Ng==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r691181186", "bodyText": "I like the newer version. We can revisit changing RewriteContext once we have other non-JDBC connectors that implement agg pushdown. We'll have better information at that time to decide the correct abstraction.", "author": "hashhar", "createdAt": "2021-08-18T12:18:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY4NzEyMTg5Mg=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5MTE4MDAxMA==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r691180010", "bodyText": "Should this return empty if the grouping column doesn't contain the column on which aggregation is applied? Or should it throw an error?", "author": "hashhar", "createdAt": "2021-08-18T12:16:51Z", "path": "plugin/trino-pinot/src/main/java/io/trino/plugin/pinot/PinotMetadata.java", "diffHunk": "@@ -305,6 +328,109 @@ public ConnectorTableProperties getTableProperties(ConnectorSession session, Con\n         return Optional.of(new ConstraintApplicationResult<>(handle, remainingFilter, false));\n     }\n \n+    @Override\n+    public Optional<AggregationApplicationResult<ConnectorTableHandle>> applyAggregation(\n+            ConnectorSession session,\n+            ConnectorTableHandle handle,\n+            List<AggregateFunction> aggregates,\n+            Map<String, ColumnHandle> assignments,\n+            List<List<ColumnHandle>> groupingSets)\n+    {\n+        if (!isAggregationPushdownEnabled(session)) {\n+            return Optional.empty();\n+        }\n+\n+        // Global aggregation is represented by [[]]\n+        verify(!groupingSets.isEmpty(), \"No grouping sets provided\");\n+\n+        // Pinot currently only supports simple GROUP BY clauses with a single grouping set\n+        if (groupingSets.size() != 1) {\n+            return Optional.empty();\n+        }\n+\n+        PinotTableHandle tableHandle = (PinotTableHandle) handle;\n+        // If aggregate are present than no further aggregations\n+        // can be pushed down: there are currently no subqueries in pinot\n+        if (tableHandle.getQuery().isPresent() &&\n+                !tableHandle.getQuery().get().getAggregateColumns().isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        ImmutableList.Builder<ConnectorExpression> projections = ImmutableList.builder();\n+        ImmutableList.Builder<Assignment> resultAssignments = ImmutableList.builder();\n+        ImmutableList.Builder<PinotColumnHandle> aggregationExpressions = ImmutableList.builder();\n+\n+        for (AggregateFunction aggregate : aggregates) {\n+            Optional<PinotColumnHandle> rewriteResult = aggregateFunctionRewriter.rewrite(session, aggregate, assignments);\n+            rewriteResult = applyCountDistinct(session, aggregate, assignments, tableHandle, rewriteResult);\n+            if (rewriteResult.isEmpty()) {\n+                return Optional.empty();\n+            }\n+            PinotColumnHandle pinotColumnHandle = rewriteResult.get();\n+            aggregationExpressions.add(pinotColumnHandle);\n+            projections.add(new Variable(pinotColumnHandle.getColumnName(), pinotColumnHandle.getDataType()));\n+            resultAssignments.add(new Assignment(pinotColumnHandle.getColumnName(), pinotColumnHandle, pinotColumnHandle.getDataType()));\n+        }\n+        List<String> groupingColumns = getOnlyElement(groupingSets).stream()\n+                .map(PinotColumnHandle.class::cast)\n+                .map(PinotColumnHandle::getColumnName)\n+                .collect(toImmutableList());\n+        OptionalLong limitForDynamicTable = OptionalLong.empty();\n+        // Ensure that pinot default limit of 10 rows is not used\n+        // By setting the limit to maxRowsPerBrokerQuery + 1 the connector will\n+        // know when the limit was exceeded and throw an error\n+        if (tableHandle.getLimit().isEmpty() && !groupingColumns.isEmpty()) {\n+            limitForDynamicTable = OptionalLong.of(maxRowsPerBrokerQuery + 1);\n+        }\n+        DynamicTable dynamicTable = new DynamicTable(\n+                tableHandle.getTableName(),\n+                Optional.empty(),\n+                ImmutableList.of(),\n+                tableHandle.getQuery().flatMap(DynamicTable::getFilter),\n+                groupingColumns,\n+                aggregationExpressions.build(),\n+                ImmutableList.of(),\n+                limitForDynamicTable,\n+                OptionalLong.empty(),\n+                \"\");\n+        tableHandle = new PinotTableHandle(tableHandle.getSchemaName(), tableHandle.getTableName(), tableHandle.getConstraint(), tableHandle.getLimit(), Optional.of(dynamicTable));\n+\n+        return Optional.of(new AggregationApplicationResult<>(tableHandle, projections.build(), resultAssignments.build(), ImmutableMap.of(), false));\n+    }\n+\n+    private Optional<PinotColumnHandle> applyCountDistinct(ConnectorSession session, AggregateFunction aggregate, Map<String, ColumnHandle> assignments, PinotTableHandle tableHandle, Optional<PinotColumnHandle> rewriteResult)\n+    {\n+        AggregateFunctionRule.RewriteContext context = new AggregateFunctionRule.RewriteContext()\n+        {\n+            @Override\n+            public Map<String, ColumnHandle> getAssignments()\n+            {\n+                return assignments;\n+            }\n+\n+            @Override\n+            public Function<String, String> getIdentifierQuote()\n+            {\n+                return identity();\n+            }\n+\n+            @Override\n+            public ConnectorSession getSession()\n+            {\n+                return session;\n+            }\n+        };\n+\n+        if (implementCountDistinct.getPattern().matches(aggregate, context) && aggregate.getInputs().size() == 1) {\n+            Variable input = (Variable) getOnlyElement(aggregate.getInputs());\n+            if (tableHandle.getQuery().isEmpty() ||\n+                    !tableHandle.getQuery().get().getGroupingColumns().contains(input.getName())) {\n+                return Optional.empty();", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5MzM5MjEyNQ==", "url": "https://github.com/trinodb/trino/pull/6069#discussion_r693392125", "bodyText": "It should return empty not push the aggregation down. Added tests to verify this behavior with corner cases, like when the broker query is present and there is no count distinct. Also added a comment explaining the reason: count() is allowed in the query, just should not be pushed down, it's not an error condition.", "author": "elonazoulay", "createdAt": "2021-08-21T19:29:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY5MTE4MDAxMA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "a30d8750e7120739e2118bcc987ca5349ad0c22a", "url": "https://github.com/trinodb/trino/commit/a30d8750e7120739e2118bcc987ca5349ad0c22a", "message": "Reorder DynamicTable members\n\nReorder members and constructor parameters in order\nof pushdown application.", "committedDate": "2021-08-22T21:52:54Z", "type": "commit"}, {"oid": "a0a92dd574008f4dc6cefc15337ecfff159ee02e", "url": "https://github.com/trinodb/trino/commit/a0a92dd574008f4dc6cefc15337ecfff159ee02e", "message": "Add filter to equals, hashCode and toString in DynamicTable", "committedDate": "2021-08-22T21:55:38Z", "type": "commit"}, {"oid": "e9e6ad81fdf542080b4368f901f1ccdac527e13f", "url": "https://github.com/trinodb/trino/commit/e9e6ad81fdf542080b4368f901f1ccdac527e13f", "message": "Add limit for broker queries\n\nAdd a config to set broker query limit.\nIf the limit is set too high, pinot can oom:\nhttps://github.com/apache/incubator-pinot/issues/7110", "committedDate": "2021-08-22T21:56:07Z", "type": "commit"}, {"oid": "f58979f68eda059ca3c8ee686ffb08ed98aefab1", "url": "https://github.com/trinodb/trino/commit/f58979f68eda059ca3c8ee686ffb08ed98aefab1", "message": "Add null handling for decoders\n\nThis is a prepatory commit for aggregation pushdown\nwhich sets values to null, otherwise pinot never\nreturns null values.", "committedDate": "2021-08-22T21:56:14Z", "type": "commit"}, {"oid": "a1feed23cdaa5f60b5eb5a9f7f1d26303a18960f", "url": "https://github.com/trinodb/trino/commit/a1feed23cdaa5f60b5eb5a9f7f1d26303a18960f", "message": "Implement aggregation pushdown in Pinot", "committedDate": "2021-08-22T22:01:16Z", "type": "commit"}, {"oid": "8723d41d1d78ce30174fc9b953c969b02616387e", "url": "https://github.com/trinodb/trino/commit/8723d41d1d78ce30174fc9b953c969b02616387e", "message": "Implement Distinct Count Pushdown in Pinot", "committedDate": "2021-08-22T22:03:14Z", "type": "commit"}, {"oid": "8723d41d1d78ce30174fc9b953c969b02616387e", "url": "https://github.com/trinodb/trino/commit/8723d41d1d78ce30174fc9b953c969b02616387e", "message": "Implement Distinct Count Pushdown in Pinot", "committedDate": "2021-08-22T22:03:14Z", "type": "forcePushed"}]}