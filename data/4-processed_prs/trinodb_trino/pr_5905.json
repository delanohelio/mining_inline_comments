{"pr_number": 5905, "pr_title": "Improve serde performance for Long blocks", "pr_createdAt": "2020-11-10T16:49:46Z", "pr_url": "https://github.com/trinodb/trino/pull/5905", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEyOTAxNA==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521129014", "bodyText": "Can we implement the same for other native array block ?", "author": "Praveen2112", "createdAt": "2020-11-11T05:55:57Z", "path": "presto-spi/src/main/java/io/prestosql/spi/block/LongArrayBlockEncoding.java", "diffHunk": "@@ -53,9 +54,14 @@ public Block readBlock(BlockEncodingSerde blockEncodingSerde, SliceInput sliceIn\n         boolean[] valueIsNull = decodeNullBits(sliceInput, positionCount).orElse(null);\n \n         long[] values = new long[positionCount];\n-        for (int position = 0; position < positionCount; position++) {\n-            if (valueIsNull == null || !valueIsNull[position]) {\n-                values[position] = sliceInput.readLong();\n+        if (valueIsNull == null) {\n+            sliceInput.readBytes(Slices.wrappedLongArray(values), 0, Long.BYTES * positionCount);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxMDU4Mg==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r522210582", "bodyText": "This will be part of follow up PRs", "author": "sopel39", "createdAt": "2020-11-12T15:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEyOTAxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEyOTEwMA==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521129100", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        sliceInput.readBytes(Slices.wrappedLongArray(values), 0, Long.BYTES * positionCount);\n          \n          \n            \n                        sliceInput.readBytes(Slices.wrappedLongArray(values), Long.BYTES * positionCount);", "author": "Praveen2112", "createdAt": "2020-11-11T05:56:15Z", "path": "presto-spi/src/main/java/io/prestosql/spi/block/LongArrayBlockEncoding.java", "diffHunk": "@@ -53,9 +54,14 @@ public Block readBlock(BlockEncodingSerde blockEncodingSerde, SliceInput sliceIn\n         boolean[] valueIsNull = decodeNullBits(sliceInput, positionCount).orElse(null);\n \n         long[] values = new long[positionCount];\n-        for (int position = 0; position < positionCount; position++) {\n-            if (valueIsNull == null || !valueIsNull[position]) {\n-                values[position] = sliceInput.readLong();\n+        if (valueIsNull == null) {\n+            sliceInput.readBytes(Slices.wrappedLongArray(values), 0, Long.BYTES * positionCount);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTEzMTIyOA==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521131228", "bodyText": "Can we use RecordPageSource ? But we might need to add it to pom I guess", "author": "Praveen2112", "createdAt": "2020-11-11T06:03:24Z", "path": "presto-tpch/src/main/java/io/prestosql/plugin/tpch/TpchTables.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.tpch;\n+\n+import com.google.common.collect.AbstractIterator;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.connector.ConnectorPageSource;\n+import io.prestosql.spi.predicate.TupleDomain;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.tpch.TpchTable;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.tpch.TpchRecordSet.createTpchRecordSet;\n+\n+public final class TpchTables\n+{\n+    private TpchTables()\n+    {\n+    }\n+\n+    public static List<Type> getTableColumns(String tableName)\n+    {\n+        TpchTable<?> table = TpchTable.getTable(tableName);\n+        return table.getColumns().stream()\n+                .map(TpchMetadata::getPrestoType)\n+                .collect(toImmutableList());\n+    }\n+\n+    public static Iterator<Page> getTablePages(\n+            String tableName,\n+            double scaleFactor,\n+            int maxRowsPerPage)\n+    {\n+        TpchTable table = TpchTable.getTable(tableName);\n+        ConnectorPageSource pageSource = new LazyRecordPageSource(", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIwNjg2OQ==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521206869", "bodyText": "nit: static import", "author": "skrzypo987", "createdAt": "2020-11-11T08:54:16Z", "path": "presto-orc/src/test/java/io/prestosql/orc/BenchmarkColumnReaders.java", "diffHunk": "@@ -1066,6 +1060,20 @@ public void setup()\n         }\n     }\n \n+    @State(Scope.Thread)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIwNzY4Ng==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521207686", "bodyText": "while(pages.hasNext()){", "author": "skrzypo987", "createdAt": "2020-11-11T08:55:43Z", "path": "presto-orc/src/test/java/io/prestosql/orc/OrcTester.java", "diffHunk": "@@ -602,6 +604,34 @@ static OrcRecordReader createCustomOrcRecordReader(TempFile tempFile, OrcPredica\n                 RuntimeException::new);\n     }\n \n+    public static void writeOrcPages(File outputFile, CompressionKind compression, List<Type> types, Iterator<Page> pages, OrcWriterStats stats)\n+            throws Exception\n+    {\n+        List<String> columnNames = IntStream.range(0, types.size())\n+                .mapToObj(i -> \"test\" + i)\n+                .collect(toImmutableList());\n+\n+        OrcWriter writer = new OrcWriter(\n+                new OutputStreamOrcDataSink(new FileOutputStream(outputFile)),\n+                columnNames,\n+                types,\n+                OrcType.createRootOrcType(columnNames, types),\n+                compression,\n+                new OrcWriterOptions(),\n+                false,\n+                ImmutableMap.of(),\n+                true,\n+                BOTH,\n+                stats);\n+\n+        for (; pages.hasNext(); ) {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIxNTYwNg==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521215606", "bodyText": "What is the difference between this one and BigintWithNullBenchmarkDataNonOptimized?\nThey look the same", "author": "skrzypo987", "createdAt": "2020-11-11T09:09:46Z", "path": "presto-main/src/test/java/io/prestosql/execution/buffer/BenchmarkBlockSerde.java", "diffHunk": "@@ -0,0 +1,448 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.execution.buffer;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.airlift.slice.BasicSliceInput;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.OutputStreamSliceOutput;\n+import io.airlift.slice.Slice;\n+import io.prestosql.spi.Page;\n+import io.prestosql.spi.PageBuilder;\n+import io.prestosql.spi.block.BlockBuilder;\n+import io.prestosql.spi.block.TestingBlockEncodingSerde;\n+import io.prestosql.spi.type.DecimalType;\n+import io.prestosql.spi.type.Decimals;\n+import io.prestosql.spi.type.SqlDecimal;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.VarcharType;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OperationsPerInvocation;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.VerboseMode;\n+import org.testng.annotations.Test;\n+\n+import java.math.BigInteger;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+\n+import static io.airlift.slice.Slices.utf8Slice;\n+import static io.prestosql.execution.buffer.PagesSerdeUtil.readPages;\n+import static io.prestosql.execution.buffer.PagesSerdeUtil.writePages;\n+import static io.prestosql.plugin.tpch.TpchTables.getTablePages;\n+import static io.prestosql.spi.type.BigintType.BIGINT;\n+import static io.prestosql.spi.type.DecimalType.createDecimalType;\n+import static io.prestosql.spi.type.VarcharType.VARCHAR;\n+import static io.prestosql.spi.type.Varchars.truncateToLength;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+@State(Scope.Thread)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@Fork(3)\n+@Warmup(iterations = 30, time = 500, timeUnit = MILLISECONDS)\n+@Measurement(iterations = 20, time = 500, timeUnit = MILLISECONDS)\n+@BenchmarkMode(Mode.AverageTime)\n+@OperationsPerInvocation(BenchmarkBlockSerde.ROWS)\n+public class BenchmarkBlockSerde\n+{\n+    private static final DecimalType LONG_DECIMAL_TYPE = createDecimalType(30, 5);\n+\n+    public static final int ROWS = 10_000_000;\n+    private static final int MAX_STRING = 19;\n+\n+    @Benchmark\n+    public Object deserializeLongDecimalNoNull(LongDecimalNoNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeLongDecimalWithNull(LongDecimalWithNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeLongNonRandomNoNull(BigintNonRandomNoNullNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeLongNoNull(BigintNoNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeLongWithNull(BigintWithNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeSliceDirectNoNull(VarcharDirectNoNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeSliceDirectWithNull(VarcharDirectWithNullBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    @Benchmark\n+    public Object deserializeLineitem(LineitemBenchmarkData data)\n+    {\n+        return ImmutableList.copyOf(readPages(data.getPagesSerde(), new BasicSliceInput(data.getDataSource())));\n+    }\n+\n+    public abstract static class BenchmarkData\n+    {\n+        protected final Random random = new Random(0);\n+        private Slice dataSource;\n+        private PagesSerde pagesSerde;\n+\n+        public void setup(Iterator<Page> pages)\n+                throws Exception\n+        {\n+            pagesSerde = new TestingPagesSerdeFactory(new TestingBlockEncodingSerde(), false).createPagesSerde();\n+\n+            DynamicSliceOutput sliceOutput = new DynamicSliceOutput(0);\n+            writePages(pagesSerde, new OutputStreamSliceOutput(sliceOutput), pages);\n+            dataSource = sliceOutput.slice();\n+        }\n+\n+        public void setup(Type type, Iterator<?> values)\n+                throws Exception\n+        {\n+            pagesSerde = new TestingPagesSerdeFactory(new TestingBlockEncodingSerde(), false).createPagesSerde();\n+            PageBuilder pageBuilder = new PageBuilder(ImmutableList.of(type));\n+            BlockBuilder blockBuilder = pageBuilder.getBlockBuilder(0);\n+            ImmutableList.Builder<Page> pages = ImmutableList.builder();\n+            while (values.hasNext()) {\n+                Object value = values.next();\n+                if (value == null) {\n+                    blockBuilder.appendNull();\n+                }\n+                else if (BIGINT.equals(type)) {\n+                    BIGINT.writeLong(blockBuilder, ((Number) value).longValue());\n+                }\n+                else if (Decimals.isLongDecimal(type)) {\n+                    type.writeSlice(blockBuilder, Decimals.encodeUnscaledValue(((SqlDecimal) value).toBigDecimal().unscaledValue()));\n+                }\n+                else if (type instanceof VarcharType) {\n+                    Slice slice = truncateToLength(utf8Slice((String) value), type);\n+                    type.writeSlice(blockBuilder, slice);\n+                }\n+                else {\n+                    throw new IllegalArgumentException(\"Unsupported type \" + type);\n+                }\n+                pageBuilder.declarePosition();\n+                if (pageBuilder.isFull()) {\n+                    pages.add(pageBuilder.build());\n+                    pageBuilder.reset();\n+                    blockBuilder = pageBuilder.getBlockBuilder(0);\n+                }\n+            }\n+            if (pageBuilder.getPositionCount() > 0) {\n+                pages.add(pageBuilder.build());\n+            }\n+\n+            DynamicSliceOutput sliceOutput = new DynamicSliceOutput(0);\n+            writePages(pagesSerde, new OutputStreamSliceOutput(sliceOutput), pages.build().iterator());\n+            dataSource = sliceOutput.slice();\n+        }\n+\n+        public PagesSerde getPagesSerde()\n+        {\n+            return pagesSerde;\n+        }\n+\n+        public Slice getDataSource()\n+        {\n+            return dataSource;\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class LongDecimalNoNullBenchmarkData\n+            extends BenchmarkData\n+    {\n+        @Setup\n+        public void setup()\n+                throws Exception\n+        {\n+            setup(LONG_DECIMAL_TYPE, createValues());\n+        }\n+\n+        private Iterator<?> createValues()\n+        {\n+            List<SqlDecimal> values = new ArrayList<>();\n+            for (int i = 0; i < ROWS; ++i) {\n+                values.add(new SqlDecimal(new BigInteger(96, random), 30, 5));\n+            }\n+            return values.iterator();\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class LongDecimalWithNullBenchmarkData\n+            extends BenchmarkData\n+    {\n+        @Setup\n+        public void setup()\n+                throws Exception\n+        {\n+            setup(LONG_DECIMAL_TYPE, createValues());\n+        }\n+\n+        private Iterator<?> createValues()\n+        {\n+            List<SqlDecimal> values = new ArrayList<>();\n+            for (int i = 0; i < ROWS; ++i) {\n+                if (random.nextBoolean()) {\n+                    values.add(new SqlDecimal(new BigInteger(96, random), 30, 5));\n+                }\n+                else {\n+                    values.add(null);\n+                }\n+            }\n+            return values.iterator();\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BigintNonRandomNoNullNullBenchmarkData\n+            extends BenchmarkData\n+    {\n+        @Setup\n+        public void setup()\n+                throws Exception\n+        {\n+            setup(BIGINT, createValues());\n+        }\n+\n+        private Iterator<?> createValues()\n+        {\n+            List<Long> values = new ArrayList<>();\n+            for (int i = 0; i < ROWS; ++i) {\n+                values.add((long) i);\n+            }\n+            return values.iterator();\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BigintNoNullBenchmarkData\n+            extends BenchmarkData\n+    {\n+        @Setup\n+        public void setup()\n+                throws Exception\n+        {\n+            setup(BIGINT, createValues());\n+        }\n+\n+        private Iterator<?> createValues()\n+        {\n+            List<Long> values = new ArrayList<>();\n+            for (int i = 0; i < ROWS; ++i) {\n+                values.add(random.nextLong());\n+            }\n+            return values.iterator();\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BigintWithNullBenchmarkData\n+            extends BenchmarkData\n+    {\n+        @Setup\n+        public void setup()\n+                throws Exception\n+        {\n+            setup(BIGINT, createValues());\n+        }\n+\n+        private Iterator<?> createValues()\n+        {\n+            List<Long> values = new ArrayList<>();\n+            for (int i = 0; i < ROWS; ++i) {\n+                if (random.nextBoolean()) {\n+                    values.add(random.nextLong());\n+                }\n+                else {\n+                    values.add(null);\n+                }\n+            }\n+            return values.iterator();\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BigintWithNullBenchmarkDataNonOptimized\n+            extends BenchmarkData\n+    {\n+        @Setup\n+        public void setup()\n+                throws Exception\n+        {\n+            setup(BIGINT, createValues());\n+        }\n+\n+        private Iterator<?> createValues()\n+        {\n+            List<Long> values = new ArrayList<>();\n+            for (int i = 0; i < ROWS; ++i) {\n+                if (random.nextBoolean()) {\n+                    values.add(random.nextLong());\n+                }\n+                else {\n+                    values.add(null);\n+                }\n+            }\n+            return values.iterator();\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public static class BigintWithNullBenchmarkDataFixedWidthBlock", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxODM3NQ==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r522218375", "bodyText": "That is leftover from previous experiments", "author": "sopel39", "createdAt": "2020-11-12T16:00:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIxNTYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMTIzNA==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521421234", "bodyText": "You might need to handle the case when (positionCount * Long.BYTES) > Integer.MAX_VALUE", "author": "pettyjamesm", "createdAt": "2020-11-11T15:05:09Z", "path": "presto-spi/src/main/java/io/prestosql/spi/block/LongArrayBlockEncoding.java", "diffHunk": "@@ -53,9 +54,14 @@ public Block readBlock(BlockEncodingSerde blockEncodingSerde, SliceInput sliceIn\n         boolean[] valueIsNull = decodeNullBits(sliceInput, positionCount).orElse(null);\n \n         long[] values = new long[positionCount];\n-        for (int position = 0; position < positionCount; position++) {\n-            if (valueIsNull == null || !valueIsNull[position]) {\n-                values[position] = sliceInput.readLong();\n+        if (valueIsNull == null) {\n+            sliceInput.readBytes(Slices.wrappedLongArray(values), 0, Long.BYTES * positionCount);", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMjUzNw==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r521422537", "bodyText": "As an aside, maybe we should consider implementingSliceInput#readLongs(long[], int, int) and similar methods for other primitive types?", "author": "pettyjamesm", "createdAt": "2020-11-11T15:07:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQyMTIzNA=="}], "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "925aea6144241b7189d2edc79716e65ad96b0496", "url": "https://github.com/trinodb/trino/commit/925aea6144241b7189d2edc79716e65ad96b0496", "message": "Benchmark lineitem data in BenchmarkColumnReaders", "committedDate": "2020-11-12T15:59:47Z", "type": "commit"}, {"oid": "2423b976cded17022739f861868e4977eac9bdb5", "url": "https://github.com/trinodb/trino/commit/2423b976cded17022739f861868e4977eac9bdb5", "message": "Benchmark different compression methods in BenchmarkColumnReaders", "committedDate": "2020-11-12T15:59:47Z", "type": "commit"}, {"oid": "c9525af68fe57d105388751e42ac1b980ddb34a7", "url": "https://github.com/trinodb/trino/commit/c9525af68fe57d105388751e42ac1b980ddb34a7", "message": "Remove unused map", "committedDate": "2020-11-12T15:59:47Z", "type": "commit"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0MTI5MQ==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r522441291", "bodyText": "This extra allocation is going to be a bit of a bummer if you only have a few nulls since it effectively doubles the allocations involved with decoding.", "author": "pettyjamesm", "createdAt": "2020-11-12T21:36:38Z", "path": "presto-spi/src/main/java/io/prestosql/spi/block/LongArrayBlockEncoding.java", "diffHunk": "@@ -53,9 +65,20 @@ public Block readBlock(BlockEncodingSerde blockEncodingSerde, SliceInput sliceIn\n         boolean[] valueIsNull = decodeNullBits(sliceInput, positionCount).orElse(null);\n \n         long[] values = new long[positionCount];\n-        for (int position = 0; position < positionCount; position++) {\n-            if (valueIsNull == null || !valueIsNull[position]) {\n-                values[position] = sliceInput.readLong();\n+        if (valueIsNull == null) {\n+            sliceInput.readBytes(Slices.wrappedLongArray(values));\n+        }\n+        else {\n+            int nonNullPositionCount = sliceInput.readInt();\n+            long[] valuesWithoutNull = new long[nonNullPositionCount + 1];", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ2ODU4OA==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r522468588", "bodyText": "this is where we could use buffer cache potentially. Still, even now there is > 2x improvement here (and more then that for serialization)", "author": "sopel39", "createdAt": "2020-11-12T22:22:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0MTI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjc0NTQ4MQ==", "url": "https://github.com/trinodb/trino/pull/5905#discussion_r522745481", "bodyText": "Changed to\n            long[] valuesWithoutNull = new long[positionCount];\n            int nonNullPositionCount = 0;\n            for (int i = 0; i < positionCount; i++) {\n                valuesWithoutNull[nonNullPositionCount] = block.getLong(i, 0);\n                if (!block.isNull(i)) {\n                    nonNullPositionCount++;\n                }\n            }\n\nsince it yields slightly better results without extra allocation", "author": "sopel39", "createdAt": "2020-11-13T07:47:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjQ0MTI5MQ=="}], "type": "inlineReview"}, {"oid": "25a8e964b0d3ef8a2febcd60dd060ed4077f1143", "url": "https://github.com/trinodb/trino/commit/25a8e964b0d3ef8a2febcd60dd060ed4077f1143", "message": "Add BenchmarkBlockSerde\n\nAdd BenchmarkBlockSerde which is similar to BenchmarkColumnReaders\nso it's possible to compare both methods of data deserialization.", "committedDate": "2020-11-12T22:07:37Z", "type": "commit"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "2c206e18f82a90ec568a7ddc3313afec648ee266", "url": "https://github.com/trinodb/trino/commit/2c206e18f82a90ec568a7ddc3313afec648ee266", "message": "Add TestLongArrayBlockEncoding", "committedDate": "2020-11-13T07:47:13Z", "type": "commit"}, {"oid": "c138859054285d8557785a059a988dc5e4600a2b", "url": "https://github.com/trinodb/trino/commit/c138859054285d8557785a059a988dc5e4600a2b", "message": "Improve serde performance for Long blocks with no nulls\n\nAFTER\nBenchmark                                  Mode  Cnt  Score   Error  Units\nBenchmarkBlockSerde.deserializeLineitem    avgt   60  1,202 \u00b1 0,020  ns/op\nBenchmarkBlockSerde.deserializeLongNoNull  avgt   60  1,115 \u00b1 0,008  ns/op\nBenchmarkBlockSerde.serializeLineitem      avgt   60  3,663 \u00b1 0,026  ns/op\nBenchmarkBlockSerde.serializeLongNoNull    avgt   60  1,515 \u00b1 0,015  ns/op\n\nBEFORE\nBenchmark                                  Mode  Cnt  Score   Error  Units\nBenchmarkBlockSerde.deserializeLineitem    avgt   60  1,869 \u00b1 0,015  ns/op\nBenchmarkBlockSerde.deserializeLongNoNull  avgt   60  2,533 \u00b1 0,015  ns/op\nBenchmarkBlockSerde.serializeLineitem      avgt   60  4,709 \u00b1 0,086  ns/op\nBenchmarkBlockSerde.serializeLongNoNull    avgt   60  5,250 \u00b1 0,074  ns/op", "committedDate": "2020-11-13T07:47:13Z", "type": "commit"}, {"oid": "3f0ce5d1205493abad7d698fd4599e64ec19ad4b", "url": "https://github.com/trinodb/trino/commit/3f0ce5d1205493abad7d698fd4599e64ec19ad4b", "message": "Improve serde performance for Long blocks with nulls\n\nAFTER\n\nBenchmark                                    Mode  Cnt  Score   Error  Units\nBenchmarkBlockSerde.deserializeLineitem      avgt   60  1,212 \u00b1 0,015  ns/op\nBenchmarkBlockSerde.deserializeLongWithNull  avgt   60  2,500 \u00b1 0,038  ns/op\nBenchmarkBlockSerde.serializeLineitem        avgt   60  3,645 \u00b1 0,039  ns/op\nBenchmarkBlockSerde.serializeLongWithNull    avgt   60  3,351 \u00b1 0,016  ns/op\n\nBEFORE\n\nBenchmark                                    Mode  Cnt  Score   Error  Units\nBenchmarkBlockSerde.deserializeLineitem      avgt   60  1,219 \u00b1 0,016  ns/op\nBenchmarkBlockSerde.deserializeLongWithNull  avgt   60  5,524 \u00b1 0,062  ns/op\nBenchmarkBlockSerde.serializeLineitem        avgt   60  3,671 \u00b1 0,041  ns/op\nBenchmarkBlockSerde.serializeLongWithNull    avgt   60  8,844 \u00b1 0,086  ns/op", "committedDate": "2020-11-13T07:47:13Z", "type": "commit"}, {"oid": "0dd5c94b5db8889c62487436d9fd1ec8bcde3aa5", "url": "https://github.com/trinodb/trino/commit/0dd5c94b5db8889c62487436d9fd1ec8bcde3aa5", "message": "Extract BlockTestUtils#assertBlockEquals", "committedDate": "2020-11-13T07:47:13Z", "type": "commit"}, {"oid": "92ded01377e69470694b568a333f69809d6d8c1c", "url": "https://github.com/trinodb/trino/commit/92ded01377e69470694b568a333f69809d6d8c1c", "message": "Static import Scope.Thread", "committedDate": "2020-11-13T07:47:13Z", "type": "commit"}, {"oid": "92ded01377e69470694b568a333f69809d6d8c1c", "url": "https://github.com/trinodb/trino/commit/92ded01377e69470694b568a333f69809d6d8c1c", "message": "Static import Scope.Thread", "committedDate": "2020-11-13T07:47:13Z", "type": "forcePushed"}]}