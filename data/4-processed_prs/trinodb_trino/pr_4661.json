{"pr_number": 4661, "pr_title": "Integrate Coral with Presto to enable querying hive views", "pr_createdAt": "2020-08-01T00:53:53Z", "pr_url": "https://github.com/trinodb/trino/pull/4661", "timeline": [{"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDA1OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464754059", "bodyText": "It looks like there was a rebase conflict which duplicated these dependencies. We recently re-ordered all the dependencies in the POMs.", "author": "electrum", "createdAt": "2020-08-04T01:57:16Z", "path": "pom.xml", "diffHunk": "@@ -573,6 +583,87 @@\n                 <version>1.0</version>\n             </dependency>\n \n+            <!-- Airlift -->", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI5OTM4OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483299389", "bodyText": "Rebased.", "author": "laurachenyu", "createdAt": "2020-09-03T23:08:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDA1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDk5MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464754990", "bodyText": "I assume this is temporary and these artifacts will soon be published to Maven Central? We don't want to depend on a third party repository.", "author": "electrum", "createdAt": "2020-08-04T02:01:01Z", "path": "pom.xml", "diffHunk": "@@ -33,6 +33,13 @@\n         <tag>HEAD</tag>\n     </scm>\n \n+    <repositories>\n+        <repository>\n+            <id>dl.bintray</id>\n+            <url>http://dl.bintray.com/funcheetah8/maven/</url>", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIyNDM5OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r465224399", "bodyText": "Yes, I will remove this repository after it is published to Maven Central.", "author": "laurachenyu", "createdAt": "2020-08-04T17:48:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDk5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTkzNTg1Mg==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r465935852", "bodyText": "@electrum Is it OK to have calcite-core artifact published in https://linkedin.bintray.com/maven/ ?", "author": "laurachenyu", "createdAt": "2020-08-05T18:55:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDk5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ0MDc1OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r473440759", "bodyText": "Calcite-core 1.21.0.138 published. Will remove it now.", "author": "laurachenyu", "createdAt": "2020-08-19T23:41:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDk5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI5OTc1OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483299758", "bodyText": "Removed. Both Calcite-core and Coral are now in Maven Central.", "author": "laurachenyu", "createdAt": "2020-09-03T23:10:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NDk5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NTE3NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464755174", "bodyText": "Let's remove this comment. We don't have it for other dependencies.", "author": "electrum", "createdAt": "2020-08-04T02:01:36Z", "path": "pom.xml", "diffHunk": "@@ -54,6 +61,9 @@\n         <dep.oracle.version>19.3.0.0</dep.oracle.version>\n         <dep.drift.version>1.14</dep.drift.version>\n         <dep.tempto.version>180</dep.tempto.version>\n+        <!-- coral version for reading hive views -->", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NTI4MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464755280", "bodyText": "No need for a property here since it's only used for one dependency. We only add properties for versions that need to be the same across multiple dependencies.", "author": "electrum", "createdAt": "2020-08-04T02:02:02Z", "path": "pom.xml", "diffHunk": "@@ -54,6 +61,9 @@\n         <dep.oracle.version>19.3.0.0</dep.oracle.version>\n         <dep.drift.version>1.14</dep.drift.version>\n         <dep.tempto.version>180</dep.tempto.version>\n+        <!-- coral version for reading hive views -->\n+        <dep.coral.version>1.0.5</dep.coral.version>\n+        <dep.calcite.version>1.21.1.1</dep.calcite.version>", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMwMDExMA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483300110", "bodyText": "Removed.", "author": "laurachenyu", "createdAt": "2020-09-03T23:11:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NTI4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NTUzMw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464755533", "bodyText": "Remove version since it's specified in the room POM", "author": "electrum", "createdAt": "2020-08-04T02:02:57Z", "path": "presto-hive/pom.xml", "diffHunk": "@@ -351,7 +351,36 @@\n             <artifactId>testng</artifactId>\n             <scope>test</scope>\n         </dependency>\n-    </dependencies>\n+        \n+        <!-- for coral -->\n+        <dependency>\n+            <groupId>com.linkedin.coral</groupId>\n+            <artifactId>coral-presto</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.linkedin.calcite</groupId>\n+            <artifactId>calcite-core</artifactId>\n+            <version>1.21.1.1</version>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NTYxOA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464755618", "bodyText": "Remove exclusions since they are in the root POM", "author": "electrum", "createdAt": "2020-08-04T02:03:15Z", "path": "presto-hive/pom.xml", "diffHunk": "@@ -351,7 +351,36 @@\n             <artifactId>testng</artifactId>\n             <scope>test</scope>\n         </dependency>\n-    </dependencies>\n+        \n+        <!-- for coral -->\n+        <dependency>\n+            <groupId>com.linkedin.coral</groupId>\n+            <artifactId>coral-presto</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.linkedin.calcite</groupId>\n+            <artifactId>calcite-core</artifactId>\n+            <version>1.21.1.1</version>\n+            <classifier>shaded</classifier>\n+            <scope>compile</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.linkedin.coral</groupId>\n+            <artifactId>coral-hive</artifactId>\n+            <exclusions>", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2MjY4Mg==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r465362682", "bodyText": "I moved the exclusions to root POM.", "author": "laurachenyu", "createdAt": "2020-08-04T22:20:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1NTYxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1Njg5NQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464756895", "bodyText": "Since this abstract class only defines one method and doesn't have any state or other helpers, it might be cleaner to structure it as a utility class with a nested interface:\npublic final class ViewReaderUtil\n{\n    public interface ViewReader\n    {\n        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n    }\n\n    public static ViewReader createViewReader(...) ...\n}", "author": "electrum", "createdAt": "2020-08-04T02:08:09Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReader.java", "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+/**\n+ * Decode view definitions stored in Hive metastore. This class instantiates\n+ * correct decoder based on the type of view (hive or presto view).\n+ */\n+public abstract class ViewReader", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMwMDMzNA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483300334", "bodyText": "Modified accordingly, please review again.", "author": "laurachenyu", "createdAt": "2020-09-03T23:12:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1Njg5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1ODQ1NQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r464758455", "bodyText": "We should move this to io.prestosql.tests.hive.TestHiveViews which already tests Hive view translation. Many of those tests will need to be updated anyway, as the translation will work with Coral.", "author": "electrum", "createdAt": "2020-08-04T02:14:07Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestCoralIntegration.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.io.Files;\n+import io.prestosql.Session;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.Database;\n+import io.prestosql.plugin.hive.metastore.MetastoreUtil;\n+import io.prestosql.plugin.hive.metastore.Storage;\n+import io.prestosql.plugin.hive.metastore.StorageFormat;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.file.FileHiveMetastore;\n+import io.prestosql.plugin.hive.testing.TestingHivePlugin;\n+import io.prestosql.plugin.tpch.TpchPlugin;\n+import io.prestosql.spi.security.PrincipalType;\n+import io.prestosql.testing.AbstractTestQueryFramework;\n+import io.prestosql.testing.DistributedQueryRunner;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.TestingSession;\n+import io.prestosql.tpch.TpchTable;\n+import org.apache.hadoop.hive.metastore.TableType;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import static com.google.common.io.MoreFiles.deleteRecursively;\n+import static com.google.common.io.RecursiveDeleteOption.ALLOW_INSECURE;\n+import static io.prestosql.plugin.hive.HiveQueryRunner.TPCH_SCHEMA;\n+import static io.prestosql.plugin.tpch.TpchMetadata.TINY_SCHEMA_NAME;\n+import static io.prestosql.testing.QueryAssertions.copyTpchTables;\n+\n+public class TestCoralIntegration\n+        extends AbstractTestQueryFramework\n+{\n+    private static final String HIVE_CATALOG = \"hive\";\n+    private File catalogDirectory = Files.createTempDir();\n+\n+    @AfterClass(alwaysRun = true)\n+    public void close()\n+    {\n+        try {\n+            deleteRecursively(catalogDirectory.toPath(), ALLOW_INSECURE);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        Session session = TestingSession.testSessionBuilder().setCatalog(HIVE_CATALOG).build();\n+        DistributedQueryRunner queryRunner = DistributedQueryRunner.builder(session).build();\n+\n+        // Create tpch catalog\n+        queryRunner.installPlugin(new TpchPlugin());\n+        queryRunner.createCatalog(\"tpch\", \"tpch\", ImmutableMap.of());\n+\n+        // Create hive catalog\n+        FileHiveMetastore metastore = FileHiveMetastore.createTestingFileHiveMetastore(catalogDirectory);\n+        queryRunner.installPlugin(new TestingHivePlugin(metastore));\n+        queryRunner.createCatalog(HIVE_CATALOG, \"hive\", ImmutableMap.of());\n+\n+        // Populate TPC-H tables to Hive\n+        metastore.createDatabase(new HiveIdentity(session.toConnectorSession()), new Database(TPCH_SCHEMA, Optional.empty(), \"ignored\", PrincipalType.USER, Optional.empty(), ImmutableMap.of()));\n+        Session tpchSession = Session.builder(queryRunner.getDefaultSession()).setSchema(\"tpch\").build();\n+        copyTpchTables(queryRunner, \"tpch\", TINY_SCHEMA_NAME, tpchSession, ImmutableList.of(TpchTable.ORDERS));\n+\n+        // And create the Hive-defined views we'll use for testing\n+        createHiveView(\n+                metastore,\n+                new HiveIdentity(session.toConnectorSession()),\n+                \"tpch\",\n+                \"counting_view\",\n+                \"select count(1) as count from tpch.orders\",\n+                \"select count(1) as `count` from `tpch`.`orders`\");\n+        createHiveView(\n+                metastore,\n+                new HiveIdentity(session.toConnectorSession()),\n+                \"tpch\",\n+                \"zero_index_view\",\n+                // Arrays in Hive are zero-indexed. This query will return 'hive' only if it's being parsed as a Hive query\n+                \"select array('presto','hive')[1] as sql_dialect\",\n+                \"select array('presto','hive')[1] as `sql_dialect`\");\n+\n+        return queryRunner;\n+    }\n+\n+    private static void createHiveView(FileHiveMetastore metastore, HiveIdentity identity, String databaseName, String tableName, String originalViewText, String expandedViewText)\n+    {\n+        Storage storage = Storage.builder()\n+                .setLocation(\"\")\n+                .setStorageFormat(StorageFormat.VIEW_STORAGE_FORMAT)\n+                .setBucketProperty(Optional.empty())\n+                .setSerdeParameters(ImmutableMap.of())\n+                .build();\n+        metastore.createTable(identity, new Table(\n+                        databaseName,\n+                        tableName,\n+                        \"admin\",\n+                        TableType.VIRTUAL_VIEW.toString(),\n+                        storage,\n+                        ImmutableList.of(),\n+                        ImmutableList.of(),\n+                        ImmutableMap.of(),\n+                        Optional.of(originalViewText),\n+                        Optional.of(expandedViewText)),\n+                MetastoreUtil.buildInitialPrivilegeSet(\"admin\"));\n+    }\n+\n+    // The intent here is not to exhaustively test Coral itself, only that we have properly integrated with it. Queries of all different shapes are tested within Coral.\n+    @Test\n+    public void testSimpleCoralIntegration()", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMwMDk3NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483300974", "bodyText": "I have trouble running product test with following command \"presto-product-tests-launcher/bin/run-launcher test run --environment singlenode -t io.prestosql.tests.hive.TestHiveViews.testSelectOnView\", it complains about UNKNOWN HOST presto-master or cannot connect to presto-master.", "author": "laurachenyu", "createdAt": "2020-09-03T23:14:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDc1ODQ1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r466306158", "bodyText": "Does this work for field names with special characters that need quoting? Or does the field already return the quoted name?", "author": "hashhar", "createdAt": "2020-08-06T10:05:06Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReader.java", "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+/**\n+ * Decode view definitions stored in Hive metastore. This class instantiates\n+ * correct decoder based on the type of view (hive or presto view).\n+ */\n+public abstract class ViewReader\n+{\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+\n+    private static Logger log = Logger.get(ViewReader.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Decodes view definition stored in hive metastore. Currently, it supports decoding\n+     * hive or presto view definitions.\n+     *\n+     * @param metastore hive metastore to read view definitions from. This is required\n+     * to decode Hive view definitions.\n+     * @param table virtual table (view) instance\n+     * @return json representation of view definition\n+     */\n+    public static ConnectorViewDefinition decodeView(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, CatalogName catalogName, TypeManager typemanager)\n+    {\n+        ViewReader viewReader = create(metastore, identity, table, typemanager);\n+        return viewReader.decodeViewData(table.getViewOriginalText().get(), table, catalogName);\n+    }\n+\n+    public static ViewReader create(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new PrestoViewDecoder();\n+        }\n+        else {\n+            return new HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    /**\n+     * Decode view definition\n+     *\n+     * @param viewData view definition stored as \"View Original Text\" in Hive metastore\n+     * @param table table representing virtual view to decode\n+     * @return json representation of view definition\n+     */\n+    public abstract ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            extends ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            extends ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());\n+                    StringBuilder sb = new StringBuilder(\"row(\");\n+                    List<RelDataTypeField> fieldList = type.getFieldList();\n+                    for (int i = 0; i < fieldList.size(); i++) {\n+                        if (i != 0) {\n+                            // There should not be space after comma. Presto deserializer doesn't like it\n+                            sb.append(\",\");\n+                        }\n+                        RelDataTypeField field = fieldList.get(i);\n+                        sb.append(field.getName().toLowerCase(Locale.ENGLISH)).append(\" \").append(getTypeString(field.getType()));", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMxNjU4OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483316589", "bodyText": "Yes. It works with field names with special characters.\nI tested with following example with field name \"_a\" and field name \"count\":\n\nselect * from hive.u_ychen6.viewtest_view3;\n_a | b\n------+-----\n1 |   1\n2 |   2\nselect * from hive.u_ychen6.viewtest_view2;\ncol1 | count\n------+-------\n1 |     1\n2 |     2", "author": "laurachenyu", "createdAt": "2020-09-04T00:09:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU3MjY0MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483572640", "bodyText": "_ doesn't need quoting AFAIK. Maybe some column with . in it's name?", "author": "hashhar", "createdAt": "2020-09-04T12:03:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc2MTk5Nw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483761997", "bodyText": "Sorry, I was wrong. RelDataTypeField does not return quoted names.", "author": "laurachenyu", "createdAt": "2020-09-04T17:32:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzc4MDE4MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r483780180", "bodyText": "@martint Any way to get properly quoted identifiers (or to quote them) for such cases?\nThe end-goal seems to be to generate DDL like ROW(plain_column, \"dotted.column.name\").", "author": "hashhar", "createdAt": "2020-09-04T18:14:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwMDIzNg==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r485100236", "bodyText": "@hashhar, you'd need to have rules that understand what characters are not valid in the context of an identifier and quote them. Alternatively, you can quote all generated identifiers and avoid having to think about it.", "author": "martint", "createdAt": "2020-09-08T17:59:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIzODU4OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r485238588", "bodyText": "Quoted identifiers have different semantics when you consider case sensitivity.", "author": "electrum", "createdAt": "2020-09-08T22:52:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIzOTE2OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r485239168", "bodyText": "Indeed, but presumably, something that knows how to translate queries automatically would generate identifiers that are already normalized according to the semantics of the target.", "author": "martint", "createdAt": "2020-09-08T22:54:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMwNjE1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMxMTM1Mw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r466311353", "bodyText": "Nice.", "author": "hashhar", "createdAt": "2020-08-06T10:15:16Z", "path": "presto-hive/src/test/java/io/prestosql/plugin/hive/TestCoralIntegration.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.io.Files;\n+import io.prestosql.Session;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.Database;\n+import io.prestosql.plugin.hive.metastore.MetastoreUtil;\n+import io.prestosql.plugin.hive.metastore.Storage;\n+import io.prestosql.plugin.hive.metastore.StorageFormat;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.plugin.hive.metastore.file.FileHiveMetastore;\n+import io.prestosql.plugin.hive.testing.TestingHivePlugin;\n+import io.prestosql.plugin.tpch.TpchPlugin;\n+import io.prestosql.spi.security.PrincipalType;\n+import io.prestosql.testing.AbstractTestQueryFramework;\n+import io.prestosql.testing.DistributedQueryRunner;\n+import io.prestosql.testing.QueryRunner;\n+import io.prestosql.testing.TestingSession;\n+import io.prestosql.tpch.TpchTable;\n+import org.apache.hadoop.hive.metastore.TableType;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.Test;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Optional;\n+\n+import static com.google.common.io.MoreFiles.deleteRecursively;\n+import static com.google.common.io.RecursiveDeleteOption.ALLOW_INSECURE;\n+import static io.prestosql.plugin.hive.HiveQueryRunner.TPCH_SCHEMA;\n+import static io.prestosql.plugin.tpch.TpchMetadata.TINY_SCHEMA_NAME;\n+import static io.prestosql.testing.QueryAssertions.copyTpchTables;\n+\n+public class TestCoralIntegration\n+        extends AbstractTestQueryFramework\n+{\n+    private static final String HIVE_CATALOG = \"hive\";\n+    private File catalogDirectory = Files.createTempDir();\n+\n+    @AfterClass(alwaysRun = true)\n+    public void close()\n+    {\n+        try {\n+            deleteRecursively(catalogDirectory.toPath(), ALLOW_INSECURE);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        Session session = TestingSession.testSessionBuilder().setCatalog(HIVE_CATALOG).build();\n+        DistributedQueryRunner queryRunner = DistributedQueryRunner.builder(session).build();\n+\n+        // Create tpch catalog\n+        queryRunner.installPlugin(new TpchPlugin());\n+        queryRunner.createCatalog(\"tpch\", \"tpch\", ImmutableMap.of());\n+\n+        // Create hive catalog\n+        FileHiveMetastore metastore = FileHiveMetastore.createTestingFileHiveMetastore(catalogDirectory);\n+        queryRunner.installPlugin(new TestingHivePlugin(metastore));\n+        queryRunner.createCatalog(HIVE_CATALOG, \"hive\", ImmutableMap.of());\n+\n+        // Populate TPC-H tables to Hive\n+        metastore.createDatabase(new HiveIdentity(session.toConnectorSession()), new Database(TPCH_SCHEMA, Optional.empty(), \"ignored\", PrincipalType.USER, Optional.empty(), ImmutableMap.of()));\n+        Session tpchSession = Session.builder(queryRunner.getDefaultSession()).setSchema(\"tpch\").build();\n+        copyTpchTables(queryRunner, \"tpch\", TINY_SCHEMA_NAME, tpchSession, ImmutableList.of(TpchTable.ORDERS));\n+\n+        // And create the Hive-defined views we'll use for testing\n+        createHiveView(\n+                metastore,\n+                new HiveIdentity(session.toConnectorSession()),\n+                \"tpch\",\n+                \"counting_view\",\n+                \"select count(1) as count from tpch.orders\",\n+                \"select count(1) as `count` from `tpch`.`orders`\");\n+        createHiveView(\n+                metastore,\n+                new HiveIdentity(session.toConnectorSession()),\n+                \"tpch\",\n+                \"zero_index_view\",\n+                // Arrays in Hive are zero-indexed. This query will return 'hive' only if it's being parsed as a Hive query", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzE1OTAxNA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r493159014", "bodyText": "I don't think we this these comment since all the dependencies have \"coral\" in the name", "author": "electrum", "createdAt": "2020-09-23T02:24:28Z", "path": "pom.xml", "diffHunk": "@@ -981,6 +981,43 @@\n                 <version>1.4.200</version>\n             </dependency>\n \n+            <!-- for coral -->", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMyODMzMA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495328330", "bodyText": "Same", "author": "electrum", "createdAt": "2020-09-25T23:56:25Z", "path": "presto-hive/pom.xml", "diffHunk": "@@ -173,6 +173,24 @@\n             <artifactId>guice</artifactId>\n         </dependency>\n \n+        <!-- for coral -->", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMyODQzOQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495328439", "bodyText": "Remove since compile is the default scope", "author": "electrum", "createdAt": "2020-09-25T23:56:44Z", "path": "pom.xml", "diffHunk": "@@ -981,6 +981,43 @@\n                 <version>1.4.200</version>\n             </dependency>\n \n+            <!-- for coral -->\n+            <dependency>\n+                <groupId>com.linkedin.calcite</groupId>\n+                <artifactId>calcite-core</artifactId>\n+                <version>1.21.0.140</version>\n+                <classifier>shaded</classifier>\n+                <scope>compile</scope>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMyODcwNw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495328707", "bodyText": "Remove since compile is the default scope", "author": "electrum", "createdAt": "2020-09-25T23:57:25Z", "path": "presto-hive/pom.xml", "diffHunk": "@@ -173,6 +173,24 @@\n             <artifactId>guice</artifactId>\n         </dependency>\n \n+        <!-- for coral -->\n+        <dependency>\n+            <groupId>com.linkedin.calcite</groupId>\n+            <artifactId>calcite-core</artifactId>\n+            <classifier>shaded</classifier>\n+            <scope>compile</scope>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMyOTIwOQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495329209", "bodyText": "Add a property dep.coral.version so that the versions stay in sync between coral-hive and coral-presto", "author": "electrum", "createdAt": "2020-09-25T23:58:49Z", "path": "pom.xml", "diffHunk": "@@ -981,6 +981,43 @@\n                 <version>1.4.200</version>\n             </dependency>\n \n+            <!-- for coral -->\n+            <dependency>\n+                <groupId>com.linkedin.calcite</groupId>\n+                <artifactId>calcite-core</artifactId>\n+                <version>1.21.0.140</version>\n+                <classifier>shaded</classifier>\n+                <scope>compile</scope>\n+                <exclusions>\n+                    <exclusion>\n+                        <groupId>*</groupId>\n+                        <artifactId>*</artifactId>\n+                    </exclusion>\n+                </exclusions>\n+            </dependency>\n+\n+            <dependency>\n+                <groupId>com.linkedin.coral</groupId>\n+                <artifactId>coral-hive</artifactId>\n+                <version>1.0.8</version>", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMyOTQzNQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495329435", "bodyText": "Nit: wrap .decodeViewData() onto the next line since the line is very long", "author": "electrum", "createdAt": "2020-09-25T23:59:29Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/HiveMetadata.java", "diffHunk": "@@ -1843,35 +1843,24 @@ public void dropView(ConnectorSession session, SchemaTableName viewName)\n             return Optional.empty();\n         }\n         return metastore.getTable(new HiveIdentity(session), viewName.getSchemaName(), viewName.getTableName())\n-                .flatMap(view -> {\n-                    if (isPrestoView(view)) {\n-                        ConnectorViewDefinition definition = decodeViewData(view.getViewOriginalText()\n-                                .orElseThrow(() -> new PrestoException(HIVE_INVALID_METADATA, \"No view original text: \" + viewName)));\n-                        // use owner from table metadata if it exists\n-                        if (view.getOwner() != null && !definition.isRunAsInvoker()) {\n-                            definition = new ConnectorViewDefinition(\n-                                    definition.getOriginalSql(),\n-                                    definition.getCatalog(),\n-                                    definition.getSchema(),\n-                                    definition.getColumns(),\n-                                    definition.getComment(),\n-                                    Optional.of(view.getOwner()),\n-                                    false);\n-                        }\n-                        return Optional.of(definition);\n+                .filter(ViewReaderUtil::canDecodeView)\n+                .map(view -> {\n+                    ConnectorViewDefinition definition = createViewReader(metastore, new HiveIdentity(session), view, typeManager).decodeViewData(view.getViewOriginalText().get(), view, catalogName);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMDExMg==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495330112", "bodyText": "We avoid abbreviations. How about metastoreClient", "author": "electrum", "createdAt": "2020-09-26T00:01:07Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMDEzNQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495330135", "bodyText": "Check for null", "author": "electrum", "createdAt": "2020-09-26T00:01:12Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMDY5MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495330690", "bodyText": "You can simply reference PrestoViewDecoder and HiveViewDecoder since they are visible within this class", "author": "electrum", "createdAt": "2020-09-26T00:02:35Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMDg3Mw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495330873", "bodyText": "Nit: the \"else\" is redundant since the \"if\" returns. Write this as\nif (xxx) { \n    return ...;\n}\nreturn ...;", "author": "electrum", "createdAt": "2020-09-26T00:03:05Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMTUxNA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495331514", "bodyText": "We avoid acronyms or abbreviations. How about CoralHiveMetastoreClient", "author": "electrum", "createdAt": "2020-09-26T00:04:46Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/CoralSemiTransactionalHiveMSCAdapter.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore;\n+\n+import com.google.common.collect.ImmutableMultimap;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+/**\n+ * Class to adapt Presto's {@link SemiTransactionalHiveMetastore} to Coral's\n+ * {@link HiveMetastoreClient}. This allows reuse of the hive metastore instantiated by\n+ * Presto, based on configuration, inside Coral.\n+ */\n+public class CoralSemiTransactionalHiveMSCAdapter", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMTY4OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495331688", "bodyText": "Check for null", "author": "electrum", "createdAt": "2020-09-26T00:05:05Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/CoralSemiTransactionalHiveMSCAdapter.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore;\n+\n+import com.google.common.collect.ImmutableMultimap;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+/**\n+ * Class to adapt Presto's {@link SemiTransactionalHiveMetastore} to Coral's\n+ * {@link HiveMetastoreClient}. This allows reuse of the hive metastore instantiated by\n+ * Presto, based on configuration, inside Coral.\n+ */\n+public class CoralSemiTransactionalHiveMSCAdapter\n+        implements HiveMetastoreClient\n+{\n+    private final SemiTransactionalHiveMetastore delegate;\n+    private final HiveIdentity identity;\n+\n+    public CoralSemiTransactionalHiveMSCAdapter(SemiTransactionalHiveMetastore msc, HiveIdentity identity)\n+    {\n+        this.delegate = msc;", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMjM0Nw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495332347", "bodyText": "We can write this as\nreturn delegate.getTable(identity, dbName, tableName)\n        .map(value -> ThriftMetastoreUtil.toMetastoreApiTable(value, new PrincipalPrivileges(ImmutableMultimap.of(), ImmutableMultimap.of())))\n        .orElse(null);", "author": "electrum", "createdAt": "2020-09-26T00:06:45Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/CoralSemiTransactionalHiveMSCAdapter.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore;\n+\n+import com.google.common.collect.ImmutableMultimap;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+/**\n+ * Class to adapt Presto's {@link SemiTransactionalHiveMetastore} to Coral's\n+ * {@link HiveMetastoreClient}. This allows reuse of the hive metastore instantiated by\n+ * Presto, based on configuration, inside Coral.\n+ */\n+public class CoralSemiTransactionalHiveMSCAdapter\n+        implements HiveMetastoreClient\n+{\n+    private final SemiTransactionalHiveMetastore delegate;\n+    private final HiveIdentity identity;\n+\n+    public CoralSemiTransactionalHiveMSCAdapter(SemiTransactionalHiveMetastore msc, HiveIdentity identity)\n+    {\n+        this.delegate = msc;\n+        this.identity = identity;\n+    }\n+\n+    @Override\n+    public List<String> getAllDatabases()\n+    {\n+        return delegate.getAllDatabases();\n+    }\n+\n+    // returning null for missing entry is as per Coral's requirements\n+    @Override\n+    public Database getDatabase(String dbName)\n+    {\n+        return delegate.getDatabase(dbName).map(ThriftMetastoreUtil::toMetastoreApiDatabase).orElse(null);\n+    }\n+\n+    @Override\n+    public List<String> getAllTables(String dbName)\n+    {\n+        return delegate.getAllTables(dbName);\n+    }\n+\n+    @Override\n+    public org.apache.hadoop.hive.metastore.api.Table getTable(String dbName, String tableName)\n+    {\n+        Optional<io.prestosql.plugin.hive.metastore.Table> table = delegate.getTable(identity, dbName, tableName);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMjY3Ng==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495332676", "bodyText": "Do we need a TODO here? If Coral needs the permissions, then we should implement it. If not, then it doesn't matter.", "author": "electrum", "createdAt": "2020-09-26T00:07:38Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/CoralSemiTransactionalHiveMSCAdapter.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive.metastore;\n+\n+import com.google.common.collect.ImmutableMultimap;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.thrift.ThriftMetastoreUtil;\n+import org.apache.hadoop.hive.metastore.api.Database;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+/**\n+ * Class to adapt Presto's {@link SemiTransactionalHiveMetastore} to Coral's\n+ * {@link HiveMetastoreClient}. This allows reuse of the hive metastore instantiated by\n+ * Presto, based on configuration, inside Coral.\n+ */\n+public class CoralSemiTransactionalHiveMSCAdapter\n+        implements HiveMetastoreClient\n+{\n+    private final SemiTransactionalHiveMetastore delegate;\n+    private final HiveIdentity identity;\n+\n+    public CoralSemiTransactionalHiveMSCAdapter(SemiTransactionalHiveMetastore msc, HiveIdentity identity)\n+    {\n+        this.delegate = msc;\n+        this.identity = identity;\n+    }\n+\n+    @Override\n+    public List<String> getAllDatabases()\n+    {\n+        return delegate.getAllDatabases();\n+    }\n+\n+    // returning null for missing entry is as per Coral's requirements\n+    @Override\n+    public Database getDatabase(String dbName)\n+    {\n+        return delegate.getDatabase(dbName).map(ThriftMetastoreUtil::toMetastoreApiDatabase).orElse(null);\n+    }\n+\n+    @Override\n+    public List<String> getAllTables(String dbName)\n+    {\n+        return delegate.getAllTables(dbName);\n+    }\n+\n+    @Override\n+    public org.apache.hadoop.hive.metastore.api.Table getTable(String dbName, String tableName)\n+    {\n+        Optional<io.prestosql.plugin.hive.metastore.Table> table = delegate.getTable(identity, dbName, tableName);\n+        // TODO: Get the right privileges here. This could be problematic if Coral needs permissions of the table.", "originalCommit": null, "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTYxMDE4NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495610184", "bodyText": "This is LI internal to check table access permission, will remove this.", "author": "laurachenyu", "createdAt": "2020-09-27T20:06:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMjY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMjk0OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495332949", "bodyText": "You can inline this variable", "author": "electrum", "createdAt": "2020-09-26T00:08:25Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/metastore/file/FileHiveMetastore.java", "diffHunk": "@@ -443,7 +442,15 @@ public synchronized void updatePartitionStatistics(HiveIdentity identity, Table\n     @Override\n     public synchronized List<String> getAllViews(String databaseName)\n     {\n-        return getTablesWithParameter(databaseName, PRESTO_VIEW_FLAG, \"true\");\n+        List<String> tables = getAllTables(databaseName);", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMzA3Mw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495333073", "bodyText": "Nit: No need to wrap here", "author": "electrum", "createdAt": "2020-09-26T00:08:43Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveViews.java", "diffHunk": "@@ -174,6 +173,20 @@ public void testHiveViewWithParametrizedTypes()\n         assertThat(query(\"SELECT data_type FROM information_schema.columns WHERE table_name = 'hive_view_parametrized'\")).containsOnly(\n                 row(\"decimal(20,4)\"),\n                 row(\"bigint\"),\n-                row(\"varchar(20)\"));\n+                row(\"varchar\"));\n+    }\n+\n+    @Test(groups = HIVE_VIEWS)\n+    public void testSimpleCoral()\n+    {\n+        onHive().executeQuery(\"DROP VIEW IF EXISTS hive_zero_index_view\");\n+        onHive().executeQuery(\"DROP TABLE IF EXISTS hive_table_dummy\");\n+\n+        onHive().executeQuery(\"CREATE TABLE hive_table_dummy(a int)\");\n+        onHive().executeQuery(\"CREATE VIEW hive_zero_index_view AS SELECT array('presto','hive')[1] AS sql_dialect from hive_table_dummy\");\n+        onHive().executeQuery(\"INSERT INTO TABLE hive_table_dummy VALUES (1)\");\n+\n+        assertThat(query(\"SELECT * FROM hive_zero_index_view\")).containsOnly(\n+                row(\"hive\"));", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzMzM5NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495333394", "bodyText": "Nit: uppercase FROM keyword", "author": "electrum", "createdAt": "2020-09-26T00:09:38Z", "path": "presto-product-tests/src/main/java/io/prestosql/tests/hive/TestHiveViews.java", "diffHunk": "@@ -174,6 +173,20 @@ public void testHiveViewWithParametrizedTypes()\n         assertThat(query(\"SELECT data_type FROM information_schema.columns WHERE table_name = 'hive_view_parametrized'\")).containsOnly(\n                 row(\"decimal(20,4)\"),\n                 row(\"bigint\"),\n-                row(\"varchar(20)\"));\n+                row(\"varchar\"));\n+    }\n+\n+    @Test(groups = HIVE_VIEWS)\n+    public void testSimpleCoral()\n+    {\n+        onHive().executeQuery(\"DROP VIEW IF EXISTS hive_zero_index_view\");\n+        onHive().executeQuery(\"DROP TABLE IF EXISTS hive_table_dummy\");\n+\n+        onHive().executeQuery(\"CREATE TABLE hive_table_dummy(a int)\");\n+        onHive().executeQuery(\"CREATE VIEW hive_zero_index_view AS SELECT array('presto','hive')[1] AS sql_dialect from hive_table_dummy\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzNDY1OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495334658", "bodyText": "Do we expect this class to get substantially bigger as the transactional support is expanded? If so, it would be better to make it a top level class.", "author": "electrum", "createdAt": "2020-09-26T00:13:12Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzNTA3NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495335074", "bodyText": "Let's call these PrestoViewReader and HiveViewReader so that the names match the interface (that's the typical convention).", "author": "electrum", "createdAt": "2020-09-26T00:14:22Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzNTc3Mg==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495335772", "bodyText": "Is this useful to leave in the code? If so, we should expand it to include the view name. Otherwise, if it's just for development, please remove it.", "author": "electrum", "createdAt": "2020-09-26T00:15:59Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzNTg3OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495335878", "bodyText": "Nit: wrap all the arguments if wrapping any", "author": "electrum", "createdAt": "2020-09-26T00:16:16Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzNzQxMw==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495337413", "bodyText": "I think you want to remove this second part :)\nIs it useful to duplicate the error message here? It's available in the stack trace. Let's also add quotes around the table name, and use the right error code.\nthrow new PrestoException(HIVE_VIEW_TRANSLATION_ERROR, format(\"Failed to translate Hive view '%s': %s', table.getSchemaTableName(), e.getMessage()), e);", "author": "electrum", "createdAt": "2020-09-26T00:20:15Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMzOTIzOQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495339239", "bodyText": "Use verify() as IllegalStateException means something different. This is a general problem of the RelDataType invariants being violated.\nverify(type.isStrict(), \"expected ROW type to be a struct: %s\", type);", "author": "electrum", "createdAt": "2020-09-26T00:24:27Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTM0MDA3MQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495340071", "bodyText": "This can be done with a stream\nreturn type.getFieldList().stream()\n        .map(field -> field.getName().toLowerCase(ENGLISH) + \" \" + getTypeString(field.getType()))\n        .collect(joining(\",\", \"row(\", \")\"));", "author": "electrum", "createdAt": "2020-09-26T00:26:32Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());\n+                    StringBuilder sb = new StringBuilder(\"row(\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTM0MTEzOA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495341138", "bodyText": "This can chain (no need for a variable). Though I think it's easier to read with string formatting\nreturn format(\"map(%s,%s)\", getTypeString(keyType), getTypeString(valueType));", "author": "electrum", "createdAt": "2020-09-26T00:29:15Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());\n+                    StringBuilder sb = new StringBuilder(\"row(\");\n+                    List<RelDataTypeField> fieldList = type.getFieldList();\n+                    for (int i = 0; i < fieldList.size(); i++) {\n+                        if (i != 0) {\n+                            // There should not be space after comma. Presto deserializer doesn't like it\n+                            sb.append(\",\");\n+                        }\n+                        RelDataTypeField field = fieldList.get(i);\n+                        sb.append(field.getName().toLowerCase(Locale.ENGLISH)).append(\" \").append(getTypeString(field.getType()));\n+                    }\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case CHAR:\n+                    return \"varchar\";\n+                case FLOAT:\n+                    return \"real\";\n+                case BINARY:\n+                case VARBINARY:\n+                    return \"varbinary\";\n+                case MAP: {\n+                    RelDataType keyType = type.getKeyType();\n+                    RelDataType valueType = type.getValueType();\n+                    StringBuilder sb = new StringBuilder(\"map(\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTM0MTI3NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495341274", "bodyText": "return format(\"array(%s)\", type.getComponentType());", "author": "electrum", "createdAt": "2020-09-26T00:29:30Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());\n+                    StringBuilder sb = new StringBuilder(\"row(\");\n+                    List<RelDataTypeField> fieldList = type.getFieldList();\n+                    for (int i = 0; i < fieldList.size(); i++) {\n+                        if (i != 0) {\n+                            // There should not be space after comma. Presto deserializer doesn't like it\n+                            sb.append(\",\");\n+                        }\n+                        RelDataTypeField field = fieldList.get(i);\n+                        sb.append(field.getName().toLowerCase(Locale.ENGLISH)).append(\" \").append(getTypeString(field.getType()));\n+                    }\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case CHAR:\n+                    return \"varchar\";\n+                case FLOAT:\n+                    return \"real\";\n+                case BINARY:\n+                case VARBINARY:\n+                    return \"varbinary\";\n+                case MAP: {\n+                    RelDataType keyType = type.getKeyType();\n+                    RelDataType valueType = type.getValueType();\n+                    StringBuilder sb = new StringBuilder(\"map(\");\n+                    sb.append(getTypeString(keyType))\n+                            .append(\",\")\n+                            .append(getTypeString(valueType));\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case ARRAY: {\n+                    StringBuilder sb = new StringBuilder(\"array(\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTM0MTQxNg==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495341416", "bodyText": "return format(\"decimal(%s,%s)\", type.getPrecision(), type.getScale());", "author": "electrum", "createdAt": "2020-09-26T00:29:50Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());\n+                    StringBuilder sb = new StringBuilder(\"row(\");\n+                    List<RelDataTypeField> fieldList = type.getFieldList();\n+                    for (int i = 0; i < fieldList.size(); i++) {\n+                        if (i != 0) {\n+                            // There should not be space after comma. Presto deserializer doesn't like it\n+                            sb.append(\",\");\n+                        }\n+                        RelDataTypeField field = fieldList.get(i);\n+                        sb.append(field.getName().toLowerCase(Locale.ENGLISH)).append(\" \").append(getTypeString(field.getType()));\n+                    }\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case CHAR:\n+                    return \"varchar\";\n+                case FLOAT:\n+                    return \"real\";\n+                case BINARY:\n+                case VARBINARY:\n+                    return \"varbinary\";\n+                case MAP: {\n+                    RelDataType keyType = type.getKeyType();\n+                    RelDataType valueType = type.getValueType();\n+                    StringBuilder sb = new StringBuilder(\"map(\");\n+                    sb.append(getTypeString(keyType))\n+                            .append(\",\")\n+                            .append(getTypeString(valueType));\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case ARRAY: {\n+                    StringBuilder sb = new StringBuilder(\"array(\");\n+                    sb.append(getTypeString(type.getComponentType()));\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case DECIMAL: {\n+                    StringBuilder sb = new StringBuilder(\"decimal(\");", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTM0MjIwMA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495342200", "bodyText": "We might consider explicitly listing all of the other supported types here, allowing us to throw an error if we get an unexpected type, rather than failing later when Presto parses the view.", "author": "electrum", "createdAt": "2020-09-26T00:31:34Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());\n+                for (RelDataTypeField field : rowType.getFieldList()) {\n+                    log.debug(\"Adding column %s, %s, %s, %s\", field.getName(),\n+                            field.getType().getFullTypeString(),\n+                            field.getType().getSqlTypeName(),\n+                            field);\n+\n+                    Type type = typeManager.fromSqlType(getTypeString(field.getType()));\n+                    ConnectorViewDefinition.ViewColumn column = new ConnectorViewDefinition.ViewColumn(field.getName(), type.getTypeId());\n+                    columns.add(column);\n+                }\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);\n+            }\n+            catch (RuntimeException e) {\n+                throw new PrestoException(HIVE_UNKNOWN_ERROR,\n+                        format(\"Error decoding view definition for %s.%s: %s. Please report this to ask_dali@linkedin.com\",\n+                                table.getDatabaseName(),\n+                                table.getTableName(),\n+                                e.getMessage()),\n+                        e);\n+            }\n+        }\n+\n+        // Calcite does not provide correct type strings for non-primitive types.\n+        // We add custom code here to make it work. Goal is for calcite/coral to handle this\n+        private String getTypeString(RelDataType type)\n+        {\n+            switch (type.getSqlTypeName()) {\n+                case ROW: {\n+                    Preconditions.checkState(type.isStruct());\n+                    StringBuilder sb = new StringBuilder(\"row(\");\n+                    List<RelDataTypeField> fieldList = type.getFieldList();\n+                    for (int i = 0; i < fieldList.size(); i++) {\n+                        if (i != 0) {\n+                            // There should not be space after comma. Presto deserializer doesn't like it\n+                            sb.append(\",\");\n+                        }\n+                        RelDataTypeField field = fieldList.get(i);\n+                        sb.append(field.getName().toLowerCase(Locale.ENGLISH)).append(\" \").append(getTypeString(field.getType()));\n+                    }\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case CHAR:\n+                    return \"varchar\";\n+                case FLOAT:\n+                    return \"real\";\n+                case BINARY:\n+                case VARBINARY:\n+                    return \"varbinary\";\n+                case MAP: {\n+                    RelDataType keyType = type.getKeyType();\n+                    RelDataType valueType = type.getValueType();\n+                    StringBuilder sb = new StringBuilder(\"map(\");\n+                    sb.append(getTypeString(keyType))\n+                            .append(\",\")\n+                            .append(getTypeString(valueType));\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case ARRAY: {\n+                    StringBuilder sb = new StringBuilder(\"array(\");\n+                    sb.append(getTypeString(type.getComponentType()));\n+                    sb.append(\")\");\n+                    return sb.toString();\n+                }\n+                case DECIMAL: {\n+                    StringBuilder sb = new StringBuilder(\"decimal(\");\n+                    sb.append(type.getPrecision())\n+                            .append(\",\")\n+                            .append(type.getScale())\n+                            .append(\")\");\n+                    return sb.toString();\n+                }\n+                default:", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTM0MzQ4OQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r495343489", "bodyText": "Import ViewColumn directly for readability.\nMaybe use a stream for this\nList<ViewColumn> columns = rowType.getFieldList().stream()\n        .map(field -> new ViewColumn(\n                field.getName(),\n                typeManager.fromSqlType(getTypeString(field.getType())).getTypeId()))\n        .collect(toImmutableList());", "author": "electrum", "createdAt": "2020-09-26T00:34:17Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,229 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.google.common.base.Preconditions;\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.type.Type;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.calcite.rel.type.RelDataTypeField;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.ArrayList;\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.PrestoViewDecoder();\n+        }\n+        else {\n+            return new io.prestosql.plugin.hive.ViewReaderUtil.HiveViewDecoder(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+        }\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewDecoder\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewDecoder\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient mscClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewDecoder(HiveMetastoreClient mscClient, TypeManager typemanager)\n+        {\n+            this.mscClient = mscClient;\n+            this.typeManager = requireNonNull(typemanager, \"metadata is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(mscClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ConnectorViewDefinition.ViewColumn> columns = new ArrayList<>(rowType.getFieldCount());", "originalCommit": null, "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": null, "url": null, "message": null, "committedDate": null, "type": "forcePushed"}, {"oid": "f93122c17424bed9e39b6a4a29b6fede102dc8d2", "url": "https://github.com/trinodb/trino/commit/f93122c17424bed9e39b6a4a29b6fede102dc8d2", "message": "Integrate Coral with Presto to enable querying hive views", "committedDate": "2020-10-09T19:24:24Z", "type": "commit"}, {"oid": "f93122c17424bed9e39b6a4a29b6fede102dc8d2", "url": "https://github.com/trinodb/trino/commit/f93122c17424bed9e39b6a4a29b6fede102dc8d2", "message": "Integrate Coral with Presto to enable querying hive views", "committedDate": "2020-10-09T19:24:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r507056215", "bodyText": "Just double checking. Is this deliberate choice to execute Hive views by INVOKER? Previously they were executed by INVOKER. It sounds like a backward incompatible change (just noting for release notes if it is deliberate choice).", "author": "kokosing", "createdAt": "2020-10-18T09:16:37Z", "path": "presto-hive/src/main/java/io/prestosql/plugin/hive/ViewReaderUtil.java", "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.prestosql.plugin.hive;\n+\n+import com.linkedin.coral.hive.hive2rel.HiveMetastoreClient;\n+import com.linkedin.coral.hive.hive2rel.HiveToRelConverter;\n+import com.linkedin.coral.presto.rel2presto.RelToPrestoConverter;\n+import io.airlift.json.JsonCodec;\n+import io.airlift.json.JsonCodecFactory;\n+import io.airlift.json.ObjectMapperProvider;\n+import io.airlift.log.Logger;\n+import io.prestosql.plugin.base.CatalogName;\n+import io.prestosql.plugin.hive.authentication.HiveIdentity;\n+import io.prestosql.plugin.hive.metastore.CoralSemiTransactionalHiveMSCAdapter;\n+import io.prestosql.plugin.hive.metastore.SemiTransactionalHiveMetastore;\n+import io.prestosql.plugin.hive.metastore.Table;\n+import io.prestosql.spi.PrestoException;\n+import io.prestosql.spi.connector.ConnectorViewDefinition;\n+import io.prestosql.spi.connector.ConnectorViewDefinition.ViewColumn;\n+import io.prestosql.spi.type.TypeManager;\n+import org.apache.calcite.rel.RelNode;\n+import org.apache.calcite.rel.type.RelDataType;\n+import org.apache.hadoop.hive.metastore.TableType;\n+\n+import java.util.Base64;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Optional;\n+\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_INVALID_VIEW_DATA;\n+import static io.prestosql.plugin.hive.HiveErrorCode.HIVE_VIEW_TRANSLATION_ERROR;\n+import static io.prestosql.plugin.hive.HiveMetadata.TABLE_COMMENT;\n+import static io.prestosql.plugin.hive.util.HiveUtil.checkCondition;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.stream.Collectors.joining;\n+import static org.apache.hadoop.hive.metastore.TableType.VIRTUAL_VIEW;\n+\n+public final class ViewReaderUtil\n+{\n+    private ViewReaderUtil()\n+    {}\n+\n+    public interface ViewReader\n+    {\n+        ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName);\n+    }\n+\n+    public static ViewReader createViewReader(SemiTransactionalHiveMetastore metastore, HiveIdentity identity, Table table, TypeManager typemanager)\n+    {\n+        if (isPrestoView(table)) {\n+            return new PrestoViewReader();\n+        }\n+        return new HiveViewReader(new CoralSemiTransactionalHiveMSCAdapter(metastore, identity), typemanager);\n+    }\n+\n+    public static final String PRESTO_VIEW_FLAG = \"presto_view\";\n+    static final String VIEW_PREFIX = \"/* Presto View: \";\n+    static final String VIEW_SUFFIX = \" */\";\n+    private static final JsonCodec<ConnectorViewDefinition> VIEW_CODEC =\n+            new JsonCodecFactory(new ObjectMapperProvider()).jsonCodec(ConnectorViewDefinition.class);\n+    private static Logger log = Logger.get(io.prestosql.plugin.hive.ViewReaderUtil.class);\n+\n+    public static boolean isPrestoView(Table table)\n+    {\n+        return \"true\".equals(table.getParameters().get(PRESTO_VIEW_FLAG));\n+    }\n+\n+    public static boolean isHiveOrPrestoView(Table table)\n+    {\n+        return table.getTableType().equals(TableType.VIRTUAL_VIEW.name());\n+    }\n+\n+    public static boolean canDecodeView(Table table)\n+    {\n+        // we can decode Hive or Presto view\n+        return table.getTableType().equals(VIRTUAL_VIEW.name());\n+    }\n+\n+    public static String encodeViewData(ConnectorViewDefinition definition)\n+    {\n+        byte[] bytes = VIEW_CODEC.toJsonBytes(definition);\n+        String data = Base64.getEncoder().encodeToString(bytes);\n+        return VIEW_PREFIX + data + VIEW_SUFFIX;\n+    }\n+\n+    /**\n+     * Supports decoding of Presto views\n+     */\n+    public static class PrestoViewReader\n+            implements ViewReader\n+    {\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewData, Table table, CatalogName catalogName)\n+        {\n+            checkCondition(viewData.startsWith(VIEW_PREFIX), HIVE_INVALID_VIEW_DATA, \"View data missing prefix: %s\", viewData);\n+            checkCondition(viewData.endsWith(VIEW_SUFFIX), HIVE_INVALID_VIEW_DATA, \"View data missing suffix: %s\", viewData);\n+            viewData = viewData.substring(VIEW_PREFIX.length());\n+            viewData = viewData.substring(0, viewData.length() - VIEW_SUFFIX.length());\n+            byte[] bytes = Base64.getDecoder().decode(viewData);\n+            return VIEW_CODEC.fromJson(bytes);\n+        }\n+    }\n+\n+    /**\n+     * Class to decode Hive view definitions\n+     */\n+    public static class HiveViewReader\n+            implements ViewReader\n+    {\n+        private final HiveMetastoreClient metastoreClient;\n+        private final TypeManager typeManager;\n+\n+        public HiveViewReader(HiveMetastoreClient hiveMetastoreClient, TypeManager typemanager)\n+        {\n+            this.metastoreClient = requireNonNull(hiveMetastoreClient, \"metastoreClient is null\");\n+            this.typeManager = requireNonNull(typemanager, \"typeManager is null\");\n+        }\n+\n+        @Override\n+        public ConnectorViewDefinition decodeViewData(String viewSql, Table table, CatalogName catalogName)\n+        {\n+            try {\n+                HiveToRelConverter hiveToRelConverter = HiveToRelConverter.create(metastoreClient);\n+                RelNode rel = hiveToRelConverter.convertView(table.getDatabaseName(), table.getTableName());\n+                RelToPrestoConverter rel2Presto = new RelToPrestoConverter();\n+                String prestoSql = rel2Presto.convert(rel);\n+                RelDataType rowType = rel.getRowType();\n+                List<ViewColumn> columns = rowType.getFieldList().stream()\n+                        .map(field -> new ViewColumn(\n+                                field.getName(),\n+                                typeManager.fromSqlType(getTypeString(field.getType())).getTypeId()))\n+                        .collect(toImmutableList());\n+                return new ConnectorViewDefinition(prestoSql,\n+                        Optional.of(catalogName.toString()),\n+                        Optional.of(table.getDatabaseName()),\n+                        columns,\n+                        Optional.ofNullable(table.getParameters().get(TABLE_COMMENT)),\n+                        Optional.empty(),\n+                        true);", "originalCommit": "f93122c17424bed9e39b6a4a29b6fede102dc8d2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzE5OTgzMQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r507199831", "bodyText": "@kokosing Thanks for noticing that. I just noticed it is incompatible with previous version.  It has been running in our production environment with RunAsInvoker set to true. But if it is preferred to be backward compatible, I am ok to change.", "author": "laurachenyu", "createdAt": "2020-10-18T19:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzIwMzM5MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r507203390", "bodyText": "I am not that much concerned about being backward compatible, I wonder more about correctness. The question is what is the view semantic in Hive. Does Hive support running as invoker only or as owner only, does it allow to choose? We should do what view says we should do.\nI found it with a case when user has only access to a view and no access to underlying table, and query fails because we check the access to the table for that user (invoker), while previously we checked access to table but for the view owner.\nDo you use views in your production environment for access control purposes?\nRegarding backward compatibility, I hope that previous behavior was deliberate but I am not 100% sure.", "author": "kokosing", "createdAt": "2020-10-18T19:33:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzIwNTA5Ng==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r507205096", "bodyText": "Actually, I tested this with Hive and it works there, while in Presto I now get access denied.", "author": "kokosing", "createdAt": "2020-10-18T19:49:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY4NTc4NA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r507685784", "bodyText": "#5597", "author": "findepi", "createdAt": "2020-10-19T11:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTU0ODk0MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r515548940", "bodyText": "@findepi - Would it be better to have this Config controlled?", "author": "dmitryfill", "createdAt": "2020-10-31T22:47:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2NTg1MA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r515665850", "bodyText": "@dmitryfill\nIn #5597 we made those VIEWs back in line with SQL standard.\ni do not see why we would want this to be controlled by config just yet.\nPlease do not hesitate to file a new issue and ideally provide some rationale too.", "author": "findepi", "createdAt": "2020-11-01T20:08:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2NjI3MQ==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r515666271", "bodyText": "Alternatively, possibly more powerful would be to have ALTER VIEW x SET SECURITY DEFINER", "author": "kokosing", "createdAt": "2020-11-01T20:12:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTY2NjM2OA==", "url": "https://github.com/trinodb/trino/pull/4661#discussion_r515666368", "bodyText": "I was too quick. It won't work for Hive views as Presto do not control them.", "author": "kokosing", "createdAt": "2020-11-01T20:13:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzA1NjIxNQ=="}], "type": "inlineReview"}]}