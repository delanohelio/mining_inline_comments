{"pr_number": 2490, "pr_title": "Update instructions for enabling binary logs", "pr_createdAt": "2020-12-10T06:39:51Z", "pr_url": "https://github.com/wso2/docs-apim/pull/2490", "timeline": [{"oid": "1004df316d6fc06c207ebb41d74d78217ae28d15", "url": "https://github.com/wso2/docs-apim/commit/1004df316d6fc06c207ebb41d74d78217ae28d15", "message": "Correct link paths and rename files to comply to APIM documentation standards - Develop  section", "committedDate": "2020-12-10T06:34:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE2MTUxNA==", "url": "https://github.com/wso2/docs-apim/pull/2490#discussion_r540161514", "bodyText": "@RukshiW , looks like you forgot to add the link here", "author": "Mariangela", "createdAt": "2020-12-10T13:19:14Z", "path": "en/docs/streaming/extracting-data-from-static-sources-in-real-time/extracting-data-from-static-sources-in-real-time.md", "diffHunk": "@@ -443,7 +463,7 @@ define stream InStream (symbol string, message_id string);\n To transfer the content of the cloud storage to a file, add another stream with a sink of the `file` type as shown in the example below.\n \n !!! tip\n-    To learn more about publishing data to files, see [Loading and Writing Data](../loa).\n+    To learn more about publishing data to files, see [Loading and Writing Data](Loading and Writing Data).", "originalCommit": "1004df316d6fc06c207ebb41d74d78217ae28d15", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE2MjcwNA==", "url": "https://github.com/wso2/docs-apim/pull/2490#discussion_r540162704", "bodyText": "@RukshiW , does the following link actually work? I recall when links used to have the .md it the link used to break. Not sure how this will work.\nProcessing Data - Transforming Data", "author": "Mariangela", "createdAt": "2020-12-10T13:20:54Z", "path": "en/docs/streaming/extracting-data-from-static-sources-in-real-time/extracting-data-from-static-sources-in-real-time.md", "diffHunk": "@@ -496,4 +516,23 @@ The following is a list of cloud platforms from which you can extract stored dat\n | AWS Simple Cloud Storage (S3) | [S3](https://siddhi-io.github.io/siddhi-io-s3/api/latest/)                                            |\n | Google Cloud Storage          | [GCS](https://siddhi-io.github.io/siddhi-io-gcs/api/latest/)                                          |\n | CosmosDB                      | [CosmosDB](https://github.com/wso2-extensions/siddhi-store-cosmosdb/blob/master/docs/api/latest.md)   |\n-| Azure Data Lake               | [azuredatalake](https://siddhi-io.github.io/siddhi-io-azuredatalake/api/latest/#source)               |\n\\ No newline at end of file\n+| Azure Data Lake               | [azuredatalake](https://siddhi-io.github.io/siddhi-io-azuredatalake/api/latest/#source)               |\n+\n+### Supported mappers\n+\n+Mappers determine the format in which the event is received. For information about transforming events by changing the format in which the data is received/published, see [Processing Data - Transforming Data](processing-data.md#transforming-data).", "originalCommit": "1004df316d6fc06c207ebb41d74d78217ae28d15", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}