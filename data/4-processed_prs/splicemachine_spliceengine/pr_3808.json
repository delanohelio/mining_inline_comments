{"pr_number": 3808, "pr_title": "DB-9797 Restore DB-9651 with consistency fix", "pr_createdAt": "2020-07-11T00:16:02Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3808", "timeline": [{"oid": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "url": "https://github.com/splicemachine/spliceengine/commit/1afd1cc0de678f5b46c2ea4113d6256806824b4b", "message": "DB-9797 Restore DB-9651 with consistency fix", "committedDate": "2020-07-11T01:17:27Z", "type": "commit"}, {"oid": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "url": "https://github.com/splicemachine/spliceengine/commit/1afd1cc0de678f5b46c2ea4113d6256806824b4b", "message": "DB-9797 Restore DB-9651 with consistency fix", "committedDate": "2020-07-11T01:17:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyMjY4MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455222680", "bodyText": "(optional) could you maybe remove this field? it looks redundant.", "author": "hatyo", "createdAt": "2020-07-15T17:35:22Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -68,6 +68,8 @@\n     private boolean flushed;\n     private long numberOfRows = 0;\n     private FileSystem customFilesystem;", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyMzc5Ng==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455223796", "bodyText": "(optional) it would be nice if you could maybe document the purpose of this class. IIUC it allows Spark to interface with memstore, right?", "author": "hatyo", "createdAt": "2020-07-15T17:36:24Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -14,39 +14,39 @@\n \n package com.splicemachine.access.client;\n \n-import java.io.IOException;\n-import java.nio.charset.StandardCharsets;\n-import java.util.*;\n-import java.util.stream.Collectors;\n-\n import com.google.common.collect.Sets;\n import com.splicemachine.coprocessor.SpliceMessage;\n-import com.splicemachine.mrio.MRConstants;\n import com.splicemachine.si.constants.SIConstants;\n import com.splicemachine.si.impl.driver.SIDriver;\n import com.splicemachine.storage.Partition;\n import com.splicemachine.storage.SkeletonHBaseClientPartition;\n+import com.splicemachine.utils.SpliceLogUtils;\n+import org.apache.commons.codec.binary.Hex;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.hbase.*;\n+import org.apache.hadoop.hbase.Cell;\n+import org.apache.hadoop.hbase.CellUtil;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.HRegionInfo;\n import org.apache.hadoop.hbase.client.IsolationLevel;\n-import org.apache.hadoop.hbase.client.*;\n import org.apache.hadoop.hbase.client.ResultScanner;\n import org.apache.hadoop.hbase.client.Scan;\n import org.apache.hadoop.hbase.client.TableDescriptor;\n import org.apache.hadoop.hbase.ipc.CoprocessorRpcUtils;\n import org.apache.hadoop.hbase.ipc.ServerRpcController;\n-import org.apache.hadoop.hbase.regionserver.*;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HRegionUtil;\n+import org.apache.hadoop.hbase.regionserver.KeyValueScanner;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n import org.apache.hadoop.hbase.util.Bytes;\n import org.apache.hadoop.hbase.util.FSUtils;\n-import org.apache.hadoop.hdfs.ProxiedFilesystem;\n-import org.apache.hadoop.hdfs.DistributedFileSystem;\n-import org.apache.hadoop.security.AccessControlException;\n import org.apache.log4j.Logger;\n-import com.splicemachine.utils.SpliceLogUtils;\n import org.spark_project.guava.base.Throwables;\n \n+import java.io.IOException;\n+import java.util.*;\n+\n /**\n  * \n  * ", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgxMDAwOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455810008", "bodyText": "So if there are no more rows, we consume the rowBuffer and return, otherwise, we consume the rowBuffer and pre-fetch the next row into rowBuffer, right?", "author": "hatyo", "createdAt": "2020-07-16T14:02:24Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -141,10 +143,44 @@ public boolean isFilterDone() throws IOException{\n         return scanner.isFilterDone();\n     }\n \n+    private void fetchNextAndGiveBuffer(List<Cell> result) throws IOException {\n+        assert result.isEmpty();\n+        List<Cell> nextResult = new ArrayList<>();\n+        boolean response = nextMerged(nextResult);\n+        if (matchingFamily(nextResult, ClientRegionConstants.FLUSH)) {\n+            // A flush should be returned before a potential partial result in the buffer\n+            result.addAll(nextResult);\n+        } else {\n+            result.addAll(rowBuffer);\n+            rowBuffer = nextResult;\n+            if (!response) {\n+                noMoreRecords = true;\n+            }\n+        }\n+    }\n+\n     @Override\n     public boolean nextRaw(List<Cell> result) throws IOException {\n-        boolean res = nextMerged(result);\n-        boolean returnValue = updateTopCell(res,result);\n+        boolean firstCall = rowBuffer == null;\n+        boolean response;\n+        if (firstCall) {\n+            rowBuffer = new ArrayList<>();\n+            response = nextMerged(rowBuffer);\n+            if (!response) {\n+                result.addAll(rowBuffer);\n+                rowBuffer = null;\n+            } else {\n+                fetchNextAndGiveBuffer(result);\n+            }", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgzMDI3Nw==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455830277", "bodyText": "yes", "author": "arnaud-splice", "createdAt": "2020-07-16T14:29:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgxMDAwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgxMDg2OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455810869", "bodyText": "Is this field necessary? could you please consider removing it, it makes understanding the code unnecessarily more complicated IMHO, i.e.:\nmake fetchNextAndGiveBuffer() return boolean indicating whether more rows are to come  (similar to RegionScanner.nextRaw) and assign it to a local variable in nextRaw call (maybe with some documentation)", "author": "hatyo", "createdAt": "2020-07-16T14:03:35Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -68,6 +68,8 @@\n     private boolean flushed;\n     private long numberOfRows = 0;\n     private FileSystem customFilesystem;\n+    private List<Cell> rowBuffer = null;\n+    private boolean noMoreRecords = false;", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyODA4NQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455828085", "bodyText": "That's not possible. The attribute would be read only the next time that nextRaw is being called, and that happens through some hbase code.", "author": "arnaud-splice", "createdAt": "2020-07-16T14:26:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgxMDg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgxNTk1OA==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455815958", "bodyText": "consider renaming this to something like: moreRowsFollow.", "author": "hatyo", "createdAt": "2020-07-16T14:10:24Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -141,10 +143,44 @@ public boolean isFilterDone() throws IOException{\n         return scanner.isFilterDone();\n     }\n \n+    private void fetchNextAndGiveBuffer(List<Cell> result) throws IOException {\n+        assert result.isEmpty();\n+        List<Cell> nextResult = new ArrayList<>();\n+        boolean response = nextMerged(nextResult);\n+        if (matchingFamily(nextResult, ClientRegionConstants.FLUSH)) {\n+            // A flush should be returned before a potential partial result in the buffer\n+            result.addAll(nextResult);\n+        } else {\n+            result.addAll(rowBuffer);\n+            rowBuffer = nextResult;\n+            if (!response) {\n+                noMoreRecords = true;\n+            }\n+        }\n+    }\n+\n     @Override\n     public boolean nextRaw(List<Cell> result) throws IOException {\n-        boolean res = nextMerged(result);\n-        boolean returnValue = updateTopCell(res,result);\n+        boolean firstCall = rowBuffer == null;\n+        boolean response;", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyMDAxMg==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455820012", "bodyText": "I think this is neither thread-safe nor exception-safe.\nInstead maybe we should:\n\nMoved the flushed flag into the updateScanner method and update it there with care.\nMark updateScanner method as synchronized.", "author": "hatyo", "createdAt": "2020-07-16T14:15:26Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -189,8 +232,7 @@ public HRegion getRegion(){\n     /*private helper methods*/\n \n     private boolean updateTopCell(boolean response, List<Cell> results) throws IOException {\n-        if (!results.isEmpty() &&\n-                CellUtil.matchingFamily(results.get(0),ClientRegionConstants.FLUSH)){\n+        if (matchingFamily(results, ClientRegionConstants.FLUSH)) {\n             if (LOG.isDebugEnabled())\n                 SpliceLogUtils.debug(LOG,\"received flush message \" + results.get(0));\n             flushed = true;", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgzMjU2Nw==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455832567", "bodyText": "It does not need to be thread safe, only one thread is using this scanner.", "author": "arnaud-splice", "createdAt": "2020-07-16T14:32:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyMDAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyMTQ5NA==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455821494", "bodyText": "could you please rephrase the documentation.", "author": "hatyo", "createdAt": "2020-07-16T14:17:34Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -155,7 +191,7 @@ public boolean nextRaw(List<Cell> result) throws IOException {\n      * refresh underlying RegionScanner we call this when new store file gets", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyMjQxOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455822418", "bodyText": "optional: add: assert htd != null && htd.getTableName() != null;", "author": "hatyo", "createdAt": "2020-07-16T14:18:52Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -155,7 +191,7 @@ public boolean nextRaw(List<Cell> result) throws IOException {\n      * refresh underlying RegionScanner we call this when new store file gets\n      * created by MemStore flushes or current scanner fails due to compaction\n      */\n-    public void updateScanner() throws IOException {\n+    void updateScanner() throws IOException {\n             if (LOG.isDebugEnabled()) {\n                 SpliceLogUtils.debug(LOG,\n                         \"updateScanner with hregionInfo=%s, tableName=%s, rootDir=%s, scan=%s\",", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyMzExMw==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455823113", "bodyText": "nice! \ud83d\udc4d", "author": "hatyo", "createdAt": "2020-07-16T14:19:53Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -164,11 +200,18 @@ public void updateScanner() throws IOException {\n             if (flushed) {\n                 if (LOG.isDebugEnabled())\n                     SpliceLogUtils.debug(LOG, \"Flush occurred\");\n-                if (this.topCell != null) {\n+                byte[] restartRow = null;\n+                if (rowBuffer != null && !rowBuffer.isEmpty()) {\n+                    restartRow = CellUtil.cloneRow(rowBuffer.get(0));\n+                    rowBuffer = null;\n+                } else if (this.topCell != null) {\n+                    restartRow = Bytes.add(CellUtil.cloneRow(topCell), new byte[]{0});\n+                }\n+                if (restartRow != null) {\n                     if (LOG.isDebugEnabled())\n-                        SpliceLogUtils.debug(LOG, \"setting start row to %s\", topCell);\n+                        SpliceLogUtils.debug(LOG, \"setting start row to %s\", Hex.encodeHexString(restartRow));", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyNDUzNA==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455824534", "bodyText": "I don't understand this comment, does it mean that we have the full nextResult or could it be partial?", "author": "hatyo", "createdAt": "2020-07-16T14:21:51Z", "path": "hbase_storage/src/main/java/com/splicemachine/access/client/SkeletonClientSideRegionScanner.java", "diffHunk": "@@ -141,10 +143,44 @@ public boolean isFilterDone() throws IOException{\n         return scanner.isFilterDone();\n     }\n \n+    private void fetchNextAndGiveBuffer(List<Cell> result) throws IOException {\n+        assert result.isEmpty();\n+        List<Cell> nextResult = new ArrayList<>();\n+        boolean response = nextMerged(nextResult);\n+        if (matchingFamily(nextResult, ClientRegionConstants.FLUSH)) {\n+            // A flush should be returned before a potential partial result in the buffer", "originalCommit": "1afd1cc0de678f5b46c2ea4113d6256806824b4b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyOTQ5Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3808#discussion_r455829492", "bodyText": "Typically, when we return from this function, we have managed to put the buffer in result and we've gotten a new buffer.\nIf we get a flush token, we cannot return the current buffer, because it may contain partial results. Those partial results would never be completed since nextRaw would return FLUSH.\nSo we need to return the flush before.", "author": "arnaud-splice", "createdAt": "2020-07-16T14:28:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTgyNDUzNA=="}], "type": "inlineReview"}]}