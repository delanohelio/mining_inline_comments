{"pr_number": 3153, "pr_title": "DB-9057 Separate Control and Spark costing", "pr_createdAt": "2020-01-21T12:01:40Z", "pr_url": "https://github.com/splicemachine/spliceengine/pull/3153", "timeline": [{"oid": "026549e7e23be818a49b0a71105c533fdfc00b75", "url": "https://github.com/splicemachine/spliceengine/commit/026549e7e23be818a49b0a71105c533fdfc00b75", "message": "DB-9057 Separate Control and Spark costing", "committedDate": "2020-01-21T16:07:29Z", "type": "forcePushed"}, {"oid": "6c462e49864c7f1b3a825a3d24371282b9738edd", "url": "https://github.com/splicemachine/spliceengine/commit/6c462e49864c7f1b3a825a3d24371282b9738edd", "message": "DB-9057 Separate Control and Spark costing", "committedDate": "2020-01-21T18:04:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4NDU1Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r371584552", "bodyText": "We use different OptimizerImpl instance to plan each SELECT block. We set the useSpark variable for the OptimizerImpl instance for the top SELECT, but I don't see logic that passes the setting to the OptimizerImpl instance for the nested SELECT block.\nGiven the following query as an example:\nexplain select * from (select * from t1 --splice-properties useDefaultRowCount=30000000\n, t2 where a1=a2) dt1, (select * from t3, t4 where a3=a4) dt2 where a1=a2; \n\nWhen the top SELECT is planning for the spark path, the nested SELECT still has useSpark=false.", "author": "yxia92", "createdAt": "2020-01-28T02:31:35Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/SelectNode.java", "diffHunk": "@@ -1601,39 +1599,37 @@ public ResultSetNode optimize(DataDictionary dataDictionary,\n                 }\n             }\n         }\n-\t\t/* Get a new optimizer */\n-        optimizer=getOptimizer(fromList, wherePredicates, dataDictionary, orderByList);\n-        optimizer.setOuterRows(outerRows);\n \n-        // Aggregation with no GROUP BY always outputs one row.\n-        if ((selectAggregates != null && !selectAggregates.isEmpty() ||\n-             havingAggregates !=null  && !havingAggregates.isEmpty()) && hasNoGroupBy())\n-            optimizer.setSingleRow(true);\n+        Optimizer optimizer = getOptimizer(fromList, wherePredicates, dataDictionary, orderByList);\n+        if (nestingLevel == 0) {\n+            // Top level select node, we should try to cost control first, and fallback to spark if necessary\n \n-\t\t/* Optimize this SelectNode */\n-        while(optimizer.nextJoinOrder()){\n-            while(optimizer.getNextDecoratedPermutation()){\n-                optimizer.costPermutation();\n+            if (!determineSpark()) {\n+                optimizer.setForSpark(false);\n+                findBestPlan(optimizer, dataDictionary, outerRows);\n+            }\n+\n+            if (determineSpark()) {\n+                for (int i = 0; i < fromList.size(); ++i) {\n+                    FromTable ft = (FromTable) fromList.elementAt(i);\n+                    ft.resetAccessPaths();\n+                }\n+                optimizer.setForSpark(true);\n+                optimizer.prepForNextRound();\n+                findBestPlan(optimizer, dataDictionary, outerRows);\n             }\n+        } else {\n+            findBestPlan(optimizer, dataDictionary, outerRows);", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMDg0Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r373000842", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-30T15:02:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4NDU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4NjYwNw==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r371586607", "bodyText": "This seems only resetting the access path for the tables in the top level SELECT, but not that of the nested SELECT, shouldn't we reset that too?", "author": "yxia92", "createdAt": "2020-01-28T02:41:39Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/SelectNode.java", "diffHunk": "@@ -1601,39 +1599,37 @@ public ResultSetNode optimize(DataDictionary dataDictionary,\n                 }\n             }\n         }\n-\t\t/* Get a new optimizer */\n-        optimizer=getOptimizer(fromList, wherePredicates, dataDictionary, orderByList);\n-        optimizer.setOuterRows(outerRows);\n \n-        // Aggregation with no GROUP BY always outputs one row.\n-        if ((selectAggregates != null && !selectAggregates.isEmpty() ||\n-             havingAggregates !=null  && !havingAggregates.isEmpty()) && hasNoGroupBy())\n-            optimizer.setSingleRow(true);\n+        Optimizer optimizer = getOptimizer(fromList, wherePredicates, dataDictionary, orderByList);\n+        if (nestingLevel == 0) {\n+            // Top level select node, we should try to cost control first, and fallback to spark if necessary\n \n-\t\t/* Optimize this SelectNode */\n-        while(optimizer.nextJoinOrder()){\n-            while(optimizer.getNextDecoratedPermutation()){\n-                optimizer.costPermutation();\n+            if (!determineSpark()) {\n+                optimizer.setForSpark(false);\n+                findBestPlan(optimizer, dataDictionary, outerRows);\n+            }\n+\n+            if (determineSpark()) {\n+                for (int i = 0; i < fromList.size(); ++i) {\n+                    FromTable ft = (FromTable) fromList.elementAt(i);\n+                    ft.resetAccessPaths();", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMDczOQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r373000739", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-30T15:02:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4NjYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4ODQ3Mg==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r371588472", "bodyText": "For the case of forced control, should we skip costing the second path?", "author": "yxia92", "createdAt": "2020-01-28T02:52:22Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/SelectNode.java", "diffHunk": "@@ -1601,39 +1599,37 @@ public ResultSetNode optimize(DataDictionary dataDictionary,\n                 }\n             }\n         }\n-\t\t/* Get a new optimizer */\n-        optimizer=getOptimizer(fromList, wherePredicates, dataDictionary, orderByList);\n-        optimizer.setOuterRows(outerRows);\n \n-        // Aggregation with no GROUP BY always outputs one row.\n-        if ((selectAggregates != null && !selectAggregates.isEmpty() ||\n-             havingAggregates !=null  && !havingAggregates.isEmpty()) && hasNoGroupBy())\n-            optimizer.setSingleRow(true);\n+        Optimizer optimizer = getOptimizer(fromList, wherePredicates, dataDictionary, orderByList);\n+        if (nestingLevel == 0) {\n+            // Top level select node, we should try to cost control first, and fallback to spark if necessary\n \n-\t\t/* Optimize this SelectNode */\n-        while(optimizer.nextJoinOrder()){\n-            while(optimizer.getNextDecoratedPermutation()){\n-                optimizer.costPermutation();\n+            if (!determineSpark()) {\n+                optimizer.setForSpark(false);\n+                findBestPlan(optimizer, dataDictionary, outerRows);\n+            }\n+\n+            if (determineSpark()) {", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzAwMDY4Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r373000683", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-30T15:02:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTU4ODQ3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjIzOTk4MQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372239981", "bodyText": "Shouldn't it be isForSpark since it's a predicate?", "author": "jaceklaskowski", "createdAt": "2020-01-29T08:15:42Z", "path": "db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/Optimizer.java", "diffHunk": "@@ -402,4 +402,7 @@ void considerCost(Optimizable optimizable,\n \n     public void setSingleRow(boolean singleRowInRelation);\n \n+    public void setForSpark(boolean forSpark);\n+\n+    public boolean getForSpark();", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5NTIzOA==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372395238", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-29T13:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjIzOTk4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI0MDQ3MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372240470", "bodyText": "Since we're at spacing, what about spaces after commas?", "author": "jaceklaskowski", "createdAt": "2020-01-29T08:16:49Z", "path": "db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/RequiredRowOrdering.java", "diffHunk": "@@ -44,83 +44,87 @@\n  */\n public interface RequiredRowOrdering\n {\n-\tint SORT_REQUIRED = 1;\n-\tint ELIMINATE_DUPS = 2;\n-\tint NOTHING_REQUIRED = 3;\n+    int SORT_REQUIRED = 1;\n+    int ELIMINATE_DUPS = 2;\n+    int NOTHING_REQUIRED = 3;\n \n-\t/**\n-\t * Tell whether sorting is required for this RequiredRowOrdering,\n-\t * given a RowOrdering.\n-\t *\n-\t * @param rowOrdering\tThe order of rows in question\n-\t * @param optimizableList\tThe current join order being considered by \n-\t *    the optimizer. We need to look into this to determine if the outer\n-\t *    optimizables are single row resultset if the order by column is\n-\t *    on an inner optimizable and that inner optimizable is not a one\n-\t *    row resultset. DERBY-3926\n-\t *\n-\t * @return\tSORT_REQUIRED if sorting is required,\n-\t *\t\t\tELIMINATE_DUPS if no sorting is required but duplicates\n-\t *\t\t\t\t\t\t\tmust be eliminated (i.e. the rows are in\n-\t *\t\t\t\t\t\t\tthe right order but there may be duplicates),\n-\t *\t\t\tNOTHING_REQUIRED is no operation is required\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tint sortRequired(RowOrdering rowOrdering, OptimizableList optimizableList)  throws StandardException;\n+    /**\n+     * Tell whether sorting is required for this RequiredRowOrdering,\n+     * given a RowOrdering.\n+     *\n+     * @param rowOrdering    The order of rows in question\n+     * @param optimizableList    The current join order being considered by\n+     *    the optimizer. We need to look into this to determine if the outer\n+     *    optimizables are single row resultset if the order by column is\n+     *    on an inner optimizable and that inner optimizable is not a one\n+     *    row resultset. DERBY-3926\n+     *\n+     * @return    SORT_REQUIRED if sorting is required,\n+     *            ELIMINATE_DUPS if no sorting is required but duplicates\n+     *                            must be eliminated (i.e. the rows are in\n+     *                            the right order but there may be duplicates),\n+     *            NOTHING_REQUIRED is no operation is required\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    int sortRequired(RowOrdering rowOrdering, OptimizableList optimizableList)  throws StandardException;\n \n-\t/**\n-\t * Tell whether sorting is required for this RequiredRowOrdering,\n-\t * given a RowOrdering representing a partial join order, and\n-\t * a bit map telling what tables are represented in the join order.\n-\t * This is useful for reducing the number of cases the optimizer\n-\t * has to consider.\n-\t *\n-\t * @param rowOrdering\tThe order of rows in the partial join order\n-\t * @param tableMap\t\tA bit map of the tables in the partial join order\n-\t * @param optimizableList\tThe current join order being considered by \n-\t *    the optimizer. We need to look into this to determine if the outer\n-\t *    optimizables are single row resultset if the order by column is\n-\t *    on an inner optimizable and that inner optimizable is not a one\n-\t *    row resultset. DERBY-3926\n-\t *\n-\t * @return\tSORT_REQUIRED if sorting is required,\n-\t *\t\t\tELIMINATE_DUPS if no sorting is required by duplicates\n-\t *\t\t\t\t\t\t\tmust be eliminated (i.e. the rows are in\n-\t *\t\t\t\t\t\t\tthe right order but there may be duplicates),\n-\t *\t\t\tNOTHING_REQUIRED is no operation is required\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tint sortRequired(RowOrdering rowOrdering,JBitSet tableMap,OptimizableList optimizableList) throws StandardException;\n+    /**\n+     * Tell whether sorting is required for this RequiredRowOrdering,\n+     * given a RowOrdering representing a partial join order, and\n+     * a bit map telling what tables are represented in the join order.\n+     * This is useful for reducing the number of cases the optimizer\n+     * has to consider.\n+     *\n+     * @param rowOrdering    The order of rows in the partial join order\n+     * @param tableMap        A bit map of the tables in the partial join order\n+     * @param optimizableList    The current join order being considered by\n+     *    the optimizer. We need to look into this to determine if the outer\n+     *    optimizables are single row resultset if the order by column is\n+     *    on an inner optimizable and that inner optimizable is not a one\n+     *    row resultset. DERBY-3926\n+     *\n+     * @return    SORT_REQUIRED if sorting is required,\n+     *            ELIMINATE_DUPS if no sorting is required by duplicates\n+     *                            must be eliminated (i.e. the rows are in\n+     *                            the right order but there may be duplicates),\n+     *            NOTHING_REQUIRED is no operation is required\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    int sortRequired(RowOrdering rowOrdering,JBitSet tableMap,OptimizableList optimizableList) throws StandardException;", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5NTQ3NA==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372395474", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-29T13:56:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI0MDQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI0MDY4Ng==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372240686", "bodyText": "Should really be isSortNeeded.", "author": "jaceklaskowski", "createdAt": "2020-01-29T08:17:24Z", "path": "db-engine/src/main/java/com/splicemachine/db/iapi/sql/compile/RequiredRowOrdering.java", "diffHunk": "@@ -44,83 +44,87 @@\n  */\n public interface RequiredRowOrdering\n {\n-\tint SORT_REQUIRED = 1;\n-\tint ELIMINATE_DUPS = 2;\n-\tint NOTHING_REQUIRED = 3;\n+    int SORT_REQUIRED = 1;\n+    int ELIMINATE_DUPS = 2;\n+    int NOTHING_REQUIRED = 3;\n \n-\t/**\n-\t * Tell whether sorting is required for this RequiredRowOrdering,\n-\t * given a RowOrdering.\n-\t *\n-\t * @param rowOrdering\tThe order of rows in question\n-\t * @param optimizableList\tThe current join order being considered by \n-\t *    the optimizer. We need to look into this to determine if the outer\n-\t *    optimizables are single row resultset if the order by column is\n-\t *    on an inner optimizable and that inner optimizable is not a one\n-\t *    row resultset. DERBY-3926\n-\t *\n-\t * @return\tSORT_REQUIRED if sorting is required,\n-\t *\t\t\tELIMINATE_DUPS if no sorting is required but duplicates\n-\t *\t\t\t\t\t\t\tmust be eliminated (i.e. the rows are in\n-\t *\t\t\t\t\t\t\tthe right order but there may be duplicates),\n-\t *\t\t\tNOTHING_REQUIRED is no operation is required\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tint sortRequired(RowOrdering rowOrdering, OptimizableList optimizableList)  throws StandardException;\n+    /**\n+     * Tell whether sorting is required for this RequiredRowOrdering,\n+     * given a RowOrdering.\n+     *\n+     * @param rowOrdering    The order of rows in question\n+     * @param optimizableList    The current join order being considered by\n+     *    the optimizer. We need to look into this to determine if the outer\n+     *    optimizables are single row resultset if the order by column is\n+     *    on an inner optimizable and that inner optimizable is not a one\n+     *    row resultset. DERBY-3926\n+     *\n+     * @return    SORT_REQUIRED if sorting is required,\n+     *            ELIMINATE_DUPS if no sorting is required but duplicates\n+     *                            must be eliminated (i.e. the rows are in\n+     *                            the right order but there may be duplicates),\n+     *            NOTHING_REQUIRED is no operation is required\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    int sortRequired(RowOrdering rowOrdering, OptimizableList optimizableList)  throws StandardException;\n \n-\t/**\n-\t * Tell whether sorting is required for this RequiredRowOrdering,\n-\t * given a RowOrdering representing a partial join order, and\n-\t * a bit map telling what tables are represented in the join order.\n-\t * This is useful for reducing the number of cases the optimizer\n-\t * has to consider.\n-\t *\n-\t * @param rowOrdering\tThe order of rows in the partial join order\n-\t * @param tableMap\t\tA bit map of the tables in the partial join order\n-\t * @param optimizableList\tThe current join order being considered by \n-\t *    the optimizer. We need to look into this to determine if the outer\n-\t *    optimizables are single row resultset if the order by column is\n-\t *    on an inner optimizable and that inner optimizable is not a one\n-\t *    row resultset. DERBY-3926\n-\t *\n-\t * @return\tSORT_REQUIRED if sorting is required,\n-\t *\t\t\tELIMINATE_DUPS if no sorting is required by duplicates\n-\t *\t\t\t\t\t\t\tmust be eliminated (i.e. the rows are in\n-\t *\t\t\t\t\t\t\tthe right order but there may be duplicates),\n-\t *\t\t\tNOTHING_REQUIRED is no operation is required\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tint sortRequired(RowOrdering rowOrdering,JBitSet tableMap,OptimizableList optimizableList) throws StandardException;\n+    /**\n+     * Tell whether sorting is required for this RequiredRowOrdering,\n+     * given a RowOrdering representing a partial join order, and\n+     * a bit map telling what tables are represented in the join order.\n+     * This is useful for reducing the number of cases the optimizer\n+     * has to consider.\n+     *\n+     * @param rowOrdering    The order of rows in the partial join order\n+     * @param tableMap        A bit map of the tables in the partial join order\n+     * @param optimizableList    The current join order being considered by\n+     *    the optimizer. We need to look into this to determine if the outer\n+     *    optimizables are single row resultset if the order by column is\n+     *    on an inner optimizable and that inner optimizable is not a one\n+     *    row resultset. DERBY-3926\n+     *\n+     * @return    SORT_REQUIRED if sorting is required,\n+     *            ELIMINATE_DUPS if no sorting is required by duplicates\n+     *                            must be eliminated (i.e. the rows are in\n+     *                            the right order but there may be duplicates),\n+     *            NOTHING_REQUIRED is no operation is required\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    int sortRequired(RowOrdering rowOrdering,JBitSet tableMap,OptimizableList optimizableList) throws StandardException;\n \n-\t/**\n-\t * Estimate the cost of doing a sort for this row ordering, given\n-\t * the number of rows to be sorted.  This does not take into account\n-\t * whether the sort is really needed.  It also estimates the number of\n-\t * result rows.\n-\t *\n-\t * @param rowOrdering\t\t\tThe ordering of the input rows\n-\t *\n-\t * @exception StandardException\t\tThrown on error\n-\t */\n-\tvoid estimateCost(Optimizer optimizer, RowOrdering rowOrdering, CostEstimate baseCost, CostEstimate sortCost) throws StandardException;\n+    /**\n+     * Estimate the cost of doing a sort for this row ordering, given\n+     * the number of rows to be sorted.  This does not take into account\n+     * whether the sort is really needed.  It also estimates the number of\n+     * result rows.\n+     *\n+     * @param rowOrdering       The ordering of the input rows\n+     *\n+     * @exception StandardException        Thrown on error\n+     */\n+    void estimateCost(Optimizer optimizer,\n+                      RowOrdering rowOrdering,\n+                      CostEstimate baseCost,\n+                      CostEstimate sortCost)\n+            throws StandardException;\n \n-\t/**\n-\t * Indicate that a sort is necessary to fulfill this required ordering.\n-\t * This method may be called many times during a single optimization.\n-\t */\n-\tvoid sortNeeded();\n+    /**\n+     * Indicate that a sort is necessary to fulfill this required ordering.\n+     * This method may be called many times during a single optimization.\n+     */\n+    void sortNeeded();\n \n-\t/**\n-\t * Indicate that a sort is *NOT* necessary to fulfill this required\n-\t * ordering.  This method may be called many times during a single\n-\t * optimization.\n-\t */\n-\tvoid sortNotNeeded();\n+    /**\n+     * Indicate that a sort is *NOT* necessary to fulfill this required\n+     * ordering.  This method may be called many times during a single\n+     * optimization.\n+     */\n+    void sortNotNeeded();\n \n-\t/**\n-\t * @return Whether or not a sort is needed.\n-\t */\n-\tboolean getSortNeeded();\n+    /**\n+     * @return Whether or not a sort is needed.\n+     */\n+    boolean getSortNeeded();", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5NTczNQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372395735", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-29T13:57:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI0MDY4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI0MDk0MA==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372240940", "bodyText": "Still one space needed", "author": "jaceklaskowski", "createdAt": "2020-01-29T08:18:04Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/FromTable.java", "diffHunk": "@@ -236,10 +235,10 @@ public boolean nextAccessPath(Optimizer optimizer,\n         }\n         ap.setMissingHashKeyOK(false);\n \n-\t\t/*\n-\t\t** Tell the RowOrdering about columns that are equal to constant\n-\t\t** expressions.\n-\t\t*/\n+        /*\n+        ** Tell the RowOrdering about columns that are equal to constant", "originalCommit": "6c462e49864c7f1b3a825a3d24371282b9738edd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjM5NjUzMA==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r372396530", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-01-29T13:58:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI0MDk0MA=="}], "type": "inlineReview"}, {"oid": "89da2a31d1a582eb0cea8d0f478e3c6d71197c08", "url": "https://github.com/splicemachine/spliceengine/commit/89da2a31d1a582eb0cea8d0f478e3c6d71197c08", "message": "DB-9057 Support FORCED_CONTROL", "committedDate": "2020-01-30T15:01:13Z", "type": "forcePushed"}, {"oid": "7e751c133c93930c52de10b478c5568b58d2121f", "url": "https://github.com/splicemachine/spliceengine/commit/7e751c133c93930c52de10b478c5568b58d2121f", "message": "DB-9057 Support FORCED_CONTROL", "committedDate": "2020-01-30T15:15:31Z", "type": "forcePushed"}, {"oid": "1ed88ce2ee6d69639a18d7dbab91f031036590fe", "url": "https://github.com/splicemachine/spliceengine/commit/1ed88ce2ee6d69639a18d7dbab91f031036590fe", "message": "DB-9057 Separate Control and Spark costing", "committedDate": "2020-02-03T16:08:32Z", "type": "forcePushed"}, {"oid": "1a5268f75d60ebb1d51bf3c4fed8c48ab210dc8d", "url": "https://github.com/splicemachine/spliceengine/commit/1a5268f75d60ebb1d51bf3c4fed8c48ab210dc8d", "message": "DB-9057 Introduce finer granularity in DataSetProcessorType", "committedDate": "2020-02-04T20:49:31Z", "type": "forcePushed"}, {"oid": "73e203a07c0c981170f8ae556ee8d7439748882d", "url": "https://github.com/splicemachine/spliceengine/commit/73e203a07c0c981170f8ae556ee8d7439748882d", "message": "DB-9057 Separate Control and Spark costing", "committedDate": "2020-02-04T23:17:53Z", "type": "commit"}, {"oid": "a60e7d2e0b7b747f39e07d7fbe0b9d787a304260", "url": "https://github.com/splicemachine/spliceengine/commit/a60e7d2e0b7b747f39e07d7fbe0b9d787a304260", "message": "DB-9057 set control/spark in opt phase of Insert/Delete", "committedDate": "2020-02-04T23:17:53Z", "type": "commit"}, {"oid": "ef859861d31338fedcee1487566a29c5ff8a7cee", "url": "https://github.com/splicemachine/spliceengine/commit/ef859861d31338fedcee1487566a29c5ff8a7cee", "message": "DB-9057 Introduce finer granularity in DataSetProcessorType", "committedDate": "2020-02-04T23:29:46Z", "type": "forcePushed"}, {"oid": "feaa5c85ae7a720e370a09394e711e11dbb0544c", "url": "https://github.com/splicemachine/spliceengine/commit/feaa5c85ae7a720e370a09394e711e11dbb0544c", "message": "DB-9057 Introduce finer granularity in DataSetProcessorType", "committedDate": "2020-02-05T12:24:48Z", "type": "commit"}, {"oid": "feaa5c85ae7a720e370a09394e711e11dbb0544c", "url": "https://github.com/splicemachine/spliceengine/commit/feaa5c85ae7a720e370a09394e711e11dbb0544c", "message": "DB-9057 Introduce finer granularity in DataSetProcessorType", "committedDate": "2020-02-05T12:24:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU1NjEzNw==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r375556137", "bodyText": "I think the call to verifyProperties() should be moved down to the for loop at line 203, as the call here only touches the tables in the top level Select, but not the tables in the nested SELECT nodes.", "author": "yxia92", "createdAt": "2020-02-05T22:59:17Z", "path": "db-engine/src/main/java/com/splicemachine/db/impl/sql/compile/DMLStatementNode.java", "diffHunk": "@@ -166,11 +167,62 @@ public void optimizeStatement() throws StandardException {\n         // prune tree based on unsat condition\n         accept(new TreePruningVisitor());\n \n-        resultSet = resultSet.optimize(getDataDictionary(), null, 1.0d);\n+\n+\n+        // We should try to cost control first, and fallback to spark if necessary\n+        DataSetProcessorType connectionType = getLanguageConnectionContext().getDataSetProcessorType();\n+        getCompilerContext().setDataSetProcessorType(connectionType);\n+\n+        if (shouldRunControl(resultSet)) {\n+            resultSet = resultSet.optimize(getDataDictionary(), null, 1.0d, false);\n+        }\n+\n+        if (shouldRunSpark(resultSet)) {\n+            CollectNodesVisitor cnv = new CollectNodesVisitor(FromTable.class);\n+            resultSet.accept(cnv);\n+            for (Object obj : cnv.getList()) {\n+                FromTable ft = (FromTable) obj;\n+                ft.resetAccessPaths();\n+            }\n+            resultSet = resultSet.optimize(getDataDictionary(), null, 1.0d, true);\n+        }\n+\n         resultSet = resultSet.modifyAccessPaths();\n \n     }\n \n+    private boolean shouldRunControl(ResultSetNode resultSet) throws StandardException {\n+        DataSetProcessorType type = getCompilerContext().getDataSetProcessorType();\n+        if (type.isForced()) {\n+            return (!type.isSpark());\n+        }\n+        resultSet.getFromList().verifyProperties(getDataDictionary());", "originalCommit": "feaa5c85ae7a720e370a09394e711e11dbb0544c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc3MjMzMw==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r375772333", "bodyText": "Done", "author": "arnaud-splice", "createdAt": "2020-02-06T11:06:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU1NjEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4NjE1OQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r375586159", "bodyText": "I think we don't need to read dataSetProcessorType from the FromBaseTable, instead, we can directly use  ((FromBaseTable) innerTable).getCompilerContext().getDataSetProcessorType(), as using Spark or not is pre-set now.", "author": "yxia92", "createdAt": "2020-02-06T00:38:16Z", "path": "splice_machine/src/main/java/com/splicemachine/derby/impl/sql/compile/CrossJoinStrategy.java", "diffHunk": "@@ -203,9 +203,10 @@ public boolean feasible(Optimizable innerTable,\n         boolean isOneRow = false;\n         boolean isHinted = currentAccessPath.isHintedJoinStrategy();\n         if (innerTable instanceof FromBaseTable) {\n-            CompilerContext.DataSetProcessorType dspt = ((FromBaseTable) innerTable).getdataSetProcessorTypeForAccessPath(currentAccessPath);\n-            isSpark = ((FromBaseTable)innerTable).isSpark(dspt);\n-            isForcedControl = dspt.name().equals(\"FORCED_CONTROL\");\n+            DataSetProcessorType dspt = ((FromBaseTable) innerTable).getDataSetProcessorTypeForAccessPath(currentAccessPath);\n+            dspt.combine(((FromBaseTable) innerTable).getCompilerContext().getDataSetProcessorType());", "originalCommit": "feaa5c85ae7a720e370a09394e711e11dbb0544c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc0NzY1Mw==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r375747653", "bodyText": "Good point, I should use optimizer.isForSpark here instead. This is the governing instruction to follow while crawling through join strategies and permutations.", "author": "arnaud-splice", "createdAt": "2020-02-06T10:16:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4NjE1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5ODQzMw==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r375598433", "bodyText": "If we skip the check of dataSetProcessorType() in LanguageConnectionContext, we may not be able to honor the session level useSpark hint for some special cases. For example:\nsplice> connect 'jdbc:splice://localhost:1527/splicedb;user=splice;password=admin;useSpark=true' as spark_con;\nexplain select name from new com.splicemachine.derby.vti.SchemaFilterVTI() as b (NAME VARCHAR(128));\n\nThe explain will show Spark, but the query is actually sent to control. This is because we didn't call ActivationClassBuilder.setDataSetProcessorType() for this case. As a general solution, maybe we should calll this function in ScrollInsensitiveResultSetNode.generate().", "author": "yxia92", "createdAt": "2020-02-06T01:24:55Z", "path": "hbase_sql/src/main/java/com/splicemachine/derby/lifecycle/CostChoosingDataSetProcessorFactory.java", "diffHunk": "@@ -75,23 +77,10 @@ public DataSetProcessor chooseProcessor(@Nullable Activation activation,@Nullabl\n         if (op.isOlapServer())\n             return new SparkDataSetProcessor();\n \n-        switch(activation.getLanguageConnectionContext().getDataSetProcessorType()){\n-            case FORCED_CONTROL:\n-                return new ControlDataSetProcessor(driver.getTxnSupplier(), driver.getTransactor(), driver.getOperationFactory());\n-            case FORCED_SPARK:\n-                return new SparkDataSetProcessor();\n-            default:\n-                break;\n-        }\n-        switch (((BaseActivation)activation).datasetProcessorType()) {\n-            case FORCED_SPARK:\n-            case SPARK:\n-                return new SparkDataSetProcessor();\n-            case FORCED_CONTROL:\n-                return new ControlDataSetProcessor(driver.getTxnSupplier(), driver.getTransactor(), driver.getOperationFactory());\n-            case DEFAULT_CONTROL:\n-            default:\n-                return new ControlDataSetProcessor(driver.getTxnSupplier(), driver.getTransactor(), driver.getOperationFactory());\n+        if (((BaseActivation)activation).datasetProcessorType().isSpark()) {", "originalCommit": "feaa5c85ae7a720e370a09394e711e11dbb0544c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTc1MjM4MQ==", "url": "https://github.com/splicemachine/spliceengine/pull/3153#discussion_r375752381", "bodyText": "Better yet, we can remove all particular calls to ActivationClassBuilder.setDataSetProcessorType() (since they were all the same) and call it only once after the creation of ActivationClassBuilder. As we now set compilerContext.dataSetProcessorType in stone during opt phase, that will suffice.\nThanks for catching this!", "author": "arnaud-splice", "createdAt": "2020-02-06T10:25:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5ODQzMw=="}], "type": "inlineReview"}, {"oid": "278058918637ea85d89e4c1e51f01deb588d4d06", "url": "https://github.com/splicemachine/spliceengine/commit/278058918637ea85d89e4c1e51f01deb588d4d06", "message": "DB-9057 Address review comments", "committedDate": "2020-02-06T11:05:05Z", "type": "commit"}, {"oid": "a588914332ca787a0ddd336d8ea8bf44e39a8534", "url": "https://github.com/splicemachine/spliceengine/commit/a588914332ca787a0ddd336d8ea8bf44e39a8534", "message": "Merge branch 'master' into DB-9057", "committedDate": "2020-02-06T11:09:56Z", "type": "commit"}]}