{"pr_number": 330, "pr_title": "Adding Cache RCAs to Analysis Graph, using cache max size from Node Config Cache and minor fixes", "pr_createdAt": "2020-08-01T02:48:47Z", "pr_url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330", "timeline": [{"oid": "5bccfc0641356540d5f1e63aed761514e36d5ba7", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/5bccfc0641356540d5f1e63aed761514e36d5ba7", "message": "Adding FieldDataCacheRCA to ElasticSearchAnalysisGraph", "committedDate": "2020-07-29T03:13:20Z", "type": "commit"}, {"oid": "039a843da894f2bfd6fd5f3564b153f51e254200", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/039a843da894f2bfd6fd5f3564b153f51e254200", "message": "Squashed commit of the following:\n\ncommit d61da520ef806b34b5f27506a9b517862ea57566\nAuthor: Joydeep Sinha <49728262+yojs@users.noreply.github.com>\nDate:   Tue Jul 28 18:46:08 2020 -0700\n\n    Grpc server can run on different ports on different nodes of the cluster (#310)\n\n    * Introducing grpcPort in the InstanceDetail and NodeDetail\n\n    * Addressing PR comments\n\n    * Fixing SpotBug errors\n\n    * adding some tests to increase coverage\n\n    * Adding a new test targetting multiple NetServers\n\n    * rebased with latest master and added a test that talks to grpc server on a different port", "committedDate": "2020-07-29T03:14:37Z", "type": "commit"}, {"oid": "0dd56fc84016b09dbeecdec4079b8590d806941a", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/0dd56fc84016b09dbeecdec4079b8590d806941a", "message": "Fixing the UTs post the Config Cache Change", "committedDate": "2020-07-29T05:12:18Z", "type": "commit"}, {"oid": "409708432270391cc23fe8ac44a2d5541d008e65", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/409708432270391cc23fe8ac44a2d5541d008e65", "message": "Fixing the bugs in Cache RCA and adding the RCAs to Analysis Graph", "committedDate": "2020-07-31T08:12:31Z", "type": "commit"}, {"oid": "0344bf5f48b1d5f2fcfc54219219197557ed2de6", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/0344bf5f48b1d5f2fcfc54219219197557ed2de6", "message": "Merging the changes from master", "committedDate": "2020-07-31T08:14:50Z", "type": "commit"}, {"oid": "2bd1558ffd811bf32bda3b1d9ba87ad005b37eeb", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/2bd1558ffd811bf32bda3b1d9ba87ad005b37eeb", "message": "Fixing merge failure", "committedDate": "2020-07-31T08:24:06Z", "type": "commit"}, {"oid": "68dfbd34b8a94871cbd5f1ba55ecd50b0c29f52f", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/68dfbd34b8a94871cbd5f1ba55ecd50b0c29f52f", "message": "Enabling the Cache RCAs to be queryable via RCA APIs", "committedDate": "2020-08-01T02:24:06Z", "type": "commit"}, {"oid": "28fb5a265ba83e61b2d57a5e048e4e4e16823c0a", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/28fb5a265ba83e61b2d57a5e048e4e4e16823c0a", "message": "Merge branch 'master' into khushbr-cache-rca", "committedDate": "2020-08-01T02:30:12Z", "type": "commit"}, {"oid": "19e1e06072b73b682464350bac73b42f59d1165e", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/19e1e06072b73b682464350bac73b42f59d1165e", "message": "Undoing one of the merge Test change", "committedDate": "2020-08-01T02:44:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyNjM3OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464526379", "bodyText": "Can any of these Record values be NaN?", "author": "vigyasharma", "createdAt": "2020-08-03T16:33:30Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -15,44 +15,64 @@\n \n package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n \n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.AppContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cluster.NodeKey;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n \n public class CacheUtil {\n     private static final Logger LOG = LogManager.getLogger(CacheUtil.class);\n \n     public static Double getTotalSizeInKB(final Metric cacheSizeGroupByOperation) {\n-        double sizeTotalInKB = 0;\n+        double totalSizeInKB = 0;\n \n         if (cacheSizeGroupByOperation.getFlowUnits().size() > 0) {\n             // we expect the Metric to have single flow unit since it is consumed locally\n             MetricFlowUnit flowUnit = cacheSizeGroupByOperation.getFlowUnits().get(0);\n             if (flowUnit.isEmpty() || flowUnit.getData() == null) {\n-                return sizeTotalInKB;\n+                return totalSizeInKB;\n             }\n \n-            // since the flow unit data is aggregated, we should have a single value\n+            // since the flow unit data is aggregated by index, summing the size across indices\n             if (flowUnit.getData().size() > 0) {\n-                double size = flowUnit.getData().get(0).getValue(MetricsDB.SUM, Double.class);\n-                if (Double.isNaN(size)) {\n-                    LOG.error(\"Failed to parse metric in FlowUnit from {}\", cacheSizeGroupByOperation.getClass().getName());\n-                } else {\n-                    sizeTotalInKB += size / 1024.0;\n-                }\n+                Result<Record> records = flowUnit.getData();\n+                double size = records.stream().mapToDouble(\n+                        record -> record.getValue(MetricsDB.SUM, Double.class)).sum();", "originalCommit": "19e1e06072b73b682464350bac73b42f59d1165e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDY1NTAwNg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464655006", "bodyText": "Yes, they can be NaN.\nAdded to throw IllegalArgumentException in case totalSizeInKB is NaN.", "author": "khushbr", "createdAt": "2020-08-03T20:50:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyNjM3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyNzYzOQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464527639", "bodyText": "Can we throw an exception here instead? I try to avoid overloading return values with error codes in java. Off the top of my head, if cache size ever is less than 1KB, we cannot distinguish between that and error values.", "author": "vigyasharma", "createdAt": "2020-08-03T16:35:51Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -15,44 +15,64 @@\n \n package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n \n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.AppContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cluster.NodeKey;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n \n public class CacheUtil {\n     private static final Logger LOG = LogManager.getLogger(CacheUtil.class);\n \n     public static Double getTotalSizeInKB(final Metric cacheSizeGroupByOperation) {\n-        double sizeTotalInKB = 0;\n+        double totalSizeInKB = 0;\n \n         if (cacheSizeGroupByOperation.getFlowUnits().size() > 0) {\n             // we expect the Metric to have single flow unit since it is consumed locally\n             MetricFlowUnit flowUnit = cacheSizeGroupByOperation.getFlowUnits().get(0);\n             if (flowUnit.isEmpty() || flowUnit.getData() == null) {\n-                return sizeTotalInKB;\n+                return totalSizeInKB;\n             }\n \n-            // since the flow unit data is aggregated, we should have a single value\n+            // since the flow unit data is aggregated by index, summing the size across indices\n             if (flowUnit.getData().size() > 0) {\n-                double size = flowUnit.getData().get(0).getValue(MetricsDB.SUM, Double.class);\n-                if (Double.isNaN(size)) {\n-                    LOG.error(\"Failed to parse metric in FlowUnit from {}\", cacheSizeGroupByOperation.getClass().getName());\n-                } else {\n-                    sizeTotalInKB += size / 1024.0;\n-                }\n+                Result<Record> records = flowUnit.getData();\n+                double size = records.stream().mapToDouble(\n+                        record -> record.getValue(MetricsDB.SUM, Double.class)).sum();\n+                totalSizeInKB += getSizeInKB(size);\n             }\n         }\n-        return sizeTotalInKB;\n+        return totalSizeInKB;\n+    }\n+\n+    public static Double getSizeInKB(double sizeinBytes) {\n+        double sizeInKB = 0;\n+        if (Double.isNaN(sizeinBytes)) {\n+            LOG.error(\"getSizeInKB called with NaN value\");", "originalCommit": "19e1e06072b73b682464350bac73b42f59d1165e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDY0ODc4NQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464648785", "bodyText": "Makes sense, updating to throw exception here.", "author": "khushbr", "createdAt": "2020-08-03T20:37:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyNzYzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyODk2OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464528969", "bodyText": "Again, why don't we just throw the exception and let callers handle it their way. If we want to prevent it from breaking code, we should throw a checked exception here.", "author": "vigyasharma", "createdAt": "2020-08-03T16:38:10Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -15,44 +15,64 @@\n \n package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n \n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.AppContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cluster.NodeKey;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n \n public class CacheUtil {\n     private static final Logger LOG = LogManager.getLogger(CacheUtil.class);\n \n     public static Double getTotalSizeInKB(final Metric cacheSizeGroupByOperation) {\n-        double sizeTotalInKB = 0;\n+        double totalSizeInKB = 0;\n \n         if (cacheSizeGroupByOperation.getFlowUnits().size() > 0) {\n             // we expect the Metric to have single flow unit since it is consumed locally\n             MetricFlowUnit flowUnit = cacheSizeGroupByOperation.getFlowUnits().get(0);\n             if (flowUnit.isEmpty() || flowUnit.getData() == null) {\n-                return sizeTotalInKB;\n+                return totalSizeInKB;\n             }\n \n-            // since the flow unit data is aggregated, we should have a single value\n+            // since the flow unit data is aggregated by index, summing the size across indices\n             if (flowUnit.getData().size() > 0) {\n-                double size = flowUnit.getData().get(0).getValue(MetricsDB.SUM, Double.class);\n-                if (Double.isNaN(size)) {\n-                    LOG.error(\"Failed to parse metric in FlowUnit from {}\", cacheSizeGroupByOperation.getClass().getName());\n-                } else {\n-                    sizeTotalInKB += size / 1024.0;\n-                }\n+                Result<Record> records = flowUnit.getData();\n+                double size = records.stream().mapToDouble(\n+                        record -> record.getValue(MetricsDB.SUM, Double.class)).sum();\n+                totalSizeInKB += getSizeInKB(size);\n             }\n         }\n-        return sizeTotalInKB;\n+        return totalSizeInKB;\n+    }\n+\n+    public static Double getSizeInKB(double sizeinBytes) {\n+        double sizeInKB = 0;\n+        if (Double.isNaN(sizeinBytes)) {\n+            LOG.error(\"getSizeInKB called with NaN value\");\n+        } else {\n+            sizeInKB = sizeinBytes / 1024.0;\n+        }\n+        return sizeInKB;\n+    }\n+\n+    public static double getCacheMaxSize(AppContext appContext, NodeKey esNode, Resource cacheResource) {\n+        try {\n+            return appContext.getNodeConfigCache().get(esNode, cacheResource);", "originalCommit": "19e1e06072b73b682464350bac73b42f59d1165e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDY0MjYwNw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464642607", "bodyText": "We will run into IllegalArgumentException in case the cacheResource is not present for the given esNode in the Cache Config. This behavior is common to only the first run post the RCA enable since the cache hasn't been formed yet\nThus, rather than throwing an exception, we are just logging(added now) that the expected resource is currently not available.", "author": "khushbr", "createdAt": "2020-08-03T20:24:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyODk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3ODM0MA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464578340", "bodyText": "shardRequestCacheNodeRca needs to be connected to shardRequestCacheEvictions leaf node as well right?\nArrays.asList(All the metrics this node is consuming)?", "author": "sruti1312", "createdAt": "2020-08-03T18:07:18Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/ElasticSearchAnalysisGraph.java", "diffHunk": "@@ -203,6 +212,58 @@ public void construct() {\n     nodeConfigClusterCollector.addAllUpstreams(Collections.singletonList(nodeConfigCollector));\n     nodeConfigClusterCollector.addTag(TAG_AGGREGATE_UPSTREAM, LOCUS_DATA_NODE);\n \n+    // Field Data Cache RCA\n+    Metric fieldDataCacheEvictions = new Cache_FieldData_Eviction(EVALUATION_INTERVAL_SECONDS);\n+    fieldDataCacheEvictions.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    addLeaf(fieldDataCacheEvictions);\n+\n+    Metric fieldDataCacheSizeGroupByOperation = new AggregateMetric(EVALUATION_INTERVAL_SECONDS,\n+            Cache_FieldData_Size.NAME,\n+            AggregateFunction.SUM,\n+            MetricsDB.MAX, ShardStatsDerivedDimension.INDEX_NAME.toString());\n+    fieldDataCacheSizeGroupByOperation.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    addLeaf(fieldDataCacheSizeGroupByOperation);\n+\n+    FieldDataCacheRca fieldDataCacheNodeRca = new FieldDataCacheRca(RCA_PERIOD,\n+            fieldDataCacheEvictions,\n+            fieldDataCacheSizeGroupByOperation);\n+    fieldDataCacheNodeRca.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    fieldDataCacheNodeRca.addAllUpstreams(Collections.singletonList(fieldDataCacheEvictions));\n+\n+    FieldDataCacheClusterRca fieldDataCacheClusterRca = new FieldDataCacheClusterRca(RCA_PERIOD, fieldDataCacheNodeRca);\n+    fieldDataCacheClusterRca.addTag(TAG_LOCUS, LOCUS_MASTER_NODE);\n+    fieldDataCacheClusterRca.addAllUpstreams(Collections.singletonList(fieldDataCacheNodeRca));\n+    fieldDataCacheClusterRca.addTag(TAG_AGGREGATE_UPSTREAM, LOCUS_DATA_NODE);\n+\n+    // Shard Request Cache RCA\n+    Metric shardRequestCacheEvictions = new Cache_Request_Eviction(EVALUATION_INTERVAL_SECONDS);\n+    shardRequestCacheEvictions.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    addLeaf(shardRequestCacheEvictions);\n+    Metric shardRequestHits = new Cache_Request_Hit(EVALUATION_INTERVAL_SECONDS);\n+    shardRequestHits.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    addLeaf(shardRequestHits);\n+\n+    Metric shardRequestCacheSizeGroupByOperation = new AggregateMetric(EVALUATION_INTERVAL_SECONDS,\n+            Cache_Request_Size.NAME,\n+            AggregateFunction.SUM,\n+            MetricsDB.MAX, ShardStatsDerivedDimension.INDEX_NAME.toString());\n+    shardRequestCacheSizeGroupByOperation.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    addLeaf(shardRequestCacheSizeGroupByOperation);\n+\n+    ShardRequestCacheRca shardRequestCacheNodeRca = new ShardRequestCacheRca(RCA_PERIOD,\n+            shardRequestCacheEvictions,\n+            shardRequestHits,\n+            shardRequestCacheSizeGroupByOperation);\n+    shardRequestCacheNodeRca.addTag(TAG_LOCUS, LOCUS_DATA_MASTER_NODE);\n+    shardRequestCacheNodeRca.addAllUpstreams(Collections.singletonList(shardRequestHits));", "originalCommit": "19e1e06072b73b682464350bac73b42f59d1165e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU4MTQ3OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464581479", "bodyText": "Thank You for catching this issue, we need to add remainder metrics as well.  Adding them.", "author": "khushbr", "createdAt": "2020-08-03T18:13:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3ODM0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYzODI4NQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/330#discussion_r464638285", "bodyText": "Fixed both FieldDataCacheRca and ShardRequestCacheRca", "author": "khushbr", "createdAt": "2020-08-03T20:14:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU3ODM0MA=="}], "type": "inlineReview"}, {"oid": "57eefa54263091d4da009a33e25fa9eb1ff9c362", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/57eefa54263091d4da009a33e25fa9eb1ff9c362", "message": "Addressing the PR comments:", "committedDate": "2020-08-03T21:26:24Z", "type": "commit"}]}