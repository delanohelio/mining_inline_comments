{"pr_number": 3408, "pr_title": "[MO] - [dyn.conf] -> system tests", "pr_createdAt": "2020-07-29T11:23:16Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3MDI1MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r462570250", "bodyText": "Wouldn't it be better to make some variable for this? Because you use it in AssertionError too.", "author": "im-konge", "createdAt": "2020-07-29T20:31:37Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +153,47 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration.toString(), value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateConfigurationWithStabilityWait(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, which encapsulates the update phase of dyn. configuration + verifying that updating configuration were successfully done\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void verifyDynamicConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaUtils.updateConfigurationWithStabilityWait(clusterName, kafkaDynamicConfiguration, value);\n+\n+        boolean result = KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration.toString()) == value;", "originalCommit": "95e0f621c7e649132ed6849083368832adb6970a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjgzODg1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r462838853", "bodyText": "It was not a good approach on how to verify I have changed the it....", "author": "see-quick", "createdAt": "2020-07-30T08:34:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3MDI1MA=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 767abab48..d5b94d917 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -160,11 +161,11 @@ public class KafkaUtils {\n      * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration.toString(), value);\n+            config.put(kafkaDynamicConfiguration, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3MDU4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r462570582", "bodyText": "To the variable I mentioned above (just as note)", "author": "im-konge", "createdAt": "2020-07-29T20:32:13Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +153,47 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration.toString(), value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateConfigurationWithStabilityWait(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, which encapsulates the update phase of dyn. configuration + verifying that updating configuration were successfully done\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void verifyDynamicConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaUtils.updateConfigurationWithStabilityWait(clusterName, kafkaDynamicConfiguration, value);\n+\n+        boolean result = KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration.toString()) == value;\n+\n+        if (!result) {\n+            throw new AssertionError(KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration.toString() + \" value doesn't match to expected value \" + value));", "originalCommit": "95e0f621c7e649132ed6849083368832adb6970a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 767abab48..d5b94d917 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -160,11 +161,11 @@ public class KafkaUtils {\n      * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration.toString(), value);\n+            config.put(kafkaDynamicConfiguration, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3Mzc0Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r462573746", "bodyText": "Just thinking -> is this encapsulation needed? I know the code is cleaner, but I don't know if this is worth for these two lines.\nAnyway the KafkaUtils is not needed.", "author": "im-konge", "createdAt": "2020-07-29T20:38:13Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +153,47 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration.toString(), value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateConfigurationWithStabilityWait(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, which encapsulates the update phase of dyn. configuration + verifying that updating configuration were successfully done\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void verifyDynamicConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaUtils.updateConfigurationWithStabilityWait(clusterName, kafkaDynamicConfiguration, value);", "originalCommit": "95e0f621c7e649132ed6849083368832adb6970a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk5MDAyMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r462990021", "bodyText": "I have split these 2...", "author": "see-quick", "createdAt": "2020-07-30T13:19:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3Mzc0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 767abab48..d5b94d917 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -160,11 +161,11 @@ public class KafkaUtils {\n      * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration.toString(), value);\n+            config.put(kafkaDynamicConfiguration, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4NjQ4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463186489", "bodyText": "KafkaDynamicConfiguration? typo?", "author": "scholzj", "createdAt": "2020-07-30T18:21:14Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.enums;\n+\n+/**\n+ * KafkaConfiguration enum class, which provides all supported configuration, which does not need to trigger rolling-update (dynamic configuration)", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java b/systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java\ndeleted file mode 100644\nindex bf5c3bd8e..000000000\n--- a/systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java\n+++ /dev/null\n\n@@ -1,58 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.enums;\n-\n-/**\n- * KafkaConfiguration enum class, which provides all supported configuration, which does not need to trigger rolling-update (dynamic configuration)\n- */\n-public enum KafkaDynamicConfiguration {\n-\n-    background_threads,\n-    compression_type,\n-    min_insync_replicas,\n-    unclean_leader_election_enable,\n-    message_max_bytes,\n-    metric_reporters,\n-\n-    log_flush_interval_messages,\n-    log_flush_interval_ms,\n-    log_retention_bytes,\n-    log_retention_ms,\n-    log_roll_jitter_ms,\n-    log_roll_ms,\n-    log_segment_bytes,\n-    log_segment_delete_delay_ms,\n-    log_cleaner_backoff_ms,\n-    log_cleaner_dedupe_buffer_size,\n-    log_cleaner_delete_retention_ms,\n-    log_cleaner_io_buffer_load_factor,\n-    log_cleaner_io_buffer_size,\n-    log_cleaner_io_max_bytes_per_second,\n-    log_cleaner_max_compaction_lag_ms,\n-    log_cleaner_min_cleanable_ratio,\n-    log_cleaner_min_compaction_lag_ms,\n-    log_cleaner_threads,\n-    log_cleanup_policy,\n-    log_index_interval_bytes,\n-    log_index_size_max_bytes,\n-    log_message_timestamp_difference_max_ms,\n-    log_message_timestamp_type,\n-    log_message_downconversion_enable,\n-    log_preallocate,\n-\n-    num_io_threads,\n-    num_network_threads,\n-    num_recovery_threads_per_data_dir,\n-    num_replica_fetchers,\n-\n-    max_connections,\n-    max_connections_per_ip,\n-    max_connections_per_ip_overrides;\n-\n-    @Override\n-    public String toString() {\n-        return this.name().replaceAll(\"_\", \".\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4NzcxOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463187718", "bodyText": "What is the source of these? I'm a bit in doubt about this. If it is so important that we have to test every single of these values, then this should be probably autogenerated from the Kafka sources and needs to also distinguish and test it for all Kafka versions.", "author": "scholzj", "createdAt": "2020-07-30T18:23:29Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.enums;\n+\n+/**\n+ * KafkaConfiguration enum class, which provides all supported configuration, which does not need to trigger rolling-update (dynamic configuration)\n+ */\n+public enum KafkaDynamicConfiguration {\n+\n+    background_threads,\n+    compression_type,\n+    min_insync_replicas,\n+    unclean_leader_election_enable,\n+    message_max_bytes,\n+    metric_reporters,\n+\n+    log_flush_interval_messages,\n+    log_flush_interval_ms,\n+    log_retention_bytes,\n+    log_retention_ms,\n+    log_roll_jitter_ms,\n+    log_roll_ms,\n+    log_segment_bytes,\n+    log_segment_delete_delay_ms,\n+    log_cleaner_backoff_ms,\n+    log_cleaner_dedupe_buffer_size,\n+    log_cleaner_delete_retention_ms,\n+    log_cleaner_io_buffer_load_factor,\n+    log_cleaner_io_buffer_size,\n+    log_cleaner_io_max_bytes_per_second,\n+    log_cleaner_max_compaction_lag_ms,\n+    log_cleaner_min_cleanable_ratio,\n+    log_cleaner_min_compaction_lag_ms,\n+    log_cleaner_threads,\n+    log_cleanup_policy,\n+    log_index_interval_bytes,\n+    log_index_size_max_bytes,\n+    log_message_timestamp_difference_max_ms,\n+    log_message_timestamp_type,\n+    log_message_downconversion_enable,\n+    log_preallocate,\n+\n+    num_io_threads,\n+    num_network_threads,\n+    num_recovery_threads_per_data_dir,\n+    num_replica_fetchers,\n+\n+    max_connections,\n+    max_connections_per_ip,\n+    max_connections_per_ip_overrides;", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0MzM4OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463443388", "bodyText": "I think it's just sample from all configuration options which Kafka offers. but I am not sure.", "author": "Frawless", "createdAt": "2020-07-31T07:12:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4NzcxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3MzI5OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464273299", "bodyText": "Yes this is all Kafka configuration, which can by changed without triggering rolling update.", "author": "see-quick", "createdAt": "2020-08-03T08:40:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4NzcxOA=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java b/systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java\ndeleted file mode 100644\nindex bf5c3bd8e..000000000\n--- a/systemtest/src/main/java/io/strimzi/systemtest/enums/KafkaDynamicConfiguration.java\n+++ /dev/null\n\n@@ -1,58 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.enums;\n-\n-/**\n- * KafkaConfiguration enum class, which provides all supported configuration, which does not need to trigger rolling-update (dynamic configuration)\n- */\n-public enum KafkaDynamicConfiguration {\n-\n-    background_threads,\n-    compression_type,\n-    min_insync_replicas,\n-    unclean_leader_election_enable,\n-    message_max_bytes,\n-    metric_reporters,\n-\n-    log_flush_interval_messages,\n-    log_flush_interval_ms,\n-    log_retention_bytes,\n-    log_retention_ms,\n-    log_roll_jitter_ms,\n-    log_roll_ms,\n-    log_segment_bytes,\n-    log_segment_delete_delay_ms,\n-    log_cleaner_backoff_ms,\n-    log_cleaner_dedupe_buffer_size,\n-    log_cleaner_delete_retention_ms,\n-    log_cleaner_io_buffer_load_factor,\n-    log_cleaner_io_buffer_size,\n-    log_cleaner_io_max_bytes_per_second,\n-    log_cleaner_max_compaction_lag_ms,\n-    log_cleaner_min_cleanable_ratio,\n-    log_cleaner_min_compaction_lag_ms,\n-    log_cleaner_threads,\n-    log_cleanup_policy,\n-    log_index_interval_bytes,\n-    log_index_size_max_bytes,\n-    log_message_timestamp_difference_max_ms,\n-    log_message_timestamp_type,\n-    log_message_downconversion_enable,\n-    log_preallocate,\n-\n-    num_io_threads,\n-    num_network_threads,\n-    num_recovery_threads_per_data_dir,\n-    num_replica_fetchers,\n-\n-    max_connections,\n-    max_connections_per_ip,\n-    max_connections_per_ip_overrides;\n-\n-    @Override\n-    public String toString() {\n-        return this.name().replaceAll(\"_\", \".\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4OTU5OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463189599", "bodyText": "The unclean.leader.election.enable should show up here as well. So maybe you can assert it too?", "author": "scholzj", "createdAt": "2020-07-30T18:26:46Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4OTk4Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463189987", "bodyText": "Is this some copy paster left-over? Or what is the value of this?", "author": "scholzj", "createdAt": "2020-07-30T18:27:29Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3NDEyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464274122", "bodyText": "These DynamicConfigurationIsolatedST are the Standa`s tests, which were located in the KafkaST. @stanlyDoge", "author": "see-quick", "createdAt": "2020-08-03T08:42:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE4OTk4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MTQxOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463191418", "bodyText": "Using both node port and loadbalancer in the same test will mean that it works only in environment which supports both. Can't we find some listener change which is less restrictive to the environment where you run this? For example use only node ports and change advertised hostnames?", "author": "scholzj", "createdAt": "2020-07-30T18:30:07Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);\n+    }\n+\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        int kafkaReplicas = 2;\n+        int zkReplicas = 1;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalLoadBalancer()\n+                        .endKafkaListenerExternalLoadBalancer()\n+                        .withNewPlain()\n+                        .endPlain()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+                .endSpec()\n+                .done();\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MjMyNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463192324", "bodyText": "A very long test which seems a bit complicated. Having a comment properly explaining what it does would be helpful.", "author": "scholzj", "createdAt": "2020-07-30T18:31:44Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);\n+    }\n+\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDI3NzU4NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464277585", "bodyText": "I did not write these tests (just copy-paste) but I will split him if it will be possible.", "author": "see-quick", "createdAt": "2020-08-03T08:48:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MjMyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgzNDAxOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464834018", "bodyText": "The idea behind this test was to perform as many as possible changes in listeners. I agree the test is complicated and the environmental restrictions suck. Splitting test to smaller bits (one listener, one test) seem like a good idea.", "author": "sknot-rh", "createdAt": "2020-08-04T06:45:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MjMyNA=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MjY0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463192644", "bodyText": "You seem to be doing rolling updates. Please use persistent cluster.", "author": "scholzj", "createdAt": "2020-07-30T18:32:27Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);\n+    }\n+\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        int kafkaReplicas = 2;\n+        int zkReplicas = 1;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, zkReplicas)", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5Mjk3MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463192971", "bodyText": "Again ... can we find something less restrictive than both load balancers and node ports? Also, should these tags be on the text above as well?", "author": "scholzj", "createdAt": "2020-07-30T18:33:11Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);\n+    }\n+\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        int kafkaReplicas = 2;\n+        int zkReplicas = 1;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalLoadBalancer()\n+                        .endKafkaListenerExternalLoadBalancer()\n+                        .withNewPlain()\n+                        .endPlain()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+                .endSpec()\n+                .done();\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=false\"));\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MzY0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463193640", "bodyText": "Are you saying that the change here doesn't trigger RU?", "author": "scholzj", "createdAt": "2020-07-30T18:34:26Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);\n+    }\n+\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        int kafkaReplicas = 2;\n+        int zkReplicas = 1;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalLoadBalancer()\n+                        .endKafkaListenerExternalLoadBalancer()\n+                        .withNewPlain()\n+                        .endPlain()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+                .endSpec()\n+                .done();\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=false\"));\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewListeners()\n+                            .withNewKafkaListenerExternalLoadBalancer()\n+                                .withTls(false)\n+                            .endKafkaListenerExternalLoadBalancer()\n+                        .endListeners()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientTls = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(USER_NAME)\n+            .withConsumerGroupName(CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE))\n+            .withSecurityProtocol(SecurityProtocol.SSL)\n+            .build();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientPlain = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withConsumerGroupName(CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE))\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .build();\n+\n+        String userName = \"john\";\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();\n+\n+        basicExternalKafkaClientTls.setKafkaUsername(userName);\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withNewKafkaListenerAuthenticationTlsAuth()\n+                        .endKafkaListenerAuthenticationTlsAuth()\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDk5NjAyOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464996028", "bodyText": "This should trigger a rolling update! Using method verifyThatRunningPodsAreStable is not a good practice here (again I did write these tests :D) and I have replaced it with the snapShot waitTillSsHasRolled.", "author": "see-quick", "createdAt": "2020-08-04T11:55:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5MzY0MA=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5NDcxNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463194717", "bodyText": "Hmm, I thought that this would be a bit more dynamically generated. This will be very expensive to maintain.", "author": "scholzj", "createdAt": "2020-07-30T18:36:26Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.enums.KafkaDynamicConfiguration;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Arrays;\n+\n+import static io.strimzi.systemtest.Constants.ACCEPTANCE;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class DynamicConfigurationSharedST extends AbstractST {", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ1MjgzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463452836", "bodyText": "Ye, I suggest to use https://junit.org/junit5/docs/current/user-guide/#writing-tests-parameterized-tests or https://junit.org/junit5/docs/current/user-guide/#writing-tests-dynamic-tests", "author": "Frawless", "createdAt": "2020-07-31T07:36:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5NDcxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDk1MjM2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464952361", "bodyText": "Done", "author": "see-quick", "createdAt": "2020-08-04T10:24:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzE5NDcxNw=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\nindex 9444a5b20..461b9b89b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n\n@@ -6,7 +6,6 @@ package io.strimzi.systemtest.dynamicconfiguration;\n \n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.systemtest.AbstractST;\n-import io.strimzi.systemtest.enums.KafkaDynamicConfiguration;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0Mzg5Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463443896", "bodyText": "How the output of this log looks? It's formated to be easily readable ?", "author": "Frawless", "createdAt": "2020-07-31T07:13:35Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +154,75 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDk4NTI3OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464985279", "bodyText": "Yes :)", "author": "see-quick", "createdAt": "2020-08-04T11:34:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0Mzg5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex fcca5b948..d5b94d917 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -161,11 +161,11 @@ public class KafkaUtils {\n      * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration.toString(), value);\n+            config.put(kafkaDynamicConfiguration, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0NDQwMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463444400", "bodyText": "Maybe we should show dyn.configuration in case of error as well?", "author": "Frawless", "createdAt": "2020-07-31T07:15:01Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +154,75 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration.toString(), value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateConfigurationWithStabilityWait(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, verifying that updating configuration were successfully changed inside Kafka CR\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            kafkaDynamicConfiguration.toString(),\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration.toString()),\n+            kafkaDynamicConfiguration.toString(),\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration.toString()).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+            LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+            if (!result.contains(kafkaDynamicConfiguration + \"=\" + value)) {\n+                LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), kafkaDynamicConfiguration.toString(), value);", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTAwMTcxMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r465001711", "bodyText": "?", "author": "see-quick", "createdAt": "2020-08-04T12:07:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0NDQwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTAwNDI1Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r465004252", "bodyText": "If the error occurs then we show the Kafka Pod {}....", "author": "see-quick", "createdAt": "2020-08-04T12:12:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0NDQwMA=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex fcca5b948..d5b94d917 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -161,11 +161,11 @@ public class KafkaUtils {\n      * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, KafkaDynamicConfiguration kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration.toString(), value);\n+            config.put(kafkaDynamicConfiguration, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ0NDY1NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463444654", "bodyText": "Why 2 brokers instead of 3?", "author": "Frawless", "createdAt": "2020-07-31T07:15:34Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ1MTQ1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463451451", "bodyText": "Are you sure we don't have similar test like this? Maybe in ListenersST or in rollingupdate ?", "author": "Frawless", "createdAt": "2020-07-31T07:32:33Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,374 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        int kafkaReplicas = 2;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, is(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"default.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.4\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPodsSnapshot);\n+    }\n+\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        int kafkaReplicas = 2;\n+        int zkReplicas = 1;\n+        Map<String, Object> kafkaConfig = new HashMap<>();\n+        kafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        kafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        kafkaConfig.put(\"default.replication.factor\", \"1\");\n+        kafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+\n+        Map<String, Object> updatedKafkaConfig = new HashMap<>();\n+        updatedKafkaConfig.put(\"offsets.topic.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"transaction.state.log.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"default.replication.factor\", \"1\");\n+        updatedKafkaConfig.put(\"log.message.format.version\", \"2.4\");\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, kafkaReplicas, zkReplicas)\n+                .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalLoadBalancer()\n+                        .endKafkaListenerExternalLoadBalancer()\n+                        .withNewPlain()\n+                        .endPlain()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+                .endSpec()\n+                .done();\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"false\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=false\"));\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+\n+        // change dynamically changeable option\n+        updatedKafkaConfig.put(\"unclean.leader.election.enable\", \"true\");\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating configuration of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setConfig(updatedKafkaConfig);\n+        });\n+\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(false));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=true\"));\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 932ecfd55..a4d75b43b 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -17,12 +17,14 @@ import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n import org.junit.jupiter.api.Tag;\n import org.junit.jupiter.api.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ1MzAxMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r463453011", "bodyText": "Indent", "author": "Frawless", "createdAt": "2020-07-31T07:36:32Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java", "diffHunk": "@@ -1534,332 +1524,18 @@ void testKafkaOffsetsReplicationFactorHigherThanReplicas() {\n         int replicas = 3;\n         Kafka kafka = KafkaResource.kafkaWithoutWait(KafkaResource.defaultKafka(CLUSTER_NAME, replicas, 1)\n             .editSpec()\n-                .editKafka()\n-                    .addToConfig(\"offsets.topic.replication.factor\", 4)\n-                    .addToConfig(\"transaction.state.log.min.isr\", 4)\n-                    .addToConfig(\"transaction.state.log.replication.factor\", 4)\n-                .endKafka()\n+            .editKafka()", "originalCommit": "d2b6a98e958649fdc656a2032c6c8a42f3923eca", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDk4NzQ5MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r464987490", "bodyText": "Always fun! :D", "author": "see-quick", "createdAt": "2020-08-04T11:38:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ1MzAxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java b/systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java\nindex e2051b074..27171681c 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java\n\n@@ -1524,11 +1524,11 @@ class KafkaST extends AbstractST {\n         int replicas = 3;\n         Kafka kafka = KafkaResource.kafkaWithoutWait(KafkaResource.defaultKafka(CLUSTER_NAME, replicas, 1)\n             .editSpec()\n-            .editKafka()\n-            .addToConfig(\"offsets.topic.replication.factor\", 4)\n-            .addToConfig(\"transaction.state.log.min.isr\", 4)\n-            .addToConfig(\"transaction.state.log.replication.factor\", 4)\n-            .endKafka()\n+                .editKafka()\n+                    .addToConfig(\"offsets.topic.replication.factor\", 4)\n+                    .addToConfig(\"transaction.state.log.min.isr\", 4)\n+                    .addToConfig(\"transaction.state.log.replication.factor\", 4)\n+                .endKafka()\n             .endSpec().build());\n \n         KafkaUtils.waitUntilKafkaStatusConditionContainsMessage(CLUSTER_NAME, NAMESPACE,\n"}}, {"oid": "277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/277b305b0db5eb6b9d0d93d0840e91a974b15d3f", "message": "indent/\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-04T11:47:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI3MTEzNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r465271135", "bodyText": "Indent?", "author": "im-konge", "createdAt": "2020-08-04T19:14:07Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,297 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()", "originalCommit": "47c73e4bf8bad1b92721fd4b3cd76cac0013e601", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 51f61281b..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI3MjY0NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r465272645", "bodyText": "I think this is generated if you don't specify it. But maybe I'm wrong. (This is same for above code)", "author": "im-konge", "createdAt": "2020-08-04T19:17:01Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,297 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+    }\n+\n+    @Test\n+    @Tag(LOADBALANCER_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewListeners()\n+                            .withNewKafkaListenerExternalLoadBalancer()\n+                                .withTls(false)\n+                            .endKafkaListenerExternalLoadBalancer()\n+                        .endListeners()\n+                        .withConfig(kafkaConfig)\n+                    .endKafka()\n+                .endSpec()\n+                .done();\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientTls = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(USER_NAME)\n+            .withConsumerGroupName(CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE))\n+            .withSecurityProtocol(SecurityProtocol.SSL)\n+            .build();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientPlain = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withConsumerGroupName(CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE))", "originalCommit": "47c73e4bf8bad1b92721fd4b3cd76cac0013e601", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 51f61281b..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI3MzY4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r465273689", "bodyText": "This is little bit weird for me, I know what you want to say by that, but wouldn't it be better just like parametrizedTest? Maybe @samuel-hawker will be better for this \ud83d\ude04", "author": "im-konge", "createdAt": "2020-08-04T19:19:07Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.CsvSource;\n+\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationSharedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationSharedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-shared-cluster-test\";\n+\n+    @ParameterizedTest\n+    @CsvSource({\n+        \"background.threads, \" + 12,\n+\n+        \"compression.type,  snappy\",\n+        \"compression.type,  gzip\",\n+        \"compression.type,  lz4\",\n+        \"compression.type,  zstd\",\n+\n+        \"log.flush.interval.ms, \" + 20,\n+\n+        \"log.retention.ms,  \" + 20,\n+        \"log.retention.bytes, \" + 250,\n+\n+        \"log.segment.bytes,   \" + 1_100,\n+        \"log.segment.delete.delay.ms,  \" + 400,\n+\n+        \"log.roll.jitter.ms, \" + 500,\n+        \"log.roll.ms, \" + 300,\n+\n+        \"log.cleaner.dedupe.buffer.size, \" + 4_000_000,\n+        \"log.cleaner.delete.retention.ms, \" + 1_000,\n+        \"log.cleaner.io.buffer.load.factor, \" + 12,\n+        \"log.cleaner.io.buffer.size, \" + 10_000,\n+        \"log.cleaner.io.max.bytes.per.second, \" + 1.523,\n+        \"log.cleaner.max.compaction.lag.ms, \" + 32_000,\n+        \"log.cleaner.min.compaction.lag.ms, \" + 1_000,\n+        \"log.cleaner.threads, \" + 1,\n+\n+        \"num.network.threads, \" + 2,\n+        \"testLogIndexLogMessageLogMessage, \" + 5,\n+        \"log.message.timestamp.difference.max.ms, \" + 12_000,\n+        \"log.preallocate, \" + true,\n+\n+        \"max.connections, \" + 10,\n+        \"max.connections.per.ip, \" + 20,\n+\n+        \"unclean.leader.election.enable, \" + true,\n+        \"message.max.bytes, \" + 2048\n+    })\n+    void testParametrizedTest(String kafkaDynamicConfigurationKey, Object kafkaDynamicConfigurationValue) {", "originalCommit": "47c73e4bf8bad1b92721fd4b3cd76cac0013e601", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTU4NTkxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r465585915", "bodyText": "Already change the naming )", "author": "see-quick", "createdAt": "2020-08-05T09:11:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI3MzY4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\nindex 461b9b89b..6f0d5a76e 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n\n@@ -31,23 +31,17 @@ public class DynamicConfigurationSharedST extends AbstractST {\n     @ParameterizedTest\n     @CsvSource({\n         \"background.threads, \" + 12,\n-\n         \"compression.type,  snappy\",\n         \"compression.type,  gzip\",\n         \"compression.type,  lz4\",\n         \"compression.type,  zstd\",\n-\n         \"log.flush.interval.ms, \" + 20,\n-\n         \"log.retention.ms,  \" + 20,\n         \"log.retention.bytes, \" + 250,\n-\n         \"log.segment.bytes,   \" + 1_100,\n         \"log.segment.delete.delay.ms,  \" + 400,\n-\n         \"log.roll.jitter.ms, \" + 500,\n         \"log.roll.ms, \" + 300,\n-\n         \"log.cleaner.dedupe.buffer.size, \" + 4_000_000,\n         \"log.cleaner.delete.retention.ms, \" + 1_000,\n         \"log.cleaner.io.buffer.load.factor, \" + 12,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzODAyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466338023", "bodyText": "What enum?", "author": "tombentley", "createdAt": "2020-08-06T11:10:19Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +154,79 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM2MTgxOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466361819", "bodyText": "old code....i have changed it.", "author": "see-quick", "createdAt": "2020-08-06T12:00:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzODAyMw=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 3e57a1dc6..aad772f4d 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -158,14 +158,14 @@ public class KafkaUtils {\n     /**\n      * Method which, update/replace Kafka configuration\n      * @param clusterName name of the cluster where Kafka resource can be found\n-     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param brokerConfigName key of specific property\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration, value);\n+            config.put(brokerConfigName, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzODkzMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466338931", "bodyText": "For all these I would call it brokerConfigName or something. You don't care, in these methods whether the particular config supports dynamic update or not.", "author": "tombentley", "createdAt": "2020-08-06T11:12:22Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +154,79 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, verifying that updating configuration were successfully changed inside Kafka CR\n+     * @param kafkaDynamicConfiguration key of specific property", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 3e57a1dc6..aad772f4d 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -158,14 +158,14 @@ public class KafkaUtils {\n     /**\n      * Method which, update/replace Kafka configuration\n      * @param clusterName name of the cluster where Kafka resource can be found\n-     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param brokerConfigName key of specific property\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration, value);\n+            config.put(brokerConfigName, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzOTI3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466339278", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n          \n          \n            \n                 * Verifies that updated configuration was successfully changed inside Kafka pods", "author": "tombentley", "createdAt": "2020-08-06T11:13:07Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +154,79 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, verifying that updating configuration were successfully changed inside Kafka CR\n+     * @param kafkaDynamicConfiguration key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            kafkaDynamicConfiguration,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration),\n+            kafkaDynamicConfiguration,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 3e57a1dc6..aad772f4d 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -158,14 +158,14 @@ public class KafkaUtils {\n     /**\n      * Method which, update/replace Kafka configuration\n      * @param clusterName name of the cluster where Kafka resource can be found\n-     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param brokerConfigName key of specific property\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration, value);\n+            config.put(brokerConfigName, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzOTcyNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466339727", "bodyText": "Is there any reason for doing this via kafka-configs.sh and not just using an Admin client instance?", "author": "tombentley", "createdAt": "2020-08-06T11:14:12Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -151,4 +154,79 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(kafkaDynamicConfiguration, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param kafkaDynamicConfiguration key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        updateSpecificConfiguration(clusterName, kafkaDynamicConfiguration, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Method, verifying that updating configuration were successfully changed inside Kafka CR\n+     * @param kafkaDynamicConfiguration key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            kafkaDynamicConfiguration,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration),\n+            kafkaDynamicConfiguration,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(kafkaDynamicConfiguration).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param kafkaDynamicConfiguration key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String kafkaDynamicConfiguration, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM2OTEwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466369103", "bodyText": "AdminClient has one disadvantage. If we use him we need som external listener, which is not a good for run the tests in all envinronments.", "author": "see-quick", "createdAt": "2020-08-06T12:15:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjMzOTcyNw=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 3e57a1dc6..aad772f4d 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -158,14 +158,14 @@ public class KafkaUtils {\n     /**\n      * Method which, update/replace Kafka configuration\n      * @param clusterName name of the cluster where Kafka resource can be found\n-     * @param kafkaDynamicConfiguration enum instance, which defines all supported configurations\n+     * @param brokerConfigName key of specific property\n      * @param value value of specific property\n      */\n-    public static void updateSpecificConfiguration(String clusterName, String kafkaDynamicConfiguration, Object value) {\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n         KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n             LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n             Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n-            config.put(kafkaDynamicConfiguration, value);\n+            config.put(brokerConfigName, value);\n             kafka.getSpec().getKafka().setConfig(config);\n             LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n         });\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MDg0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466340844", "bodyText": "Why are you calling both like this?", "author": "tombentley", "createdAt": "2020-08-06T11:16:32Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+        updateAndVerifyDynConf(\"true\");", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM2NzI0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466367242", "bodyText": "This is just refactored tests, which just update the Dyn. configuration of the broker. The point is to make as many changes as possible. If I understand correctly from @stanlyDoge.", "author": "see-quick", "createdAt": "2020-08-06T12:12:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MDg0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM3NTc5OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466375799", "bodyText": "Yeah, as I understand the test this two lines set the same property (unclean.leader.election.enable) to false and then to true. We are checking at the end of the test, whether kafka pods rolled.\nI would consider changing another property.", "author": "sknot-rh", "createdAt": "2020-08-06T12:28:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MDg0NA=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MzY1OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466343658", "bodyText": "Is this a complete list? If not, how did you decide which to tests? How will we keep it up to date as more configs are added in new versions of Kafka?\nIt's not a problem for this PR, but I do think we really need, written down, a list of which configs can be changed dynamically and which not. It needs to be part of the docs, so users can have certainty that changing some particular configs will or won't result in a rolling restart. Because new configs get regularly added it needs to be generated from the code, rather than something which we maintain by hand. @stanlyDoge would you be able to do this?", "author": "tombentley", "createdAt": "2020-08-06T11:22:38Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.CsvSource;\n+\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationSharedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationSharedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-shared-cluster-test\";\n+\n+    @ParameterizedTest\n+    @CsvSource({\n+        \"background.threads, \" + 12,\n+        \"compression.type,  snappy\",\n+        \"compression.type,  gzip\",\n+        \"compression.type,  lz4\",\n+        \"compression.type,  zstd\",\n+        \"log.flush.interval.ms, \" + 20,\n+        \"log.retention.ms,  \" + 20,\n+        \"log.retention.bytes, \" + 250,\n+        \"log.segment.bytes,   \" + 1_100,\n+        \"log.segment.delete.delay.ms,  \" + 400,\n+        \"log.roll.jitter.ms, \" + 500,\n+        \"log.roll.ms, \" + 300,\n+        \"log.cleaner.dedupe.buffer.size, \" + 4_000_000,\n+        \"log.cleaner.delete.retention.ms, \" + 1_000,\n+        \"log.cleaner.io.buffer.load.factor, \" + 12,\n+        \"log.cleaner.io.buffer.size, \" + 10_000,\n+        \"log.cleaner.io.max.bytes.per.second, \" + 1.523,\n+        \"log.cleaner.max.compaction.lag.ms, \" + 32_000,\n+        \"log.cleaner.min.compaction.lag.ms, \" + 1_000,\n+        \"log.preallocate, \" + true,\n+        \"max.connections, \" + 10,\n+        \"max.connections.per.ip, \" + 20,\n+        \"unclean.leader.election.enable, \" + true,\n+        \"message.max.bytes, \" + 2048,", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM3MDgzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466370839", "bodyText": "It is an almost a complete list of Dyn. configuration. I picked randomly, which were not read-only and also which does not have this\n FORBIDDEN_PREFIXES = \"listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, authorizer., super.user, cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers;", "author": "see-quick", "createdAt": "2020-08-06T12:19:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MzY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM3MTY4Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466371686", "bodyText": "Hmmm, I can create a .csv files, which will bind to specific version :)", "author": "see-quick", "createdAt": "2020-08-06T12:20:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MzY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2NzUxMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r469367510", "bodyText": "No. You could include columns in the CSV defining the version range between which to test with that config, skipping versions outside that range. But the key point here is that to get complete coverage we need to automate this, which means not relying on an annotation to drive the values, but that generated file I described.", "author": "tombentley", "createdAt": "2020-08-12T15:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0MzY1OA=="}], "type": "inlineReview", "revised_code": {"commit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\ndeleted file mode 100644\nindex 6f0d5a76e..000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n+++ /dev/null\n\n@@ -1,75 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.dynamicconfiguration;\n-\n-import io.strimzi.api.kafka.model.KafkaResources;\n-import io.strimzi.systemtest.AbstractST;\n-import io.strimzi.systemtest.resources.ResourceManager;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.BeforeAll;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.params.ParameterizedTest;\n-import org.junit.jupiter.params.provider.CsvSource;\n-\n-import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-@Tag(DYNAMIC_CONFIGURATION)\n-public class DynamicConfigurationSharedST extends AbstractST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationSharedST.class);\n-    private static final String NAMESPACE = \"kafka-configuration-shared-cluster-test\";\n-\n-    @ParameterizedTest\n-    @CsvSource({\n-        \"background.threads, \" + 12,\n-        \"compression.type,  snappy\",\n-        \"compression.type,  gzip\",\n-        \"compression.type,  lz4\",\n-        \"compression.type,  zstd\",\n-        \"log.flush.interval.ms, \" + 20,\n-        \"log.retention.ms,  \" + 20,\n-        \"log.retention.bytes, \" + 250,\n-        \"log.segment.bytes,   \" + 1_100,\n-        \"log.segment.delete.delay.ms,  \" + 400,\n-        \"log.roll.jitter.ms, \" + 500,\n-        \"log.roll.ms, \" + 300,\n-        \"log.cleaner.dedupe.buffer.size, \" + 4_000_000,\n-        \"log.cleaner.delete.retention.ms, \" + 1_000,\n-        \"log.cleaner.io.buffer.load.factor, \" + 12,\n-        \"log.cleaner.io.buffer.size, \" + 10_000,\n-        \"log.cleaner.io.max.bytes.per.second, \" + 1.523,\n-        \"log.cleaner.max.compaction.lag.ms, \" + 32_000,\n-        \"log.cleaner.min.compaction.lag.ms, \" + 1_000,\n-        \"log.preallocate, \" + true,\n-        \"max.connections, \" + 10,\n-        \"max.connections.per.ip, \" + 20,\n-        \"unclean.leader.election.enable, \" + true,\n-        \"message.max.bytes, \" + 2048,\n-    })\n-    void testLogDynamicKafkaConfigurationProperties(String kafkaDynamicConfigurationKey, Object kafkaDynamicConfigurationValue) {\n-        // exercise phase\n-        KafkaUtils.updateConfigurationWithStabilityWait(CLUSTER_NAME, kafkaDynamicConfigurationKey, kafkaDynamicConfigurationValue);\n-\n-        // verify phase\n-        assertThat(KafkaUtils.verifyCrDynamicConfiguration(CLUSTER_NAME, kafkaDynamicConfigurationKey, kafkaDynamicConfigurationValue), is(true));\n-        assertThat(KafkaUtils.verifyPodDynamicConfiguration(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaDynamicConfigurationKey, kafkaDynamicConfigurationValue), is(true));\n-    }\n-\n-    @BeforeAll\n-    void setup() throws Exception {\n-        ResourceManager.setClassResources();\n-        installClusterOperator(NAMESPACE);\n-\n-        LOGGER.info(\"Deploying shared Kafka across all test cases!\");\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1).done();\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0NjE2Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466346162", "bodyText": "Is this meant to be only for kafka config or also for the various (kafka, CO, ...) dynamic logging configurations?", "author": "sknot-rh", "createdAt": "2020-08-06T11:28:05Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/Constants.java", "diffHunk": "@@ -240,4 +240,9 @@\n      * Tag for tests where cruise control used\n      */\n     String CRUISE_CONTROL = \"cruisecontrol\";\n+\n+    /**\n+     * Tag for tests where mainly dynamic configuration is used\n+     */\n+    String DYNAMIC_CONFIGURATION = \"dynamicconfiguration\";", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM3MjY2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466372661", "bodyText": "Everywhere, where the broker will not be triggered by change of dyn. configuration we should tag as DYNAMIC_CONFIGURATION", "author": "see-quick", "createdAt": "2020-08-06T12:22:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0NjE2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/Constants.java b/systemtest/src/main/java/io/strimzi/systemtest/Constants.java\nindex 9248d8077..9e19f4ec2 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/Constants.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/Constants.java\n\n@@ -245,4 +245,14 @@ public interface Constants {\n      * Tag for tests where mainly dynamic configuration is used\n      */\n     String DYNAMIC_CONFIGURATION = \"dynamicconfiguration\";\n+\n+    /**\n+     * Tag for tests which contains rolling update of resource\n+     */\n+    String ROLLING_UPDATE = \"rollingupdate\";\n+\n+    /**\n+     * Tag for tests where OLM is used for deploying CO\n+     */\n+    String OLM = \"olm\";\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0ODQ5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466348498", "bodyText": "Should we add a parameter String dynConfProperty to make this more general?", "author": "sknot-rh", "createdAt": "2020-08-06T11:32:53Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalNodePort()\n+                            .withTls(false)\n+                        .endKafkaListenerExternalNodePort()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientTls = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(USER_NAME)\n+            .withSecurityProtocol(SecurityProtocol.SSL)\n+            .build();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientPlain = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .build();\n+\n+        String userName = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();\n+\n+        basicExternalKafkaClientTls.setKafkaUsername(userName);\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withNewKafkaListenerAuthenticationTlsAuth()\n+                        .endKafkaListenerAuthenticationTlsAuth()\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        basicExternalKafkaClientTls.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientTls.sendMessagesTls(),\n+                basicExternalKafkaClientTls.sendMessagesTls()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientPlain.sendMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientPlain.receiveMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to tls communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+    }\n+\n+    private void updateAndVerifyDynConf(String dynConfValue) {", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM3NDQ3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466374475", "bodyText": "Currently, I am using only the one specific property. So it would be useless from my POV to extend it for now.", "author": "see-quick", "createdAt": "2020-08-06T12:26:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM0ODQ5OA=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MDQwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466350403", "bodyText": "Just a nit. Should this be execute phase?", "author": "sknot-rh", "createdAt": "2020-08-06T11:36:59Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.CsvSource;\n+\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationSharedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationSharedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-shared-cluster-test\";\n+\n+    @ParameterizedTest\n+    @CsvSource({\n+        \"background.threads, \" + 12,\n+        \"compression.type,  snappy\",\n+        \"compression.type,  gzip\",\n+        \"compression.type,  lz4\",\n+        \"compression.type,  zstd\",\n+        \"log.flush.interval.ms, \" + 20,\n+        \"log.retention.ms,  \" + 20,\n+        \"log.retention.bytes, \" + 250,\n+        \"log.segment.bytes,   \" + 1_100,\n+        \"log.segment.delete.delay.ms,  \" + 400,\n+        \"log.roll.jitter.ms, \" + 500,\n+        \"log.roll.ms, \" + 300,\n+        \"log.cleaner.dedupe.buffer.size, \" + 4_000_000,\n+        \"log.cleaner.delete.retention.ms, \" + 1_000,\n+        \"log.cleaner.io.buffer.load.factor, \" + 12,\n+        \"log.cleaner.io.buffer.size, \" + 10_000,\n+        \"log.cleaner.io.max.bytes.per.second, \" + 1.523,\n+        \"log.cleaner.max.compaction.lag.ms, \" + 32_000,\n+        \"log.cleaner.min.compaction.lag.ms, \" + 1_000,\n+        \"log.preallocate, \" + true,\n+        \"max.connections, \" + 10,\n+        \"max.connections.per.ip, \" + 20,\n+        \"unclean.leader.election.enable, \" + true,\n+        \"message.max.bytes, \" + 2048,\n+    })\n+    void testLogDynamicKafkaConfigurationProperties(String kafkaDynamicConfigurationKey, Object kafkaDynamicConfigurationValue) {\n+        // exercise phase", "originalCommit": "64d1ac624b2f41b7401f52d4bd2054a8dc893294", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM3ODI2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466378266", "bodyText": "No, it is exercise phase -> https://thoughtbot.com/blog/four-phase-test. I am changing the state of the SUT.", "author": "see-quick", "createdAt": "2020-08-06T12:32:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MDQwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM4MDU3MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466380571", "bodyText": "Ah, ok. Thanks.", "author": "sknot-rh", "createdAt": "2020-08-06T12:37:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM1MDQwMw=="}], "type": "inlineReview", "revised_code": {"commit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\ndeleted file mode 100644\nindex 6f0d5a76e..000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n+++ /dev/null\n\n@@ -1,75 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.dynamicconfiguration;\n-\n-import io.strimzi.api.kafka.model.KafkaResources;\n-import io.strimzi.systemtest.AbstractST;\n-import io.strimzi.systemtest.resources.ResourceManager;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.BeforeAll;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.params.ParameterizedTest;\n-import org.junit.jupiter.params.provider.CsvSource;\n-\n-import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-@Tag(DYNAMIC_CONFIGURATION)\n-public class DynamicConfigurationSharedST extends AbstractST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationSharedST.class);\n-    private static final String NAMESPACE = \"kafka-configuration-shared-cluster-test\";\n-\n-    @ParameterizedTest\n-    @CsvSource({\n-        \"background.threads, \" + 12,\n-        \"compression.type,  snappy\",\n-        \"compression.type,  gzip\",\n-        \"compression.type,  lz4\",\n-        \"compression.type,  zstd\",\n-        \"log.flush.interval.ms, \" + 20,\n-        \"log.retention.ms,  \" + 20,\n-        \"log.retention.bytes, \" + 250,\n-        \"log.segment.bytes,   \" + 1_100,\n-        \"log.segment.delete.delay.ms,  \" + 400,\n-        \"log.roll.jitter.ms, \" + 500,\n-        \"log.roll.ms, \" + 300,\n-        \"log.cleaner.dedupe.buffer.size, \" + 4_000_000,\n-        \"log.cleaner.delete.retention.ms, \" + 1_000,\n-        \"log.cleaner.io.buffer.load.factor, \" + 12,\n-        \"log.cleaner.io.buffer.size, \" + 10_000,\n-        \"log.cleaner.io.max.bytes.per.second, \" + 1.523,\n-        \"log.cleaner.max.compaction.lag.ms, \" + 32_000,\n-        \"log.cleaner.min.compaction.lag.ms, \" + 1_000,\n-        \"log.preallocate, \" + true,\n-        \"max.connections, \" + 10,\n-        \"max.connections.per.ip, \" + 20,\n-        \"unclean.leader.election.enable, \" + true,\n-        \"message.max.bytes, \" + 2048,\n-    })\n-    void testLogDynamicKafkaConfigurationProperties(String kafkaDynamicConfigurationKey, Object kafkaDynamicConfigurationValue) {\n-        // exercise phase\n-        KafkaUtils.updateConfigurationWithStabilityWait(CLUSTER_NAME, kafkaDynamicConfigurationKey, kafkaDynamicConfigurationValue);\n-\n-        // verify phase\n-        assertThat(KafkaUtils.verifyCrDynamicConfiguration(CLUSTER_NAME, kafkaDynamicConfigurationKey, kafkaDynamicConfigurationValue), is(true));\n-        assertThat(KafkaUtils.verifyPodDynamicConfiguration(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaDynamicConfigurationKey, kafkaDynamicConfigurationValue), is(true));\n-    }\n-\n-    @BeforeAll\n-    void setup() throws Exception {\n-        ResourceManager.setClassResources();\n-        installClusterOperator(NAMESPACE);\n-\n-        LOGGER.info(\"Deploying shared Kafka across all test cases!\");\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1).done();\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzMDk4OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466430988", "bodyText": "I think the indent is still same here.", "author": "im-konge", "createdAt": "2020-08-06T13:56:14Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzOTc0OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466639748", "bodyText": "I assume this will be changing with every Kafka release. So you should make this somehow dynamic maybe?", "author": "scholzj", "createdAt": "2020-08-06T19:32:57Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzczMTA3Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r467731076", "bodyText": "Yes I will use TestKafkaVersion class to do it dynamically. :) Thanks", "author": "see-quick", "createdAt": "2020-08-10T07:33:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzOTc0OA=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzOTkyNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466639927", "bodyText": "I'm not sure I understand why are we asserting these when we don't configure them anywhere.", "author": "scholzj", "createdAt": "2020-08-06T19:33:19Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzczMTA5Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r467731092", "bodyText": "If I understand you correctly...but I configure it in the @BeforeEach phase.", "author": "see-quick", "createdAt": "2020-08-10T07:33:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYzOTkyNw=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MDEwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466640104", "bodyText": "Why should this be \"true\"?", "author": "scholzj", "createdAt": "2020-08-06T19:33:41Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg0MTg1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466841853", "bodyText": "This method (as you pointed) is setting unclean.leader.election.enable, which is dynamically changeable option. Default value is false so it is just changing its value.", "author": "sknot-rh", "createdAt": "2020-08-07T06:14:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MDEwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjkzMzczNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466933737", "bodyText": "I think the code should be improved to make it easier to understand and read even without understanding some Kafka defaults.", "author": "scholzj", "createdAt": "2020-08-07T09:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MDEwNA=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MDIwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466640208", "bodyText": "Why should this be \"true\"?", "author": "scholzj", "createdAt": "2020-08-06T19:33:52Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg0MTg3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466841874", "bodyText": "And after the value is changed, it is verified whether it actually changed.", "author": "sknot-rh", "createdAt": "2020-08-07T06:14:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MDIwOA=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MTE1OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466641159", "bodyText": "This has generic name, but it is not generic method. It should ba then maybe named updateAndVerifyDynUncleanLeaderElectionConf", "author": "scholzj", "createdAt": "2020-08-06T19:35:30Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalNodePort()\n+                            .withTls(false)\n+                        .endKafkaListenerExternalNodePort()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientTls = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(USER_NAME)\n+            .withSecurityProtocol(SecurityProtocol.SSL)\n+            .build();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientPlain = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .build();\n+\n+        String userName = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();\n+\n+        basicExternalKafkaClientTls.setKafkaUsername(userName);\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withNewKafkaListenerAuthenticationTlsAuth()\n+                        .endKafkaListenerAuthenticationTlsAuth()\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        basicExternalKafkaClientTls.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientTls.sendMessagesTls(),\n+                basicExternalKafkaClientTls.sendMessagesTls()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientPlain.sendMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientPlain.receiveMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to tls communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+    }\n+\n+    private void updateAndVerifyDynConf(String dynConfValue) {", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzc0NDI2NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r467744264", "bodyText": "I have refactored that method to be more generic :)", "author": "see-quick", "createdAt": "2020-08-10T08:04:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MTE1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0MTY3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466641675", "bodyText": "I think the use of a class field with unclear value is a bit dubious. Why are we not just setting the single options you are setting? Or why don't you pass kafkaConfig as parameter?", "author": "scholzj", "createdAt": "2020-08-06T19:36:24Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalNodePort()\n+                            .withTls(false)\n+                        .endKafkaListenerExternalNodePort()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientTls = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(USER_NAME)\n+            .withSecurityProtocol(SecurityProtocol.SSL)\n+            .build();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientPlain = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .build();\n+\n+        String userName = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();\n+\n+        basicExternalKafkaClientTls.setKafkaUsername(userName);\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withNewKafkaListenerAuthenticationTlsAuth()\n+                        .endKafkaListenerAuthenticationTlsAuth()\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        basicExternalKafkaClientTls.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientTls.sendMessagesTls(),\n+                basicExternalKafkaClientTls.sendMessagesTls()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientPlain.sendMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientPlain.receiveMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to tls communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+    }\n+\n+    private void updateAndVerifyDynConf(String dynConfValue) {\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        // change dynamically changeable option\n+        kafkaConfig.put(\"unclean.leader.election.enable\", dynConfValue);", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0NDUxNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466644517", "bodyText": "Can we add some Javadoc explaining what this does?", "author": "scholzj", "createdAt": "2020-08-06T19:42:06Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();\n+\n+        Map<String, String> kafkaPodsSnapshot = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Updating logging of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setLogging(il);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPodsSnapshot);\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+            .editKafka()\n+                .withNewListeners()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                .endListeners()\n+                .withConfig(kafkaConfig)\n+            .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+        updateAndVerifyDynConf(\"true\");\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        updateAndVerifyDynConf(\"false\");\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalNodePort()\n+                            .withTls(false)\n+                        .endKafkaListenerExternalNodePort()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientTls = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withKafkaUsername(USER_NAME)\n+            .withSecurityProtocol(SecurityProtocol.SSL)\n+            .build();\n+\n+        BasicExternalKafkaClient basicExternalKafkaClientPlain = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withSecurityProtocol(SecurityProtocol.PLAINTEXT)\n+            .build();\n+\n+        String userName = KafkaUserUtils.generateRandomNameOfKafkaUser();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();\n+\n+        basicExternalKafkaClientTls.setKafkaUsername(userName);\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withNewKafkaListenerAuthenticationTlsAuth()\n+                        .endKafkaListenerAuthenticationTlsAuth()\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        basicExternalKafkaClientTls.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientTls.sendMessagesTls(),\n+                basicExternalKafkaClientTls.sendMessagesTls()\n+        );\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientPlain.sendMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientPlain.receiveMessagesPlain(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to tls communication\");\n+        });\n+\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaListeners updatedKl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                        .withTls(false)\n+                    .endKafkaListenerExternalNodePort()\n+                    .build();\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            kafkaClusterSpec.setListeners(updatedKl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+\n+        assertThrows(Exception.class, () -> {\n+            basicExternalKafkaClientTls.sendMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            basicExternalKafkaClientTls.receiveMessagesTls(Constants.GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT);\n+            LOGGER.error(\"Producer & Consumer did not send and receive messages because external listener is set to plain communication\");\n+        });\n+\n+        basicExternalKafkaClientPlain.verifyProducedAndConsumedMessages(\n+                basicExternalKafkaClientPlain.sendMessagesPlain(),\n+                basicExternalKafkaClientPlain.receiveMessagesPlain()\n+        );\n+    }\n+\n+    private void updateAndVerifyDynConf(String dynConfValue) {", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0NTMyOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466645329", "bodyText": "Why are we suddenly changing logging? Standa is working on a PR to make logging changes not roll the pods. So this will stop working soon.", "author": "scholzj", "createdAt": "2020-08-06T19:43:32Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,292 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.InlineLogging;\n+import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+\n+        updateAndVerifyDynConf(\"true\");\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=2.5\"));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+\n+        InlineLogging il = new InlineLoggingBuilder().withLoggers(Collections.singletonMap(\"kafka.logger.level\", \"INFO\")).build();", "originalCommit": "a3e061ab713da9d51258d389a8ed6b1822ce9e0e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njg0MjU5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r466842598", "bodyText": "It is copy-paste from test I wrote. At the time we had dynamic updates of kafka configuration only, we wanted to be sure the changes of logging will trigger RU. For the reasons you mentioned, it should be deleted in this PR or in my PR after rebase.", "author": "sknot-rh", "createdAt": "2020-08-07T06:17:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0NTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzc0NDQxMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r467744413", "bodyText": "Removed :)", "author": "see-quick", "createdAt": "2020-08-10T08:04:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0NTMyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7517de0b3496641bd930171d41daeccd54ff86ce", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 95dec7333..6d1808183 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -4,19 +4,19 @@\n  */\n package io.strimzi.systemtest.dynamicconfiguration;\n \n-import io.strimzi.api.kafka.model.InlineLogging;\n-import io.strimzi.api.kafka.model.InlineLoggingBuilder;\n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.listener.KafkaListeners;\n import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n"}}, {"oid": "7517de0b3496641bd930171d41daeccd54ff86ce", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7517de0b3496641bd930171d41daeccd54ff86ce", "message": "adding diff property\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-10T08:06:07Z", "type": "forcePushed"}, {"oid": "22a5375f16130e257b4e13364bfd459227de4a7e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/22a5375f16130e257b4e13364bfd459227de4a7e", "message": "adding diff property\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-10T14:15:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM2NDg0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r469364840", "bodyText": "What does this tell you that the result of the update to the Kafka CR does not?", "author": "tombentley", "createdAt": "2020-08-12T15:52:49Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +156,79 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {", "originalCommit": "defb26bb06660cf9d8eb8f07c9b899cb920b4796", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 3992a395f..8e6c33747 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -231,4 +238,76 @@ public class KafkaUtils {\n         }\n         return true;\n     }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n+     * @param kafkaVersion specific kafka version\n+     * @return JsonObject all supported kafka properties\n+     */\n+    @SuppressFBWarnings(\"RR_NOT_CHECKED\")\n+    public static JsonObject loadSupportedKafkaConfigs(String kafkaVersion) {\n+\n+        File file = new File(\"../cluster-operator/src/main/resources/kafka-\" + kafkaVersion + \"-config-model.json\");\n+        byte[] data = new byte[0];\n+\n+        try (FileInputStream fis = new FileInputStream(file)) {\n+\n+            data = new byte[(int) file.length()];\n+            fis.read(data);\n+\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+\n+        String kafkaConfigs = new String(data, Charset.defaultCharset());\n+\n+        return new JsonObject(kafkaConfigs);\n+    }\n+\n+    /**\n+     * Method, which process all supported configs by Kafka and filter all which are not dynamic\n+     * @param kafkaVersion specific kafka version\n+     * @return Map<String, Object> all dynamic properties for specific kafka version\n+     */\n+    @SuppressWarnings({\"checkstyle:CyclomaticComplexity\", \"checkstyle:BooleanExpressionComplexity\", \"unchecked\"})\n+    public static Map<String, Object> getDynamicConfigurationProperties(String kafkaVersion)  {\n+\n+        JsonObject kafkaConfig = KafkaUtils.loadSupportedKafkaConfigs(kafkaVersion);\n+\n+        Map<String, Object> dynamicConfigs = kafkaConfig.getJsonObject(\"configs\")\n+            .getMap()\n+            .entrySet()\n+            .stream()\n+            .filter(a ->\n+                // ignoring everything which is READ_ONLY\n+                !((LinkedHashMap<String, String>) a.getValue()).get(\"scope\").equals(\"READ_ONLY\") &&\n+                    // filtering configs with following prefixes\n+                    // \"listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl.,\n+                    // security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, authorizer.,\n+                    // super.user, cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers\n+                    !(\n+                        a.getKey().startsWith(\"listeners\") ||\n+                            a.getKey().startsWith(\"advertised\") ||\n+                            a.getKey().startsWith(\"broker\") ||\n+                            a.getKey().startsWith(\"listener\") ||\n+                            a.getKey().startsWith(\"host.name\") ||\n+                            a.getKey().startsWith(\"port\") ||\n+                            a.getKey().startsWith(\"inter.broker.listener.name\") ||\n+                            a.getKey().startsWith(\"sasl\") ||\n+                            a.getKey().startsWith(\"ssl\") ||\n+                            a.getKey().startsWith(\"security\") ||\n+                            a.getKey().startsWith(\"password\") ||\n+                            a.getKey().startsWith(\"principal.builder.class\") ||\n+                            a.getKey().startsWith(\"log.dir\") ||\n+                            a.getKey().startsWith(\"zookeeper.connect\") ||\n+                            a.getKey().startsWith(\"zookeeper.set.acl\") ||\n+                            a.getKey().startsWith(\"authorizer\") ||\n+                            a.getKey().startsWith(\"super.user\") ||\n+                            a.getKey().startsWith(\"cruise.control.metrics.topic\") ||\n+                            a.getKey().startsWith(\"cruise.control.metrics.reporter.bootstrap.servers\"))\n+            )\n+            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n+\n+        return dynamicConfigs;\n+    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU4MDU3OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r471580579", "bodyText": "I think it should be in kafka directory in systemtest package", "author": "Frawless", "createdAt": "2020-08-17T16:01:52Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;", "originalCommit": "347dd238537142b016a9fa33e8fe7c077da7583c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationSharedST.java\nsimilarity index 79%\nrename from systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\nrename to systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationSharedST.java\nindex 712f00643..5cdad5b99 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationSharedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationSharedST.java\n\n@@ -2,24 +2,25 @@\n  * Copyright Strimzi authors.\n  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n  */\n-package io.strimzi.systemtest.dynamicconfiguration;\n+package io.strimzi.systemtest.kafka.dynamicconfiguration;\n \n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.systemtest.AbstractST;\n import io.strimzi.systemtest.Environment;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.FileUtils;\n import io.strimzi.systemtest.utils.TestKafkaVersion;\n import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.DynamicTest;\n import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.params.ParameterizedTest;\n-import org.junit.jupiter.params.provider.CsvFileSource;\n+import org.junit.jupiter.api.TestFactory;\n \n+import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Iterator;\n import java.util.LinkedHashMap;\n import java.util.List;\n import java.util.Map;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTU4MTUzOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r471581538", "bodyText": "It should be in kafka directory of systemtest I think.", "author": "Frawless", "createdAt": "2020-08-17T16:03:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.dynamicconfiguration;", "originalCommit": "347dd238537142b016a9fa33e8fe7c077da7583c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nsimilarity index 99%\nrename from systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nrename to systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 4c8eed075..8b18e8dbe 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -2,7 +2,7 @@\n  * Copyright Strimzi authors.\n  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n  */\n-package io.strimzi.systemtest.dynamicconfiguration;\n+package io.strimzi.systemtest.kafka.dynamicconfiguration;\n \n import io.strimzi.api.kafka.model.KafkaClusterSpec;\n import io.strimzi.api.kafka.model.KafkaResources;\n"}}, {"oid": "58b10ba7d48706f744cd81e4924a02eea22d660b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/58b10ba7d48706f744cd81e4924a02eea22d660b", "message": "spotbugs\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-17T18:38:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NTUxMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r472085511", "bodyText": "Shouldn't be this annotation from spotbugs?", "author": "Frawless", "createdAt": "2020-08-18T10:44:28Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -4,6 +4,8 @@\n  */\n package io.strimzi.systemtest.utils.kafkaUtils;\n \n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;", "originalCommit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQzMjUzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r476432536", "bodyText": "AFAIK everywhere we use SuppressFBWarnings. I know that FB were deprecated and replaced by SpotBugs but  from code a i cannot find any SuppressSBWarnings or something similar like this.", "author": "see-quick", "createdAt": "2020-08-25T13:05:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjA4NTUxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "9bc6b07c0fc7a7a17ebaf447d03b48931ffdb63d", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 8e6c33747..44a0fdd31 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -4,40 +4,43 @@\n  */\n package io.strimzi.systemtest.utils.kafkaUtils;\n \n-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n import io.fabric8.kubernetes.api.model.Pod;\n import io.strimzi.api.kafka.model.Kafka;\n import io.strimzi.api.kafka.model.KafkaResources;\n import io.strimzi.api.kafka.model.status.Condition;\n import io.strimzi.api.kafka.model.status.ListenerStatus;\n+import io.strimzi.kafka.config.model.ConfigModel;\n+import io.strimzi.kafka.config.model.ConfigModels;\n+import io.strimzi.kafka.config.model.Scope;\n import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.resources.ResourceManager;\n import io.strimzi.systemtest.resources.crd.KafkaResource;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n import io.strimzi.test.TestUtils;\n import io.strimzi.test.k8s.exceptions.KubeClusterException;\n-import io.vertx.core.json.JsonObject;\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n \n-import java.io.File;\n import java.io.FileInputStream;\n import java.io.IOException;\n+import java.io.InputStream;\n import java.nio.charset.Charset;\n+import java.time.Duration;\n import java.util.Base64;\n-import java.util.LinkedHashMap;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.regex.Pattern;\n import java.util.stream.Collectors;\n \n+import static io.strimzi.api.kafka.model.KafkaClusterSpec.FORBIDDEN_PREFIXES;\n+import static io.strimzi.api.kafka.model.KafkaClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS;\n import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n import static io.strimzi.api.kafka.model.KafkaResources.zookeeperStatefulSetName;\n import static io.strimzi.systemtest.enums.CustomResourceStatus.NotReady;\n import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;\n-import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;\n import static io.strimzi.test.TestUtils.indent;\n import static io.strimzi.test.TestUtils.waitFor;\n import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjEwNzQxNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r472107416", "bodyText": "Maybe we should use prefixes from FORBIDDEN_PREFIXES ?", "author": "Frawless", "createdAt": "2020-08-18T11:29:10Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +163,151 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            brokerConfigName,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName),\n+            brokerConfigName,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String brokerConfigName, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n+                () -> {\n+                    String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+                    LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+                    if (!result.contains(brokerConfigName + \"=\" + value)) {\n+                        LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), brokerConfigName, value);\n+                        LOGGER.error(\"Kafka configuration {}\", result);\n+                        return false;\n+                    }\n+                    return true;\n+                });\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n+     * @param kafkaVersion specific kafka version\n+     * @return JsonObject all supported kafka properties\n+     */\n+    @SuppressFBWarnings(\"RR_NOT_CHECKED\")\n+    public static JsonObject loadSupportedKafkaConfigs(String kafkaVersion) {\n+\n+        File file = new File(\"../cluster-operator/src/main/resources/kafka-\" + kafkaVersion + \"-config-model.json\");\n+        byte[] data = new byte[0];\n+\n+        try (FileInputStream fis = new FileInputStream(file)) {\n+\n+            data = new byte[(int) file.length()];\n+            fis.read(data);\n+\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+\n+        String kafkaConfigs = new String(data, Charset.defaultCharset());\n+\n+        return new JsonObject(kafkaConfigs);\n+    }\n+\n+    /**\n+     * Method, which process all supported configs by Kafka and filter all which are not dynamic\n+     * @param kafkaVersion specific kafka version\n+     * @return Map<String, Object> all dynamic properties for specific kafka version\n+     */\n+    @SuppressWarnings({\"checkstyle:CyclomaticComplexity\", \"checkstyle:BooleanExpressionComplexity\", \"unchecked\"})\n+    public static Map<String, Object> getDynamicConfigurationProperties(String kafkaVersion)  {\n+\n+        JsonObject kafkaConfig = KafkaUtils.loadSupportedKafkaConfigs(kafkaVersion);\n+\n+        Map<String, Object> dynamicConfigs = kafkaConfig.getJsonObject(\"configs\")\n+            .getMap()\n+            .entrySet()\n+            .stream()\n+            .filter(a ->\n+                // ignoring everything which is READ_ONLY\n+                !((LinkedHashMap<String, String>) a.getValue()).get(\"scope\").equals(\"READ_ONLY\") &&\n+                    // filtering configs with following prefixes\n+                    // \"listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl.,", "originalCommit": "58b10ba7d48706f744cd81e4924a02eea22d660b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 8e6c33747..404a2059c 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -267,7 +267,7 @@ public class KafkaUtils {\n     /**\n      * Method, which process all supported configs by Kafka and filter all which are not dynamic\n      * @param kafkaVersion specific kafka version\n-     * @return Map<String, Object> all dynamic properties for specific kafka version\n+     * @return all dynamic properties for specific kafka version\n      */\n     @SuppressWarnings({\"checkstyle:CyclomaticComplexity\", \"checkstyle:BooleanExpressionComplexity\", \"unchecked\"})\n     public static Map<String, Object> getDynamicConfigurationProperties(String kafkaVersion)  {\n"}}, {"oid": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "message": "doc\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-18T15:03:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ1NTcyNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r472455724", "bodyText": "I think that @im-konge is in other PR adding the tag ROLLING_UPDATE. I think we should use it here as well because these are closely related.", "author": "scholzj", "createdAt": "2020-08-18T20:11:50Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/Constants.java", "diffHunk": "@@ -240,4 +240,9 @@\n      * Tag for tests where cruise control used\n      */\n     String CRUISE_CONTROL = \"cruisecontrol\";\n+\n+    /**\n+     * Tag for tests where mainly dynamic configuration is used\n+     */\n+    String DYNAMIC_CONFIGURATION = \"dynamicconfiguration\";", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/Constants.java b/systemtest/src/main/java/io/strimzi/systemtest/Constants.java\nindex 9248d8077..9e19f4ec2 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/Constants.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/Constants.java\n\n@@ -245,4 +245,14 @@ public interface Constants {\n      * Tag for tests where mainly dynamic configuration is used\n      */\n     String DYNAMIC_CONFIGURATION = \"dynamicconfiguration\";\n+\n+    /**\n+     * Tag for tests which contains rolling update of resource\n+     */\n+    String ROLLING_UPDATE = \"rollingupdate\";\n+\n+    /**\n+     * Tag for tests where OLM is used for deploying CO\n+     */\n+    String OLM = \"olm\";\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ4MTA0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r472481042", "bodyText": "How does this deal with the exceptions to the forbidden prefixes?", "author": "scholzj", "createdAt": "2020-08-18T20:42:44Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +163,151 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            brokerConfigName,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName),\n+            brokerConfigName,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String brokerConfigName, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n+                () -> {\n+                    String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+                    LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+                    if (!result.contains(brokerConfigName + \"=\" + value)) {\n+                        LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), brokerConfigName, value);\n+                        LOGGER.error(\"Kafka configuration {}\", result);\n+                        return false;\n+                    }\n+                    return true;\n+                });\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n+     * @param kafkaVersion specific kafka version\n+     * @return JsonObject all supported kafka properties\n+     */\n+    @SuppressFBWarnings(\"RR_NOT_CHECKED\")\n+    public static JsonObject loadSupportedKafkaConfigs(String kafkaVersion) {\n+\n+        File file = new File(\"../cluster-operator/src/main/resources/kafka-\" + kafkaVersion + \"-config-model.json\");\n+        byte[] data = new byte[0];\n+\n+        try (FileInputStream fis = new FileInputStream(file)) {\n+\n+            data = new byte[(int) file.length()];\n+            fis.read(data);\n+\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+\n+        String kafkaConfigs = new String(data, Charset.defaultCharset());\n+\n+        return new JsonObject(kafkaConfigs);\n+    }\n+\n+    /**\n+     * Method, which process all supported configs by Kafka and filter all which are not dynamic\n+     * @param kafkaVersion specific kafka version\n+     * @return all dynamic properties for specific kafka version\n+     */\n+    @SuppressWarnings({\"checkstyle:CyclomaticComplexity\", \"checkstyle:BooleanExpressionComplexity\", \"unchecked\"})\n+    public static Map<String, Object> getDynamicConfigurationProperties(String kafkaVersion)  {\n+\n+        JsonObject kafkaConfig = KafkaUtils.loadSupportedKafkaConfigs(kafkaVersion);\n+\n+        Map<String, Object> dynamicConfigs = kafkaConfig.getJsonObject(\"configs\")\n+            .getMap()\n+            .entrySet()\n+            .stream()\n+            .filter(a ->\n+                // ignoring everything which is READ_ONLY\n+                !((LinkedHashMap<String, String>) a.getValue()).get(\"scope\").equals(\"READ_ONLY\") &&\n+                    // filtering configs with following prefixes\n+                    // \"listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl.,\n+                    // security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, authorizer.,\n+                    // super.user, cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers\n+                    !(\n+                        a.getKey().startsWith(\"listeners\") ||\n+                            a.getKey().startsWith(\"advertised\") ||\n+                            a.getKey().startsWith(\"broker\") ||\n+                            a.getKey().startsWith(\"listener\") ||\n+                            a.getKey().startsWith(\"host.name\") ||\n+                            a.getKey().startsWith(\"port\") ||\n+                            a.getKey().startsWith(\"inter.broker.listener.name\") ||\n+                            a.getKey().startsWith(\"sasl\") ||\n+                            a.getKey().startsWith(\"ssl\") ||\n+                            a.getKey().startsWith(\"security\") ||\n+                            a.getKey().startsWith(\"password\") ||\n+                            a.getKey().startsWith(\"principal.builder.class\") ||\n+                            a.getKey().startsWith(\"log.dir\") ||\n+                            a.getKey().startsWith(\"zookeeper.connect\") ||\n+                            a.getKey().startsWith(\"zookeeper.set.acl\") ||\n+                            a.getKey().startsWith(\"authorizer\") ||\n+                            a.getKey().startsWith(\"super.user\") ||\n+                            a.getKey().startsWith(\"cruise.control.metrics.topic\") ||", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 404a2059c..c6d3a814a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -181,7 +184,7 @@ public class KafkaUtils {\n     }\n \n     /**\n-     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * Method which, extends the @link updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n      * with stability and ensures after update of Kafka resource there will be not rolling update\n      * @param clusterName name of the cluster where Kafka resource can be found\n      * @param brokerConfigName key of specific property\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDczMTI5MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474731290", "bodyText": "I think you mean @link.", "author": "tombentley", "createdAt": "2020-08-21T14:23:51Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +163,151 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 404a2059c..c6d3a814a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -181,7 +184,7 @@ public class KafkaUtils {\n     }\n \n     /**\n-     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * Method which, extends the @link updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n      * with stability and ensures after update of Kafka resource there will be not rolling update\n      * @param clusterName name of the cluster where Kafka resource can be found\n      * @param brokerConfigName key of specific property\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDczMzczOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474733739", "bodyText": "You don't have to say it's a method (we already know that!). Javadocs are best when they're to the point:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n          \n          \n            \n                 * Loads all kafka config parameters supported by the given {@code kafkaVersion}, as generated by #KafkaConfigModelGenerator in config-model-generator.", "author": "tombentley", "createdAt": "2020-08-21T14:27:58Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +163,151 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            brokerConfigName,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName),\n+            brokerConfigName,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String brokerConfigName, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n+                () -> {\n+                    String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+                    LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+                    if (!result.contains(brokerConfigName + \"=\" + value)) {\n+                        LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), brokerConfigName, value);\n+                        LOGGER.error(\"Kafka configuration {}\", result);\n+                        return false;\n+                    }\n+                    return true;\n+                });\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 404a2059c..c6d3a814a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -181,7 +184,7 @@ public class KafkaUtils {\n     }\n \n     /**\n-     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * Method which, extends the @link updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n      * with stability and ensures after update of Kafka resource there will be not rolling update\n      * @param clusterName name of the cluster where Kafka resource can be found\n      * @param brokerConfigName key of specific property\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDczNDA3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474734075", "bodyText": "rethrow a RuntimeException", "author": "tombentley", "createdAt": "2020-08-21T14:28:33Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +163,151 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            brokerConfigName,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName),\n+            brokerConfigName,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String brokerConfigName, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n+                () -> {\n+                    String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+                    LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+                    if (!result.contains(brokerConfigName + \"=\" + value)) {\n+                        LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), brokerConfigName, value);\n+                        LOGGER.error(\"Kafka configuration {}\", result);\n+                        return false;\n+                    }\n+                    return true;\n+                });\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n+     * @param kafkaVersion specific kafka version\n+     * @return JsonObject all supported kafka properties\n+     */\n+    @SuppressFBWarnings(\"RR_NOT_CHECKED\")\n+    public static JsonObject loadSupportedKafkaConfigs(String kafkaVersion) {\n+\n+        File file = new File(\"../cluster-operator/src/main/resources/kafka-\" + kafkaVersion + \"-config-model.json\");\n+        byte[] data = new byte[0];\n+\n+        try (FileInputStream fis = new FileInputStream(file)) {\n+\n+            data = new byte[(int) file.length()];\n+            fis.read(data);\n+\n+        } catch (IOException e) {\n+            e.printStackTrace();", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 404a2059c..c6d3a814a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -181,7 +184,7 @@ public class KafkaUtils {\n     }\n \n     /**\n-     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * Method which, extends the @link updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n      * with stability and ensures after update of Kafka resource there will be not rolling update\n      * @param clusterName name of the cluster where Kafka resource can be found\n      * @param brokerConfigName key of specific property\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDczODI1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474738256", "bodyText": "You should be able to use the config-model module. This is what KafkaConfiguration does:\nprivate Map<String, ConfigModel> readConfigModel(KafkaVersion kafkaVersion) {\n        String name = \"/kafka-\" + kafkaVersion.version() + \"-config-model.json\";\n        try {\n            try (InputStream in = KafkaConfiguration.class.getResourceAsStream(name)) {\n                ConfigModels configModels = new ObjectMapper().readValue(in, ConfigModels.class);\n                if (!kafkaVersion.version().equals(configModels.getVersion())) {\n                    throw new RuntimeException(\"Incorrect version\");\n                }\n                return configModels.getConfigs();\n            }\n        } catch (IOException e) {\n            throw new RuntimeException(\"Error reading from classpath resource \" + name, e);\n        }\n    }\nThat will give you nicely typed ConfigModel to deal with, rather than JsonObject. Please try to refactor KafkaConfiguration to use a common implementation rather than copying the above code.", "author": "tombentley", "createdAt": "2020-08-21T14:35:04Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -153,4 +163,151 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            brokerConfigName,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName),\n+            brokerConfigName,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String brokerConfigName, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,\n+                () -> {\n+                    String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+                    LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+                    if (!result.contains(brokerConfigName + \"=\" + value)) {\n+                        LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), brokerConfigName, value);\n+                        LOGGER.error(\"Kafka configuration {}\", result);\n+                        return false;\n+                    }\n+                    return true;\n+                });\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n+     * @param kafkaVersion specific kafka version\n+     * @return JsonObject all supported kafka properties\n+     */\n+    @SuppressFBWarnings(\"RR_NOT_CHECKED\")\n+    public static JsonObject loadSupportedKafkaConfigs(String kafkaVersion) {\n+\n+        File file = new File(\"../cluster-operator/src/main/resources/kafka-\" + kafkaVersion + \"-config-model.json\");\n+        byte[] data = new byte[0];\n+\n+        try (FileInputStream fis = new FileInputStream(file)) {\n+\n+            data = new byte[(int) file.length()];\n+            fis.read(data);\n+\n+        } catch (IOException e) {\n+            e.printStackTrace();\n+        }\n+\n+        String kafkaConfigs = new String(data, Charset.defaultCharset());\n+\n+        return new JsonObject(kafkaConfigs);", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ4ODM5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r476488398", "bodyText": "Done :)", "author": "see-quick", "createdAt": "2020-08-25T14:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDczODI1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex 404a2059c..c6d3a814a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -181,7 +184,7 @@ public class KafkaUtils {\n     }\n \n     /**\n-     * Method which, extends the @see updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * Method which, extends the @link updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n      * with stability and ensures after update of Kafka resource there will be not rolling update\n      * @param clusterName name of the cluster where Kafka resource can be found\n      * @param brokerConfigName key of specific property\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDc0MDg3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474740874", "bodyText": "Not for this PR, but I'm assuming we run the kafka tools in the pod quite often in the tests. So we could consider refactoring so we can say something like:\ncmdKubeClient().execKafkaConfigsInPod(podName, \"--entity-type brokers --entity-name 0 --describe\")", "author": "tombentley", "createdAt": "2020-08-21T14:39:34Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+/**\n+ * DynamicConfigurationIsolatedST is responsible for verify that if we change dynamic Kafka configuration it will not\n+ * trigger rolling update.\n+ * Isolated -> for each test case we have different configuration of Kafka resource\n+ */\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=\" + TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).messageVersion()));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"unclean.leader.election.enable\", true);\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDc2Njk4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474766980", "bodyText": "Yeah, will do in another PR and also create an issue for that.", "author": "see-quick", "createdAt": "2020-08-21T15:22:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDc0MDg3NA=="}], "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 8b18e8dbe..c55ed69b0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -36,6 +36,7 @@ import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.Constants.ROLLING_UPDATE;\n import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n import static org.hamcrest.CoreMatchers.containsString;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDc0MzQ5Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474743497", "bodyText": "I think we increasingly need javadocs explaining what the test is trying to test. Or at least ore descriptive method names. This one is not really about withExternalListeners, it's that changing an external listeners config causes a RU. So the name would be better as testUpdateToExternalListenerCausesRollingRestart", "author": "tombentley", "createdAt": "2020-08-21T14:44:04Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+/**\n+ * DynamicConfigurationIsolatedST is responsible for verify that if we change dynamic Kafka configuration it will not\n+ * trigger rolling update.\n+ * Isolated -> for each test case we have different configuration of Kafka resource\n+ */\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=\" + TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).messageVersion()));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"unclean.leader.election.enable\", true);\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=\" + true));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=\" + TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).messageVersion()));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 8b18e8dbe..c55ed69b0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -36,6 +36,7 @@ import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.Constants.ROLLING_UPDATE;\n import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n import static org.hamcrest.CoreMatchers.containsString;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDc0NDA1NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r474744054", "bodyText": "Same comment about javadoc or method name.", "author": "tombentley", "createdAt": "2020-08-21T14:44:57Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.kafka.dynamicconfiguration;\n+\n+import io.strimzi.api.kafka.model.KafkaClusterSpec;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.systemtest.AbstractST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.Environment;\n+import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.TestKafkaVersion;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.security.auth.SecurityProtocol;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;\n+import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n+import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+/**\n+ * DynamicConfigurationIsolatedST is responsible for verify that if we change dynamic Kafka configuration it will not\n+ * trigger rolling update.\n+ * Isolated -> for each test case we have different configuration of Kafka resource\n+ */\n+@Tag(REGRESSION)\n+@Tag(DYNAMIC_CONFIGURATION)\n+public class DynamicConfigurationIsolatedST extends AbstractST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(DynamicConfigurationIsolatedST.class);\n+    private static final String NAMESPACE = \"kafka-configuration-isolated-cluster-test\";\n+    private static final int KAFKA_REPLICAS = 1;\n+\n+    private Map<String, Object> kafkaConfig;\n+\n+    @Test\n+    void testSimpleDynamicConfiguration() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=\" + TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).messageVersion()));\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"unclean.leader.election.enable\", true);\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=\" + true));\n+\n+        LOGGER.info(\"Verify values after update\");\n+        kafkaConfiguration = kubeClient().getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(CLUSTER_NAME)).getData().get(\"server.config\");\n+        assertThat(kafkaConfiguration, containsString(\"offsets.topic.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"transaction.state.log.replication.factor=1\"));\n+        assertThat(kafkaConfiguration, containsString(\"log.message.format.version=\" + TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).messageVersion()));\n+        assertThat(kafkaConfiguration, containsString(\"unclean.leader.election.enable=true\"));\n+    }\n+\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Test\n+    void testDynamicConfigurationWithExternalListeners() {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewListeners()\n+                        .withNewKafkaListenerExternalNodePort()\n+                            .withTls(false)\n+                        .endKafkaListenerExternalNodePort()\n+                        .withNewPlain()\n+                        .endPlain()\n+                    .endListeners()\n+                    .withConfig(kafkaConfig)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        String kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"unclean.leader.election.enable\", true);\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=\" + true));\n+\n+        // Edit listeners - this should cause RU (because of new crts)\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewKafkaListenerExternalNodePort()\n+                    .endKafkaListenerExternalNodePort()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"compression.type\", \"snappy\");\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"compression.type=snappy\"));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"unclean.leader.election.enable\", true);\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=\" + true));\n+\n+        // Remove external listeners (node port) - this should cause RU (we need to update advertised.listeners)\n+        // Other external listeners cases are rolling because of crts\n+        kafkaPods = StatefulSetUtils.ssSnapshot(kafkaStatefulSetName(CLUSTER_NAME));\n+        LOGGER.info(\"Updating listeners of Kafka cluster\");\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            KafkaClusterSpec kafkaClusterSpec = k.getSpec().getKafka();\n+            KafkaListeners kl = new KafkaListenersBuilder()\n+                    .withNewPlain()\n+                    .endPlain()\n+                    .build();\n+            kafkaClusterSpec.setListeners(kl);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), KAFKA_REPLICAS, kafkaPods);\n+        assertThat(StatefulSetUtils.ssHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods), is(true));\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"Dynamic configs for broker 0 are:\\n\"));\n+\n+        kafkaConfig.put(\"unclean.leader.election.enable\", false);\n+\n+        updateAndVerifyDynConf(kafkaConfig);\n+\n+        kafkaConfigurationFromPod = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+        assertThat(kafkaConfigurationFromPod, containsString(\"unclean.leader.election.enable=\" + false));\n+    }\n+\n+    @Test\n+    @Tag(NODEPORT_SUPPORTED)\n+    @Tag(EXTERNAL_CLIENTS_USED)\n+    void testDynamicConfigurationExternalTls() {", "originalCommit": "581a847e561524a3b7c849c4a53f2fc5ce2dbb33", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\nindex 8b18e8dbe..c55ed69b0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java\n\n@@ -36,6 +36,7 @@ import static io.strimzi.systemtest.Constants.DYNAMIC_CONFIGURATION;\n import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;\n import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static io.strimzi.systemtest.Constants.ROLLING_UPDATE;\n import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;\n import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;\n import static org.hamcrest.CoreMatchers.containsString;\n"}}, {"oid": "0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0213a6ace36a75f02d4c9cb58134774bcf0e0ce1", "message": "tags\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-21T18:19:14Z", "type": "forcePushed"}, {"oid": "9bc6b07c0fc7a7a17ebaf447d03b48931ffdb63d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9bc6b07c0fc7a7a17ebaf447d03b48931ffdb63d", "message": "exceptions\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-08-26T13:48:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM3Njg1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3408#discussion_r478376856", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Method, which process all supported configs by Kafka and filter all which are not dynamic\n          \n          \n            \n                 * Return dynamic Kafka configs supported by the the given version of Kafka.", "author": "tombentley", "createdAt": "2020-08-27T12:21:58Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java", "diffHunk": "@@ -157,4 +170,152 @@ public static void waitForClusterStability(String clusterName) {\n             return false;\n         });\n     }\n+\n+    /**\n+     * Method which, update/replace Kafka configuration\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void updateSpecificConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        KafkaResource.replaceKafkaResource(clusterName, kafka -> {\n+            LOGGER.info(\"Kafka config before updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+            Map<String, Object> config = kafka.getSpec().getKafka().getConfig();\n+            config.put(brokerConfigName, value);\n+            kafka.getSpec().getKafka().setConfig(config);\n+            LOGGER.info(\"Kafka config after updating '{}'\", kafka.getSpec().getKafka().getConfig().toString());\n+        });\n+    }\n+\n+    /**\n+     * Method which, extends the @link updateConfiguration(String clusterName, KafkaConfiguration kafkaConfiguration, Object value) method\n+     * with stability and ensures after update of Kafka resource there will be not rolling update\n+     * @param clusterName name of the cluster where Kafka resource can be found\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static void  updateConfigurationWithStabilityWait(String clusterName, String brokerConfigName, Object value) {\n+        updateSpecificConfiguration(clusterName, brokerConfigName, value);\n+    }\n+\n+    /**\n+     * Verifies that updated configuration was successfully changed inside Kafka CR\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     */\n+    public static boolean verifyCrDynamicConfiguration(String clusterName, String brokerConfigName, Object value) {\n+        LOGGER.info(\"Dynamic Configuration in Kafka CR is {}={} and excepted is {}={}\",\n+            brokerConfigName,\n+            KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName),\n+            brokerConfigName,\n+            value);\n+\n+        return KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getSpec().getKafka().getConfig().get(brokerConfigName).equals(value);\n+    }\n+\n+    /**\n+     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * @param kafkaPodNamePrefix prefix of Kafka pods\n+     * @param brokerConfigName key of specific property\n+     * @param value value of specific property\n+     * @return\n+     * true = if specific property match the excepted property\n+     * false = if specific property doesn't match the excepted property\n+     */\n+    public static boolean verifyPodDynamicConfiguration(String kafkaPodNamePrefix, String brokerConfigName, Object value) {\n+\n+        List<Pod> kafkaPods = kubeClient().listPodsByPrefixInName(kafkaPodNamePrefix);\n+\n+        for (Pod pod : kafkaPods) {\n+\n+            TestUtils.waitFor(\"Wait until dyn.configuration is changed\", Constants.GLOBAL_POLL_INTERVAL, Constants.RECONCILIATION_INTERVAL + Duration.ofSeconds(10).toMillis(),\n+                () -> {\n+                    String result = cmdKubeClient().execInPod(pod.getMetadata().getName(), \"/bin/bash\", \"-c\", \"bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\").out();\n+\n+                    LOGGER.debug(\"This dyn.configuration {} inside the Kafka pod {}\", result, pod.getMetadata().getName());\n+\n+                    if (!result.contains(brokerConfigName + \"=\" + value)) {\n+                        LOGGER.error(\"Kafka Pod {} doesn't contain {} with value {}\", pod.getMetadata().getName(), brokerConfigName, value);\n+                        LOGGER.error(\"Kafka configuration {}\", result);\n+                        return false;\n+                    }\n+                    return true;\n+                });\n+        }\n+        return true;\n+    }\n+\n+    /**\n+     * Method, which load all supported kafka configuration generated by #KafkaConfigModelGenerator in config-model-generator\n+     * @param kafkaVersion specific kafka version\n+     * @return all supported kafka properties\n+     */\n+    public static Map<String, ConfigModel> readConfigModel(String kafkaVersion) {\n+        String name = \"../cluster-operator/src/main/resources/kafka-\" + kafkaVersion + \"-config-model.json\";\n+        try {\n+            try (InputStream in = new FileInputStream(name)) {\n+                ConfigModels configModels = new ObjectMapper().readValue(in, ConfigModels.class);\n+                if (!kafkaVersion.equals(configModels.getVersion())) {\n+                    throw new RuntimeException(\"Incorrect version\");\n+                }\n+                return configModels.getConfigs();\n+            }\n+        } catch (IOException e) {\n+            throw new RuntimeException(\"Error reading from classpath resource \" + name, e);\n+        }\n+    }\n+\n+    /**\n+     * Method, which process all supported configs by Kafka and filter all which are not dynamic", "originalCommit": "308c3ecdb4ea1d3e0389c44e4da596f89bf08acd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "76de14021f24172b40ce8bc26d3bceb3babb323d", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\nindex e9b1203f3..ab45879a1 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java\n\n@@ -214,7 +214,7 @@ public class KafkaUtils {\n     }\n \n     /**\n-     * Method, which, verifying that updating configuration were successfully changed inside Kafka pods\n+     * Verifies that updated configuration was successfully changed inside Kafka pods\n      * @param kafkaPodNamePrefix prefix of Kafka pods\n      * @param brokerConfigName key of specific property\n      * @param value value of specific property\n"}}, {"oid": "76de14021f24172b40ce8bc26d3bceb3babb323d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/76de14021f24172b40ce8bc26d3bceb3babb323d", "message": "user prefix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-07T09:03:22Z", "type": "forcePushed"}, {"oid": "5a1f8b89006bbbb2d706a3a779e7fc9c0877cdc2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5a1f8b89006bbbb2d706a3a779e7fc9c0877cdc2", "message": "[MO] - [dyn.conf] -> tests draft\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:55:59Z", "type": "commit"}, {"oid": "959776c5b0016187d4f31d166bdb1aaa6b973c50", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/959776c5b0016187d4f31d166bdb1aaa6b973c50", "message": "[MO] - [tests] -> additional tests\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:55:59Z", "type": "commit"}, {"oid": "ec6c5aa6228e72783b9cfdfa3bbbc2cf6c2ee14b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ec6c5aa6228e72783b9cfdfa3bbbc2cf6c2ee14b", "message": "adding pod verification + changing the way how to verify\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:55:59Z", "type": "commit"}, {"oid": "7183c843117f568922ac13319fb0281e40d1aabd", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7183c843117f568922ac13319fb0281e40d1aabd", "message": "create shared, iso + separate phases\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "faa36204a6d0a281eb1f3e232040f6675fd4d853", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/faa36204a6d0a281eb1f3e232040f6675fd4d853", "message": "some nits\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "e095f29aaafd8abfd9b8a1975033b711292393a3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e095f29aaafd8abfd9b8a1975033b711292393a3", "message": "[MO] -> changes\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "fac2acd69f7c72748c8086553260001d86926804", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fac2acd69f7c72748c8086553260001d86926804", "message": "parametrized tst\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "ffc6a3ff77fd82360658159a45c05ad8a1f7c874", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ffc6a3ff77fd82360658159a45c05ad8a1f7c874", "message": "updatee\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "76541b66628223a9dea92fb49d2a35b1b87f1906", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/76541b66628223a9dea92fb49d2a35b1b87f1906", "message": "[MO] - adding new profile + tests separation\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "f47afcab2df41630f38fa641f4567d8bda5cb3bc", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f47afcab2df41630f38fa641f4567d8bda5cb3bc", "message": "indent/\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "7aceb5d6871ac5eb185c28ff5a0b638d9f682e40", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7aceb5d6871ac5eb185c28ff5a0b638d9f682e40", "message": "RU fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "699cd9422f1387d2cfde7a2b2fd0da48951c6bb8", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/699cd9422f1387d2cfde7a2b2fd0da48951c6bb8", "message": "removing un-used toString()\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "9c8ccb0a22dde9b835f5631e29881736159fc2ba", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9c8ccb0a22dde9b835f5631e29881736159fc2ba", "message": "fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "241f3f4b8fc82b9e955f604cf3dca7b4202cd606", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/241f3f4b8fc82b9e955f604cf3dca7b4202cd606", "message": "[MO] - commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "eb6c7f8804e8dd7c04c5446337f474a67da0fe66", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/eb6c7f8804e8dd7c04c5446337f474a67da0fe66", "message": "[MO] dyn\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "280900459f501a8cc4e97a9d5a489d268c5ccb0f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/280900459f501a8cc4e97a9d5a489d268c5ccb0f", "message": "[MO] - fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "f331eb558309ec2340070057f9ab4fd3f8daf250", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f331eb558309ec2340070057f9ab4fd3f8daf250", "message": "commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "ac9787b55a1c2b97ceae9da41a42c4ee1da7eff6", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ac9787b55a1c2b97ceae9da41a42c4ee1da7eff6", "message": "resolve commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "e02bbaf61dfc1fcaa6fe804123f0fbf22cd15cba", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e02bbaf61dfc1fcaa6fe804123f0fbf22cd15cba", "message": "adding diff property\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "60da26d546e118073bf7edf2d19f6a5ab3761ef8", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/60da26d546e118073bf7edf2d19f6a5ab3761ef8", "message": "description\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "b6e3d352cc392b605d51c6a5c9a38489dfa7b8c7", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b6e3d352cc392b605d51c6a5c9a38489dfa7b8c7", "message": "space\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "7b4f05888d312f2167e5ac74927e73d78665eb1a", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7b4f05888d312f2167e5ac74927e73d78665eb1a", "message": "automatical generation of test cases\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "964470971f3e228be1dcb17efd8156cc1ef95007", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/964470971f3e228be1dcb17efd8156cc1ef95007", "message": "update fix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:39Z", "type": "commit"}, {"oid": "10e4cbdc8ec0e8e860223fd3dcbbd40ed174d595", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/10e4cbdc8ec0e8e860223fd3dcbbd40ed174d595", "message": "test factory removing csv file\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "f787c7fa0c0b534b9022a0fa2ec772ec2b514500", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f787c7fa0c0b534b9022a0fa2ec772ec2b514500", "message": "supress unchecked\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "d151f9c44ef7b1c761b44ff4be9cd6ededbdbbc3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d151f9c44ef7b1c761b44ff4be9cd6ededbdbbc3", "message": "move\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "222629b3400b246e42bf0627e1091fbea41850fa", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/222629b3400b246e42bf0627e1091fbea41850fa", "message": "spotbugs\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "0234793179c6624771a00322a0150d7eedb7ac05", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0234793179c6624771a00322a0150d7eedb7ac05", "message": "doc\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "7decfc02e8ba8e7917ba90a42841dcda405a7508", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7decfc02e8ba8e7917ba90a42841dcda405a7508", "message": "commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "854f623fa48d6f9cd3c8104748cbfeeba8e89d7b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/854f623fa48d6f9cd3c8104748cbfeeba8e89d7b", "message": "tags\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "64b5044b6cfa6ebf95e6e2f60418ad312f552b00", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/64b5044b6cfa6ebf95e6e2f60418ad312f552b00", "message": "dependecies\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "3c47407b41c4d5ff203dba0f935177e44f7d7bf9", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3c47407b41c4d5ff203dba0f935177e44f7d7bf9", "message": "sd\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "ff69976bca9ce196e746465f8f444bbb5d584eeb", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ff69976bca9ce196e746465f8f444bbb5d584eeb", "message": "fix all\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "0423f843d88ec5cf1a8f9da3a76eda2fec322aa5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0423f843d88ec5cf1a8f9da3a76eda2fec322aa5", "message": "dsds\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "fe509f09a63587f1103f9d178e25094c00fb47d6", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fe509f09a63587f1103f9d178e25094c00fb47d6", "message": "sds\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "683cf641b3b84c75858d28950653dcb5c526adc3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/683cf641b3b84c75858d28950653dcb5c526adc3", "message": "exceptions\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "61c88a6c58a3b515eccca7d620aa128f192727d4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/61c88a6c58a3b515eccca7d620aa128f192727d4", "message": "done\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "1ff1560d339af68e38b497e676ed7f847bb349b7", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1ff1560d339af68e38b497e676ed7f847bb349b7", "message": "ds\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "b9e4a0e926c0102ca69eb3cafadda43a7e9bff75", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b9e4a0e926c0102ca69eb3cafadda43a7e9bff75", "message": "this\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "ab78bbec5d646b8a9672d92f6cb4a1a4ccf18f3b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ab78bbec5d646b8a9672d92f6cb4a1a4ccf18f3b", "message": "dpj\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "163425f0d185336b2edefd0b9f3c1e96d613bce8", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/163425f0d185336b2edefd0b9f3c1e96d613bce8", "message": "last change\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "237b7528382790286d1251af98c3069a6043a497", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/237b7528382790286d1251af98c3069a6043a497", "message": "Tom commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "f674e4ccfd53635b09216a64c39c276b73d5f714", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f674e4ccfd53635b09216a64c39c276b73d5f714", "message": "check\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "2ab3dceb6eaf4cfdbb324bccef2375b20ece2a95", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2ab3dceb6eaf4cfdbb324bccef2375b20ece2a95", "message": "user prefix\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T10:56:40Z", "type": "commit"}, {"oid": "9b9106c92559dee1288b5f9176a211ba4c47948f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9b9106c92559dee1288b5f9176a211ba4c47948f", "message": "rebase\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T14:34:28Z", "type": "commit"}, {"oid": "9b9106c92559dee1288b5f9176a211ba4c47948f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9b9106c92559dee1288b5f9176a211ba4c47948f", "message": "rebase\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T14:34:28Z", "type": "forcePushed"}, {"oid": "f2ce488bde5d2749f61f27611840297fef8c6542", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f2ce488bde5d2749f61f27611840297fef8c6542", "message": "last\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-09-08T17:41:28Z", "type": "commit"}]}