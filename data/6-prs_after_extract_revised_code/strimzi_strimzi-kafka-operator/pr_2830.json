{"pr_number": 2830, "pr_title": "[MO] - [system test] -> additional properties of `SSL`", "pr_createdAt": "2020-04-14T14:45:08Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408206078", "bodyText": "If I read the test correctly ... the configWithLowestVersionOfTls is not compatible with configWithNewestVersionOfTls ... so this should fail and you need to test that it fails IMHO?", "author": "scholzj", "createdAt": "2020-04-14T14:59:30Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        PodUtils.waitUntilPodIsPresent(KafkaConnectResources.deploymentName(CLUSTER_NAME)); // pod is not ready...", "originalCommit": "4496a4c4310559fc9cabbdcd210f1766e658ba40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ1NTU0Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408455543", "bodyText": "So, I do not want to verify it via logs in the Kafka connect pod, which is not a reliable option and can cost us flakiness. Actually, if the test will not work we will be able to find the bug\nPodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));  -> if the bug will be present this method will failed because Kafka Connect pod will not be ready.\nDo you have some though? How to specifically verify it without using logs?", "author": "see-quick", "createdAt": "2020-04-14T21:46:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ1NTczMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408455730", "bodyText": "So, I do not want to verify it via logs in the Kafka connect pod, which is not a reliable option and can cost us flakiness. Actually, if the test will not work we will be able to find the bug\nPodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME)); ->\nIf the bug will be present this method will fail because Kafka Connect pod will not be ready.\nDo you have some though? How to specifically verify it without using logs?", "author": "see-quick", "createdAt": "2020-04-14T21:47:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ2NzEwNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408467106", "bodyText": "Well, when you deploy it with wrong configuration, the pod will not get ready. So you should at least check whether that is in the status before fixing the configuration and checking that it gets fixed. That was what I was thinking about.", "author": "scholzj", "createdAt": "2020-04-14T22:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODc4NzcxNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408787714", "bodyText": "Yeah... I have done it.", "author": "see-quick", "createdAt": "2020-04-15T12:00:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}], "type": "inlineReview", "revised_code": {"commit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java\ndeleted file mode 100644\nindex 60787165d0..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,92 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        PodUtils.waitUntilPodIsPresent(KafkaConnectResources.deploymentName(CLUSTER_NAME)); // pod is not ready...\n-\n-        LOGGER.info(\"Replacing Kafka connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        Map<String, Object> configsFromKafkaConnectCustomResource = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka connect has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        LOGGER.info(\"Verifying that Kafka connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjYxNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408206614", "bodyText": "Connect with capital C? Just a detail ...", "author": "scholzj", "createdAt": "2020-04-14T15:00:04Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        PodUtils.waitUntilPodIsPresent(KafkaConnectResources.deploymentName(CLUSTER_NAME)); // pod is not ready...\n+\n+        LOGGER.info(\"Replacing Kafka connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        Map<String, Object> configsFromKafkaConnectCustomResource = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka connect has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        LOGGER.info(\"Verifying that Kafka connect is stable\");", "originalCommit": "4496a4c4310559fc9cabbdcd210f1766e658ba40", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java\ndeleted file mode 100644\nindex 60787165d0..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,92 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        PodUtils.waitUntilPodIsPresent(KafkaConnectResources.deploymentName(CLUSTER_NAME)); // pod is not ready...\n-\n-        LOGGER.info(\"Replacing Kafka connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        Map<String, Object> configsFromKafkaConnectCustomResource = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka connect has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        LOGGER.info(\"Verifying that Kafka connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM5OTg2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409399866", "bodyText": "Shouldn't we reset the counter here?", "author": "Frawless", "createdAt": "2020-04-16T09:06:26Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -233,25 +250,27 @@ public static void waitUntilPodsStability(List<Pod> pods) {\n         int[] stabilityCounter = {0};\n \n         TestUtils.waitFor(\"Waiting for pods stability\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> {\n-                for (Pod pod : pods) {\n-                    if (pod.getStatus().getPhase().equals(\"Running\")) {\n-                        LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n-                            pod.getMetadata().getName(), pod.getStatus().getPhase(),\n-                            Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n-                    } else {\n-                        LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());\n-                        return false;\n-                    }\n-                }\n-                stabilityCounter[0]++;\n+            () -> verifyThatPodsAreStable(pods, stabilityCounter));\n+    }\n \n-                if (stabilityCounter[0] == Constants.GLOBAL_RECONCILIATION_COUNT) {\n-                    LOGGER.info(\"All pods are stable {}\", pods.toString());\n-                    return true;\n-                }\n+    private static boolean verifyThatPodsAreStable(List<Pod> pods, int[] stabilityCounter) {\n+        for (Pod pod : pods) {\n+            if (pod.getStatus().getPhase().equals(\"Running\")) {\n+                LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n+                    pod.getMetadata().getName(), pod.getStatus().getPhase(),\n+                    Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n+            } else {\n+                LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());", "originalCommit": "c73a91da86ec30fe7ec8b6369ea566ce2b8eb1c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxMjY4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409512689", "bodyText": "Good catch!!!", "author": "see-quick", "createdAt": "2020-04-16T12:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM5OTg2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\nindex 0f43b3cb96..0e8cfcc633 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\n\n@@ -260,7 +260,9 @@ public class PodUtils {\n                     pod.getMetadata().getName(), pod.getStatus().getPhase(),\n                     Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n             } else {\n-                LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());\n+                LOGGER.info(\"Pod {} is not stable in phase following phase {} reset the stability counter from {} to {}\",\n+                    pod.getMetadata().getName(), pod.getStatus().getPhase(), stabilityCounter[0], 0);\n+                stabilityCounter[0] = 0;\n                 return false;\n             }\n         }\n"}}, {"oid": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6950efa8d467f4019340d4ee3495ecf8a9db64be", "message": "[MO] - [commend] -> Jakub\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-16T12:21:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY0NjQ5MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409646491", "bodyText": "I think we should add also a check that the condition is Ready now.", "author": "scholzj", "createdAt": "2020-04-16T15:26:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));", "originalCommit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE2NDk5NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r411164994", "bodyText": "make sense )))", "author": "see-quick", "createdAt": "2020-04-20T07:46:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY0NjQ5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex 0501401dfb..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,151 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY0Njc2NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409646764", "bodyText": "Same as above - you should also check that the KafkaConnect is now ready.", "author": "scholzj", "createdAt": "2020-04-16T15:26:41Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n+    }\n+\n+    @Test\n+    void testKafkaAndKafkaConnectCipherSuites() {\n+        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n+\n+        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n+        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n+\n+        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithCipherSuitesSha384)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n+\n+        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n+\n+        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithCipherSuitesSha256)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));", "originalCommit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex 0501401dfb..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,151 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM5ODkyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416398923", "bodyText": "I always try to start my method Javadocs with a verb (gets, waits, calculates etc), that tends to ensure that the first sentence is concise and to the point.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed\n          \n          \n            \n                 * Waits until the kafka connect CR config has changed.", "author": "tombentley", "createdAt": "2020-04-28T07:42:14Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -53,4 +53,22 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN\n         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,\n                 \"\\\"Sending messages\\\": \\\"Hello-world - 99\\\"\");\n     }\n+\n+    /**\n+     *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\nindex 4a90093a32..741b6d731a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n\n@@ -19,56 +20,43 @@ public class KafkaConnectUtils {\n \n     private KafkaConnectUtils() {}\n \n-    public static void createFileSinkConnector(String podName, String topicName, String sinkFileName, String apiUrl) {\n-        cmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\",\n-            \"curl -X POST -H \\\"Content-Type: application/json\\\" \" + \"--data '{ \\\"name\\\": \\\"sink-test\\\", \" +\n-                \"\\\"config\\\": \" + \"{ \\\"connector.class\\\": \\\"FileStreamSink\\\", \" +\n-                \"\\\"tasks.max\\\": \\\"1\\\", \\\"topics\\\": \\\"\" + topicName + \"\\\",\" + \" \\\"file\\\": \\\"\" + sinkFileName + \"\\\" } }' \" +\n-                    apiUrl + \"/connectors\"\n-        );\n+    /**\n+     * Wait until the given Kafka Connect is in desired state.\n+     * @param clusterName name of KafkaConnect cluster\n+     * @param status desired state\n+     */\n+    public static void waitForConnectStatus(String clusterName, String status) {\n+        LOGGER.info(\"Waiting for Kafka Connect {} state: {}\", clusterName, status);\n+        TestUtils.waitFor(\"Kafka Connect \" + clusterName + \" state: \" + status, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,\n+            () -> KafkaConnectResource.kafkaConnectClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getStatus().getConditions().get(0).getType().equals(status),\n+            () -> StUtils.logCurrentStatus(KafkaConnectResource.kafkaConnectClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get()));\n+        LOGGER.info(\"Kafka Connect {} is in desired state: {}\", clusterName, status);\n+    }\n+\n+    public static void waitForConnectReady(String clusterName) {\n+        waitForConnectStatus(clusterName, \"Ready\");\n     }\n \n-    public static void waitForConnectStatus(String name, String status) {\n-        LOGGER.info(\"Waiting for Kafka Connect {} state: {}\", name, status);\n-        TestUtils.waitFor(\"Kafka Connect \" + name + \" state: \" + status, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,\n-            () -> KafkaConnectResource.kafkaConnectClient().inNamespace(kubeClient().getNamespace()).withName(name).get().getStatus().getConditions().get(0).getType().equals(status));\n-        LOGGER.info(\"Kafka Connect {} is in desired state: {}\", name, status);\n+    public static void waitForConnectNotReady(String clusterName) {\n+        waitForConnectStatus(clusterName, \"NotReady\");\n     }\n \n     public static void waitUntilKafkaConnectRestApiIsAvailable(String podNamePrefix) {\n-        LOGGER.info(\"Waiting until kafka connect service is present\");\n-        TestUtils.waitFor(\"Waiting until kafka connect service is present\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,\n+        LOGGER.info(\"Waiting until KafkaConnect API is available\");\n+        TestUtils.waitFor(\"Waiting until KafkaConnect API is available\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,\n             () -> cmdKubeClient().execInPod(podNamePrefix, \"/bin/bash\", \"-c\", \"curl -I http://localhost:8083/connectors\").out().contains(\"HTTP/1.1 200 OK\\n\"));\n-        LOGGER.info(\"Kafka connect service is present\");\n+        LOGGER.info(\"KafkaConnect API is available\");\n     }\n \n     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName, String message) {\n-        LOGGER.info(\"Waiting for messages in file sink\");\n+        LOGGER.info(\"Waiting for messages in file sink on {}\", kafkaConnectPodName);\n         TestUtils.waitFor(\"messages in file sink\", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_SEND_RECEIVE_MSG,\n             () -> cmdKubeClient().execInPod(kafkaConnectPodName, \"/bin/bash\", \"-c\", \"cat \" + sinkFileName).out().contains(message));\n-        LOGGER.info(\"Expected messages are in file sink\");\n+        LOGGER.info(\"Expected messages are in file sink on {}\", kafkaConnectPodName);\n     }\n \n     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName) {\n         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,\n                 \"\\\"Sending messages\\\": \\\"Hello-world - 99\\\"\");\n     }\n-\n-    /**\n-     *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed\n-     * @param propertyKey property key in the Kafka Connect CR config\n-     * @param propertyValue property value in the Kafka Connect CR config\n-     * @param namespace namespace name\n-     * @param clusterName cluster name\n-     */\n-    public static void waitForKafkaConnectConfigChange(String propertyKey, String propertyValue, String namespace, String clusterName) {\n-        LOGGER.info(\"Waiting for Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n-        TestUtils.waitFor(\"Waiting for Kafka Connect config \" + propertyKey + \" -> \" + propertyValue, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> {\n-                LOGGER.debug(\"Property key -> {}, Current property value -> {}\", propertyKey, KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey));\n-                LOGGER.debug(KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey) + \" == \" + propertyValue);\n-                return KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey).equals(propertyValue);\n-            });\n-        LOGGER.info(\"Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMDgxOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416400819", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Method waitUntilPodsByNameStability ensuring for every pod listed for kafka or zookeeper statefulSet will be controlling\n          \n          \n            \n                 * their status in Running phase. If the pod will be running for selected time #Constants.GLOBAL_RECONCILIATION_COUNT\n          \n          \n            \n                 * pod is considered as a stable. Otherwise this procedure will be repeat.\n          \n          \n            \n                 * Waits until all matching pods are {@linkplain #verifyThatPodsAreStable(List, int) stable} in the \"Running\" phase.", "author": "tombentley", "createdAt": "2020-04-28T07:45:16Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -223,6 +224,22 @@ public static void waitUntilPodLabelsDeletion(String podName, String... labelKey\n         }\n     }\n \n+    /**\n+     * Method waitUntilPodsByNameStability ensuring for every pod listed for kafka or zookeeper statefulSet will be controlling\n+     * their status in Running phase. If the pod will be running for selected time #Constants.GLOBAL_RECONCILIATION_COUNT\n+     * pod is considered as a stable. Otherwise this procedure will be repeat.", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\nindex 0e8cfcc633..1f1f727137 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\n\n@@ -215,12 +224,12 @@ public class PodUtils {\n \n     public static void waitUntilPodLabelsDeletion(String podName, String... labelKeys) {\n         for (final String labelKey : labelKeys) {\n-            LOGGER.info(\"Waiting for Kafka pod label {} change to {}\", labelKey, null);\n-            TestUtils.waitFor(\"Waiting for Kafka pod label\" + labelKey + \" change to \" + null, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS,\n+            LOGGER.info(\"Waiting for Pod label {} change to {}\", labelKey, null);\n+            TestUtils.waitFor(\"Pod label\" + labelKey + \" change to \" + null, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS,\n                 Constants.TIMEOUT_FOR_RESOURCE_READINESS, () ->\n                     kubeClient().getPod(podName).getMetadata().getLabels().get(labelKey) == null\n             );\n-            LOGGER.info(\"Kafka pod label {} change to {}\", labelKey, null);\n+            LOGGER.info(\"Pod label {} changed to {}\", labelKey, null);\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMTkyNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416401927", "bodyText": "It's a bit confusing that this Constants.GLOBAL_RECONCILIATION_COUNT is called a count when according to that logging it's actually a number of seconds. I think you're relying on the caller invoking this from a waitFor() which is polling once per second. I guess that's OK since this is a private method, but I wonder if this contract could be improved.\nI guess the two callers are basically the same except for how they supply the List<Pod>, right? So why not:\n\nChange the List<Pod> pods to Supplier<List<Pod>> pods\nMove the waitFor and the int[] stabilityCounter = {0}; from the callers into this method.\nCall the Supplier each time in the waitFor\n\nThat way the poll interval is defined in the same method as how you're using the stabilityCounter.", "author": "tombentley", "createdAt": "2020-04-28T07:46:54Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -233,25 +250,29 @@ public static void waitUntilPodsStability(List<Pod> pods) {\n         int[] stabilityCounter = {0};\n \n         TestUtils.waitFor(\"Waiting for pods stability\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> {\n-                for (Pod pod : pods) {\n-                    if (pod.getStatus().getPhase().equals(\"Running\")) {\n-                        LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n-                            pod.getMetadata().getName(), pod.getStatus().getPhase(),\n-                            Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n-                    } else {\n-                        LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());\n-                        return false;\n-                    }\n-                }\n-                stabilityCounter[0]++;\n+            () -> verifyThatPodsAreStable(pods, stabilityCounter));\n+    }\n \n-                if (stabilityCounter[0] == Constants.GLOBAL_RECONCILIATION_COUNT) {\n-                    LOGGER.info(\"All pods are stable {}\", pods.toString());\n-                    return true;\n-                }\n+    private static boolean verifyThatPodsAreStable(List<Pod> pods, int[] stabilityCounter) {\n+        for (Pod pod : pods) {\n+            if (pod.getStatus().getPhase().equals(\"Running\")) {\n+                LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n+                    pod.getMetadata().getName(), pod.getStatus().getPhase(),\n+                    Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ5MjA0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416492042", "bodyText": "Thanks )", "author": "see-quick", "createdAt": "2020-04-28T10:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMTkyNw=="}], "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\nindex 0e8cfcc633..1f1f727137 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java\n\n@@ -249,8 +258,29 @@ public class PodUtils {\n     public static void waitUntilPodsStability(List<Pod> pods) {\n         int[] stabilityCounter = {0};\n \n-        TestUtils.waitFor(\"Waiting for pods stability\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> verifyThatPodsAreStable(pods, stabilityCounter));\n+        TestUtils.waitFor(\"Pods stability\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> {\n+                List<Pod> actualPods = pods.stream().map(p -> kubeClient().getPod(p.getMetadata().getName())).collect(Collectors.toList());\n+\n+                for (Pod pod : actualPods) {\n+                    if (pod.getStatus().getPhase().equals(\"Running\")) {\n+                        LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n+                            pod.getMetadata().getName(), pod.getStatus().getPhase(),\n+                            Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n+                    } else {\n+                        LOGGER.info(\"Pod {} is not stable with phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());\n+                        stabilityCounter[0] = 0;\n+                        return false;\n+                    }\n+                }\n+                stabilityCounter[0]++;\n+\n+                if (stabilityCounter[0] == Constants.GLOBAL_RECONCILIATION_COUNT) {\n+                    LOGGER.info(\"All pods are stable {}\", pods.stream().map(p -> p.getMetadata().getName()).collect(Collectors.joining(\" ,\")));\n+                    return true;\n+                }\n+                return false;\n+            });\n     }\n \n     private static boolean verifyThatPodsAreStable(List<Pod> pods, int[] stabilityCounter) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNjA5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416406098", "bodyText": "Do you mean accepted rather than excepted?", "author": "tombentley", "createdAt": "2020-04-28T07:53:44Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex bffe91f498..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,159 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNjUzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416406536", "bodyText": "Why using + when you could interpolate with {}?", "author": "tombentley", "createdAt": "2020-04-28T07:54:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex bffe91f498..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,159 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzEzMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416407133", "bodyText": "Should we also assert on the NotReady reason?", "author": "tombentley", "createdAt": "2020-04-28T07:55:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQzNzUxNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416437516", "bodyText": "I think, there is no need to assert value. This dynamic wait just ensures the CR of Kafka Connect will be in the desired state.", "author": "see-quick", "createdAt": "2020-04-28T08:42:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzEzMw=="}], "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex bffe91f498..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,159 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzYxMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416407610", "bodyText": "Similar comments", "author": "tombentley", "createdAt": "2020-04-28T07:56:05Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n+    }\n+\n+    @Test\n+    void testKafkaAndKafkaConnectCipherSuites() {\n+        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n+\n+        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n+        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n+\n+        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithCipherSuitesSha384)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex bffe91f498..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,159 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzg0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416407842", "bodyText": "Again why +", "author": "tombentley", "createdAt": "2020-04-28T07:56:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n+    }\n+\n+    @Test\n+    void testKafkaAndKafkaConnectCipherSuites() {\n+        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n+\n+        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n+        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n+\n+        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithCipherSuitesSha384)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n+\n+        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n+\n+        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithCipherSuitesSha256)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex bffe91f498..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,159 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwODAxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416408015", "bodyText": "Again, why +?", "author": "tombentley", "createdAt": "2020-04-28T07:56:42Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java b/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\ndeleted file mode 100644\nindex bffe91f498..0000000000\n--- a/systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java\n+++ /dev/null\n\n@@ -1,159 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.systemtest.security;\n-\n-import io.strimzi.api.kafka.model.KafkaConnectResources;\n-import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n-import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n-import io.strimzi.systemtest.resources.crd.KafkaResource;\n-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n-import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n-import org.apache.kafka.common.config.SslConfigs;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.Tag;\n-import org.junit.jupiter.api.Test;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import static io.strimzi.systemtest.Constants.REGRESSION;\n-import static org.hamcrest.MatcherAssert.assertThat;\n-import static org.hamcrest.CoreMatchers.is;\n-\n-@Tag(REGRESSION)\n-public class SslConfigurationST extends SecurityST {\n-\n-    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n-\n-    @Test\n-    void testKafkaAndKafkaConnectTlsVersion() {\n-\n-        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n-\n-        final String tlsVersion12 = \"TLSv1.2\";\n-        final String tlsVersion1 = \"TLSv1\";\n-\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n-        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithNewestVersionOfTls)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n-                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n-                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n-\n-        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n-\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n-        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithLowestVersionOfTls)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n-            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-\n-    @Test\n-    void testKafkaAndKafkaConnectCipherSuites() {\n-        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n-\n-        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n-        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n-\n-        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n-\n-        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n-\n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-            .editSpec()\n-                .editKafka()\n-                    .withConfig(configWithCipherSuitesSha384)\n-                .endKafka()\n-            .endSpec()\n-            .done();\n-\n-        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n-\n-        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n-            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n-\n-        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n-\n-        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n-\n-        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n-\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-            .editSpec()\n-                .withConfig(configWithCipherSuitesSha256)\n-            .endSpec()\n-            .build());\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n-\n-        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n-\n-        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n-            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n-\n-        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n-\n-        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n-\n-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n-\n-        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm\");\n-\n-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQxMTQ5NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416411494", "bodyText": "You should factor out a local variable for KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey)", "author": "tombentley", "createdAt": "2020-04-28T08:02:09Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -53,4 +53,22 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN\n         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,\n                 \"\\\"Sending messages\\\": \\\"Hello-world - 99\\\"\");\n     }\n+\n+    /**\n+     *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed\n+     * @param propertyKey property key in the Kafka Connect CR config\n+     * @param propertyValue property value in the Kafka Connect CR config\n+     * @param namespace namespace name\n+     * @param clusterName cluster name\n+     */\n+    public static void waitForKafkaConnectConfigChange(String propertyKey, String propertyValue, String namespace, String clusterName) {\n+        LOGGER.info(\"Waiting for Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n+        TestUtils.waitFor(\"Waiting for Kafka Connect config \" + propertyKey + \" -> \" + propertyValue, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> {\n+                LOGGER.debug(\"Property key -> {}, Current property value -> {}\", propertyKey, KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey));\n+                LOGGER.debug(KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey) + \" == \" + propertyValue);\n+                return KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey).equals(propertyValue);", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\nindex 4a90093a32..741b6d731a 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n\n@@ -19,56 +20,43 @@ public class KafkaConnectUtils {\n \n     private KafkaConnectUtils() {}\n \n-    public static void createFileSinkConnector(String podName, String topicName, String sinkFileName, String apiUrl) {\n-        cmdKubeClient().execInPod(podName, \"/bin/bash\", \"-c\",\n-            \"curl -X POST -H \\\"Content-Type: application/json\\\" \" + \"--data '{ \\\"name\\\": \\\"sink-test\\\", \" +\n-                \"\\\"config\\\": \" + \"{ \\\"connector.class\\\": \\\"FileStreamSink\\\", \" +\n-                \"\\\"tasks.max\\\": \\\"1\\\", \\\"topics\\\": \\\"\" + topicName + \"\\\",\" + \" \\\"file\\\": \\\"\" + sinkFileName + \"\\\" } }' \" +\n-                    apiUrl + \"/connectors\"\n-        );\n+    /**\n+     * Wait until the given Kafka Connect is in desired state.\n+     * @param clusterName name of KafkaConnect cluster\n+     * @param status desired state\n+     */\n+    public static void waitForConnectStatus(String clusterName, String status) {\n+        LOGGER.info(\"Waiting for Kafka Connect {} state: {}\", clusterName, status);\n+        TestUtils.waitFor(\"Kafka Connect \" + clusterName + \" state: \" + status, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,\n+            () -> KafkaConnectResource.kafkaConnectClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getStatus().getConditions().get(0).getType().equals(status),\n+            () -> StUtils.logCurrentStatus(KafkaConnectResource.kafkaConnectClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get()));\n+        LOGGER.info(\"Kafka Connect {} is in desired state: {}\", clusterName, status);\n+    }\n+\n+    public static void waitForConnectReady(String clusterName) {\n+        waitForConnectStatus(clusterName, \"Ready\");\n     }\n \n-    public static void waitForConnectStatus(String name, String status) {\n-        LOGGER.info(\"Waiting for Kafka Connect {} state: {}\", name, status);\n-        TestUtils.waitFor(\"Kafka Connect \" + name + \" state: \" + status, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,\n-            () -> KafkaConnectResource.kafkaConnectClient().inNamespace(kubeClient().getNamespace()).withName(name).get().getStatus().getConditions().get(0).getType().equals(status));\n-        LOGGER.info(\"Kafka Connect {} is in desired state: {}\", name, status);\n+    public static void waitForConnectNotReady(String clusterName) {\n+        waitForConnectStatus(clusterName, \"NotReady\");\n     }\n \n     public static void waitUntilKafkaConnectRestApiIsAvailable(String podNamePrefix) {\n-        LOGGER.info(\"Waiting until kafka connect service is present\");\n-        TestUtils.waitFor(\"Waiting until kafka connect service is present\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,\n+        LOGGER.info(\"Waiting until KafkaConnect API is available\");\n+        TestUtils.waitFor(\"Waiting until KafkaConnect API is available\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,\n             () -> cmdKubeClient().execInPod(podNamePrefix, \"/bin/bash\", \"-c\", \"curl -I http://localhost:8083/connectors\").out().contains(\"HTTP/1.1 200 OK\\n\"));\n-        LOGGER.info(\"Kafka connect service is present\");\n+        LOGGER.info(\"KafkaConnect API is available\");\n     }\n \n     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName, String message) {\n-        LOGGER.info(\"Waiting for messages in file sink\");\n+        LOGGER.info(\"Waiting for messages in file sink on {}\", kafkaConnectPodName);\n         TestUtils.waitFor(\"messages in file sink\", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_SEND_RECEIVE_MSG,\n             () -> cmdKubeClient().execInPod(kafkaConnectPodName, \"/bin/bash\", \"-c\", \"cat \" + sinkFileName).out().contains(message));\n-        LOGGER.info(\"Expected messages are in file sink\");\n+        LOGGER.info(\"Expected messages are in file sink on {}\", kafkaConnectPodName);\n     }\n \n     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName) {\n         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,\n                 \"\\\"Sending messages\\\": \\\"Hello-world - 99\\\"\");\n     }\n-\n-    /**\n-     *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed\n-     * @param propertyKey property key in the Kafka Connect CR config\n-     * @param propertyValue property value in the Kafka Connect CR config\n-     * @param namespace namespace name\n-     * @param clusterName cluster name\n-     */\n-    public static void waitForKafkaConnectConfigChange(String propertyKey, String propertyValue, String namespace, String clusterName) {\n-        LOGGER.info(\"Waiting for Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n-        TestUtils.waitFor(\"Waiting for Kafka Connect config \" + propertyKey + \" -> \" + propertyValue, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> {\n-                LOGGER.debug(\"Property key -> {}, Current property value -> {}\", propertyKey, KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey));\n-                LOGGER.debug(KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey) + \" == \" + propertyValue);\n-                return KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey).equals(propertyValue);\n-            });\n-        LOGGER.info(\"Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n-    }\n }\n"}}, {"oid": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "message": "[MO] - [system test] -> ssl\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "89410e3705ccd09839157945c01aaeef8e189c77", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/89410e3705ccd09839157945c01aaeef8e189c77", "message": "[MO] - [commends] -> Jakub\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "66e7c730a0c534f3449eedc99dc47be288de7add", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/66e7c730a0c534f3449eedc99dc47be288de7add", "message": "[MO] -s\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "12b270dc334950ce97e7593bd5f671662047e207", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/12b270dc334950ce97e7593bd5f671662047e207", "message": "[MO] - [cipher] -> adding test case for cipher version\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "6235d85c88e4216f22737f97cbcb59d45e3654c4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6235d85c88e4216f22737f97cbcb59d45e3654c4", "message": "[MO] - [tag] -> regression\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "c2ad735bbf54ae2e78730189a1c4851c255b23cc", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c2ad735bbf54ae2e78730189a1c4851c255b23cc", "message": "s\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "5c8994c8fb6cef1d4397245ffee97ced47a43f1e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5c8994c8fb6cef1d4397245ffee97ced47a43f1e", "message": "[MO] - [commend] -> Jakub\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "9ee3a8d1cbb12d6ebab8995a88d823dd919d62d2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9ee3a8d1cbb12d6ebab8995a88d823dd919d62d2", "message": "[MO] - [jakub] -> commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "070db9a6f21e1d9d421abe6d55558f105c1c1113", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/070db9a6f21e1d9d421abe6d55558f105c1c1113", "message": "Tom's suggestion\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-04-28T10:16:21Z", "type": "commit"}, {"oid": "4704d55f276d075067c38801fe0aba940dd73ffa", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4704d55f276d075067c38801fe0aba940dd73ffa", "message": "[MO] -[ ss\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:16:21Z", "type": "commit"}, {"oid": "b2e626d126485b8c1ddccc53539c66b6701d0b35", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2e626d126485b8c1ddccc53539c66b6701d0b35", "message": "ss\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:16:58Z", "type": "commit"}, {"oid": "b2e626d126485b8c1ddccc53539c66b6701d0b35", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2e626d126485b8c1ddccc53539c66b6701d0b35", "message": "ss\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:16:58Z", "type": "forcePushed"}]}