{"pr_number": 2805, "pr_title": "[systemtest] Upgrade metrics change test", "pr_createdAt": "2020-04-08T12:01:20Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2805", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ3ODgzMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2805#discussion_r405478830", "bodyText": "I think the original test checked that no rolling update happened. But the new test seems to be missing it. Could you add it?", "author": "scholzj", "createdAt": "2020-04-08T12:16:12Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java", "diffHunk": "@@ -912,6 +881,101 @@ void testClusterCaRemovedTriggersRollingUpdate() {\n         assertThat(sentAfter, is(MESSAGE_COUNT));\n     }\n \n+    @Test\n+    void testMetricsChange() throws InterruptedException, ExecutionException, IOException {\n+        //Kafka\n+        Map<String, Object> kafkaRule = new HashMap<>();\n+        kafkaRule.put(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\");\n+        kafkaRule.put(\"name\", \"kafka_$1_$2_$3_count\");\n+        kafkaRule.put(\"type\", \"COUNTER\");\n+\n+        Map<String, Object> kafkaMetrics = new HashMap<>();\n+        kafkaMetrics.put(\"lowercaseOutputName\", true);\n+        kafkaMetrics.put(\"rules\", Collections.singletonList(kafkaRule));\n+\n+        //Zookeeper\n+        Map<String, Object> zookeeperLabels = new HashMap<>();\n+        zookeeperLabels.put(\"replicaId\", \"$2\");\n+\n+        Map<String, Object> zookeeperRule = new HashMap<>();\n+        zookeeperRule.put(\"labels\", zookeeperLabels);\n+        zookeeperRule.put(\"name\", \"zookeeper_$3\");\n+        zookeeperRule.put(\"pattern\", \"org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\\\d+), name1=replica.(\\\\d+)><>(\\\\w+)\");\n+\n+        Map<String, Object> zookeeperMetrics = new HashMap<>();\n+        zookeeperMetrics.put(\"lowercaseOutputName\", true);\n+        zookeeperMetrics.put(\"rules\", Collections.singletonList(zookeeperRule));\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withMetrics(kafkaMetrics)\n+                    .endKafka()\n+                    .editOrNewZookeeper()\n+                        .withMetrics(zookeeperMetrics)\n+                    .endZookeeper()\n+                    .withNewKafkaExporter()\n+                    .endKafkaExporter()\n+                .endSpec()\n+                .done();\n+\n+        LOGGER.info(\"Check if metrics are present in pod of Kafka and Zookeeper\");\n+        String kafkaMetricsOutput = MetricsUtils.collectMetrics(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"\");\n+        String zkMetricsOutput = MetricsUtils.collectMetrics(CLUSTER_NAME + \"-zookeeper-0\", \"\");\n+        assertThat(kafkaMetricsOutput, containsString(\"kafka_\"));\n+        assertThat(zkMetricsOutput, containsString(\"replicaId\"));\n+\n+        LOGGER.info(\"Changing metrics to something else\");\n+        kafkaRule.replace(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\",\n+                \"kafka.(\\\\w+)<type=(.+), name=(.+)Percent\\\\w*><>MeanRate\");\n+        kafkaRule.replace(\"name\", \"kafka_$1_$2_$3_count\", \"kafka_$1_$2_$3_percent\");\n+        kafkaRule.replace(\"type\", \"COUNTER\", \"GAUGE\");\n+\n+        zookeeperRule.replace(\"pattern\",\n+                \"org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\\\d+), name1=replica.(\\\\d+)><>(\\\\w+)\",\n+                \"org.apache.ZooKeeperService<name0=StandaloneServer_port(\\\\d+)><>(\\\\w+)\");\n+        zookeeperRule.replace(\"name\", \"zookeeper_$3\", \"zookeeper_$2\");\n+        zookeeperRule.replace(\"labels\", zookeeperLabels, null);\n+\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setMetrics(kafkaMetrics);\n+            kafka.getSpec().getZookeeper().setMetrics(zookeeperMetrics);\n+        });\n+\n+        LOGGER.info(\"Check if Kafka and Zookeeper metrics are changed\");", "originalCommit": "a3092d11f3cbcff81e2aa363c43fc5755efa5817", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ4NjUxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2805#discussion_r405486515", "bodyText": "Yes I missed it, thanks", "author": "im-konge", "createdAt": "2020-04-08T12:29:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ3ODgzMA=="}], "type": "inlineReview", "revised_code": {"commit": "5277f48ba0f47a6430130003c793be3a54a8657f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java b/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\nindex afa00bcc64..a8f7366d1d 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\n\n@@ -882,7 +880,7 @@ class RollingUpdateST extends BaseST {\n     }\n \n     @Test\n-    void testMetricsChange() throws InterruptedException, ExecutionException, IOException {\n+    void testMetricsChange() {\n         //Kafka\n         Map<String, Object> kafkaRule = new HashMap<>();\n         kafkaRule.put(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ4MDk5Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2805#discussion_r405480992", "bodyText": "I think you can use collectKafkaPodsMetrics, same for zookeeper. Or is there any reason why you didn't use it?", "author": "Frawless", "createdAt": "2020-04-08T12:19:56Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java", "diffHunk": "@@ -912,6 +881,101 @@ void testClusterCaRemovedTriggersRollingUpdate() {\n         assertThat(sentAfter, is(MESSAGE_COUNT));\n     }\n \n+    @Test\n+    void testMetricsChange() throws InterruptedException, ExecutionException, IOException {\n+        //Kafka\n+        Map<String, Object> kafkaRule = new HashMap<>();\n+        kafkaRule.put(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\");\n+        kafkaRule.put(\"name\", \"kafka_$1_$2_$3_count\");\n+        kafkaRule.put(\"type\", \"COUNTER\");\n+\n+        Map<String, Object> kafkaMetrics = new HashMap<>();\n+        kafkaMetrics.put(\"lowercaseOutputName\", true);\n+        kafkaMetrics.put(\"rules\", Collections.singletonList(kafkaRule));\n+\n+        //Zookeeper\n+        Map<String, Object> zookeeperLabels = new HashMap<>();\n+        zookeeperLabels.put(\"replicaId\", \"$2\");\n+\n+        Map<String, Object> zookeeperRule = new HashMap<>();\n+        zookeeperRule.put(\"labels\", zookeeperLabels);\n+        zookeeperRule.put(\"name\", \"zookeeper_$3\");\n+        zookeeperRule.put(\"pattern\", \"org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\\\d+), name1=replica.(\\\\d+)><>(\\\\w+)\");\n+\n+        Map<String, Object> zookeeperMetrics = new HashMap<>();\n+        zookeeperMetrics.put(\"lowercaseOutputName\", true);\n+        zookeeperMetrics.put(\"rules\", Collections.singletonList(zookeeperRule));\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withMetrics(kafkaMetrics)\n+                    .endKafka()\n+                    .editOrNewZookeeper()\n+                        .withMetrics(zookeeperMetrics)\n+                    .endZookeeper()\n+                    .withNewKafkaExporter()\n+                    .endKafkaExporter()\n+                .endSpec()\n+                .done();\n+\n+        LOGGER.info(\"Check if metrics are present in pod of Kafka and Zookeeper\");\n+        String kafkaMetricsOutput = MetricsUtils.collectMetrics(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"\");\n+        String zkMetricsOutput = MetricsUtils.collectMetrics(CLUSTER_NAME + \"-zookeeper-0\", \"\");\n+        assertThat(kafkaMetricsOutput, containsString(\"kafka_\"));\n+        assertThat(zkMetricsOutput, containsString(\"replicaId\"));\n+\n+        LOGGER.info(\"Changing metrics to something else\");\n+        kafkaRule.replace(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\",\n+                \"kafka.(\\\\w+)<type=(.+), name=(.+)Percent\\\\w*><>MeanRate\");\n+        kafkaRule.replace(\"name\", \"kafka_$1_$2_$3_count\", \"kafka_$1_$2_$3_percent\");\n+        kafkaRule.replace(\"type\", \"COUNTER\", \"GAUGE\");\n+\n+        zookeeperRule.replace(\"pattern\",\n+                \"org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\\\d+), name1=replica.(\\\\d+)><>(\\\\w+)\",\n+                \"org.apache.ZooKeeperService<name0=StandaloneServer_port(\\\\d+)><>(\\\\w+)\");\n+        zookeeperRule.replace(\"name\", \"zookeeper_$3\", \"zookeeper_$2\");\n+        zookeeperRule.replace(\"labels\", zookeeperLabels, null);\n+\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setMetrics(kafkaMetrics);\n+            kafka.getSpec().getZookeeper().setMetrics(zookeeperMetrics);\n+        });\n+\n+        LOGGER.info(\"Check if Kafka and Zookeeper metrics are changed\");\n+        assertThat(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getMetrics(), is(kafkaMetrics));\n+        assertThat(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getZookeeper().getMetrics(), is(zookeeperMetrics));\n+\n+        LOGGER.info(\"Check if metrics are present in pod of Kafka and Zookeeper\");\n+\n+        kafkaMetricsOutput = MetricsUtils.collectMetrics(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"\");\n+        zkMetricsOutput = MetricsUtils.collectMetrics(CLUSTER_NAME + \"-zookeeper-0\", \"\");\n+\n+        assertThat(kafkaMetricsOutput, containsString(\"kafka_\"));\n+        assertThat(zkMetricsOutput, containsString(\"replicaId\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        Map<String, String> zkPods = StatefulSetUtils.ssSnapshot(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Changing metrics to null\");\n+\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setMetrics(null);\n+            kafka.getSpec().getZookeeper().setMetrics(null);\n+        });\n+\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), 3, zkPods);\n+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);\n+\n+        LOGGER.info(\"Check if metrics is empty in pods\");\n+\n+        kafkaMetricsOutput = MetricsUtils.collectMetrics(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"\");", "originalCommit": "a3092d11f3cbcff81e2aa363c43fc5755efa5817", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5277f48ba0f47a6430130003c793be3a54a8657f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java b/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\nindex afa00bcc64..a8f7366d1d 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\n\n@@ -882,7 +880,7 @@ class RollingUpdateST extends BaseST {\n     }\n \n     @Test\n-    void testMetricsChange() throws InterruptedException, ExecutionException, IOException {\n+    void testMetricsChange() {\n         //Kafka\n         Map<String, Object> kafkaRule = new HashMap<>();\n         kafkaRule.put(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTQ4MTM5MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2805#discussion_r405481390", "bodyText": "Maybe you can improve logging, this could pass more info to us", "author": "Frawless", "createdAt": "2020-04-08T12:20:35Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java", "diffHunk": "@@ -912,6 +881,101 @@ void testClusterCaRemovedTriggersRollingUpdate() {\n         assertThat(sentAfter, is(MESSAGE_COUNT));\n     }\n \n+    @Test\n+    void testMetricsChange() throws InterruptedException, ExecutionException, IOException {\n+        //Kafka\n+        Map<String, Object> kafkaRule = new HashMap<>();\n+        kafkaRule.put(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\");\n+        kafkaRule.put(\"name\", \"kafka_$1_$2_$3_count\");\n+        kafkaRule.put(\"type\", \"COUNTER\");\n+\n+        Map<String, Object> kafkaMetrics = new HashMap<>();\n+        kafkaMetrics.put(\"lowercaseOutputName\", true);\n+        kafkaMetrics.put(\"rules\", Collections.singletonList(kafkaRule));\n+\n+        //Zookeeper\n+        Map<String, Object> zookeeperLabels = new HashMap<>();\n+        zookeeperLabels.put(\"replicaId\", \"$2\");\n+\n+        Map<String, Object> zookeeperRule = new HashMap<>();\n+        zookeeperRule.put(\"labels\", zookeeperLabels);\n+        zookeeperRule.put(\"name\", \"zookeeper_$3\");\n+        zookeeperRule.put(\"pattern\", \"org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\\\d+), name1=replica.(\\\\d+)><>(\\\\w+)\");\n+\n+        Map<String, Object> zookeeperMetrics = new HashMap<>();\n+        zookeeperMetrics.put(\"lowercaseOutputName\", true);\n+        zookeeperMetrics.put(\"rules\", Collections.singletonList(zookeeperRule));\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withMetrics(kafkaMetrics)\n+                    .endKafka()\n+                    .editOrNewZookeeper()\n+                        .withMetrics(zookeeperMetrics)\n+                    .endZookeeper()\n+                    .withNewKafkaExporter()\n+                    .endKafkaExporter()\n+                .endSpec()\n+                .done();\n+\n+        LOGGER.info(\"Check if metrics are present in pod of Kafka and Zookeeper\");\n+        String kafkaMetricsOutput = MetricsUtils.collectMetrics(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"\");\n+        String zkMetricsOutput = MetricsUtils.collectMetrics(CLUSTER_NAME + \"-zookeeper-0\", \"\");\n+        assertThat(kafkaMetricsOutput, containsString(\"kafka_\"));\n+        assertThat(zkMetricsOutput, containsString(\"replicaId\"));\n+\n+        LOGGER.info(\"Changing metrics to something else\");\n+        kafkaRule.replace(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\",\n+                \"kafka.(\\\\w+)<type=(.+), name=(.+)Percent\\\\w*><>MeanRate\");\n+        kafkaRule.replace(\"name\", \"kafka_$1_$2_$3_count\", \"kafka_$1_$2_$3_percent\");\n+        kafkaRule.replace(\"type\", \"COUNTER\", \"GAUGE\");\n+\n+        zookeeperRule.replace(\"pattern\",\n+                \"org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\\\d+), name1=replica.(\\\\d+)><>(\\\\w+)\",\n+                \"org.apache.ZooKeeperService<name0=StandaloneServer_port(\\\\d+)><>(\\\\w+)\");\n+        zookeeperRule.replace(\"name\", \"zookeeper_$3\", \"zookeeper_$2\");\n+        zookeeperRule.replace(\"labels\", zookeeperLabels, null);\n+\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {\n+            kafka.getSpec().getKafka().setMetrics(kafkaMetrics);\n+            kafka.getSpec().getZookeeper().setMetrics(zookeeperMetrics);\n+        });\n+\n+        LOGGER.info(\"Check if Kafka and Zookeeper metrics are changed\");\n+        assertThat(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getMetrics(), is(kafkaMetrics));\n+        assertThat(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getZookeeper().getMetrics(), is(zookeeperMetrics));\n+\n+        LOGGER.info(\"Check if metrics are present in pod of Kafka and Zookeeper\");\n+\n+        kafkaMetricsOutput = MetricsUtils.collectMetrics(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), \"\");\n+        zkMetricsOutput = MetricsUtils.collectMetrics(CLUSTER_NAME + \"-zookeeper-0\", \"\");\n+\n+        assertThat(kafkaMetricsOutput, containsString(\"kafka_\"));\n+        assertThat(zkMetricsOutput, containsString(\"replicaId\"));\n+\n+        Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));\n+        Map<String, String> zkPods = StatefulSetUtils.ssSnapshot(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Changing metrics to null\");", "originalCommit": "a3092d11f3cbcff81e2aa363c43fc5755efa5817", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5277f48ba0f47a6430130003c793be3a54a8657f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java b/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\nindex afa00bcc64..a8f7366d1d 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java\n\n@@ -882,7 +880,7 @@ class RollingUpdateST extends BaseST {\n     }\n \n     @Test\n-    void testMetricsChange() throws InterruptedException, ExecutionException, IOException {\n+    void testMetricsChange() {\n         //Kafka\n         Map<String, Object> kafkaRule = new HashMap<>();\n         kafkaRule.put(\"pattern\", \"kafka.(\\\\w+)<type=(.+), name=(.+)><>Count\");\n"}}, {"oid": "5277f48ba0f47a6430130003c793be3a54a8657f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5277f48ba0f47a6430130003c793be3a54a8657f", "message": "upgrade our metrics change test\n\nSigned-off-by: Lukas Kral <lkral@redhat.com>", "committedDate": "2020-04-08T14:49:10Z", "type": "commit"}, {"oid": "5277f48ba0f47a6430130003c793be3a54a8657f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5277f48ba0f47a6430130003c793be3a54a8657f", "message": "upgrade our metrics change test\n\nSigned-off-by: Lukas Kral <lkral@redhat.com>", "committedDate": "2020-04-08T14:49:10Z", "type": "forcePushed"}]}