{"pr_number": 2548, "pr_title": "ST: Add tests for cover topics recovery from PV", "pr_createdAt": "2020-02-13T15:49:20Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2548", "timeline": [{"oid": "b3fff6b34e2b149d92729afd10eeb9b3e5eb61a2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b3fff6b34e2b149d92729afd10eeb9b3e5eb61a2", "message": "Add tests for cover topics recovery from PV\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-15T23:16:05Z", "type": "commit"}, {"oid": "17aa325e487dce3cd5a138d564a6ccd2aa56bba4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/17aa325e487dce3cd5a138d564a6ccd2aa56bba4", "message": "Add storage class creation\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-15T23:16:05Z", "type": "commit"}, {"oid": "8908d82b03d90e05d62a22ee5281aa62c74d92c2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/8908d82b03d90e05d62a22ee5281aa62c74d92c2", "message": "fixup! Add storage class creation\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-15T23:16:05Z", "type": "commit"}, {"oid": "0877a4cfa3c5bb4ed59b20b205a88914f9b43e88", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0877a4cfa3c5bb4ed59b20b205a88914f9b43e88", "message": "fixup! fixup! Add storage class creation\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-17T07:28:58Z", "type": "commit"}, {"oid": "73bf5537b660782ef0ae37227dc955ec51c5d41d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/73bf5537b660782ef0ae37227dc955ec51c5d41d", "message": "fixup! fixup! fixup! Add storage class creation\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-17T08:28:50Z", "type": "commit"}, {"oid": "73bf5537b660782ef0ae37227dc955ec51c5d41d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/73bf5537b660782ef0ae37227dc955ec51c5d41d", "message": "fixup! fixup! fixup! Add storage class creation\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-17T08:28:50Z", "type": "forcePushed"}, {"oid": "9d54946a1fd4ef84cb0ae2fba3172dbca4e971ea", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9d54946a1fd4ef84cb0ae2fba3172dbca4e971ea", "message": "Add some fixes after maros review\n\nSigned-off-by: Jakub Stejskal <xstejs24@gmail.com>", "committedDate": "2020-02-17T12:38:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1NDIwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2548#discussion_r380954204", "bodyText": "Should you actually check the status or something?", "author": "scholzj", "createdAt": "2020-02-18T21:46:38Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java", "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.recovery;\n+\n+import io.fabric8.kubernetes.api.model.PersistentVolume;\n+import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;\n+import io.fabric8.kubernetes.api.model.storage.StorageClass;\n+import io.fabric8.kubernetes.api.model.storage.StorageClassBuilder;\n+import io.strimzi.api.kafka.model.EntityOperatorSpecBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.KafkaTopic;\n+import io.strimzi.systemtest.BaseST;\n+import io.strimzi.systemtest.Constants;\n+import io.strimzi.systemtest.resources.KubernetesResource;\n+import io.strimzi.systemtest.resources.ResourceManager;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.NamespaceUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.List;\n+import java.util.Random;\n+\n+import static io.strimzi.systemtest.Constants.RECOVERY;\n+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(RECOVERY)\n+class NamespaceDeletionRecoveryST extends BaseST {\n+\n+    static final String NAMESPACE = \"namespace-recovery-cluster-test\";\n+    static final String CLUSTER_NAME = \"recovery-cluster\";\n+\n+    private static final Logger LOGGER = LogManager.getLogger(NamespaceDeletionRecoveryST.class);\n+\n+    private String storageClassName = \"retain\";\n+\n+    @Test\n+    void testTopicAvailable() throws InterruptedException {\n+        String topicName = \"test-topic-\" + new Random().nextInt(Integer.MAX_VALUE);\n+\n+        prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);\n+\n+        // Wait till consumer offset topic is created\n+        KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix(\"consumer-offsets\");\n+        // Get list of topics and list of PVC needed for recovery\n+        List<KafkaTopic> kafkaTopicList = KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).list().getItems();\n+        List<PersistentVolumeClaim> persistentVolumeClaimList = kubeClient().getClient().persistentVolumeClaims().list().getItems();\n+        deleteAndRecreateNamespace();\n+\n+        recreatePvcAndUpdatePv(persistentVolumeClaimList);\n+        recreateClusterOperator();\n+\n+        // Recreate all KafkaTopic resources\n+        for (KafkaTopic kafkaTopic : kafkaTopicList) {\n+            kafkaTopic.getMetadata().setResourceVersion(null);\n+            KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).createOrReplace(kafkaTopic);\n+        }\n+\n+        String consumerGroup = \"group-\" + new Random().nextInt(Integer.MAX_VALUE);\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endKafka()\n+                .editZookeeper()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endZookeeper()\n+            .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+\n+        String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+\n+        internalKafkaClient.setPodName(defaultKafkaClientsPodName);\n+\n+        LOGGER.info(\"Checking produced and consumed messages to pod:{}\", internalKafkaClient.getPodName());\n+        Integer consumed = internalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT, consumerGroup);\n+        assertThat(consumed, is(MESSAGE_COUNT));\n+    }\n+\n+    @Test\n+    void testTopicNotAvailable() throws InterruptedException {\n+        String topicName = \"test-topic-\" + new Random().nextInt(Integer.MAX_VALUE);\n+\n+        prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);\n+\n+        // Wait till consumer offset topic is created\n+        KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix(\"consumer-offsets\");\n+        // Get list of topics and list of PVC needed for recovery\n+        List<PersistentVolumeClaim> persistentVolumeClaimList = kubeClient().getClient().persistentVolumeClaims().list().getItems();\n+        deleteAndRecreateNamespace();\n+        recreatePvcAndUpdatePv(persistentVolumeClaimList);\n+        recreateClusterOperator();\n+\n+        String consumerGroup = \"group-\" + new Random().nextInt(Integer.MAX_VALUE);\n+        // Recreate Kafka Cluster\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endKafka()\n+                .editZookeeper()\n+                    .withNewPersistentClaimStorage()\n+                        .withNewSize(\"100\")\n+                        .withStorageClass(storageClassName)\n+                    .endPersistentClaimStorage()\n+                .endZookeeper()\n+                .withNewEntityOperator()\n+                .endEntityOperator()\n+            .endSpec().done();\n+\n+        // Wait some time after kafka is ready before delete topics files\n+        Thread.sleep(60000);", "originalCommit": "9d54946a1fd4ef84cb0ae2fba3172dbca4e971ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEyNTk3Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2548#discussion_r381125972", "bodyText": "This whould be great, but I am not sure what exactly I can check in that case, because Kafka CR is ready, but when I execute the following command to delete topic data from ZK, I got strange errors as I sent you in offline discussion. Only this way help to solve it. If you have any siggestion what I can check instead of this sleep, I am happy to change it", "author": "Frawless", "createdAt": "2020-02-19T07:56:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk1NDIwNA=="}], "type": "inlineReview", "revised_code": null}]}