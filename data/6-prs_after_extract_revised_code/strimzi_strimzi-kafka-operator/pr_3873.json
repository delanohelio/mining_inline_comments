{"pr_number": 3873, "pr_title": "FIX(Tests) testRackAware (no external clients) & new testRackAwareConnect", "pr_createdAt": "2020-10-26T07:16:14Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgwNzM5Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r511807396", "bodyText": "Why is this in any way relevant only to this ST? Also, sleeping for the whole reconciliation interval could be waste of time. You should check periodically with some small backoff for example to make sure you don't waste time on it.", "author": "scholzj", "createdAt": "2020-10-26T09:05:17Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,6 +100,15 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n+        LOGGER.info(\"Waiting for reconciliation to happen. \" +\n+                \"Giving some time to DNS/load balancer to propagate kafka address.\" +\n+                \"Sleeping for {}ms\", Constants.RECONCILIATION_INTERVAL);\n+        try {\n+            Thread.sleep(Constants.RECONCILIATION_INTERVAL);\n+        } catch (InterruptedException e) {\n+            e.printStackTrace();\n+        }", "originalCommit": "ef35a4e7393c0d91afbdeb2f94c3c95d3435e6c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzI2NTMyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r513265322", "bodyText": "Removed with LB and External clients usage.", "author": "michalxo", "createdAt": "2020-10-28T08:41:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTgwNzM5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "e6907c23439339e2b9636c0eb7d73da2f3bafc79", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex e75925f488..323b82d629 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -100,26 +92,21 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        LOGGER.info(\"Waiting for reconciliation to happen. \" +\n-                \"Giving some time to DNS/load balancer to propagate kafka address.\" +\n-                \"Sleeping for {}ms\", Constants.RECONCILIATION_INTERVAL);\n-        try {\n-            Thread.sleep(Constants.RECONCILIATION_INTERVAL);\n-        } catch (InterruptedException e) {\n-            e.printStackTrace();\n-        }\n-\n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n"}}, {"oid": "e6907c23439339e2b9636c0eb7d73da2f3bafc79", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e6907c23439339e2b9636c0eb7d73da2f3bafc79", "message": "FIX(Tests) TestRackAware do not use load balance w/ ext clients\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-10-26T15:05:44Z", "type": "forcePushed"}, {"oid": "14a3b390216fae011b06b50920aa3a692238c448", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/14a3b390216fae011b06b50920aa3a692238c448", "message": "NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-04T10:45:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMyMDM0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517320340", "bodyText": "I guess ideally you should also deploy some connector and send some messages to verify it is all working and is connected.", "author": "scholzj", "createdAt": "2020-11-04T12:51:13Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ0MDA1OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517440059", "bodyText": "#3917", "author": "git175", "createdAt": "2020-11-04T15:45:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzMyMDM0MA=="}], "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -123,18 +124,19 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(CONNECT)\n+    @Tag(REGRESSION)\n     void testRackAwareConnect() {\n         String wrongRackKey = \"wrong-key\";\n         String rackKey = \"rack-key\";\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n                 .editSpec()\n-                .editKafka()\n-                .withNewRack()\n-                .withTopologyKey(rackKey)\n-                .endRack()\n-                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                .endKafka()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n                 .endSpec().done();\n \n         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwNzc4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517407782", "bodyText": "You should add REGRESSION tag here", "author": "Frawless", "createdAt": "2020-11-04T15:01:27Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -56,8 +69,6 @@\n     public static final String NAMESPACE = \"specific-cluster-test\";\n \n     @Test\n-    @Tag(LOADBALANCER_SUPPORTED)\n-    @Tag(EXTERNAL_CLIENTS_USED)\n     void testRackAware() {", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -69,6 +69,7 @@ public class SpecificST extends AbstractST {\n     public static final String NAMESPACE = \"specific-cluster-test\";\n \n     @Test\n+    @Tag(REGRESSION)\n     void testRackAware() {\n         String rackKey = \"rack-key\";\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwNzg5NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517407894", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-11-04T15:01:36Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -123,18 +124,19 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(CONNECT)\n+    @Tag(REGRESSION)\n     void testRackAwareConnect() {\n         String wrongRackKey = \"wrong-key\";\n         String rackKey = \"rack-key\";\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n                 .editSpec()\n-                .editKafka()\n-                .withNewRack()\n-                .withTopologyKey(rackKey)\n-                .endRack()\n-                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                .endKafka()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n                 .endSpec().done();\n \n         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwODE4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517408189", "bodyText": "Indent", "author": "Frawless", "createdAt": "2020-11-04T15:02:00Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -123,18 +124,19 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(CONNECT)\n+    @Tag(REGRESSION)\n     void testRackAwareConnect() {\n         String wrongRackKey = \"wrong-key\";\n         String rackKey = \"rack-key\";\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n                 .editSpec()\n-                .editKafka()\n-                .withNewRack()\n-                .withTopologyKey(rackKey)\n-                .endRack()\n-                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                .endKafka()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n                 .endSpec().done();\n \n         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwODI3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517408275", "bodyText": "Indent", "author": "Frawless", "createdAt": "2020-11-04T15:02:09Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(wrongRackKey)\n+                .endRack()\n+                .endSpec()\n+                .build());", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -123,18 +124,19 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(CONNECT)\n+    @Tag(REGRESSION)\n     void testRackAwareConnect() {\n         String wrongRackKey = \"wrong-key\";\n         String rackKey = \"rack-key\";\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n                 .editSpec()\n-                .editKafka()\n-                .withNewRack()\n-                .withTopologyKey(rackKey)\n-                .endRack()\n-                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                .endKafka()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n                 .endSpec().done();\n \n         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQwODU0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517408542", "bodyText": "indent", "author": "Frawless", "createdAt": "2020-11-04T15:02:24Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(wrongRackKey)\n+                .endRack()\n+                .endSpec()\n+                .build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n+        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n+        PodUtils.deletePodWithWait(connectWrongPodName);\n+\n+        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 2)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .endSpec()\n+                .done();", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -123,18 +124,19 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(CONNECT)\n+    @Tag(REGRESSION)\n     void testRackAwareConnect() {\n         String wrongRackKey = \"wrong-key\";\n         String rackKey = \"rack-key\";\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n                 .editSpec()\n-                .editKafka()\n-                .withNewRack()\n-                .withTopologyKey(rackKey)\n-                .endRack()\n-                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                .endKafka()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n                 .endSpec().done();\n \n         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxMzMzNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517413337", "bodyText": "Wouldn't be better to check KC status instead of pod status which is set by kubernetes? If there is something useful of course.", "author": "Frawless", "createdAt": "2020-11-04T15:09:07Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +103,84 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    void testRackAwareConnect() {\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                .editKafka()\n+                .withNewRack()\n+                .withTopologyKey(rackKey)\n+                .endRack()\n+                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                .withNewRack()\n+                .withTopologyKey(wrongRackKey)\n+                .endRack()\n+                .endSpec()\n+                .build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();", "originalCommit": "14a3b390216fae011b06b50920aa3a692238c448", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxNzkwNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r517417907", "bodyText": "I will check it out. Thanks for pointer.", "author": "michalxo", "createdAt": "2020-11-04T15:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQxMzMzNw=="}], "type": "inlineReview", "revised_code": {"commit": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex b76a315be7..445e984cb0 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -123,18 +124,19 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(CONNECT)\n+    @Tag(REGRESSION)\n     void testRackAwareConnect() {\n         String wrongRackKey = \"wrong-key\";\n         String rackKey = \"rack-key\";\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n                 .editSpec()\n-                .editKafka()\n-                .withNewRack()\n-                .withTopologyKey(rackKey)\n-                .endRack()\n-                .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                .endKafka()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n                 .endSpec().done();\n \n         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n"}}, {"oid": "9f647c40ef0258e15da6770dcf79def95bfd7ea0", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9f647c40ef0258e15da6770dcf79def95bfd7ea0", "message": "fixup! FIX(Tests) TestRackAware do not use load balance w/ ext clients\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-05T08:08:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEwOTIxMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518109211", "bodyText": "Didn't you had some waitFor methods which can do this in a more efficient way?", "author": "scholzj", "createdAt": "2020-11-05T14:50:39Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +109,120 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnect() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));", "originalCommit": "872a420efbc02018f9b12b676dab17786d08ca09", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a34467fbdc216c9256041ddf74b46f844d33915f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 65f30b60bd..e75925f488 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -109,121 +100,30 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n-        final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n-        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n-                .withUsingPodName(defaultKafkaClientsPodName)\n-                .withTopicName(TOPIC_NAME)\n-                .withNamespaceName(NAMESPACE)\n-                .withClusterName(CLUSTER_NAME)\n-                .withMessageCount(MESSAGE_COUNT)\n-                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n-                .build();\n-\n-        internalKafkaClient.verifyProducedAndConsumedMessages(\n-                internalKafkaClient.sendMessagesPlain(),\n-                internalKafkaClient.receiveMessagesPlain()\n-        );\n-    }\n-\n-    @Test\n-    @Tag(CONNECT)\n-    @Tag(REGRESSION)\n-    void testRackAwareConnect() throws Exception {\n-        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+        LOGGER.info(\"Waiting for reconciliation to happen. \" +\n+                \"Giving some time to DNS/load balancer to propagate kafka address.\" +\n+                \"Sleeping for {}ms\", Constants.RECONCILIATION_INTERVAL);\n+        try {\n+            Thread.sleep(Constants.RECONCILIATION_INTERVAL);\n+        } catch (InterruptedException e) {\n+            e.printStackTrace();\n+        }\n \n-        String wrongRackKey = \"wrong-key\";\n-        String rackKey = \"rack-key\";\n+        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n+            .build();\n \n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-                .editSpec()\n-                    .editKafka()\n-                        .withNewRack()\n-                            .withTopologyKey(rackKey)\n-                        .endRack()\n-                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                    .endKafka()\n-                .endSpec().done();\n-\n-        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n-        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n-\n-        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-                .editSpec()\n-                    .withNewRack()\n-                        .withTopologyKey(wrongRackKey)\n-                    .endRack()\n-                .endSpec().build());\n-\n-        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n-        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n-        String connectWrongPodName = connectWrongPods.get(0);\n-        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n-        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n-\n-        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n-        Condition kcCondition = kc.getStatus().getConditions().get(0);\n-        assertThat(\"NotReady\", is(kcCondition.getType()));\n-        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n-\n-        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n-        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n-        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n-        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n-        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n-        PodUtils.deletePodWithWait(connectWrongPodName);\n-\n-\n-        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n-                .editSpec()\n-                    .withNewRack()\n-                        .withTopologyKey(rackKey)\n-                    .endRack()\n-                    .addToConfig(\"key.converter.schemas.enable\", false)\n-                    .addToConfig(\"value.converter.schemas.enable\", false)\n-                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n-                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n-                .endSpec().done();\n-\n-        String topicName = \"topic-test-rack-aware\";\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-\n-        List<String> connectPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n-        for (String connectPodName : connectPods) {\n-            Affinity connectPodSpecAffinity = kubeClient().getDeployment(KafkaConnectResources.deploymentName(CLUSTER_NAME)).getSpec().getTemplate().getSpec().getAffinity();\n-            NodeSelectorRequirement connectPodNodeSelectorRequirement = connectPodSpecAffinity.getNodeAffinity()\n-                    .getRequiredDuringSchedulingIgnoredDuringExecution().getNodeSelectorTerms().get(0).getMatchExpressions().get(0);\n-            Pod connectPod = kubeClient().getPod(connectPodName);\n-            NodeAffinity nodeAffinity = connectPod.getSpec().getAffinity().getNodeAffinity();\n-\n-            LOGGER.info(\"PodName: {}\\nNodeAffinity: {}\", connectPodName, nodeAffinity);\n-            assertThat(connectPodNodeSelectorRequirement.getKey(), is(rackKey));\n-            assertThat(connectPodNodeSelectorRequirement.getOperator(), is(\"Exists\"));\n-\n-            LOGGER.info(\"Test sending and receiving messages through KafkaConnect\");\n-            KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(connectPodName);\n-            KafkaConnectorUtils.createFileSinkConnector(connectPodName, topicName, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n-\n-            InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n-                    .withUsingPodName(kafkaClientsPodName)\n-                    .withTopicName(topicName)\n-                    .withNamespaceName(NAMESPACE)\n-                    .withClusterName(CLUSTER_NAME)\n-                    .withMessageCount(MESSAGE_COUNT)\n-                    .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n-                    .build();\n-\n-            internalKafkaClient.checkProducedAndConsumedMessages(\n-                    internalKafkaClient.sendMessagesPlain(),\n-                    internalKafkaClient.receiveMessagesPlain()\n-            );\n-            KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(connectPodName, Constants.DEFAULT_SINK_FILE_PATH, \"99\");\n-        }\n+        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n+            basicExternalKafkaClient.sendMessagesPlain(),\n+            basicExternalKafkaClient.receiveMessagesPlain()\n+        );\n     }\n \n+\n     @Test\n     @Tag(LOADBALANCER_SUPPORTED)\n     @Tag(EXTERNAL_CLIENTS_USED)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMDEzMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518110132", "bodyText": "I wonder if we do really want to have the error text hardcoded. It is often different with Kubernetes versions and makes the test lass portable and future-proof.", "author": "scholzj", "createdAt": "2020-11-05T14:51:47Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +109,120 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnect() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));", "originalCommit": "872a420efbc02018f9b12b676dab17786d08ca09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyMTUwMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518121502", "bodyText": "Yeah, I was thinking the same if it should be regexp or this line should be completely omitted.\nI will remove it for KISS.", "author": "michalxo", "createdAt": "2020-11-05T15:06:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMDEzMg=="}], "type": "inlineReview", "revised_code": {"commit": "a34467fbdc216c9256041ddf74b46f844d33915f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 65f30b60bd..e75925f488 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -109,121 +100,30 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n-        final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n-        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n-                .withUsingPodName(defaultKafkaClientsPodName)\n-                .withTopicName(TOPIC_NAME)\n-                .withNamespaceName(NAMESPACE)\n-                .withClusterName(CLUSTER_NAME)\n-                .withMessageCount(MESSAGE_COUNT)\n-                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n-                .build();\n-\n-        internalKafkaClient.verifyProducedAndConsumedMessages(\n-                internalKafkaClient.sendMessagesPlain(),\n-                internalKafkaClient.receiveMessagesPlain()\n-        );\n-    }\n-\n-    @Test\n-    @Tag(CONNECT)\n-    @Tag(REGRESSION)\n-    void testRackAwareConnect() throws Exception {\n-        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+        LOGGER.info(\"Waiting for reconciliation to happen. \" +\n+                \"Giving some time to DNS/load balancer to propagate kafka address.\" +\n+                \"Sleeping for {}ms\", Constants.RECONCILIATION_INTERVAL);\n+        try {\n+            Thread.sleep(Constants.RECONCILIATION_INTERVAL);\n+        } catch (InterruptedException e) {\n+            e.printStackTrace();\n+        }\n \n-        String wrongRackKey = \"wrong-key\";\n-        String rackKey = \"rack-key\";\n+        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n+            .build();\n \n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-                .editSpec()\n-                    .editKafka()\n-                        .withNewRack()\n-                            .withTopologyKey(rackKey)\n-                        .endRack()\n-                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                    .endKafka()\n-                .endSpec().done();\n-\n-        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n-        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n-\n-        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-                .editSpec()\n-                    .withNewRack()\n-                        .withTopologyKey(wrongRackKey)\n-                    .endRack()\n-                .endSpec().build());\n-\n-        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n-        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n-        String connectWrongPodName = connectWrongPods.get(0);\n-        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n-        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n-\n-        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n-        Condition kcCondition = kc.getStatus().getConditions().get(0);\n-        assertThat(\"NotReady\", is(kcCondition.getType()));\n-        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n-\n-        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n-        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n-        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n-        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n-        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n-        PodUtils.deletePodWithWait(connectWrongPodName);\n-\n-\n-        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n-                .editSpec()\n-                    .withNewRack()\n-                        .withTopologyKey(rackKey)\n-                    .endRack()\n-                    .addToConfig(\"key.converter.schemas.enable\", false)\n-                    .addToConfig(\"value.converter.schemas.enable\", false)\n-                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n-                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n-                .endSpec().done();\n-\n-        String topicName = \"topic-test-rack-aware\";\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-\n-        List<String> connectPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n-        for (String connectPodName : connectPods) {\n-            Affinity connectPodSpecAffinity = kubeClient().getDeployment(KafkaConnectResources.deploymentName(CLUSTER_NAME)).getSpec().getTemplate().getSpec().getAffinity();\n-            NodeSelectorRequirement connectPodNodeSelectorRequirement = connectPodSpecAffinity.getNodeAffinity()\n-                    .getRequiredDuringSchedulingIgnoredDuringExecution().getNodeSelectorTerms().get(0).getMatchExpressions().get(0);\n-            Pod connectPod = kubeClient().getPod(connectPodName);\n-            NodeAffinity nodeAffinity = connectPod.getSpec().getAffinity().getNodeAffinity();\n-\n-            LOGGER.info(\"PodName: {}\\nNodeAffinity: {}\", connectPodName, nodeAffinity);\n-            assertThat(connectPodNodeSelectorRequirement.getKey(), is(rackKey));\n-            assertThat(connectPodNodeSelectorRequirement.getOperator(), is(\"Exists\"));\n-\n-            LOGGER.info(\"Test sending and receiving messages through KafkaConnect\");\n-            KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(connectPodName);\n-            KafkaConnectorUtils.createFileSinkConnector(connectPodName, topicName, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n-\n-            InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n-                    .withUsingPodName(kafkaClientsPodName)\n-                    .withTopicName(topicName)\n-                    .withNamespaceName(NAMESPACE)\n-                    .withClusterName(CLUSTER_NAME)\n-                    .withMessageCount(MESSAGE_COUNT)\n-                    .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n-                    .build();\n-\n-            internalKafkaClient.checkProducedAndConsumedMessages(\n-                    internalKafkaClient.sendMessagesPlain(),\n-                    internalKafkaClient.receiveMessagesPlain()\n-            );\n-            KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(connectPodName, Constants.DEFAULT_SINK_FILE_PATH, \"99\");\n-        }\n+        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n+            basicExternalKafkaClient.sendMessagesPlain(),\n+            basicExternalKafkaClient.receiveMessagesPlain()\n+        );\n     }\n \n+\n     @Test\n     @Tag(LOADBALANCER_SUPPORTED)\n     @Tag(EXTERNAL_CLIENTS_USED)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518111126", "bodyText": "Maybe if you already start with a wrong rack, you could also just change the Connect CR and see that it recovers instead of deleting it?", "author": "scholzj", "createdAt": "2020-11-05T14:53:04Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +109,120 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnect() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n+        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n+        PodUtils.deletePodWithWait(connectWrongPodName);", "originalCommit": "872a420efbc02018f9b12b676dab17786d08ca09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExNDg5Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518114897", "bodyText": "I was thinking about it while writing this test. After your suggestion, I think that probably it should be a different test.\nOr even better this test split into two.\n\nPositive case (second portion of test)\nNegative case (incorrect rack-key) with happy-ending (edit pf CR as you suggest)\n\nWDYT @Frawless @scholzj", "author": "michalxo", "createdAt": "2020-11-05T14:57:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyMzI0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518123249", "bodyText": "Sounds good to me.", "author": "scholzj", "createdAt": "2020-11-05T15:09:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODEyNjU0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r518126542", "bodyText": "Ye, sounds reasonable. What about recovery from the wrong rack? Isn't it something which could be useful for KafkaRoller coverage?", "author": "Frawless", "createdAt": "2020-11-05T15:13:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzNTUxMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r526935512", "bodyText": "What do you mean by recovery from wrong rack? @Frawless - Is this question targeted at me or @scholzj ?\nI added both tests now into PR. Locally they are passing, but I think they will fail in this PR's as we will miss rack-key label on nodes...", "author": "michalxo", "createdAt": "2020-11-19T14:37:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzOTYyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r526939622", "bodyText": "You deploy it with the wrong one => check it fails => fix it to the correct one in the CR => check that the operator recovers from it and fixes it.", "author": "scholzj", "createdAt": "2020-11-19T14:42:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjk1MjMxOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r526952318", "bodyText": "Yup, that's what I did I believe in testRackAwareConnectWrongDeployment :-)", "author": "michalxo", "createdAt": "2020-11-19T14:58:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODExMTEyNg=="}], "type": "inlineReview", "revised_code": {"commit": "a34467fbdc216c9256041ddf74b46f844d33915f", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 65f30b60bd..e75925f488 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -109,121 +100,30 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n-        final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n-        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n-                .withUsingPodName(defaultKafkaClientsPodName)\n-                .withTopicName(TOPIC_NAME)\n-                .withNamespaceName(NAMESPACE)\n-                .withClusterName(CLUSTER_NAME)\n-                .withMessageCount(MESSAGE_COUNT)\n-                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n-                .build();\n-\n-        internalKafkaClient.verifyProducedAndConsumedMessages(\n-                internalKafkaClient.sendMessagesPlain(),\n-                internalKafkaClient.receiveMessagesPlain()\n-        );\n-    }\n-\n-    @Test\n-    @Tag(CONNECT)\n-    @Tag(REGRESSION)\n-    void testRackAwareConnect() throws Exception {\n-        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+        LOGGER.info(\"Waiting for reconciliation to happen. \" +\n+                \"Giving some time to DNS/load balancer to propagate kafka address.\" +\n+                \"Sleeping for {}ms\", Constants.RECONCILIATION_INTERVAL);\n+        try {\n+            Thread.sleep(Constants.RECONCILIATION_INTERVAL);\n+        } catch (InterruptedException e) {\n+            e.printStackTrace();\n+        }\n \n-        String wrongRackKey = \"wrong-key\";\n-        String rackKey = \"rack-key\";\n+        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n+            .withTopicName(TOPIC_NAME)\n+            .withNamespaceName(NAMESPACE)\n+            .withClusterName(CLUSTER_NAME)\n+            .withMessageCount(MESSAGE_COUNT)\n+            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n+            .build();\n \n-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n-                .editSpec()\n-                    .editKafka()\n-                        .withNewRack()\n-                            .withTopologyKey(rackKey)\n-                        .endRack()\n-                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n-                    .endKafka()\n-                .endSpec().done();\n-\n-        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n-        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n-\n-        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n-        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n-                .editSpec()\n-                    .withNewRack()\n-                        .withTopologyKey(wrongRackKey)\n-                    .endRack()\n-                .endSpec().build());\n-\n-        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n-        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n-        String connectWrongPodName = connectWrongPods.get(0);\n-        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n-        Thread.sleep(CO_OPERATION_TIMEOUT_SHORT + 10000);\n-\n-        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n-        Condition kcCondition = kc.getStatus().getConditions().get(0);\n-        assertThat(\"NotReady\", is(kcCondition.getType()));\n-        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n-\n-        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n-        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n-        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n-        assertThat(kcWrongStatus.getConditions().get(0).getMessage(), containsString(\"didn't match node selector\"));\n-        KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();\n-        PodUtils.deletePodWithWait(connectWrongPodName);\n-\n-\n-        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n-                .editSpec()\n-                    .withNewRack()\n-                        .withTopologyKey(rackKey)\n-                    .endRack()\n-                    .addToConfig(\"key.converter.schemas.enable\", false)\n-                    .addToConfig(\"value.converter.schemas.enable\", false)\n-                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n-                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n-                .endSpec().done();\n-\n-        String topicName = \"topic-test-rack-aware\";\n-        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n-\n-        List<String> connectPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n-        for (String connectPodName : connectPods) {\n-            Affinity connectPodSpecAffinity = kubeClient().getDeployment(KafkaConnectResources.deploymentName(CLUSTER_NAME)).getSpec().getTemplate().getSpec().getAffinity();\n-            NodeSelectorRequirement connectPodNodeSelectorRequirement = connectPodSpecAffinity.getNodeAffinity()\n-                    .getRequiredDuringSchedulingIgnoredDuringExecution().getNodeSelectorTerms().get(0).getMatchExpressions().get(0);\n-            Pod connectPod = kubeClient().getPod(connectPodName);\n-            NodeAffinity nodeAffinity = connectPod.getSpec().getAffinity().getNodeAffinity();\n-\n-            LOGGER.info(\"PodName: {}\\nNodeAffinity: {}\", connectPodName, nodeAffinity);\n-            assertThat(connectPodNodeSelectorRequirement.getKey(), is(rackKey));\n-            assertThat(connectPodNodeSelectorRequirement.getOperator(), is(\"Exists\"));\n-\n-            LOGGER.info(\"Test sending and receiving messages through KafkaConnect\");\n-            KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(connectPodName);\n-            KafkaConnectorUtils.createFileSinkConnector(connectPodName, topicName, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n-\n-            InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n-                    .withUsingPodName(kafkaClientsPodName)\n-                    .withTopicName(topicName)\n-                    .withNamespaceName(NAMESPACE)\n-                    .withClusterName(CLUSTER_NAME)\n-                    .withMessageCount(MESSAGE_COUNT)\n-                    .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n-                    .build();\n-\n-            internalKafkaClient.checkProducedAndConsumedMessages(\n-                    internalKafkaClient.sendMessagesPlain(),\n-                    internalKafkaClient.receiveMessagesPlain()\n-            );\n-            KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(connectPodName, Constants.DEFAULT_SINK_FILE_PATH, \"99\");\n-        }\n+        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n+            basicExternalKafkaClient.sendMessagesPlain(),\n+            basicExternalKafkaClient.receiveMessagesPlain()\n+        );\n     }\n \n+\n     @Test\n     @Tag(LOADBALANCER_SUPPORTED)\n     @Tag(EXTERNAL_CLIENTS_USED)\n"}}, {"oid": "a34467fbdc216c9256041ddf74b46f844d33915f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a34467fbdc216c9256041ddf74b46f844d33915f", "message": "FIX(Tests) testRackAware added wait for DNS propagation of kafka to load balancer\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-19T14:34:41Z", "type": "commit"}, {"oid": "0338dc6395c2383c906130b1ffba861c852633af", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0338dc6395c2383c906130b1ffba861c852633af", "message": "FIX(Tests) TestRackAware do not use load balance w/ ext clients\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-19T14:34:42Z", "type": "commit"}, {"oid": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "message": "fixup! NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-19T14:34:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNTc5OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527025799", "bodyText": "It's not a test", "author": "Frawless", "createdAt": "2020-11-19T16:31:26Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -78,4 +80,33 @@ public static void waitForKafkaConnectConfigChange(String propertyKey, String pr\n             });\n         LOGGER.info(\"Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n     }\n+\n+    /**\n+     * Test sending and receiving messages through file sink connector (using Kafka Connect).", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\nindex c8199f915e..4cba4c39de 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n\n@@ -82,7 +86,27 @@ public class KafkaConnectUtils {\n     }\n \n     /**\n-     * Test sending and receiving messages through file sink connector (using Kafka Connect).\n+     * Wait for designated Kafka Connect pod condition type and reason to happen.\n+     * @param conditionReason String regexp of condition reason\n+     * @param conditionType String regexp of condition type\n+     * @param namespace namespace name\n+     * @param clusterName cluster name\n+     */\n+    public static void waitForPodCondition(String conditionReason, String conditionType, String namespace, String clusterName) {\n+        TestUtils.waitFor(\"Wait for KafkaConnect '\" + conditionReason + \"' condition with type '\" + conditionType + \"'.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(conditionReason) && condition.getType().matches(conditionType)) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+    }\n+\n+    /**\n+     * Send and receive messages through file sink connector (using Kafka Connect).\n      * @param connectPodName kafkaConnect pod name\n      * @param topicName topic to be used\n      * @param kafkaClientsPodName kafkaClients pod name\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNTk1OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527025958", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-11-19T16:31:38Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -78,4 +80,33 @@ public static void waitForKafkaConnectConfigChange(String propertyKey, String pr\n             });\n         LOGGER.info(\"Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n     }\n+\n+    /**\n+     * Test sending and receiving messages through file sink connector (using Kafka Connect).\n+     * @param connectPodName kafkaConnect pod name\n+     * @param topicName topic to be used\n+     * @param kafkaClientsPodName kafkaClients pod name\n+     * @param namespace namespace name\n+     * @param clusterName cluster name\n+     */\n+    public static void sendReceiveMessagesThroughConnect(String connectPodName, String topicName, String kafkaClientsPodName, String namespace, String clusterName) {\n+        LOGGER.info(\"Test sending and receiving messages through KafkaConnect\");", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\nindex c8199f915e..4cba4c39de 100644\n--- a/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n+++ b/systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java\n\n@@ -82,7 +86,27 @@ public class KafkaConnectUtils {\n     }\n \n     /**\n-     * Test sending and receiving messages through file sink connector (using Kafka Connect).\n+     * Wait for designated Kafka Connect pod condition type and reason to happen.\n+     * @param conditionReason String regexp of condition reason\n+     * @param conditionType String regexp of condition type\n+     * @param namespace namespace name\n+     * @param clusterName cluster name\n+     */\n+    public static void waitForPodCondition(String conditionReason, String conditionType, String namespace, String clusterName) {\n+        TestUtils.waitFor(\"Wait for KafkaConnect '\" + conditionReason + \"' condition with type '\" + conditionType + \"'.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(conditionReason) && condition.getType().matches(conditionType)) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+    }\n+\n+    /**\n+     * Send and receive messages through file sink connector (using Kafka Connect).\n      * @param connectPodName kafkaConnect pod name\n      * @param topicName topic to be used\n      * @param kafkaClientsPodName kafkaClients pod name\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzQ4Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527027486", "bodyText": "Move it to some utils class? You basically wait until KC is not ready, I don't see any specific message in status. Also, the test will wait 5 minutes until deployment will timeout. WOuldn't be enough just to wait for the pending, wait for the next reconciliation, check if the pod is still pending, and then proceed?", "author": "Frawless", "createdAt": "2020-11-19T16:33:43Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MTE4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527091189", "bodyText": "Makes sense to move it to KCUtils.waitUntilCondition(Reason, Type). Good idea.\nActually it will wait only 1min as long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis(); *2", "author": "michalxo", "createdAt": "2020-11-19T18:03:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzQ4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIxNjc2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527216766", "bodyText": "I see. Anyway, move it is still a good idea :)", "author": "Frawless", "createdAt": "2020-11-19T21:37:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzQ4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 7b5d0f03b2..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzgwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527027805", "bodyText": "Why do you assert something, which is verified a few lines above?", "author": "Frawless", "createdAt": "2020-11-19T16:34:12Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MTcyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527091722", "bodyText": "Thanks, left-over from previous test case (work).", "author": "michalxo", "createdAt": "2020-11-19T18:04:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzgwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 7b5d0f03b2..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyODU2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527028561", "bodyText": "maybe put rack key into the log as well?", "author": "Frawless", "createdAt": "2020-11-19T16:35:06Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> {\n+            kafkaConnect.getSpec().setRack(new Rack(rackKey));\n+        });\n+        KafkaConnectUtils.waitForConnectReady(CLUSTER_NAME);\n+        LOGGER.info(\"KafkaConnect is ready with changed rack key.\");", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 7b5d0f03b2..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527029839", "bodyText": "isn't it by default applied for each KC which we create during tests?", "author": "Frawless", "createdAt": "2020-11-19T16:36:51Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> {\n+            kafkaConnect.getSpec().setRack(new Rack(rackKey));\n+        });\n+        KafkaConnectUtils.waitForConnectReady(CLUSTER_NAME);\n+        LOGGER.info(\"KafkaConnect is ready with changed rack key.\");\n+        LOGGER.info(\"Verify KafkaConnect rack key update\");\n+        kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        assertThat(kc.getSpec().getRack().getTopologyKey(), is(rackKey));\n+\n+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {\n+            KubernetesResource.allowNetworkPolicySettingsForResource(kc, KafkaConnectResources.deploymentName(kc.getMetadata().getName()));\n+        }", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MjgwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527092804", "bodyText": "No, as I am not using specifically KafkaConnectResource.deployKafkaConnect() method. @im-konge also mentioned me this today.", "author": "michalxo", "createdAt": "2020-11-19T18:06:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIxOTY3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527219673", "bodyText": "I don't say you have to change it in this PR, but maybe we should think about applying the NP in kafkaConnectWithoutWait as we do in deployKafkaConnect", "author": "Frawless", "createdAt": "2020-11-19T21:40:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyMTcwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527221703", "bodyText": "Yes, but I thought that you will add it to the KafkaConnectResource.kafkaConnectWithoutWait() method. I don't think that having it directly in a test is a good idea. But ... there comes another problem -> you have to create KafkaClients pod before creating the KafkaConnect, so you'll have to add it to all tests where the Connect is deployed via the withoutWait method.", "author": "im-konge", "createdAt": "2020-11-19T21:43:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyMzU0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527223544", "bodyText": "Ye, maybe we should think more about it and solve it a little bit differently to avoid the situation with clients", "author": "Frawless", "createdAt": "2020-11-19T21:47:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNDQ4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527224482", "bodyText": "And you are using this if more than once ... so ... what about to create some different method, which will create the NP and then deploy the Connect without wait? To not add unnecessary Clients pods to other testcases?", "author": "im-konge", "createdAt": "2020-11-19T21:48:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTgzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 7b5d0f03b2..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAzMDA4NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527030084", "bodyText": "indent", "author": "Frawless", "createdAt": "2020-11-19T16:37:09Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 7b5d0f03b2..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAzMjA1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527032051", "bodyText": "Same as I mentioned above", "author": "Frawless", "createdAt": "2020-11-19T16:39:44Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,151 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        final String defaultKafkaClientsPodName =\n+                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+        InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n+                .withUsingPodName(defaultKafkaClientsPodName)\n+                .withTopicName(TOPIC_NAME)\n+                .withNamespaceName(NAMESPACE)\n+                .withClusterName(CLUSTER_NAME)\n+                .withMessageCount(MESSAGE_COUNT)\n+                .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)\n+                .build();\n+\n+        internalKafkaClient.verifyProducedAndConsumedMessages(\n+                internalKafkaClient.sendMessagesPlain(),\n+                internalKafkaClient.receiveMessagesPlain()\n         );\n     }\n \n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    void testRackAwareConnectWrongDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String wrongRackKey = \"wrong-key\";\n+        String rackKey = \"rack-key\";\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with wrong rack-aware topology key: {}\", wrongRackKey);\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(wrongRackKey)\n+                    .endRack()\n+                .addToConfig(\"key.converter.schemas.enable\", false)\n+                .addToConfig(\"value.converter.schemas.enable\", false)\n+                .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().build());\n+\n+        PodUtils.waitForPendingPod(CLUSTER_NAME + \"-connect\");\n+        List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        String connectWrongPodName = connectWrongPods.get(0);\n+        LOGGER.info(\"Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect\");\n+        TestUtils.waitFor(\"Wait for KafkaConnect 'Unschedulable' condition due to wrong rackKey used.\",\n+                Constants.GLOBAL_POLL_INTERVAL, CO_OPERATION_TIMEOUT_SHORT * 2, () -> {\n+                List<Condition> conditions = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions();\n+                for (Condition condition : conditions) {\n+                    if (condition.getReason().matches(\"TimeoutException\") && condition.getType().matches(\"NotReady\")) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            });\n+\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        Condition kcCondition = kc.getStatus().getConditions().get(0);\n+        assertThat(\"NotReady\", is(kcCondition.getType()));\n+        assertThat(\"TimeoutException\", is(kcCondition.getReason()));\n+\n+        PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();\n+        assertThat(\"Unschedulable\", is(kcWrongStatus.getConditions().get(0).getReason()));\n+        assertThat(\"PodScheduled\", is(kcWrongStatus.getConditions().get(0).getType()));\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> {\n+            kafkaConnect.getSpec().setRack(new Rack(rackKey));\n+        });\n+        KafkaConnectUtils.waitForConnectReady(CLUSTER_NAME);\n+        LOGGER.info(\"KafkaConnect is ready with changed rack key.\");\n+        LOGGER.info(\"Verify KafkaConnect rack key update\");\n+        kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();\n+        assertThat(kc.getSpec().getRack().getTopologyKey(), is(rackKey));\n+\n+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {\n+            KubernetesResource.allowNetworkPolicySettingsForResource(kc, KafkaConnectResources.deploymentName(kc.getMetadata().getName()));\n+        }\n+        List<String> kcPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);\n+        KafkaConnectUtils.sendReceiveMessagesThroughConnect(kcPods.get(0), TOPIC_NAME, kafkaClientsPodName, NAMESPACE, CLUSTER_NAME);\n+    }\n+\n+    @Test\n+    @Tag(CONNECT)\n+    @Tag(REGRESSION)\n+    public void testRackAwareConnectCorrectDeployment() throws Exception {\n+        installClusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT);\n+\n+        String rackKey = \"rack-key\";\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+                .editSpec()\n+                    .editKafka()\n+                        .withNewRack()\n+                            .withTopologyKey(rackKey)\n+                        .endRack()\n+                        .addToConfig(\"replica.selector.class\", \"org.apache.kafka.common.replica.RackAwareReplicaSelector\")\n+                    .endKafka()\n+                .endSpec().done();\n+\n+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();\n+        String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n+\n+        LOGGER.info(\"Deploy KafkaConnect with correct rack-aware topology key: {}\", rackKey);\n+        KafkaConnect kc = KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n+                .editSpec()\n+                    .withNewRack()\n+                        .withTopologyKey(rackKey)\n+                    .endRack()\n+                    .addToConfig(\"key.converter.schemas.enable\", false)\n+                    .addToConfig(\"value.converter.schemas.enable\", false)\n+                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                .endSpec().done();\n+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {\n+            KubernetesResource.allowNetworkPolicySettingsForResource(kc, KafkaConnectResources.deploymentName(kc.getMetadata().getName()));\n+        }", "originalCommit": "aac1bfe88b502c06821a1c3a93cf1b7ff448395f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 7b5d0f03b2..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNTUwNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527225506", "bodyText": "How about to add INTERNAL_CLIENTS_USED as well?", "author": "im-konge", "createdAt": "2020-11-19T21:50:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -56,8 +75,7 @@\n     public static final String NAMESPACE = \"specific-cluster-test\";\n \n     @Test\n-    @Tag(LOADBALANCER_SUPPORTED)\n-    @Tag(EXTERNAL_CLIENTS_USED)\n+    @Tag(REGRESSION)\n     void testRackAware() {", "originalCommit": "9b9af81b61d1cf33d87366ab643d8b8c09e4fcd2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNzY3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527227674", "bodyText": "Same also for the second test", "author": "im-konge", "createdAt": "2020-11-19T21:54:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNTUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 1ac321cfb6..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -76,6 +73,7 @@ public class SpecificST extends AbstractST {\n \n     @Test\n     @Tag(REGRESSION)\n+    @Tag(INTERNAL_CLIENTS_USED)\n     void testRackAware() {\n         String rackKey = \"rack-key\";\n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNjEyMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3873#discussion_r527226120", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n          \n          \n            \n                    KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n          \n          \n            \n            ``` ?", "author": "im-konge", "createdAt": "2020-11-19T21:51:31Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java", "diffHunk": "@@ -100,20 +110,147 @@ void testRackAware() {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()\n-            .withTopicName(TOPIC_NAME)\n-            .withNamespaceName(NAMESPACE)\n-            .withClusterName(CLUSTER_NAME)\n-            .withMessageCount(MESSAGE_COUNT)\n-            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)\n-            .build();\n-\n-        basicExternalKafkaClient.verifyProducedAndConsumedMessages(\n-            basicExternalKafkaClient.sendMessagesPlain(),\n-            basicExternalKafkaClient.receiveMessagesPlain()\n+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();", "originalCommit": "9b9af81b61d1cf33d87366ab643d8b8c09e4fcd2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "chunk": "diff --git a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\nindex 1ac321cfb6..493d82bbf8 100644\n--- a/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n+++ b/systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java\n\n@@ -110,9 +108,9 @@ public class SpecificST extends AbstractST {\n         List<Event> events = kubeClient().listEvents(uid);\n         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));\n \n-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).done();\n+        KafkaClientsResource.deployKafkaClients(true, KAFKA_CLIENTS_NAME).done();\n         final String defaultKafkaClientsPodName =\n-                ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + \"-\" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();\n+                ResourceManager.kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();\n         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()\n                 .withUsingPodName(defaultKafkaClientsPodName)\n                 .withTopicName(TOPIC_NAME)\n"}}, {"oid": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "message": "NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-26T11:04:53Z", "type": "commit"}, {"oid": "7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7c3634c20d32ebb1c124f8c3b9666cd5f623de01", "message": "NEW(Tests) testRackAwareConnect\n\nSigned-off-by: Michal T\u00f3th <mtoth@redhat.com>", "committedDate": "2020-11-26T11:04:53Z", "type": "forcePushed"}]}