{"pr_number": 762, "pr_title": "Object store/ analysis submissions", "pr_createdAt": "2020-07-21T19:20:17Z", "pr_url": "https://github.com/phac-nml/irida/pull/762", "timeline": [{"oid": "3c3c748946d7e1ae333646bcde747f13137c59d3", "url": "https://github.com/phac-nml/irida/commit/3c3c748946d7e1ae333646bcde747f13137c59d3", "message": "Updated azure-storage-blob to latest stable version", "committedDate": "2021-08-25T16:37:22Z", "type": "commit"}, {"oid": "886e8ce910b7706d857ee5d0a4d9bd1dde0bbedc", "url": "https://github.com/phac-nml/irida/commit/886e8ce910b7706d857ee5d0a4d9bd1dde0bbedc", "message": "Simplified getting of upload identifier from galaxy", "committedDate": "2021-08-25T17:59:07Z", "type": "commit"}, {"oid": "44bd1cda83c6fcb1d048c592bc5031e1809ab442", "url": "https://github.com/phac-nml/irida/commit/44bd1cda83c6fcb1d048c592bc5031e1809ab442", "message": "Updated getting of file size for a cloud file on pipeline page", "committedDate": "2021-08-25T19:32:11Z", "type": "commit"}, {"oid": "9f8363a40147e8dfb509e62b08c38d81703f3bee", "url": "https://github.com/phac-nml/irida/commit/9f8363a40147e8dfb509e62b08c38d81703f3bee", "message": "Updated to use getFileSize method within the ReferenceFile object", "committedDate": "2021-08-25T19:40:40Z", "type": "commit"}, {"oid": "061e1164cf8d0e0a5e6e2291ebca2c4247c6fc73", "url": "https://github.com/phac-nml/irida/commit/061e1164cf8d0e0a5e6e2291ebca2c4247c6fc73", "message": "Updated logic to log an error if a referencefile file cannot be found on server", "committedDate": "2021-08-25T22:06:31Z", "type": "commit"}, {"oid": "8f4d2f248caa9e2609acbacf1b21f9c5449a40ca", "url": "https://github.com/phac-nml/irida/commit/8f4d2f248caa9e2609acbacf1b21f9c5449a40ca", "message": "Updated galaxylibraryservice to have access to files in cloud storage.", "committedDate": "2020-04-24T20:28:10Z", "type": "commit"}, {"oid": "b3778b5084546bbc9be73a3c1bda6e97879fdbd0", "url": "https://github.com/phac-nml/irida/commit/b3778b5084546bbc9be73a3c1bda6e97879fdbd0", "message": "Updated tests", "committedDate": "2020-04-27T19:33:52Z", "type": "commit"}, {"oid": "7b36364687b926a5aac172ce86888744683d1804", "url": "https://github.com/phac-nml/irida/commit/7b36364687b926a5aac172ce86888744683d1804", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-04-27T19:36:33Z", "type": "commit"}, {"oid": "2cf225d0fb0a4e3a857f6aa80d91d12953509611", "url": "https://github.com/phac-nml/irida/commit/2cf225d0fb0a4e3a857f6aa80d91d12953509611", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-04-29T16:01:01Z", "type": "commit"}, {"oid": "b0a4b16df29a0c50f2c8cbd08c6d581d493ce7d0", "url": "https://github.com/phac-nml/irida/commit/b0a4b16df29a0c50f2c8cbd08c6d581d493ce7d0", "message": "Removed unused imports", "committedDate": "2020-04-29T16:10:59Z", "type": "commit"}, {"oid": "aa8cd5aeedb41b03abfe013f3876c2f6b96d8ef0", "url": "https://github.com/phac-nml/irida/commit/aa8cd5aeedb41b03abfe013f3876c2f6b96d8ef0", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-04-29T16:32:10Z", "type": "commit"}, {"oid": "6bf87a9fc5818777fe3442bf93b6d78f3f12ee2f", "url": "https://github.com/phac-nml/irida/commit/6bf87a9fc5818777fe3442bf93b6d78f3f12ee2f", "message": "Updated galaxy connector code to make use of cloud stored reference files", "committedDate": "2020-04-29T22:45:22Z", "type": "commit"}, {"oid": "d43c0a149e7e00796b016acacd829de18f48f95a", "url": "https://github.com/phac-nml/irida/commit/d43c0a149e7e00796b016acacd829de18f48f95a", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-04-30T17:15:23Z", "type": "commit"}, {"oid": "eef7c5071d36d4b7dc0f709c7831ecd4aff138b3", "url": "https://github.com/phac-nml/irida/commit/eef7c5071d36d4b7dc0f709c7831ecd4aff138b3", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-04-30T18:56:34Z", "type": "commit"}, {"oid": "9de15230df0491a834e86ea88198070c0f2a6404", "url": "https://github.com/phac-nml/irida/commit/9de15230df0491a834e86ea88198070c0f2a6404", "message": "Updated getTemporaryFile methods for cloud storage to create a temp folder in the location provided", "committedDate": "2020-05-04T23:48:48Z", "type": "commit"}, {"oid": "b2be307e357fa29ead93226bd57bada3ad03838b", "url": "https://github.com/phac-nml/irida/commit/b2be307e357fa29ead93226bd57bada3ad03838b", "message": "Removed code not required. Changed cloud temp file directory prefix", "committedDate": "2020-05-05T16:14:35Z", "type": "commit"}, {"oid": "ed429124a0399136d2883894106936b2d4355bc4", "url": "https://github.com/phac-nml/irida/commit/ed429124a0399136d2883894106936b2d4355bc4", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-05-06T13:58:54Z", "type": "commit"}, {"oid": "0d719a602711c47c4c3673c92602c19fd25ac38d", "url": "https://github.com/phac-nml/irida/commit/0d719a602711c47c4c3673c92602c19fd25ac38d", "message": "Merge branch 'object_store/_azure' into object_store/_analysis-submissions", "committedDate": "2020-05-20T19:42:00Z", "type": "commit"}, {"oid": "f81376bc1bde63d5872449384ba2d0f3c8ffee13", "url": "https://github.com/phac-nml/irida/commit/f81376bc1bde63d5872449384ba2d0f3c8ffee13", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-05-20T19:42:17Z", "type": "commit"}, {"oid": "225c8f0fe36a6b4a4b8c7efbc7b8104af97a7124", "url": "https://github.com/phac-nml/irida/commit/225c8f0fe36a6b4a4b8c7efbc7b8104af97a7124", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-05-22T23:34:17Z", "type": "commit"}, {"oid": "3a63bdfd00e5b048658c56d34538dcf4b969aa02", "url": "https://github.com/phac-nml/irida/commit/3a63bdfd00e5b048658c56d34538dcf4b969aa02", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-05-26T19:25:00Z", "type": "commit"}, {"oid": "3268f3a075c6412f36243146dfa3b3cc8e64ecc6", "url": "https://github.com/phac-nml/irida/commit/3268f3a075c6412f36243146dfa3b3cc8e64ecc6", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-06-16T20:10:31Z", "type": "commit"}, {"oid": "dd7347058a3514e12b067459e6cbe939a4be5c1a", "url": "https://github.com/phac-nml/irida/commit/dd7347058a3514e12b067459e6cbe939a4be5c1a", "message": "Merged in gui branch, fixed merge conflicts, updated to use IridaFiles, updated class names", "committedDate": "2020-07-16T00:14:22Z", "type": "commit"}, {"oid": "c66fb6d34a56710858165506baef5aaf260ff07f", "url": "https://github.com/phac-nml/irida/commit/c66fb6d34a56710858165506baef5aaf260ff07f", "message": "Updated tests", "committedDate": "2020-07-16T04:18:07Z", "type": "commit"}, {"oid": "266655b317d552993c13ffc83867e8e0517263ef", "url": "https://github.com/phac-nml/irida/commit/266655b317d552993c13ffc83867e8e0517263ef", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-07-17T15:53:27Z", "type": "commit"}, {"oid": "b99c06525d01f080a447032bd495dea1312f89b4", "url": "https://github.com/phac-nml/irida/commit/b99c06525d01f080a447032bd495dea1312f89b4", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-07-20T20:11:10Z", "type": "commit"}, {"oid": "ad1c19c8802c95b898752a90f0bc68b7cc1e2862", "url": "https://github.com/phac-nml/irida/commit/ad1c19c8802c95b898752a90f0bc68b7cc1e2862", "message": "Merged gui branch and fixed merge conflicts", "committedDate": "2020-07-21T19:12:41Z", "type": "commit"}, {"oid": "6328a2751ba469be45ce8220673516bc645f448f", "url": "https://github.com/phac-nml/irida/commit/6328a2751ba469be45ce8220673516bc645f448f", "message": "Added default null for galaxy.cloud.storage.temporary.directory if not set in conf file", "committedDate": "2020-07-21T22:00:20Z", "type": "commit"}, {"oid": "7cda1785b63cda8e7048d0548e52dc537407b21a", "url": "https://github.com/phac-nml/irida/commit/7cda1785b63cda8e7048d0548e52dc537407b21a", "message": "Added temporary file cleanup (files downloaded from an object store). Changed getTemporaryFile method to getFile", "committedDate": "2020-07-23T21:41:23Z", "type": "commit"}, {"oid": "c289104ccae4b733d9e11be21c0ac9b74c11db83", "url": "https://github.com/phac-nml/irida/commit/c289104ccae4b733d9e11be21c0ac9b74c11db83", "message": "Removed dto not used. Removed unused imports", "committedDate": "2020-07-23T22:01:55Z", "type": "commit"}, {"oid": "91132c3086ca321219e35651d97fc316ab7d7447", "url": "https://github.com/phac-nml/irida/commit/91132c3086ca321219e35651d97fc316ab7d7447", "message": "Removed use of another directory for temp downloads and made use of existing directories. Added file cleanup after an analysis has completed or errored when using an object store", "committedDate": "2020-07-24T19:13:34Z", "type": "commit"}, {"oid": "0944704432457869ffdc57429c4f4d162f574687", "url": "https://github.com/phac-nml/irida/commit/0944704432457869ffdc57429c4f4d162f574687", "message": "Fixed reference in @param", "committedDate": "2020-07-24T22:46:08Z", "type": "commit"}, {"oid": "fd0b6c74049b901dff398673a26555bb545aaa5d", "url": "https://github.com/phac-nml/irida/commit/fd0b6c74049b901dff398673a26555bb545aaa5d", "message": "Updated logic to remove files downloaded from object store and its parent directory", "committedDate": "2020-07-24T23:32:52Z", "type": "commit"}, {"oid": "8212a36976dfcd829116621e5dc580575bd5c4e1", "url": "https://github.com/phac-nml/irida/commit/8212a36976dfcd829116621e5dc580575bd5c4e1", "message": "Updated logic so the base directories are not removed if empty", "committedDate": "2020-07-27T18:11:46Z", "type": "commit"}, {"oid": "0d236e1095ad7bcc7de3c3e62ac804f13f9dd2f5", "url": "https://github.com/phac-nml/irida/commit/0d236e1095ad7bcc7de3c3e62ac804f13f9dd2f5", "message": "Removed unused import", "committedDate": "2020-07-27T18:50:40Z", "type": "commit"}, {"oid": "0de23c848a94122c454d484ea95bdf5355a35257", "url": "https://github.com/phac-nml/irida/commit/0de23c848a94122c454d484ea95bdf5355a35257", "message": "Updated to close inputstream on exit from method", "committedDate": "2020-07-31T18:34:32Z", "type": "commit"}, {"oid": "8bdf77d74e0032bc5f12d6c603301360bc3ea99c", "url": "https://github.com/phac-nml/irida/commit/8bdf77d74e0032bc5f12d6c603301360bc3ea99c", "message": "Merged in gui branch and fixed merge conflicts", "committedDate": "2020-08-12T16:06:25Z", "type": "commit"}, {"oid": "8dfbe469b39541be390fd81013bd2bbe9842be40", "url": "https://github.com/phac-nml/irida/commit/8dfbe469b39541be390fd81013bd2bbe9842be40", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-08-12T16:52:51Z", "type": "commit"}, {"oid": "5a16f0a2e642d48aa17b243517218b43527d091a", "url": "https://github.com/phac-nml/irida/commit/5a16f0a2e642d48aa17b243517218b43527d091a", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-08-13T16:39:06Z", "type": "commit"}, {"oid": "e8074f71583ab247dc397a71e2b87d03aee813f5", "url": "https://github.com/phac-nml/irida/commit/e8074f71583ab247dc397a71e2b87d03aee813f5", "message": "Merged gui branch and fixed merge conflicts. Updated to not download file from object store when reading via chunks but rather retrieve bytes from the input stream", "committedDate": "2020-11-25T17:09:52Z", "type": "commit"}, {"oid": "7a235eb0866caec5a85e35f02070a444d991b34e", "url": "https://github.com/phac-nml/irida/commit/7a235eb0866caec5a85e35f02070a444d991b34e", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-11-25T18:45:38Z", "type": "commit"}, {"oid": "ed20220c5c0796a2b53b68cb6a55bc69daf3fb20", "url": "https://github.com/phac-nml/irida/commit/ed20220c5c0796a2b53b68cb6a55bc69daf3fb20", "message": "Added contentloading spinner when retrieving data for outputfiles", "committedDate": "2020-11-25T19:06:30Z", "type": "commit"}, {"oid": "934ed7d5fbbf5c15ca297327b9b31f7fc4f77c92", "url": "https://github.com/phac-nml/irida/commit/934ed7d5fbbf5c15ca297327b9b31f7fc4f77c92", "message": "Merged gui branch and fixed merge conflicts", "committedDate": "2020-11-27T16:05:53Z", "type": "commit"}, {"oid": "d7f592c3c742cd2ff959a70ccc20e8a12b166bdc", "url": "https://github.com/phac-nml/irida/commit/d7f592c3c742cd2ff959a70ccc20e8a12b166bdc", "message": "Merge branch 'object_store/_gui' into object_store/_analysis-submissions", "committedDate": "2020-11-30T20:48:39Z", "type": "commit"}, {"oid": "bfc1e7aed0c82c5f9af518ff06a18ced5a4071c7", "url": "https://github.com/phac-nml/irida/commit/bfc1e7aed0c82c5f9af518ff06a18ced5a4071c7", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-02T19:12:52Z", "type": "commit"}, {"oid": "84c6da44de59bb99abc66d96d8d8915d0632db45", "url": "https://github.com/phac-nml/irida/commit/84c6da44de59bb99abc66d96d8d8915d0632db45", "message": "Updated getOutputFile to use the iridafilestorageutility to retrieve requsted chunk of text from output file. Also, updated this method to use the inputstream of a file to read lines", "committedDate": "2020-12-03T21:44:25Z", "type": "commit"}, {"oid": "2877746336e884226e0d11e4e41c6eb88596f042", "url": "https://github.com/phac-nml/irida/commit/2877746336e884226e0d11e4e41c6eb88596f042", "message": "Updated addFirstLine method to use inputstreamreader rather than using randomaccessfile as we use the inputstreamreader with the bufferedreader to read the file inputstream. Updated filepointers when getting chunks through the irida storage utility classes for object storage", "committedDate": "2020-12-04T00:52:06Z", "type": "commit"}, {"oid": "00ae52fa3cccd0509608f4e8ee70243872192a87", "url": "https://github.com/phac-nml/irida/commit/00ae52fa3cccd0509608f4e8ee70243872192a87", "message": "Removed unused imports and refactored to use try-with-resources", "committedDate": "2020-12-04T01:04:29Z", "type": "commit"}, {"oid": "ae30b2611a972dd1fc608e18e4191826ae08a151", "url": "https://github.com/phac-nml/irida/commit/ae30b2611a972dd1fc608e18e4191826ae08a151", "message": "Removed extra lines added, general refactoring", "committedDate": "2020-12-04T01:14:49Z", "type": "commit"}, {"oid": "199c63efc9c1138264e8b5cb202ae69f7a54d73c", "url": "https://github.com/phac-nml/irida/commit/199c63efc9c1138264e8b5cb202ae69f7a54d73c", "message": "Updated getting sistr results from output file to use inputstream rather than a filereader:", "committedDate": "2020-12-04T15:10:58Z", "type": "commit"}, {"oid": "215717b4b11ab44d946ccfe338159f1e2992c32f", "url": "https://github.com/phac-nml/irida/commit/215717b4b11ab44d946ccfe338159f1e2992c32f", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-04T16:42:11Z", "type": "commit"}, {"oid": "1fef38a8fd7e98f3722ae837f65bc4278d8539e7", "url": "https://github.com/phac-nml/irida/commit/1fef38a8fd7e98f3722ae837f65bc4278d8539e7", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-04T21:23:35Z", "type": "commit"}, {"oid": "5cfee4fb80cb9f2b9179d752ba820f4a8fc08450", "url": "https://github.com/phac-nml/irida/commit/5cfee4fb80cb9f2b9179d752ba820f4a8fc08450", "message": "Removed duplicate setting of setLoading to false", "committedDate": "2020-12-04T21:28:12Z", "type": "commit"}, {"oid": "a4df754dfcaeb5ffdb31b0854a76c2b7ff2c9c31", "url": "https://github.com/phac-nml/irida/commit/a4df754dfcaeb5ffdb31b0854a76c2b7ff2c9c31", "message": "Removed unused method and imports", "committedDate": "2020-12-07T15:30:00Z", "type": "commit"}, {"oid": "7f222c3a7b229f4887431db73e5b7d79e8a22380", "url": "https://github.com/phac-nml/irida/commit/7f222c3a7b229f4887431db73e5b7d79e8a22380", "message": "Moved code block into a try with resources block so that the underlying inputstream is closed", "committedDate": "2020-12-07T15:34:16Z", "type": "commit"}, {"oid": "9104af3bedf7c1f3b7d168a15cabf945e331e58e", "url": "https://github.com/phac-nml/irida/commit/9104af3bedf7c1f3b7d168a15cabf945e331e58e", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-08T20:41:39Z", "type": "commit"}, {"oid": "12c2cd785d800f51bb3ebd4622cdc42624423090", "url": "https://github.com/phac-nml/irida/commit/12c2cd785d800f51bb3ebd4622cdc42624423090", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-08T22:15:01Z", "type": "commit"}, {"oid": "0708c260ae84f48ad42cb53563b35d72d98d2e35", "url": "https://github.com/phac-nml/irida/commit/0708c260ae84f48ad42cb53563b35d72d98d2e35", "message": "Updated to clean up temp files downloaded to server from an object store when running an analysis submission with cloud stored files", "committedDate": "2020-12-16T21:43:08Z", "type": "commit"}, {"oid": "3562cf7ec11af7f7ca7dc3a4400a310d9dc6e6e9", "url": "https://github.com/phac-nml/irida/commit/3562cf7ec11af7f7ca7dc3a4400a310d9dc6e6e9", "message": "Added overloaded method getTemporaryFile which accepts a path and prefix. Added params to javadoc", "committedDate": "2020-12-17T17:12:56Z", "type": "commit"}, {"oid": "e80234be450d37fb1c14d8d6b359b3cc9ccdcdd5", "url": "https://github.com/phac-nml/irida/commit/e80234be450d37fb1c14d8d6b359b3cc9ccdcdd5", "message": "Updated getTemporary call with passing an 'analysis' prefix so we can delineate between regular object store temp files and analysis ones", "committedDate": "2020-12-17T18:55:21Z", "type": "commit"}, {"oid": "3b937b1d4d2dc9542d7dfbc5fd56707341025a2f", "url": "https://github.com/phac-nml/irida/commit/3b937b1d4d2dc9542d7dfbc5fd56707341025a2f", "message": "Changed to check if storage type isn't local before attempting to cleanup temp files", "committedDate": "2020-12-17T20:01:04Z", "type": "commit"}, {"oid": "579625e52368f71dcd9c23d4f1b2c02ceab58481", "url": "https://github.com/phac-nml/irida/commit/579625e52368f71dcd9c23d4f1b2c02ceab58481", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-21T02:53:04Z", "type": "commit"}, {"oid": "a8bdc124d2bddb83e0f2302d20a3edd54d320bd5", "url": "https://github.com/phac-nml/irida/commit/a8bdc124d2bddb83e0f2302d20a3edd54d320bd5", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2020-12-24T20:35:07Z", "type": "commit"}, {"oid": "c77d79ff1c24b95868d2dc056eeb920b14d46161", "url": "https://github.com/phac-nml/irida/commit/c77d79ff1c24b95868d2dc056eeb920b14d46161", "message": "Merged object-store and fixed merge conflicts", "committedDate": "2021-01-06T19:32:33Z", "type": "commit"}, {"oid": "8b3e955dc4fc155c948c9b268d3b3159cd1f609c", "url": "https://github.com/phac-nml/irida/commit/8b3e955dc4fc155c948c9b268d3b3159cd1f609c", "message": "Merged object-store and fixed merge conflicts", "committedDate": "2021-01-12T19:23:55Z", "type": "commit"}, {"oid": "0693df1b8060c5c1d409e5f65ca7faefdb19b8f4", "url": "https://github.com/phac-nml/irida/commit/0693df1b8060c5c1d409e5f65ca7faefdb19b8f4", "message": "Merged object-store and fixed merge conflicts", "committedDate": "2021-01-15T21:30:14Z", "type": "commit"}, {"oid": "067c76d3e7c7092a78f2e4badec7c2f5214833a5", "url": "https://github.com/phac-nml/irida/commit/067c76d3e7c7092a78f2e4badec7c2f5214833a5", "message": "Merged object-store and fixed merge conflicts", "committedDate": "2021-02-02T16:56:03Z", "type": "commit"}, {"oid": "6ee8908d303ce05b9aa2ee95811bbc06c4c8cc46", "url": "https://github.com/phac-nml/irida/commit/6ee8908d303ce05b9aa2ee95811bbc06c4c8cc46", "message": "Updated sistr and bio hansel sample updaters to use an input stream to get file required to support use of object store", "committedDate": "2021-02-02T22:35:20Z", "type": "commit"}, {"oid": "8f41ddcdc2900c9d36c460d4acb493a59b689cd3", "url": "https://github.com/phac-nml/irida/commit/8f41ddcdc2900c9d36c460d4acb493a59b689cd3", "message": "Updated Sistr sample updater test expected condition", "committedDate": "2021-02-03T18:47:45Z", "type": "commit"}, {"oid": "d05c73d1a4f75328dc2552c7a0df3eabdf775fae", "url": "https://github.com/phac-nml/irida/commit/d05c73d1a4f75328dc2552c7a0df3eabdf775fae", "message": "Removed unused imports", "committedDate": "2021-02-03T20:15:52Z", "type": "commit"}, {"oid": "40d9ef0f43abdf0162b1bba7c3f38ac424ef4876", "url": "https://github.com/phac-nml/irida/commit/40d9ef0f43abdf0162b1bba7c3f38ac424ef4876", "message": "Refactored cleanup of temporary files used by a submission and the associated analysissubmissiontempfile objects into a private method. Updated storage utilities to check which storagetype is set to determine if storage type is local or not. Updated setting of pointer after reading first line of a file to set to 0 if there is no text in the file", "committedDate": "2021-02-12T20:25:33Z", "type": "commit"}, {"oid": "1e584140a8b34277397357648c16511bb4bac582", "url": "https://github.com/phac-nml/irida/commit/1e584140a8b34277397357648c16511bb4bac582", "message": "Updated to use storagetype when checking for storage type", "committedDate": "2021-02-12T21:17:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyMjAyNQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578722025", "bodyText": "Changes to the updater here makes it occur to me that we'll need to push this out to our plugin developers too.  At least it's not immediately necessary unless they're running on a cloud system.  Until then they can just keep the FileReader.", "author": "tom114", "createdAt": "2021-02-18T20:23:31Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/pipeline/results/updater/impl/BioHanselSampleUpdater.java", "diffHunk": "@@ -78,9 +80,9 @@ public void update(Collection<Sample> samples, AnalysisSubmission analysis) thro\n \t\tPath filePath = aof.getFile();\n \n \t\tMap<String, MetadataEntry> stringEntries = new HashMap<>();\n-\t\ttry {\n-\t\t\t@SuppressWarnings(\"resource\") String jsonText = new Scanner(\n-\t\t\t\t\tnew BufferedReader(new FileReader(filePath.toFile()))).useDelimiter(\"\\\\Z\")\n+\n+\t\ttry(InputStream inputStream = iridaFileStorageUtility.getFileInputStream(filePath)) {\n+\t\t\t@SuppressWarnings(\"resource\") String jsonText = new Scanner(inputStream).useDelimiter(\"\\\\Z\")", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTIyNzIyOQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579227229", "bodyText": "Actually thinking about this a bit more, I think this can be done IridaFiles instead of the iridaFileStorageUtility?  That way we don't need to wire a new dependency into every updater class.", "author": "tom114", "createdAt": "2021-02-19T14:32:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyMjAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM4MDk3OA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579380978", "bodyText": "Updated the built in sample updaters to use IridaFiles in eb2d3b4", "author": "deepsidhu85", "createdAt": "2021-02-19T18:15:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyMjAyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/pipeline/results/updater/impl/BioHanselSampleUpdater.java b/src/main/java/ca/corefacility/bioinformatics/irida/pipeline/results/updater/impl/BioHanselSampleUpdater.java\nindex b5c2b51361..5f97862fe4 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/pipeline/results/updater/impl/BioHanselSampleUpdater.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/pipeline/results/updater/impl/BioHanselSampleUpdater.java\n\n@@ -81,7 +80,7 @@ public class BioHanselSampleUpdater implements AnalysisSampleUpdater {\n \n \t\tMap<String, MetadataEntry> stringEntries = new HashMap<>();\n \n-\t\ttry(InputStream inputStream = iridaFileStorageUtility.getFileInputStream(filePath)) {\n+\t\ttry(InputStream inputStream = IridaFiles.getFileInputStream(filePath)) {\n \t\t\t@SuppressWarnings(\"resource\") String jsonText = new Scanner(inputStream).useDelimiter(\"\\\\Z\")\n \t\t\t\t\t.next();\n \t\t\tObjectMapper mapper = new ObjectMapper();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyMzg3NA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578723874", "bodyText": "This seems weird that we need to manage the permissions here and in the Azure utility.  What's up with this?", "author": "tom114", "createdAt": "2021-02-18T20:26:53Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAwsUtilityImpl.java", "diffHunk": "@@ -55,11 +60,46 @@ public IridaFileStorageAwsUtilityImpl(String bucketName, String bucketRegion, St\n \t */\n \t@Override\n \tpublic IridaTemporaryFile getTemporaryFile(Path file) {\n+\t\tString perm = \"rwxrwxr-x\";\n \t\ttry {\n \t\t\tlogger.trace(\"Getting file from aws s3 [\" + file.toString() + \"]\");\n \t\t\tPath tempDirectory = Files.createTempDirectory(\"aws-tmp-\");\n \t\t\tPath tempFile = tempDirectory.resolve(file.getFileName()\n \t\t\t\t\t.toString());\n+\t\t\tSet<PosixFilePermission> permissions = PosixFilePermissions.fromString(perm);", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxNTkyMTY2OQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r615921669", "bodyText": "This has been removed. It was used for galaxy to be able to read/execute the file but we now upload the file to galaxy instead of linking to the files when using an object store", "author": "deepsidhu85", "createdAt": "2021-04-19T14:55:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyMzg3NA=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAwsUtilityImpl.java b/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAwsUtilityImpl.java\nindex 452322397c..a2045d95d7 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAwsUtilityImpl.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAwsUtilityImpl.java\n\n@@ -60,14 +56,11 @@ public class IridaFileStorageAwsUtilityImpl implements IridaFileStorageUtility {\n \t */\n \t@Override\n \tpublic IridaTemporaryFile getTemporaryFile(Path file) {\n-\t\tString perm = \"rwxrwxr-x\";\n \t\ttry {\n \t\t\tlogger.trace(\"Getting file from aws s3 [\" + file.toString() + \"]\");\n \t\t\tPath tempDirectory = Files.createTempDirectory(\"aws-tmp-\");\n \t\t\tPath tempFile = tempDirectory.resolve(file.getFileName()\n \t\t\t\t\t.toString());\n-\t\t\tSet<PosixFilePermission> permissions = PosixFilePermissions.fromString(perm);\n-\t\t\tFiles.setPosixFilePermissions(tempDirectory, permissions);\n \n \t\t\ttry (S3Object s3Object = s3.getObject(bucketName, getAwsFileAbsolutePath(file));\n \t\t\t\t\tS3ObjectInputStream s3ObjectInputStream = s3Object.getObjectContent()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyNjgwNA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578726804", "bodyText": "Should the file processor be deleting directories here or is is the iridaFileStorageUtility?", "author": "tom114", "createdAt": "2021-02-18T20:32:08Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/processing/impl/FastqcFileProcessor.java", "diffHunk": "@@ -160,7 +160,7 @@ private void processSingleFile(SequenceFile sequenceFile) throws FileProcessorEx\n \t\t\ttry {\n \t\t\t\tlogger.trace(\"Removing directory: \" + outputDirectory.toString());\n \t\t\t\t// Delete the analysis-output* temp directory\n-\t\t\t\tFileUtils.deleteDirectory(outputDirectory.toFile());\n+\t\t\t\torg.apache.commons.io.FileUtils.deleteDirectory(outputDirectory.toFile());", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM1OTQ1NA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579359454", "bodyText": "This directory is created by IRIDA and not created by one of the file storage utility classes. So we just let the file processor delete it", "author": "deepsidhu85", "createdAt": "2021-02-19T17:39:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyNjgwNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyNzYwOQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578727609", "bodyText": "Living dangerously going by the JPA docs naming convention \ud83d\ude04 .  Can you add the @Query annotation here even though it'll function exactly the same?  We've just used the @Query in every other JPA repo so I want to stay consistent.", "author": "tom114", "createdAt": "2021-02-18T20:33:38Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/analysis/submission/AnalysisSubmissionTempFileRepository.java", "diffHunk": "@@ -0,0 +1,22 @@\n+package ca.corefacility.bioinformatics.irida.repositories.analysis.submission;\n+\n+import java.util.List;\n+\n+\n+import ca.corefacility.bioinformatics.irida.model.workflow.submission.AnalysisSubmissionTempFile;\n+import ca.corefacility.bioinformatics.irida.repositories.IridaJpaRepository;\n+\n+/**\n+ * A repository for managing {@link AnalysisSubmissionTempFile} objects.\n+ */\n+\n+public interface AnalysisSubmissionTempFileRepository extends IridaJpaRepository<AnalysisSubmissionTempFile, Long> {\n+\n+\t/**\n+\t * Get all {@link AnalysisSubmissionTempFile} objects by submission id.\n+\t *\n+\t * @param analysisSubmissionId The analysis submission id\n+\t * @return a list of {@link AnalysisSubmissionTempFile}\n+\t */\n+\tList<AnalysisSubmissionTempFile> findAllByAnalysisSubmissionId(Long analysisSubmissionId);", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM1OTc1OQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579359759", "bodyText": "Haha I love living dangerously \ud83d\ude06 Sure thing :)", "author": "deepsidhu85", "createdAt": "2021-02-19T17:40:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyNzYwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM4MDU0OA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579380548", "bodyText": "Added @query annotation in eb2d3b4", "author": "deepsidhu85", "createdAt": "2021-02-19T18:14:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODcyNzYwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/repositories/analysis/submission/AnalysisSubmissionTempFileRepository.java b/src/main/java/ca/corefacility/bioinformatics/irida/repositories/analysis/submission/AnalysisSubmissionTempFileRepository.java\ndeleted file mode 100644\nindex d30d82fba4..0000000000\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/repositories/analysis/submission/AnalysisSubmissionTempFileRepository.java\n+++ /dev/null\n\n@@ -1,22 +0,0 @@\n-package ca.corefacility.bioinformatics.irida.repositories.analysis.submission;\n-\n-import java.util.List;\n-\n-\n-import ca.corefacility.bioinformatics.irida.model.workflow.submission.AnalysisSubmissionTempFile;\n-import ca.corefacility.bioinformatics.irida.repositories.IridaJpaRepository;\n-\n-/**\n- * A repository for managing {@link AnalysisSubmissionTempFile} objects.\n- */\n-\n-public interface AnalysisSubmissionTempFileRepository extends IridaJpaRepository<AnalysisSubmissionTempFile, Long> {\n-\n-\t/**\n-\t * Get all {@link AnalysisSubmissionTempFile} objects by submission id.\n-\t *\n-\t * @param analysisSubmissionId The analysis submission id\n-\t * @return a list of {@link AnalysisSubmissionTempFile}\n-\t */\n-\tList<AnalysisSubmissionTempFile> findAllByAnalysisSubmissionId(Long analysisSubmissionId);\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODczMDM4NQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578730385", "bodyText": "We already have the getFileSize function in here.  Can we refactor down to one of those methods in here?  I see that both implementations in IridaFiles just call down to the methods in the FileStorageUtility.  Can you just do the FileUtils.humanReadableByteCount conversion within IridaFiles instead of having both methods in the FileStorageUtility implmentations?", "author": "tom114", "createdAt": "2021-02-18T20:38:45Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageAwsUtilityImpl.java", "diffHunk": "@@ -310,6 +342,46 @@ public String getFileExtension(List<? extends SequencingObject> sequencingObject\n \t\treturn bytes;\n \t}\n \n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic Long getFileSizeBytes(Path file) {\n+\t\tLong fileSize = 0L;\n+\n+\t\ttry(S3Object s3Object = s3.getObject(bucketName, getAwsFileAbsolutePath(file))) {\n+\t\t\tfileSize = s3Object.getObjectMetadata().getContentLength();\n+\t\t} catch (AmazonServiceException e) {\n+\t\t\tlogger.error(\"Unable to get file size from s3 bucket: \" + e);\n+\t\t} catch (IOException e) {\n+\t\t\tlogger.error(\"Unable to close connection to s3object: \" + e);\n+\t\t}\n+\n+\t\treturn fileSize;\n+\t}", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTQzMTA0Ng==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579431046", "bodyText": "Refactored to use just the one method in the storage utility classes in c1fb8af", "author": "deepsidhu85", "createdAt": "2021-02-19T19:38:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODczMDM4NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODc0NTI1Ng==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578745256", "bodyText": "Rather than storing the analysisSubmissionId can you link directly to the AnalysisSubmission?  That way we can keep some integrity between the objects and it's not just a loose ID being passed around.", "author": "tom114", "createdAt": "2021-02-18T21:07:08Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/model/workflow/submission/AnalysisSubmissionTempFile.java", "diffHunk": "@@ -0,0 +1,95 @@\n+package ca.corefacility.bioinformatics.irida.model.workflow.submission;\n+\n+import java.nio.file.Path;\n+import java.util.Date;\n+\n+import javax.persistence.*;\n+import javax.validation.constraints.NotNull;\n+\n+import ca.corefacility.bioinformatics.irida.model.IridaThing;\n+\n+/**\n+ * A temporary file which required by an {@link AnalysisSubmission} when\n+ * the storage type is an object store.\n+ */\n+@Entity\n+@Table(name = \"analysis_submission_temp_files\")\n+public class AnalysisSubmissionTempFile implements IridaThing {\n+\t@Id\n+\t@GeneratedValue(strategy = GenerationType.IDENTITY)\n+\tprivate final Long id;\n+\n+\t@NotNull\n+\t@Column(name = \"analysis_submission_id\")\n+\tprivate final Long analysisSubmissionId;", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTQ5NzIwNg==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579497206", "bodyText": "Linked directly to the AnalysisSubmission in 28c6030", "author": "deepsidhu85", "createdAt": "2021-02-19T21:53:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODc0NTI1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/model/workflow/submission/AnalysisSubmissionTempFile.java b/src/main/java/ca/corefacility/bioinformatics/irida/model/workflow/submission/AnalysisSubmissionTempFile.java\ndeleted file mode 100644\nindex 36a330a86a..0000000000\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/model/workflow/submission/AnalysisSubmissionTempFile.java\n+++ /dev/null\n\n@@ -1,95 +0,0 @@\n-package ca.corefacility.bioinformatics.irida.model.workflow.submission;\n-\n-import java.nio.file.Path;\n-import java.util.Date;\n-\n-import javax.persistence.*;\n-import javax.validation.constraints.NotNull;\n-\n-import ca.corefacility.bioinformatics.irida.model.IridaThing;\n-\n-/**\n- * A temporary file which required by an {@link AnalysisSubmission} when\n- * the storage type is an object store.\n- */\n-@Entity\n-@Table(name = \"analysis_submission_temp_files\")\n-public class AnalysisSubmissionTempFile implements IridaThing {\n-\t@Id\n-\t@GeneratedValue(strategy = GenerationType.IDENTITY)\n-\tprivate final Long id;\n-\n-\t@NotNull\n-\t@Column(name = \"analysis_submission_id\")\n-\tprivate final Long analysisSubmissionId;\n-\n-\t@NotNull\n-\t@Column(name = \"temp_file_path\")\n-\tprivate final Path filePath;\n-\n-\t@NotNull\n-\t@Column(name = \"temp_file_directory_path\")\n-\tprivate final Path fileDirectoryPath;\n-\n-\t@NotNull\n-\t@Temporal(TemporalType.TIMESTAMP)\n-\t@Column(name = \"created_date\")\n-\tprivate final Date createdDate;\n-\n-\t/**\n-\t * for hibernate\n-\t */\n-\t@SuppressWarnings(\"unused\")\n-\tprivate AnalysisSubmissionTempFile() {\n-\t\tthis.analysisSubmissionId = null;\n-\t\tthis.filePath = null;\n-\t\tthis.fileDirectoryPath = null;\n-\t\tthis.id = null;\n-\t\tthis.createdDate = null;\n-\t}\n-\n-\t/**\n-\t * Create a new {@link AnalysisSubmissionTempFile} with the given file\n-\t * analysis submission id, file path, and directory path.\n-\t *\n-\t * @param analysisSubmissionId The id of the {@link AnalysisSubmission}\n-\t * @param filePath The path to the temporary file\n-\t * @param fileDirectoryPath The path to the temporary file directory\n-\t */\n-\tpublic AnalysisSubmissionTempFile(Long analysisSubmissionId, Path filePath, Path fileDirectoryPath) {\n-\t\tthis.analysisSubmissionId = analysisSubmissionId;\n-\t\tthis.filePath = filePath;\n-\t\tthis.fileDirectoryPath = fileDirectoryPath;\n-\t\tthis.id = null;\n-\t\tthis.createdDate = new Date();\n-\t}\n-\n-\t/**\n-\t * Get the implementation-specific file label.\n-\t *\n-\t * @return the file label.\n-\t */\n-\t@Override\n-\tpublic String getLabel() {\n-\t\treturn filePath.getFileName().toString();\n-\t}\n-\n-\t@Override\n-\tpublic Date getCreatedDate() {\n-\t\treturn this.createdDate;\n-\t}\n-\n-\t@Override\n-\tpublic Long getId() {\n-\t\treturn this.id;\n-\t}\n-\n-\tpublic Path getFilePath() {\n-\t\treturn filePath;\n-\t}\n-\n-\tpublic Path getFileDirectoryPath() {\n-\t\treturn fileDirectoryPath;\n-\t}\n-\t\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODc0NzE1NQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578747155", "bodyText": "I see we're passing the StorageType around a lot.  Since we're already passing the iridaFileStorageUtility, can we just make that a property of that object?  That'll remove a dependency and save wiring StorageType around all over the place.", "author": "tom114", "createdAt": "2021-02-18T21:10:32Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java", "diffHunk": "@@ -52,35 +58,42 @@\n \tprivate GalaxyJobErrorsService galaxyJobErrorsService;\n \tprivate JobErrorRepository jobErrorRepository;\n \tprivate final EmailController emailController;\n+\tprivate IridaFileStorageUtility iridaFileStorageUtility;\n \tprivate AnalysisWorkspaceService analysisWorkspaceService;\n-\n+\tprivate AnalysisSubmissionTempFileRepository analysisSubmissionTempFileRepository;\n+\tprivate StorageType storageType;", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM4MDI5OQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579380299", "bodyText": "Updated storage utilities to have storageType as a property in eb2d3b4", "author": "deepsidhu85", "createdAt": "2021-02-19T18:14:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODc0NzE1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java b/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java\nindex 1a1356eedd..0e2a9da2de 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java\n\n@@ -43,25 +38,22 @@ import com.google.common.collect.Sets;\n  */\n public class AnalysisExecutionScheduledTaskImpl implements AnalysisExecutionScheduledTask {\n \n-\tprivate Object prepareAnalysesLock = new Object();\n-\tprivate Object executeAnalysesLock = new Object();\n-\tprivate Object monitorRunningAnalysesLock = new Object();\n-\tprivate Object postProcessingLock = new Object();\n-\tprivate Object transferAnalysesResultsLock = new Object();\n-\tprivate Object cleanupAnalysesResultsLock = new Object();\n+\tprivate final Object prepareAnalysesLock = new Object();\n+\tprivate final Object executeAnalysesLock = new Object();\n+\tprivate final Object monitorRunningAnalysesLock = new Object();\n+\tprivate final Object postProcessingLock = new Object();\n+\tprivate final Object transferAnalysesResultsLock = new Object();\n+\tprivate final Object cleanupAnalysesResultsLock = new Object();\n \n \tprivate static final Logger logger = LoggerFactory.getLogger(AnalysisExecutionScheduledTaskImpl.class);\n \n \tprivate AnalysisSubmissionRepository analysisSubmissionRepository;\n \tprivate AnalysisExecutionService analysisExecutionService;\n-\tprivate final CleanupAnalysisSubmissionCondition cleanupCondition;\n+\tprivate CleanupAnalysisSubmissionCondition cleanupCondition;\n \tprivate GalaxyJobErrorsService galaxyJobErrorsService;\n \tprivate JobErrorRepository jobErrorRepository;\n-\tprivate final EmailController emailController;\n-\tprivate IridaFileStorageUtility iridaFileStorageUtility;\n+\tprivate EmailController emailController;\n \tprivate AnalysisWorkspaceService analysisWorkspaceService;\n-\tprivate AnalysisSubmissionTempFileRepository analysisSubmissionTempFileRepository;\n-\tprivate StorageType storageType;\n \n \t/**\n \t * Builds a new AnalysisExecutionScheduledTaskImpl with the given service\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODc0ODMwMw==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r578748303", "bodyText": "We likely don't need the check here for StorageType.LOCAL since they won't have been created if it wasn't local.  Also if we remove this check, we can add a test for the cleanup function.", "author": "tom114", "createdAt": "2021-02-18T21:12:45Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java", "diffHunk": "@@ -348,4 +374,28 @@ private void handleJobErrors(AnalysisSubmission analysisSubmission) {\n \t\t\treturn cleanedSubmissions;\n \t\t}\n \t}\n+\n+\t/**\n+\t * Cleanup any temporary downloaded files and cleanup associated {@link AnalysisSubmissionTempFile} objects\n+\t *\n+\t * @param submission The analysis submission to clean up temporary downloaded files for\n+\t */\n+\tprivate void cleanupTemporaryDownloadedFiles(AnalysisSubmission submission) {\n+\t\t/*\n+\t\t Cleanup any files that were downloaded from an object store to run an analysis and\n+\t\t remove the analysis submission temp file record from the database.\n+\t\t */\n+\t\tif (!storageType.equals(StorageType.LOCAL)) {", "originalCommit": "1e584140a8b34277397357648c16511bb4bac582", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTM3OTk5NQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r579379995", "bodyText": "Removed check in eb2d3b4", "author": "deepsidhu85", "createdAt": "2021-02-19T18:13:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODc0ODMwMw=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java b/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java\nindex 1a1356eedd..0e2a9da2de 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/service/impl/AnalysisExecutionScheduledTaskImpl.java\n\n@@ -374,28 +347,4 @@ public class AnalysisExecutionScheduledTaskImpl implements AnalysisExecutionSche\n \t\t\treturn cleanedSubmissions;\n \t\t}\n \t}\n-\n-\t/**\n-\t * Cleanup any temporary downloaded files and cleanup associated {@link AnalysisSubmissionTempFile} objects\n-\t *\n-\t * @param submission The analysis submission to clean up temporary downloaded files for\n-\t */\n-\tprivate void cleanupTemporaryDownloadedFiles(AnalysisSubmission submission) {\n-\t\t/*\n-\t\t Cleanup any files that were downloaded from an object store to run an analysis and\n-\t\t remove the analysis submission temp file record from the database.\n-\t\t */\n-\t\tif (!storageType.equals(StorageType.LOCAL)) {\n-\t\t\tList<AnalysisSubmissionTempFile> analysisSubmissionTempFiles = analysisSubmissionTempFileRepository.findAllByAnalysisSubmissionId(\n-\t\t\t\t\tsubmission.getId());\n-\t\t\tlogger.debug(\"Cleaning up \" + analysisSubmissionTempFiles.size()\n-\t\t\t\t\t+ \" temporary files downloaded from object store.\");\n-\t\t\tfor (AnalysisSubmissionTempFile analysisSubmissionTempFile : analysisSubmissionTempFiles) {\n-\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(\n-\t\t\t\t\t\tnew IridaTemporaryFile(analysisSubmissionTempFile.getFilePath(),\n-\t\t\t\t\t\t\t\tanalysisSubmissionTempFile.getFileDirectoryPath()));\n-\t\t\t\tanalysisSubmissionTempFileRepository.delete(analysisSubmissionTempFile);\n-\t\t\t}\n-\t\t}\n-\t}\n }\n"}}, {"oid": "eb2d3b4fd2ef1fc91ed99b94fb0574c6bc579ea9", "url": "https://github.com/phac-nml/irida/commit/eb2d3b4fd2ef1fc91ed99b94fb0574c6bc579ea9", "message": "Updated storage utility classes to contain storagetype as a property. Updated sistr and biohansel sample updaters to use getFileInputStream from IridaFiles so we don't need to autowire in the iridafilestorageutility. Added query annotation. Removed storage type check when cleaning up analysissubmissiontempfile objects.", "committedDate": "2021-02-19T18:12:44Z", "type": "commit"}, {"oid": "c1fb8af8b583d6192f5bbe60e4eac160fa4c5752", "url": "https://github.com/phac-nml/irida/commit/c1fb8af8b583d6192f5bbe60e4eac160fa4c5752", "message": "Updated biohansel and sistr sample updater tests to set the iridaFileStorageUtility for IridaFiles. Refactored storageutility classes to only have one method to get a file size and let IridaFiles return the appropriate response (bytes or human readable string)", "committedDate": "2021-02-19T18:58:49Z", "type": "commit"}, {"oid": "282bab366a17b8646167b7f38e23bf0edfddda3e", "url": "https://github.com/phac-nml/irida/commit/282bab366a17b8646167b7f38e23bf0edfddda3e", "message": "Added mock for analysisSubmissionTempFile to fix broken test", "committedDate": "2021-02-19T19:33:53Z", "type": "commit"}, {"oid": "28c6030222586ca96886f9096c9e5cde3533bfd1", "url": "https://github.com/phac-nml/irida/commit/28c6030222586ca96886f9096c9e5cde3533bfd1", "message": "Updated AnalysisSubmissionTempFile class to link to analysis submission via the AnalysisSubmission object rather than just an id", "committedDate": "2021-02-19T21:52:28Z", "type": "commit"}, {"oid": "11a7a48e89e73f47c7671b3ca0392227d7c3f938", "url": "https://github.com/phac-nml/irida/commit/11a7a48e89e73f47c7671b3ca0392227d7c3f938", "message": "Fixed InvalidUseOfMatchers errors", "committedDate": "2021-02-19T22:09:35Z", "type": "commit"}, {"oid": "aa1153498d672ff5c1c4588caadfe0dfd97cc74e", "url": "https://github.com/phac-nml/irida/commit/aa1153498d672ff5c1c4588caadfe0dfd97cc74e", "message": "Updated tests and fixed javadoc param", "committedDate": "2021-02-22T15:02:53Z", "type": "commit"}, {"oid": "fba505cf0963beea296538030c6ee5a29f6aadf0", "url": "https://github.com/phac-nml/irida/commit/fba505cf0963beea296538030c6ee5a29f6aadf0", "message": "Updated tests", "committedDate": "2021-02-22T15:31:24Z", "type": "commit"}, {"oid": "22cac5a9366cf29a6e9efcd9502e2bf2ba51beda", "url": "https://github.com/phac-nml/irida/commit/22cac5a9366cf29a6e9efcd9502e2bf2ba51beda", "message": "Merged object-store base branch and fixed merge conflicts", "committedDate": "2021-04-14T18:24:29Z", "type": "commit"}, {"oid": "5c11469077d1b2b03ac5c92ded903787514287cf", "url": "https://github.com/phac-nml/irida/commit/5c11469077d1b2b03ac5c92ded903787514287cf", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-04-14T19:10:59Z", "type": "commit"}, {"oid": "93b0401897d56947dce8ba37839206c47788bfac", "url": "https://github.com/phac-nml/irida/commit/93b0401897d56947dce8ba37839206c47788bfac", "message": "Updated to use iridafilestorageutility to get file size bytes as the previous getFileSize method was removed", "committedDate": "2021-04-14T19:14:30Z", "type": "commit"}, {"oid": "8cfa8a6958cbc45cf204d7a46eb33f3b14cd5014", "url": "https://github.com/phac-nml/irida/commit/8cfa8a6958cbc45cf204d7a46eb33f3b14cd5014", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-04-15T13:29:53Z", "type": "commit"}, {"oid": "cca9f04a26e861aab796422db781719cfd72387f", "url": "https://github.com/phac-nml/irida/commit/cca9f04a26e861aab796422db781719cfd72387f", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-04-16T19:35:29Z", "type": "commit"}, {"oid": "7085dc2c26838bde37d6f3330d78d5565c0da639", "url": "https://github.com/phac-nml/irida/commit/7085dc2c26838bde37d6f3330d78d5565c0da639", "message": "Updated to set datastorage to remote if using an object store otherwisse defaults to local", "committedDate": "2021-04-20T15:05:43Z", "type": "commit"}, {"oid": "e61b5fdf870aaae9cc9c7adab764a6bfffcc9e46", "url": "https://github.com/phac-nml/irida/commit/e61b5fdf870aaae9cc9c7adab764a6bfffcc9e46", "message": "Updated to remove permissions required for galaxy to read files as we now just upload the files to galaxy if using a remote filesystem", "committedDate": "2021-04-26T18:38:11Z", "type": "commit"}, {"oid": "70b13b01fe1850cef296b4667e1cd895384902a8", "url": "https://github.com/phac-nml/irida/commit/70b13b01fe1850cef296b4667e1cd895384902a8", "message": "Updated setting of file size for reference file", "committedDate": "2021-04-26T19:12:51Z", "type": "commit"}, {"oid": "10baf40fab533d6e0d96b68f9d8097a6014ec0c3", "url": "https://github.com/phac-nml/irida/commit/10baf40fab533d6e0d96b68f9d8097a6014ec0c3", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-04-26T19:21:37Z", "type": "commit"}, {"oid": "d6922e651aee002a44e04b3345afe878907be435", "url": "https://github.com/phac-nml/irida/commit/d6922e651aee002a44e04b3345afe878907be435", "message": "Removed unused imports", "committedDate": "2021-04-26T19:24:19Z", "type": "commit"}, {"oid": "4bd005c5341b6e0f521e6b935d11986abbf28be0", "url": "https://github.com/phac-nml/irida/commit/4bd005c5341b6e0f521e6b935d11986abbf28be0", "message": "Removed iridaFileStorageUtility autowiring from GalaxyHistoriesService and moved into AnalysisWorkspaceServiceGalaxy when uploading reference files. Updated azure iridafilestorageutility to upload files in blocks rather than in one go to prevent timeouts with larger files", "committedDate": "2021-04-27T19:29:31Z", "type": "commit"}, {"oid": "33da2640d5c18f6b6cf8ae5c7199e1906dd5bc91", "url": "https://github.com/phac-nml/irida/commit/33da2640d5c18f6b6cf8ae5c7199e1906dd5bc91", "message": "Updated azure file storage utility to download files directly rather than through a stream when getting files from azure", "committedDate": "2021-04-27T19:47:11Z", "type": "commit"}, {"oid": "d6a11c24c31816b5a0436ff2cbc3acab5c0ae65d", "url": "https://github.com/phac-nml/irida/commit/d6a11c24c31816b5a0436ff2cbc3acab5c0ae65d", "message": "Removed analysisSubmissionTempFile repository and table as they are no longer required since when using an object store once the files are uploaded to galaxy we remove them", "committedDate": "2021-04-28T13:53:59Z", "type": "commit"}, {"oid": "57b16186e7ab8666d7e0ae41b29fb43c28b80707", "url": "https://github.com/phac-nml/irida/commit/57b16186e7ab8666d7e0ae41b29fb43c28b80707", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-05-17T14:45:09Z", "type": "commit"}, {"oid": "78eb419f0f9a9398f5da54753d056e459ff4c43e", "url": "https://github.com/phac-nml/irida/commit/78eb419f0f9a9398f5da54753d056e459ff4c43e", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-05-18T15:29:17Z", "type": "commit"}, {"oid": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "url": "https://github.com/phac-nml/irida/commit/da59fd20ef17810e207e2cee7805c7c0b452eac3", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-05-20T15:33:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODA0NDg4NQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668044885", "bodyText": "This is no longer used.", "author": "tom114", "createdAt": "2021-07-12T15:42:52Z", "path": "src/test/java/ca/corefacility/bioinformatics/irida/pipeline/upload/galaxy/integration/GalaxyHistoriesServiceIT.java", "diffHunk": "@@ -103,6 +103,8 @@\n \t */\n \tprivate static final int LIBRARY_POLLING_TIME = 5;\n \n+\tprivate static final Long ANALYSIS_SUBMISSION_ID = 1L;", "originalCommit": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODIwNDQ5NQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668204495", "bodyText": "Removed in 50d4f4f", "author": "deepsidhu85", "createdAt": "2021-07-12T19:40:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODA0NDg4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/test/java/ca/corefacility/bioinformatics/irida/pipeline/upload/galaxy/integration/GalaxyHistoriesServiceIT.java b/src/test/java/ca/corefacility/bioinformatics/irida/pipeline/upload/galaxy/integration/GalaxyHistoriesServiceIT.java\nindex 08320f9c7c..561e7623f0 100644\n--- a/src/test/java/ca/corefacility/bioinformatics/irida/pipeline/upload/galaxy/integration/GalaxyHistoriesServiceIT.java\n+++ b/src/test/java/ca/corefacility/bioinformatics/irida/pipeline/upload/galaxy/integration/GalaxyHistoriesServiceIT.java\n\n@@ -103,7 +103,6 @@ public class GalaxyHistoriesServiceIT {\n \t */\n \tprivate static final int LIBRARY_POLLING_TIME = 5;\n \n-\tprivate static final Long ANALYSIS_SUBMISSION_ID = 1L;\n \n \t/**\n \t * Sets up files for history tests.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4MzAzMQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668183031", "bodyText": "Much of these new variables are unused now.", "author": "tom114", "createdAt": "2021-07-12T19:04:28Z", "path": "src/test/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/impl/integration/AnalysisCollectionServiceGalaxyIT.java", "diffHunk": "@@ -121,6 +136,17 @@\n \tprivate static final String FORWARD_NAME = \"forward\";\n \tprivate static final String REVERSE_NAME = \"reverse\";\n \n+\tprivate SingleEndSequenceFile singleEndFile;\n+\tprivate SequenceFile sequenceFile;\n+\tprivate UUID workflowId = UUID.randomUUID();\n+\tprivate ReferenceFile referenceFile;\n+\n+\tprivate static final String analysisId = \"1\";\n+\n+\tprivate final String analysisName = \"analysis 1\";\n+\n+\tprivate User submitter1;", "originalCommit": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODIwNDQ0Ng==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668204446", "bodyText": "Removed in 50d4f4f", "author": "deepsidhu85", "createdAt": "2021-07-12T19:40:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4MzAzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/test/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/impl/integration/AnalysisCollectionServiceGalaxyIT.java b/src/test/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/impl/integration/AnalysisCollectionServiceGalaxyIT.java\nindex 7f24d61cfb..481615638a 100644\n--- a/src/test/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/impl/integration/AnalysisCollectionServiceGalaxyIT.java\n+++ b/src/test/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/impl/integration/AnalysisCollectionServiceGalaxyIT.java\n\n@@ -141,11 +138,6 @@ public class AnalysisCollectionServiceGalaxyIT {\n \tprivate UUID workflowId = UUID.randomUUID();\n \tprivate ReferenceFile referenceFile;\n \n-\tprivate static final String analysisId = \"1\";\n-\n-\tprivate final String analysisName = \"analysis 1\";\n-\n-\tprivate User submitter1;\n \n \t/**\n \t * Sets up variables for testing.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4MzQ5MQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668183491", "bodyText": "Format this to expand out the one-liner please.", "author": "tom114", "createdAt": "2021-07-12T19:05:20Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java", "diffHunk": "@@ -79,14 +86,21 @@ public static String getFileExtension(List<? extends SequencingObject> files) th\n \t}\n \n \t/**\n-\t * Check if file exists\n-\t * Checks if the file exists\n+\t * Gets the file size in bytes of the file from the iridaFileStorageUtility\n \t *\n \t * @param file The path to the file\n-\t * @return if file exists or not\n+\t * @return file size in bytes\n \t */\n-\tpublic static boolean fileExists(Path file) {\n-\t\treturn iridaFileStorageUtility.fileExists(file);\n+\tpublic static Long getFileSizeBytes(Path file) {\n+\t\treturn iridaFileStorageUtility.getFileSizeBytes(file);\n \t}\n \n+\t/**\n+\t * Checks if the file exists in iridaFileStorageUtility\n+\t *\n+\t * @param file The path to the file\n+\t * @return if file exists or not\n+\t */\n+\tpublic static boolean fileExists(Path file) { return iridaFileStorageUtility.fileExists(file);}", "originalCommit": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODIwNDM5Nw==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668204397", "bodyText": "Formatted in 50d4f4f", "author": "deepsidhu85", "createdAt": "2021-07-12T19:40:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4MzQ5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java b/src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java\nindex 3074eeb7d6..69d668d1ee 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/util/IridaFiles.java\n\n@@ -80,7 +80,7 @@ public final class IridaFiles {\n \t * @return the bytes for the file\n \t * @throws IOException if the file couldn't be read\n \t */\n-\tpublic static byte[] getBytesForFile(Path file) throws IOException  {\n+\tpublic static byte[] getBytesForFile(Path file) throws IOException {\n \t\tbyte[] bytes = iridaFileStorageUtility.readAllBytes(file);\n \t\treturn bytes;\n \t}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NDE3Mg==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668184172", "bodyText": "Should this be in a try/catch or finally block?  That way if something fails, the temp file isn't left there.", "author": "tom114", "createdAt": "2021-07-12T19:06:34Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisWorkspaceServiceGalaxy.java", "diffHunk": "@@ -295,14 +301,18 @@ private void prepareReferenceFile(ReferenceFile referenceFile, History workflowH\n \t\t\tWorkflowDetails workflowDetails, WorkflowInvocationInputs inputs)\n \t\t\tthrows UploadException, GalaxyDatasetException, WorkflowException {\n \n-\t\tDataset referenceDataset = galaxyHistoriesService.fileToHistory(referenceFile.getFile(), InputFileType.FASTA,\n+\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(referenceFile.getFile());\n+\n+\t\tDataset referenceDataset = galaxyHistoriesService.fileToHistory(iridaTemporaryFile.getFile(), InputFileType.FASTA,\n \t\t\t\tworkflowHistory);\n \n \t\tString workflowReferenceFileInputId = galaxyWorkflowService.getWorkflowInputId(workflowDetails,\n \t\t\t\treferenceFileLabel);\n \n \t\tinputs.setInput(workflowReferenceFileInputId,\n \t\t\t\tnew WorkflowInvocationInputs.WorkflowInvocationInput(referenceDataset.getId(), WorkflowInvocationInputs.InputSourceType.HDA));\n+\n+\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);", "originalCommit": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODIwNDY2Mg==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668204662", "bodyText": "Yeah that might be a good idea. I will take a look :)", "author": "deepsidhu85", "createdAt": "2021-07-12T19:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NDE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTg3NzkzNg==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r669877936", "bodyText": "Added try/catch to try to delete the file again if an exception is thrown so that the temp file is not left sitting behind in 5579950", "author": "deepsidhu85", "createdAt": "2021-07-14T19:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NDE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MDc4ODUyOQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r670788529", "bodyText": "Updated as discussed in ed32951", "author": "deepsidhu85", "createdAt": "2021-07-15T20:37:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NDE3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisWorkspaceServiceGalaxy.java b/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisWorkspaceServiceGalaxy.java\nindex 3ea0af23d1..c50fd8692e 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisWorkspaceServiceGalaxy.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisWorkspaceServiceGalaxy.java\n\n@@ -299,20 +299,27 @@ public class AnalysisWorkspaceServiceGalaxy implements AnalysisWorkspaceService\n \t */\n \tprivate void prepareReferenceFile(ReferenceFile referenceFile, History workflowHistory, String referenceFileLabel,\n \t\t\tWorkflowDetails workflowDetails, WorkflowInvocationInputs inputs)\n-\t\t\tthrows UploadException, GalaxyDatasetException, WorkflowException {\n+\t\t\tthrows UploadException, GalaxyDatasetException, WorkflowException, IOException {\n \n-\t\tIridaTemporaryFile iridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(referenceFile.getFile());\n+\t\tIridaTemporaryFile iridaTemporaryFile = null;\n+\t\ttry {\n+\t\t\tiridaTemporaryFile = iridaFileStorageUtility.getTemporaryFile(referenceFile.getFile());\n \n-\t\tDataset referenceDataset = galaxyHistoriesService.fileToHistory(iridaTemporaryFile.getFile(), InputFileType.FASTA,\n-\t\t\t\tworkflowHistory);\n+\t\t\tDataset referenceDataset = galaxyHistoriesService.fileToHistory(iridaTemporaryFile.getFile(), InputFileType.FASTA,\n+\t\t\t\t\tworkflowHistory);\n \n-\t\tString workflowReferenceFileInputId = galaxyWorkflowService.getWorkflowInputId(workflowDetails,\n-\t\t\t\treferenceFileLabel);\n+\t\t\tString workflowReferenceFileInputId = galaxyWorkflowService.getWorkflowInputId(workflowDetails,\n+\t\t\t\t\treferenceFileLabel);\n \n-\t\tinputs.setInput(workflowReferenceFileInputId,\n-\t\t\t\tnew WorkflowInvocationInputs.WorkflowInvocationInput(referenceDataset.getId(), WorkflowInvocationInputs.InputSourceType.HDA));\n+\t\t\tinputs.setInput(workflowReferenceFileInputId,\n+\t\t\t\t\tnew WorkflowInvocationInputs.WorkflowInvocationInput(referenceDataset.getId(),\n+\t\t\t\t\t\t\tWorkflowInvocationInputs.InputSourceType.HDA));\n \n-\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);\n+\t\t} finally {\n+\t\t\tif(iridaTemporaryFile != null) {\n+\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFile);\n+\t\t\t}\n+\t\t}\n \t}\n \n \t/**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NjAzOQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668186039", "bodyText": "Something feels wrong with the logic here.  We've got a for loop above making the iridaTemporaryFile*, but only 1 call cleaning them up.  Should that be dealt with differently?", "author": "tom114", "createdAt": "2021-07-12T19:09:31Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisCollectionServiceGalaxy.java", "diffHunk": "@@ -167,6 +186,13 @@ public CollectionResponse uploadSequenceFilesPaired(\n \t\t\t\tdescription.addDatasetElement(pairedElement);\n \t\t\t}\n \t\t}\n+\t\tif(iridaTemporaryFileForward != null) {\n+\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFileForward);\n+\t\t}\n+\n+\t\tif(iridaTemporaryFileReverse != null) {\n+\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFileReverse);\n+\t\t}", "originalCommit": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODIwNDk2OA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668204968", "bodyText": "Looking at it now it does seem incorrect. Looks like I had a brain cramp. Will get it fixed up", "author": "deepsidhu85", "createdAt": "2021-07-12T19:41:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NjAzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTg3NzMwMg==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r669877302", "bodyText": "Updated to cleanup a list of irida temporary files created by the for loops for uploadSequenceFilesSingleEnd and uploadSequenceFilesPaired in 5579950", "author": "deepsidhu85", "createdAt": "2021-07-14T19:03:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NjAzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY3MDc4ODQxMQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r670788411", "bodyText": "Updated as discussed in ed32951", "author": "deepsidhu85", "createdAt": "2021-07-15T20:37:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NjAzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisCollectionServiceGalaxy.java b/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisCollectionServiceGalaxy.java\nindex b113502ada..1dd890d193 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisCollectionServiceGalaxy.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/service/analysis/workspace/galaxy/AnalysisCollectionServiceGalaxy.java\n\n@@ -124,76 +130,106 @@ public class AnalysisCollectionServiceGalaxy {\n \t * given files.\n \t * @throws ExecutionManagerException If there was an error uploading the files.\n \t * @throws IOException               If there was an error reading the sequence file.\n+\t * @throws StorageException          If there was an error removing a temporary file\n \t */\n \tpublic CollectionResponse uploadSequenceFilesPaired(\n \t\t\tMap<Sample, SequenceFilePair> sampleSequenceFilesPaired, History workflowHistory,\n-\t\t\tLibrary workflowLibrary) throws ExecutionManagerException, IOException {\n-\n-\t\tCollectionDescription description = new CollectionDescription();\n-\t\tdescription.setCollectionType(DatasetCollectionType.LIST_PAIRED.toString());\n-\t\tdescription.setName(COLLECTION_NAME_PAIRED);\n-\n-\t\tIridaTemporaryFile iridaTemporaryFileForward = null;\n-\t\tIridaTemporaryFile iridaTemporaryFileReverse = null;\n-\n-\t\tMap<Sample, Path> samplesMapPairForward = new HashMap<>();\n-\t\tMap<Sample, Path> samplesMapPairReverse = new HashMap<>();\n-\t\tSet<Path> pathsToUpload = new HashSet<>();\n-\t\tfor (Sample sample : sampleSequenceFilesPaired.keySet()) {\n-\t\t\tSequenceFilePair sequenceFilePair = sampleSequenceFilesPaired.get(sample);\n-\t\t\tSequenceFile fileForward = sequenceFilePair.getForwardSequenceFile();\n-\t\t\tSequenceFile fileReverse = sequenceFilePair.getReverseSequenceFile();\n-\n-\t\t\tiridaTemporaryFileForward = iridaFileStorageUtility.getTemporaryFile(fileForward.getFile(), \"analysis\");\n-\t\t\tiridaTemporaryFileReverse = iridaFileStorageUtility.getTemporaryFile(fileReverse.getFile(), \"analysis\");\n+\t\t\tLibrary workflowLibrary) throws ExecutionManagerException, IOException, StorageException {\n+\n+\t\tList<IridaTemporaryFile> filesToCleanUp = new ArrayList<>();\n+\t\ttry {\n+\t\t\tCollectionDescription description = new CollectionDescription();\n+\t\t\tdescription.setCollectionType(DatasetCollectionType.LIST_PAIRED.toString());\n+\t\t\tdescription.setName(COLLECTION_NAME_PAIRED);\n+\n+\t\t\tIridaTemporaryFile iridaTemporaryFileForward;\n+\t\t\tIridaTemporaryFile iridaTemporaryFileReverse;\n+\n+\t\t\tMap<Sample, Path> samplesMapPairForward = new HashMap<>();\n+\t\t\tMap<Sample, Path> samplesMapPairReverse = new HashMap<>();\n+\t\t\tSet<Path> pathsToUpload = new HashSet<>();\n+\t\t\tfor (Sample sample : sampleSequenceFilesPaired.keySet()) {\n+\t\t\t\tSequenceFilePair sequenceFilePair = sampleSequenceFilesPaired.get(sample);\n+\t\t\t\tSequenceFile fileForward = sequenceFilePair.getForwardSequenceFile();\n+\t\t\t\tSequenceFile fileReverse = sequenceFilePair.getReverseSequenceFile();\n+\n+\t\t\t\tiridaTemporaryFileForward = iridaFileStorageUtility.getTemporaryFile(fileForward.getFile(), \"analysis\");\n+\t\t\t\tiridaTemporaryFileReverse = iridaFileStorageUtility.getTemporaryFile(fileReverse.getFile(), \"analysis\");\n+\n+\t\t\t\tfilesToCleanUp.add(iridaTemporaryFileForward);\n+\t\t\t\tfilesToCleanUp.add(iridaTemporaryFileReverse);\n+\n+\t\t\t\tsamplesMapPairForward.put(sample, iridaTemporaryFileForward.getFile());\n+\t\t\t\tsamplesMapPairReverse.put(sample, iridaTemporaryFileReverse.getFile());\n+\t\t\t\tpathsToUpload.add(iridaTemporaryFileForward.getFile());\n+\t\t\t\tpathsToUpload.add(iridaTemporaryFileReverse.getFile());\n+\t\t\t}\n \n-\t\t\tsamplesMapPairForward.put(sample, iridaTemporaryFileForward.getFile());\n-\t\t\tsamplesMapPairReverse.put(sample, iridaTemporaryFileReverse.getFile());\n-\t\t\tpathsToUpload.add(iridaTemporaryFileForward.getFile());\n-\t\t\tpathsToUpload.add(iridaTemporaryFileReverse.getFile());\n+\t\t\t// upload files to library and then to a history\n+\t\t\tMap<Path, String> pathHistoryDatasetId = galaxyHistoriesService.filesToLibraryToHistory(pathsToUpload,\n+\t\t\t\t\tworkflowHistory, workflowLibrary, dataStorageType);\n+\n+\t\t\tfor (Sample sample : sampleSequenceFilesPaired.keySet()) {\n+\t\t\t\tPath fileForward = samplesMapPairForward.get(sample);\n+\t\t\t\tPath fileReverse = samplesMapPairReverse.get(sample);\n+\n+\t\t\t\tif (!pathHistoryDatasetId.containsKey(fileForward)) {\n+\t\t\t\t\tthrow new UploadException(\"Error, no corresponding history item found for \" + fileForward);\n+\t\t\t\t} else if (!pathHistoryDatasetId.containsKey(fileReverse)) {\n+\t\t\t\t\tthrow new UploadException(\"Error, no corresponding history item found for \" + fileReverse);\n+\t\t\t\t} else {\n+\t\t\t\t\tString datasetHistoryIdForward = pathHistoryDatasetId.get(fileForward);\n+\t\t\t\t\tString datasetHistoryIdReverse = pathHistoryDatasetId.get(fileReverse);\n+\n+\t\t\t\t\tCollectionElement pairedElement = new CollectionElement();\n+\t\t\t\t\tpairedElement.setName(sample.getSampleName());\n+\t\t\t\t\tpairedElement.setCollectionType(DatasetCollectionType.PAIRED.toString());\n+\n+\t\t\t\t\tHistoryDatasetElement datasetElementForward = new HistoryDatasetElement();\n+\t\t\t\t\tdatasetElementForward.setId(datasetHistoryIdForward);\n+\t\t\t\t\tdatasetElementForward.setName(FORWARD_NAME);\n+\t\t\t\t\tpairedElement.addCollectionElement(datasetElementForward);\n+\n+\t\t\t\t\tHistoryDatasetElement datasetElementReverse = new HistoryDatasetElement();\n+\t\t\t\t\tdatasetElementReverse.setId(datasetHistoryIdReverse);\n+\t\t\t\t\tdatasetElementReverse.setName(REVERSE_NAME);\n+\t\t\t\t\tpairedElement.addCollectionElement(datasetElementReverse);\n+\n+\t\t\t\t\tdescription.addDatasetElement(pairedElement);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn galaxyHistoriesService.constructCollection(description, workflowHistory);\n+\t\t} finally {\n+\t\t\tif (filesToCleanUp.size() > 0) {\n+\t\t\t\tcleanupTemporaryGalaxyFiles(filesToCleanUp);\n+\t\t\t}\n \t\t}\n \n-\t\t// upload files to library and then to a history\n-\t\tMap<Path, String> pathHistoryDatasetId = galaxyHistoriesService.filesToLibraryToHistory(pathsToUpload,\n-\t\t\t\tworkflowHistory, workflowLibrary, dataStorageType);\n-\n-\t\tfor (Sample sample : sampleSequenceFilesPaired.keySet()) {\n-\t\t\tPath fileForward = samplesMapPairForward.get(sample);\n-\t\t\tPath fileReverse = samplesMapPairReverse.get(sample);\n-\n-\t\t\tif (!pathHistoryDatasetId.containsKey(fileForward)) {\n-\t\t\t\tthrow new UploadException(\"Error, no corresponding history item found for \" + fileForward);\n-\t\t\t} else if (!pathHistoryDatasetId.containsKey(fileReverse)) {\n-\t\t\t\tthrow new UploadException(\"Error, no corresponding history item found for \" + fileReverse);\n-\t\t\t} else {\n-\t\t\t\tString datasetHistoryIdForward = pathHistoryDatasetId.get(fileForward);\n-\t\t\t\tString datasetHistoryIdReverse = pathHistoryDatasetId.get(fileReverse);\n-\n-\t\t\t\tCollectionElement pairedElement = new CollectionElement();\n-\t\t\t\tpairedElement.setName(sample.getSampleName());\n-\t\t\t\tpairedElement.setCollectionType(DatasetCollectionType.PAIRED.toString());\n-\n-\t\t\t\tHistoryDatasetElement datasetElementForward = new HistoryDatasetElement();\n-\t\t\t\tdatasetElementForward.setId(datasetHistoryIdForward);\n-\t\t\t\tdatasetElementForward.setName(FORWARD_NAME);\n-\t\t\t\tpairedElement.addCollectionElement(datasetElementForward);\n-\n-\t\t\t\tHistoryDatasetElement datasetElementReverse = new HistoryDatasetElement();\n-\t\t\t\tdatasetElementReverse.setId(datasetHistoryIdReverse);\n-\t\t\t\tdatasetElementReverse.setName(REVERSE_NAME);\n-\t\t\t\tpairedElement.addCollectionElement(datasetElementReverse);\n-\n-\t\t\t\tdescription.addDatasetElement(pairedElement);\n+\t}\n+\n+\t/**\n+\t * Clean up a collection of temporary files that were downloaded and uploaded to Galaxy\n+\t * from an object store\n+\t *\n+\t * @param filesToCleanUp A list of {@link IridaTemporaryFile}'s to cleanup.\n+\t */\n+\tprivate void cleanupTemporaryGalaxyFiles(List<IridaTemporaryFile> filesToCleanUp) {\n+\t\tList<String> exceptions = new ArrayList<>();\n+\t\tfor (IridaTemporaryFile itf : filesToCleanUp) {\n+\t\t\t/*\n+\t\t\t * If there was an error when cleaning up the downloaded temporary\n+\t\t\t * files then add exception message to the list of exception messages\n+\t\t\t */\n+\t\t\ttry {\n+\t\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(itf);\n+\t\t\t} catch (StorageException e) {\n+\t\t\t\texceptions.add(e.getMessage());\n \t\t\t}\n \t\t}\n-\t\tif(iridaTemporaryFileForward != null) {\n-\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFileForward);\n+\t\tif(exceptions.size() > 0) {\n+\t\t\t// Throw StorageException if there were any exceptions in the for loop above\n+\t\t\tString exceptionMsg = String.join(\"\\n\", exceptions);\n+\t\t\tthrow new StorageException(exceptionMsg);\n \t\t}\n-\n-\t\tif(iridaTemporaryFileReverse != null) {\n-\t\t\tiridaFileStorageUtility.cleanupDownloadedLocalTemporaryFiles(iridaTemporaryFileReverse);\n-\t\t}\n-\n-\t\treturn galaxyHistoriesService.constructCollection(description, workflowHistory);\n \t}\n }\n\\ No newline at end of file\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NzA1OQ==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668187059", "bodyText": "These implementations seem odd in all the filestorageutility classes.  Can they just return true or false as needed?", "author": "tom114", "createdAt": "2021-07-12T19:11:10Z", "path": "src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageLocalUtilityImpl.java", "diffHunk": "@@ -260,4 +285,11 @@ public boolean checkWriteAccess(Path baseDirectory) {\n \t\treturn true;\n \t}\n \n+\t/**\n+\t * {@inheritDoc}\n+\t */\n+\t@Override\n+\tpublic boolean isStorageTypeLocal() {\n+\t\treturn storageType.equals(StorageType.LOCAL);\n+\t}", "originalCommit": "da59fd20ef17810e207e2cee7805c7c0b452eac3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODIwNDI5MA==", "url": "https://github.com/phac-nml/irida/pull/762#discussion_r668204290", "bodyText": "Yup that works! Updated in 50d4f4f", "author": "deepsidhu85", "createdAt": "2021-07-12T19:39:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2ODE4NzA1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3c3c748946d7e1ae333646bcde747f13137c59d3", "chunk": "diff --git a/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageLocalUtilityImpl.java b/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageLocalUtilityImpl.java\nindex f626623a8a..78742ce527 100644\n--- a/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageLocalUtilityImpl.java\n+++ b/src/main/java/ca/corefacility/bioinformatics/irida/repositories/filesystem/IridaFileStorageLocalUtilityImpl.java\n\n@@ -290,6 +288,6 @@ public class IridaFileStorageLocalUtilityImpl implements IridaFileStorageUtility\n \t */\n \t@Override\n \tpublic boolean isStorageTypeLocal() {\n-\t\treturn storageType.equals(StorageType.LOCAL);\n+\t\treturn true;\n \t}\n }\n"}}, {"oid": "50d4f4fd7d2a884fc1dc8abc61771bc106536aad", "url": "https://github.com/phac-nml/irida/commit/50d4f4fd7d2a884fc1dc8abc61771bc106536aad", "message": "Removed unused variables, fixed formatting, removed StorageType logic in file storage utility classes when checking if storage type is local or not and replaced with true/false", "committedDate": "2021-07-12T19:38:59Z", "type": "commit"}, {"oid": "55799501f82e13585f8b7a670ee3feace53f349c", "url": "https://github.com/phac-nml/irida/commit/55799501f82e13585f8b7a670ee3feace53f349c", "message": "Updated logic to cleanup a list of iridatemporaryfiles. Added try/catch block to cleaning up temporary downloaded files so if an exception is thrown we try to remove the temp file again so that it is not left behind", "committedDate": "2021-07-14T19:00:19Z", "type": "commit"}, {"oid": "ed329514516fc78562b1070af2fde122f529ae42", "url": "https://github.com/phac-nml/irida/commit/ed329514516fc78562b1070af2fde122f529ae42", "message": "Moved logic into try/finally block so temp files get cleared even if an exception is thrown", "committedDate": "2021-07-15T19:57:16Z", "type": "commit"}, {"oid": "9e2ce84c606ff33198453f1609b6eff648cf0ffc", "url": "https://github.com/phac-nml/irida/commit/9e2ce84c606ff33198453f1609b6eff648cf0ffc", "message": "Removed unused import and updated javadoc", "committedDate": "2021-07-15T20:40:10Z", "type": "commit"}, {"oid": "1d083a5375a05f2e726e2d95c00ccfe0413511bb", "url": "https://github.com/phac-nml/irida/commit/1d083a5375a05f2e726e2d95c00ccfe0413511bb", "message": "Updated to store exception messages in a list and once the for loop is done executing then throw the exceptions", "committedDate": "2021-07-16T17:30:46Z", "type": "commit"}, {"oid": "57ffc590613d7805770f014a0b6f1dcbd7f4c20e", "url": "https://github.com/phac-nml/irida/commit/57ffc590613d7805770f014a0b6f1dcbd7f4c20e", "message": "Merge branch 'object-store' into object_store/_analysis-submissions", "committedDate": "2021-08-09T20:48:55Z", "type": "commit"}, {"oid": "bf8e1598df8e01d640a7057b16f1404fc01fc3f1", "url": "https://github.com/phac-nml/irida/commit/bf8e1598df8e01d640a7057b16f1404fc01fc3f1", "message": "Merged object store base branch and fixed merge conflict", "committedDate": "2021-08-10T17:41:27Z", "type": "commit"}, {"oid": "db0fc89bb4df07050072e0dd548e0b3e34a0e35b", "url": "https://github.com/phac-nml/irida/commit/db0fc89bb4df07050072e0dd548e0b3e34a0e35b", "message": "Fixed bug with incorrect files  being uploaded into galaxy due to an incorrect file identifier that was being returned in GalaxyLibrariesService", "committedDate": "2021-08-24T21:06:58Z", "type": "commit"}]}