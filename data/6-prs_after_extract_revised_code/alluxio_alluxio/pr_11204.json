{"pr_number": 11204, "pr_title": "Improve metadata sync operations", "pr_createdAt": "2020-03-24T16:14:14Z", "pr_url": "https://github.com/Alluxio/alluxio/pull/11204", "timeline": [{"oid": "0d77a3a975661bce5c480abcdb6a14b5fdb1b3da", "url": "https://github.com/Alluxio/alluxio/commit/0d77a3a975661bce5c480abcdb6a14b5fdb1b3da", "message": "temp commit", "committedDate": "2020-03-24T16:23:41Z", "type": "forcePushed"}, {"oid": "b4796b83c2c17ca7469c0448e88004b884cb66b3", "url": "https://github.com/Alluxio/alluxio/commit/b4796b83c2c17ca7469c0448e88004b884cb66b3", "message": "temp commit", "committedDate": "2020-03-24T16:45:50Z", "type": "forcePushed"}, {"oid": "bc4d33422a0a5979c01b6c400c2b5035ca69b2d0", "url": "https://github.com/Alluxio/alluxio/commit/bc4d33422a0a5979c01b6c400c2b5035ca69b2d0", "message": "Fixed FSMasterRestartIT, UfsSyncIT, PinIT, ReadOnlyMountIT", "committedDate": "2020-03-25T08:34:53Z", "type": "forcePushed"}, {"oid": "8fb4cabb89411d23c5538a5fbb524b31570ac6ce", "url": "https://github.com/Alluxio/alluxio/commit/8fb4cabb89411d23c5538a5fbb524b31570ac6ce", "message": "Fixed FSMasterRestartIT, UfsSyncIT, PinIT, ReadOnlyMountIT", "committedDate": "2020-03-25T09:28:28Z", "type": "forcePushed"}, {"oid": "2270cb22c90e1078930570abf0256783f65695cd", "url": "https://github.com/Alluxio/alluxio/commit/2270cb22c90e1078930570abf0256783f65695cd", "message": "Add UfsStatus Prefetch mechanism", "committedDate": "2020-03-26T00:15:29Z", "type": "forcePushed"}, {"oid": "ee07539a8dc549542162cdf87931d05621d807ae", "url": "https://github.com/Alluxio/alluxio/commit/ee07539a8dc549542162cdf87931d05621d807ae", "message": "Add UfsStatus Prefetch mechanism", "committedDate": "2020-03-26T15:52:37Z", "type": "forcePushed"}, {"oid": "52b9f426ffbc0b0edf70f63d335e96225069aeb9", "url": "https://github.com/Alluxio/alluxio/commit/52b9f426ffbc0b0edf70f63d335e96225069aeb9", "message": "Re-architect syncing primitive in FileSystemMaster", "committedDate": "2020-03-27T15:15:14Z", "type": "forcePushed"}, {"oid": "66ee306530d4ad3c6837bbb1e81d181cc565738b", "url": "https://github.com/Alluxio/alluxio/commit/66ee306530d4ad3c6837bbb1e81d181cc565738b", "message": "Appease findbugs and make parallelism configurable", "committedDate": "2020-04-03T17:29:57Z", "type": "forcePushed"}, {"oid": "d0800a320ddfd09aa0db26ec3e23b188de2c248a", "url": "https://github.com/Alluxio/alluxio/commit/d0800a320ddfd09aa0db26ec3e23b188de2c248a", "message": "Split sync executor size from sync concurrency\n\nThis can help limit the impact of a single sync job on the\nperformance of Alluxio as a whole. This is especially\nimportant if more than one path is being synced at a time.\nIt allows for a limited level of concurrency but still lets\nus share a single thread pool for executing sync tasks.", "committedDate": "2020-04-06T04:48:03Z", "type": "forcePushed"}, {"oid": "4922a6e6daa7f55b8f6c5151a8c14f36f30a08a3", "url": "https://github.com/Alluxio/alluxio/commit/4922a6e6daa7f55b8f6c5151a8c14f36f30a08a3", "message": "Remove unnecessary logs", "committedDate": "2020-04-23T19:22:05Z", "type": "forcePushed"}, {"oid": "6b7d52bc3f226f8e2c7ffb0e65b2df90f496343e", "url": "https://github.com/Alluxio/alluxio/commit/6b7d52bc3f226f8e2c7ffb0e65b2df90f496343e", "message": "Fix FSMSyncMetadataTest", "committedDate": "2020-04-28T19:59:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY3NzUxMA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417677510", "bodyText": "is this change related to this PR?", "author": "gpang", "createdAt": "2020-04-29T23:50:32Z", "path": "core/client/fs/src/test/java/alluxio/client/metrics/MetricsHeartbeatContextTest.java", "diffHunk": "@@ -41,8 +41,8 @@\n \n   @Test\n   public void testExecutorInitialized() {\n-\n     InstancedConfiguration conf = ConfigurationTestUtils.defaults();\n+    conf.set(PropertyKey.MASTER_HOSTNAME, \"localhost\");", "originalCommit": "6b7d52bc3f226f8e2c7ffb0e65b2df90f496343e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4OTg3MA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417689870", "bodyText": "This test was failing for me locally without that change...I can try reverting it", "author": "ZacBlanco", "createdAt": "2020-04-30T00:31:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY3NzUxMA=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/client/fs/src/test/java/alluxio/client/metrics/MetricsHeartbeatContextTest.java b/core/client/fs/src/test/java/alluxio/client/metrics/MetricsHeartbeatContextTest.java\nindex f7c7d80601..132804dff4 100644\n--- a/core/client/fs/src/test/java/alluxio/client/metrics/MetricsHeartbeatContextTest.java\n+++ b/core/client/fs/src/test/java/alluxio/client/metrics/MetricsHeartbeatContextTest.java\n\n@@ -41,8 +41,8 @@ public class MetricsHeartbeatContextTest {\n \n   @Test\n   public void testExecutorInitialized() {\n+\n     InstancedConfiguration conf = ConfigurationTestUtils.defaults();\n-    conf.set(PropertyKey.MASTER_HOSTNAME, \"localhost\");\n     conf.set(PropertyKey.USER_RPC_RETRY_MAX_DURATION, \"1s\");\n     ClientContext ctx = ClientContext.create(conf);\n     MasterInquireClient client = MasterInquireClient.Factory\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY3ODAwNw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417678007", "bodyText": "finish these params", "author": "gpang", "createdAt": "2020-04-29T23:51:58Z", "path": "core/server/master/src/main/java/alluxio/master/file/meta/LockingScheme.java", "diffHunk": "@@ -38,6 +41,26 @@ public LockingScheme(AlluxioURI path, LockPattern desiredLockPattern, boolean sh\n     mShouldSync = shouldSync;\n   }\n \n+  /**\n+   * Create a new {@link LockingScheme}.\n+   *\n+   * @param path a", "originalCommit": "6b7d52bc3f226f8e2c7ffb0e65b2df90f496343e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/meta/LockingScheme.java b/core/server/master/src/main/java/alluxio/master/file/meta/LockingScheme.java\nindex be51355b19..1a81e351e3 100644\n--- a/core/server/master/src/main/java/alluxio/master/file/meta/LockingScheme.java\n+++ b/core/server/master/src/main/java/alluxio/master/file/meta/LockingScheme.java\n\n@@ -41,26 +38,6 @@ public final class LockingScheme {\n     mShouldSync = shouldSync;\n   }\n \n-  /**\n-   * Create a new {@link LockingScheme}.\n-   *\n-   * @param path a\n-   * @param desiredPattern a\n-   * @param options a\n-   * @param pathCache a\n-   * @param isGetFileInfo a\n-   */\n-  public LockingScheme(AlluxioURI path, LockPattern desiredPattern,\n-      FileSystemMasterCommonPOptions options, UfsSyncPathCache pathCache, boolean isGetFileInfo) {\n-    mPath = path;\n-    mDesiredLockPattern = desiredPattern;\n-    // If client options didn't specify the interval, fallback to whatever the server has\n-    // configured to prevent unnecessary syncing due to the default value being 0\n-    long syncInterval = options.hasSyncIntervalMs() ? options.getSyncIntervalMs() :\n-        ServerConfiguration.getMs(PropertyKey.USER_FILE_METADATA_SYNC_INTERVAL);\n-    mShouldSync = pathCache.shouldSyncPath(path.getPath(), syncInterval, isGetFileInfo);\n-  }\n-\n   /**\n    * @return the desired mode for the locking\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MTkzNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417681935", "bodyText": "Should this be a parameter? Also, do we want to loop indefinitely, or throw some sort of exception when it was looping for too long? I'd imagine throwing an exception would prevent possible deadlocks or long delays, but failures would be less-user friendly. What do you think?", "author": "gpang", "createdAt": "2020-04-30T00:04:29Z", "path": "core/common/src/main/java/alluxio/resource/LockResource.java", "diffHunk": "@@ -35,24 +39,39 @@\n    * @param lock the lock to acquire\n    */\n   public LockResource(Lock lock) {\n-    this(lock, true);\n+    this(lock, true, false);\n   }\n \n   /**\n    * Creates a new instance of {@link LockResource} using the given lock.\n    *\n+   * This method may use the {@link Lock#tryLock()} method to gain ownership of the locks. The\n+   * reason one might want to use this is to avoid the fairness heuristics within the\n+   * {@link java.util.concurrent.locks.ReentrantReadWriteLock}'s NonFairSync which may block reader\n+   * threads if a writer if the first in the queue.\n+   *\n    * @param lock the lock to acquire\n    * @param acquireLock whether to lock the lock\n+   * @param useTryLock whether or not use to {@link Lock#tryLock()}\n    */\n-  public LockResource(Lock lock, boolean acquireLock) {\n+  public LockResource(Lock lock, boolean acquireLock, boolean useTryLock) {\n     mLock = lock;\n     if (acquireLock) {\n-      mLock.lock();\n+      if (useTryLock) {\n+        while (!mLock.tryLock()) { // returns immediately\n+          // The reason we don't use #tryLock(int, TimeUnit) here is because we found there is a bug\n+          // somewhere in the internal accounting of the ReentrantRWLock that, even though all\n+          // threads had released the lock, that a final thread would never be able to acquire it.\n+          LockSupport.parkNanos(10000);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY5MDU0Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417690546", "bodyText": "The current implementation before tryLock will also hang indefinitely, so I felt it was okay to not have any timeout for the tryLock code path.\nAnd I don't think this should really be configurable on the user end. I think it's too low-level and the likelihood someone would ever want to configure this is very, very low. I've done some testing myself and found 10000 to be suitable for most situations so we don't constantly eat CPU cycles, but also try often enough so that we can still make progress without parking the threads for too long.", "author": "ZacBlanco", "createdAt": "2020-04-30T00:33:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MTkzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/common/src/main/java/alluxio/resource/LockResource.java b/core/common/src/main/java/alluxio/resource/LockResource.java\nindex 17c3a5cc41..c93f3c5990 100644\n--- a/core/common/src/main/java/alluxio/resource/LockResource.java\n+++ b/core/common/src/main/java/alluxio/resource/LockResource.java\n\n@@ -39,39 +35,24 @@ public class LockResource implements Closeable {\n    * @param lock the lock to acquire\n    */\n   public LockResource(Lock lock) {\n-    this(lock, true, false);\n+    this(lock, true);\n   }\n \n   /**\n    * Creates a new instance of {@link LockResource} using the given lock.\n    *\n-   * This method may use the {@link Lock#tryLock()} method to gain ownership of the locks. The\n-   * reason one might want to use this is to avoid the fairness heuristics within the\n-   * {@link java.util.concurrent.locks.ReentrantReadWriteLock}'s NonFairSync which may block reader\n-   * threads if a writer if the first in the queue.\n-   *\n    * @param lock the lock to acquire\n    * @param acquireLock whether to lock the lock\n-   * @param useTryLock whether or not use to {@link Lock#tryLock()}\n    */\n-  public LockResource(Lock lock, boolean acquireLock, boolean useTryLock) {\n+  public LockResource(Lock lock, boolean acquireLock) {\n     mLock = lock;\n     if (acquireLock) {\n-      if (useTryLock) {\n-        while (!mLock.tryLock()) { // returns immediately\n-          // The reason we don't use #tryLock(int, TimeUnit) here is because we found there is a bug\n-          // somewhere in the internal accounting of the ReentrantRWLock that, even though all\n-          // threads had released the lock, that a final thread would never be able to acquire it.\n-          LockSupport.parkNanos(10000);\n-        }\n-      } else {\n-        mLock.lock();\n-      }\n+      mLock.lock();\n     }\n   }\n \n   /**\n-   * Returns true if the other {@link LockResource} contains the same lock.\n+   * Returns true if the other lockresource contains the same lock.\n    *\n    * @param other other LockResource\n    * @return true if the other lockResource has the same lock\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MjcyNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417682726", "bodyText": "How does this relate to the other parameters, MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE and MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE? Also, it would be helpful to state what the potential tradeoffs are for a higher vs lower value (for the other parameters as well).", "author": "gpang", "createdAt": "2020-04-30T00:06:45Z", "path": "core/common/src/main/java/alluxio/conf/PropertyKey.java", "diffHunk": "@@ -2132,6 +2132,30 @@ public String toString() {\n           .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n           .setScope(Scope.MASTER)\n           .build();\n+  public static final PropertyKey MASTER_METADATA_SYNC_CONCURRENCY_LEVEL =\n+      new Builder(Name.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL)\n+          .setDefaultValue(6)\n+          .setDescription(\"The maximum number of concurrent sync tasks running for a given sync \"", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc1NTczOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417755739", "bodyText": "Good question\n\nMASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE\n\nThis parameter determines exactly how many inodes can be processing sync in parallel.\nThe executor affected by this value is shared by all RPC calls to the master. So if you have 64 total threads in this executor, then a syncMetadata operation from a listStatus will compete for threads (submit tasks to the same executor) as a createDirectory RPC.\n\n\n\nNow imagine you have a user who does a listStatus RPC that is high up in the inode tree, say, /dir1; but then another user comes along who wants to call getStatus on /dir2. It is mutually exclusive from /dir1, and may trigger a metadata sync, but if we allow listStatus on /dir1 to use all threads within this executor, concurrent sync operations could suffer in performance, even if /dir2 does not contain a large tree structure.\n\nMASTER_METADATA_SYNC_CONCURRENCY_LEVEL restricts max #of threads a single RPC is allowed to use at any given time for processing an inode sync.\n\nThe reason that MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE is separate is because in order to make progress during sync, ufs prefetch threads must be available, and so if all threads in MASTER_METADATA_SYNC_CONCURRENCY_LEVEL are taken and none can be used for ufs fetching, then we could run into a deadlock scenario. There is no limit per sync operation on how many threads can be used for prefetch. Though the throughput of requests to the prefetch pool is limited to an extent by the MASTER_METADATA_SYNC_CONCURRENCY_LEVEL", "author": "ZacBlanco", "createdAt": "2020-04-30T05:06:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MjcyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjg5Mjk4Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r422892982", "bodyText": "could we have some of these comments in the source code?  helps the next reader", "author": "yuzhu", "createdAt": "2020-05-11T09:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MjcyNg=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/common/src/main/java/alluxio/conf/PropertyKey.java b/core/common/src/main/java/alluxio/conf/PropertyKey.java\nindex 2542c5f080..5cd4bbe4c3 100644\n--- a/core/common/src/main/java/alluxio/conf/PropertyKey.java\n+++ b/core/common/src/main/java/alluxio/conf/PropertyKey.java\n\n@@ -2132,30 +2132,6 @@ public final class PropertyKey implements Comparable<PropertyKey> {\n           .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n           .setScope(Scope.MASTER)\n           .build();\n-  public static final PropertyKey MASTER_METADATA_SYNC_CONCURRENCY_LEVEL =\n-      new Builder(Name.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL)\n-          .setDefaultValue(6)\n-          .setDescription(\"The maximum number of concurrent sync tasks running for a given sync \"\n-              + \"operation\")\n-          .setScope(Scope.MASTER)\n-          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n-          .build();\n-  public static final PropertyKey MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE =\n-      new Builder(Name.MASTER_METADATA_SYNC_EXECUTOR_POOL_SIZE)\n-          .setDefaultValue(32)\n-          .setDescription(\"The number of threads used to execute all metadata sync\"\n-              + \"operations\")\n-          .setScope(Scope.MASTER)\n-          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n-          .build();\n-  public static final PropertyKey MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE =\n-      new Builder(Name.MASTER_METADATA_SYNC_UFS_PREFETCH_POOL_SIZE)\n-          .setDefaultValue(32)\n-          .setDescription(\"The number of threads used to fetch UFS objects for all metadata sync\"\n-              + \"operations\")\n-          .setScope(Scope.MASTER)\n-          .setConsistencyCheckLevel(ConsistencyCheckLevel.WARN)\n-          .build();\n   public static final PropertyKey MASTER_RPC_EXECUTOR_PARALLELISM =\n       new Builder(Name.MASTER_RPC_EXECUTOR_PARALLELISM)\n           .setDefaultSupplier(() -> 2 * Runtime.getRuntime().availableProcessors(),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MzgyOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417683829", "bodyText": "Is this test useful anymore, if it is not validating how the load is happening?", "author": "gpang", "createdAt": "2020-04-30T00:10:30Z", "path": "tests/src/test/java/alluxio/client/fs/LoadMetadataIntegrationTest.java", "diffHunk": "@@ -219,15 +219,9 @@ public void loadRecursive() throws Exception {\n         fileWriter.close();\n       }\n     }\n-    long startMs = CommonUtils.getCurrentMs();\n     List<URIStatus> list = mFileSystem.listStatus(new AlluxioURI(\"/mnt\"), options);\n-    long durationMs = CommonUtils.getCurrentMs() - startMs;\n     // 25 files, 25 level 2 dirs, 5 level 1 dirs, 1 file and 1 dir created in before\n     Assert.assertEquals(25 * 2 + 5 + 2, list.size());\n-\n-    // Should load metadata once, in one recursive call", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4OTY3NA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r417689674", "bodyText": "I think validating the listStatus size is better than validating the runtime? Runtime can vary for a lot of reasons during tests- especially in jenkins if a system is overloaded.\nWe might be able to come up with some better assertions, but I think the test is still validating that we load metadata since all of the file creations above are through the UFS, and then the listStatus call is executed through Alluxio, so we verify that at least all of the files expected are loaded in Alluxio under the /mnt path.", "author": "ZacBlanco", "createdAt": "2020-04-30T00:30:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzY4MzgyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/tests/src/test/java/alluxio/client/fs/LoadMetadataIntegrationTest.java b/tests/src/test/java/alluxio/client/fs/LoadMetadataIntegrationTest.java\nindex 307ef904f8..cb94f9b41e 100644\n--- a/tests/src/test/java/alluxio/client/fs/LoadMetadataIntegrationTest.java\n+++ b/tests/src/test/java/alluxio/client/fs/LoadMetadataIntegrationTest.java\n\n@@ -219,9 +219,15 @@ public class LoadMetadataIntegrationTest extends BaseIntegrationTest {\n         fileWriter.close();\n       }\n     }\n+    long startMs = CommonUtils.getCurrentMs();\n     List<URIStatus> list = mFileSystem.listStatus(new AlluxioURI(\"/mnt\"), options);\n+    long durationMs = CommonUtils.getCurrentMs() - startMs;\n     // 25 files, 25 level 2 dirs, 5 level 1 dirs, 1 file and 1 dir created in before\n     Assert.assertEquals(25 * 2 + 5 + 2, list.size());\n+\n+    // Should load metadata once, in one recursive call\n+    Assert.assertTrue(\"Expected to be between one and two SLEEP_MS. actual duration (ms): \"\n+            + durationMs, durationMs >= LONG_SLEEP_MS && durationMs <= 2 * LONG_SLEEP_MS);\n   }\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2MzE4Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418263186", "bodyText": "NIT\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  throw new IOException(\"Failed to await evictor termination\", e);\n          \n          \n            \n                  throw new IOException(\"Failed to await LockPool evictor termination\", e);", "author": "gpang", "createdAt": "2020-04-30T20:16:02Z", "path": "core/common/src/main/java/alluxio/collections/LockPool.java", "diffHunk": "@@ -77,8 +82,20 @@ public LockPool(Function<? super K, ? extends ReentrantReadWriteLock> defaultLoa\n     mHighWatermark = highWatermark;\n     mPool = new ConcurrentHashMap<>(initialSize, DEFAULT_LOAD_FACTOR, concurrencyLevel);\n     mEvictor = Executors.newSingleThreadExecutor(\n-        ThreadFactoryUtils.build(EVICTOR_THREAD_NAME, true));\n-    mEvictor.submit(new Evictor());\n+        ThreadFactoryUtils.build(String.format(\"%s-%s\", EVICTOR_THREAD_NAME, toString()), true));\n+    mEvictorTask = mEvictor.submit(new Evictor());\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    mEvictorTask.cancel(true);\n+    mEvictor.shutdownNow(); // immediately halt the evictor thread.\n+    try {\n+      mEvictor.awaitTermination(2, TimeUnit.SECONDS);\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      throw new IOException(\"Failed to await evictor termination\", e);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDMxMw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364313", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:37:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2MzE4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/common/src/main/java/alluxio/collections/LockPool.java b/core/common/src/main/java/alluxio/collections/LockPool.java\nindex b92681a971..e7ad0ebb5e 100644\n--- a/core/common/src/main/java/alluxio/collections/LockPool.java\n+++ b/core/common/src/main/java/alluxio/collections/LockPool.java\n\n@@ -82,20 +77,8 @@ public class LockPool<K> implements Closeable {\n     mHighWatermark = highWatermark;\n     mPool = new ConcurrentHashMap<>(initialSize, DEFAULT_LOAD_FACTOR, concurrencyLevel);\n     mEvictor = Executors.newSingleThreadExecutor(\n-        ThreadFactoryUtils.build(String.format(\"%s-%s\", EVICTOR_THREAD_NAME, toString()), true));\n-    mEvictorTask = mEvictor.submit(new Evictor());\n-  }\n-\n-  @Override\n-  public void close() throws IOException {\n-    mEvictorTask.cancel(true);\n-    mEvictor.shutdownNow(); // immediately halt the evictor thread.\n-    try {\n-      mEvictor.awaitTermination(2, TimeUnit.SECONDS);\n-    } catch (InterruptedException e) {\n-      Thread.currentThread().interrupt();\n-      throw new IOException(\"Failed to await evictor termination\", e);\n-    }\n+        ThreadFactoryUtils.build(EVICTOR_THREAD_NAME, true));\n+    mEvictor.submit(new Evictor());\n   }\n \n   private final class Evictor implements Runnable {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NTAwMg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418265002", "bodyText": "The param is nullable, what does that mean? Can you update this line?", "author": "gpang", "createdAt": "2020-04-30T20:19:27Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDI5Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364293", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NTAwMg=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NzUxMQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418267511", "bodyText": "what is prev for, and if it was already there, what should we do?", "author": "gpang", "createdAt": "2020-04-30T20:24:32Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzNDMzOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418334339", "bodyText": "since it's a cache, I just ignore the previous value. We should never add the same status twice to the cache with the current code path, but if it does happen I think overwriting it is fine.\nI will update this method to return the old status if there is one. No one in the current code will use the result though.", "author": "ZacBlanco", "createdAt": "2020-04-30T22:55:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NzUxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDI2Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364262", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NzUxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2Nzc3NA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418267774", "bodyText": "why is this check done after it was inserted?", "author": "gpang", "createdAt": "2020-04-30T20:25:00Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzNDgyMg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418334822", "bodyText": "ooh..good catch", "author": "ZacBlanco", "createdAt": "2020-04-30T22:56:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2Nzc3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDI0Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364242", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2Nzc3NA=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzE1Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418293152", "bodyText": "When is this parent-child relationship used?", "author": "gpang", "createdAt": "2020-04-30T21:14:39Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzNTMzMg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418335332", "bodyText": "here and here", "author": "ZacBlanco", "createdAt": "2020-04-30T22:58:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzE1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NDgwNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418294805", "bodyText": "Why can't we add this parent->children listing cache even if the parent status is not in the other map?", "author": "gpang", "createdAt": "2020-04-30T21:18:06Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzNTQ0Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418335446", "bodyText": "ah, this was a limitation of my previous implementation. It is possible now.", "author": "ZacBlanco", "createdAt": "2020-04-30T22:58:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NDgwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDIwNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364206", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NDgwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418295473", "bodyText": "Is the contract that if the status DNE, then the children list DNE for that path? It is unclear what the relationship is between the 2 maps.", "author": "gpang", "createdAt": "2020-04-30T21:19:27Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0MjMxOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418342319", "bodyText": "the child map is a 1:N mapping of alluxio directory to UFS children.\nIf we remove the parent status from the cache, then it's assumed that we won't need to access its parent-child relationship information either. The UfsStatus information for each individual child still resides in mStatuses after calling remove", "author": "ZacBlanco", "createdAt": "2020-04-30T23:20:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0MzUwOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418343509", "bodyText": "Another solution is to make the parent-child relationship removal independent of the removing a single status, but then status removal will need 2 calls, and I think that is more prone to errors. We want to remove those references otherwise the JVM won't be able to GC the children if they are removed individually.", "author": "ZacBlanco", "createdAt": "2020-04-30T23:24:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4MDI3Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419580272", "bodyText": "Ok, so if the structure is /parent/child and /parent is removed, it looks like the child listing is removed for /parent, but the status may still remain for /parent/child?\nIs this status cache supposed to be thread safe?", "author": "gpang", "createdAt": "2020-05-04T16:53:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYxMzY1Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419613656", "bodyText": "Yes\nYes. Do you see thread-safety issues?", "author": "ZacBlanco", "createdAt": "2020-05-04T17:46:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjkwNDkzOA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r422904938", "bodyText": "in this case, are we ok with dangling cache entries? for a path /a/b/c, if /a is removed , /a/b -> {/a/b/c} is still in the cache, so is /a/b, do you think we should do cascading removal?", "author": "yuzhu", "createdAt": "2020-05-11T09:24:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjkwNTU3Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r422905576", "bodyText": "let's say /a is removed and added later, it will suddenly get many entries from the past", "author": "yuzhu", "createdAt": "2020-05-11T09:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE3OTU4NA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r423179584", "bodyText": "@ZacBlanco Is there any relationship between the listings cache, and the status cache? Meaning, if the listing cache has the mapping /parent/ -> [/parent/a, /parent/b, /parent/c], is the status cache guaranteed to have the status of /parent/a, /parent/b, and /parent/c?", "author": "gpang", "createdAt": "2020-05-11T16:52:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzIwNTM2OA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r423205368", "bodyText": "@yuzhu  We don't want to do a cascading removal because it would be removing statuses from the cache that are potentially used in a later part of the sync.\nThe implementation is designed for the inode sync stream so that the statuses can be re-used later without needing to do more UFS listings. Additionally, the way this is used is that the parent is always synced and removed before a child status even begins to sync.\nWe remove only the information that was needed for the parent to sync, while leaving all information about children in-tact so they don't need to call to the UFS when they are synced. Then the children then add information about their children to the cache, while removing theirs once finished, etc...\n@gpang When initially added, they are guaranteed to be in sync, i.e. if /parent -> {/parent/a, /parent/b, /parent/c} exists then /parent/a, /parent/b, /parent/c will all exist in the cache individually. However, it's possible they could be removed before the parent listing.\nIn the current code, the parent is always synced and removed before the child even begins to sync because we don't add children to the processing queue until the parent has completed all of its syncing.", "author": "ZacBlanco", "createdAt": "2020-05-11T17:34:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzIxMzc1Nw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r423213757", "bodyText": "Also, I do see the issue with children still existing even if the parent doesn't.\nThere are not cases currently where that could happen as far as I'm aware in the current usage, but I meant to push an update for this when I changed the internal representation of the maps. Guess I missed it.", "author": "ZacBlanco", "createdAt": "2020-05-11T17:49:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTQ3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTg1Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418295856", "bodyText": "What if it was already cached? The children cache would be stale?", "author": "gpang", "createdAt": "2020-04-30T21:20:13Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDE4OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364189", "bodyText": "updated to always overwrite", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NTg1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5ODY5Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418298693", "bodyText": "What happens if there is no scheduled prefetch job? Is that what (3) is?", "author": "gpang", "createdAt": "2020-04-30T21:26:27Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0NDgxNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418344816", "bodyText": "If no prefetch job - isn't that what 3 says?", "author": "ZacBlanco", "createdAt": "2020-04-30T23:28:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5ODY5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMDE5Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418300193", "bodyText": "Removing it means other callers which call this same method would think there are no prefetch jobs? Is that intended?", "author": "gpang", "createdAt": "2020-04-30T21:29:43Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0NjM5MA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418346390", "bodyText": "In the current code path, we never have concurrent callers on the same path, but I will change the code so that it does work for concurrent callers.", "author": "ZacBlanco", "createdAt": "2020-04-30T23:33:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMDE5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMDM4MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418300381", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    LOG.warn(\"Failed waiting to fetch children at {}\", path);\n          \n          \n            \n                    LOG.warn(\"Failed waiting to prefetch children at {}\", path);", "author": "gpang", "createdAt": "2020-04-30T21:30:09Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LOG.warn(\"Failed waiting to fetch children at {}\", path);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDEyMQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364121", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMDM4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMDQzMw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418300433", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (e instanceof  InterruptedException) {\n          \n          \n            \n                    if (e instanceof InterruptedException) {", "author": "gpang", "createdAt": "2020-04-30T21:30:18Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n+        if (e instanceof  InterruptedException) {", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDEwNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364105", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMDQzMw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjA2Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418302063", "bodyText": "hrmmm, is fute a real term? I am not familiar with it...", "author": "gpang", "createdAt": "2020-04-30T21:33:53Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n+        if (e instanceof  InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        throw new IOException(e);\n+      }\n+    }\n+    if (useFallback) {\n+      return getChildrenIfAbsent(path, mountTable);\n+    }\n+    return null;\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n+   *\n+   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n+   * a prefetch job was scheduled or not.\n+   *\n+   * @param path the Alluxio path\n+   * @param mountTable the Alluxio mount table\n+   * @return child UFS statuses of the alluxio path\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n+   */\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws IOException, InvalidPathException {\n+    return fetchChildrenIfAbsent(path, mountTable, true);\n+  }\n+\n+  /**\n+   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n+   *\n+   * This method first checks if the children have already been retrieved, and if not, then\n+   * retrieves them.\n+\n+   * @param path the path to get the children for\n+   * @param mountTable the Alluxio mount table\n+   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n+   *         statuses\n+   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n+   */\n+  @Nullable\n+  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    MountTable.Resolution resolution = mountTable.resolve(path);\n+    AlluxioURI ufsUri = resolution.getUri();\n+    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n+      UnderFileSystem ufs = ufsResource.get();\n+      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n+      if (statuses == null) {\n+        return null;\n+      }\n+      children = Arrays.asList(statuses);\n+      addChildren(path, children);\n+    } catch (IllegalArgumentException | IOException e) {\n+      LOG.debug(\"Failed to add status to cache\", e);\n+    }\n+    return children;\n+  }\n+\n+  /**\n+   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n+    return mChildren.get(path);\n+  }\n+\n+  /**\n+   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n+   *\n+   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n+   * with the same Alluxio path.\n+   *\n+   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n+   * a no-op.\n+   *\n+   * @param path the path to prefetch\n+   * @param mountTable the Alluxio mount table\n+   */\n+  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n+    if (mPrefetchExecutor == null) {\n+      return;\n+    }\n+    try {\n+      Future<Collection<UfsStatus>> fute =", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0NzAxNw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418347017", "bodyText": "updated to job", "author": "ZacBlanco", "createdAt": "2020-04-30T23:35:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjA2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjUyNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418302526", "bodyText": "Why cancel the old one? Could this cause an endless cycle of constantly cancelled tasks?", "author": "gpang", "createdAt": "2020-04-30T21:34:48Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  public void addStatus(AlluxioURI path, UfsStatus status) {\n+    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n+   *                                  exists\n+   */\n+  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    UfsStatus status = mStatuses.get(path);\n+    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n+    // We can still add statuses to the cache regardless\n+    if (status != null) {\n+      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n+    }\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+    });\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n+        if (e instanceof  InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        throw new IOException(e);\n+      }\n+    }\n+    if (useFallback) {\n+      return getChildrenIfAbsent(path, mountTable);\n+    }\n+    return null;\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n+   *\n+   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n+   * a prefetch job was scheduled or not.\n+   *\n+   * @param path the Alluxio path\n+   * @param mountTable the Alluxio mount table\n+   * @return child UFS statuses of the alluxio path\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n+   */\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws IOException, InvalidPathException {\n+    return fetchChildrenIfAbsent(path, mountTable, true);\n+  }\n+\n+  /**\n+   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n+   *\n+   * This method first checks if the children have already been retrieved, and if not, then\n+   * retrieves them.\n+\n+   * @param path the path to get the children for\n+   * @param mountTable the Alluxio mount table\n+   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n+   *         statuses\n+   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n+   */\n+  @Nullable\n+  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    MountTable.Resolution resolution = mountTable.resolve(path);\n+    AlluxioURI ufsUri = resolution.getUri();\n+    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n+      UnderFileSystem ufs = ufsResource.get();\n+      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n+      if (statuses == null) {\n+        return null;\n+      }\n+      children = Arrays.asList(statuses);\n+      addChildren(path, children);\n+    } catch (IllegalArgumentException | IOException e) {\n+      LOG.debug(\"Failed to add status to cache\", e);\n+    }\n+    return children;\n+  }\n+\n+  /**\n+   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n+    return mChildren.get(path);\n+  }\n+\n+  /**\n+   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n+   *\n+   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n+   * with the same Alluxio path.\n+   *\n+   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n+   * a no-op.\n+   *\n+   * @param path the path to prefetch\n+   * @param mountTable the Alluxio mount table\n+   */\n+  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n+    if (mPrefetchExecutor == null) {\n+      return;\n+    }\n+    try {\n+      Future<Collection<UfsStatus>> fute =\n+          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n+      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n+      if (prev != null) {\n+        prev.cancel(true);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0ODQ5NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418348495", "bodyText": "How could it cause an endless cycle?\nIt only returns the previously submitted job for the given path. We have two options if there is already a prefetch job running on that path.\n\n(current approach) Cancel the old one, submit the new one\nIgnore the current request and rely on the future for the previously submitted future.\n\nThis path shouldn't really occur in the current code, but in the case it does happen I wanted to define the behavior. If the task is submitted later, I make the assumption that the user is submitting it because of some possible updated data in the UFS. The current prefetch job may already be executing or may be finished. I cancel it anyway in case it is running or about to run, and then submit the next one so whoever goes looking for the children later on will have a likely more up-to-date version of the UfsStatuses.\nI don't see how this could cause an endless cycle?", "author": "ZacBlanco", "createdAt": "2020-04-30T23:40:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjUyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU3NzU4Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419577582", "bodyText": "Well, if we keep calling prefetchChildren, it will never terminate if we keep taking the latest request (and canceling the previous one), right?", "author": "gpang", "createdAt": "2020-05-04T16:49:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjUyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYwMTUwOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419601509", "bodyText": "Well, if we keep calling prefetchChildren, it will never terminate\n\nI don't understand what is \"never terminating\"?\ncalling this method only schedules the job and immediately returns. It may cancel a previous one if it exists. This method will never block.\nwe only ever call prefetchChildren once in the code, and it doesn't depend on whether or not there is a job in the cache for that path. For the code paths that use that job to retrieve the child statuses, they also don't have a strong dependency on the prefetch job existing or not. If the job they wait for gets cancelled (or doesn't exist) it will just make the call to the UFS serially.", "author": "ZacBlanco", "createdAt": "2020-05-04T17:26:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjUyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkyMjIxMg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r420922212", "bodyText": "In fetchChildrenIfAbsent, it is supposed to wait for the prefetch job. If the prefetch job is always getting canceled and re-created, I'd imagine the prefetch job would never finish, and that i where the \"cycle\" would happen.\nBut it sounds like you are saying prefetchChildren is only called once per path per instance of this class?", "author": "gpang", "createdAt": "2020-05-06T16:22:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjUyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI3Mjc2NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r422272765", "bodyText": "Yes, it should only ever happen once per path in the current code", "author": "ZacBlanco", "createdAt": "2020-05-08T17:32:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMjUyNg=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex d3f92d9d40..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,275 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  public void addStatus(AlluxioURI path, UfsStatus status) {\n-    UfsStatus prev = mStatuses.putIfAbsent(path, status);\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @throws IllegalArgumentException when {@code path} already exists or if any child already\n-   *                                  exists\n-   */\n-  public void addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    UfsStatus status = mStatuses.get(path);\n-    // If this path doesn't yet exist, we can't keep track of the parent-child relationship\n-    // We can still add statuses to the cache regardless\n-    if (status != null) {\n-      mChildren.computeIfAbsent(path, ufsStatus -> new ConcurrentHashSet<>()).addAll(children);\n-    }\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-    });\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.remove(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LOG.warn(\"Failed waiting to fetch children at {}\", path);\n-        if (e instanceof  InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   * @see {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable, boolean)}\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> fute =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, fute);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwNTA4Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418305083", "bodyText": "call this forceSync?", "author": "gpang", "createdAt": "2020-04-30T21:40:38Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDA4Nw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364087", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:36:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwNTA4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwNTg3Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418305876", "bodyText": "Would pendingPaths is more descriptive?", "author": "gpang", "createdAt": "2020-04-30T21:42:30Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM1MDc3NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418350775", "bodyText": "yeah, i like that one better :D", "author": "ZacBlanco", "createdAt": "2020-04-30T23:48:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwNTg3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDA3OA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364078", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwNTg3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNTUwOA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418315508", "bodyText": "Does this have to be all caps?", "author": "gpang", "createdAt": "2020-04-30T22:05:05Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDA2OA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364068", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNTUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNTgzMQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418315831", "bodyText": "why remove the status?", "author": "gpang", "createdAt": "2020-04-30T22:05:56Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyOTE3Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418329173", "bodyText": "This will drop all references to the statuses allowing the JVM to GC it. If we don't remove it then for a huge namespace the statusCache can become large", "author": "ZacBlanco", "createdAt": "2020-04-30T22:40:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNTgzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNjEwMQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418316101", "bodyText": "Please add the root path to message", "author": "gpang", "createdAt": "2020-04-30T22:06:33Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDAxMw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418364013", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNjEwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNjUxNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418316515", "bodyText": "Please add root path to message", "author": "gpang", "createdAt": "2020-04-30T22:07:32Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;\n+          }\n+        } catch (InterruptedException | ExecutionException e) {\n+          if (e instanceof  InterruptedException) {\n+            Thread.currentThread().interrupt();\n+          }\n+          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2Mzg3Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418363872", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNjUxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNjY3Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418316672", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      if (e instanceof  InterruptedException) {\n          \n          \n            \n                      if (e instanceof InterruptedException) {", "author": "gpang", "createdAt": "2020-04-30T22:07:56Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;\n+          }\n+        } catch (InterruptedException | ExecutionException e) {\n+          if (e instanceof  InterruptedException) {", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2Mzg5MA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418363890", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNjY3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzA1OQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418317059", "bodyText": "if some of the tasks failed for some reason, will the count accounting still work? If I want to load a directory with 10 children, but 1 failed, will it still stop after all 10 finished (fail or succeed)?", "author": "gpang", "createdAt": "2020-04-30T22:08:54Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzMDAzNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418330036", "bodyText": "Technically for more complicated directory structures it depends, (directory high up can fail, causing its children not to sync) but generally the accounting is only for paths which successfully synced. So if all paths fail, then this function returns false. If at least one path syncs, we return true.\nWe can keep track of the number of failed paths too and report them as debug logs?", "author": "ZacBlanco", "createdAt": "2020-04-30T22:42:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzA1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzQ1MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418317451", "bodyText": "debug logging?", "author": "gpang", "createdAt": "2020-04-30T22:09:50Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;\n+          }\n+        } catch (InterruptedException | ExecutionException e) {\n+          if (e instanceof  InterruptedException) {\n+            Thread.currentThread().interrupt();\n+          }\n+          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n+        }\n+      }\n+\n+      // When using descendant type of ONE, we need to stop prematurely.\n+      if (stopNum != -1 && syncPathCount > stopNum) {\n+        break;\n+      }\n+\n+      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n+      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n+      for (int i = 0; i < submissions; i++) {\n+        AlluxioURI path = mSyncMetadataQ.poll();\n+        if (path == null) {\n+          // no paths left to sync\n+          break;\n+        }\n+        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n+        mSyncPathJobs.offer(job);\n+      }\n+      // After submitting all jobs wait for the job at the head of the queue to finish.\n+      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n+      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n+        continue;\n+      }\n+      try {\n+        oldestJob.get(); // block until the oldest job finished.\n+      } catch (InterruptedException | ExecutionException e) {\n+        if (e instanceof InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n+      }\n+    }\n+    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2MzkxNw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418363917", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzQ1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzY5NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418317695", "bodyText": "Does it matter if the oldest job finishes first or last? How would that affect behavior?", "author": "gpang", "createdAt": "2020-04-30T22:10:25Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;\n+          }\n+        } catch (InterruptedException | ExecutionException e) {\n+          if (e instanceof  InterruptedException) {\n+            Thread.currentThread().interrupt();\n+          }\n+          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n+        }\n+      }\n+\n+      // When using descendant type of ONE, we need to stop prematurely.\n+      if (stopNum != -1 && syncPathCount > stopNum) {\n+        break;\n+      }\n+\n+      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n+      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n+      for (int i = 0; i < submissions; i++) {\n+        AlluxioURI path = mSyncMetadataQ.poll();\n+        if (path == null) {\n+          // no paths left to sync\n+          break;\n+        }\n+        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n+        mSyncPathJobs.offer(job);\n+      }\n+      // After submitting all jobs wait for the job at the head of the queue to finish.\n+      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n+      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n+        continue;\n+      }\n+      try {\n+        oldestJob.get(); // block until the oldest job finished.", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMzMjIyMg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418332222", "bodyText": "I just take the oldest job submitted, because as long as the threadpool uses a fair queueing policy for running jobs, it has the highest probability of being completed before other jobs. If the oldest job runs slower, it can theoretically prevent other tasks from being submitted.\nIn a follow-up I'd actually like to design a ThreadPoolExecutor that doesn't need this control logic and can simply just iterate over the queue of pending paths and submit them. My idea is that the executor pool can be shared in a limited manner, so that you can lease out a portion of the threads. ex:\nExecutorService mainExecutor = Executors.newCachedThreadpool(64);\n\nsharedExecutor = mainExecutor.lease(4); // executor service that uses the pool backing mainExecutor, that can have up to 4 tasks running concurrently.\nsharedExecutor = mainExecutor.lease(32); // executor service that uses the pool backing mainExecutor, that can have up to 32 tasks running concurrently.\nWe can use a semaphore to block submitting tasks to the executor when they are already runing. Completely negates all the control logic of this thread. I haven't written the executor yet. This is all ideas yet. I don't plan on implementing it for this PR", "author": "ZacBlanco", "createdAt": "2020-04-30T22:49:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzY5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzczNw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418317737", "bodyText": "add root path to message", "author": "gpang", "createdAt": "2020-04-30T22:10:32Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;\n+          }\n+        } catch (InterruptedException | ExecutionException e) {\n+          if (e instanceof  InterruptedException) {\n+            Thread.currentThread().interrupt();\n+          }\n+          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n+        }\n+      }\n+\n+      // When using descendant type of ONE, we need to stop prematurely.\n+      if (stopNum != -1 && syncPathCount > stopNum) {\n+        break;\n+      }\n+\n+      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n+      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n+      for (int i = 0; i < submissions; i++) {\n+        AlluxioURI path = mSyncMetadataQ.poll();\n+        if (path == null) {\n+          // no paths left to sync\n+          break;\n+        }\n+        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n+        mSyncPathJobs.offer(job);\n+      }\n+      // After submitting all jobs wait for the job at the head of the queue to finish.\n+      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n+      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n+        continue;\n+      }\n+      try {\n+        oldestJob.get(); // block until the oldest job finished.\n+      } catch (InterruptedException | ExecutionException e) {\n+        if (e instanceof InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2Mzk1MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418363951", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxNzczNw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxODAxNw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418318017", "bodyText": "all caps?", "author": "gpang", "createdAt": "2020-04-30T22:11:15Z", "path": "core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java", "diffHunk": "@@ -0,0 +1,810 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.master.file;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.client.WriteType;\n+import alluxio.collections.Pair;\n+import alluxio.conf.PropertyKey;\n+import alluxio.conf.ServerConfiguration;\n+import alluxio.exception.AccessControlException;\n+import alluxio.exception.BlockInfoException;\n+import alluxio.exception.DirectoryNotEmptyException;\n+import alluxio.exception.FileAlreadyCompletedException;\n+import alluxio.exception.FileAlreadyExistsException;\n+import alluxio.exception.FileDoesNotExistException;\n+import alluxio.exception.InvalidFileSizeException;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.file.options.DescendantType;\n+import alluxio.grpc.CompleteFilePOptions;\n+import alluxio.grpc.DeletePOptions;\n+import alluxio.grpc.FileSystemMasterCommonPOptions;\n+import alluxio.grpc.GrpcUtils;\n+import alluxio.grpc.LoadDescendantPType;\n+import alluxio.grpc.LoadMetadataPOptions;\n+import alluxio.grpc.SetAttributePOptions;\n+import alluxio.master.file.contexts.CompleteFileContext;\n+import alluxio.master.file.contexts.CreateDirectoryContext;\n+import alluxio.master.file.contexts.CreateFileContext;\n+import alluxio.master.file.contexts.DeleteContext;\n+import alluxio.master.file.contexts.GetStatusContext;\n+import alluxio.master.file.contexts.LoadMetadataContext;\n+import alluxio.master.file.contexts.SetAttributeContext;\n+import alluxio.master.file.meta.Inode;\n+import alluxio.master.file.meta.InodeFile;\n+import alluxio.master.file.meta.InodeLockManager;\n+import alluxio.master.file.meta.InodeTree;\n+import alluxio.master.file.meta.InodeTree.LockPattern;\n+import alluxio.master.file.meta.LockedInodePath;\n+import alluxio.master.file.meta.LockingScheme;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.master.file.meta.UfsSyncPathCache;\n+import alluxio.master.file.meta.UfsSyncUtils;\n+import alluxio.master.metastore.ReadOnlyInodeStore;\n+import alluxio.resource.CloseableResource;\n+import alluxio.security.authorization.AccessControlList;\n+import alluxio.security.authorization.DefaultAccessControlList;\n+import alluxio.security.authorization.Mode;\n+import alluxio.underfs.Fingerprint;\n+import alluxio.underfs.UfsFileStatus;\n+import alluxio.underfs.UfsStatus;\n+import alluxio.underfs.UfsStatusCache;\n+import alluxio.underfs.UnderFileSystem;\n+import alluxio.util.interfaces.Scoped;\n+import alluxio.util.io.PathUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+\n+/**\n+ * This class is responsible for maintaining the logic which surrounds syncing metadata between\n+ * Alluxio and its UFSes.\n+ *\n+ * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n+ * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n+ * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n+ * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n+ * are completed and there are no new inodes left in the queue.\n+ *\n+ * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n+ * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n+ * inode begins processing, it can retrieve the results. After processing, it can then remove its\n+ * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n+ * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n+ * concurrently process other inodes while waiting for UFS RPCs to complete.\n+ *\n+ * With regards to locking, this class expects to be able to take a write lock on any inode, and\n+ * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n+ * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n+ * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n+ * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n+ *\n+ * A user of this class is expected to create a new instance for each path that they would like\n+ * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n+ * {@link #sync()}.\n+ *\n+ */\n+public class InodeSyncStream {\n+  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n+\n+  /** The root path. Should be locked with a write lock. */\n+  private final LockedInodePath mRootPath;\n+\n+  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n+  private final UfsSyncPathCache mUfsSyncPathCache;\n+\n+  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n+  private final UfsStatusCache mStatusCache;\n+\n+  /** Inode tree to lock new paths. */\n+  private final InodeTree mInodeTree;\n+\n+  /** Determines how deep in the tree we need to load. */\n+  private final DescendantType mDescendantType;\n+\n+  /** The {@link RpcContext} from the caller. */\n+  private final RpcContext mRpcContext;\n+\n+  /** The inode store to look up children. */\n+  private final ReadOnlyInodeStore mInodeStore;\n+\n+  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n+  private final MountTable mMountTable;\n+\n+  /** The lock manager used to try acquiring the persisting lock. */\n+  private final InodeLockManager mInodeLockManager;\n+\n+  /** The FS master creating this object. */\n+  private final DefaultFileSystemMaster mFsMaster;\n+\n+  /** Set this to true to force a sync regardless of the UfsPathCache. */\n+  private final boolean mShouldSync;\n+\n+  /** The sync options on the RPC.  */\n+  private final FileSystemMasterCommonPOptions mSyncOptions;\n+\n+  /**\n+   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n+   * This is used for the {@link #mUfsSyncPathCache}.\n+   */\n+  private final boolean mIsGetFileInfo;\n+\n+  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n+  private final boolean mLoadOnly;\n+\n+  /** Queue used to keep track of paths that still need to be synced. */\n+  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n+\n+  /** Queue of paths that have been submitted to the executor. */\n+  private final Queue<Future<Boolean>> mSyncPathJobs;\n+\n+  /** The executor enabling concurrent processing. */\n+  private final ExecutorService mMetadataSyncService;\n+\n+  /** The maximum number of concurrent paths that can be syncing at any moment. */\n+  private final int mConcurrencyLevel =\n+      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n+\n+  /**\n+   * Create a new instance of {@link InodeSyncStream}.\n+   *\n+   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n+   * only planning on loading metadata. The desired pattern should always be\n+   * {@link LockPattern#READ}.\n+   *\n+   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n+   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n+   *\n+   * @param rootPath The root path to begin syncing\n+   * @param concurrencyService executor used to process paths concurrently\n+   * @param fsMaster the {@link FileSystemMaster} calling this method\n+   * @param inodeTree the {@link InodeTree}\n+   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n+   * @param inodeLockManager the {@link InodeLockManager}\n+   * @param mountTable the master's {@link MountTable}\n+   * @param rpcContext the caller's {@link RpcContext}\n+   * @param descendantType determines the number of descendant inodes to sync\n+   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n+   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n+   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n+   * @param forceSync whether to sync inode metadata no matter what\n+   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n+   */\n+  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n+      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n+      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n+      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n+      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n+      boolean loadOnly) {\n+    mDescendantType = descendantType;\n+    mFsMaster = fsMaster;\n+    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n+    mInodeLockManager = inodeLockManager;\n+    mInodeStore = inodeStore;\n+    mInodeTree = inodeTree;\n+    mMountTable = mountTable;\n+    mRpcContext = rpcContext;\n+    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n+    mUfsSyncPathCache = ufsSyncPathCache;\n+    mShouldSync = forceSync;\n+    mRootPath = rootPath;\n+    mSyncOptions = options;\n+    mIsGetFileInfo = isGetFileInfo;\n+    mLoadOnly = loadOnly;\n+    mSyncPathJobs = new LinkedList<>();\n+    mMetadataSyncService = concurrencyService;\n+  }\n+\n+  /**\n+   * Sync the metadata according the the root path the stream was created with.\n+   *\n+   * @return true if at least one path was synced\n+   */\n+  public boolean sync() {\n+    // The high-level process for the syncing is:\n+    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n+    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n+    // 2. If only the metadata changed, update the inode with the new metadata\n+    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n+    // 4. If not deleted, load metadata from the UFS\n+    // 5. If a recursive sync, add children inodes to sync queue\n+    int syncPathCount = 0;\n+    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n+\n+    try {\n+      syncInodeMetadata(mRootPath);\n+      syncPathCount++;\n+      if (mDescendantType == DescendantType.ONE) {\n+        // If descendantType is ONE, then we shouldn't process any more paths except for those\n+        // currently in the queue\n+        stopNum = mSyncMetadataQ.size();\n+      }\n+\n+      // process the sync result for the original path\n+      try {\n+        mRootPath.traverse();\n+      } catch (InvalidPathException e) {\n+        throw new RuntimeException(e);\n+      }\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n+    } finally {\n+      // regardless of the outcome, remove the UfsStatus for this path from the cache\n+      mStatusCache.remove(mRootPath.getUri());\n+      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n+      // concurrent operations\n+      mRootPath.downgradeToPattern(LockPattern.READ);\n+    }\n+\n+    // Process any children after the root.\n+    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Metadata syncing was interrupted before completion\");\n+        break;\n+      }\n+      // There are still paths to process\n+      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n+      // successfully\n+      while (true) {\n+        Future<Boolean> job = mSyncPathJobs.peek();\n+        if (job == null || !job.isDone()) {\n+          break;\n+        }\n+        // remove the job because we know it is done.\n+        if (mSyncPathJobs.poll() != job) {\n+          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n+              + \"head of queue\");\n+        }\n+        try {\n+          // we synced the path successfully\n+          if (job.get()) {\n+            syncPathCount++;\n+          }\n+        } catch (InterruptedException | ExecutionException e) {\n+          if (e instanceof  InterruptedException) {\n+            Thread.currentThread().interrupt();\n+          }\n+          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n+        }\n+      }\n+\n+      // When using descendant type of ONE, we need to stop prematurely.\n+      if (stopNum != -1 && syncPathCount > stopNum) {\n+        break;\n+      }\n+\n+      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n+      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n+      for (int i = 0; i < submissions; i++) {\n+        AlluxioURI path = mSyncMetadataQ.poll();\n+        if (path == null) {\n+          // no paths left to sync\n+          break;\n+        }\n+        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n+        mSyncPathJobs.offer(job);\n+      }\n+      // After submitting all jobs wait for the job at the head of the queue to finish.\n+      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n+      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n+        continue;\n+      }\n+      try {\n+        oldestJob.get(); // block until the oldest job finished.\n+      } catch (InterruptedException | ExecutionException e) {\n+        if (e instanceof InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n+      }\n+    }\n+    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n+    mStatusCache.cancelAllPrefetch();\n+    mSyncPathJobs.forEach(f -> f.cancel(true));\n+    return syncPathCount > 0;\n+  }\n+\n+  /**\n+   * Process a path to sync.\n+   *\n+   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n+   * be synced as well.\n+   *\n+   * @param path The path to sync\n+   * @return true if this path was synced\n+   */\n+  private boolean processSyncPath(AlluxioURI path) {\n+    if (path == null) {\n+      return false;\n+    }\n+    LockingScheme scheme;\n+    if (mShouldSync) {\n+      scheme = new LockingScheme(path, LockPattern.READ, true);\n+    } else {\n+      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n+          mUfsSyncPathCache, mIsGetFileInfo);\n+    }\n+\n+    if (!scheme.shouldSync() && !mShouldSync) {\n+      return false;\n+    }\n+    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n+      if (Thread.currentThread().isInterrupted()) {\n+        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n+        return false;\n+      }\n+      syncInodeMetadata(inodePath);\n+      return true;\n+    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n+        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n+        | IOException e) {\n+      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);", "originalCommit": "aea2599ba2565e052e3871653282b3f22a325203", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2Mzk2MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r418363961", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-01T00:35:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxODAxNw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java b/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\ndeleted file mode 100644\nindex b14039c5c0..0000000000\n--- a/core/server/master/src/main/java/alluxio/master/file/InodeSyncStream.java\n+++ /dev/null\n\n@@ -1,810 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.master.file;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.client.WriteType;\n-import alluxio.collections.Pair;\n-import alluxio.conf.PropertyKey;\n-import alluxio.conf.ServerConfiguration;\n-import alluxio.exception.AccessControlException;\n-import alluxio.exception.BlockInfoException;\n-import alluxio.exception.DirectoryNotEmptyException;\n-import alluxio.exception.FileAlreadyCompletedException;\n-import alluxio.exception.FileAlreadyExistsException;\n-import alluxio.exception.FileDoesNotExistException;\n-import alluxio.exception.InvalidFileSizeException;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.file.options.DescendantType;\n-import alluxio.grpc.CompleteFilePOptions;\n-import alluxio.grpc.DeletePOptions;\n-import alluxio.grpc.FileSystemMasterCommonPOptions;\n-import alluxio.grpc.GrpcUtils;\n-import alluxio.grpc.LoadDescendantPType;\n-import alluxio.grpc.LoadMetadataPOptions;\n-import alluxio.grpc.SetAttributePOptions;\n-import alluxio.master.file.contexts.CompleteFileContext;\n-import alluxio.master.file.contexts.CreateDirectoryContext;\n-import alluxio.master.file.contexts.CreateFileContext;\n-import alluxio.master.file.contexts.DeleteContext;\n-import alluxio.master.file.contexts.GetStatusContext;\n-import alluxio.master.file.contexts.LoadMetadataContext;\n-import alluxio.master.file.contexts.SetAttributeContext;\n-import alluxio.master.file.meta.Inode;\n-import alluxio.master.file.meta.InodeFile;\n-import alluxio.master.file.meta.InodeLockManager;\n-import alluxio.master.file.meta.InodeTree;\n-import alluxio.master.file.meta.InodeTree.LockPattern;\n-import alluxio.master.file.meta.LockedInodePath;\n-import alluxio.master.file.meta.LockingScheme;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.master.file.meta.UfsSyncPathCache;\n-import alluxio.master.file.meta.UfsSyncUtils;\n-import alluxio.master.metastore.ReadOnlyInodeStore;\n-import alluxio.resource.CloseableResource;\n-import alluxio.security.authorization.AccessControlList;\n-import alluxio.security.authorization.DefaultAccessControlList;\n-import alluxio.security.authorization.Mode;\n-import alluxio.underfs.Fingerprint;\n-import alluxio.underfs.UfsFileStatus;\n-import alluxio.underfs.UfsStatus;\n-import alluxio.underfs.UfsStatusCache;\n-import alluxio.underfs.UnderFileSystem;\n-import alluxio.util.interfaces.Scoped;\n-import alluxio.util.io.PathUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Optional;\n-import java.util.Queue;\n-import java.util.concurrent.ConcurrentLinkedQueue;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-\n-/**\n- * This class is responsible for maintaining the logic which surrounds syncing metadata between\n- * Alluxio and its UFSes.\n- *\n- * This implementation uses a BFS-based approach to crawl the inode tree. In order to speed up\n- * the sync process we use an {@link ExecutorService} which we submit inode paths to using\n- * {@link #processSyncPath(AlluxioURI)}. The processing of inode paths will discover new paths to\n- * sync depending on the {@link #mDescendantType}. Syncing is finished when all submitted tasks\n- * are completed and there are no new inodes left in the queue.\n- *\n- * Syncing inode metadata requires making calls to the UFS. This implementation will schedule UFS\n- * RPCs with the {@link UfsStatusCache#prefetchChildren(AlluxioURI, MountTable)}. Then, once the\n- * inode begins processing, it can retrieve the results. After processing, it can then remove its\n- * {@link UfsStatus} from the cache. This strategy helps reduce memory pressure on the master\n- * while performing a sync for a large tree. Additionally, by using a prefetch mechanism we can\n- * concurrently process other inodes while waiting for UFS RPCs to complete.\n- *\n- * With regards to locking, this class expects to be able to take a write lock on any inode, and\n- * then subsequently downgrades or unlocks after the sync is finished. Even though we use\n- * {@link java.util.concurrent.locks.ReentrantReadWriteLock}, because we concurrently process\n- * inodes on separate threads, we cannot utilize the reetrnant behavior. The implications of\n- * that mean the caller of this class must not hold a write while calling {@link #sync()}.\n- *\n- * A user of this class is expected to create a new instance for each path that they would like\n- * to process. This is because the Lock on the {@link #mRootPath} may be changed after calling\n- * {@link #sync()}.\n- *\n- */\n-public class InodeSyncStream {\n-  private static final Logger LOG = LoggerFactory.getLogger(InodeSyncStream.class);\n-\n-  /** The root path. Should be locked with a write lock. */\n-  private final LockedInodePath mRootPath;\n-\n-  /** A {@link UfsSyncPathCache} maintained from the {@link DefaultFileSystemMaster}. */\n-  private final UfsSyncPathCache mUfsSyncPathCache;\n-\n-  /** Object holding the {@link UfsStatus}es which may be required for syncing. */\n-  private final UfsStatusCache mStatusCache;\n-\n-  /** Inode tree to lock new paths. */\n-  private final InodeTree mInodeTree;\n-\n-  /** Determines how deep in the tree we need to load. */\n-  private final DescendantType mDescendantType;\n-\n-  /** The {@link RpcContext} from the caller. */\n-  private final RpcContext mRpcContext;\n-\n-  /** The inode store to look up children. */\n-  private final ReadOnlyInodeStore mInodeStore;\n-\n-  /** The mount table for looking up the proper UFS client based on the Alluxio path. */\n-  private final MountTable mMountTable;\n-\n-  /** The lock manager used to try acquiring the persisting lock. */\n-  private final InodeLockManager mInodeLockManager;\n-\n-  /** The FS master creating this object. */\n-  private final DefaultFileSystemMaster mFsMaster;\n-\n-  /** Set this to true to force a sync regardless of the UfsPathCache. */\n-  private final boolean mShouldSync;\n-\n-  /** The sync options on the RPC.  */\n-  private final FileSystemMasterCommonPOptions mSyncOptions;\n-\n-  /**\n-   * Whether the caller is {@link FileSystemMaster#getFileInfo(AlluxioURI, GetStatusContext)}.\n-   * This is used for the {@link #mUfsSyncPathCache}.\n-   */\n-  private final boolean mIsGetFileInfo;\n-\n-  /** Whether to only read+create metadata from the UFS, or to update metadata as well. */\n-  private final boolean mLoadOnly;\n-\n-  /** Queue used to keep track of paths that still need to be synced. */\n-  private final ConcurrentLinkedQueue<AlluxioURI> mSyncMetadataQ;\n-\n-  /** Queue of paths that have been submitted to the executor. */\n-  private final Queue<Future<Boolean>> mSyncPathJobs;\n-\n-  /** The executor enabling concurrent processing. */\n-  private final ExecutorService mMetadataSyncService;\n-\n-  /** The maximum number of concurrent paths that can be syncing at any moment. */\n-  private final int mConcurrencyLevel =\n-      ServerConfiguration.getInt(PropertyKey.MASTER_METADATA_SYNC_CONCURRENCY_LEVEL);\n-\n-  /**\n-   * Create a new instance of {@link InodeSyncStream}.\n-   *\n-   * The root path should be already locked with {@link LockPattern#WRITE_EDGE} unless the user is\n-   * only planning on loading metadata. The desired pattern should always be\n-   * {@link LockPattern#READ}.\n-   *\n-   * It is an error to initiate sync without a WRITE_EDGE lock when loadOnly is {@code false}.\n-   * If loadOnly is set to {@code true}, then the the root path may have a read lock.\n-   *\n-   * @param rootPath The root path to begin syncing\n-   * @param concurrencyService executor used to process paths concurrently\n-   * @param fsMaster the {@link FileSystemMaster} calling this method\n-   * @param inodeTree the {@link InodeTree}\n-   * @param inodeStore the {@link alluxio.master.metastore.InodeStore}\n-   * @param inodeLockManager the {@link InodeLockManager}\n-   * @param mountTable the master's {@link MountTable}\n-   * @param rpcContext the caller's {@link RpcContext}\n-   * @param descendantType determines the number of descendant inodes to sync\n-   * @param ufsSyncPathCache the sync path cache to determine when inodes should be synced\n-   * @param options the RPC's {@link FileSystemMasterCommonPOptions}\n-   * @param isGetFileInfo whether the caller is {@link FileSystemMaster#getFileInfo}\n-   * @param forceSync whether to sync inode metadata no matter what\n-   * @param loadOnly whether to only load new metadata, rather than update existing metadata\n-   */\n-  public InodeSyncStream(LockedInodePath rootPath, ExecutorService concurrencyService,\n-      DefaultFileSystemMaster fsMaster, InodeTree inodeTree, ReadOnlyInodeStore inodeStore,\n-      InodeLockManager inodeLockManager, MountTable mountTable, RpcContext rpcContext,\n-      DescendantType descendantType, UfsSyncPathCache ufsSyncPathCache,\n-      FileSystemMasterCommonPOptions options, boolean isGetFileInfo, boolean forceSync,\n-      boolean loadOnly) {\n-    mDescendantType = descendantType;\n-    mFsMaster = fsMaster;\n-    mSyncMetadataQ = new ConcurrentLinkedQueue<>();\n-    mInodeLockManager = inodeLockManager;\n-    mInodeStore = inodeStore;\n-    mInodeTree = inodeTree;\n-    mMountTable = mountTable;\n-    mRpcContext = rpcContext;\n-    mStatusCache = new UfsStatusCache(fsMaster.mSyncPrefetchExecutor);\n-    mUfsSyncPathCache = ufsSyncPathCache;\n-    mShouldSync = forceSync;\n-    mRootPath = rootPath;\n-    mSyncOptions = options;\n-    mIsGetFileInfo = isGetFileInfo;\n-    mLoadOnly = loadOnly;\n-    mSyncPathJobs = new LinkedList<>();\n-    mMetadataSyncService = concurrencyService;\n-  }\n-\n-  /**\n-   * Sync the metadata according the the root path the stream was created with.\n-   *\n-   * @return true if at least one path was synced\n-   */\n-  public boolean sync() {\n-    // The high-level process for the syncing is:\n-    // 1. Given an Alluxio path, determine if it is not consistent with the corresponding UFS path.\n-    //     this means the UFS path does not exist, or has metadata which differs from Alluxio\n-    // 2. If only the metadata changed, update the inode with the new metadata\n-    // 3. If the path does not exist in the UFS, delete the inode in Alluxio\n-    // 4. If not deleted, load metadata from the UFS\n-    // 5. If a recursive sync, add children inodes to sync queue\n-    int syncPathCount = 0;\n-    int stopNum = -1; // stop syncing when we've processed this many paths. -1 for infinite\n-\n-    try {\n-      syncInodeMetadata(mRootPath);\n-      syncPathCount++;\n-      if (mDescendantType == DescendantType.ONE) {\n-        // If descendantType is ONE, then we shouldn't process any more paths except for those\n-        // currently in the queue\n-        stopNum = mSyncMetadataQ.size();\n-      }\n-\n-      // process the sync result for the original path\n-      try {\n-        mRootPath.traverse();\n-      } catch (InvalidPathException e) {\n-        throw new RuntimeException(e);\n-      }\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(mRootPath.getUri());\n-      // downgrade so that if operations are parallelized, the lock on the root doesn't restrict\n-      // concurrent operations\n-      mRootPath.downgradeToPattern(LockPattern.READ);\n-    }\n-\n-    // Process any children after the root.\n-    while (!mSyncMetadataQ.isEmpty() || !mSyncPathJobs.isEmpty()) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Metadata syncing was interrupted before completion\");\n-        break;\n-      }\n-      // There are still paths to process\n-      // First, remove any futures which have completed. Add to the sync path count if they sync'd\n-      // successfully\n-      while (true) {\n-        Future<Boolean> job = mSyncPathJobs.peek();\n-        if (job == null || !job.isDone()) {\n-          break;\n-        }\n-        // remove the job because we know it is done.\n-        if (mSyncPathJobs.poll() != job) {\n-          throw new IllegalStateException(\"Last node to be de-queued was not equal to the expected\"\n-              + \"head of queue\");\n-        }\n-        try {\n-          // we synced the path successfully\n-          if (job.get()) {\n-            syncPathCount++;\n-          }\n-        } catch (InterruptedException | ExecutionException e) {\n-          if (e instanceof  InterruptedException) {\n-            Thread.currentThread().interrupt();\n-          }\n-          LOG.warn(\"metadata sync job was interrupted while waiting for completion\");\n-        }\n-      }\n-\n-      // When using descendant type of ONE, we need to stop prematurely.\n-      if (stopNum != -1 && syncPathCount > stopNum) {\n-        break;\n-      }\n-\n-      // We can submit up to ( max_concurrency - <jobs queue size>) jobs back into the queue\n-      int submissions = mConcurrencyLevel - mSyncPathJobs.size();\n-      for (int i = 0; i < submissions; i++) {\n-        AlluxioURI path = mSyncMetadataQ.poll();\n-        if (path == null) {\n-          // no paths left to sync\n-          break;\n-        }\n-        Future<Boolean> job = mMetadataSyncService.submit(() -> processSyncPath(path));\n-        mSyncPathJobs.offer(job);\n-      }\n-      // After submitting all jobs wait for the job at the head of the queue to finish.\n-      Future<Boolean> oldestJob = mSyncPathJobs.peek();\n-      if (oldestJob == null) { // There might not be any jobs, restart the loop.\n-        continue;\n-      }\n-      try {\n-        oldestJob.get(); // block until the oldest job finished.\n-      } catch (InterruptedException | ExecutionException e) {\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        LOG.warn(\"Interrupted while waiting for metadata sync job to finish\", e);\n-      }\n-    }\n-    LOG.info(\"TRACING - Synced {} paths\", syncPathCount);\n-    mStatusCache.cancelAllPrefetch();\n-    mSyncPathJobs.forEach(f -> f.cancel(true));\n-    return syncPathCount > 0;\n-  }\n-\n-  /**\n-   * Process a path to sync.\n-   *\n-   * This can update metadata for the inode, delete the inode, and/or queue any children that should\n-   * be synced as well.\n-   *\n-   * @param path The path to sync\n-   * @return true if this path was synced\n-   */\n-  private boolean processSyncPath(AlluxioURI path) {\n-    if (path == null) {\n-      return false;\n-    }\n-    LockingScheme scheme;\n-    if (mShouldSync) {\n-      scheme = new LockingScheme(path, LockPattern.READ, true);\n-    } else {\n-      scheme = new LockingScheme(path, LockPattern.READ, mSyncOptions,\n-          mUfsSyncPathCache, mIsGetFileInfo);\n-    }\n-\n-    if (!scheme.shouldSync() && !mShouldSync) {\n-      return false;\n-    }\n-    try (LockedInodePath inodePath = mInodeTree.tryLockInodePath(scheme)) {\n-      if (Thread.currentThread().isInterrupted()) {\n-        LOG.warn(\"Thread syncing {} was interrupted before completion\", inodePath.getUri());\n-        return false;\n-      }\n-      syncInodeMetadata(inodePath);\n-      return true;\n-    } catch (AccessControlException | BlockInfoException | FileAlreadyCompletedException\n-        | FileDoesNotExistException | InvalidFileSizeException | InvalidPathException\n-        | IOException e) {\n-      LOG.warn(\"FAILED TO SYNC METADATA: {}\", e.getMessage(), e);\n-    } finally {\n-      // regardless of the outcome, remove the UfsStatus for this path from the cache\n-      mStatusCache.remove(path);\n-    }\n-    return false;\n-  }\n-\n-  private void syncInodeMetadata(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-    if (!inodePath.fullPathExists()) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    syncExistingInodeMetadata(inodePath);\n-  }\n-\n-  /**\n-   * Sync inode metadata with the UFS state.\n-   *\n-   * This method expects the {@code inodePath} to already exist in the inode tree.\n-   */\n-  private void syncExistingInodeMetadata(LockedInodePath inodePath)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    if (inodePath.getLockPattern() != LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      throw new RuntimeException(String.format(\n-          \"syncExistingInodeMetadata was called on %s when only locked with %s. Load metadata\"\n-          + \" only was not specified.\", inodePath.getUri(), inodePath.getLockPattern()));\n-    }\n-\n-    // Set to true if the given inode was deleted.\n-    boolean deletedInode = false;\n-    // whether we need to load metadata for the current path\n-    boolean loadMetadata = mLoadOnly;\n-    boolean syncChildren = true;\n-    LOG.debug(\"Syncing inode metadata {}\", inodePath.getUri());\n-\n-    // The requested path already exists in Alluxio.\n-    Inode inode = inodePath.getInode();\n-\n-    // if the lock pattern is WRITE_EDGE, then we can sync (update or delete). Otherwise, if it is\n-    // we can only load metadata.\n-\n-    if (inodePath.getLockPattern() == LockPattern.WRITE_EDGE && !mLoadOnly) {\n-      if (inode instanceof InodeFile && !inode.asFile().isCompleted()) {\n-        // Do not sync an incomplete file, since the UFS file is expected to not exist.\n-        return;\n-      }\n-\n-      Optional<Scoped> persistingLock = mInodeLockManager.tryAcquirePersistingLock(inode.getId());\n-      if (!persistingLock.isPresent()) {\n-        // Do not sync a file in the process of being persisted, since the UFS file is being\n-        // written.\n-        return;\n-      }\n-      persistingLock.get().close();\n-\n-      UfsStatus cachedStatus = mStatusCache.getStatus(inodePath.getUri());\n-      MountTable.Resolution resolution = mMountTable.resolve(inodePath.getUri());\n-      AlluxioURI ufsUri = resolution.getUri();\n-      try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-        UnderFileSystem ufs = ufsResource.get();\n-        String ufsFingerprint;\n-        Fingerprint ufsFpParsed;\n-        if (cachedStatus == null) {\n-          // TODO(david): change the interface so that getFingerprint returns a parsed fingerprint\n-          ufsFingerprint = ufs.getFingerprint(ufsUri.toString());\n-          ufsFpParsed = Fingerprint.parse(ufsFingerprint);\n-        } else {\n-          Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-              ufs.getAclPair(ufsUri.toString());\n-\n-          if (aclPair == null || aclPair.getFirst() == null || !aclPair.getFirst().hasExtended()) {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus);\n-          } else {\n-            ufsFpParsed = Fingerprint.create(ufs.getUnderFSType(), cachedStatus,\n-                aclPair.getFirst());\n-          }\n-          ufsFingerprint = ufsFpParsed.serialize();\n-        }\n-        boolean containsMountPoint = mMountTable.containsMountPoint(inodePath.getUri(), true);\n-\n-        UfsSyncUtils.SyncPlan syncPlan =\n-            UfsSyncUtils.computeSyncPlan(inode, ufsFpParsed, containsMountPoint);\n-\n-        if (syncPlan.toUpdateMetaData()) {\n-          // UpdateMetadata is used when a file or a directory only had metadata change.\n-          // It works by calling SetAttributeInternal on the inodePath.\n-          if (ufsFpParsed != null && ufsFpParsed.isValid()) {\n-            short mode = Short.parseShort(ufsFpParsed.getTag(Fingerprint.Tag.MODE));\n-            long opTimeMs = System.currentTimeMillis();\n-            SetAttributePOptions.Builder builder = SetAttributePOptions.newBuilder()\n-                .setMode(new Mode(mode).toProto());\n-            String owner = ufsFpParsed.getTag(Fingerprint.Tag.OWNER);\n-            if (!owner.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set owner if not empty\n-              builder.setOwner(owner);\n-            }\n-            String group = ufsFpParsed.getTag(Fingerprint.Tag.GROUP);\n-            if (!group.equals(Fingerprint.UNDERSCORE)) {\n-              // Only set group if not empty\n-              builder.setGroup(group);\n-            }\n-            mFsMaster.setAttributeSingleFile(mRpcContext, inodePath, false, opTimeMs,\n-                SetAttributeContext.mergeFrom(SetAttributePOptions.newBuilder()\n-                    .setMode(new Mode(mode).toProto())).setUfsFingerprint(ufsFingerprint));\n-          }\n-        }\n-\n-        if (syncPlan.toDelete()) {\n-          deletedInode = true;\n-          try {\n-            // The options for deleting.\n-            DeleteContext syncDeleteContext = DeleteContext.mergeFrom(\n-                DeletePOptions.newBuilder()\n-                .setRecursive(true)\n-                .setAlluxioOnly(true)\n-                .setUnchecked(true));\n-            mFsMaster.deleteInternal(mRpcContext, inodePath, syncDeleteContext);\n-          } catch (DirectoryNotEmptyException | IOException e) {\n-            // Should not happen, since it is an unchecked delete.\n-            LOG.error(\"Unexpected error for unchecked delete.\", e);\n-          }\n-        }\n-\n-        if (syncPlan.toLoadMetadata()) {\n-          loadMetadata = true;\n-        }\n-\n-        syncChildren = syncPlan.toSyncChildren();\n-      }\n-    }\n-\n-    syncChildren = syncChildren\n-        && inode.isDirectory()\n-        && mDescendantType != DescendantType.NONE;\n-\n-    Map<String, Inode> inodeChildren = new HashMap<>();\n-    if (syncChildren) {\n-      // maps children name to inode\n-      mInodeStore.getChildren(inode.asDirectory())\n-          .forEach(child -> inodeChildren.put(child.getName(), child));\n-\n-      // Fetch and populate children into the cache\n-      Collection<UfsStatus> listStatus = mStatusCache\n-          .fetchChildrenIfAbsent(inodePath.getUri(), mMountTable);\n-      // Iterate over UFS listings and process UFS children.\n-      if (listStatus != null) {\n-        for (UfsStatus ufsChildStatus : listStatus) {\n-          if (!inodeChildren.containsKey(ufsChildStatus.getName()) && !PathUtils\n-              .isTemporaryFileName(ufsChildStatus.getName())) {\n-            // Ufs child exists, but Alluxio child does not. Must load metadata.\n-            loadMetadata = true;\n-            break;\n-          }\n-        }\n-      }\n-    }\n-    // If the inode was deleted in the previous sync step, we need to remove the inode from the\n-    // locked path\n-    if (deletedInode) {\n-      inodePath.removeLastInode();\n-    }\n-\n-    // load metadata if necessary.\n-    if (loadMetadata) {\n-      loadMetadataForPath(inodePath);\n-    }\n-    mUfsSyncPathCache.notifySyncedPath(inodePath.getUri().getPath(), DescendantType.ONE);\n-\n-    if (syncChildren) {\n-      // Iterate over Alluxio children and process persisted children.\n-      mInodeStore.getChildren(inode.asDirectory()).forEach(childInode -> {\n-        // If we are only loading non-existing metadata, then don't process any child which\n-        // was already in the tree, unless it is a directory, in which case, we might need to load\n-        // its children.\n-        if (mLoadOnly && inodeChildren.containsKey(childInode.getName()) && childInode.isFile()) {\n-          return;\n-        }\n-        // If we're performing a recursive sync, add each child of our current Inode to the queue\n-        AlluxioURI child = inodePath.getUri().joinUnsafe(childInode.getName());\n-        mSyncMetadataQ.add(child);\n-        // This asynchronously schedules a job to pre-fetch the statuses into the cache.\n-        if (childInode.isDirectory()) {\n-          mStatusCache.prefetchChildren(child, mMountTable);\n-        }\n-      });\n-    }\n-  }\n-\n-  private void loadMetadataForPath(LockedInodePath inodePath)\n-      throws InvalidPathException, AccessControlException, IOException, FileDoesNotExistException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, BlockInfoException {\n-\n-    UfsStatus status = mStatusCache.getStatus(inodePath.getUri());\n-    LoadMetadataContext ctx = LoadMetadataContext.mergeFrom(\n-        LoadMetadataPOptions.newBuilder()\n-            .setCreateAncestors(true)\n-            .setLoadDescendantType(GrpcUtils.toProto(mDescendantType)))\n-        .setUfsStatus(status);\n-    loadMetadata(inodePath, ctx);\n-  }\n-\n-  private void loadMetadata(LockedInodePath inodePath, LoadMetadataContext context)\n-      throws AccessControlException, BlockInfoException, FileAlreadyCompletedException,\n-      FileDoesNotExistException, InvalidFileSizeException, InvalidPathException, IOException {\n-    AlluxioURI path = inodePath.getUri();\n-    MountTable.Resolution resolution = mMountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null && !ufs.exists(ufsUri.toString())) {\n-        // uri does not exist in ufs\n-        Inode inode = inodePath.getInode();\n-        if (inode.isFile()) {\n-          throw new IllegalArgumentException(String.format(\n-              \"load metadata cannot be called on a file if no ufs \"\n-                  + \"status is present in the context. %s\", inodePath.getUri()));\n-        }\n-\n-        mInodeTree.setDirectChildrenLoaded(mRpcContext, inode.asDirectory());\n-        return;\n-      }\n-      boolean isFile;\n-      if (context.getUfsStatus() != null) {\n-        isFile = context.getUfsStatus().isFile();\n-      } else {\n-        isFile = ufs.isFile(ufsUri.toString());\n-      }\n-      if (isFile) {\n-        loadFileMetadataInternal(mRpcContext, inodePath, resolution, context, mFsMaster);\n-      } else {\n-        loadDirectoryMetadata(mRpcContext, inodePath, context, mMountTable, mFsMaster);\n-\n-        // now load all children if required\n-        LoadDescendantPType type = context.getOptions().getLoadDescendantType();\n-        if (type != LoadDescendantPType.NONE) {\n-          Collection<UfsStatus> children = mStatusCache.fetchChildrenIfAbsent(inodePath.getUri(),\n-              mMountTable);\n-          for (UfsStatus childStatus : children) {\n-            if (PathUtils.isTemporaryFileName(childStatus.getName())) {\n-              continue;\n-            }\n-            AlluxioURI childURI = new AlluxioURI(PathUtils.concatPath(inodePath.getUri(),\n-                childStatus.getName()));\n-            if (mInodeTree.inodePathExists(childURI) && (childStatus.isFile()\n-                || context.getOptions().getLoadDescendantType() != LoadDescendantPType.ALL)) {\n-              // stop traversing if this is an existing file, or an existing directory without\n-              // loading all descendants.\n-              continue;\n-            }\n-            LoadMetadataContext loadMetadataContext =\n-                LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder()\n-                    .setLoadDescendantType(LoadDescendantPType.NONE)\n-                    .setCreateAncestors(false))\n-                .setUfsStatus(childStatus);\n-            try (LockedInodePath descendant = inodePath\n-                .lockDescendant(inodePath.getUri().joinUnsafe(childStatus.getName()),\n-                    LockPattern.READ)) {\n-              loadMetadata(descendant, loadMetadataContext);\n-            } catch (FileNotFoundException e) {\n-              LOG.debug(\"Failed to loadMetadata because file is not in ufs:\"\n-                      + \" inodePath={}, options={}.\",\n-                  childURI, loadMetadataContext, e);\n-            }\n-          }\n-          mInodeTree.setDirectChildrenLoaded(mRpcContext, inodePath.getInode().asDirectory());\n-        }\n-      }\n-    } catch (IOException e) {\n-      LOG.debug(\"Failed to loadMetadata: inodePath={}, context={}.\", inodePath.getUri(), context,\n-          e);\n-      throw e;\n-    }\n-  }\n-\n-  /**\n-   * Loads metadata for the file identified by the given path from UFS into Alluxio.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param resolution the UFS resolution of path\n-   * @param context the load metadata context\n-   */\n-  static void loadFileMetadataInternal(RpcContext rpcContext, LockedInodePath inodePath,\n-      MountTable.Resolution resolution, LoadMetadataContext context,\n-      DefaultFileSystemMaster fsMaster)\n-      throws BlockInfoException, FileDoesNotExistException, InvalidPathException,\n-      FileAlreadyCompletedException, InvalidFileSizeException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    AlluxioURI ufsUri = resolution.getUri();\n-    long ufsBlockSizeByte;\n-    long ufsLength;\n-    AccessControlList acl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingFileStatus(ufsUri.toString()));\n-      }\n-      ufsLength = ((UfsFileStatus) context.getUfsStatus()).getContentLength();\n-      long blockSize = ((UfsFileStatus) context.getUfsStatus()).getBlockSize();\n-      ufsBlockSizeByte = blockSize != UfsFileStatus.UNKNOWN_BLOCK_SIZE\n-          ? blockSize : ufs.getBlockSizeByte(ufsUri.toString());\n-\n-      if (fsMaster.isAclEnabled()) {\n-        Pair<AccessControlList, DefaultAccessControlList> aclPair\n-            = ufs.getAclPair(ufsUri.toString());\n-        if (aclPair != null) {\n-          acl = aclPair.getFirst();\n-          // DefaultACL should be null, because it is a file\n-          if (aclPair.getSecond() != null) {\n-            LOG.warn(\"File {} has default ACL in the UFS\", inodePath.getUri());\n-          }\n-        }\n-      }\n-    }\n-\n-    // Metadata loaded from UFS has no TTL set.\n-    CreateFileContext createFileContext = CreateFileContext.defaults();\n-    createFileContext.getOptions().setBlockSizeBytes(ufsBlockSizeByte);\n-    createFileContext.getOptions().setRecursive(context.getOptions().getCreateAncestors());\n-    createFileContext.getOptions()\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createFileContext.setWriteType(WriteType.THROUGH); // set as through since already in UFS\n-    createFileContext.setMetadataLoad(true);\n-    createFileContext.setOwner(context.getUfsStatus().getOwner());\n-    createFileContext.setGroup(context.getUfsStatus().getGroup());\n-    createFileContext.setXAttr(context.getUfsStatus().getXAttr());\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Mode mode = new Mode(ufsMode);\n-    Long ufsLastModified = context.getUfsStatus().getLastModifiedTime();\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createFileContext.getOptions().setMode(mode.toProto());\n-    if (acl != null) {\n-      createFileContext.setAcl(acl.getEntries());\n-    }\n-    if (ufsLastModified != null) {\n-      createFileContext.setOperationTimeMs(ufsLastModified);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createFileInternal(rpcContext, writeLockedPath, createFileContext);\n-      CompleteFileContext completeContext =\n-          CompleteFileContext.mergeFrom(CompleteFilePOptions.newBuilder().setUfsLength(ufsLength))\n-              .setUfsStatus(context.getUfsStatus());\n-      if (ufsLastModified != null) {\n-        completeContext.setOperationTimeMs(ufsLastModified);\n-      }\n-      fsMaster.completeFileInternal(rpcContext, writeLockedPath, completeContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the file before we got the write lock.\n-      // The file already exists, so nothing needs to be loaded.\n-      LOG.debug(\"Failed to load file metadata: {}\", e.toString());\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-\n-  /**\n-   * Loads metadata for the directory identified by the given path from UFS into Alluxio. This does\n-   * not actually require looking at the UFS path.\n-   * It is a no-op if the directory exists.\n-   *\n-   * This method doesn't require any specific type of locking on inodePath. If the path needs to be\n-   * loaded, we will acquire a write-edge lock if necessary.\n-   *\n-   * @param rpcContext the rpc context\n-   * @param inodePath the path for which metadata should be loaded\n-   * @param context the load metadata context\n-   */\n-  static void loadDirectoryMetadata(RpcContext rpcContext, LockedInodePath inodePath,\n-      LoadMetadataContext context, MountTable mountTable, DefaultFileSystemMaster fsMaster)\n-      throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n-    if (inodePath.fullPathExists()) {\n-      return;\n-    }\n-    CreateDirectoryContext createDirectoryContext = CreateDirectoryContext.defaults();\n-    createDirectoryContext.getOptions()\n-        .setRecursive(context.getOptions().getCreateAncestors()).setAllowExists(false)\n-        .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-            .setTtl(context.getOptions().getCommonOptions().getTtl())\n-            .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()));\n-    createDirectoryContext.setMountPoint(mountTable.isMountPoint(inodePath.getUri()));\n-    createDirectoryContext.setMetadataLoad(true);\n-    createDirectoryContext.setWriteType(WriteType.THROUGH);\n-    MountTable.Resolution resolution = mountTable.resolve(inodePath.getUri());\n-\n-    AlluxioURI ufsUri = resolution.getUri();\n-    AccessControlList acl = null;\n-    DefaultAccessControlList defaultAcl = null;\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      if (context.getUfsStatus() == null) {\n-        context.setUfsStatus(ufs.getExistingDirectoryStatus(ufsUri.toString()));\n-      }\n-      Pair<AccessControlList, DefaultAccessControlList> aclPair =\n-          ufs.getAclPair(ufsUri.toString());\n-      if (aclPair != null) {\n-        acl = aclPair.getFirst();\n-        defaultAcl = aclPair.getSecond();\n-      }\n-    }\n-    String ufsOwner = context.getUfsStatus().getOwner();\n-    String ufsGroup = context.getUfsStatus().getGroup();\n-    short ufsMode = context.getUfsStatus().getMode();\n-    Long lastModifiedTime = context.getUfsStatus().getLastModifiedTime();\n-    Mode mode = new Mode(ufsMode);\n-    if (resolution.getShared()) {\n-      mode.setOtherBits(mode.getOtherBits().or(mode.getOwnerBits()));\n-    }\n-    createDirectoryContext.getOptions().setMode(mode.toProto());\n-    createDirectoryContext.setOwner(ufsOwner).setGroup(ufsGroup)\n-        .setUfsStatus(context.getUfsStatus());\n-    createDirectoryContext.setXAttr(context.getUfsStatus().getXAttr());\n-    if (acl != null) {\n-      createDirectoryContext.setAcl(acl.getEntries());\n-    }\n-\n-    if (defaultAcl != null) {\n-      createDirectoryContext.setDefaultAcl(defaultAcl.getEntries());\n-    }\n-    if (lastModifiedTime != null) {\n-      createDirectoryContext.setOperationTimeMs(lastModifiedTime);\n-    }\n-\n-    try (LockedInodePath writeLockedPath = inodePath.lockFinalEdgeWrite()) {\n-      fsMaster.createDirectoryInternal(rpcContext, writeLockedPath, createDirectoryContext);\n-    } catch (FileAlreadyExistsException e) {\n-      // This may occur if a thread created or loaded the directory before we got the write lock.\n-      // The directory already exists, so nothing needs to be loaded.\n-    }\n-    // Re-traverse the path to pick up any newly created inodes.\n-    inodePath.traverse();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4NTgxNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419585816", "bodyText": "add path to message", "author": "gpang", "createdAt": "2020-05-04T17:01:36Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,279 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+import alluxio.util.LogUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n+   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n+   *                         schedule any tasks.\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @return the previous status for the path if it existed, null otherwise\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  @Nullable\n+  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+    return mStatuses.put(path, status);\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @return the previous set of children if the mapping existed, null otherwise\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+      set.add(child);\n+    });\n+    return mChildren.put(path, set);\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n+            path, e);\n+        if (e instanceof InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        throw new IOException(e);\n+      } finally {\n+        mActivePrefetchJobs.remove(path);\n+      }\n+    }\n+    if (useFallback) {\n+      return getChildrenIfAbsent(path, mountTable);\n+    }\n+    return null;\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n+   *\n+   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n+   * a prefetch job was scheduled or not.\n+   *\n+   * @param path the Alluxio path\n+   * @param mountTable the Alluxio mount table\n+   * @return child UFS statuses of the alluxio path\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws IOException, InvalidPathException {\n+    return fetchChildrenIfAbsent(path, mountTable, true);\n+  }\n+\n+  /**\n+   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n+   *\n+   * This method first checks if the children have already been retrieved, and if not, then\n+   * retrieves them.\n+\n+   * @param path the path to get the children for\n+   * @param mountTable the Alluxio mount table\n+   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n+   *         statuses\n+   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n+   */\n+  @Nullable\n+  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    MountTable.Resolution resolution = mountTable.resolve(path);\n+    AlluxioURI ufsUri = resolution.getUri();\n+    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n+      UnderFileSystem ufs = ufsResource.get();\n+      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n+      if (statuses == null) {\n+        return null;\n+      }\n+      children = Arrays.asList(statuses);\n+      addChildren(path, children);\n+    } catch (IllegalArgumentException | IOException e) {\n+      LOG.debug(\"Failed to add status to cache\", e);\n+    }\n+    return children;\n+  }\n+\n+  /**\n+   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n+    return mChildren.get(path);\n+  }\n+\n+  /**\n+   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n+   *\n+   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n+   * with the same Alluxio path.\n+   *\n+   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n+   * a no-op.\n+   *\n+   * @param path the path to prefetch\n+   * @param mountTable the Alluxio mount table\n+   */\n+  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n+    if (mPrefetchExecutor == null) {\n+      return;\n+    }\n+    try {\n+      Future<Collection<UfsStatus>> job =\n+          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n+      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, job);\n+      if (prev != null) {\n+        prev.cancel(true);\n+      }\n+    } catch (RejectedExecutionException e) {\n+      LOG.debug(\"Failed to submit prefetch job\", e);", "originalCommit": "ff8a137d843dabc6cb4b38fb5ae7a324cae6fec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTcwMTk0NQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419701945", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-04T20:17:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4NTgxNg=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex 278d1872f2..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,279 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-import alluxio.util.LogUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n-   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n-   *                         schedule any tasks.\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @return the previous status for the path if it existed, null otherwise\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  @Nullable\n-  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-    return mStatuses.put(path, status);\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @return the previous set of children if the mapping existed, null otherwise\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-      set.add(child);\n-    });\n-    return mChildren.put(path, set);\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n-            path, e);\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      } finally {\n-        mActivePrefetchJobs.remove(path);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> job =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, job);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4NjA2MA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419586060", "bodyText": "add path to message", "author": "gpang", "createdAt": "2020-05-04T17:01:59Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,279 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+import alluxio.util.LogUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n+   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n+   *                         schedule any tasks.\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @return the previous status for the path if it existed, null otherwise\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  @Nullable\n+  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+    return mStatuses.put(path, status);\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @return the previous set of children if the mapping existed, null otherwise\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+      set.add(child);\n+    });\n+    return mChildren.put(path, set);\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n+            path, e);\n+        if (e instanceof InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        throw new IOException(e);\n+      } finally {\n+        mActivePrefetchJobs.remove(path);\n+      }\n+    }\n+    if (useFallback) {\n+      return getChildrenIfAbsent(path, mountTable);\n+    }\n+    return null;\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n+   *\n+   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n+   * a prefetch job was scheduled or not.\n+   *\n+   * @param path the Alluxio path\n+   * @param mountTable the Alluxio mount table\n+   * @return child UFS statuses of the alluxio path\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws IOException, InvalidPathException {\n+    return fetchChildrenIfAbsent(path, mountTable, true);\n+  }\n+\n+  /**\n+   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n+   *\n+   * This method first checks if the children have already been retrieved, and if not, then\n+   * retrieves them.\n+\n+   * @param path the path to get the children for\n+   * @param mountTable the Alluxio mount table\n+   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n+   *         statuses\n+   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n+   */\n+  @Nullable\n+  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n+      throws InvalidPathException {\n+    Collection<UfsStatus> children = getChildren(path);\n+    if (children != null) {\n+      return children;\n+    }\n+    MountTable.Resolution resolution = mountTable.resolve(path);\n+    AlluxioURI ufsUri = resolution.getUri();\n+    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n+      UnderFileSystem ufs = ufsResource.get();\n+      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n+      if (statuses == null) {\n+        return null;\n+      }\n+      children = Arrays.asList(statuses);\n+      addChildren(path, children);\n+    } catch (IllegalArgumentException | IOException e) {\n+      LOG.debug(\"Failed to add status to cache\", e);", "originalCommit": "ff8a137d843dabc6cb4b38fb5ae7a324cae6fec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTcwMTg5Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419701896", "bodyText": "updated", "author": "ZacBlanco", "createdAt": "2020-05-04T20:17:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4NjA2MA=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex 278d1872f2..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,279 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-import alluxio.util.LogUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n-   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n-   *                         schedule any tasks.\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @return the previous status for the path if it existed, null otherwise\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  @Nullable\n-  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-    return mStatuses.put(path, status);\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @return the previous set of children if the mapping existed, null otherwise\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-      set.add(child);\n-    });\n-    return mChildren.put(path, set);\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n-            path, e);\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      } finally {\n-        mActivePrefetchJobs.remove(path);\n-      }\n-    }\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache\", e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> job =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, job);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job\", e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(true);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4ODQ5Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419588493", "bodyText": "Won't this print out the entire stack trace of the exception?", "author": "gpang", "createdAt": "2020-05-04T17:05:44Z", "path": "core/common/src/main/java/alluxio/util/LogUtils.java", "diffHunk": "@@ -127,7 +127,7 @@ public static void warnWithException(Logger logger, String message, Object ...ar\n       logger.debug(message, args);\n     } else {\n       if (args.length > 0 && args[args.length - 1] instanceof Throwable) {\n-        args[args.length - 1] = ((Throwable) args[args.length - 1]).getMessage();\n+        args[args.length - 1] = (args[args.length - 1]).toString();", "originalCommit": "ff8a137d843dabc6cb4b38fb5ae7a324cae6fec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYwNDExOA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419604118", "bodyText": "No, this just prints <ExceptionClass>: <Exception message>. Before we would lose the exception type.", "author": "ZacBlanco", "createdAt": "2020-05-04T17:30:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU4ODQ5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/common/src/main/java/alluxio/util/LogUtils.java b/core/common/src/main/java/alluxio/util/LogUtils.java\nindex 691cd7136e..65601061c1 100644\n--- a/core/common/src/main/java/alluxio/util/LogUtils.java\n+++ b/core/common/src/main/java/alluxio/util/LogUtils.java\n\n@@ -127,7 +127,7 @@ public final class LogUtils {\n       logger.debug(message, args);\n     } else {\n       if (args.length > 0 && args[args.length - 1] instanceof Throwable) {\n-        args[args.length - 1] = (args[args.length - 1]).toString();\n+        args[args.length - 1] = ((Throwable) args[args.length - 1]).getMessage();\n       }\n       logger.warn(message + \": {}\", args);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5MzE0Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419593146", "bodyText": "Is the general approach for RPCs to have a sync phase first, then the actual execution of the RPC? (Before it did the sync within the same contexts of the RPC execution).", "author": "gpang", "createdAt": "2020-05-04T17:13:07Z", "path": "core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java", "diffHunk": "@@ -726,45 +744,53 @@ public FileInfo getFileInfo(AlluxioURI path, GetStatusContext context)\n       throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n     Metrics.GET_FILE_INFO_OPS.inc();\n     long opTimeMs = System.currentTimeMillis();\n-    LockingScheme lockingScheme =\n-        createLockingScheme(path, context.getOptions().getCommonOptions(), LockPattern.READ, true);\n     try (RpcContext rpcContext = createRpcContext();\n-         LockedInodePath inodePath = mInodeTree\n-             .lockInodePath(lockingScheme.getPath(), lockingScheme.getPattern());\n-         FileSystemMasterAuditContext auditContext =\n-             createAuditContext(\"getFileInfo\", path, null, inodePath.getInodeOrNull())) {\n-      try {\n-        mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n-      } catch (AccessControlException e) {\n-        auditContext.setAllowed(false);\n-        throw e;\n-      }\n-      // Possible ufs sync.\n-      if (syncMetadata(rpcContext, inodePath, lockingScheme, DescendantType.ONE)) {\n+        FileSystemMasterAuditContext auditContext =\n+            createAuditContext(\"getFileInfo\", path, null, null)) {\n+\n+      if (syncMetadata(rpcContext,", "originalCommit": "ff8a137d843dabc6cb4b38fb5ae7a324cae6fec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYwODAzMA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419608030", "bodyText": "For All RPCs previously the sync phase typically came at the very beginning of the RPC after the initial permission check. This was the old way:\n\ncreate RPC, audit context, lock inode path\ncheck permissions\nperform sync\nperform RPC\nunlock\n\nBecause of the new locking requirements, there is a new paradigm of\n\ncreate RPC/audit context\ncheck if sync is required\n\nif so, lock properly for sync\ncheck permissions\ndo sync\nunlock from sync\n\n\nlock for RPC\ncheck permissions\nperform RPC\nunlock\n\nThe reason permission check is performed twice is because it requires having a locked inode path before doing the check.", "author": "ZacBlanco", "createdAt": "2020-05-04T17:37:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5MzE0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java b/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\nindex 598ee6be56..31acef06ca 100644\n--- a/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\n+++ b/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\n\n@@ -744,53 +728,45 @@ public final class DefaultFileSystemMaster extends CoreMaster\n       throws FileDoesNotExistException, InvalidPathException, AccessControlException, IOException {\n     Metrics.GET_FILE_INFO_OPS.inc();\n     long opTimeMs = System.currentTimeMillis();\n+    LockingScheme lockingScheme =\n+        createLockingScheme(path, context.getOptions().getCommonOptions(), LockPattern.READ, true);\n     try (RpcContext rpcContext = createRpcContext();\n-        FileSystemMasterAuditContext auditContext =\n-            createAuditContext(\"getFileInfo\", path, null, null)) {\n-\n-      if (syncMetadata(rpcContext,\n-          path,\n-          context.getOptions().getCommonOptions(),\n-          DescendantType.ONE,\n-          auditContext,\n-          LockedInodePath::getInodeOrNull,\n-          (inodePath, permChecker) -> permChecker.checkPermission(Mode.Bits.READ, inodePath),\n-          true)) {\n+         LockedInodePath inodePath = mInodeTree\n+             .lockInodePath(lockingScheme.getPath(), lockingScheme.getPattern());\n+         FileSystemMasterAuditContext auditContext =\n+             createAuditContext(\"getFileInfo\", path, null, inodePath.getInodeOrNull())) {\n+      try {\n+        mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n+      } catch (AccessControlException e) {\n+        auditContext.setAllowed(false);\n+        throw e;\n+      }\n+      // Possible ufs sync.\n+      if (syncMetadata(rpcContext, inodePath, lockingScheme, DescendantType.ONE)) {\n         // If synced, do not load metadata.\n         context.getOptions().setLoadMetadataType(LoadMetadataPType.NEVER);\n       }\n \n-      LockingScheme lockingScheme = new LockingScheme(path, LockPattern.READ, false);\n-      try (LockedInodePath inodePath = mInodeTree.lockInodePath(lockingScheme)) {\n-        auditContext.setSrcInode(inodePath.getInodeOrNull());\n-        try {\n-          mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n-        } catch (AccessControlException e) {\n-          auditContext.setAllowed(false);\n-          throw e;\n-        }\n-        // If the file already exists, then metadata does not need to be loaded,\n-        // otherwise load metadata.\n-        if (!inodePath.fullPathExists()) {\n-          checkLoadMetadataOptions(context.getOptions().getLoadMetadataType(), inodePath.getUri());\n-          loadMetadataIfNotExist(rpcContext, inodePath, LoadMetadataContext.mergeFrom(\n-              LoadMetadataPOptions.newBuilder().setCreateAncestors(true).setCommonOptions(\n-                  FileSystemMasterCommonPOptions.newBuilder()\n-                      .setTtl(context.getOptions().getCommonOptions().getTtl())\n-                      .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()))),\n-              true);\n-          ensureFullPathAndUpdateCache(inodePath);\n-        }\n-        FileInfo fileInfo = getFileInfoInternal(inodePath);\n-        Mode.Bits accessMode = Mode.Bits.fromProto(context.getOptions().getAccessMode());\n-        if (context.getOptions().getUpdateTimestamps() && context.getOptions().hasAccessMode() && (\n-            accessMode.imply(Mode.Bits.READ) || accessMode.imply(Mode.Bits.WRITE))) {\n-          mAccessTimeUpdater\n-              .updateAccessTime(rpcContext.getJournalContext(), inodePath.getInode(), opTimeMs);\n-        }\n-        auditContext.setSrcInode(inodePath.getInode()).setSucceeded(true);\n-        return fileInfo;\n+      // If the file already exists, then metadata does not need to be loaded,\n+      // otherwise load metadata.\n+      if (!inodePath.fullPathExists()) {\n+        checkLoadMetadataOptions(context.getOptions().getLoadMetadataType(), inodePath.getUri());\n+        loadMetadataIfNotExist(rpcContext, inodePath,\n+            LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder().setCreateAncestors(true)\n+                .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n+                    .setTtl(context.getOptions().getCommonOptions().getTtl())\n+                    .setTtlAction(context.getOptions().getCommonOptions().getTtlAction()))));\n+        ensureFullPathAndUpdateCache(inodePath);\n+      }\n+      FileInfo fileInfo = getFileInfoInternal(inodePath);\n+      Mode.Bits accessMode = Mode.Bits.fromProto(context.getOptions().getAccessMode());\n+      if (context.getOptions().getUpdateTimestamps() && context.getOptions().hasAccessMode()\n+           && (accessMode.imply(Mode.Bits.READ) || accessMode.imply(Mode.Bits.WRITE))) {\n+        mAccessTimeUpdater.updateAccessTime(rpcContext.getJournalContext(),\n+            inodePath.getInode(), opTimeMs);\n       }\n+      auditContext.setSrcInode(inodePath.getInode()).setSucceeded(true);\n+      return fileInfo;\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5Mzg5Mw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419593893", "bodyText": "Can the new syncMetadata also take care of loadMetadata? I think the full sync is a superset of load metadata, so can't we just do the sync, which can optionally take care of loading metadata only if requested? I think load metadata only happens on getFileInfo and listStatus.", "author": "gpang", "createdAt": "2020-05-04T17:14:18Z", "path": "core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java", "diffHunk": "@@ -815,73 +841,81 @@ public void listStatus(AlluxioURI path, ListStatusContext context,\n       ResultStream<FileInfo> resultStream)\n       throws AccessControlException, FileDoesNotExistException, InvalidPathException, IOException {\n     Metrics.GET_FILE_INFO_OPS.inc();\n-    LockingScheme lockingScheme =\n-        createLockingScheme(path, context.getOptions().getCommonOptions(), LockPattern.READ);\n     try (RpcContext rpcContext = createRpcContext();\n-         LockedInodePath inodePath = mInodeTree\n-             .lockInodePath(lockingScheme.getPath(), lockingScheme.getPattern());\n-         FileSystemMasterAuditContext auditContext =\n-             createAuditContext(\"listStatus\", path, null, inodePath.getInodeOrNull())) {\n-      try {\n-        mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n-      } catch (AccessControlException e) {\n-        auditContext.setAllowed(false);\n-        throw e;\n-      }\n-\n-      DescendantType descendantType = context.getOptions().getRecursive() ? DescendantType.ALL\n-          : DescendantType.ONE;\n-      // Possible ufs sync.\n-      if (syncMetadata(rpcContext, inodePath, lockingScheme, descendantType)) {\n+        FileSystemMasterAuditContext auditContext =\n+            createAuditContext(\"listStatus\", path, null, null)) {\n+\n+      DescendantType descendantType =\n+          context.getOptions().getRecursive() ? DescendantType.ALL : DescendantType.ONE;\n+      if (syncMetadata(rpcContext,\n+          path,\n+          context.getOptions().getCommonOptions(),\n+          descendantType,\n+          auditContext,\n+          LockedInodePath::getInodeOrNull,\n+          (inodePath, permChecker) -> permChecker.checkPermission(Mode.Bits.READ, inodePath))) {\n         // If synced, do not load metadata.\n         context.getOptions().setLoadMetadataType(LoadMetadataPType.NEVER);\n       }\n \n-      DescendantType loadDescendantType;\n-      if (context.getOptions().getLoadMetadataType() == LoadMetadataPType.NEVER) {\n-        loadDescendantType = DescendantType.NONE;\n-      } else if (context.getOptions().getRecursive()) {\n-        loadDescendantType = DescendantType.ALL;\n-      } else {\n-        loadDescendantType = DescendantType.ONE;\n-      }\n-      // load metadata for 1 level of descendants, or all descendants if recursive\n-      LoadMetadataContext loadMetadataContext =\n-          LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder().setCreateAncestors(true)\n-              .setLoadDescendantType(GrpcUtils.toProto(loadDescendantType))\n-              .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-                  .setTtl(context.getOptions().getCommonOptions().getTtl())\n-                  .setTtlAction(context.getOptions().getCommonOptions().getTtlAction())));\n-      Inode inode;\n-      if (inodePath.fullPathExists()) {\n-        inode = inodePath.getInode();\n-        if (inode.isDirectory()\n-            && context.getOptions().getLoadMetadataType() != LoadMetadataPType.ALWAYS) {\n-          InodeDirectory inodeDirectory = inode.asDirectory();\n+      // We just synced; the new lock pattern should not sync.\n+      LockingScheme lockingScheme = new LockingScheme(path, LockPattern.READ, false);\n+      try (LockedInodePath inodePath = mInodeTree.lockInodePath(lockingScheme)) {\n+        auditContext.setSrcInode(inodePath.getInodeOrNull());\n+        try {\n+          mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n+        } catch (AccessControlException e) {\n+          auditContext.setAllowed(false);\n+          throw e;\n+        }\n \n-          boolean isLoaded = inodeDirectory.isDirectChildrenLoaded();\n-          if (context.getOptions().getRecursive()) {\n-            isLoaded = areDescendantsLoaded(inodeDirectory);\n-          }\n-          if (isLoaded) {\n-            // no need to load again.\n-            loadMetadataContext.getOptions().setLoadDescendantType(LoadDescendantPType.NONE);\n+        DescendantType loadDescendantType;\n+        if (context.getOptions().getLoadMetadataType() == LoadMetadataPType.NEVER) {\n+          loadDescendantType = DescendantType.NONE;\n+        } else if (context.getOptions().getRecursive()) {\n+          loadDescendantType = DescendantType.ALL;\n+        } else {\n+          loadDescendantType = DescendantType.ONE;\n+        }\n+        // load metadata for 1 level of descendants, or all descendants if recursive\n+        LoadMetadataContext loadMetadataContext = LoadMetadataContext.mergeFrom(\n+            LoadMetadataPOptions.newBuilder()\n+                .setCreateAncestors(true)\n+                .setLoadDescendantType(GrpcUtils.toProto(loadDescendantType))\n+                .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n+                    .setTtl(context.getOptions().getCommonOptions().getTtl())\n+                    .setTtlAction(context.getOptions().getCommonOptions().getTtlAction())));\n+        Inode inode;\n+        if (inodePath.fullPathExists()) {\n+          inode = inodePath.getInode();\n+          if (inode.isDirectory()\n+              && context.getOptions().getLoadMetadataType() != LoadMetadataPType.ALWAYS) {\n+            InodeDirectory inodeDirectory = inode.asDirectory();\n+\n+            boolean isLoaded = inodeDirectory.isDirectChildrenLoaded();\n+            if (context.getOptions().getRecursive()) {\n+              isLoaded = areDescendantsLoaded(inodeDirectory);\n+            }\n+            if (isLoaded) {\n+              // no need to load again.\n+              loadMetadataContext.getOptions().setLoadDescendantType(LoadDescendantPType.NONE);\n+            }\n           }\n+        } else {\n+          checkLoadMetadataOptions(context.getOptions().getLoadMetadataType(), inodePath.getUri());\n         }\n-      } else {\n-        checkLoadMetadataOptions(context.getOptions().getLoadMetadataType(), inodePath.getUri());\n-      }\n \n-      loadMetadataIfNotExist(rpcContext, inodePath, loadMetadataContext);\n-      ensureFullPathAndUpdateCache(inodePath);\n-      inode = inodePath.getInode();\n-      auditContext.setSrcInode(inode);\n-      DescendantType descendantTypeForListStatus =\n-          (context.getOptions().getRecursive()) ? DescendantType.ALL : DescendantType.ONE;\n-      listStatusInternal(context, rpcContext, inodePath, auditContext, descendantTypeForListStatus,\n-          resultStream, 0);\n-      auditContext.setSucceeded(true);\n-      Metrics.FILE_INFOS_GOT.inc();\n+        loadMetadataIfNotExist(rpcContext, inodePath, loadMetadataContext, false);", "originalCommit": "ff8a137d843dabc6cb4b38fb5ae7a324cae6fec4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTYwOTc1MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419609751", "bodyText": "Unfortunately in my testing this breaks behavior and some assumptions about what metadata gets loaded during these RPCs. I did this because my goal around these improvements was to not change any assumptions about how we load metadata.\nI don't remember exactly which tests broke, but basically loading is a strict load of metadata, whereas a sync could possibly delete or remove inodes, and so that broke a bunch of test assumptions. Breaking previous RPC behavior probably requires a larger discussion.", "author": "ZacBlanco", "createdAt": "2020-05-04T17:40:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5Mzg5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY2MzEwMw==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r419663103", "bodyText": "Yeah, I know load is different from sync. But maybe something like load-only could be an option to sync, so that when that option is used, it does not do the update/delete part of the sync?\nThis would only be for greater simplicity. I'm not sure if this would actually make it simpler, but I thought maybe it could.", "author": "gpang", "createdAt": "2020-05-04T19:08:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5Mzg5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NTAyNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r422285025", "bodyText": "That's actually what it already does....go to the definition of loadMetadataIfNotExist :)", "author": "ZacBlanco", "createdAt": "2020-05-08T17:57:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5Mzg5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE3MzAzNg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r423173036", "bodyText": "Yeah, I know loadMetadata call reuses sync. However, do you think it is possible for everything to be taken care of with the syncMetadata() at the beginning of this method? Basically, for listStatus and fileInfo they both have a concept of loading metadata, which is just the creating part of sync. I wonder if everything could be taken care of in the syncMetadata() call, so we don't even need the loadMetadata() method anymore.\n(This would not be part of this PR)", "author": "gpang", "createdAt": "2020-05-11T16:42:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTU5Mzg5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java b/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\nindex 598ee6be56..31acef06ca 100644\n--- a/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\n+++ b/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\n\n@@ -841,81 +817,73 @@ public final class DefaultFileSystemMaster extends CoreMaster\n       ResultStream<FileInfo> resultStream)\n       throws AccessControlException, FileDoesNotExistException, InvalidPathException, IOException {\n     Metrics.GET_FILE_INFO_OPS.inc();\n+    LockingScheme lockingScheme =\n+        createLockingScheme(path, context.getOptions().getCommonOptions(), LockPattern.READ);\n     try (RpcContext rpcContext = createRpcContext();\n-        FileSystemMasterAuditContext auditContext =\n-            createAuditContext(\"listStatus\", path, null, null)) {\n-\n-      DescendantType descendantType =\n-          context.getOptions().getRecursive() ? DescendantType.ALL : DescendantType.ONE;\n-      if (syncMetadata(rpcContext,\n-          path,\n-          context.getOptions().getCommonOptions(),\n-          descendantType,\n-          auditContext,\n-          LockedInodePath::getInodeOrNull,\n-          (inodePath, permChecker) -> permChecker.checkPermission(Mode.Bits.READ, inodePath))) {\n+         LockedInodePath inodePath = mInodeTree\n+             .lockInodePath(lockingScheme.getPath(), lockingScheme.getPattern());\n+         FileSystemMasterAuditContext auditContext =\n+             createAuditContext(\"listStatus\", path, null, inodePath.getInodeOrNull())) {\n+      try {\n+        mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n+      } catch (AccessControlException e) {\n+        auditContext.setAllowed(false);\n+        throw e;\n+      }\n+\n+      DescendantType descendantType = context.getOptions().getRecursive() ? DescendantType.ALL\n+          : DescendantType.ONE;\n+      // Possible ufs sync.\n+      if (syncMetadata(rpcContext, inodePath, lockingScheme, descendantType)) {\n         // If synced, do not load metadata.\n         context.getOptions().setLoadMetadataType(LoadMetadataPType.NEVER);\n       }\n \n-      // We just synced; the new lock pattern should not sync.\n-      LockingScheme lockingScheme = new LockingScheme(path, LockPattern.READ, false);\n-      try (LockedInodePath inodePath = mInodeTree.lockInodePath(lockingScheme)) {\n-        auditContext.setSrcInode(inodePath.getInodeOrNull());\n-        try {\n-          mPermissionChecker.checkPermission(Mode.Bits.READ, inodePath);\n-        } catch (AccessControlException e) {\n-          auditContext.setAllowed(false);\n-          throw e;\n-        }\n+      DescendantType loadDescendantType;\n+      if (context.getOptions().getLoadMetadataType() == LoadMetadataPType.NEVER) {\n+        loadDescendantType = DescendantType.NONE;\n+      } else if (context.getOptions().getRecursive()) {\n+        loadDescendantType = DescendantType.ALL;\n+      } else {\n+        loadDescendantType = DescendantType.ONE;\n+      }\n+      // load metadata for 1 level of descendants, or all descendants if recursive\n+      LoadMetadataContext loadMetadataContext =\n+          LoadMetadataContext.mergeFrom(LoadMetadataPOptions.newBuilder().setCreateAncestors(true)\n+              .setLoadDescendantType(GrpcUtils.toProto(loadDescendantType))\n+              .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n+                  .setTtl(context.getOptions().getCommonOptions().getTtl())\n+                  .setTtlAction(context.getOptions().getCommonOptions().getTtlAction())));\n+      Inode inode;\n+      if (inodePath.fullPathExists()) {\n+        inode = inodePath.getInode();\n+        if (inode.isDirectory()\n+            && context.getOptions().getLoadMetadataType() != LoadMetadataPType.ALWAYS) {\n+          InodeDirectory inodeDirectory = inode.asDirectory();\n \n-        DescendantType loadDescendantType;\n-        if (context.getOptions().getLoadMetadataType() == LoadMetadataPType.NEVER) {\n-          loadDescendantType = DescendantType.NONE;\n-        } else if (context.getOptions().getRecursive()) {\n-          loadDescendantType = DescendantType.ALL;\n-        } else {\n-          loadDescendantType = DescendantType.ONE;\n-        }\n-        // load metadata for 1 level of descendants, or all descendants if recursive\n-        LoadMetadataContext loadMetadataContext = LoadMetadataContext.mergeFrom(\n-            LoadMetadataPOptions.newBuilder()\n-                .setCreateAncestors(true)\n-                .setLoadDescendantType(GrpcUtils.toProto(loadDescendantType))\n-                .setCommonOptions(FileSystemMasterCommonPOptions.newBuilder()\n-                    .setTtl(context.getOptions().getCommonOptions().getTtl())\n-                    .setTtlAction(context.getOptions().getCommonOptions().getTtlAction())));\n-        Inode inode;\n-        if (inodePath.fullPathExists()) {\n-          inode = inodePath.getInode();\n-          if (inode.isDirectory()\n-              && context.getOptions().getLoadMetadataType() != LoadMetadataPType.ALWAYS) {\n-            InodeDirectory inodeDirectory = inode.asDirectory();\n-\n-            boolean isLoaded = inodeDirectory.isDirectChildrenLoaded();\n-            if (context.getOptions().getRecursive()) {\n-              isLoaded = areDescendantsLoaded(inodeDirectory);\n-            }\n-            if (isLoaded) {\n-              // no need to load again.\n-              loadMetadataContext.getOptions().setLoadDescendantType(LoadDescendantPType.NONE);\n-            }\n+          boolean isLoaded = inodeDirectory.isDirectChildrenLoaded();\n+          if (context.getOptions().getRecursive()) {\n+            isLoaded = areDescendantsLoaded(inodeDirectory);\n+          }\n+          if (isLoaded) {\n+            // no need to load again.\n+            loadMetadataContext.getOptions().setLoadDescendantType(LoadDescendantPType.NONE);\n           }\n-        } else {\n-          checkLoadMetadataOptions(context.getOptions().getLoadMetadataType(), inodePath.getUri());\n         }\n-\n-        loadMetadataIfNotExist(rpcContext, inodePath, loadMetadataContext, false);\n-        ensureFullPathAndUpdateCache(inodePath);\n-        inode = inodePath.getInode();\n-        auditContext.setSrcInode(inode);\n-        DescendantType descendantTypeForListStatus =\n-            (context.getOptions().getRecursive()) ? DescendantType.ALL : DescendantType.ONE;\n-        listStatusInternal(context, rpcContext, inodePath, auditContext,\n-            descendantTypeForListStatus, resultStream, 0);\n-        auditContext.setSucceeded(true);\n-        Metrics.FILE_INFOS_GOT.inc();\n+      } else {\n+        checkLoadMetadataOptions(context.getOptions().getLoadMetadataType(), inodePath.getUri());\n       }\n+\n+      loadMetadataIfNotExist(rpcContext, inodePath, loadMetadataContext);\n+      ensureFullPathAndUpdateCache(inodePath);\n+      inode = inodePath.getInode();\n+      auditContext.setSrcInode(inode);\n+      DescendantType descendantTypeForListStatus =\n+          (context.getOptions().getRecursive()) ? DescendantType.ALL : DescendantType.ONE;\n+      listStatusInternal(context, rpcContext, inodePath, auditContext, descendantTypeForListStatus,\n+          resultStream, 0);\n+      auditContext.setSucceeded(true);\n+      Metrics.FILE_INFOS_GOT.inc();\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkyMzIxNA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r420923214", "bodyText": "If the prefetch job is canceled, this will throw an error, right? Does something external retry this?", "author": "gpang", "createdAt": "2020-05-06T16:24:17Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+import alluxio.util.LogUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+@ThreadSafe\n+public class UfsStatusCache {\n+  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n+\n+  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n+  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n+  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n+  private final ExecutorService mPrefetchExecutor;\n+\n+  /**\n+   * Create a new instance of {@link UfsStatusCache}.\n+   *\n+   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n+   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n+   *                         schedule any tasks.\n+   */\n+  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n+    mStatuses = new ConcurrentHashMap<>();\n+    mChildren = new ConcurrentHashMap<>();\n+    mActivePrefetchJobs = new ConcurrentHashMap<>();\n+    mPrefetchExecutor = prefetchExecutor;\n+  }\n+\n+  /**\n+   * Add a new status to the cache.\n+   *\n+   * The last component of the path in the {@link AlluxioURI} must match the result of\n+   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n+   * URI.\n+   *\n+   * @param path the Alluxio path to key on\n+   * @param status the ufs status to store\n+   * @return the previous status for the path if it existed, null otherwise\n+   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n+   */\n+  @Nullable\n+  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n+    if (!path.getName().equals(status.getName())) {\n+      throw new IllegalArgumentException(\n+          String.format(\"path name %s does not match ufs status name %s\",\n+              path.getName(), status.getName()));\n+    }\n+    return mStatuses.put(path, status);\n+  }\n+\n+  /**\n+   * Add a parent-child mapping to the status cache.\n+   *\n+   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n+   *\n+   * @param path the directory inode path which contains the children\n+   * @param children the children of the {@code path}\n+   * @return the previous set of children if the mapping existed, null otherwise\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n+    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n+    children.forEach(child -> {\n+      AlluxioURI childPath = path.joinUnsafe(child.getName());\n+      addStatus(childPath, child);\n+      set.add(child);\n+    });\n+    return mChildren.put(path, set);\n+  }\n+\n+  /**\n+   * Remove a status from the cache.\n+   *\n+   *  Any children added to this status will remain in the cache.\n+   *\n+   * @param path the path corresponding to the {@link UfsStatus} to remove\n+   * @return the removed UfsStatus\n+   */\n+  public UfsStatus remove(AlluxioURI path) {\n+    UfsStatus removed = mStatuses.remove(path);\n+    if (removed == null) {\n+      return null;\n+    }\n+\n+    mChildren.remove(path); // ok if there aren't any children\n+    return removed;\n+  }\n+\n+  /**\n+   * Get the UfsStatus from a given AlluxioURI.\n+   *\n+   * @param path the path the retrieve\n+   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n+   */\n+  public UfsStatus getStatus(AlluxioURI path) {\n+    return mStatuses.get(path);\n+  }\n+\n+  /**\n+   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n+   *\n+   * Children can be returned in a few ways\n+   * 1. Children already exist in the internal index. We simply return them\n+   * 2. If children did not already exist in the index, then check if there was a scheduled\n+   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n+   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n+   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n+   * return null.\n+   *\n+   * @param path the Alluxio path to get the children of\n+   * @param mountTable the Alluxio mount table\n+   * @param useFallback whether or not to fall back to calling the UFS\n+   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n+   *         specified as false\n+   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n+   */\n+  @Nullable\n+  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n+      boolean useFallback)\n+      throws IOException, InvalidPathException {\n+    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n+    if (prefetchJob != null) {\n+      try {\n+        return prefetchJob.get();\n+      } catch (InterruptedException | ExecutionException e) {\n+        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n+            path, e);\n+        if (e instanceof InterruptedException) {\n+          Thread.currentThread().interrupt();\n+        }\n+        throw new IOException(e);", "originalCommit": "d7b701e8535c863ae9c395a75668c6f2f9f88c38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI3NDIxOA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r422274218", "bodyText": "There is currently no retry.\nI think that we should only throw the IOException if it is an InterruptedException, because that's something signalling the thread to stop. Otherwise if it is an ExecutionException or CancelledException then we should just continue with the fallback operation?", "author": "ZacBlanco", "createdAt": "2020-05-08T17:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkyMzIxNA=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex 5d590eabca..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,282 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-import alluxio.util.LogUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.ThreadSafe;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-@ThreadSafe\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n-   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n-   *                         schedule any tasks.\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @return the previous status for the path if it existed, null otherwise\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  @Nullable\n-  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-    return mStatuses.put(path, status);\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @return the previous set of children if the mapping existed, null otherwise\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-      set.add(child);\n-    });\n-    return mChildren.put(path, set);\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n-            path, e);\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      } finally {\n-        mActivePrefetchJobs.remove(path);\n-      }\n-    }\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache {}\", path, e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> job =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, job);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job for path {}\", path, e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(false);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDkyOTAxMg==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r420929012", "bodyText": "Should we make the force sync option a static constant, and reuse it here and below?", "author": "gpang", "createdAt": "2020-05-06T16:32:47Z", "path": "core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java", "diffHunk": "@@ -3235,28 +3096,33 @@ public void activeSyncMetadata(AlluxioURI path, Collection<AlluxioURI> changedFi\n     try (RpcContext rpcContext = createRpcContext()) {\n       if (changedFiles == null) {\n         // full sync\n-        LockingScheme lockingScheme = new LockingScheme(path, LockPattern.READ, true);\n-        try (LockedInodePath inodePath =\n-            mInodeTree.lockInodePath(lockingScheme.getPath(), lockingScheme.getPattern())) {\n-          syncMetadataInternal(rpcContext, inodePath, lockingScheme, DescendantType.ALL,\n-              populateStatusCache(path, DescendantType.ALL));\n+        long start = System.currentTimeMillis();\n+\n+        // Set sync interval to 0 to force a sync.\n+        FileSystemMasterCommonPOptions options =", "originalCommit": "d7b701e8535c863ae9c395a75668c6f2f9f88c38", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java b/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\nindex 598ee6be56..31acef06ca 100644\n--- a/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\n+++ b/core/server/master/src/main/java/alluxio/master/file/DefaultFileSystemMaster.java\n\n@@ -3096,33 +3301,35 @@ public final class DefaultFileSystemMaster extends CoreMaster\n     try (RpcContext rpcContext = createRpcContext()) {\n       if (changedFiles == null) {\n         // full sync\n-        long start = System.currentTimeMillis();\n-\n-        // Set sync interval to 0 to force a sync.\n-        FileSystemMasterCommonPOptions options =\n-            FileSystemMasterCommonPOptions.newBuilder().setSyncIntervalMs(0).build();\n-        try {\n-          syncMetadata(rpcContext, path, options, DescendantType.ALL, null, null, null);\n-        } catch (AccessControlException e) {\n-          // This shouldn never happen because the permission check function is passed as null.\n-          LOG.error(\"Active sync full scan failed on {}\", path, e);\n+        LockingScheme lockingScheme = new LockingScheme(path, LockPattern.READ, true);\n+        // Populate the status cache before taking a write lock\n+        Map<AlluxioURI, UfsStatus> statusCache;\n+        try (LockedInodePath inodePath =\n+            mInodeTree.lockInodePath(lockingScheme.getPath(), LockPattern.READ)) {\n+          statusCache = populateStatusCache(path, DescendantType.ALL);\n         }\n \n+        try (LockedInodePath inodePath =\n+            mInodeTree.lockInodePath(lockingScheme.getPath(), lockingScheme.getPattern())) {\n+          syncMetadataInternal(rpcContext, inodePath, lockingScheme, DescendantType.ALL,\n+              statusCache);\n+        }\n         LOG.info(\"Ended an active full sync of {}\", path.toString());\n         return;\n       } else {\n         // incremental sync\n+        Map<AlluxioURI, UfsStatus> statusCache = populateStatusCache(\n+            PathUtils.findLowestCommonAncestor(changedFiles), DescendantType.ALL);\n         Set<Callable<Void>> callables = new HashSet<>();\n         for (AlluxioURI changedFile : changedFiles) {\n           callables.add(() -> {\n-            // Set sync interval to 0 to force a sync.\n-            FileSystemMasterCommonPOptions options =\n-                FileSystemMasterCommonPOptions.newBuilder().setSyncIntervalMs(0).build();\n-            try {\n-              syncMetadata(rpcContext, changedFile, options, DescendantType.ONE, null, null, null);\n-            } catch (InvalidPathException | AccessControlException e) {\n-              LogUtils.warnWithException(LOG,\n-                  \"incremental active sync processed an invalid path {}\", changedFile.getPath(), e);\n+            LockingScheme lockingScheme = new LockingScheme(path, LockPattern.READ, true);\n+            try (LockedInodePath changedFilePath =\n+                mInodeTree.lockInodePath(changedFile, lockingScheme.getPattern())) {\n+              syncMetadataInternal(rpcContext, changedFilePath, lockingScheme, DescendantType.NONE,\n+                  statusCache);\n+            } catch (InvalidPathException e) {\n+              LOG.info(\"forceSyncMetadata processed an invalid path {}\", changedFile.getPath());\n             }\n             return null;\n           });\n"}}, {"oid": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "url": "https://github.com/Alluxio/alluxio/commit/2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "message": "Initial parallelized implementation", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "b38097f7de977e75377b871077266cae9cca2015", "url": "https://github.com/Alluxio/alluxio/commit/b38097f7de977e75377b871077266cae9cca2015", "message": "Stop deadlock when caller already has a write lock", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "2bccad4f2c4f4c8580581da325a34cfecf61b6c0", "url": "https://github.com/Alluxio/alluxio/commit/2bccad4f2c4f4c8580581da325a34cfecf61b6c0", "message": "Remove parallelization from loadMetadataInternal", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "46a3f5b69e87ebc08f03a0288cc25598dc5e305d", "url": "https://github.com/Alluxio/alluxio/commit/46a3f5b69e87ebc08f03a0288cc25598dc5e305d", "message": "Re-architect syncing primitive in FileSystemMaster", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "95f823f19d30ec61c5e7d422d9f53f7135fef268", "url": "https://github.com/Alluxio/alluxio/commit/95f823f19d30ec61c5e7d422d9f53f7135fef268", "message": "Remove duplicate code from DFSM", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "27521e30dde045d35199d2e8c32c6d4c334b951d", "url": "https://github.com/Alluxio/alluxio/commit/27521e30dde045d35199d2e8c32c6d4c334b951d", "message": "Fix complete for loadMetadataIfNotExist", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "0757fc583a0dc9ad00b8c46e61f96e2b3e9dfc96", "url": "https://github.com/Alluxio/alluxio/commit/0757fc583a0dc9ad00b8c46e61f96e2b3e9dfc96", "message": "Remove and replace old UfsStatusCache", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "1eed29033c7a2bf68c3a8423c7ebc2164400c90b", "url": "https://github.com/Alluxio/alluxio/commit/1eed29033c7a2bf68c3a8423c7ebc2164400c90b", "message": "Fully concurrent path syncing", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "29ec2eafa11d6eafd13aa0e730762905b89c35cf", "url": "https://github.com/Alluxio/alluxio/commit/29ec2eafa11d6eafd13aa0e730762905b89c35cf", "message": "Appease findbugs and make parallelism configurable", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "0fae41a86cc0c2c8e7ec20e6849f2043477d3341", "url": "https://github.com/Alluxio/alluxio/commit/0fae41a86cc0c2c8e7ec20e6849f2043477d3341", "message": "Remove test assertion with runtime assumption", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "4793f33f23862af675a672db0b569b19cf689ea0", "url": "https://github.com/Alluxio/alluxio/commit/4793f33f23862af675a672db0b569b19cf689ea0", "message": "Shut down lock pool evictor threads", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "966809048a1a189c3fd9c22ef49030ac78b2789b", "url": "https://github.com/Alluxio/alluxio/commit/966809048a1a189c3fd9c22ef49030ac78b2789b", "message": "Make metrics heartbeat test always use localhost\n\nOccasionally the JVM would pick up my computer's\nLAN name rather than localhost which would cause this test to fail", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "d0074877d63bd6b5b8eb086437648dfcb1f44ac6", "url": "https://github.com/Alluxio/alluxio/commit/d0074877d63bd6b5b8eb086437648dfcb1f44ac6", "message": "Close FSMaster during tests\n\nThis prevents lots of un-closed resources from\naccumulating while the test runs", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "08fe686de8355a75215e0970d7c3408d7bf7cfc9", "url": "https://github.com/Alluxio/alluxio/commit/08fe686de8355a75215e0970d7c3408d7bf7cfc9", "message": "Only use tryLock for sync stream", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "122c8fe58882ead3608e503622250fd7f5029898", "url": "https://github.com/Alluxio/alluxio/commit/122c8fe58882ead3608e503622250fd7f5029898", "message": "Fix LockPoolTest\n\nI'm not sure how this test didn't fail more consistently before.\n\nPreviously, the test would insert values [0,15] into the lock pool.\nThen, insert 16 in order to trigger an eviction. Next, it would finally\nattempt to insert [16,23]. Which should go up to the high watermark.\nHowever, sometimes the lock pool would evict entries [0, 8] (instead\nof [0,7]) leaving [9, 16], and attempting to insert [16, 23]. [9,23] is\nonly 15 total entries, when it expects 16. I make the test now insert\n[17,24]. It inserts the same amount of keys. It's just that the key\nrange is shifted, so that there is no key overlap.\n\nThe reason is because the evictor thread calculates numToEvict as\npool size - low watermark. After inserting the 17th item, the\nnumToEvict is 17 - 8 -> 9. For some reason before my changes,\nthis was being calculated as 8. As if the evictor was triggered prior\nto the key being added.", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "2492f81ebd357c28a3a5484313e9ac8b5a65dfcf", "url": "https://github.com/Alluxio/alluxio/commit/2492f81ebd357c28a3a5484313e9ac8b5a65dfcf", "message": "Split sync executor size from sync concurrency\n\nThis can help limit the impact of a single sync job on the\nperformance of Alluxio as a whole. This is especially\nimportant if more than one path is being synced at a time.\nIt allows for a limited level of concurrency but still lets\nus share a single thread pool for executing sync tasks.", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "455e16e059fe485611be71f4dfa52633ddf1e254", "url": "https://github.com/Alluxio/alluxio/commit/455e16e059fe485611be71f4dfa52633ddf1e254", "message": "Remove unnecessary logs", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "e338eb0cac3727f041ecc8d74121e70b426ff197", "url": "https://github.com/Alluxio/alluxio/commit/e338eb0cac3727f041ecc8d74121e70b426ff197", "message": "Improve sync stream javadoc", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "57fe6801c3d3ef197ef7b5c90dccff53606a1a85", "url": "https://github.com/Alluxio/alluxio/commit/57fe6801c3d3ef197ef7b5c90dccff53606a1a85", "message": "Fix FSMSyncMetadataTest", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "87ea39506454ef4195fe3634884b6593dc0c5895", "url": "https://github.com/Alluxio/alluxio/commit/87ea39506454ef4195fe3634884b6593dc0c5895", "message": "Use AlluxioURI for child index key\n\n- Using the UfsStatus presents a few problems because of the possibility\nof hash or equals collisions occurring because the UfsStatus object\ndoesn't compare the full path of the status, rather just the name\nof that index. We don't lose anything by indexing using the full path\nIt is also guaranteed to not have collisions. It is strictly better.", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "e7ffc1023ce8232b41bc0fe2ead8a1d3656041c8", "url": "https://github.com/Alluxio/alluxio/commit/e7ffc1023ce8232b41bc0fe2ead8a1d3656041c8", "message": "Address comments: UfsStatusCache", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "b8dcf2dbc9c4d1dd097f5c952e18151b6ea4e8fe", "url": "https://github.com/Alluxio/alluxio/commit/b8dcf2dbc9c4d1dd097f5c952e18151b6ea4e8fe", "message": "Address comments: InodeSyncStream", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "0b959cdfa525ba3af130652c4b174144e7f182ec", "url": "https://github.com/Alluxio/alluxio/commit/0b959cdfa525ba3af130652c4b174144e7f182ec", "message": "UfsSyncIntegrationTest passes\n\nFixed FSMasterRestartIT, UfsSyncIT, PinIT, ReadOnlyMountIT\n\nFix unit and integration tests", "committedDate": "2020-05-08T19:09:20Z", "type": "commit"}, {"oid": "ea2ade8c1f2cdf29df73c737177bcc6cac22e8f9", "url": "https://github.com/Alluxio/alluxio/commit/ea2ade8c1f2cdf29df73c737177bcc6cac22e8f9", "message": "Add UfsStatus Prefetch mechanism", "committedDate": "2020-05-08T19:09:12Z", "type": "commit"}, {"oid": "c0e5d3bf2c90233a4ad4f76381423f15766e1617", "url": "https://github.com/Alluxio/alluxio/commit/c0e5d3bf2c90233a4ad4f76381423f15766e1617", "message": "Rethrow InterruptedException on status cache fetch", "committedDate": "2020-05-08T19:09:12Z", "type": "forcePushed"}, {"oid": "26d6f0b37496604d66e68f19447cda6edbffd2e6", "url": "https://github.com/Alluxio/alluxio/commit/26d6f0b37496604d66e68f19447cda6edbffd2e6", "message": "Rethrow InterruptedException on status cache fetch", "committedDate": "2020-05-08T21:13:18Z", "type": "forcePushed"}, {"oid": "831e03cb111ae3191fdc52e82b131311e3038e59", "url": "https://github.com/Alluxio/alluxio/commit/831e03cb111ae3191fdc52e82b131311e3038e59", "message": "Improve logging for sync and profiling\n\nUtilized LogUtils.warnWithException to improve behavior of exception\nlogging.", "committedDate": "2020-05-08T21:36:09Z", "type": "commit"}, {"oid": "b032ccff3d816515b344ee16380a4aecf51f1123", "url": "https://github.com/Alluxio/alluxio/commit/b032ccff3d816515b344ee16380a4aecf51f1123", "message": "Improve UfsStatusCache\n\n- We always check for a prefetch job first before calling getChildren,\nbecause a subsequent prefetch on the same path would then never get\nremoved.\n- Added paths to some error log messages\n- Increased test coverage on the class to 90%", "committedDate": "2020-05-08T21:36:09Z", "type": "commit"}, {"oid": "44210c38347d506143a6322968513abf309802d4", "url": "https://github.com/Alluxio/alluxio/commit/44210c38347d506143a6322968513abf309802d4", "message": "Rethrow InterruptedException on status cache fetch", "committedDate": "2020-05-08T21:36:09Z", "type": "forcePushed"}, {"oid": "9ce6230d7814448bcda3d43142a84d0b26a6ff3c", "url": "https://github.com/Alluxio/alluxio/commit/9ce6230d7814448bcda3d43142a84d0b26a6ff3c", "message": "Rethrow InterruptedException on status cache fetch", "committedDate": "2020-05-08T21:39:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY5OTY2MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r421699661", "bodyText": "is there any value in reusing CacheBuilder from guava for this?", "author": "yuzhu", "createdAt": "2020-05-07T18:14:37Z", "path": "core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n+ * (the \"License\"). You may not use this work except in compliance with the License, which is\n+ * available at www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n+ * either express or implied, as more fully set forth in the License.\n+ *\n+ * See the NOTICE file distributed with this work for information regarding copyright ownership.\n+ */\n+\n+package alluxio.underfs;\n+\n+import alluxio.AlluxioURI;\n+import alluxio.collections.ConcurrentHashSet;\n+import alluxio.exception.InvalidPathException;\n+import alluxio.master.file.meta.MountTable;\n+import alluxio.resource.CloseableResource;\n+import alluxio.util.LogUtils;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+/**\n+ * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n+ * UFS statuses.\n+ *\n+ * It also allows associating a path with child inodes, so that the statuses for a specific path can\n+ * be searched for later.\n+ */\n+@ThreadSafe\n+public class UfsStatusCache {", "originalCommit": "d7b701e8535c863ae9c395a75668c6f2f9f88c38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE5NDczMA==", "url": "https://github.com/Alluxio/alluxio/pull/11204#discussion_r423194730", "bodyText": "I am not sure how much it would help. Do you know what the benefits are?\nMuch of the implementation is specialized for the usage of InodeSyncStream", "author": "ZacBlanco", "createdAt": "2020-05-11T17:17:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY5OTY2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "2d1a8fcb7a445a1ec8753b5e7a1f2d8d6abc8b4a", "chunk": "diff --git a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java b/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\ndeleted file mode 100644\nindex 5d590eabca..0000000000\n--- a/core/server/master/src/main/java/alluxio/underfs/UfsStatusCache.java\n+++ /dev/null\n\n@@ -1,282 +0,0 @@\n-/*\n- * The Alluxio Open Foundation licenses this work under the Apache License, version 2.0\n- * (the \"License\"). You may not use this work except in compliance with the License, which is\n- * available at www.apache.org/licenses/LICENSE-2.0\n- *\n- * This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\n- * either express or implied, as more fully set forth in the License.\n- *\n- * See the NOTICE file distributed with this work for information regarding copyright ownership.\n- */\n-\n-package alluxio.underfs;\n-\n-import alluxio.AlluxioURI;\n-import alluxio.collections.ConcurrentHashSet;\n-import alluxio.exception.InvalidPathException;\n-import alluxio.master.file.meta.MountTable;\n-import alluxio.resource.CloseableResource;\n-import alluxio.util.LogUtils;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import javax.annotation.Nullable;\n-import javax.annotation.concurrent.ThreadSafe;\n-import java.io.IOException;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.RejectedExecutionException;\n-\n-/**\n- * This class is a cache from an Alluxio namespace URI ({@link AlluxioURI}, i.e. /path/to/inode) to\n- * UFS statuses.\n- *\n- * It also allows associating a path with child inodes, so that the statuses for a specific path can\n- * be searched for later.\n- */\n-@ThreadSafe\n-public class UfsStatusCache {\n-  private static final Logger LOG = LoggerFactory.getLogger(UfsStatusCache.class);\n-\n-  private final ConcurrentHashMap<AlluxioURI, UfsStatus> mStatuses;\n-  private final ConcurrentHashMap<AlluxioURI, Future<Collection<UfsStatus>>> mActivePrefetchJobs;\n-  private final ConcurrentHashMap<AlluxioURI, Collection<UfsStatus>> mChildren;\n-  private final ExecutorService mPrefetchExecutor;\n-\n-  /**\n-   * Create a new instance of {@link UfsStatusCache}.\n-   *\n-   * @param prefetchExecutor the executor service used to prefetch statuses. If set to null, then\n-   *                         calls to {@link #prefetchChildren(AlluxioURI, MountTable)} will not\n-   *                         schedule any tasks.\n-   */\n-  public UfsStatusCache(@Nullable ExecutorService prefetchExecutor) {\n-    mStatuses = new ConcurrentHashMap<>();\n-    mChildren = new ConcurrentHashMap<>();\n-    mActivePrefetchJobs = new ConcurrentHashMap<>();\n-    mPrefetchExecutor = prefetchExecutor;\n-  }\n-\n-  /**\n-   * Add a new status to the cache.\n-   *\n-   * The last component of the path in the {@link AlluxioURI} must match the result of\n-   * {@link UfsStatus#getName()}. This method overrides any status currently cached for the same\n-   * URI.\n-   *\n-   * @param path the Alluxio path to key on\n-   * @param status the ufs status to store\n-   * @return the previous status for the path if it existed, null otherwise\n-   * @throws IllegalArgumentException if the status name doesn't match the final URI path component\n-   */\n-  @Nullable\n-  public UfsStatus addStatus(AlluxioURI path, UfsStatus status) {\n-    if (!path.getName().equals(status.getName())) {\n-      throw new IllegalArgumentException(\n-          String.format(\"path name %s does not match ufs status name %s\",\n-              path.getName(), status.getName()));\n-    }\n-    return mStatuses.put(path, status);\n-  }\n-\n-  /**\n-   * Add a parent-child mapping to the status cache.\n-   *\n-   * All child statuses added via this method will be available via {@link #getStatus(AlluxioURI)}.\n-   *\n-   * @param path the directory inode path which contains the children\n-   * @param children the children of the {@code path}\n-   * @return the previous set of children if the mapping existed, null otherwise\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> addChildren(AlluxioURI path, Collection<UfsStatus> children) {\n-    ConcurrentHashSet<UfsStatus> set = new ConcurrentHashSet<>();\n-    children.forEach(child -> {\n-      AlluxioURI childPath = path.joinUnsafe(child.getName());\n-      addStatus(childPath, child);\n-      set.add(child);\n-    });\n-    return mChildren.put(path, set);\n-  }\n-\n-  /**\n-   * Remove a status from the cache.\n-   *\n-   *  Any children added to this status will remain in the cache.\n-   *\n-   * @param path the path corresponding to the {@link UfsStatus} to remove\n-   * @return the removed UfsStatus\n-   */\n-  public UfsStatus remove(AlluxioURI path) {\n-    UfsStatus removed = mStatuses.remove(path);\n-    if (removed == null) {\n-      return null;\n-    }\n-\n-    mChildren.remove(path); // ok if there aren't any children\n-    return removed;\n-  }\n-\n-  /**\n-   * Get the UfsStatus from a given AlluxioURI.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  public UfsStatus getStatus(AlluxioURI path) {\n-    return mStatuses.get(path);\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path, stores them in the cache, then returns them.\n-   *\n-   * Children can be returned in a few ways\n-   * 1. Children already exist in the internal index. We simply return them\n-   * 2. If children did not already exist in the index, then check if there was a scheduled\n-   * prefetch job running for this path. If so, wait for the job to finish and return the result.\n-   * 3. If no prefetch job, and children don't yet exist in the cache, then if the fallback\n-   * parameter is true, fetch them from the UFS and store them in the cache. Otherwise, simply\n-   * return null.\n-   *\n-   * @param path the Alluxio path to get the children of\n-   * @param mountTable the Alluxio mount table\n-   * @param useFallback whether or not to fall back to calling the UFS\n-   * @return child UFS statuses of the alluxio path, or null if no prefetch job and fallback\n-   *         specified as false\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable,\n-      boolean useFallback)\n-      throws IOException, InvalidPathException {\n-    Future<Collection<UfsStatus>> prefetchJob = mActivePrefetchJobs.get(path);\n-    if (prefetchJob != null) {\n-      try {\n-        return prefetchJob.get();\n-      } catch (InterruptedException | ExecutionException e) {\n-        LogUtils.warnWithException(LOG, \"Failed to get result for prefetch job on alluxio path {}\",\n-            path, e);\n-        if (e instanceof InterruptedException) {\n-          Thread.currentThread().interrupt();\n-        }\n-        throw new IOException(e);\n-      } finally {\n-        mActivePrefetchJobs.remove(path);\n-      }\n-    }\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-\n-    if (useFallback) {\n-      return getChildrenIfAbsent(path, mountTable);\n-    }\n-    return null;\n-  }\n-\n-  /**\n-   * Fetches children of a given alluxio path stores them in the cache, then returns them.\n-   *\n-   * Will always return statuses from the UFS whether or not they exist in the cache, and whether\n-   * a prefetch job was scheduled or not.\n-   *\n-   * @param path the Alluxio path\n-   * @param mountTable the Alluxio mount table\n-   * @return child UFS statuses of the alluxio path\n-   * @throws InvalidPathException if the alluxio path can't be resolved to a UFS mount\n-   */\n-  public Collection<UfsStatus> fetchChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws IOException, InvalidPathException {\n-    return fetchChildrenIfAbsent(path, mountTable, true);\n-  }\n-\n-  /**\n-   * Retrieves the child UFS statuses for a given path and stores them in the cache.\n-   *\n-   * This method first checks if the children have already been retrieved, and if not, then\n-   * retrieves them.\n-\n-   * @param path the path to get the children for\n-   * @param mountTable the Alluxio mount table\n-   * @return the child statuses that were stored in the cache, or null if the UFS couldn't list the\n-   *         statuses\n-   * @throws InvalidPathException when the table can't resolve the mount for the given URI\n-   */\n-  @Nullable\n-  private Collection<UfsStatus> getChildrenIfAbsent(AlluxioURI path, MountTable mountTable)\n-      throws InvalidPathException {\n-    Collection<UfsStatus> children = getChildren(path);\n-    if (children != null) {\n-      return children;\n-    }\n-    MountTable.Resolution resolution = mountTable.resolve(path);\n-    AlluxioURI ufsUri = resolution.getUri();\n-    try (CloseableResource<UnderFileSystem> ufsResource = resolution.acquireUfsResource()) {\n-      UnderFileSystem ufs = ufsResource.get();\n-      UfsStatus[] statuses = ufs.listStatus(ufsUri.toString());\n-      if (statuses == null) {\n-        return null;\n-      }\n-      children = Arrays.asList(statuses);\n-      addChildren(path, children);\n-    } catch (IllegalArgumentException | IOException e) {\n-      LOG.debug(\"Failed to add status to cache {}\", path, e);\n-    }\n-    return children;\n-  }\n-\n-  /**\n-   * Get the child {@link UfsStatus}es from a given {@link AlluxioURI}.\n-   *\n-   * @param path the path the retrieve\n-   * @return The corresponding {@link UfsStatus} or {@code null} if there is none stored\n-   */\n-  @Nullable\n-  public Collection<UfsStatus> getChildren(AlluxioURI path) {\n-    return mChildren.get(path);\n-  }\n-\n-  /**\n-   * Submit a request to asynchronously fetch the statuses corresponding to a given directory.\n-   *\n-   * Retrieve any fetched statuses by calling {@link #fetchChildrenIfAbsent(AlluxioURI, MountTable)}\n-   * with the same Alluxio path.\n-   *\n-   * If no {@link ExecutorService} was provided to this object before instantiation, this method is\n-   * a no-op.\n-   *\n-   * @param path the path to prefetch\n-   * @param mountTable the Alluxio mount table\n-   */\n-  public void prefetchChildren(AlluxioURI path, MountTable mountTable) {\n-    if (mPrefetchExecutor == null) {\n-      return;\n-    }\n-    try {\n-      Future<Collection<UfsStatus>> job =\n-          mPrefetchExecutor.submit(() -> getChildrenIfAbsent(path, mountTable));\n-      Future<Collection<UfsStatus>> prev = mActivePrefetchJobs.put(path, job);\n-      if (prev != null) {\n-        prev.cancel(true);\n-      }\n-    } catch (RejectedExecutionException e) {\n-      LOG.debug(\"Failed to submit prefetch job for path {}\", path, e);\n-    }\n-  }\n-\n-  /**\n-   * Interrupts and cancels any currently running prefetch jobs.\n-   */\n-  public void cancelAllPrefetch() {\n-    for (Future<?> f : mActivePrefetchJobs.values()) {\n-      f.cancel(false);\n-    }\n-    mActivePrefetchJobs.clear();\n-  }\n-}\n"}}, {"oid": "f5bf2dbaf1db2175a8ff8ca1506aa77555cd47e8", "url": "https://github.com/Alluxio/alluxio/commit/f5bf2dbaf1db2175a8ff8ca1506aa77555cd47e8", "message": "Rethrow InterruptedException on status cache fetch", "committedDate": "2020-05-11T16:40:09Z", "type": "commit"}, {"oid": "f5bf2dbaf1db2175a8ff8ca1506aa77555cd47e8", "url": "https://github.com/Alluxio/alluxio/commit/f5bf2dbaf1db2175a8ff8ca1506aa77555cd47e8", "message": "Rethrow InterruptedException on status cache fetch", "committedDate": "2020-05-11T16:40:09Z", "type": "forcePushed"}, {"oid": "681f9317b17a1bbf457807d2b1a2f24526ea6829", "url": "https://github.com/Alluxio/alluxio/commit/681f9317b17a1bbf457807d2b1a2f24526ea6829", "message": "Fix UfsStatusCache removal, add tests", "committedDate": "2020-05-11T20:53:32Z", "type": "commit"}]}