{"pr_number": 4863, "pr_title": "Issue 4830: Lazily instantiate Auto Scale Processor's writer ", "pr_createdAt": "2020-06-10T11:50:44Z", "pr_url": "https://github.com/pravega/pravega/pull/4863", "timeline": [{"oid": "79b49938d4dbdbda2774c5ca0ee885b578a5b3c9", "url": "https://github.com/pravega/pravega/commit/79b49938d4dbdbda2774c5ca0ee885b578a5b3c9", "message": "issue4830\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-10T11:24:23Z", "type": "commit"}, {"oid": "eb333689a27f885ea0aa3b63a6d8de9e2a2a3b0e", "url": "https://github.com/pravega/pravega/commit/eb333689a27f885ea0aa3b63a6d8de9e2a2a3b0e", "message": "Merge branch 'master' into issu4830", "committedDate": "2020-06-10T11:25:47Z", "type": "commit"}, {"oid": "3c708f84df7a66dd3d756a1270147a1b3840dde9", "url": "https://github.com/pravega/pravega/commit/3c708f84df7a66dd3d756a1270147a1b3840dde9", "message": "checkstyle\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-10T15:32:23Z", "type": "commit"}, {"oid": "3c708f84df7a66dd3d756a1270147a1b3840dde9", "url": "https://github.com/pravega/pravega/commit/3c708f84df7a66dd3d756a1270147a1b3840dde9", "message": "checkstyle\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-10T15:32:23Z", "type": "forcePushed"}, {"oid": "c9bf54b0774d260814336531fecadb53ca0a21ad", "url": "https://github.com/pravega/pravega/commit/c9bf54b0774d260814336531fecadb53ca0a21ad", "message": "spotbug static inner class\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-11T01:58:13Z", "type": "commit"}, {"oid": "c9bf54b0774d260814336531fecadb53ca0a21ad", "url": "https://github.com/pravega/pravega/commit/c9bf54b0774d260814336531fecadb53ca0a21ad", "message": "spotbug static inner class\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-11T01:58:13Z", "type": "forcePushed"}, {"oid": "2025f3c22dea3a605b1ed613731a51793220dc6d", "url": "https://github.com/pravega/pravega/commit/2025f3c22dea3a605b1ed613731a51793220dc6d", "message": "Merge branch 'master' into issu4830", "committedDate": "2020-06-11T04:27:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODU0Njc2Nw==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r438546767", "bodyText": "we can use io.pravega.common.concurrent.Futures#isSuccessful here.", "author": "shrids", "createdAt": "2020-06-11T05:14:38Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java", "diffHunk": "@@ -116,48 +122,51 @@\n                 }, executor))\n                 .build();\n \n+        this.executor = executor;\n+        \n         // Even if there is no activity, keep cleaning up the cache so that scale down can be triggered.\n         // caches do not perform clean up if there is no activity. This is because they do not maintain their\n         // own background thread.\n         this.cacheCleanup = executor.scheduleAtFixedRate(cache::cleanUp, 0, configuration.getCacheCleanup().getSeconds(), TimeUnit.SECONDS);\n-        if (clientFactory != null) {\n-            bootstrapRequestWriters(clientFactory, executor);\n-        }\n     }\n \n     @Override\n+    @Synchronized\n     public void close() {\n-        val w = this.writer.get();\n-        if (w != null) {\n-            w.close();\n-            this.writer.set(null);\n+        if (writer != null) {\n+            writer.cancel(true);\n+\n+            if (!writer.isCancelled() && !writer.isCompletedExceptionally()) {", "originalCommit": "2025f3c22dea3a605b1ed613731a51793220dc6d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "af960a6045dba78ecda743c2d5e6f07ab960c520", "chunk": "diff --git a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\nindex 35aa3c9a4..a634e6c5e 100644\n--- a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n+++ b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n\n@@ -136,7 +137,7 @@ public class AutoScaleProcessor implements AutoCloseable {\n         if (writer != null) {\n             writer.cancel(true);\n \n-            if (!writer.isCancelled() && !writer.isCompletedExceptionally()) {\n+            if (Futures.isSuccessful(writer)) {\n                 val w = this.writer.join();\n                 if (w != null) {\n                     w.close();\n"}}, {"oid": "af960a6045dba78ecda743c2d5e6f07ab960c520", "url": "https://github.com/pravega/pravega/commit/af960a6045dba78ecda743c2d5e6f07ab960c520", "message": "PR comment\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-11T09:00:19Z", "type": "commit"}, {"oid": "5cd178ff71d528c4c10b2edaac5c36915f9ee84d", "url": "https://github.com/pravega/pravega/commit/5cd178ff71d528c4c10b2edaac5c36915f9ee84d", "message": "Merge branch 'issu4830' of https://github.com/shiveshr/pravega-1 into issu4830", "committedDate": "2020-06-11T09:00:53Z", "type": "commit"}, {"oid": "ff35c5143598fefba2769f8a29246e7e658e1770", "url": "https://github.com/pravega/pravega/commit/ff35c5143598fefba2769f8a29246e7e658e1770", "message": "illegal char\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-11T09:49:36Z", "type": "commit"}, {"oid": "ff95784ab8bfb420a484fceb60b28f2236b3f4c1", "url": "https://github.com/pravega/pravega/commit/ff95784ab8bfb420a484fceb60b28f2236b3f4c1", "message": "Merge branch 'issu4830' of https://github.com/shiveshr/pravega-1 into issu4830", "committedDate": "2020-06-11T09:49:58Z", "type": "commit"}, {"oid": "039847398915fd9278c3d5c8cbf6adeff7ee4834", "url": "https://github.com/pravega/pravega/commit/039847398915fd9278c3d5c8cbf6adeff7ee4834", "message": "coverage\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-11T13:13:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkyMDg5OQ==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r438920899", "bodyText": "Non-final fields make it look like something's not right. Let's see if we can make this better. Would this work?\n\nMake this final and remove the \"GuardedBy\"\nIn the getWriter method, do exactly what you're doing, but when the retry loop is done, set the result on this future, whether it be the writer or an exception. You can use Futures.completeAfter (I may forget the actual name).\n\nThis way we don't need a new lock and we can make this field final. CompletableFuture internally is thread safe so it takes care of any concurrency issues for us.", "author": "andreipaduroiu", "createdAt": "2020-06-11T16:35:39Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java", "diffHunk": "@@ -61,10 +66,12 @@\n \n     private final EventStreamClientFactory clientFactory;\n     private final Cache<String, Pair<Long, Long>> cache;\n-    private final AtomicReference<EventStreamWriter<AutoScaleEvent>> writer;\n+    @GuardedBy(\"$lock\")\n+    private CompletableFuture<EventStreamWriter<AutoScaleEvent>> writer;", "originalCommit": "039847398915fd9278c3d5c8cbf6adeff7ee4834", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTIwMDI3OQ==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r439200279", "bodyText": "We can avoid non final writer. But the objective is to make the bootstrap of writer be triggered exactly once which will eventually complete the future.\nIn existing code, the bootstrap was being invoked from the constructor.\nBut now we want to do it lazily, upon first request. But there could be multiple concurrent requests.\nSo we need some syncrhonization to make sure exactly one of them end up attempting to create a writer.\nSo syncrhonization is really for that. And instead of using a non-final boolean which is synchronized (or atomic boolean) i had chosen to do with writerFuture = null.\nI have an alternate idea though -- which would still require using atomic boolean.. let me make and push that change and see if that is better.", "author": "shiveshr", "createdAt": "2020-06-12T04:27:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkyMDg5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "85e8405e5fe2c591291190991adb81e592028f5e", "chunk": "diff --git a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\nindex 05e05f736..4b6f57f17 100644\n--- a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n+++ b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n\n@@ -66,12 +64,11 @@ public class AutoScaleProcessor implements AutoCloseable {\n \n     private final EventStreamClientFactory clientFactory;\n     private final Cache<String, Pair<Long, Long>> cache;\n-    @GuardedBy(\"$lock\")\n-    private CompletableFuture<EventStreamWriter<AutoScaleEvent>> writer;\n+    private final CompletableFuture<EventStreamWriter<AutoScaleEvent>> writer;\n+    private final AtomicBoolean startInitWriter;\n     private final AutoScalerConfig configuration;\n     private final Supplier<Long> requestIdGenerator = RandomFactory.create()::nextLong;\n     private final ScheduledFuture<?> cacheCleanup;\n-    private final ScheduledExecutorService executor;\n \n     /**\n      * Creates a new instance of the {@link AutoScaleProcessor} class. This sets up its own {@link EventStreamClientFactory}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkyMTQwMQ==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r438921401", "bodyText": "Writer should always be non-null.", "author": "andreipaduroiu", "createdAt": "2020-06-11T16:36:28Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java", "diffHunk": "@@ -116,48 +123,51 @@\n                 }, executor))\n                 .build();\n \n+        this.executor = executor;\n+        \n         // Even if there is no activity, keep cleaning up the cache so that scale down can be triggered.\n         // caches do not perform clean up if there is no activity. This is because they do not maintain their\n         // own background thread.\n         this.cacheCleanup = executor.scheduleAtFixedRate(cache::cleanUp, 0, configuration.getCacheCleanup().getSeconds(), TimeUnit.SECONDS);\n-        if (clientFactory != null) {\n-            bootstrapRequestWriters(clientFactory, executor);\n-        }\n     }\n \n     @Override\n+    @Synchronized\n     public void close() {\n-        val w = this.writer.get();\n-        if (w != null) {\n-            w.close();\n-            this.writer.set(null);\n+        if (writer != null) {", "originalCommit": "039847398915fd9278c3d5c8cbf6adeff7ee4834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "85e8405e5fe2c591291190991adb81e592028f5e", "chunk": "diff --git a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\nindex 05e05f736..4b6f57f17 100644\n--- a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n+++ b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n\n@@ -123,51 +120,57 @@ public class AutoScaleProcessor implements AutoCloseable {\n                 }, executor))\n                 .build();\n \n-        this.executor = executor;\n-        \n         // Even if there is no activity, keep cleaning up the cache so that scale down can be triggered.\n         // caches do not perform clean up if there is no activity. This is because they do not maintain their\n         // own background thread.\n         this.cacheCleanup = executor.scheduleAtFixedRate(cache::cleanUp, 0, configuration.getCacheCleanup().getSeconds(), TimeUnit.SECONDS);\n+        if (clientFactory != null) {\n+            bootstrapRequestWriters(clientFactory, executor);\n+        }\n     }\n \n     @Override\n-    @Synchronized\n     public void close() {\n-        if (writer != null) {\n-            writer.cancel(true);\n+        writer.cancel(true);\n \n-            if (Futures.isSuccessful(writer)) {\n-                val w = this.writer.join();\n-                if (w != null) {\n-                    w.close();\n-                }\n+        if (Futures.isSuccessful(writer)) {\n+            val w = this.writer.join();\n+            if (w != null) {\n+                w.close();\n             }\n         }\n \n-        this.clientFactory.close();\n+        if (clientFactory != null) {\n+            this.clientFactory.close();\n+        }\n         this.cacheCleanup.cancel(true);\n     }\n+    \n+    private void bootstrapRequestWriters(EventStreamClientFactory clientFactory, ScheduledExecutorService executor) {\n+        AtomicReference<EventStreamWriter<AutoScaleEvent>> w = new AtomicReference<>();\n \n-    @Synchronized\n-    private CompletableFuture<EventStreamWriter<AutoScaleEvent>> getWriter() {\n-        if (writer == null) {\n-            AtomicReference<EventStreamWriter<AutoScaleEvent>> w = new AtomicReference<>();\n-            EventWriterConfig writerConfig = EventWriterConfig.builder().build();\n-            writer = Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n-                        .runInExecutor(() -> {\n-                            w.set(clientFactory.createEventWriter(configuration.getInternalRequestStream(), SERIALIZER, writerConfig));\n-                            log.info(\"AutoScale Processor Initialized. RequestStream={}\", configuration.getInternalRequestStream());\n-                        }, executor)\n-                        .thenApply(v -> w.get());\n-        }\n-        return writer;\n+        Futures.completeAfter(() -> Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n+                                         .runInExecutor(() -> bootstrapOnce(clientFactory, w), \n+                                                 executor).thenApply(v -> w.get()), writer);\n     }\n \n     private void handleBootstrapException(Throwable e) {\n         log.warn(\"Unable to create writer for requeststream: {}.\", LoggerHelpers.exceptionSummary(log, e));\n     }\n \n+    private void bootstrapOnce(EventStreamClientFactory clientFactory, AtomicReference<EventStreamWriter<AutoScaleEvent>> writerRef) {\n+        if (!writer.isDone()) {\n+            if (!startInitWriter.get()) {\n+                throw new RuntimeException(\"Init not requested\");\n+            }\n+            EventWriterConfig writerConfig = EventWriterConfig.builder().build();\n+            writerRef.set(clientFactory.createEventWriter(configuration.getInternalRequestStream(),\n+                    SERIALIZER, writerConfig));\n+            log.info(\"AutoScale Processor Initialized. RequestStream={}\",\n+                    configuration.getInternalRequestStream());\n+        }\n+    }\n+\n     private static EventStreamClientFactory createFactory(AutoScalerConfig configuration) {\n         return EventStreamClientFactory.withScope(NameUtils.INTERNAL_SCOPE_NAME, prepareClientConfig(configuration));\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkyMjI1OQ==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r438922259", "bodyText": "This indefinite retry won't work well in case we fail to bootstrap and we decide to shut down. It will likely leave this running forever. You should include a condition that can cancel it. My recommendation would be to check this.writer.isDone (it will be true when either a writer has been set or when it got completed with an exception).", "author": "andreipaduroiu", "createdAt": "2020-06-11T16:37:55Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java", "diffHunk": "@@ -116,48 +123,51 @@\n                 }, executor))\n                 .build();\n \n+        this.executor = executor;\n+        \n         // Even if there is no activity, keep cleaning up the cache so that scale down can be triggered.\n         // caches do not perform clean up if there is no activity. This is because they do not maintain their\n         // own background thread.\n         this.cacheCleanup = executor.scheduleAtFixedRate(cache::cleanUp, 0, configuration.getCacheCleanup().getSeconds(), TimeUnit.SECONDS);\n-        if (clientFactory != null) {\n-            bootstrapRequestWriters(clientFactory, executor);\n-        }\n     }\n \n     @Override\n+    @Synchronized\n     public void close() {\n-        val w = this.writer.get();\n-        if (w != null) {\n-            w.close();\n-            this.writer.set(null);\n+        if (writer != null) {\n+            writer.cancel(true);\n+\n+            if (Futures.isSuccessful(writer)) {\n+                val w = this.writer.join();\n+                if (w != null) {\n+                    w.close();\n+                }\n+            }\n         }\n \n         this.clientFactory.close();\n         this.cacheCleanup.cancel(true);\n     }\n \n-    private void bootstrapRequestWriters(EventStreamClientFactory clientFactory, ScheduledExecutorService executor) {\n-        // Starting with initial delay, in case request stream has not been created, to give it time to start\n-        // However, we have this wrapped in consumeFailure which means the creation of writer will be retried.\n-        // We are introducing a delay to avoid exceptions in the log in case creation of writer is attempted before\n-        // creation of requeststream.\n-        executor.schedule(\n-                () -> Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n-                        .runInExecutor(() -> bootstrapOnce(clientFactory), executor),\n-                10, TimeUnit.SECONDS);\n+    @Synchronized\n+    private CompletableFuture<EventStreamWriter<AutoScaleEvent>> getWriter() {\n+        if (writer == null) {\n+            AtomicReference<EventStreamWriter<AutoScaleEvent>> w = new AtomicReference<>();\n+            EventWriterConfig writerConfig = EventWriterConfig.builder().build();\n+            writer = Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)", "originalCommit": "039847398915fd9278c3d5c8cbf6adeff7ee4834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "85e8405e5fe2c591291190991adb81e592028f5e", "chunk": "diff --git a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\nindex 05e05f736..4b6f57f17 100644\n--- a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n+++ b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n\n@@ -123,51 +120,57 @@ public class AutoScaleProcessor implements AutoCloseable {\n                 }, executor))\n                 .build();\n \n-        this.executor = executor;\n-        \n         // Even if there is no activity, keep cleaning up the cache so that scale down can be triggered.\n         // caches do not perform clean up if there is no activity. This is because they do not maintain their\n         // own background thread.\n         this.cacheCleanup = executor.scheduleAtFixedRate(cache::cleanUp, 0, configuration.getCacheCleanup().getSeconds(), TimeUnit.SECONDS);\n+        if (clientFactory != null) {\n+            bootstrapRequestWriters(clientFactory, executor);\n+        }\n     }\n \n     @Override\n-    @Synchronized\n     public void close() {\n-        if (writer != null) {\n-            writer.cancel(true);\n+        writer.cancel(true);\n \n-            if (Futures.isSuccessful(writer)) {\n-                val w = this.writer.join();\n-                if (w != null) {\n-                    w.close();\n-                }\n+        if (Futures.isSuccessful(writer)) {\n+            val w = this.writer.join();\n+            if (w != null) {\n+                w.close();\n             }\n         }\n \n-        this.clientFactory.close();\n+        if (clientFactory != null) {\n+            this.clientFactory.close();\n+        }\n         this.cacheCleanup.cancel(true);\n     }\n+    \n+    private void bootstrapRequestWriters(EventStreamClientFactory clientFactory, ScheduledExecutorService executor) {\n+        AtomicReference<EventStreamWriter<AutoScaleEvent>> w = new AtomicReference<>();\n \n-    @Synchronized\n-    private CompletableFuture<EventStreamWriter<AutoScaleEvent>> getWriter() {\n-        if (writer == null) {\n-            AtomicReference<EventStreamWriter<AutoScaleEvent>> w = new AtomicReference<>();\n-            EventWriterConfig writerConfig = EventWriterConfig.builder().build();\n-            writer = Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n-                        .runInExecutor(() -> {\n-                            w.set(clientFactory.createEventWriter(configuration.getInternalRequestStream(), SERIALIZER, writerConfig));\n-                            log.info(\"AutoScale Processor Initialized. RequestStream={}\", configuration.getInternalRequestStream());\n-                        }, executor)\n-                        .thenApply(v -> w.get());\n-        }\n-        return writer;\n+        Futures.completeAfter(() -> Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n+                                         .runInExecutor(() -> bootstrapOnce(clientFactory, w), \n+                                                 executor).thenApply(v -> w.get()), writer);\n     }\n \n     private void handleBootstrapException(Throwable e) {\n         log.warn(\"Unable to create writer for requeststream: {}.\", LoggerHelpers.exceptionSummary(log, e));\n     }\n \n+    private void bootstrapOnce(EventStreamClientFactory clientFactory, AtomicReference<EventStreamWriter<AutoScaleEvent>> writerRef) {\n+        if (!writer.isDone()) {\n+            if (!startInitWriter.get()) {\n+                throw new RuntimeException(\"Init not requested\");\n+            }\n+            EventWriterConfig writerConfig = EventWriterConfig.builder().build();\n+            writerRef.set(clientFactory.createEventWriter(configuration.getInternalRequestStream(),\n+                    SERIALIZER, writerConfig));\n+            log.info(\"AutoScale Processor Initialized. RequestStream={}\",\n+                    configuration.getInternalRequestStream());\n+        }\n+    }\n+\n     private static EventStreamClientFactory createFactory(AutoScalerConfig configuration) {\n         return EventStreamClientFactory.withScope(NameUtils.INTERNAL_SCOPE_NAME, prepareClientConfig(configuration));\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODkyMjg2Mw==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r438922863", "bodyText": "Please revert this. This will result in too much garbage in the segment store logs.", "author": "andreipaduroiu", "createdAt": "2020-06-11T16:38:54Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java", "diffHunk": "@@ -192,113 +202,99 @@ static boolean hasTlsEnabled(@NonNull final URI controllerURI) {\n         return uriScheme.equals(\"tls\") || uriScheme.equals(\"pravegas\");\n     }\n \n-    private boolean isInitialized() {\n-        return this.writer.get() != null;\n-    }\n-\n     private void triggerScaleUp(String streamSegmentName, int numOfSplits) {\n-        if (isInitialized()) {\n-            Pair<Long, Long> pair = cache.getIfPresent(streamSegmentName);\n-            long lastRequestTs = 0;\n+        Pair<Long, Long> pair = cache.getIfPresent(streamSegmentName);\n+        long lastRequestTs = 0;\n \n-            if (pair != null && pair.getKey() != null) {\n-                lastRequestTs = pair.getKey();\n-            }\n+        if (pair != null && pair.getKey() != null) {\n+            lastRequestTs = pair.getKey();\n+        }\n \n-            long timestamp = System.currentTimeMillis();\n-            long requestId = requestIdGenerator.get();\n-            if (timestamp - lastRequestTs > configuration.getMuteDuration().toMillis()) {\n-                log.info(requestId, \"sending request for scale up for {}\", streamSegmentName);\n+        long timestamp = getTimeMillis();\n+        long requestId = requestIdGenerator.get();\n+        if (timestamp - lastRequestTs > configuration.getMuteDuration().toMillis()) {\n+            log.info(requestId, \"sending request for scale up for {}\", streamSegmentName);\n \n-                Segment segment = Segment.fromScopedName(streamSegmentName);\n-                AutoScaleEvent event = new AutoScaleEvent(segment.getScope(), segment.getStreamName(), segment.getSegmentId(),\n-                        AutoScaleEvent.UP, timestamp, numOfSplits, false, requestId);\n-                // Mute scale for timestamp for both scale up and down\n-                writeRequest(event, () -> cache.put(streamSegmentName, new ImmutablePair<>(timestamp, timestamp)));\n-            }\n+            Segment segment = Segment.fromScopedName(streamSegmentName);\n+            AutoScaleEvent event = new AutoScaleEvent(segment.getScope(), segment.getStreamName(), segment.getSegmentId(),\n+                    AutoScaleEvent.UP, timestamp, numOfSplits, false, requestId);\n+            // Mute scale for timestamp for both scale up and down\n+            writeRequest(event, () -> cache.put(streamSegmentName, new ImmutablePair<>(timestamp, timestamp)));\n         }\n     }\n \n     private void triggerScaleDown(String streamSegmentName, boolean silent) {\n-        if (isInitialized()) {\n-            Pair<Long, Long> pair = cache.getIfPresent(streamSegmentName);\n-            long lastRequestTs = 0;\n+        Pair<Long, Long> pair = cache.getIfPresent(streamSegmentName);\n+        long lastRequestTs = 0;\n \n-            if (pair != null && pair.getValue() != null) {\n-                lastRequestTs = pair.getValue();\n-            }\n+        if (pair != null && pair.getValue() != null) {\n+            lastRequestTs = pair.getValue();\n+        }\n \n-            long timestamp = System.currentTimeMillis();\n-            long requestId = requestIdGenerator.get();\n-            if (timestamp - lastRequestTs > configuration.getMuteDuration().toMillis()) {\n-                log.info(requestId, \"sending request for scale down for {}\", streamSegmentName);\n-\n-                Segment segment = Segment.fromScopedName(streamSegmentName);\n-                AutoScaleEvent event = new AutoScaleEvent(segment.getScope(), segment.getStreamName(), segment.getSegmentId(),\n-                        AutoScaleEvent.DOWN, timestamp, 0, silent, requestId);\n-                writeRequest(event, () -> {\n-                    if (!silent) {\n-                        // mute only scale downs\n-                        cache.put(streamSegmentName, new ImmutablePair<>(0L, timestamp));\n-                    }\n-                });\n-            }\n+        long timestamp = getTimeMillis();\n+        long requestId = requestIdGenerator.get();\n+        if (timestamp - lastRequestTs > configuration.getMuteDuration().toMillis()) {\n+            log.info(requestId, \"sending request for scale down for {}\", streamSegmentName);\n+\n+            Segment segment = Segment.fromScopedName(streamSegmentName);\n+            AutoScaleEvent event = new AutoScaleEvent(segment.getScope(), segment.getStreamName(), segment.getSegmentId(),\n+                    AutoScaleEvent.DOWN, timestamp, 0, silent, requestId);\n+            writeRequest(event, () -> {\n+                if (!silent) {\n+                    // mute only scale downs\n+                    cache.put(streamSegmentName, new ImmutablePair<>(0L, timestamp));\n+                }\n+            });\n         }\n     }\n \n     private void writeRequest(AutoScaleEvent event, Runnable successCallback) {\n-        val writer = this.writer.get();\n-        if (writer == null) {\n-            log.warn(event.getRequestId(), \"Writer not bootstrapped; unable to post Scale Event {}.\", event);\n-        } else {\n-            writer.writeEvent(event.getKey(), event)\n+        getWriter().thenCompose(w -> w.writeEvent(event.getKey(), event)\n                     .whenComplete((r, e) -> {\n                         if (e != null) {\n                             log.error(event.getRequestId(), \"Unable to post Scale Event to RequestStream '{}'.\",\n                                     this.configuration.getInternalRequestStream(), e);\n                         } else {\n-                            log.debug(event.getRequestId(), \"Scale Event posted successfully: {}.\", event);\n+                            log.info(event.getRequestId(), \"Scale Event posted successfully: {}.\", event);", "originalCommit": "039847398915fd9278c3d5c8cbf6adeff7ee4834", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "85e8405e5fe2c591291190991adb81e592028f5e", "chunk": "diff --git a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\nindex 05e05f736..4b6f57f17 100644\n--- a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n+++ b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n\n@@ -249,13 +252,14 @@ public class AutoScaleProcessor implements AutoCloseable {\n     }\n \n     private void writeRequest(AutoScaleEvent event, Runnable successCallback) {\n-        getWriter().thenCompose(w -> w.writeEvent(event.getKey(), event)\n+        startInitWriter.set(true);\n+        writer.thenCompose(w -> w.writeEvent(event.getKey(), event)\n                     .whenComplete((r, e) -> {\n                         if (e != null) {\n                             log.error(event.getRequestId(), \"Unable to post Scale Event to RequestStream '{}'.\",\n                                     this.configuration.getInternalRequestStream(), e);\n                         } else {\n-                            log.info(event.getRequestId(), \"Scale Event posted successfully: {}.\", event);\n+                            log.debug(event.getRequestId(), \"Scale Event posted successfully: {}.\", event);\n                             successCallback.run();\n                         }\n                     }));\n"}}, {"oid": "85e8405e5fe2c591291190991adb81e592028f5e", "url": "https://github.com/pravega/pravega/commit/85e8405e5fe2c591291190991adb81e592028f5e", "message": "PR comments\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-12T07:02:12Z", "type": "commit"}, {"oid": "3a901ef2f428b7984db5b358b4a0463d2f77ed48", "url": "https://github.com/pravega/pravega/commit/3a901ef2f428b7984db5b358b4a0463d2f77ed48", "message": "code coverage\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-12T10:33:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTkxNzk1NQ==", "url": "https://github.com/pravega/pravega/pull/4863#discussion_r439917955", "bodyText": "If startInitWriter is false then we would be logging this line repeatedly.\nThis would clutter the logs with WARN messages. (including standalone) Can we avoid it?", "author": "shrids", "createdAt": "2020-06-15T03:52:43Z", "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java", "diffHunk": "@@ -127,35 +131,44 @@\n \n     @Override\n     public void close() {\n-        val w = this.writer.get();\n-        if (w != null) {\n-            w.close();\n-            this.writer.set(null);\n+        writer.cancel(true);\n+\n+        if (Futures.isSuccessful(writer)) {\n+            val w = this.writer.join();\n+            if (w != null) {\n+                w.close();\n+            }\n         }\n \n-        this.clientFactory.close();\n+        if (clientFactory != null) {\n+            this.clientFactory.close();\n+        }\n         this.cacheCleanup.cancel(true);\n     }\n-\n+    \n     private void bootstrapRequestWriters(EventStreamClientFactory clientFactory, ScheduledExecutorService executor) {\n-        // Starting with initial delay, in case request stream has not been created, to give it time to start\n-        // However, we have this wrapped in consumeFailure which means the creation of writer will be retried.\n-        // We are introducing a delay to avoid exceptions in the log in case creation of writer is attempted before\n-        // creation of requeststream.\n-        executor.schedule(\n-                () -> Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n-                        .runInExecutor(() -> bootstrapOnce(clientFactory), executor),\n-                10, TimeUnit.SECONDS);\n+        AtomicReference<EventStreamWriter<AutoScaleEvent>> w = new AtomicReference<>();\n+\n+        Futures.completeAfter(() -> Retry.indefinitelyWithExpBackoff(100, 10, 10000, this::handleBootstrapException)\n+                                         .runInExecutor(() -> bootstrapOnce(clientFactory, w), \n+                                                 executor).thenApply(v -> w.get()), writer);\n     }\n \n     private void handleBootstrapException(Throwable e) {\n         log.warn(\"Unable to create writer for requeststream: {}.\", LoggerHelpers.exceptionSummary(log, e));", "originalCommit": "3a901ef2f428b7984db5b358b4a0463d2f77ed48", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5d42674d3064d2cb0abea06c73516b93a025537f", "chunk": "diff --git a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\nindex 4b6f57f17..ca7d9664d 100644\n--- a/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n+++ b/segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/stat/AutoScaleProcessor.java\n\n@@ -155,7 +155,9 @@ public class AutoScaleProcessor implements AutoCloseable {\n     }\n \n     private void handleBootstrapException(Throwable e) {\n-        log.warn(\"Unable to create writer for requeststream: {}.\", LoggerHelpers.exceptionSummary(log, e));\n+        if (startInitWriter.get()) {\n+            log.warn(\"Unable to create writer for requeststream: {}.\", LoggerHelpers.exceptionSummary(log, e));\n+        }\n     }\n \n     private void bootstrapOnce(EventStreamClientFactory clientFactory, AtomicReference<EventStreamWriter<AutoScaleEvent>> writerRef) {\n"}}, {"oid": "5d42674d3064d2cb0abea06c73516b93a025537f", "url": "https://github.com/pravega/pravega/commit/5d42674d3064d2cb0abea06c73516b93a025537f", "message": "PR comment\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-15T04:54:08Z", "type": "commit"}, {"oid": "a6346c5d76d49895d57e8d1690f6254c076dc342", "url": "https://github.com/pravega/pravega/commit/a6346c5d76d49895d57e8d1690f6254c076dc342", "message": "coverage\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>", "committedDate": "2020-06-15T11:30:25Z", "type": "commit"}, {"oid": "a93cb24a8160610305612fad8843587c9d98d230", "url": "https://github.com/pravega/pravega/commit/a93cb24a8160610305612fad8843587c9d98d230", "message": "Merge branch 'master' into issu4830", "committedDate": "2020-06-15T23:51:17Z", "type": "commit"}]}