{"pr_number": 4716, "pr_title": "Issue 4670: SegmentContainer in recovery mode", "pr_createdAt": "2020-04-21T18:20:10Z", "pr_url": "https://github.com/pravega/pravega/pull/4716", "timeline": [{"oid": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "url": "https://github.com/pravega/pravega/commit/3387f5b297c471c3a19a00bfc8615bad363b59f6", "message": "Small changes.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-05T00:20:55Z", "type": "commit"}, {"oid": "c05a63a0c5e5863c603b08af1cf6e3dcd4c88766", "url": "https://github.com/pravega/pravega/commit/c05a63a0c5e5863c603b08af1cf6e3dcd4c88766", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-05T05:10:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5NTM1OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465995359", "bodyText": "Is it possible to define this method as empty block in the base class itself so that we don't have to keep overriding in derived classes?", "author": "sachin-j-joshi", "createdAt": "2020-08-05T20:49:44Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteReadTests.java", "diffHunk": "@@ -65,4 +65,12 @@ protected ServiceBuilder createBuilder(ServiceBuilderConfig.Builder builderConfi\n                              .withStorageFactory(setup -> this.storageFactory)\n                              .withDataLogFactory(setup -> this.durableDataLogFactory);\n     }\n+\n+    /**\n+     * This method intentionally left blank as it's out of concern for No-Op Storage.", "originalCommit": "c05a63a0c5e5863c603b08af1cf6e3dcd4c88766", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIwMzAzNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r466203036", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-06T07:33:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5NTM1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "f038d19b312e093ca946bd3092dd9f7166461563", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteReadTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteReadTests.java\nindex d2bc66866..206ee73da 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteReadTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteReadTests.java\n\n@@ -65,12 +65,4 @@ public class StreamSegmentServiceNoOpWriteReadTests extends StreamSegmentStoreTe\n                              .withStorageFactory(setup -> this.storageFactory)\n                              .withDataLogFactory(setup -> this.durableDataLogFactory);\n     }\n-\n-    /**\n-     * This method intentionally left blank as it's out of concern for No-Op Storage.\n-     * It must be here as it is defined as abstract method in super class.\n-     */\n-    @Override\n-    public void testDataRecovery() {\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5Njc5OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465996798", "bodyText": "Is it possible for this method to end up deleting the actual data in LTS?", "author": "sachin-j-joshi", "createdAt": "2020-08-05T20:52:34Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainer : debugStreamSegmentContainers.entrySet()) {\n+\n+            ContainerTableExtension ext = debugStreamSegmentContainer.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(debugStreamSegmentContainer.getKey()),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<String> metadataSegments = new HashSet<>();\n+            it.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainer.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> it = storage.listSegments();\n+        if (it == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            log.info(\"Segment to be recovered = {}\", curr.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(curr.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), curr)));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n+                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n+     */\n+    public static class SegmentRecovery implements Runnable {\n+        private final DebugStreamSegmentContainer container;\n+        private final SegmentProperties storageSegment;\n+\n+        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n+            Preconditions.checkNotNull(container);\n+            Preconditions.checkNotNull(segment);\n+            this.container = container;\n+            this.storageSegment = segment;\n+        }\n+\n+        @Override\n+        public void run() {\n+            long segmentLength = storageSegment.getLength();\n+            boolean isSealed = storageSegment.isSealed();\n+            String segmentName = storageSegment.getName();\n+\n+            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n+            /*\n+                1. segment exists in both metadata and storage, re-create it\n+                2. segment only in metadata, delete\n+                3. segment only in storage, re-create it\n+             */\n+            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                    .thenAccept(e -> {\n+                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                            container.deleteStreamSegment(segmentName, TIMEOUT).join();", "originalCommit": "c05a63a0c5e5863c603b08af1cf6e3dcd4c88766", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5NzY3MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465997671", "bodyText": "container.deleteStreamSegment(segmentName followed by container.registerExistingSegment(segmentName looks odd .\nMay be rename registerExistingSegment ?", "author": "sachin-j-joshi", "createdAt": "2020-08-05T20:54:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5Njc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxODc0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r466018742", "bodyText": "To elaborate -\nWe want to just update the metadata and not touch the actual segment on LTS. (Except for metadata segment, all other segments should be left alone.)\nI fear that calling container.deleteStreamSegment like this will actually trigger request to delete the segment from LTS (it will enqueue operation to delete in BK ledger). Once the new recovered instance restarts then it will reprocess all the enqueued operations and may end up  actually deleting the data from LTS.\nWhat we need here is ability to just delete the metadata about the segment and re-create or update it.", "author": "sachin-j-joshi", "createdAt": "2020-08-05T21:37:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5Njc5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIwNDAyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r466204029", "bodyText": "Using deleteSegment from MetadataStore now. From the javadoc, this method only deletes a Segment and any associated information from the Metadata Store.", "author": "ManishKumarKeshri", "createdAt": "2020-08-06T07:35:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk5Njc5OA=="}], "type": "inlineReview", "revised_code": {"commit": "f038d19b312e093ca946bd3092dd9f7166461563", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DataRecovery.java\nsimilarity index 94%\nrename from segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nrename to segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DataRecovery.java\nindex ef14db82a..f5f5290ad 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DataRecovery.java\n\n@@ -7,7 +7,7 @@\n  *\n  *     http://www.apache.org/licenses/LICENSE-2.0\n  */\n-package io.pravega.segmentstore.server;\n+package io.pravega.segmentstore.server.containers;\n \n import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxNTM2Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r466015366", "bodyText": "This functionality needs to live in product code and must be accessible to the admin tool. I suggest moving it in DebugStreamSegmentContainer.java", "author": "sachin-j-joshi", "createdAt": "2020-08-05T21:30:02Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {", "originalCommit": "c05a63a0c5e5863c603b08af1cf6e3dcd4c88766", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjIwNzIzNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r466207234", "bodyText": "Moved it to io.pravega.segmentstore.server.containers with new name as SegmentsRecovery.", "author": "ManishKumarKeshri", "createdAt": "2020-08-06T07:41:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxNTM2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "f038d19b312e093ca946bd3092dd9f7166461563", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DataRecovery.java\nsimilarity index 94%\nrename from segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nrename to segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DataRecovery.java\nindex ef14db82a..f5f5290ad 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DataRecovery.java\n\n@@ -7,7 +7,7 @@\n  *\n  *     http://www.apache.org/licenses/LICENSE-2.0\n  */\n-package io.pravega.segmentstore.server;\n+package io.pravega.segmentstore.server.containers;\n \n import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n"}}, {"oid": "f038d19b312e093ca946bd3092dd9f7166461563", "url": "https://github.com/pravega/pravega/commit/f038d19b312e093ca946bd3092dd9f7166461563", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-06T06:23:40Z", "type": "commit"}, {"oid": "29df39132887c50ffca5cb3a316f24280f9c1e7e", "url": "https://github.com/pravega/pravega/commit/29df39132887c50ffca5cb3a316f24280f9c1e7e", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-06T07:56:27Z", "type": "commit"}, {"oid": "698312d3567dfe119befa7b733d5a23e60293d9b", "url": "https://github.com/pravega/pravega/commit/698312d3567dfe119befa7b733d5a23e60293d9b", "message": "Using deleteSegment from metadataStore.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-07T21:40:39Z", "type": "commit"}, {"oid": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "url": "https://github.com/pravega/pravega/commit/644a58c4d832e2bfcc8bace1025eff68f12f7493", "message": "Removing attribute segment from recovery.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-12T02:12:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1NzQ3Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469557476", "bodyText": "The more I think about it, the more I do not like this name. This has little to nothing to do with \"Debugging\" so DebugSegmentContainer doesn't sound too descriptive.\nAt the same time I do not have any better ideas at this moment. But something to keep in mind as we make progress on this task.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:28:43Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * Defines debug segment container for stream segments.\n+ */\n+public interface DebugSegmentContainer extends SegmentContainer {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyMjQ4OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470422489", "bodyText": "Ok. Is RecoverySegmentContainer good?", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:47:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1NzQ3Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1ODE5Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469558197", "bodyText": "Make this a proper Javadoc. Also, \"Used by XYZ\" is not really appropriate as a class should not be concerned with who is using it.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:30:17Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java", "diffHunk": "@@ -704,6 +704,19 @@ static SegmentInfo newSegment(String name, Collection<AttributeUpdate> attribute\n                     .build();\n         }\n \n+        // Used by DebugStreamSegmentContainer to get SegmentInfo while registering a segment.", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyMzUyMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470423522", "bodyText": "Even other methods in this class don't have Javadoc, so removed it here.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:51:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1ODE5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\nindex dee7625fc..369d9f3ca 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n\n@@ -704,7 +704,6 @@ public abstract class MetadataStore implements AutoCloseable {\n                     .build();\n         }\n \n-        // Used by DebugStreamSegmentContainer to get SegmentInfo while registering a segment.\n         static ArrayView recoveredSegment(String streamSegmentName, long length, boolean isSealed) {\n             StreamSegmentInformation segmentProp = StreamSegmentInformation.builder()\n                     .name(streamSegmentName)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1ODgxNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469558816", "bodyText": "Does this class need to be public?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:31:38Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n+                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n+     */\n+    public static class SegmentRecovery implements Runnable {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyMzkyOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470423928", "bodyText": "Converted this class to a private method which returns a CompletableFuture and recovers one segment.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:52:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1ODgxNg=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1OTAyMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469559023", "bodyText": "Rename this to ContainerRecoveryUtils", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:32:08Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDAwMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424003", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1OTAyMw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1OTcyNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469559724", "bodyText": "This description is misleading.\nYou need to begin with a sentence stating what this method does.\nThen you clearly state what happens when this method completes successfully and what happens if it fails.\nThen you explain the process you follow.\nYou need to clearly document all exceptions that can be thrown out of it.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:33:46Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDA4OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424089", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:53:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1OTcyNA=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MDE3Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469560176", "bodyText": "A {@link Storage} instance that will be used to list segments from.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:34:45Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDEyMQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424121", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:53:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MDE3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MDQzNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469560437", "bodyText": "A Map of Container Ids to {@link DebugStreamSegmentContainer} instances representing the Containers that will be recovered.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:35:21Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDIwMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424203", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:53:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MDQzNw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MDY5Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469560692", "bodyText": "Validate all arguments prior to beginning. Null checks. Are all containers present in your hash map?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:35:54Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDMzNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424336", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:54:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MDY5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MzE4Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469563183", "bodyText": "Please reformat this code to be more readable.\n\nFeel free to use val when declaring types with long names (for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()))\nMove IteratorArgs... into some variable outside the loop and reuse it.\nPlease do not chain all method calls in one big line or wrapped-around line. If you choose to do chaining (no problem there), do it on a new line and let your IDE auto-format the proper placement of the the code. Look for other cases in the codebase where this is done.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:41:36Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDQxOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424418", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:54:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MzE4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MzQxMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469563410", "bodyText": "Why do you key the Map on the DebugStreamSegmentContainer? Can't you just do it on the id of the container?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:42:03Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNDQ4OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470424488", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MzQxMA=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2Mzc3Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469563772", "bodyText": "This is not what a null segmentIterator means.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:42:54Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2MzkyOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469563928", "bodyText": "And you should throw an exception in this case, not return (returning with no exception indicates a successful completion).", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:43:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2Mzc3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNTIzMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470425233", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:56:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2Mzc3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDE4MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469564181", "bodyText": "Registering Segment: {}", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:43:52Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NTI4Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469565287", "bodyText": "Actually this is superfluous. The SegmentRecovery logs it too.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:46:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDE4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNTI5Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470425292", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDE4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNTMzMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470425332", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:57:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDE4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDc1NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469564755", "bodyText": "This is going to create A LOT of concurrent threads, possibly taking over your entire thread pool.\nWhy do you do each segment individually in a thread?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:45:13Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDk0Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469564946", "bodyText": "Please be consistent about how you log it. Is it storage or long term storage. I prefer the former.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:45:39Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNTQxNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470425416", "bodyText": "Ok. Using storage", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:57:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NDk0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NTQ2OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469565468", "bodyText": "Registering: {}, {}, {}.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:46:48Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n+                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n+     */\n+    public static class SegmentRecovery implements Runnable {\n+        private final DebugStreamSegmentContainer container;\n+        private final SegmentProperties storageSegment;\n+\n+        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n+            Preconditions.checkNotNull(container);\n+            Preconditions.checkNotNull(segment);\n+            this.container = container;\n+            this.storageSegment = segment;\n+        }\n+\n+        @Override\n+        public void run() {\n+            long segmentLength = storageSegment.getLength();\n+            boolean isSealed = storageSegment.isSealed();\n+            String segmentName = storageSegment.getName();\n+\n+            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNTY1OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470425659", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T05:58:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NTQ2OA=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NjQyNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469566426", "bodyText": "You are effectively using 2 threads for this operation. One thread is the one that SegmentRecovery is running on and the other is whatever this call (and the one above) is using (this is what happens when you invoke join).\nPlease rework this entire class (the outer one) to not have a single join or get. This means you will be using CompletableFuture joins (thenCompose, thenAccept, etc). This also means your main method in this class will return a CompletableFuture.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:49:04Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n+                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n+     */\n+    public static class SegmentRecovery implements Runnable {\n+        private final DebugStreamSegmentContainer container;\n+        private final SegmentProperties storageSegment;\n+\n+        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n+            Preconditions.checkNotNull(container);\n+            Preconditions.checkNotNull(segment);\n+            this.container = container;\n+            this.storageSegment = segment;\n+        }\n+\n+        @Override\n+        public void run() {\n+            long segmentLength = storageSegment.getLength();\n+            boolean isSealed = storageSegment.isSealed();\n+            String segmentName = storageSegment.getName();\n+\n+            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n+            /*\n+                1. segment exists in both metadata and storage, re-create it\n+                2. segment only in metadata, delete\n+                3. segment only in storage, re-create it\n+             */\n+            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                    .thenAccept(e -> {\n+                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n+                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n+                        }\n+                    });\n+\n+            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNjQxNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470426415", "bodyText": "Converted this class to a private method which returns a CompletableFuture and recovers one segment. Removed all join or get.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:01:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NjQyNg=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NjY3Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469566673", "bodyText": "Do not use join", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:49:43Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery.\n+ */\n+@Slf4j\n+public class SegmentsRecovery {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n+     * container.\n+     * @param storage                           Long term storage.\n+     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws                                  Exception in case of exception during the execution.\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws Exception {\n+        log.info(\"Recovery started for all containers...\");\n+\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n+                    TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n+                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        if (segmentIterator == null) {\n+            log.info(\"No segments found in the long term storage.\");\n+            return;\n+        }\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n+            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n+            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n+                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n+     */\n+    public static class SegmentRecovery implements Runnable {\n+        private final DebugStreamSegmentContainer container;\n+        private final SegmentProperties storageSegment;\n+\n+        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n+            Preconditions.checkNotNull(container);\n+            Preconditions.checkNotNull(segment);\n+            this.container = container;\n+            this.storageSegment = segment;\n+        }\n+\n+        @Override\n+        public void run() {\n+            long segmentLength = storageSegment.getLength();\n+            boolean isSealed = storageSegment.isSealed();\n+            String segmentName = storageSegment.getName();\n+\n+            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n+            /*\n+                1. segment exists in both metadata and storage, re-create it\n+                2. segment only in metadata, delete\n+                3. segment only in storage, re-create it\n+             */\n+            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                    .thenAccept(e -> {\n+                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n+                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n+                        }\n+                    });\n+\n+            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n+        }\n+    }\n+\n+    /**\n+     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n+     * @param storage       Long term storage to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n+        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+        deleteSegment(storage, metadataSegmentName);\n+        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n+        deleteSegment(storage, attributeSegmentName);\n+    }\n+\n+    /**\n+     * Deletes the segment with given segment name from the given long term storage.\n+     * @param storage       Long term storage to delete the segment from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     */\n+    private static void deleteSegment(Storage storage, String segmentName) {\n+        try {\n+            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyNzExNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470427116", "bodyText": "I have just kept it here to make sure that method call deletes the segment. It is called from deleteContainerMetadataAndAttributeSegments which deletes both the segments.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:03:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NjY3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\ndeleted file mode 100644\nindex 2c6f0b14c..000000000\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/SegmentsRecovery.java\n+++ /dev/null\n\n@@ -1,176 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.server.containers;\n-\n-import com.google.common.base.Preconditions;\n-import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.Futures;\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n-import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n-import io.pravega.segmentstore.contracts.tables.IteratorItem;\n-import io.pravega.segmentstore.contracts.tables.TableKey;\n-import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n-import io.pravega.segmentstore.storage.SegmentHandle;\n-import io.pravega.segmentstore.storage.Storage;\n-import io.pravega.shared.NameUtils;\n-import io.pravega.shared.segment.SegmentToContainerMapper;\n-import lombok.extern.slf4j.Slf4j;\n-import lombok.val;\n-\n-import java.time.Duration;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n-\n-import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n-\n-/**\n- * Utility methods for data recovery.\n- */\n-@Slf4j\n-public class SegmentsRecovery {\n-    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n-\n-    /**\n-     * Lists all segments from a given long term storage and then re-creates them using their corresponding debug segment\n-     * container.\n-     * @param storage                           Long term storage.\n-     * @param debugStreamSegmentContainers      A hashmap which has debug segment container instances to create segments.\n-     * @param executorService                   A thread pool for execution.\n-     * @throws                                  Exception in case of exception during the execution.\n-     */\n-    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n-                                          ExecutorService executorService) throws Exception {\n-        log.info(\"Recovery started for all containers...\");\n-\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<DebugStreamSegmentContainer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        for (Map.Entry<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            ContainerTableExtension tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            AsyncIterator<IteratorItem<TableKey>> keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).get(TIMEOUT.toMillis(),\n-                    TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k -> metadataSegments.addAll(k.getEntries().stream().map(entry -> entry.getKey().toString())\n-                    .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getValue(), metadataSegments);\n-        }\n-\n-        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n-\n-        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n-        if (segmentIterator == null) {\n-            log.info(\"No segments found in the long term storage.\");\n-            return;\n-        }\n-\n-        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n-        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n-        while (segmentIterator.hasNext()) {\n-            SegmentProperties currentSegment = segmentIterator.next();\n-\n-            // skip recovery if the segment is an attribute segment.\n-            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n-                continue;\n-            }\n-\n-            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n-            log.info(\"Segment to be recovered = {}\", currentSegment.getName());\n-            metadataSegmentsByContainer.get(debugStreamSegmentContainers.get(containerId)).remove(currentSegment.getName());\n-            futures.add(CompletableFuture.runAsync(new SegmentRecovery(debugStreamSegmentContainers.get(containerId), currentSegment)));\n-        }\n-        Futures.allOf(futures).join();\n-\n-        for (Map.Entry<DebugStreamSegmentContainer, Set<String>> metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n-            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n-                log.info(\"Deleting segment '{}' as it is not in storage\", segmentName);\n-                metadataSegmentsSetEntry.getKey().deleteStreamSegment(segmentName, TIMEOUT).join();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Creates the given segment with the given DebugStreamSegmentContainer instance.\n-     */\n-    public static class SegmentRecovery implements Runnable {\n-        private final DebugStreamSegmentContainer container;\n-        private final SegmentProperties storageSegment;\n-\n-        public SegmentRecovery(DebugStreamSegmentContainer container, SegmentProperties segment) {\n-            Preconditions.checkNotNull(container);\n-            Preconditions.checkNotNull(segment);\n-            this.container = container;\n-            this.storageSegment = segment;\n-        }\n-\n-        @Override\n-        public void run() {\n-            long segmentLength = storageSegment.getLength();\n-            boolean isSealed = storageSegment.isSealed();\n-            String segmentName = storageSegment.getName();\n-\n-            log.info(\"Recovering segment with name = {}, length = {}, sealed status = {}.\", segmentName, segmentLength, isSealed);\n-            /*\n-                1. segment exists in both metadata and storage, re-create it\n-                2. segment only in metadata, delete\n-                3. segment only in storage, re-create it\n-             */\n-            val streamSegmentInfo = container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n-                    .thenAccept(e -> {\n-                        if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n-                            container.metadataStore.deleteSegment(segmentName, TIMEOUT).join();\n-                            container.registerSegment(segmentName, segmentLength, isSealed).join();\n-                        }\n-                    });\n-\n-            Futures.exceptionallyComposeExpecting(streamSegmentInfo, ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n-                    () -> container.registerSegment(segmentName, segmentLength, isSealed)).join();\n-        }\n-    }\n-\n-    /**\n-     * Deletes container-metadata segment and attribute segment of the container with given container Id.\n-     * @param storage       Long term storage to delete the segments from.\n-     * @param containerId   Id of the container for which the segments has to be deleted.\n-     */\n-    public static void deleteContainerMetadataSegments(Storage storage, int containerId) {\n-        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n-        deleteSegment(storage, metadataSegmentName);\n-        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n-        deleteSegment(storage, attributeSegmentName);\n-    }\n-\n-    /**\n-     * Deletes the segment with given segment name from the given long term storage.\n-     * @param storage       Long term storage to delete the segment from.\n-     * @param segmentName   Name of the segment to be deleted.\n-     */\n-    private static void deleteSegment(Storage storage, String segmentName) {\n-        try {\n-            SegmentHandle segmentHandle = storage.openWrite(segmentName).join();\n-            storage.delete(segmentHandle, TIMEOUT).join();\n-        } catch (Exception e) {\n-            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n-                log.info(\"Segment '{}' doesn't exist.\", segmentName);\n-            } else {\n-                throw e;\n-            }\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NzE1Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469567152", "bodyText": "return createStorageFactory()", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:50:48Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java", "diffHunk": "@@ -241,6 +241,14 @@ public void initialize() throws DurableDataLogException {\n         getSingleton(this.containerManager, this.segmentContainerManagerCreator).initialize();\n     }\n \n+    /**\n+     * To get the storageFactory after a ServiceBuilder has been initialized.\n+     * @return StorageFactory instance used to initialize ServiceBuilder.\n+     */\n+    public StorageFactory getStorageFactory() {\n+        return this.storageFactory.get();", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyODIxOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470428219", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NzE1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java\nindex 6eb15d3c7..295f86a31 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java\n\n@@ -246,7 +246,7 @@ public class ServiceBuilder implements AutoCloseable {\n      * @return StorageFactory instance used to initialize ServiceBuilder.\n      */\n     public StorageFactory getStorageFactory() {\n-        return this.storageFactory.get();\n+        return createStorageFactory();\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NzU4Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469567587", "bodyText": "SegmentStoreWithSegmentTracker", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:51:54Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentsTracker.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.MergeStreamSegmentResult;\n+import io.pravega.segmentstore.contracts.ReadResult;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * A wrapper class to StreamSegmentStore and TableStore to track the segments being created or deleted. The list of segments\n+ * obtained during this process is used in RestoreBackUpDataRecoveryTest to wait for segments to be flushed to the long term storage.\n+ */\n+public class SegmentsTracker implements StreamSegmentStore, TableStore {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyODQwMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470428400", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:08:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NzU4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentsTracker.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java\nsimilarity index 97%\nrename from segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentsTracker.java\nrename to segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java\nindex 54b8d8824..fba5997ba 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentsTracker.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java\n\n@@ -36,14 +36,14 @@ import java.util.concurrent.ConcurrentHashMap;\n  * A wrapper class to StreamSegmentStore and TableStore to track the segments being created or deleted. The list of segments\n  * obtained during this process is used in RestoreBackUpDataRecoveryTest to wait for segments to be flushed to the long term storage.\n  */\n-public class SegmentsTracker implements StreamSegmentStore, TableStore {\n+public class SegmentStoreWithSegmentTracker implements StreamSegmentStore, TableStore {\n     private final StreamSegmentStore streamSegmentStore;\n     private final TableStore tableStore;\n \n     @Getter(AccessLevel.PUBLIC)\n     private final ConcurrentHashMap<String, Boolean> segments;\n \n-    public SegmentsTracker(StreamSegmentStore streamSegmentStore, TableStore tableStore) {\n+    public SegmentStoreWithSegmentTracker(StreamSegmentStore streamSegmentStore, TableStore tableStore) {\n         this.streamSegmentStore = streamSegmentStore;\n         this.tableStore = tableStore;\n         this.segments = new ConcurrentHashMap<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2NzkxOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469567918", "bodyText": "Delete this. You can use executorService()", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:52:50Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+@Slf4j\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 60 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final int THREAD_POOL_COUNT = 30;\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService;", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex c0c0b0c73..e1e6eb163 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -45,9 +45,7 @@ import io.pravega.test.common.ThreadPooledTestSuite;\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n-import org.junit.After;\n import org.junit.Assert;\n-import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.Timeout;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2ODAyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469568029", "bodyText": "You do not need this. Remove these 2 methods.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:53:09Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+@Slf4j\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 60 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final int THREAD_POOL_COUNT = 30;\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService;\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    @Before\n+    public void setUp() {\n+        this.executorService = executorService();", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyODQ3NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470428474", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:08:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2ODAyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex c0c0b0c73..e1e6eb163 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -45,9 +45,7 @@ import io.pravega.test.common.ThreadPooledTestSuite;\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n-import org.junit.After;\n import org.junit.Assert;\n-import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.Timeout;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2ODM3NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469568374", "bodyText": "Isn't there a RANDOM.nextBoolean()?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:53:59Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+@Slf4j\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 60 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final int THREAD_POOL_COUNT = 30;\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService;\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    @Before\n+    public void setUp() {\n+        this.executorService = executorService();\n+    }\n+\n+    @After\n+    public void tearDown() {\n+        this.executorService.shutdown();\n+    }\n+\n+    protected int getThreadPoolSize() {\n+        return THREAD_POOL_COUNT;\n+    }\n+\n+    /**\n+     * It tests the ability to register an existing segment(segment existing only in Long-Term Storage) using debug\n+     * segment container. Method registerSegment in {@link DebugStreamSegmentContainer} is tested here.\n+     * The test starts a debug segment container and creates some segments using it and then verifies if the segments\n+     * were created successfully.\n+     */\n+    @Test\n+    public void testRegisterExistingSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext(executorService);\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+        log.info(\"Started debug segment container.\");\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.registerSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        // Creates all the segments.\n+        Futures.allOf(futures).join();\n+        log.info(\"Created the segments using debug segment container.\");\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. Lists the segments from the storage and and then recreates them using\n+     * debug segment containers. Before re-creating(or registering), the segments are mapped to their respective debug\n+     * segment container. Once registered, segment's properties are matched to verify if the test was successful or not.\n+     */\n+    @Test\n+    public void testEndToEnd() throws Exception {\n+        // Segments are mapped to four different containers.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+        log.info(\"Created a storage instance\");\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentByContainers.put(containerId, segmentsList);\n+            }\n+            segmentByContainers.get(containerId).add(segmentName);\n+\n+            // Create segments, write data and randomly seal some of them.\n+            val wh1 = s.create(segmentName);\n+            // Write data.\n+            s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+            if (RANDOM.nextInt(2) == 1) {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex c0c0b0c73..e1e6eb163 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -45,9 +45,7 @@ import io.pravega.test.common.ThreadPooledTestSuite;\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n-import org.junit.After;\n import org.junit.Assert;\n-import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.Timeout;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2OTQ0OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469569449", "bodyText": "testSegmentRestoration or similar. Just do not call it endToEndDebugSegmentContainer since it tells a reader nothing about what it's doing. Same with the java doc.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:56:29Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -145,7 +176,78 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyODU1NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470428554", "bodyText": "Ok. Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2OTQ0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex 26454a81f..fda1f90aa 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -177,11 +176,13 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * End to end test to verify DebugSegmentContainer process.\n+     * SegmentStore is used to create some segments, write data to them and let them flush to the storage.\n+     * This test only uses this storage to restore the container metadata segments in a new durable data log. Segment\n+     * properties are matched to verify after restoration.\n+     * segments restoration from the storage used to create a segme\n      * @throws Exception If an exception occurred.\n      */\n-    public void endToEndDebugSegmentContainer() throws Exception {\n-        ScheduledExecutorService executorService = executorService();\n+    public void testSegmentRestoration() throws Exception {\n         ArrayList<String> segmentNames;\n         HashMap<String, ArrayList<String>> transactionsBySegment;\n         HashMap<String, Long> lengths = new HashMap<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2OTUwOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469569508", "bodyText": "You do not need to hold this in a variable.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:56:39Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -145,7 +176,78 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        ScheduledExecutorService executorService = executorService();", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyODc1MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470428750", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:09:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU2OTUwOA=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex 26454a81f..fda1f90aa 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -177,11 +176,13 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * End to end test to verify DebugSegmentContainer process.\n+     * SegmentStore is used to create some segments, write data to them and let them flush to the storage.\n+     * This test only uses this storage to restore the container metadata segments in a new durable data log. Segment\n+     * properties are matched to verify after restoration.\n+     * segments restoration from the storage used to create a segme\n      * @throws Exception If an exception occurred.\n      */\n-    public void endToEndDebugSegmentContainer() throws Exception {\n-        ScheduledExecutorService executorService = executorService();\n+    public void testSegmentRestoration() throws Exception {\n         ArrayList<String> segmentNames;\n         HashMap<String, ArrayList<String>> transactionsBySegment;\n         HashMap<String, Long> lengths = new HashMap<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDA5Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469570093", "bodyText": "Attribute Segment", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:58:03Z", "path": "shared/protocol/src/main/java/io/pravega/shared/NameUtils.java", "diffHunk": "@@ -190,6 +190,16 @@ public static String extractPrimaryStreamSegmentName(String streamSegmentName) {\n         return streamSegmentName.substring(0, endOfStreamNamePos);\n     }\n \n+    /**\n+     * Checks whether the given name is an attribute Segment or not.", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyODc5MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470428790", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:09:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDA5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java b/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\nindex 707b2b9ae..026991bd4 100644\n--- a/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\n+++ b/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\n\n@@ -191,7 +191,7 @@ public final class NameUtils {\n     }\n \n     /**\n-     * Checks whether the given name is an attribute Segment or not.\n+     * Checks whether the given name is an Attribute Segment or not.\n      *\n      * @param segmentName   The name of the segment.\n      * @return              True if the segment is an attribute Segment, false otherwise.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDEzMQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469570131", "bodyText": "There are several places in this file where this can be used. Please find them and update them to make use of your new method.", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:58:06Z", "path": "shared/protocol/src/main/java/io/pravega/shared/NameUtils.java", "diffHunk": "@@ -190,6 +190,16 @@ public static String extractPrimaryStreamSegmentName(String streamSegmentName) {\n         return streamSegmentName.substring(0, endOfStreamNamePos);\n     }\n \n+    /**\n+     * Checks whether the given name is an attribute Segment or not.\n+     *\n+     * @param segmentName   The name of the segment.\n+     * @return              True if the segment is an attribute Segment, false otherwise.\n+     */\n+    public static boolean isAttributeSegment(String segmentName) {\n+        return segmentName.endsWith(ATTRIBUTE_SUFFIX);", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyOTA2Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470429063", "bodyText": "It was in one place in the same file. Updated it.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:10:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDEzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java b/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\nindex 707b2b9ae..026991bd4 100644\n--- a/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\n+++ b/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\n\n@@ -191,7 +191,7 @@ public final class NameUtils {\n     }\n \n     /**\n-     * Checks whether the given name is an attribute Segment or not.\n+     * Checks whether the given name is an Attribute Segment or not.\n      *\n      * @param segmentName   The name of the segment.\n      * @return              True if the segment is an attribute Segment, false otherwise.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDM4MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469570381", "bodyText": "Should we make this with more than just 1 container?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:58:49Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,563 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.server.containers.SegmentsRecovery;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.SegmentsTracker;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainerTests;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.net.URI;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ * What test does, step by step:\n+ * 1. Starts Pravega locally with just one segment container.\n+ * 2. Writes 300 events to two different segments.\n+ * 3. Waits for all segments created to be flushed to the long term storage.\n+ * 4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+ * 5. Deletes container metadata segment and its attribute segment from the old LTS.\n+ * 5. Starts debug segment container using a new bookeeper/zookeeper and the old LTS.\n+ * 6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+ * 7. Starts segment store and controller.\n+ * 8. Reads all 600 events again.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(100 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;", "originalCommit": "644a58c4d832e2bfcc8bace1025eff68f12f7493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQyOTc5OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470429798", "bodyText": "I have written integration tests for multiple containers, readers stall while reading and then recovery and then resume from the same point, and watermarking. Will create PRs for them, once this is merged.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T06:13:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDM4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 268512321..1b95d63f5 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -36,9 +36,9 @@ import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.StreamSegmentStore;\n-import io.pravega.segmentstore.server.containers.SegmentsRecovery;\n+import io.pravega.segmentstore.server.SegmentStoreWithSegmentTracker;\n+import io.pravega.segmentstore.server.containers.ContainerRecoveryUtils;\n import io.pravega.segmentstore.server.OperationLogFactory;\n-import io.pravega.segmentstore.server.SegmentsTracker;\n import io.pravega.segmentstore.server.containers.ContainerConfig;\n import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainerTests;\n"}}, {"oid": "7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "url": "https://github.com/pravega/pravega/commit/7b8573ebc20c33902426a5f4c4b3c5e90a384e64", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-14T06:05:39Z", "type": "commit"}, {"oid": "29a3c1d7724304638ab5fd1eb3b3325f4c672131", "url": "https://github.com/pravega/pravega/commit/29a3c1d7724304638ab5fd1eb3b3325f4c672131", "message": "Updating deleteSegment.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-14T06:52:45Z", "type": "commit"}, {"oid": "31f84c39ce33ca6d23aa1e3a123e4b83de618cbd", "url": "https://github.com/pravega/pravega/commit/31f84c39ce33ca6d23aa1e3a123e4b83de618cbd", "message": "Small changes in Javadoc.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-14T07:07:12Z", "type": "commit"}, {"oid": "883da1068638d9dae5e87aea87c92ade5260e15a", "url": "https://github.com/pravega/pravega/commit/883da1068638d9dae5e87aea87c92ade5260e15a", "message": "Minor changes in Javadoc.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-14T15:27:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjMzOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470852338", "bodyText": "What is this map holding ?\nmetadataSegmentsByContainer The name seems confusing.\nSomething like existingSegmetsMap (or similar) will convey the intent better.", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:32:47Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDc4OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470900789", "bodyText": "Ok. Changed to existingSegmentsMap.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:13:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjMzOA=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjU5Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470852596", "bodyText": "May be extract this into a method", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:33:29Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n+            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n+        }", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDY1OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470900658", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:12:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjU5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzAzNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470853036", "bodyText": "May be\nfor (val currentSegment : ...) { \n....\n}", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:34:37Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n+            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDYyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470900629", "bodyText": "OK.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:12:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzAzNg=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NTg0Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470855847", "bodyText": "Do you have test that tests exception thrown from here ?", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:42:18Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n+            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            metadataSegmentsByContainer.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (val metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                debugStreamSegmentContainers.get(metadataSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5NDcyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470894729", "bodyText": "Almost all segments in the integration test through exception that it is not present in the container metadata.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T22:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NTg0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NjUzMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470856533", "bodyText": "to avoid confusion please rename it to deleteSegmentFromStorage.", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:44:14Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n+            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            metadataSegmentsByContainer.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (val metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                debugStreamSegmentContainers.get(metadataSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                () -> container.registerSegment(segmentName, segmentLength, isSealed));\n+    }\n+\n+    /**\n+     * Deletes container metadata segment and its Attribute segment from the {@link Storage} for the given container Id.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataAndAttributeSegments(Storage storage, int containerId) {\n+        Preconditions.checkNotNull(storage);\n+        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n+        deleteSegment(storage, metadataSegmentName);\n+        deleteSegment(storage, attributeSegmentName);\n+    }\n+\n+    /**\n+     * Deletes the segment with given name from the given {@link Storage} instance.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     */\n+    private static void deleteSegment(Storage storage, String segmentName) {", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDUyNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470900524", "bodyText": "Ok.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:11:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NjUzMw=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzc5Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470857797", "bodyText": "java doc would be helpful here. Someone not familiar with it may not understand what this is for/what it does.", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:47:42Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java", "diffHunk": "@@ -704,6 +704,18 @@ static SegmentInfo newSegment(String name, Collection<AttributeUpdate> attribute\n                     .build();\n         }\n \n+        static ArrayView recoveredSegment(String streamSegmentName, long length, boolean isSealed) {", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\nindex 369d9f3ca..c983212a5 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n\n@@ -704,6 +704,14 @@ public abstract class MetadataStore implements AutoCloseable {\n                     .build();\n         }\n \n+        /**\n+         * The method takes in details of a segment i.e., name, length and sealed status and creates a\n+         * {@link StreamSegmentInformation} instance, which is returned after serialization.\n+         * @param streamSegmentName     The name of the segment.\n+         * @param length                The length of the segment.\n+         * @param isSealed              The sealed status of the segment.\n+         * @return                      An instance of ArrayView with segment information.\n+         */\n         static ArrayView recoveredSegment(String streamSegmentName, long length, boolean isSealed) {\n             StreamSegmentInformation segmentProp = StreamSegmentInformation.builder()\n                     .name(streamSegmentName)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODUyNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470858524", "bodyText": "Seems like nothing really changed in this file.\nPlease revert the irrelevant change (or  just another make change to match exactly how it was before.)", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:49:36Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -98,13 +98,13 @@\n     private static final RetryAndThrowConditionally CACHE_ATTRIBUTES_RETRY = Retry.withExpBackoff(50, 2, 10, 1000)\n             .retryWhen(ex -> ex instanceof BadAttributeUpdateException);\n     protected final StreamSegmentContainerMetadata metadata;\n+    protected final MetadataStore metadataStore;", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5ODIwNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470898205", "bodyText": "Class member metadataStore is used in ContainerRecoveryUtils and DebugStreamSegmentContainer.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:01:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODUyNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MDg2Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470860862", "bodyText": "Nit: missing javadoc", "author": "sachin-j-joshi", "createdAt": "2020-08-14T20:55:29Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.MergeStreamSegmentResult;\n+import io.pravega.segmentstore.contracts.ReadResult;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * A wrapper class to StreamSegmentStore and TableStore to track the segments being created or deleted. The list of segments\n+ * obtained during this process is used in RestoreBackUpDataRecoveryTest to wait for segments to be flushed to the long term storage.\n+ */\n+public class SegmentStoreWithSegmentTracker implements StreamSegmentStore, TableStore {\n+    private final StreamSegmentStore streamSegmentStore;\n+    private final TableStore tableStore;\n+\n+    @Getter(AccessLevel.PUBLIC)\n+    private final ConcurrentHashMap<String, Boolean> segments;\n+\n+    public SegmentStoreWithSegmentTracker(StreamSegmentStore streamSegmentStore, TableStore tableStore) {", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5OTQ0Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470899443", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:06:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg2MDg2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java\nindex fba5997ba..61685ef0d 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/SegmentStoreWithSegmentTracker.java\n\n@@ -33,8 +33,10 @@ import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ConcurrentHashMap;\n \n /**\n- * A wrapper class to StreamSegmentStore and TableStore to track the segments being created or deleted. The list of segments\n- * obtained during this process is used in RestoreBackUpDataRecoveryTest to wait for segments to be flushed to the long term storage.\n+ * A wrapper class to {@link StreamSegmentStore} and {@link TableStore} to track the segments being created or deleted\n+ * using their methods.\n+ * The set of segments obtained in here is used in Data Recovery integration test to wait for those segments to be\n+ * flushed to the storage, so that segments recovery from the storage can be performed.\n  */\n public class SegmentStoreWithSegmentTracker implements StreamSegmentStore, TableStore {\n     private final StreamSegmentStore streamSegmentStore;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MDI1Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470870256", "bodyText": "You don't need this method , why not just call createStorageFactory directly ?", "author": "sachin-j-joshi", "createdAt": "2020-08-14T21:20:08Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java", "diffHunk": "@@ -241,6 +241,14 @@ public void initialize() throws DurableDataLogException {\n         getSingleton(this.containerManager, this.segmentContainerManagerCreator).initialize();\n     }\n \n+    /**\n+     * To get the storageFactory after a ServiceBuilder has been initialized.\n+     * @return StorageFactory instance used to initialize ServiceBuilder.\n+     */\n+    public StorageFactory getStorageFactory() {\n+        return createStorageFactory();\n+    }\n+", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDQ2Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470900463", "bodyText": "Ok. Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:11:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MDI1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java\nindex 295f86a31..29ca7d814 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceBuilder.java\n\n@@ -241,14 +241,6 @@ public class ServiceBuilder implements AutoCloseable {\n         getSingleton(this.containerManager, this.segmentContainerManagerCreator).initialize();\n     }\n \n-    /**\n-     * To get the storageFactory after a ServiceBuilder has been initialized.\n-     * @return StorageFactory instance used to initialize ServiceBuilder.\n-     */\n-    public StorageFactory getStorageFactory() {\n-        return createStorageFactory();\n-    }\n-\n     /**\n      * Creates or gets the instance of the SegmentContainerRegistry used throughout this ServiceBuilder.\n      */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MDc4NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470870785", "bodyText": "This method should return CompletableFuture.", "author": "sachin-j-joshi", "createdAt": "2020-08-14T21:21:39Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n+            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            metadataSegmentsByContainer.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (val metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                debugStreamSegmentContainers.get(metadataSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                () -> container.registerSegment(segmentName, segmentLength, isSealed));\n+    }\n+\n+    /**\n+     * Deletes container metadata segment and its Attribute segment from the {@link Storage} for the given container Id.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataAndAttributeSegments(Storage storage, int containerId) {", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5OTQ4Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470899482", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:06:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MDc4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MDg1Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470870857", "bodyText": "This method should return CompletableFuture.", "author": "sachin-j-joshi", "createdAt": "2020-08-14T21:21:50Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Add all segments in the container metadata in a set for each debug segment container instance.\n+        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n+            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n+            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n+        }\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            SegmentProperties currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            metadataSegmentsByContainer.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        for (val metadataSegmentsSetEntry : metadataSegmentsByContainer.entrySet()) {\n+            for (String segmentName : metadataSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                debugStreamSegmentContainers.get(metadataSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT).join();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                () -> container.registerSegment(segmentName, segmentLength, isSealed));\n+    }\n+\n+    /**\n+     * Deletes container metadata segment and its Attribute segment from the {@link Storage} for the given container Id.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataAndAttributeSegments(Storage storage, int containerId) {\n+        Preconditions.checkNotNull(storage);\n+        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n+        deleteSegment(storage, metadataSegmentName);\n+        deleteSegment(storage, attributeSegmentName);\n+    }\n+\n+    /**\n+     * Deletes the segment with given name from the given {@link Storage} instance.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     */\n+    private static void deleteSegment(Storage storage, String segmentName) {", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5OTUxNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470899515", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:07:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MDg1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex a21985291..278ccd8a2 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -75,21 +75,8 @@ public class ContainerRecoveryUtils {\n                 \"debug segment container instance.\");\n \n         log.info(\"Recovery started for all containers...\");\n-        // Add all segments in the container metadata in a set for each debug segment container instance.\n-        Map<Integer, Set<String>> metadataSegmentsByContainer = new HashMap<>();\n-        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n-        for (val debugStreamSegmentContainerEntry : debugStreamSegmentContainers.entrySet()) {\n-            Preconditions.checkNotNull(debugStreamSegmentContainerEntry.getValue());\n-            val tableExtension = debugStreamSegmentContainerEntry.getValue().getExtension(ContainerTableExtension.class);\n-            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n-                    debugStreamSegmentContainerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            Set<String> metadataSegments = new HashSet<>();\n-            keyIterator.forEachRemaining(k ->\n-                    metadataSegments.addAll(k.getEntries().stream()\n-                            .map(entry -> entry.getKey().toString())\n-                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-            metadataSegmentsByContainer.put(debugStreamSegmentContainerEntry.getKey(), metadataSegments);\n-        }\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n \n         SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MjU2Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470872563", "bodyText": "Is this needed?\nDelete constants not used.", "author": "sachin-j-joshi", "createdAt": "2020-08-14T21:26:50Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,304 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+import static io.pravega.segmentstore.server.containers.ContainerRecoveryUtils.recoverAllSegments;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+@Slf4j\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;", "originalCommit": "883da1068638d9dae5e87aea87c92ade5260e15a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDkwMDQzNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r470900437", "bodyText": "Deleted.", "author": "ManishKumarKeshri", "createdAt": "2020-08-14T23:11:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg3MjU2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex e1e6eb163..5ebdd00af 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -72,7 +72,6 @@ public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n     private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n     private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n     private static final int CONTAINER_ID = 1234567;\n-    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n     private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n     private static final int TEST_TIMEOUT_MILLIS = 60 * 1000;\n     private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n"}}, {"oid": "c8b57d9114d856e20ea74811d03fbc186b2d6118", "url": "https://github.com/pravega/pravega/commit/c8b57d9114d856e20ea74811d03fbc186b2d6118", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-14T23:12:04Z", "type": "commit"}, {"oid": "52b45e70886737226d10a7e98e01a70bde420efa", "url": "https://github.com/pravega/pravega/commit/52b45e70886737226d10a7e98e01a70bde420efa", "message": "Removed unnecessary part.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-14T23:50:52Z", "type": "commit"}, {"oid": "3b29e1617cef3a3188a8974608b391cb56fce642", "url": "https://github.com/pravega/pravega/commit/3b29e1617cef3a3188a8974608b391cb56fce642", "message": "Minor changes.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-17T16:27:10Z", "type": "commit"}, {"oid": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "url": "https://github.com/pravega/pravega/commit/f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "message": "CheckStyle.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-17T17:12:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg0NzkzOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471847939", "bodyText": "Replace this with:\nRecovers Segments from the given Storage instance. This is done by:\n1. Listing all Segments from the given Storage instance and partitioning them by their assigned Container Id using the standard {@link StreamSegmentMapper}.\n2. Filtering out all shadow Segments (such as Attribute Segments).\n3. Registering all remaining (external) Segments to the owning Container's {@link MetadataStore}.\n\nThe {@link DebugStreamSegmentContainer} instance(s) that are provided to this method may have some segments already present in their respective {@link MetadataStore}. \n\nAfter the method successfully completes, the following are true:\n- Only the segments which exist in the {@link Storage} will remain in the Container's {@link MetadataStore}.\n- If a Segment exists both in the Container's {@link MetadataStore} and in {@link Storage}, then the information that exists in {@link Storage} (length, sealed) will prevail.\n      \nIf the method fails during execution, the appropriate exception is thrown and the Containers' {@link MetadataStores} may be left in an inconsistent state", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:36:43Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NDg2MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473264860", "bodyText": "Replaced.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:21:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg0NzkzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg0OTE4OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471849188", "bodyText": "For all these methods, do this for the exceptions:\n\nHave them declare that they throw Exception.\nDo not document InterruptedException or ExecutionException.\nFor TimeoutException and IOException please have appropriate descriptions. Required for Futures.get is not of any use for the user.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:41:15Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NDk4NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473264985", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:21:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg0OTE4OA=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDE1Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471850156", "bodyText": "Here you use join but in other methods you use get(Timeout). Please be consistent. If you already use get(Timeout) in one place, you might as well use it everywhere.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:44:54Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NTE0MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473265140", "bodyText": "Using get now.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:21:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDE1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDM1Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471850356", "bodyText": "Loop through all the given containers and verify that they are all there (i.e., no duplicate IDs and that all of the expected Ids are provided). If you get 4 containers, you should expect ids 0 through 3.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:45:34Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDQ0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471850442", "bodyText": "You can do this as a helper method and use a HashSet", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:45:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NTM3MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473265371", "bodyText": "Done. Implemented another method.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:22:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDM1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDUxMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471850513", "bodyText": "get", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:46:10Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NTQ0OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473265448", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:22:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDUxMw=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDU4Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471850587", "bodyText": "Same comment about exceptions as above.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:46:28Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NTU0MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473265540", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDU4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDg5Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471850893", "bodyText": "I am pretty sure that Futures.exceptionallyComposeExpecting unwraps it for you. Please check, and if so, simplify this line.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:47:44Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()\n+     * @throws ExecutionException       Required for Futures.get()\n+     * @throws TimeoutException         Required for Futures.get()\n+     */\n+    private static Map<Integer, Set<String>> getExistingSegments(Map<Integer, DebugStreamSegmentContainer> containerMap,\n+                                                                 ExecutorService executorService)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<Integer, Set<String>> metadataSegmentsMap = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+\n+        // Get all segments for each container entry\n+        for (val containerEntry : containerMap.entrySet()) {\n+            Preconditions.checkNotNull(containerEntry.getValue());\n+            val tableExtension = containerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    containerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Store the segments in a set\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsMap.put(containerEntry.getKey(), metadataSegments);\n+        }\n+        return metadataSegmentsMap;\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NTY4Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473265683", "bodyText": "Yeah. It does. Thanks.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:22:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDg5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTA5MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471851090", "bodyText": "This is an async operation. Where are you waiting for it?\nChange the enclosing thenAccept into a thenCompose and return it.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:48:29Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()\n+     * @throws ExecutionException       Required for Futures.get()\n+     * @throws TimeoutException         Required for Futures.get()\n+     */\n+    private static Map<Integer, Set<String>> getExistingSegments(Map<Integer, DebugStreamSegmentContainer> containerMap,\n+                                                                 ExecutorService executorService)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<Integer, Set<String>> metadataSegmentsMap = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+\n+        // Get all segments for each container entry\n+        for (val containerEntry : containerMap.entrySet()) {\n+            Preconditions.checkNotNull(containerEntry.getValue());\n+            val tableExtension = containerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    containerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Store the segments in a set\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsMap.put(containerEntry.getKey(), metadataSegments);\n+        }\n+        return metadataSegmentsMap;\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NjQwMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473266400", "bodyText": "Changed. Now returning it.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:23:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTA5MA=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTE0NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471851144", "bodyText": "This is also an async operation.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:48:45Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()\n+     * @throws ExecutionException       Required for Futures.get()\n+     * @throws TimeoutException         Required for Futures.get()\n+     */\n+    private static Map<Integer, Set<String>> getExistingSegments(Map<Integer, DebugStreamSegmentContainer> containerMap,\n+                                                                 ExecutorService executorService)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<Integer, Set<String>> metadataSegmentsMap = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+\n+        // Get all segments for each container entry\n+        for (val containerEntry : containerMap.entrySet()) {\n+            Preconditions.checkNotNull(containerEntry.getValue());\n+            val tableExtension = containerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    containerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Store the segments in a set\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsMap.put(containerEntry.getKey(), metadataSegments);\n+        }\n+        return metadataSegmentsMap;\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI2NzQ2MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473267461", "bodyText": "Now returning it.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:25:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTE0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg4OTkyMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r474889920", "bodyText": "Isn't container.registerSegment async? You need to return it too and change thenAccept to thenCompose", "author": "andreipaduroiu", "createdAt": "2020-08-21T19:25:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTE0NA=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTE4Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471851187", "bodyText": "and this.", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:48:55Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()\n+     * @throws ExecutionException       Required for Futures.get()\n+     * @throws TimeoutException         Required for Futures.get()\n+     */\n+    private static Map<Integer, Set<String>> getExistingSegments(Map<Integer, DebugStreamSegmentContainer> containerMap,\n+                                                                 ExecutorService executorService)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<Integer, Set<String>> metadataSegmentsMap = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+\n+        // Get all segments for each container entry\n+        for (val containerEntry : containerMap.entrySet()) {\n+            Preconditions.checkNotNull(containerEntry.getValue());\n+            val tableExtension = containerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    containerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Store the segments in a set\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsMap.put(containerEntry.getKey(), metadataSegments);\n+        }\n+        return metadataSegmentsMap;\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                () -> container.registerSegment(segmentName, segmentLength, isSealed));", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI3NTE0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473275142", "bodyText": "Now returning it, which will be awaited for completion at the place of method call.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:41:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTE4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTI5Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471851292", "bodyText": "no unwrapping?", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:49:15Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()\n+     * @throws ExecutionException       Required for Futures.get()\n+     * @throws TimeoutException         Required for Futures.get()\n+     */\n+    private static Map<Integer, Set<String>> getExistingSegments(Map<Integer, DebugStreamSegmentContainer> containerMap,\n+                                                                 ExecutorService executorService)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<Integer, Set<String>> metadataSegmentsMap = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+\n+        // Get all segments for each container entry\n+        for (val containerEntry : containerMap.entrySet()) {\n+            Preconditions.checkNotNull(containerEntry.getValue());\n+            val tableExtension = containerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    containerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Store the segments in a set\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsMap.put(containerEntry.getKey(), metadataSegments);\n+        }\n+        return metadataSegmentsMap;\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                () -> container.registerSegment(segmentName, segmentLength, isSealed));\n+    }\n+\n+    /**\n+     * Deletes container metadata segment and its Attribute segment from the {@link Storage} for the given container Id.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static CompletableFuture<Void> deleteMetadataAndAttributeSegments(Storage storage, int containerId) {\n+        Preconditions.checkNotNull(storage);\n+        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n+        return deleteSegmentFromStorage(storage, metadataSegmentName)\n+                .thenAccept(x -> deleteSegmentFromStorage(storage, attributeSegmentName));\n+    }\n+\n+    /**\n+     * Deletes the segment with given name from the given {@link Storage} instance. If the segment doesn't exist, it does\n+     * nothing and returns.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     * @return              CompletableFuture which when completed will have the segment deleted. In case segment didn't\n+     *                      exist, a completed future will be returned.\n+     */\n+    private static CompletableFuture<Void> deleteSegmentFromStorage(Storage storage, String segmentName) {\n+        log.info(\"Deleting Segment '{}'\", segmentName);\n+        return Futures.exceptionallyComposeExpecting(\n+                storage.openWrite(segmentName).thenCompose(segmentHandle -> storage.delete(segmentHandle, TIMEOUT)),\n+                ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI3NTIzMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473275233", "bodyText": "Yes. removed.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:41:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTI5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTUyMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r471851520", "bodyText": "use exceptionallyExpecting and return null instead of CompletableFuture.completedFuture(null)", "author": "andreipaduroiu", "createdAt": "2020-08-18T00:49:57Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.stream.Collectors;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for container recovery.\n+ */\n+@Slf4j\n+public class ContainerRecoveryUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+\n+    /**\n+     * This method lists the segments from the given storage instance. It then registers all segments except Attribute\n+     * segments to the container metadata segment(s).\n+     * {@link DebugStreamSegmentContainer} instance(s) are provided to this method which can have some segments already present\n+     * in their respective container metadata segment(s). After the method successfully completes, only the segments which\n+     * existed in the {@link Storage} will remain in the container metadata. All segments which only existed in the container\n+     * metadata or which existed in both container metadata and the storage but with different lengths and/or sealed status,\n+     * will be deleted from the container metadata. If the method fails while execution, appropriate exception is thrown.\n+     * All segments from the storage are listed one by one, then mapped to their corresponding {@link DebugStreamSegmentContainer}\n+     * instances for registering them to container metadata segment.\n+     * @param storage                           A {@link Storage} instance that will be used to list segments from.\n+     * @param debugStreamSegmentContainers      A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                          representing the containers that will be recovered.\n+     * @param executorService                   A thread pool for execution.\n+     * @throws InterruptedException             Required for Futures.get()\n+     * @throws ExecutionException               Required for Futures.get()\n+     * @throws TimeoutException                 Required for Futures.get()\n+     * @throws IOException                      Requited for Storage.listSegments()\n+     */\n+    public static void recoverAllSegments(Storage storage, Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainers,\n+                                          ExecutorService executorService) throws InterruptedException, ExecutionException,\n+            TimeoutException, IOException {\n+        Preconditions.checkNotNull(storage);\n+        Preconditions.checkNotNull(executorService);\n+        Preconditions.checkNotNull(debugStreamSegmentContainers);\n+        Preconditions.checkArgument(debugStreamSegmentContainers.size() > 0, \"There should be at least one \" +\n+                \"debug segment container instance.\");\n+\n+        log.info(\"Recovery started for all containers...\");\n+        // Get all segments in the container metadata for each debug segment container instance.\n+        Map<Integer, Set<String>> existingSegmentsMap = getExistingSegments(debugStreamSegmentContainers, executorService);\n+\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(debugStreamSegmentContainers.size());\n+\n+        Iterator<SegmentProperties> segmentIterator = storage.listSegments();\n+        Preconditions.checkNotNull(segmentIterator);\n+\n+        // Iterate through all segments. Create each one of their using their respective debugSegmentContainer instance.\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        while (segmentIterator.hasNext()) {\n+            val currentSegment = segmentIterator.next();\n+\n+            // skip recovery if the segment is an attribute segment.\n+            if (NameUtils.isAttributeSegment(currentSegment.getName())) {\n+                continue;\n+            }\n+\n+            int containerId = segToConMapper.getContainerId(currentSegment.getName());\n+            existingSegmentsMap.get(containerId).remove(currentSegment.getName());\n+            futures.add(recoverSegment(debugStreamSegmentContainers.get(containerId), currentSegment));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        futures.clear();\n+        // Delete segments which only exist in the container metadata, not in storage.\n+        for (val existingSegmentsSetEntry : existingSegmentsMap.entrySet()) {\n+            for (String segmentName : existingSegmentsSetEntry.getValue()) {\n+                log.info(\"Deleting segment '{}' as it is not in the storage.\", segmentName);\n+                futures.add(debugStreamSegmentContainers.get(existingSegmentsSetEntry.getKey()).deleteStreamSegment(segmentName, TIMEOUT));\n+            }\n+        }\n+        Futures.allOf(futures).join();\n+    }\n+\n+    /**\n+     * The method lists all segments present in the container metadata segments of the given {@link DebugStreamSegmentContainer}\n+     * instances, stores their names by container Id in a map and returns it.\n+     * @param containerMap              A Map of Container Ids to {@link DebugStreamSegmentContainer} instances\n+     *                                  representing the containers to list the segments from.\n+     * @param executorService           A thread pool for execution.\n+     * @return                          A Map of Container Ids to segment names representing all segments present in the\n+     *                                  container metadata segment of a Container.\n+     * @throws InterruptedException     Required for Futures.get()\n+     * @throws ExecutionException       Required for Futures.get()\n+     * @throws TimeoutException         Required for Futures.get()\n+     */\n+    private static Map<Integer, Set<String>> getExistingSegments(Map<Integer, DebugStreamSegmentContainer> containerMap,\n+                                                                 ExecutorService executorService)\n+            throws InterruptedException, ExecutionException, TimeoutException {\n+        Map<Integer, Set<String>> metadataSegmentsMap = new HashMap<>();\n+        val args = IteratorArgs.builder().fetchTimeout(TIMEOUT).build();\n+\n+        // Get all segments for each container entry\n+        for (val containerEntry : containerMap.entrySet()) {\n+            Preconditions.checkNotNull(containerEntry.getValue());\n+            val tableExtension = containerEntry.getValue().getExtension(ContainerTableExtension.class);\n+            val keyIterator = tableExtension.keyIterator(getMetadataSegmentName(\n+                    containerEntry.getKey()), args).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+            // Store the segments in a set\n+            Set<String> metadataSegments = new HashSet<>();\n+            keyIterator.forEachRemaining(k ->\n+                    metadataSegments.addAll(k.getEntries().stream()\n+                            .map(entry -> entry.getKey().toString())\n+                            .collect(Collectors.toSet())), executorService).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            metadataSegmentsMap.put(containerEntry.getKey(), metadataSegments);\n+        }\n+        return metadataSegmentsMap;\n+    }\n+\n+    /**\n+     * This method takes a {@link DebugStreamSegmentContainer} instance and a {@link SegmentProperties} object as arguments\n+     * and takes one of the following actions:\n+     * 1. If the segment is present in the container metadata and its length or sealed status or both doesn't match with the\n+     * given {@link SegmentProperties}, then it is deleted from there and registered using the properties from the given\n+     * {@link SegmentProperties} instance.\n+     * 2. If the segment is absent in the container metadata, then it is registered using the properties from the given\n+     * {@link SegmentProperties}.\n+     * @param container         A {@link DebugStreamSegmentContainer} instance for registering the given segment and checking\n+     *                          its existence in the container metadata.\n+     * @param storageSegment    A {@link SegmentProperties} instance which has properties of the segment to be registered.\n+     * @return                  CompletableFuture which when completed will have the segment registered on to the container\n+     *                          metadata.\n+     */\n+    private static CompletableFuture<Void> recoverSegment(DebugStreamSegmentContainer container, SegmentProperties storageSegment) {\n+        Preconditions.checkNotNull(container);\n+        Preconditions.checkNotNull(storageSegment);\n+        long segmentLength = storageSegment.getLength();\n+        boolean isSealed = storageSegment.isSealed();\n+        String segmentName = storageSegment.getName();\n+\n+        log.info(\"Registering: {}, {}, {}.\", segmentName, segmentLength, isSealed);\n+        return Futures.exceptionallyComposeExpecting(\n+                container.getStreamSegmentInfo(storageSegment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            if (segmentLength != e.getLength() || isSealed != e.isSealed()) {\n+                                container.metadataStore.deleteSegment(segmentName, TIMEOUT)\n+                                        .thenAccept(x -> container.registerSegment(segmentName, segmentLength, isSealed));\n+                            }\n+                        }), ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException,\n+                () -> container.registerSegment(segmentName, segmentLength, isSealed));\n+    }\n+\n+    /**\n+     * Deletes container metadata segment and its Attribute segment from the {@link Storage} for the given container Id.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static CompletableFuture<Void> deleteMetadataAndAttributeSegments(Storage storage, int containerId) {\n+        Preconditions.checkNotNull(storage);\n+        String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+        String attributeSegmentName = NameUtils.getAttributeSegmentName(metadataSegmentName);\n+        return deleteSegmentFromStorage(storage, metadataSegmentName)\n+                .thenAccept(x -> deleteSegmentFromStorage(storage, attributeSegmentName));\n+    }\n+\n+    /**\n+     * Deletes the segment with given name from the given {@link Storage} instance. If the segment doesn't exist, it does\n+     * nothing and returns.\n+     * @param storage       A {@link Storage} instance to delete the segments from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     * @return              CompletableFuture which when completed will have the segment deleted. In case segment didn't\n+     *                      exist, a completed future will be returned.\n+     */\n+    private static CompletableFuture<Void> deleteSegmentFromStorage(Storage storage, String segmentName) {\n+        log.info(\"Deleting Segment '{}'\", segmentName);\n+        return Futures.exceptionallyComposeExpecting(", "originalCommit": "f4bf8fdcd2c1b88e135e60c4f131db873fc1f652", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI3NTI3OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r473275279", "bodyText": "Ok.", "author": "ManishKumarKeshri", "createdAt": "2020-08-19T19:41:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MTUyMA=="}], "type": "inlineReview", "revised_code": {"commit": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\nindex 4f3a4bcee..e9336e8e3 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ContainerRecoveryUtils.java\n\n@@ -31,10 +31,8 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.stream.Collectors;\n \n import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n"}}, {"oid": "70dbedb52dabd1bde2de164ef0556ff493ac4da0", "url": "https://github.com/pravega/pravega/commit/70dbedb52dabd1bde2de164ef0556ff493ac4da0", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-19T19:04:31Z", "type": "commit"}, {"oid": "471b70c3a5d371b24742bb11ae57c748e483e28a", "url": "https://github.com/pravega/pravega/commit/471b70c3a5d371b24742bb11ae57c748e483e28a", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-19T19:41:34Z", "type": "commit"}, {"oid": "5fc116535b0b5d84b2424c29bf439483b188d403", "url": "https://github.com/pravega/pravega/commit/5fc116535b0b5d84b2424c29bf439483b188d403", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-19T19:46:02Z", "type": "commit"}, {"oid": "bd3d372dabaa4f76029efa3cccd29373bdb6bf72", "url": "https://github.com/pravega/pravega/commit/bd3d372dabaa4f76029efa3cccd29373bdb6bf72", "message": "Checkstyle.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-19T19:46:59Z", "type": "commit"}, {"oid": "28c044e2a3763528f4455611f301d739e62f329d", "url": "https://github.com/pravega/pravega/commit/28c044e2a3763528f4455611f301d739e62f329d", "message": "Minor changes in Javadoc.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-20T01:16:15Z", "type": "commit"}, {"oid": "1a8f85232cb079d2dcd4f5de012e17848784bc94", "url": "https://github.com/pravega/pravega/commit/1a8f85232cb079d2dcd4f5de012e17848784bc94", "message": "Fixing last comment.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-21T19:34:46Z", "type": "commit"}, {"oid": "3ff6a886216c121c1acc760926915426b5ee0da3", "url": "https://github.com/pravega/pravega/commit/3ff6a886216c121c1acc760926915426b5ee0da3", "message": "Minor changes.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-21T19:47:09Z", "type": "commit"}, {"oid": "49b58a722e43f6e67bc6353e84efd5cbe25f9dda", "url": "https://github.com/pravega/pravega/commit/49b58a722e43f6e67bc6353e84efd5cbe25f9dda", "message": "segmentContainer in recovery mode.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-04-21T18:16:34Z", "type": "commit"}, {"oid": "30f4fc64b3abd3e8d036490f3273d9c8bb976ead", "url": "https://github.com/pravega/pravega/commit/30f4fc64b3abd3e8d036490f3273d9c8bb976ead", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-04-22T01:43:18Z", "type": "commit"}, {"oid": "dcc15c2a9021d3b7b7e3e21642de124d895cd3df", "url": "https://github.com/pravega/pravega/commit/dcc15c2a9021d3b7b7e3e21642de124d895cd3df", "message": "Fixing build fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-04-22T02:34:24Z", "type": "commit"}, {"oid": "dbe7f53387c946084b52b555c959dc20d1596637", "url": "https://github.com/pravega/pravega/commit/dbe7f53387c946084b52b555c959dc20d1596637", "message": "Merge branch 'issue-4670-segment-continer-recovery-mode' of https://github.com/ManishKumarKeshri/pravega into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-04-22T02:35:40Z", "type": "commit"}, {"oid": "8a38faa88e8d1463eafdb90c353d1053a79ec515", "url": "https://github.com/pravega/pravega/commit/8a38faa88e8d1463eafdb90c353d1053a79ec515", "message": "Improving coverage.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-05-01T05:15:06Z", "type": "commit"}, {"oid": "f6c31a51a2d01ecac3af03e77fb2daabb2001a4b", "url": "https://github.com/pravega/pravega/commit/f6c31a51a2d01ecac3af03e77fb2daabb2001a4b", "message": "Fixing build fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-05-01T07:56:37Z", "type": "commit"}, {"oid": "03d8ed9eaad78d5032a2b8871609d3f248522a34", "url": "https://github.com/pravega/pravega/commit/03d8ed9eaad78d5032a2b8871609d3f248522a34", "message": "Code Coverage.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-05-01T09:29:43Z", "type": "commit"}, {"oid": "b96964abcb0db52a8098cc0ef7246cfe33fdadda", "url": "https://github.com/pravega/pravega/commit/b96964abcb0db52a8098cc0ef7246cfe33fdadda", "message": "Updating tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-05-05T07:35:53Z", "type": "commit"}, {"oid": "e846138bd31072996be66f42d36cc856b1a0db10", "url": "https://github.com/pravega/pravega/commit/e846138bd31072996be66f42d36cc856b1a0db10", "message": "Fixing Checkstyle fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-05-05T07:46:45Z", "type": "commit"}, {"oid": "8b849140c34c958f3b1a7d32f057965d8cce5eee", "url": "https://github.com/pravega/pravega/commit/8b849140c34c958f3b1a7d32f057965d8cce5eee", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-05-07T22:14:02Z", "type": "commit"}, {"oid": "8d62b83f8281984ad5c74f15ad044d5f89ebfdc5", "url": "https://github.com/pravega/pravega/commit/8d62b83f8281984ad5c74f15ad044d5f89ebfdc5", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-05-26T16:23:01Z", "type": "commit"}, {"oid": "fa8dfe5f5ebc8a0a4654d50e75a3311854815017", "url": "https://github.com/pravega/pravega/commit/fa8dfe5f5ebc8a0a4654d50e75a3311854815017", "message": "Updating MetadataStore.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-22T05:54:16Z", "type": "commit"}, {"oid": "c85fcd6bf6b78c014097c6a8d5fa1e28ac25e3fb", "url": "https://github.com/pravega/pravega/commit/c85fcd6bf6b78c014097c6a8d5fa1e28ac25e3fb", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-06-22T07:06:30Z", "type": "commit"}, {"oid": "8bdf1471c9b0061eed2c55d8c3f9917f91e3c75a", "url": "https://github.com/pravega/pravega/commit/8bdf1471c9b0061eed2c55d8c3f9917f91e3c75a", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-06-22T16:03:20Z", "type": "commit"}, {"oid": "8a490864c44f85e3b12b03ca03ea48bdcdc3e790", "url": "https://github.com/pravega/pravega/commit/8a490864c44f85e3b12b03ca03ea48bdcdc3e790", "message": "ListAllSegments and create Segments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-23T07:57:18Z", "type": "commit"}, {"oid": "350181f16f6254d28b45aad03558d7541679aadd", "url": "https://github.com/pravega/pravega/commit/350181f16f6254d28b45aad03558d7541679aadd", "message": "Adding tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-24T06:47:43Z", "type": "commit"}, {"oid": "afd38325714e9e565bbb361836b6fdb1933cfcbc", "url": "https://github.com/pravega/pravega/commit/afd38325714e9e565bbb361836b6fdb1933cfcbc", "message": "Updating StreamSegmentStoreTestBase\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-25T07:38:41Z", "type": "commit"}, {"oid": "a6d50e30bafdbe9bad03d8a17b75ab7e63680c32", "url": "https://github.com/pravega/pravega/commit/a6d50e30bafdbe9bad03d8a17b75ab7e63680c32", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-26T04:12:57Z", "type": "commit"}, {"oid": "6d0bdbad9b08ed33778ba1aee78a909070211a97", "url": "https://github.com/pravega/pravega/commit/6d0bdbad9b08ed33778ba1aee78a909070211a97", "message": "Updating\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-26T06:52:55Z", "type": "commit"}, {"oid": "732a9de0ded3dbd0933678a0af0a1ce97fb0c019", "url": "https://github.com/pravega/pravega/commit/732a9de0ded3dbd0933678a0af0a1ce97fb0c019", "message": "Removing changes made in List Segments of ExtendedS3Storage.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-26T07:17:37Z", "type": "commit"}, {"oid": "07a50c9b9fcdc01a2e32eeeedc11e14bccada129", "url": "https://github.com/pravega/pravega/commit/07a50c9b9fcdc01a2e32eeeedc11e14bccada129", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-26T18:24:14Z", "type": "commit"}, {"oid": "3ac607c6154a82ec2c2a449038c413d8574236a8", "url": "https://github.com/pravega/pravega/commit/3ac607c6154a82ec2c2a449038c413d8574236a8", "message": "Updating integration test.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-29T03:28:57Z", "type": "commit"}, {"oid": "634e6f7688c14b7d72b7214f9f062edff38b8619", "url": "https://github.com/pravega/pravega/commit/634e6f7688c14b7d72b7214f9f062edff38b8619", "message": "Adding layer 2 tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-29T05:26:39Z", "type": "commit"}, {"oid": "bb23e5b0cd2ba77c0ff1aa00ecbe0cb056a1e31c", "url": "https://github.com/pravega/pravega/commit/bb23e5b0cd2ba77c0ff1aa00ecbe0cb056a1e31c", "message": "Updating tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-29T05:40:39Z", "type": "commit"}, {"oid": "385a664082589ec43bd2b387500411bccbb33f48", "url": "https://github.com/pravega/pravega/commit/385a664082589ec43bd2b387500411bccbb33f48", "message": "Checkstyle.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-29T16:48:17Z", "type": "commit"}, {"oid": "b52e061a31da9b6842e314c4454fdcff4c6b6ed9", "url": "https://github.com/pravega/pravega/commit/b52e061a31da9b6842e314c4454fdcff4c6b6ed9", "message": "Updating Integration tests and checkstyle fails.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-29T19:39:43Z", "type": "commit"}, {"oid": "938592e807940c94b54b84e645524009836b63d5", "url": "https://github.com/pravega/pravega/commit/938592e807940c94b54b84e645524009836b63d5", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-29T20:11:29Z", "type": "commit"}, {"oid": "88b5870659f211f70bd9a982df6bcf3e0991c736", "url": "https://github.com/pravega/pravega/commit/88b5870659f211f70bd9a982df6bcf3e0991c736", "message": "Fixing spotbugs failure.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T04:00:05Z", "type": "commit"}, {"oid": "90e1a94463649e301bf4b1252c0ee917477cbf1b", "url": "https://github.com/pravega/pravega/commit/90e1a94463649e301bf4b1252c0ee917477cbf1b", "message": "Fixing build fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T05:33:16Z", "type": "commit"}, {"oid": "1bf1739ca2df2aae2302fc771414909b551c3832", "url": "https://github.com/pravega/pravega/commit/1bf1739ca2df2aae2302fc771414909b551c3832", "message": "Fixing build fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T06:31:52Z", "type": "commit"}, {"oid": "259f22d85dadbb2d85787849af4f80b991fa0978", "url": "https://github.com/pravega/pravega/commit/259f22d85dadbb2d85787849af4f80b991fa0978", "message": "Adding waitForSegmentsInStorage.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T18:18:26Z", "type": "commit"}, {"oid": "cbb7f0f47701d1d710d98b5977e42041f6757769", "url": "https://github.com/pravega/pravega/commit/cbb7f0f47701d1d710d98b5977e42041f6757769", "message": "Updating TableStoreWrapper\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T18:28:09Z", "type": "commit"}, {"oid": "3fbca73b27e755d9e091451152ee9deaf2edaf5d", "url": "https://github.com/pravega/pravega/commit/3fbca73b27e755d9e091451152ee9deaf2edaf5d", "message": "Updating\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T19:52:32Z", "type": "commit"}, {"oid": "66ad6016b5a93aa5f0e9c565550804cab61c9c76", "url": "https://github.com/pravega/pravega/commit/66ad6016b5a93aa5f0e9c565550804cab61c9c76", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-06-30T19:59:30Z", "type": "commit"}, {"oid": "bce3d8f58ccaaf96cb1eeb1161debf0a4539fd94", "url": "https://github.com/pravega/pravega/commit/bce3d8f58ccaaf96cb1eeb1161debf0a4539fd94", "message": "Updating TableStoreWrapper\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-06-30T20:13:37Z", "type": "commit"}, {"oid": "194162ce31816e87d55077a66c7131e16b4e9630", "url": "https://github.com/pravega/pravega/commit/194162ce31816e87d55077a66c7131e16b4e9630", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T02:50:01Z", "type": "commit"}, {"oid": "72356b5007083f73db00d847dead7ca9403ccbfc", "url": "https://github.com/pravega/pravega/commit/72356b5007083f73db00d847dead7ca9403ccbfc", "message": "Updating tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T08:07:53Z", "type": "commit"}, {"oid": "d97d37202a06d4ba5d9e9487f3f4de614722548c", "url": "https://github.com/pravega/pravega/commit/d97d37202a06d4ba5d9e9487f3f4de614722548c", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T20:33:44Z", "type": "commit"}, {"oid": "f89a4aa867596fee8fdadc1c8cb64dbc6fa50738", "url": "https://github.com/pravega/pravega/commit/f89a4aa867596fee8fdadc1c8cb64dbc6fa50738", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-07-01T21:00:15Z", "type": "commit"}, {"oid": "a8267dbdf3b38c887e14b24458017a28ced62bf1", "url": "https://github.com/pravega/pravega/commit/a8267dbdf3b38c887e14b24458017a28ced62bf1", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T21:43:47Z", "type": "commit"}, {"oid": "64d34a2b4adc28e9faf5f030d2ef982d7389a2ff", "url": "https://github.com/pravega/pravega/commit/64d34a2b4adc28e9faf5f030d2ef982d7389a2ff", "message": "Merge branch 'issue-4670-segment-continer-recovery-mode' of https://github.com/ManishKumarKeshri/pravega into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-07-01T21:44:30Z", "type": "commit"}, {"oid": "da2321c647d33031de02cc47788cea564193d95c", "url": "https://github.com/pravega/pravega/commit/da2321c647d33031de02cc47788cea564193d95c", "message": "Updating integration test.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T22:43:19Z", "type": "commit"}, {"oid": "fdd45675c6185b84eeb6284915f4e244fba7f867", "url": "https://github.com/pravega/pravega/commit/fdd45675c6185b84eeb6284915f4e244fba7f867", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T22:52:52Z", "type": "commit"}, {"oid": "709d12cd4a47cdbdbb8b0357ae034e259bb93d3b", "url": "https://github.com/pravega/pravega/commit/709d12cd4a47cdbdbb8b0357ae034e259bb93d3b", "message": "Updating DataRecoveryTestUtils\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T23:38:07Z", "type": "commit"}, {"oid": "e3e8e58cbcb1947a4c49d28bc0300ce746150304", "url": "https://github.com/pravega/pravega/commit/e3e8e58cbcb1947a4c49d28bc0300ce746150304", "message": "Updating checkstyle fail\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-01T23:43:25Z", "type": "commit"}, {"oid": "f5476478596f32300b76dd79861ea228dcb3a82a", "url": "https://github.com/pravega/pravega/commit/f5476478596f32300b76dd79861ea228dcb3a82a", "message": "Updating time out for integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-02T00:41:28Z", "type": "commit"}, {"oid": "530979f40c4116aa13ca1ed13f93f0dace0c7cbf", "url": "https://github.com/pravega/pravega/commit/530979f40c4116aa13ca1ed13f93f0dace0c7cbf", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-02T03:33:39Z", "type": "commit"}, {"oid": "7673be67d900e36297518f894dbb760cece7ada4", "url": "https://github.com/pravega/pravega/commit/7673be67d900e36297518f894dbb760cece7ada4", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-02T07:51:48Z", "type": "commit"}, {"oid": "05305614d021a818e277c2ab3524bebaa2b8a69a", "url": "https://github.com/pravega/pravega/commit/05305614d021a818e277c2ab3524bebaa2b8a69a", "message": "Updating integration tests with BookKeeperLogFactory changes.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-02T19:02:32Z", "type": "commit"}, {"oid": "e84321e3fee284e89889a162ceb5a3f9b6f618cf", "url": "https://github.com/pravega/pravega/commit/e84321e3fee284e89889a162ceb5a3f9b6f618cf", "message": "Updating\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-02T21:01:05Z", "type": "commit"}, {"oid": "65dbdedeb31d027a36d51181344a0914d6a6bdde", "url": "https://github.com/pravega/pravega/commit/65dbdedeb31d027a36d51181344a0914d6a6bdde", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-06T16:41:34Z", "type": "commit"}, {"oid": "1fff6566cd29d30d3ceddd35035d013e3b33b52f", "url": "https://github.com/pravega/pravega/commit/1fff6566cd29d30d3ceddd35035d013e3b33b52f", "message": "Updating integration tests - BK-ZK closing.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-06T16:49:52Z", "type": "commit"}, {"oid": "dce5e38bb2231a73765b6bcae62366cf57d90935", "url": "https://github.com/pravega/pravega/commit/dce5e38bb2231a73765b6bcae62366cf57d90935", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-06T18:16:28Z", "type": "commit"}, {"oid": "288321f68d06a20f526a48e695f027a6e7340354", "url": "https://github.com/pravega/pravega/commit/288321f68d06a20f526a48e695f027a6e7340354", "message": "Updating integration tests with checkstyle and namespace.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-06T20:15:28Z", "type": "commit"}, {"oid": "3f3a3b5084847a08434f44a3f3db960fa850cf54", "url": "https://github.com/pravega/pravega/commit/3f3a3b5084847a08434f44a3f3db960fa850cf54", "message": "Changing log level.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-06T20:17:32Z", "type": "commit"}, {"oid": "ca97a45a07458e5a26c1b29e4aed02be6d5dc689", "url": "https://github.com/pravega/pravega/commit/ca97a45a07458e5a26c1b29e4aed02be6d5dc689", "message": "Updating close(s) in integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T06:34:03Z", "type": "commit"}, {"oid": "5bb72ec1b0322810f10a06f25a2e04f0894de0b5", "url": "https://github.com/pravega/pravega/commit/5bb72ec1b0322810f10a06f25a2e04f0894de0b5", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T07:06:09Z", "type": "commit"}, {"oid": "c5ab80498a1bc800e956cbaa7bc16fd3241d01c0", "url": "https://github.com/pravega/pravega/commit/c5ab80498a1bc800e956cbaa7bc16fd3241d01c0", "message": "Updating checksytle fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T08:00:53Z", "type": "commit"}, {"oid": "e074c2fefdae5c852a7c49cbdaa47f643d180ac7", "url": "https://github.com/pravega/pravega/commit/e074c2fefdae5c852a7c49cbdaa47f643d180ac7", "message": "Updating Null pointer exception.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T16:12:47Z", "type": "commit"}, {"oid": "ca47a29ffd992ab101c29c3fa66f29678f81c9d3", "url": "https://github.com/pravega/pravega/commit/ca47a29ffd992ab101c29c3fa66f29678f81c9d3", "message": "Updating integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T17:33:34Z", "type": "commit"}, {"oid": "74fba6b4fffb1d23af1bc1285086d1a152f1e9e6", "url": "https://github.com/pravega/pravega/commit/74fba6b4fffb1d23af1bc1285086d1a152f1e9e6", "message": "Update integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T17:45:08Z", "type": "commit"}, {"oid": "c57dc01c2190fe446c81c7071763db3cb82237b4", "url": "https://github.com/pravega/pravega/commit/c57dc01c2190fe446c81c7071763db3cb82237b4", "message": "Update integration tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T18:03:36Z", "type": "commit"}, {"oid": "a708502f5c7cc0a53bb8d57279a95c18f6b0ce0a", "url": "https://github.com/pravega/pravega/commit/a708502f5c7cc0a53bb8d57279a95c18f6b0ce0a", "message": "Update tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T18:18:23Z", "type": "commit"}, {"oid": "ea9ba4d4854ea00bb9da94601930aa9b0db21732", "url": "https://github.com/pravega/pravega/commit/ea9ba4d4854ea00bb9da94601930aa9b0db21732", "message": "Adding zkTestServer.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T19:51:56Z", "type": "commit"}, {"oid": "f96110e70868e832fc96d1f1b9cef1f2467184dd", "url": "https://github.com/pravega/pravega/commit/f96110e70868e832fc96d1f1b9cef1f2467184dd", "message": "Remove sleep.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-07T20:46:44Z", "type": "commit"}, {"oid": "c8631f3ef4149138b734d9a483fe4528eee6d3b9", "url": "https://github.com/pravega/pravega/commit/c8631f3ef4149138b734d9a483fe4528eee6d3b9", "message": "Updating comments and tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T04:44:21Z", "type": "commit"}, {"oid": "8449515e1b90474c0a9a7c73a07c0bf688f44340", "url": "https://github.com/pravega/pravega/commit/8449515e1b90474c0a9a7c73a07c0bf688f44340", "message": "Refactoring.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T05:55:34Z", "type": "commit"}, {"oid": "a380b63832a916a46bdd32d78110aa82665884cf", "url": "https://github.com/pravega/pravega/commit/a380b63832a916a46bdd32d78110aa82665884cf", "message": "Updating tests.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T07:41:58Z", "type": "commit"}, {"oid": "d9243701fba3febae2a0eea9e14ec66ba62de5c8", "url": "https://github.com/pravega/pravega/commit/d9243701fba3febae2a0eea9e14ec66ba62de5c8", "message": "Update.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T15:52:05Z", "type": "commit"}, {"oid": "11a24df6ea92420b3a38ab0f549478c30719fffe", "url": "https://github.com/pravega/pravega/commit/11a24df6ea92420b3a38ab0f549478c30719fffe", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-07-08T16:26:47Z", "type": "commit"}, {"oid": "099d36e3496a9c90928eaff44d20c97418868c71", "url": "https://github.com/pravega/pravega/commit/099d36e3496a9c90928eaff44d20c97418868c71", "message": "Merge conflicts.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T16:34:16Z", "type": "commit"}, {"oid": "8c1e1439c6be325943aeba9f2fcf28863c9ffcbe", "url": "https://github.com/pravega/pravega/commit/8c1e1439c6be325943aeba9f2fcf28863c9ffcbe", "message": "Failures due to merge.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T17:24:08Z", "type": "commit"}, {"oid": "a44f06a9e86ab1664e0825d5a514d0d7868edf7a", "url": "https://github.com/pravega/pravega/commit/a44f06a9e86ab1664e0825d5a514d0d7868edf7a", "message": "Updating no. of threads in starting BookKeeperLogFactory.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T20:12:12Z", "type": "commit"}, {"oid": "4e00e78f61e2ba6ec02aa6024584a3bfb17a57ae", "url": "https://github.com/pravega/pravega/commit/4e00e78f61e2ba6ec02aa6024584a3bfb17a57ae", "message": "Update.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-08T20:27:13Z", "type": "commit"}, {"oid": "886737a9c1d8c340dfd203ca4885a9f82ec82da6", "url": "https://github.com/pravega/pravega/commit/886737a9c1d8c340dfd203ca4885a9f82ec82da6", "message": "Merge branch 'master' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-07-09T17:48:25Z", "type": "commit"}, {"oid": "e332e2ab2477a2ce0872e180daadd29c0c77ecec", "url": "https://github.com/pravega/pravega/commit/e332e2ab2477a2ce0872e180daadd29c0c77ecec", "message": "Removing Test.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-09T21:32:07Z", "type": "commit"}, {"oid": "0938804ca2b19541bee6908f60c9ecbfc0db5301", "url": "https://github.com/pravega/pravega/commit/0938804ca2b19541bee6908f60c9ecbfc0db5301", "message": "Small changes.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-09T22:22:46Z", "type": "commit"}, {"oid": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "url": "https://github.com/pravega/pravega/commit/43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "message": "Minor changes in integration test.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-17T05:30:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4ODY1Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456588652", "bodyText": "This class shouldn't be in contracts. Move it to wherever you have your DebugSegmentContainer.", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:51:46Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.contracts;\n+\n+import io.pravega.common.util.BufferView;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n+ */\n+public class StreamSegmentStoreWrapper implements StreamSegmentStore {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NDY2Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459754662", "bodyText": "Combined with TableStore to implement a single wrapper and moved it to segmenstore/server/tests.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:06:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4ODY1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java b/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\ndeleted file mode 100644\nindex 3dea6435b..000000000\n--- a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.contracts;\n-\n-import io.pravega.common.util.BufferView;\n-import lombok.AccessLevel;\n-import lombok.Getter;\n-\n-import java.time.Duration;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.CompletableFuture;\n-\n-/**\n- * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n- */\n-public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n-\n-    private final StreamSegmentStore streamSegmentStore;\n-\n-    @Getter(AccessLevel.PUBLIC)\n-    private HashSet<String> segments;\n-\n-    public StreamSegmentStoreWrapper(StreamSegmentStore streamSegmentStore) {\n-        this.streamSegmentStore = streamSegmentStore;\n-        this.segments = new HashSet<>();\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, BufferView data, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, long offset, BufferView data, Collection<AttributeUpdate> attributeUpdates,\n-                                          Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, offset, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> updateAttributes(String streamSegmentName, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.updateAttributes(streamSegmentName, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Map<UUID, Long>> getAttributes(String streamSegmentName, Collection<UUID> attributeIds, boolean cache, Duration timeout) {\n-        return this.streamSegmentStore.getAttributes(streamSegmentName, attributeIds, cache, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<ReadResult> read(String streamSegmentName, long offset, int maxLength, Duration timeout) {\n-        return this.streamSegmentStore.read(streamSegmentName, offset, maxLength, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.getStreamSegmentInfo(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, Collection<AttributeUpdate> attributes, Duration timeout) {\n-        segments.add(streamSegmentName); // Add the segmentName to the set\n-        return this.streamSegmentStore.createStreamSegment(streamSegmentName, attributes, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<MergeStreamSegmentResult> mergeStreamSegment(String targetStreamSegment, String sourceStreamSegment, Duration timeout) {\n-        return this.streamSegmentStore.mergeStreamSegment(targetStreamSegment, sourceStreamSegment, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> sealStreamSegment(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.sealStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> deleteStreamSegment(String streamSegmentName, Duration timeout) {\n-        if (segments.contains(streamSegmentName)) { // Remove the segmentName from the set\n-            segments.remove(streamSegmentName);\n-        }\n-        return this.streamSegmentStore.deleteStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> truncateStreamSegment(String streamSegmentName, long offset, Duration timeout) {\n-        return this.streamSegmentStore.truncateStreamSegment(streamSegmentName, offset, timeout);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4ODg4OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456588889", "bodyText": "Make this final\nMake it a ConcurrentHashMap", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:52:16Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.contracts;\n+\n+import io.pravega.common.util.BufferView;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n+ */\n+public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n+\n+    private final StreamSegmentStore streamSegmentStore;\n+\n+    @Getter(AccessLevel.PUBLIC)\n+    private HashSet<String> segments;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NDczMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459754730", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:06:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4ODg4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java b/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\ndeleted file mode 100644\nindex 3dea6435b..000000000\n--- a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.contracts;\n-\n-import io.pravega.common.util.BufferView;\n-import lombok.AccessLevel;\n-import lombok.Getter;\n-\n-import java.time.Duration;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.CompletableFuture;\n-\n-/**\n- * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n- */\n-public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n-\n-    private final StreamSegmentStore streamSegmentStore;\n-\n-    @Getter(AccessLevel.PUBLIC)\n-    private HashSet<String> segments;\n-\n-    public StreamSegmentStoreWrapper(StreamSegmentStore streamSegmentStore) {\n-        this.streamSegmentStore = streamSegmentStore;\n-        this.segments = new HashSet<>();\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, BufferView data, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, long offset, BufferView data, Collection<AttributeUpdate> attributeUpdates,\n-                                          Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, offset, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> updateAttributes(String streamSegmentName, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.updateAttributes(streamSegmentName, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Map<UUID, Long>> getAttributes(String streamSegmentName, Collection<UUID> attributeIds, boolean cache, Duration timeout) {\n-        return this.streamSegmentStore.getAttributes(streamSegmentName, attributeIds, cache, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<ReadResult> read(String streamSegmentName, long offset, int maxLength, Duration timeout) {\n-        return this.streamSegmentStore.read(streamSegmentName, offset, maxLength, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.getStreamSegmentInfo(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, Collection<AttributeUpdate> attributes, Duration timeout) {\n-        segments.add(streamSegmentName); // Add the segmentName to the set\n-        return this.streamSegmentStore.createStreamSegment(streamSegmentName, attributes, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<MergeStreamSegmentResult> mergeStreamSegment(String targetStreamSegment, String sourceStreamSegment, Duration timeout) {\n-        return this.streamSegmentStore.mergeStreamSegment(targetStreamSegment, sourceStreamSegment, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> sealStreamSegment(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.sealStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> deleteStreamSegment(String streamSegmentName, Duration timeout) {\n-        if (segments.contains(streamSegmentName)) { // Remove the segmentName from the set\n-            segments.remove(streamSegmentName);\n-        }\n-        return this.streamSegmentStore.deleteStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> truncateStreamSegment(String streamSegmentName, long offset, Duration timeout) {\n-        return this.streamSegmentStore.truncateStreamSegment(streamSegmentName, offset, timeout);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4OTMzNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456589337", "bodyText": "You risk adding this even if the below call failed. Add this as a thenRun callback to the createStreamSegment Future below.", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:53:04Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.contracts;\n+\n+import io.pravega.common.util.BufferView;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n+ */\n+public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n+\n+    private final StreamSegmentStore streamSegmentStore;\n+\n+    @Getter(AccessLevel.PUBLIC)\n+    private HashSet<String> segments;\n+\n+    public StreamSegmentStoreWrapper(StreamSegmentStore streamSegmentStore) {\n+        this.streamSegmentStore = streamSegmentStore;\n+        this.segments = new HashSet<>();\n+    }\n+\n+    @Override\n+    public CompletableFuture<Long> append(String streamSegmentName, BufferView data, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n+        return this.streamSegmentStore.append(streamSegmentName, data, attributeUpdates, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Long> append(String streamSegmentName, long offset, BufferView data, Collection<AttributeUpdate> attributeUpdates,\n+                                          Duration timeout) {\n+        return this.streamSegmentStore.append(streamSegmentName, offset, data, attributeUpdates, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> updateAttributes(String streamSegmentName, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n+        return this.streamSegmentStore.updateAttributes(streamSegmentName, attributeUpdates, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Map<UUID, Long>> getAttributes(String streamSegmentName, Collection<UUID> attributeIds, boolean cache, Duration timeout) {\n+        return this.streamSegmentStore.getAttributes(streamSegmentName, attributeIds, cache, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<ReadResult> read(String streamSegmentName, long offset, int maxLength, Duration timeout) {\n+        return this.streamSegmentStore.read(streamSegmentName, offset, maxLength, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n+        return this.streamSegmentStore.getStreamSegmentInfo(streamSegmentName, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, Collection<AttributeUpdate> attributes, Duration timeout) {\n+        segments.add(streamSegmentName); // Add the segmentName to the set", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NDgwMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459754800", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4OTMzNw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java b/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\ndeleted file mode 100644\nindex 3dea6435b..000000000\n--- a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.contracts;\n-\n-import io.pravega.common.util.BufferView;\n-import lombok.AccessLevel;\n-import lombok.Getter;\n-\n-import java.time.Duration;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.CompletableFuture;\n-\n-/**\n- * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n- */\n-public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n-\n-    private final StreamSegmentStore streamSegmentStore;\n-\n-    @Getter(AccessLevel.PUBLIC)\n-    private HashSet<String> segments;\n-\n-    public StreamSegmentStoreWrapper(StreamSegmentStore streamSegmentStore) {\n-        this.streamSegmentStore = streamSegmentStore;\n-        this.segments = new HashSet<>();\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, BufferView data, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, long offset, BufferView data, Collection<AttributeUpdate> attributeUpdates,\n-                                          Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, offset, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> updateAttributes(String streamSegmentName, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.updateAttributes(streamSegmentName, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Map<UUID, Long>> getAttributes(String streamSegmentName, Collection<UUID> attributeIds, boolean cache, Duration timeout) {\n-        return this.streamSegmentStore.getAttributes(streamSegmentName, attributeIds, cache, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<ReadResult> read(String streamSegmentName, long offset, int maxLength, Duration timeout) {\n-        return this.streamSegmentStore.read(streamSegmentName, offset, maxLength, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.getStreamSegmentInfo(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, Collection<AttributeUpdate> attributes, Duration timeout) {\n-        segments.add(streamSegmentName); // Add the segmentName to the set\n-        return this.streamSegmentStore.createStreamSegment(streamSegmentName, attributes, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<MergeStreamSegmentResult> mergeStreamSegment(String targetStreamSegment, String sourceStreamSegment, Duration timeout) {\n-        return this.streamSegmentStore.mergeStreamSegment(targetStreamSegment, sourceStreamSegment, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> sealStreamSegment(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.sealStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> deleteStreamSegment(String streamSegmentName, Duration timeout) {\n-        if (segments.contains(streamSegmentName)) { // Remove the segmentName from the set\n-            segments.remove(streamSegmentName);\n-        }\n-        return this.streamSegmentStore.deleteStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> truncateStreamSegment(String streamSegmentName, long offset, Duration timeout) {\n-        return this.streamSegmentStore.truncateStreamSegment(streamSegmentName, offset, timeout);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4OTY2Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456589666", "bodyText": "no need to check if it exists. Remove won't do anything if it doesn't.\nSame comment as above, in createStreamSegment", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:53:36Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.contracts;\n+\n+import io.pravega.common.util.BufferView;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n+ */\n+public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n+\n+    private final StreamSegmentStore streamSegmentStore;\n+\n+    @Getter(AccessLevel.PUBLIC)\n+    private HashSet<String> segments;\n+\n+    public StreamSegmentStoreWrapper(StreamSegmentStore streamSegmentStore) {\n+        this.streamSegmentStore = streamSegmentStore;\n+        this.segments = new HashSet<>();\n+    }\n+\n+    @Override\n+    public CompletableFuture<Long> append(String streamSegmentName, BufferView data, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n+        return this.streamSegmentStore.append(streamSegmentName, data, attributeUpdates, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Long> append(String streamSegmentName, long offset, BufferView data, Collection<AttributeUpdate> attributeUpdates,\n+                                          Duration timeout) {\n+        return this.streamSegmentStore.append(streamSegmentName, offset, data, attributeUpdates, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> updateAttributes(String streamSegmentName, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n+        return this.streamSegmentStore.updateAttributes(streamSegmentName, attributeUpdates, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Map<UUID, Long>> getAttributes(String streamSegmentName, Collection<UUID> attributeIds, boolean cache, Duration timeout) {\n+        return this.streamSegmentStore.getAttributes(streamSegmentName, attributeIds, cache, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<ReadResult> read(String streamSegmentName, long offset, int maxLength, Duration timeout) {\n+        return this.streamSegmentStore.read(streamSegmentName, offset, maxLength, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n+        return this.streamSegmentStore.getStreamSegmentInfo(streamSegmentName, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, Collection<AttributeUpdate> attributes, Duration timeout) {\n+        segments.add(streamSegmentName); // Add the segmentName to the set\n+        return this.streamSegmentStore.createStreamSegment(streamSegmentName, attributes, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<MergeStreamSegmentResult> mergeStreamSegment(String targetStreamSegment, String sourceStreamSegment, Duration timeout) {\n+        return this.streamSegmentStore.mergeStreamSegment(targetStreamSegment, sourceStreamSegment, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Long> sealStreamSegment(String streamSegmentName, Duration timeout) {\n+        return this.streamSegmentStore.sealStreamSegment(streamSegmentName, timeout);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> deleteStreamSegment(String streamSegmentName, Duration timeout) {\n+        if (segments.contains(streamSegmentName)) { // Remove the segmentName from the set", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NDk0OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459754949", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:06:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4OTY2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java b/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\ndeleted file mode 100644\nindex 3dea6435b..000000000\n--- a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentStoreWrapper.java\n+++ /dev/null\n\n@@ -1,97 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.contracts;\n-\n-import io.pravega.common.util.BufferView;\n-import lombok.AccessLevel;\n-import lombok.Getter;\n-\n-import java.time.Duration;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.CompletableFuture;\n-\n-/**\n- * A wrapper class to StreamSegmentStore to track the segments being created or deleted.\n- */\n-public class StreamSegmentStoreWrapper implements StreamSegmentStore {\n-\n-    private final StreamSegmentStore streamSegmentStore;\n-\n-    @Getter(AccessLevel.PUBLIC)\n-    private HashSet<String> segments;\n-\n-    public StreamSegmentStoreWrapper(StreamSegmentStore streamSegmentStore) {\n-        this.streamSegmentStore = streamSegmentStore;\n-        this.segments = new HashSet<>();\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, BufferView data, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> append(String streamSegmentName, long offset, BufferView data, Collection<AttributeUpdate> attributeUpdates,\n-                                          Duration timeout) {\n-        return this.streamSegmentStore.append(streamSegmentName, offset, data, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> updateAttributes(String streamSegmentName, Collection<AttributeUpdate> attributeUpdates, Duration timeout) {\n-        return this.streamSegmentStore.updateAttributes(streamSegmentName, attributeUpdates, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Map<UUID, Long>> getAttributes(String streamSegmentName, Collection<UUID> attributeIds, boolean cache, Duration timeout) {\n-        return this.streamSegmentStore.getAttributes(streamSegmentName, attributeIds, cache, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<ReadResult> read(String streamSegmentName, long offset, int maxLength, Duration timeout) {\n-        return this.streamSegmentStore.read(streamSegmentName, offset, maxLength, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.getStreamSegmentInfo(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, Collection<AttributeUpdate> attributes, Duration timeout) {\n-        segments.add(streamSegmentName); // Add the segmentName to the set\n-        return this.streamSegmentStore.createStreamSegment(streamSegmentName, attributes, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<MergeStreamSegmentResult> mergeStreamSegment(String targetStreamSegment, String sourceStreamSegment, Duration timeout) {\n-        return this.streamSegmentStore.mergeStreamSegment(targetStreamSegment, sourceStreamSegment, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Long> sealStreamSegment(String streamSegmentName, Duration timeout) {\n-        return this.streamSegmentStore.sealStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> deleteStreamSegment(String streamSegmentName, Duration timeout) {\n-        if (segments.contains(streamSegmentName)) { // Remove the segmentName from the set\n-            segments.remove(streamSegmentName);\n-        }\n-        return this.streamSegmentStore.deleteStreamSegment(streamSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> truncateStreamSegment(String streamSegmentName, long offset, Duration timeout) {\n-        return this.streamSegmentStore.truncateStreamSegment(streamSegmentName, offset, timeout);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MDExNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456590117", "bodyText": "Same comments as in the StreamSegmentStoreWrapper.\nQuestion: can we merge these classes into a single one? They do the same thing, but implement different interfaces.", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:54:31Z", "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/tables/TableStoreWrapper.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.contracts.tables;\n+\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.BufferView;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A wrapper class to TableStore to track the segments being created or deleted.\n+ */\n+public class TableStoreWrapper implements TableStore {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTAzNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755036", "bodyText": "Combined with TableStore to implement a single wrapper and moved it to segmenstore/server/tests", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MDExNw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/tables/TableStoreWrapper.java b/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/tables/TableStoreWrapper.java\ndeleted file mode 100644\nindex dd79908cb..000000000\n--- a/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/tables/TableStoreWrapper.java\n+++ /dev/null\n\n@@ -1,91 +0,0 @@\n-/**\n- * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n- *\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- */\n-package io.pravega.segmentstore.contracts.tables;\n-\n-import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.BufferView;\n-import lombok.AccessLevel;\n-import lombok.Getter;\n-\n-import java.time.Duration;\n-import java.util.Collection;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.concurrent.CompletableFuture;\n-\n-/**\n- * A wrapper class to TableStore to track the segments being created or deleted.\n- */\n-public class TableStoreWrapper implements TableStore {\n-    private final TableStore tableStore;\n-\n-    @Getter(AccessLevel.PUBLIC)\n-    private HashSet<String> segments;\n-\n-    public TableStoreWrapper(TableStore tableStore) {\n-        this.tableStore = tableStore;\n-        this.segments = new HashSet<>();\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> createSegment(String segmentName, Duration timeout) {\n-        this.segments.add(segmentName); // Add the segmentName to the set\n-        return this.tableStore.createSegment(segmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> createSegment(String segmentName, boolean sorted, Duration timeout) {\n-        this.segments.add(segmentName); // Add the segmentName to the set\n-        return this.tableStore.createSegment(segmentName, sorted, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> deleteSegment(String segmentName, boolean mustBeEmpty, Duration timeout) {\n-        if (this.segments.contains(segmentName)) { // Remove the segmentName from the set\n-            this.segments.remove(segmentName);\n-        }\n-        return this.tableStore.deleteSegment(segmentName, mustBeEmpty, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> merge(String targetSegmentName, String sourceSegmentName, Duration timeout) {\n-        return this.tableStore.merge(targetSegmentName, sourceSegmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> seal(String segmentName, Duration timeout) {\n-        return this.tableStore.seal(segmentName, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<List<Long>> put(String segmentName, List<TableEntry> entries, Duration timeout) {\n-        return this.tableStore.put(segmentName, entries, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<Void> remove(String segmentName, Collection<TableKey> keys, Duration timeout) {\n-        return this.tableStore.remove(segmentName, keys, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<List<TableEntry>> get(String segmentName, List<BufferView> keys, Duration timeout) {\n-        return this.tableStore.get(segmentName, keys, timeout);\n-    }\n-\n-    @Override\n-    public CompletableFuture<AsyncIterator<IteratorItem<TableKey>>> keyIterator(String segmentName, IteratorArgs args) {\n-        return this.tableStore.keyIterator(segmentName, args);\n-    }\n-\n-    @Override\n-    public CompletableFuture<AsyncIterator<IteratorItem<TableEntry>>> entryIterator(String segmentName, IteratorArgs args) {\n-        return this.tableStore.entryIterator(segmentName, args);\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MDU5OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456590599", "bodyText": "Why is this \"out of concern\"? If it's broken, please add a link to a GitHub issue that tracks its implementation.", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:55:16Z", "path": "segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/ExtendedS3IntegrationTest.java", "diffHunk": "@@ -74,6 +74,13 @@ protected ServiceBuilder createBuilder(ServiceBuilderConfig.Builder configBuilde\n                         getBookkeeper().getZkClient(), setup.getCoreExecutor()));\n     }\n \n+    /**\n+     * This method intentionally left blank as it's out of concern for ExtendedS3 Storage.", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTA5Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755092", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MDU5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/ExtendedS3IntegrationTest.java b/segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/ExtendedS3IntegrationTest.java\nindex 09826bcda..bca25f2fb 100644\n--- a/segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/ExtendedS3IntegrationTest.java\n+++ b/segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/ExtendedS3IntegrationTest.java\n\n@@ -65,45 +66,30 @@ public class ExtendedS3IntegrationTest extends BookKeeperIntegrationTestBase {\n     //region StreamSegmentStoreTestBase Implementation\n \n     @Override\n-    protected ServiceBuilder createBuilder(ServiceBuilderConfig.Builder configBuilder, int instanceId) {\n+    protected ServiceBuilder createBuilder(ServiceBuilderConfig.Builder configBuilder, int instanceId, boolean useChunkedSegmentStorage) {\n         ServiceBuilderConfig builderConfig = getBuilderConfig(configBuilder, instanceId);\n         return ServiceBuilder\n                 .newInMemoryBuilder(builderConfig)\n-                .withStorageFactory(setup -> new LocalExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), setup.getStorageExecutor()))\n+                .withStorageFactory(setup -> useChunkedSegmentStorage ?\n+                        new LocalExtendedS3SimpleStorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), setup.getStorageExecutor())\n+                        : new LocalExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), setup.getStorageExecutor()))\n                 .withDataLogFactory(setup -> new BookKeeperLogFactory(setup.getConfig(BookKeeperConfig::builder),\n                         getBookkeeper().getZkClient(), setup.getCoreExecutor()));\n     }\n \n     /**\n      * This method intentionally left blank as it's out of concern for ExtendedS3 Storage.\n+     * Link to the issue: https://github.com/pravega/pravega/issues/4970\n      * It must be here as it is defined as abstract method in super class.\n      */\n     @Override\n     public void testDataRecovery() {\n     }\n \n-    /**\n-     * We are declaring a local factory here because we need a factory that creates adapters that interact\n-     * with the local file system for the purposes of testing. Ideally, however, we should mock the extended\n-     * S3 service rather than implement the storage functionality directly in the adapter.\n-     */\n-    private class LocalExtendedS3StorageFactoryCreator implements StorageFactoryCreator {\n-\n-        @Override\n-        public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-            return new LocalExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), executor);\n-        }\n-\n-        @Override\n-        public String getName() {\n-            return \"LocalExtendedStorageFactory\";\n-        }\n-    }\n-\n     private class LocalExtendedS3StorageFactory implements StorageFactory {\n \n-        private final ExtendedS3StorageConfig config;\n-        private final ScheduledExecutorService storageExecutor;\n+        protected final ExtendedS3StorageConfig config;\n+        protected final ScheduledExecutorService storageExecutor;\n \n         LocalExtendedS3StorageFactory(ExtendedS3StorageConfig config, ScheduledExecutorService executor) {\n             this.config = Preconditions.checkNotNull(config, \"config\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MTEzMQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456591131", "bodyText": "Javadoc.", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:56:15Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java", "diffHunk": "@@ -0,0 +1,15 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+import java.util.concurrent.CompletableFuture;\n+\n+public interface DebugSegmentContainer extends SegmentContainer {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTE1Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755153", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MTEzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java\nindex 215952c26..badf30b5e 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java\n\n@@ -10,6 +10,19 @@\n package io.pravega.segmentstore.server;\n import java.util.concurrent.CompletableFuture;\n \n+/**\n+ * Defines debug segment container for stream segments.\n+ */\n public interface DebugSegmentContainer extends SegmentContainer {\n-    CompletableFuture<Void> createStreamSegment(String streamSegmentName, long length, boolean isSealed);\n+\n+    /**\n+     * Updates container metadata table with the given details of a segment. This is used during the data recovery\n+     * process when a segment exists in the long term storage, but not in the durable data log.\n+     * @param streamSegmentName         Name of the segment to be registered.\n+     * @param length                    Length of the segment to be registered.\n+     * @param isSealed                  Sealed status of the segment to be registered.\n+     * @return                          A CompletableFuture that, when completed normally, will indicate the operation\n+     * completed. If the operation failed, the future will be failed with the causing exception.\n+     */\n+    CompletableFuture<Void> registerExistingSegment(String streamSegmentName, long length, boolean isSealed);\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MTc3Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456591772", "bodyText": "DebugStreamSegmentContainer class", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:57:18Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.server.DebugSegmentContainer;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.time.Duration;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+@Slf4j\n+public class DebugStreamSegmentContainer extends StreamSegmentContainer implements DebugSegmentContainer {\n+    private static final Duration TIMEOUT = Duration.ofMinutes(1);\n+    private final ContainerConfig config;\n+\n+    /**\n+     * Creates a new instance of the StreamSegmentContainer class.", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTE4MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755180", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MTc3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\nindex 90e8c6014..1cfa176df 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n\n@@ -11,7 +11,6 @@ package io.pravega.segmentstore.server.containers;\n \n import io.pravega.common.TimeoutTimer;\n import io.pravega.common.util.ArrayView;\n-import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n import io.pravega.segmentstore.server.DebugSegmentContainer;\n import io.pravega.segmentstore.server.OperationLogFactory;\n import io.pravega.segmentstore.server.ReadIndexFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MTg0MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456591840", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:57:25Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.server.DebugSegmentContainer;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.time.Duration;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+@Slf4j\n+public class DebugStreamSegmentContainer extends StreamSegmentContainer implements DebugSegmentContainer {\n+    private static final Duration TIMEOUT = Duration.ofMinutes(1);\n+    private final ContainerConfig config;\n+\n+    /**\n+     * Creates a new instance of the StreamSegmentContainer class.\n+     *\n+     * @param streamSegmentContainerId The Id of the StreamSegmentContainer.\n+     * @param config                   The ContainerConfig to use for this StreamSegmentContainer.", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTIxOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755219", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MTg0MA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\nindex 90e8c6014..1cfa176df 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n\n@@ -11,7 +11,6 @@ package io.pravega.segmentstore.server.containers;\n \n import io.pravega.common.TimeoutTimer;\n import io.pravega.common.util.ArrayView;\n-import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n import io.pravega.segmentstore.server.DebugSegmentContainer;\n import io.pravega.segmentstore.server.OperationLogFactory;\n import io.pravega.segmentstore.server.ReadIndexFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MjY5MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456592690", "bodyText": "Let's rename this to \"registerExistingSegment` to emphasize that the Segment already exists and that we are not actually \"creating\" it.\nPlease explain in the Javadoc what this method is doing and what its outcome is.", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:58:58Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java", "diffHunk": "@@ -0,0 +1,15 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+import java.util.concurrent.CompletableFuture;\n+\n+public interface DebugSegmentContainer extends SegmentContainer {\n+    CompletableFuture<Void> createStreamSegment(String streamSegmentName, long length, boolean isSealed);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTI2Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755266", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5MjY5MA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java\nindex 215952c26..badf30b5e 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/DebugSegmentContainer.java\n\n@@ -10,6 +10,19 @@\n package io.pravega.segmentstore.server;\n import java.util.concurrent.CompletableFuture;\n \n+/**\n+ * Defines debug segment container for stream segments.\n+ */\n public interface DebugSegmentContainer extends SegmentContainer {\n-    CompletableFuture<Void> createStreamSegment(String streamSegmentName, long length, boolean isSealed);\n+\n+    /**\n+     * Updates container metadata table with the given details of a segment. This is used during the data recovery\n+     * process when a segment exists in the long term storage, but not in the durable data log.\n+     * @param streamSegmentName         Name of the segment to be registered.\n+     * @param length                    Length of the segment to be registered.\n+     * @param isSealed                  Sealed status of the segment to be registered.\n+     * @return                          A CompletableFuture that, when completed normally, will indicate the operation\n+     * completed. If the operation failed, the future will be failed with the causing exception.\n+     */\n+    CompletableFuture<Void> registerExistingSegment(String streamSegmentName, long length, boolean isSealed);\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5Mjk5NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456592994", "bodyText": "Move this to the interface Javadoc (and explain more what it is doing).", "author": "andreipaduroiu", "createdAt": "2020-07-17T17:59:26Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.server.DebugSegmentContainer;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.time.Duration;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+@Slf4j\n+public class DebugStreamSegmentContainer extends StreamSegmentContainer implements DebugSegmentContainer {\n+    private static final Duration TIMEOUT = Duration.ofMinutes(1);\n+    private final ContainerConfig config;\n+\n+    /**\n+     * Creates a new instance of the StreamSegmentContainer class.\n+     *\n+     * @param streamSegmentContainerId The Id of the StreamSegmentContainer.\n+     * @param config                   The ContainerConfig to use for this StreamSegmentContainer.\n+     * @param durableLogFactory        The DurableLogFactory to use to create DurableLogs.\n+     * @param readIndexFactory         The ReadIndexFactory to use to create Read Indices.\n+     * @param attributeIndexFactory    The AttributeIndexFactory to use to create Attribute Indices.\n+     * @param writerFactory            The WriterFactory to use to create Writers.\n+     * @param storageFactory           The StorageFactory to use to create Storage Adapters.\n+     * @param createExtensions         A Function that, given an instance of this class, will create the set of\n+     *                                 {@link SegmentContainerExtension}s to be associated with that instance.\n+     * @param executor                 An Executor that can be used to run async tasks.\n+     */\n+    DebugStreamSegmentContainer(int streamSegmentContainerId, ContainerConfig config, OperationLogFactory durableLogFactory,\n+                                ReadIndexFactory readIndexFactory, AttributeIndexFactory attributeIndexFactory,\n+                                WriterFactory writerFactory, StorageFactory storageFactory,\n+                                SegmentContainerFactory.CreateExtensions createExtensions, ScheduledExecutorService executor) {\n+        super(streamSegmentContainerId, config, durableLogFactory, readIndexFactory, attributeIndexFactory, writerFactory,\n+                storageFactory, createExtensions, executor);\n+        this.config = config;\n+    }\n+\n+    /**\n+     * Creates a segment with given properties.", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTM2Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755362", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:07:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5Mjk5NA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\nindex 90e8c6014..1cfa176df 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n\n@@ -11,7 +11,6 @@ package io.pravega.segmentstore.server.containers;\n \n import io.pravega.common.TimeoutTimer;\n import io.pravega.common.util.ArrayView;\n-import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n import io.pravega.segmentstore.server.DebugSegmentContainer;\n import io.pravega.segmentstore.server.OperationLogFactory;\n import io.pravega.segmentstore.server.ReadIndexFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5Mzc4MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456593781", "bodyText": "Create a new method in MetadataStore.SegmentInfo and name it recoveredSegment where you hide away all these details. Then revert back the visibility of both MetadataStore.SegmentInfo and MetadataStore.SegmentInfo.serialize (They are in the same package as this so you don't need the extra public visibility).", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:00:51Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.server.DebugSegmentContainer;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.time.Duration;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+@Slf4j\n+public class DebugStreamSegmentContainer extends StreamSegmentContainer implements DebugSegmentContainer {\n+    private static final Duration TIMEOUT = Duration.ofMinutes(1);\n+    private final ContainerConfig config;\n+\n+    /**\n+     * Creates a new instance of the StreamSegmentContainer class.\n+     *\n+     * @param streamSegmentContainerId The Id of the StreamSegmentContainer.\n+     * @param config                   The ContainerConfig to use for this StreamSegmentContainer.\n+     * @param durableLogFactory        The DurableLogFactory to use to create DurableLogs.\n+     * @param readIndexFactory         The ReadIndexFactory to use to create Read Indices.\n+     * @param attributeIndexFactory    The AttributeIndexFactory to use to create Attribute Indices.\n+     * @param writerFactory            The WriterFactory to use to create Writers.\n+     * @param storageFactory           The StorageFactory to use to create Storage Adapters.\n+     * @param createExtensions         A Function that, given an instance of this class, will create the set of\n+     *                                 {@link SegmentContainerExtension}s to be associated with that instance.\n+     * @param executor                 An Executor that can be used to run async tasks.\n+     */\n+    DebugStreamSegmentContainer(int streamSegmentContainerId, ContainerConfig config, OperationLogFactory durableLogFactory,\n+                                ReadIndexFactory readIndexFactory, AttributeIndexFactory attributeIndexFactory,\n+                                WriterFactory writerFactory, StorageFactory storageFactory,\n+                                SegmentContainerFactory.CreateExtensions createExtensions, ScheduledExecutorService executor) {\n+        super(streamSegmentContainerId, config, durableLogFactory, readIndexFactory, attributeIndexFactory, writerFactory,\n+                storageFactory, createExtensions, executor);\n+        this.config = config;\n+    }\n+\n+    /**\n+     * Creates a segment with given properties.\n+     * @param streamSegmentName         Name of the segment to be created.\n+     * @param length                    Length of the segment to be created.\n+     * @param isSealed                  Sealed status of the segment to be created.\n+     * @return                          A newly created segment.\n+     */\n+    @Override\n+    public CompletableFuture<Void> createStreamSegment(String streamSegmentName, long length, boolean isSealed) {\n+        StreamSegmentInformation segmentProp = StreamSegmentInformation.builder()", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTQzMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755430", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5Mzc4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\nindex 90e8c6014..1cfa176df 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainer.java\n\n@@ -11,7 +11,6 @@ package io.pravega.segmentstore.server.containers;\n \n import io.pravega.common.TimeoutTimer;\n import io.pravega.common.util.ArrayView;\n-import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n import io.pravega.segmentstore.server.DebugSegmentContainer;\n import io.pravega.segmentstore.server.OperationLogFactory;\n import io.pravega.segmentstore.server.ReadIndexFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDIwOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456594209", "bodyText": "revert", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:01:48Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java", "diffHunk": "@@ -685,7 +685,7 @@ void completeExceptionally(Throwable ex) {\n \n     @Data\n     @Builder\n-    protected static class SegmentInfo {\n+    public static class SegmentInfo {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTQ2OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755469", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDIwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\nindex 7026b8b51..c7bd8b1bf 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n\n@@ -685,7 +685,7 @@ public abstract class MetadataStore implements AutoCloseable {\n \n     @Data\n     @Builder\n-    public static class SegmentInfo {\n+    protected static class SegmentInfo {\n         private static final SegmentInfoSerializer SERIALIZER = new SegmentInfoSerializer();\n         private final long segmentId;\n         private final SegmentProperties properties;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDUxMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456594512", "bodyText": "Use this in your DebugSegmentContainer above.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:02:29Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java", "diffHunk": "@@ -704,8 +704,16 @@ static SegmentInfo newSegment(String name, Collection<AttributeUpdate> attribute\n                     .build();\n         }\n \n+        // createSegment in Metadata uses this method to get SegmentInfo\n+        static SegmentInfo recoveredSegment(SegmentProperties segmentProperties) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTUxMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755513", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDUxMg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\nindex 7026b8b51..c7bd8b1bf 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n\n@@ -704,16 +704,21 @@ public abstract class MetadataStore implements AutoCloseable {\n                     .build();\n         }\n \n-        // createSegment in Metadata uses this method to get SegmentInfo\n-        static SegmentInfo recoveredSegment(SegmentProperties segmentProperties) {\n-            return builder()\n-                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n-                    .properties(segmentProperties)\n+        // registerExistingSegment in DebugStreamSegmentContainer uses this method to get SegmentInfo\n+        static ArrayView recoveredSegment(String streamSegmentName, long length, boolean isSealed) {\n+            StreamSegmentInformation segmentProp = StreamSegmentInformation.builder()\n+                    .name(streamSegmentName)\n+                    .length(length)\n+                    .sealed(isSealed)\n                     .build();\n+            return serialize(builder()\n+                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n+                    .properties(segmentProp)\n+                    .build());\n         }\n \n         @SneakyThrows(IOException.class)\n-        public static ArrayView serialize(SegmentInfo state) {\n+        static ArrayView serialize(SegmentInfo state) {\n             return SERIALIZER.serialize(state);\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDgwOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456594808", "bodyText": "This is incorrect. Please make sure you use the code you have in DebugStreamSegmentContainer instead of setting this here.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:03:02Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java", "diffHunk": "@@ -704,8 +704,16 @@ static SegmentInfo newSegment(String name, Collection<AttributeUpdate> attribute\n                     .build();\n         }\n \n+        // createSegment in Metadata uses this method to get SegmentInfo\n+        static SegmentInfo recoveredSegment(SegmentProperties segmentProperties) {\n+            return builder()\n+                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTYwMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755602", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDgwOA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\nindex 7026b8b51..c7bd8b1bf 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n\n@@ -704,16 +704,21 @@ public abstract class MetadataStore implements AutoCloseable {\n                     .build();\n         }\n \n-        // createSegment in Metadata uses this method to get SegmentInfo\n-        static SegmentInfo recoveredSegment(SegmentProperties segmentProperties) {\n-            return builder()\n-                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n-                    .properties(segmentProperties)\n+        // registerExistingSegment in DebugStreamSegmentContainer uses this method to get SegmentInfo\n+        static ArrayView recoveredSegment(String streamSegmentName, long length, boolean isSealed) {\n+            StreamSegmentInformation segmentProp = StreamSegmentInformation.builder()\n+                    .name(streamSegmentName)\n+                    .length(length)\n+                    .sealed(isSealed)\n                     .build();\n+            return serialize(builder()\n+                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n+                    .properties(segmentProp)\n+                    .build());\n         }\n \n         @SneakyThrows(IOException.class)\n-        public static ArrayView serialize(SegmentInfo state) {\n+        static ArrayView serialize(SegmentInfo state) {\n             return SERIALIZER.serialize(state);\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDg0MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456594840", "bodyText": "revert", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:03:08Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java", "diffHunk": "@@ -704,8 +704,16 @@ static SegmentInfo newSegment(String name, Collection<AttributeUpdate> attribute\n                     .build();\n         }\n \n+        // createSegment in Metadata uses this method to get SegmentInfo\n+        static SegmentInfo recoveredSegment(SegmentProperties segmentProperties) {\n+            return builder()\n+                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n+                    .properties(segmentProperties)\n+                    .build();\n+        }\n+\n         @SneakyThrows(IOException.class)\n-        static ArrayView serialize(SegmentInfo state) {\n+        public static ArrayView serialize(SegmentInfo state) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTY0NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755644", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NDg0MA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\nindex 7026b8b51..c7bd8b1bf 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataStore.java\n\n@@ -704,16 +704,21 @@ public abstract class MetadataStore implements AutoCloseable {\n                     .build();\n         }\n \n-        // createSegment in Metadata uses this method to get SegmentInfo\n-        static SegmentInfo recoveredSegment(SegmentProperties segmentProperties) {\n-            return builder()\n-                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n-                    .properties(segmentProperties)\n+        // registerExistingSegment in DebugStreamSegmentContainer uses this method to get SegmentInfo\n+        static ArrayView recoveredSegment(String streamSegmentName, long length, boolean isSealed) {\n+            StreamSegmentInformation segmentProp = StreamSegmentInformation.builder()\n+                    .name(streamSegmentName)\n+                    .length(length)\n+                    .sealed(isSealed)\n                     .build();\n+            return serialize(builder()\n+                    .segmentId(ContainerMetadata.NO_STREAM_SEGMENT_ID)\n+                    .properties(segmentProp)\n+                    .build());\n         }\n \n         @SneakyThrows(IOException.class)\n-        public static ArrayView serialize(SegmentInfo state) {\n+        static ArrayView serialize(SegmentInfo state) {\n             return SERIALIZER.serialize(state);\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NTI4OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456595288", "bodyText": "throw new UnsupportedOperationException(\"DebugSegmentContainer not supported in ReadOnly mode.\")", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:04:04Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ReadOnlySegmentContainerFactory.java", "diffHunk": "@@ -41,4 +42,9 @@ public SegmentContainer createStreamSegmentContainer(int containerId) {\n                 \"ReadOnly Containers can only have Id %s.\", READONLY_CONTAINER_ID);\n         return new ReadOnlySegmentContainer(this.storageFactory, this.executor);\n     }\n+\n+    @Override\n+    public DebugSegmentContainer createDebugStreamSegmentContainer(int containerId) {\n+        return null;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTY3NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755675", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NTI4OA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ReadOnlySegmentContainerFactory.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ReadOnlySegmentContainerFactory.java\nindex c1543a18e..080677596 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ReadOnlySegmentContainerFactory.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/ReadOnlySegmentContainerFactory.java\n\n@@ -45,6 +45,6 @@ public class ReadOnlySegmentContainerFactory implements SegmentContainerFactory\n \n     @Override\n     public DebugSegmentContainer createDebugStreamSegmentContainer(int containerId) {\n-        return null;\n+        throw new UnsupportedOperationException(\"DebugSegmentContainer not supported in ReadOnly mode.\");\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NjU1MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456596550", "bodyText": "You should never create a thread pool and keep it as a static variable. This pool will never shut down.\nI suggest removing this altogether from here and pass an Executor via your method calls whenever you need one.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:06:46Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTc0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755742", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:08:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NjU1MA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NjY1OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456596658", "bodyText": "What's tier2?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:06:59Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NTkzMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459755932", "bodyText": "Changed to storage.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NjY1OA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5Njg3NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456596875", "bodyText": "I don't see the point of this log message.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:07:30Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NjAzNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459756035", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:09:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5Njg3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NzQ5OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456597498", "bodyText": "You can combine this line and the second half of line 76 into a single line after this if-else block. You already have a pointer to segmentsList so you can add it afterwards.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:08:56Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NjA5MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459756090", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:09:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NzQ5OA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NzYyNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456597627", "bodyText": "This is not needed. Looks copy pasted from ExecutorServiceHelpers", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:09:11Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NjI0Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459756243", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:10:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5NzYyNw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODE1Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456598152", "bodyText": "What is this worker and why is it in your test package? Isn't this doing the bulk of your recovery work?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:10:22Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NjY2NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459756664", "bodyText": "It is only used by tests in integration and StreamSegmentTestBase. Though, I changed it's name.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:11:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODE1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM5Mzk1MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465393950", "bodyText": "Should I move it to main? I think I will need to reuse it in CLI tool.", "author": "ManishKumarKeshri", "createdAt": "2020-08-04T23:56:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODE1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODMwMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456598300", "bodyText": "Instead of doing this, check for nulls in the constructor and throw an exception there.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:10:41Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1NjcyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459756729", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:11:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODMwMA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODcwNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456598704", "bodyText": "join will not time out. You have a timeout defined somewhere in this class. Use get(timeoutMillis, TimeUnit.MILLISECONDS)", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:11:34Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODc1Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456598757", "bodyText": "And below", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:11:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODA1NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459758055", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:14:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5ODcwNA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5OTQyMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456599423", "bodyText": "for better clarity, rename this to metadataSegments and make it a Set of String. There's no point in this being a TableKey here.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:13:03Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODU3MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459758571", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:16:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5OTQyMw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5OTU5MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456599591", "bodyText": "I suggest renaming this to storageSegments", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:13:26Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1ODY1MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459758650", "bodyText": "Changed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:16:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU5OTU5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDAzOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456600039", "bodyText": "Why do you attempt to create the segment if it already exists? getStreamSegmentInfo will return a value (not an exception) if it exists.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:14:26Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1OTM3Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459759373", "bodyText": "Now, deleting the segment to remove it from Tier1, and then recreating it using the length and sealed status from LTS.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:18:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDAzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDM4Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456600387", "bodyText": "There's a method in Futures (exceptionallyComposeExpecting) that will simplify your code here.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:15:07Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1OTQ4NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459759485", "bodyText": "Using it now.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:18:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDM4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDUzNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456600534", "bodyText": "You should fail the whole process here instead of just logging a message.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:15:26Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1OTU3NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459759575", "bodyText": "OK.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:19:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDUzNA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDY4Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456600686", "bodyText": "Deleting segment '{}' ...", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:15:46Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1OTYyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459759629", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDY4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDc3NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456600775", "bodyText": "Fail the whole process.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:16:00Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);\n+                try {\n+                    container.deleteStreamSegment(segmentName, TIMEOUT).join();\n+                } catch (Throwable e) {\n+                    log.error(\"Error while deleting the segment = {}\", segmentName);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc1OTkyMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459759920", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMDc3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTAzOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456601039", "bodyText": "You won't need this anymore if you implement my suggestion above.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:16:36Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);\n+                try {\n+                    container.deleteStreamSegment(segmentName, TIMEOUT).join();\n+                } catch (Throwable e) {\n+                    log.error(\"Error while deleting the segment = {}\", segmentName);\n+                }\n+            }\n+            log.info(\"Recovery done for container = {}\", containerId);\n+        }\n+    }\n+\n+    public static ArrayView getTableKey(String segmentName) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MDM0OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459760348", "bodyText": "Yes. Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:21:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTAzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTQ0NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456601444", "bodyText": "Why is this static and public?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:17:23Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);\n+                try {\n+                    container.deleteStreamSegment(segmentName, TIMEOUT).join();\n+                } catch (Throwable e) {\n+                    log.error(\"Error while deleting the segment = {}\", segmentName);\n+                }\n+            }\n+            log.info(\"Recovery done for container = {}\", containerId);\n+        }\n+    }\n+\n+    public static ArrayView getTableKey(String segmentName) {\n+        return new ByteArraySegment(segmentName.getBytes(Charsets.UTF_8));\n+    }\n+\n+    /**\n+     * Deletes container-metadata segment and attribute index segment for the given container Id.\n+     * @param tier2         Long term storage to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataSegments(Storage tier2, int containerId) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMjA0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456602042", "bodyText": "And what's tier2?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:18:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTQ0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MTg3OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459761879", "bodyText": "Made it private. But static, because static method recoverAllSegments uses it.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:25:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTQ0NA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTgyMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456601823", "bodyText": "Do not hardcode this format here. Look in TableMetadataStore on how this is obtained.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:18:10Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);\n+                try {\n+                    container.deleteStreamSegment(segmentName, TIMEOUT).join();\n+                } catch (Throwable e) {\n+                    log.error(\"Error while deleting the segment = {}\", segmentName);\n+                }\n+            }\n+            log.info(\"Recovery done for container = {}\", containerId);\n+        }\n+    }\n+\n+    public static ArrayView getTableKey(String segmentName) {\n+        return new ByteArraySegment(segmentName.getBytes(Charsets.UTF_8));\n+    }\n+\n+    /**\n+     * Deletes container-metadata segment and attribute index segment for the given container Id.\n+     * @param tier2         Long term storage to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataSegments(Storage tier2, int containerId) {\n+        deleteSegment(tier2, \"_system/containers/metadata_\" + containerId);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MTk2Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459761967", "bodyText": "Yes, done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:25:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTgyMw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTk4MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456601981", "bodyText": "Same here. Why public and static?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:18:28Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);\n+                try {\n+                    container.deleteStreamSegment(segmentName, TIMEOUT).join();\n+                } catch (Throwable e) {\n+                    log.error(\"Error while deleting the segment = {}\", segmentName);\n+                }\n+            }\n+            log.info(\"Recovery done for container = {}\", containerId);\n+        }\n+    }\n+\n+    public static ArrayView getTableKey(String segmentName) {\n+        return new ByteArraySegment(segmentName.getBytes(Charsets.UTF_8));\n+    }\n+\n+    /**\n+     * Deletes container-metadata segment and attribute index segment for the given container Id.\n+     * @param tier2         Long term storage to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataSegments(Storage tier2, int containerId) {\n+        deleteSegment(tier2, \"_system/containers/metadata_\" + containerId);\n+        deleteSegment(tier2, \"_system/containers/metadata_\" + containerId + \"$attributes.index\");\n+    }\n+\n+    /**\n+     * Deletes the segment with given segment name from the given long term storage.\n+     * @param tier2         Long term storage to delete the segment from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     */\n+    public static void deleteSegment(Storage tier2, String segmentName) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MjI4Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459762282", "bodyText": "private now, but still static as it used by another static method.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMTk4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMjE0Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456602146", "bodyText": "Let the exception bubble up", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:18:46Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server;\n+\n+import com.google.common.base.Charsets;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static io.pravega.shared.NameUtils.getMetadataSegmentName;\n+\n+/**\n+ * Utility methods for data recovery tests.\n+ */\n+@Slf4j\n+public class DataRecoveryTestUtils {\n+    private static final Duration TIMEOUT = Duration.ofSeconds(30);\n+    private static final ScheduledExecutorService EXECUTOR_SERVICE = createExecutorService(10);\n+\n+    /**\n+     * Lists all segments from a given long term storage.\n+     * @param tier2             Long term storage.\n+     * @param containerCount    Total number of segment containers.\n+     * @return                  A map of lists containing segments by container Ids.\n+     * @throws                  IOException in case of exception during the execution.\n+     */\n+    public static Map<Integer, List<SegmentProperties>> listAllSegments(Storage tier2, int containerCount) throws IOException {\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        Map<Integer, List<SegmentProperties>> segmentToContainers = new HashMap<Integer, List<SegmentProperties>>();\n+        log.info(\"Generating container files with the segments they own...\");\n+        Iterator<SegmentProperties> it = tier2.listSegments();\n+        if (it == null) {\n+            return segmentToContainers;\n+        }\n+        // Iterate through all segments. Put each one of them in its respective list.\n+        while (it.hasNext()) {\n+            SegmentProperties curr = it.next();\n+            int containerId = segToConMapper.getContainerId(curr.getName());\n+            List<SegmentProperties> segmentsList = segmentToContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(curr);\n+                segmentToContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentToContainers.get(containerId).add(curr);\n+            }\n+        }\n+        return segmentToContainers;\n+    }\n+\n+    public static ScheduledExecutorService createExecutorService(int threadPoolSize) {\n+        ScheduledThreadPoolExecutor es = new ScheduledThreadPoolExecutor(threadPoolSize);\n+        es.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);\n+        es.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n+        es.setRemoveOnCancelPolicy(true);\n+        return es;\n+    }\n+\n+     /**\n+     * Creates all segments given in the list with the given DebugStreamSegmentContainer.\n+     */\n+     public static class Worker implements Runnable {\n+        private final int containerId;\n+        private final DebugStreamSegmentContainer container;\n+        private final List<SegmentProperties> segments;\n+        public Worker(DebugStreamSegmentContainer container, List<SegmentProperties> segments) {\n+            this.container = container;\n+            this.containerId = container.getId();\n+            this.segments = segments;\n+        }\n+\n+        @Override\n+        public void run() {\n+            if (segments == null) {\n+                return;\n+            }\n+            log.info(\"Recovery started for container = {}\", containerId);\n+            ContainerTableExtension ext = container.getExtension(ContainerTableExtension.class);\n+            AsyncIterator<IteratorItem<TableKey>> it = ext.keyIterator(getMetadataSegmentName(containerId),\n+                    IteratorArgs.builder().fetchTimeout(TIMEOUT).build()).join();\n+\n+            // Add all segments present in the container metadata in a set.\n+            Set<TableKey> segmentsInMD = new HashSet<>();\n+            it.forEachRemaining(k -> segmentsInMD.addAll(k.getEntries()), EXECUTOR_SERVICE).join();\n+\n+            for (SegmentProperties segment : segments) {\n+                long len = segment.getLength();\n+                boolean isSealed = segment.isSealed();\n+                String segmentName = segment.getName();\n+\n+                /*\n+                    1. segment exists in both metadata and storage, re-create it\n+                    2. segment only in metadata, delete\n+                    3. segment only in storage, re-create it\n+                 */\n+                segmentsInMD.remove(TableKey.unversioned(getTableKey(segmentName)));\n+                container.getStreamSegmentInfo(segment.getName(), TIMEOUT)\n+                        .thenAccept(e -> {\n+                            container.createStreamSegment(segmentName, len, isSealed)\n+                                    .exceptionally(ex -> {\n+                                        log.error(\"Exception occurred while creating segment\", ex);\n+                                        return null;\n+                                    }).join();\n+                        })\n+                        .exceptionally(e -> {\n+                            log.error(\"Got an exception on getStreamSegmentInfo\", e);\n+                            if (Exceptions.unwrap(e) instanceof StreamSegmentNotExistsException) {\n+                                container.createStreamSegment(segmentName, len, isSealed)\n+                                        .exceptionally(ex -> {\n+                                            log.error(\"Exception occurred while creating segment\", ex);\n+                                            return null;\n+                                        }).join();\n+                            }\n+                            return null;\n+                        }).join();\n+            }\n+            for (TableKey k : segmentsInMD) {\n+                String segmentName = k.getKey().toString();\n+                log.info(\"Deleting segment : {} as it is not in storage\", segmentName);\n+                try {\n+                    container.deleteStreamSegment(segmentName, TIMEOUT).join();\n+                } catch (Throwable e) {\n+                    log.error(\"Error while deleting the segment = {}\", segmentName);\n+                }\n+            }\n+            log.info(\"Recovery done for container = {}\", containerId);\n+        }\n+    }\n+\n+    public static ArrayView getTableKey(String segmentName) {\n+        return new ByteArraySegment(segmentName.getBytes(Charsets.UTF_8));\n+    }\n+\n+    /**\n+     * Deletes container-metadata segment and attribute index segment for the given container Id.\n+     * @param tier2         Long term storage to delete the segments from.\n+     * @param containerId   Id of the container for which the segments has to be deleted.\n+     */\n+    public static void deleteContainerMetadataSegments(Storage tier2, int containerId) {\n+        deleteSegment(tier2, \"_system/containers/metadata_\" + containerId);\n+        deleteSegment(tier2, \"_system/containers/metadata_\" + containerId + \"$attributes.index\");\n+    }\n+\n+    /**\n+     * Deletes the segment with given segment name from the given long term storage.\n+     * @param tier2         Long term storage to delete the segment from.\n+     * @param segmentName   Name of the segment to be deleted.\n+     */\n+    public static void deleteSegment(Storage tier2, String segmentName) {\n+        try {\n+            SegmentHandle segmentHandle = tier2.openWrite(segmentName).join();\n+            tier2.delete(segmentHandle, TIMEOUT).join();\n+        } catch (Throwable e) {\n+            log.info(\"Error while deleting segment: {}\", segmentName);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2Mjg5NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459762895", "bodyText": "It makes the test fail all the times, if I let it bubble up. The reason is most of the time, container metadata segments for some containers don't exist while I am trying to delete them.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:27:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMjE0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDY3NjY3OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r460676679", "bodyText": "It's the only place where I am not letting the exception bubble up.", "author": "ManishKumarKeshri", "createdAt": "2020-07-27T06:40:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMjE0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\nindex 69f239716..0c8482f5f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/DataRecoveryTestUtils.java\n\n@@ -9,11 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.util.ArrayView;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.common.util.AsyncIterator;\n-import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMjI2Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456602263", "bodyText": "throw unsupported", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:19:02Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentContainerRegistryTests.java", "diffHunk": "@@ -249,6 +250,11 @@ public void testStartAlreadyRunning() throws Exception {\n             this.startReleaseSignal = startReleaseSignal;\n         }\n \n+        @Override\n+        public DebugSegmentContainer createDebugStreamSegmentContainer(int containerId) {\n+            return null;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2Mjk2OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459762968", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:28:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMjI2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentContainerRegistryTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentContainerRegistryTests.java\nindex 102f8ff2e..58e1ff51f 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentContainerRegistryTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentContainerRegistryTests.java\n\n@@ -252,7 +252,7 @@ public class StreamSegmentContainerRegistryTests extends ThreadPooledTestSuite {\n \n         @Override\n         public DebugSegmentContainer createDebugStreamSegmentContainer(int containerId) {\n-            return null;\n+            throw new UnsupportedOperationException(\"DebugSegmentContainer not supported in container Registry Tests.\");\n         }\n \n         @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMzA2MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456603060", "bodyText": "If you rename the parent method, remember to rename this test too.\nAlso, it's a good habit to describe in the test's Javadoc what it's doing.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:20:49Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDY2Nzk1Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r460667952", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-27T06:16:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMzA2MA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMzg4Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456603883", "bodyText": "If you do this, the original exception will never show up in your test result. Remove this try-catch and let the exception bubble up.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:22:39Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzE3Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459763172", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:28:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwMzg4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDMxNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456604316", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:23:38Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);\n+        } catch (IOException e) {\n+            Assert.fail(\"Exception occurred while listing segments.\");", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDY2NzYwMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r460667600", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-27T06:15:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDMxNg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDQxNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456604415", "bodyText": "Why do you create a random executor here?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:23:52Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzIyMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459763220", "bodyText": "removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:28:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDQxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDUzNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456604534", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:24:07Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);\n+        } catch (IOException e) {\n+            Assert.fail(\"Exception occurred while listing segments.\");\n+        }\n+\n+        // Verify count of segments listed.\n+        for (int i = 0; i < segments.size(); i++) {\n+            segmentsRecoveredCount += segments.get(i).size();\n+            Assert.assertTrue(\"Number of segments listed is less than the number of segments created using this container.\",\n+                    segments.get(i).size() >= segmentsCountByContainer[i]);\n+        }\n+        Assert.assertTrue(\"Total number of segments created is less than the number of segments created.\",\n+                segmentsRecoveredCount >= segmentsToCreateCount);\n+\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory,\n+                DataRecoveryTestUtils.createExecutorService(10));", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDYxNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456604614", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:24:17Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);\n+        } catch (IOException e) {\n+            Assert.fail(\"Exception occurred while listing segments.\");\n+        }\n+\n+        // Verify count of segments listed.\n+        for (int i = 0; i < segments.size(); i++) {\n+            segmentsRecoveredCount += segments.get(i).size();\n+            Assert.assertTrue(\"Number of segments listed is less than the number of segments created using this container.\",\n+                    segments.get(i).size() >= segmentsCountByContainer[i]);\n+        }\n+        Assert.assertTrue(\"Total number of segments created is less than the number of segments created.\",\n+                segmentsRecoveredCount >= segmentsToCreateCount);\n+\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory,\n+                DataRecoveryTestUtils.createExecutorService(10));\n+\n+        // Recover all segments\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            @Cleanup\n+            MetadataCleanupContainer localContainer = new MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                    context.getDefaultExtensions(), DataRecoveryTestUtils.createExecutorService(10));", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzI2MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459763260", "bodyText": "removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:29:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDYxNA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDk3Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456604976", "bodyText": "Replace this whole if block with Assert.assertEquals.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:24:57Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);\n+        } catch (IOException e) {\n+            Assert.fail(\"Exception occurred while listing segments.\");\n+        }\n+\n+        // Verify count of segments listed.\n+        for (int i = 0; i < segments.size(); i++) {\n+            segmentsRecoveredCount += segments.get(i).size();\n+            Assert.assertTrue(\"Number of segments listed is less than the number of segments created using this container.\",\n+                    segments.get(i).size() >= segmentsCountByContainer[i]);\n+        }\n+        Assert.assertTrue(\"Total number of segments created is less than the number of segments created.\",\n+                segmentsRecoveredCount >= segmentsToCreateCount);\n+\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory,\n+                DataRecoveryTestUtils.createExecutorService(10));\n+\n+        // Recover all segments\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            @Cleanup\n+            MetadataCleanupContainer localContainer = new MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                    context.getDefaultExtensions(), DataRecoveryTestUtils.createExecutorService(10));\n+\n+            Services.startAsync(localContainer, executorService)\n+                    .thenRun(new DataRecoveryTestUtils.Worker(localContainer, segments.get(containerId))).join();\n+\n+            for (String segmentName : segmentByContainers.get(containerId)) {\n+                SegmentProperties props = localContainer.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+                Assert.assertEquals(\"Segment length mismatch \", data.length, props.getLength());\n+                if (sealedSegments.contains(segmentName)) {\n+                    Assert.assertTrue(\"Segment should have been sealed\", props.isSealed());", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzMxNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459763314", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:29:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNDk3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNTMzNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456605335", "bodyText": "localContainer.close() will do the same", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:25:42Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);\n+        } catch (IOException e) {\n+            Assert.fail(\"Exception occurred while listing segments.\");\n+        }\n+\n+        // Verify count of segments listed.\n+        for (int i = 0; i < segments.size(); i++) {\n+            segmentsRecoveredCount += segments.get(i).size();\n+            Assert.assertTrue(\"Number of segments listed is less than the number of segments created using this container.\",\n+                    segments.get(i).size() >= segmentsCountByContainer[i]);\n+        }\n+        Assert.assertTrue(\"Total number of segments created is less than the number of segments created.\",\n+                segmentsRecoveredCount >= segmentsToCreateCount);\n+\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory,\n+                DataRecoveryTestUtils.createExecutorService(10));\n+\n+        // Recover all segments\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            @Cleanup\n+            MetadataCleanupContainer localContainer = new MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                    context.getDefaultExtensions(), DataRecoveryTestUtils.createExecutorService(10));\n+\n+            Services.startAsync(localContainer, executorService)\n+                    .thenRun(new DataRecoveryTestUtils.Worker(localContainer, segments.get(containerId))).join();\n+\n+            for (String segmentName : segmentByContainers.get(containerId)) {\n+                SegmentProperties props = localContainer.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+                Assert.assertEquals(\"Segment length mismatch \", data.length, props.getLength());\n+                if (sealedSegments.contains(segmentName)) {\n+                    Assert.assertTrue(\"Segment should have been sealed\", props.isSealed());\n+                }\n+            }\n+            Services.stopAsync(localContainer, executorService).join();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2MzU3Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459763576", "bodyText": "Using @cleanup now.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:29:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNTMzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNTUzMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456605530", "bodyText": "Do you actually need this?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:26:07Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentException;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerFactory;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogFactory;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.SyncStorage;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.mocks.InMemoryDurableDataLogFactory;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorage;\n+import io.pravega.segmentstore.storage.mocks.InMemoryStorageFactory;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.segment.SegmentToContainerMapper;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import lombok.Cleanup;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * Tests for DebugStreamSegmentContainer class.\n+ */\n+public class DebugStreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    private static final int MIN_SEGMENT_LENGTH = 0; // Used in randomly generating the length for a segment\n+    private static final int MAX_SEGMENT_LENGTH = 10100; // Used in randomly generating the length for a segment\n+    private static final int CONTAINER_ID = 1234567;\n+    private static final int EXPECTED_PINNED_SEGMENT_COUNT = 1;\n+    private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+    private static final int TEST_TIMEOUT_MILLIS = 10 * 1000;\n+    private static final Duration TIMEOUT = Duration.ofMillis(TEST_TIMEOUT_MILLIS);\n+    private static final Random RANDOM = new Random(1234);\n+    private static final ContainerConfig DEFAULT_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, 10 * 60)\n+            .build();\n+\n+    private static final DurableLogConfig DEFAULT_DURABLE_LOG_CONFIG = DurableLogConfig\n+            .builder()\n+            .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+            .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+            .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10 * 1024 * 1024L)\n+            .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+            .build();\n+\n+    private static final ReadIndexConfig DEFAULT_READ_INDEX_CONFIG = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+    private static final AttributeIndexConfig DEFAULT_ATTRIBUTE_INDEX_CONFIG = AttributeIndexConfig\n+            .builder()\n+            .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+            .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+            .build();\n+\n+    private static final WriterConfig DEFAULT_WRITER_CONFIG = WriterConfig\n+            .builder()\n+            .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+            .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n+            .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+            .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+            .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+            .build();\n+    private static final ContainerConfig CONTAINER_CONFIG = ContainerConfig\n+            .builder()\n+            .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+            .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 200 + EXPECTED_PINNED_SEGMENT_COUNT)\n+            .build();\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+\n+    @Rule\n+    public Timeout globalTimeout = Timeout.millis(TEST_TIMEOUT_MILLIS);\n+\n+    /**\n+     * Tests the ability to create Segments.\n+     */\n+    @Test\n+    public void testCreateStreamSegment() {\n+        int maxSegmentCount = 100;\n+        final int createdSegmentCount = maxSegmentCount * 2;\n+\n+        // Sets up dataLogFactory, readIndexFactory, attributeIndexFactory etc for the DebugSegmentContainer.\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory, executorService());\n+        // Starts a DebugSegmentContainer.\n+        @Cleanup\n+        MetadataCleanupContainer localContainer = new MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n+                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                context.getDefaultExtensions(), executorService());\n+        localContainer.startAsync().awaitRunning();\n+\n+        // Record details(name, length & sealed status) of each segment to be created.\n+        ArrayList<String> segments = new ArrayList<>();\n+        ArrayList<CompletableFuture<Void>> futures = new ArrayList<>();\n+        long[] segmentLengths = new long[createdSegmentCount];\n+        boolean[] segmentSealedStatus = new boolean[createdSegmentCount];\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            segmentLengths[i] = MIN_SEGMENT_LENGTH + RANDOM.nextInt(MAX_SEGMENT_LENGTH - MIN_SEGMENT_LENGTH);\n+            segmentSealedStatus[i] = RANDOM.nextBoolean();\n+            String name = \"Segment_\" + i;\n+            segments.add(name);\n+            futures.add(localContainer.createStreamSegment(name, segmentLengths[i], segmentSealedStatus[i]));\n+        }\n+        Futures.allOf(futures).join();\n+\n+        // Verify the Segments are still there with their length & sealed status.\n+        for (int i = 0; i < createdSegmentCount; i++) {\n+            SegmentProperties props = localContainer.getStreamSegmentInfo(segments.get(i), TIMEOUT).join();\n+            Assert.assertEquals(\"Segment length mismatch \", segmentLengths[i], props.getLength());\n+            Assert.assertEquals(\"Segment sealed status mismatch\", segmentSealedStatus[i], props.isSealed());\n+        }\n+        localContainer.stopAsync().awaitTerminated();\n+    }\n+\n+    /**\n+     * Use a storage instance to create segments. List the segments from the storage and recreate them.\n+     */\n+    @Test\n+    public void testEndToEnd() {\n+        // Segments are mapped to four different containers.\n+        // DebugSegmentContainer for each container Id is created and segments belonging to that container are recovered.\n+        int containerCount = 4;\n+        int segmentsToCreateCount = 50;\n+\n+        // Create a storage.\n+        @Cleanup\n+        val baseStorage = new InMemoryStorage();\n+        @Cleanup\n+        val s = new RollingStorage(baseStorage, new SegmentRollingPolicy(1));\n+        s.initialize(1);\n+\n+        // Record details(name, container Id & sealed status) of each segment to be created.\n+        Set<String> sealedSegments = new HashSet<>();\n+        byte[] data = \"data\".getBytes();\n+        SegmentToContainerMapper segToConMapper = new SegmentToContainerMapper(containerCount);\n+        int[] segmentsCountByContainer = new int[containerCount];\n+        Map<Integer, ArrayList<String>> segmentByContainers = new HashMap<>();\n+\n+        // Create segments and get their container Ids, sealed status and names to verify.\n+        for (int i = 0; i < segmentsToCreateCount; i++) {\n+            String segmentName = \"segment-\" + RANDOM.nextInt();\n+\n+            // Count segments by each container Id.\n+            segmentsCountByContainer[segToConMapper.getContainerId(segmentName)]++;\n+\n+            // Use segmentName to map to different containers.\n+            int containerId = segToConMapper.getContainerId(segmentName);\n+            ArrayList<String> segmentsList = segmentByContainers.get(containerId);\n+            if (segmentsList == null) {\n+                segmentsList = new ArrayList<>();\n+                segmentsList.add(segmentName);\n+                segmentByContainers.put(containerId, segmentsList);\n+            } else {\n+                segmentByContainers.get(containerId).add(segmentName);\n+            }\n+\n+            // Create segments, write data and randomly seal some of them.\n+            try {\n+                val wh1 = s.create(segmentName);\n+                // Write data.\n+                s.write(wh1, 0, new ByteArrayInputStream(data), data.length);\n+                if (RANDOM.nextInt(2) == 1) {\n+                    s.seal(wh1);\n+                    sealedSegments.add(segmentName);\n+                }\n+            } catch (StreamSegmentException e) {\n+                Assert.fail(\"Exception occurred while test execution.\");\n+            }\n+        }\n+\n+        // Keeps count of segments recovered in all container Ids.\n+        int segmentsRecoveredCount = 0;\n+\n+        // List all segments\n+        Map<Integer, List<SegmentProperties>> segments = null;\n+        try {\n+            segments = DataRecoveryTestUtils.listAllSegments(new AsyncStorageWrapper(s,\n+                    DataRecoveryTestUtils.createExecutorService(10)), containerCount);\n+        } catch (IOException e) {\n+            Assert.fail(\"Exception occurred while listing segments.\");\n+        }\n+\n+        // Verify count of segments listed.\n+        for (int i = 0; i < segments.size(); i++) {\n+            segmentsRecoveredCount += segments.get(i).size();\n+            Assert.assertTrue(\"Number of segments listed is less than the number of segments created using this container.\",\n+                    segments.get(i).size() >= segmentsCountByContainer[i]);\n+        }\n+        Assert.assertTrue(\"Total number of segments created is less than the number of segments created.\",\n+                segmentsRecoveredCount >= segmentsToCreateCount);\n+\n+        @Cleanup\n+        TestContext context = createContext();\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DEFAULT_DURABLE_LOG_CONFIG, context.dataLogFactory,\n+                DataRecoveryTestUtils.createExecutorService(10));\n+\n+        // Recover all segments\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            @Cleanup\n+            MetadataCleanupContainer localContainer = new MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, context.storageFactory,\n+                    context.getDefaultExtensions(), DataRecoveryTestUtils.createExecutorService(10));\n+\n+            Services.startAsync(localContainer, executorService)\n+                    .thenRun(new DataRecoveryTestUtils.Worker(localContainer, segments.get(containerId))).join();\n+\n+            for (String segmentName : segmentByContainers.get(containerId)) {\n+                SegmentProperties props = localContainer.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+                Assert.assertEquals(\"Segment length mismatch \", data.length, props.getLength());\n+                if (sealedSegments.contains(segmentName)) {\n+                    Assert.assertTrue(\"Segment should have been sealed\", props.isSealed());\n+                }\n+            }\n+            Services.stopAsync(localContainer, executorService).join();\n+        }\n+    }\n+\n+    public static class MetadataCleanupContainer extends DebugStreamSegmentContainer {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2Mzk4OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459763988", "bodyText": "Yes.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:30:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNTUzMA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\nindex 83b45b0ce..1da6c7a23 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/DebugStreamSegmentContainerTests.java\n\n@@ -12,7 +12,6 @@ package io.pravega.segmentstore.server.containers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.concurrent.Services;\n import io.pravega.segmentstore.contracts.SegmentProperties;\n-import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.server.CacheManager;\n import io.pravega.segmentstore.server.CachePolicy;\n import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNjIyNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456606226", "bodyText": "You already have this defined in your configBuilder object", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:27:26Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -146,7 +178,98 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n+     * persisted storage is used to re-create all segments.\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    public void testDataRecovery() throws Exception {\n+        endToEndDebugSegmentContainer();\n+    }\n+\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        int containerCount = 4;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDAxOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764018", "bodyText": "OK.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:31:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNjIyNg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -179,8 +177,9 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n-     * persisted storage is used to re-create all segments.\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments, and segments are let\n+     * to be flushed to the long term storage. And then just using the long persisted storage, debug segment container\n+     * registers all the segments.\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNjUwMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456606502", "bodyText": "tier2", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:27:58Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -146,7 +178,98 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n+     * persisted storage is used to re-create all segments.\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    public void testDataRecovery() throws Exception {\n+        endToEndDebugSegmentContainer();\n+    }\n+\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        int containerCount = 4;\n+        ArrayList<String> segmentNames;\n+        HashMap<String, ArrayList<String>> transactionsBySegment;\n+        HashMap<String, Long> lengths = new HashMap<>();\n+        ArrayList<ByteBuf> appendBuffers = new ArrayList<>();\n+        HashMap<String, ByteArrayOutputStream> segmentContents = new HashMap<>();\n+\n+        try (val builder = createBuilder(0);\n+             val readOnlyBuilder = createReadOnlyBuilder()) {\n+            val segmentStore = builder.createStreamSegmentService();\n+            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n+\n+            segmentNames = createSegments(segmentStore);\n+            log.info(\"Created Segments: {}.\", String.join(\", \", segmentNames));\n+            transactionsBySegment = createTransactions(segmentNames, segmentStore);\n+            log.info(\"Created Transactions: {}.\", transactionsBySegment.values().stream().flatMap(Collection::stream).collect(Collectors.joining(\", \")));\n+\n+            // Add some appends and seal segments\n+            ArrayList<String> segmentsAndTransactions = new ArrayList<>(segmentNames);\n+            transactionsBySegment.values().forEach(segmentsAndTransactions::addAll);\n+            appendData(segmentsAndTransactions, segmentContents, lengths, appendBuffers, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished appending data.\");\n+\n+            // Wait for flushing the segments to tier2\n+            waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished waiting for segments in Storage.\");\n+\n+            // Get the persistent storage from readOnlySegmentStore.\n+            Storage tier2 = getReadOnlyStorageFactory().createStorageAdapter();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDA4Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764082", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:31:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNjUwMg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -179,8 +177,9 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n-     * persisted storage is used to re-create all segments.\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments, and segments are let\n+     * to be flushed to the long term storage. And then just using the long persisted storage, debug segment container\n+     * registers all the segments.\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzAyNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456607026", "bodyText": "I suggest you move this to private final fields on top of this class and name them appropriately", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:28:58Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -146,7 +178,98 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n+     * persisted storage is used to re-create all segments.\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    public void testDataRecovery() throws Exception {\n+        endToEndDebugSegmentContainer();\n+    }\n+\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        int containerCount = 4;\n+        ArrayList<String> segmentNames;\n+        HashMap<String, ArrayList<String>> transactionsBySegment;\n+        HashMap<String, Long> lengths = new HashMap<>();\n+        ArrayList<ByteBuf> appendBuffers = new ArrayList<>();\n+        HashMap<String, ByteArrayOutputStream> segmentContents = new HashMap<>();\n+\n+        try (val builder = createBuilder(0);\n+             val readOnlyBuilder = createReadOnlyBuilder()) {\n+            val segmentStore = builder.createStreamSegmentService();\n+            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n+\n+            segmentNames = createSegments(segmentStore);\n+            log.info(\"Created Segments: {}.\", String.join(\", \", segmentNames));\n+            transactionsBySegment = createTransactions(segmentNames, segmentStore);\n+            log.info(\"Created Transactions: {}.\", transactionsBySegment.values().stream().flatMap(Collection::stream).collect(Collectors.joining(\", \")));\n+\n+            // Add some appends and seal segments\n+            ArrayList<String> segmentsAndTransactions = new ArrayList<>(segmentNames);\n+            transactionsBySegment.values().forEach(segmentsAndTransactions::addAll);\n+            appendData(segmentsAndTransactions, segmentContents, lengths, appendBuffers, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished appending data.\");\n+\n+            // Wait for flushing the segments to tier2\n+            waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished waiting for segments in Storage.\");\n+\n+            // Get the persistent storage from readOnlySegmentStore.\n+            Storage tier2 = getReadOnlyStorageFactory().createStorageAdapter();\n+\n+            // Delete container metadata segment and attribute index segment for each container Id from the persistent storage.\n+            for (int containerId = 0; containerId < containerCount; containerId++) {\n+                DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, containerId);\n+            }\n+\n+            // List all segments from the long term storage.\n+            Map<Integer, List<SegmentProperties>> segments = DataRecoveryTestUtils.listAllSegments(tier2, containerCount);\n+\n+            // Configurations for DebugSegmentContainer\n+            final ContainerConfig containerConfig = ContainerConfig", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDEzNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764135", "bodyText": "Ok.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:31:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzAyNg=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -179,8 +177,9 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n-     * persisted storage is used to re-create all segments.\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments, and segments are let\n+     * to be flushed to the long term storage. And then just using the long persisted storage, debug segment container\n+     * registers all the segments.\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzEzMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456607130", "bodyText": "why create a new executor?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:29:10Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -146,7 +178,98 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n+     * persisted storage is used to re-create all segments.\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    public void testDataRecovery() throws Exception {\n+        endToEndDebugSegmentContainer();\n+    }\n+\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        int containerCount = 4;\n+        ArrayList<String> segmentNames;\n+        HashMap<String, ArrayList<String>> transactionsBySegment;\n+        HashMap<String, Long> lengths = new HashMap<>();\n+        ArrayList<ByteBuf> appendBuffers = new ArrayList<>();\n+        HashMap<String, ByteArrayOutputStream> segmentContents = new HashMap<>();\n+\n+        try (val builder = createBuilder(0);\n+             val readOnlyBuilder = createReadOnlyBuilder()) {\n+            val segmentStore = builder.createStreamSegmentService();\n+            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n+\n+            segmentNames = createSegments(segmentStore);\n+            log.info(\"Created Segments: {}.\", String.join(\", \", segmentNames));\n+            transactionsBySegment = createTransactions(segmentNames, segmentStore);\n+            log.info(\"Created Transactions: {}.\", transactionsBySegment.values().stream().flatMap(Collection::stream).collect(Collectors.joining(\", \")));\n+\n+            // Add some appends and seal segments\n+            ArrayList<String> segmentsAndTransactions = new ArrayList<>(segmentNames);\n+            transactionsBySegment.values().forEach(segmentsAndTransactions::addAll);\n+            appendData(segmentsAndTransactions, segmentContents, lengths, appendBuffers, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished appending data.\");\n+\n+            // Wait for flushing the segments to tier2\n+            waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished waiting for segments in Storage.\");\n+\n+            // Get the persistent storage from readOnlySegmentStore.\n+            Storage tier2 = getReadOnlyStorageFactory().createStorageAdapter();\n+\n+            // Delete container metadata segment and attribute index segment for each container Id from the persistent storage.\n+            for (int containerId = 0; containerId < containerCount; containerId++) {\n+                DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, containerId);\n+            }\n+\n+            // List all segments from the long term storage.\n+            Map<Integer, List<SegmentProperties>> segments = DataRecoveryTestUtils.listAllSegments(tier2, containerCount);\n+\n+            // Configurations for DebugSegmentContainer\n+            final ContainerConfig containerConfig = ContainerConfig\n+                    .builder()\n+                    .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+                    .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 100)\n+                    .build();\n+            final DurableLogConfig durableLogConfig = DurableLogConfig\n+                    .builder()\n+                    .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                    .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                    .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024)\n+                    .build();\n+\n+            // Create the environment for DebugSegmentContainer using the given storageFactory.\n+            @Cleanup TestContext context = createContext(getReadOnlyStorageFactory());\n+            OperationLogFactory localDurableLogFactory = new DurableLogFactory(durableLogConfig, context.dataLogFactory,\n+                    DataRecoveryTestUtils.createExecutorService(10));", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDQ4MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764481", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:32:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzEzMA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -179,8 +177,9 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n-     * persisted storage is used to re-create all segments.\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments, and segments are let\n+     * to be flushed to the long term storage. And then just using the long persisted storage, debug segment container\n+     * registers all the segments.\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzIxNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456607215", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:29:18Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -146,7 +178,98 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n+     * persisted storage is used to re-create all segments.\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    public void testDataRecovery() throws Exception {\n+        endToEndDebugSegmentContainer();\n+    }\n+\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        int containerCount = 4;\n+        ArrayList<String> segmentNames;\n+        HashMap<String, ArrayList<String>> transactionsBySegment;\n+        HashMap<String, Long> lengths = new HashMap<>();\n+        ArrayList<ByteBuf> appendBuffers = new ArrayList<>();\n+        HashMap<String, ByteArrayOutputStream> segmentContents = new HashMap<>();\n+\n+        try (val builder = createBuilder(0);\n+             val readOnlyBuilder = createReadOnlyBuilder()) {\n+            val segmentStore = builder.createStreamSegmentService();\n+            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n+\n+            segmentNames = createSegments(segmentStore);\n+            log.info(\"Created Segments: {}.\", String.join(\", \", segmentNames));\n+            transactionsBySegment = createTransactions(segmentNames, segmentStore);\n+            log.info(\"Created Transactions: {}.\", transactionsBySegment.values().stream().flatMap(Collection::stream).collect(Collectors.joining(\", \")));\n+\n+            // Add some appends and seal segments\n+            ArrayList<String> segmentsAndTransactions = new ArrayList<>(segmentNames);\n+            transactionsBySegment.values().forEach(segmentsAndTransactions::addAll);\n+            appendData(segmentsAndTransactions, segmentContents, lengths, appendBuffers, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished appending data.\");\n+\n+            // Wait for flushing the segments to tier2\n+            waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished waiting for segments in Storage.\");\n+\n+            // Get the persistent storage from readOnlySegmentStore.\n+            Storage tier2 = getReadOnlyStorageFactory().createStorageAdapter();\n+\n+            // Delete container metadata segment and attribute index segment for each container Id from the persistent storage.\n+            for (int containerId = 0; containerId < containerCount; containerId++) {\n+                DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, containerId);\n+            }\n+\n+            // List all segments from the long term storage.\n+            Map<Integer, List<SegmentProperties>> segments = DataRecoveryTestUtils.listAllSegments(tier2, containerCount);\n+\n+            // Configurations for DebugSegmentContainer\n+            final ContainerConfig containerConfig = ContainerConfig\n+                    .builder()\n+                    .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+                    .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 100)\n+                    .build();\n+            final DurableLogConfig durableLogConfig = DurableLogConfig\n+                    .builder()\n+                    .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                    .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                    .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024)\n+                    .build();\n+\n+            // Create the environment for DebugSegmentContainer using the given storageFactory.\n+            @Cleanup TestContext context = createContext(getReadOnlyStorageFactory());\n+            OperationLogFactory localDurableLogFactory = new DurableLogFactory(durableLogConfig, context.dataLogFactory,\n+                    DataRecoveryTestUtils.createExecutorService(10));\n+\n+            for (int containerId = 0; containerId < containerCount; containerId++) {\n+                // start DebugSegmentContainer with given container Id.\n+                DebugStreamSegmentContainerTests.MetadataCleanupContainer localContainer = new\n+                        DebugStreamSegmentContainerTests.MetadataCleanupContainer(containerId, containerConfig, localDurableLogFactory,\n+                        context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, getReadOnlyStorageFactory(),\n+                        context.getDefaultExtensions(), DataRecoveryTestUtils.createExecutorService(10));", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDU5OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764599", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:32:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzIxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -179,8 +177,9 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n-     * persisted storage is used to re-create all segments.\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments, and segments are let\n+     * to be flushed to the long term storage. And then just using the long persisted storage, debug segment container\n+     * registers all the segments.\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzM0OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456607348", "bodyText": "This is superfluous. The next line does this.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:29:36Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -146,7 +178,98 @@ protected boolean appendAfterMerging() {\n         return true;\n     }\n \n-    //endregion\n+    /**\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n+     * persisted storage is used to re-create all segments.\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    public void testDataRecovery() throws Exception {\n+        endToEndDebugSegmentContainer();\n+    }\n+\n+    /**\n+     * End to end test to verify DebugSegmentContainer process.\n+     * @throws Exception If an exception occurred.\n+     */\n+    public void endToEndDebugSegmentContainer() throws Exception {\n+        int containerCount = 4;\n+        ArrayList<String> segmentNames;\n+        HashMap<String, ArrayList<String>> transactionsBySegment;\n+        HashMap<String, Long> lengths = new HashMap<>();\n+        ArrayList<ByteBuf> appendBuffers = new ArrayList<>();\n+        HashMap<String, ByteArrayOutputStream> segmentContents = new HashMap<>();\n+\n+        try (val builder = createBuilder(0);\n+             val readOnlyBuilder = createReadOnlyBuilder()) {\n+            val segmentStore = builder.createStreamSegmentService();\n+            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n+\n+            segmentNames = createSegments(segmentStore);\n+            log.info(\"Created Segments: {}.\", String.join(\", \", segmentNames));\n+            transactionsBySegment = createTransactions(segmentNames, segmentStore);\n+            log.info(\"Created Transactions: {}.\", transactionsBySegment.values().stream().flatMap(Collection::stream).collect(Collectors.joining(\", \")));\n+\n+            // Add some appends and seal segments\n+            ArrayList<String> segmentsAndTransactions = new ArrayList<>(segmentNames);\n+            transactionsBySegment.values().forEach(segmentsAndTransactions::addAll);\n+            appendData(segmentsAndTransactions, segmentContents, lengths, appendBuffers, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished appending data.\");\n+\n+            // Wait for flushing the segments to tier2\n+            waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Finished waiting for segments in Storage.\");\n+\n+            // Get the persistent storage from readOnlySegmentStore.\n+            Storage tier2 = getReadOnlyStorageFactory().createStorageAdapter();\n+\n+            // Delete container metadata segment and attribute index segment for each container Id from the persistent storage.\n+            for (int containerId = 0; containerId < containerCount; containerId++) {\n+                DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, containerId);\n+            }\n+\n+            // List all segments from the long term storage.\n+            Map<Integer, List<SegmentProperties>> segments = DataRecoveryTestUtils.listAllSegments(tier2, containerCount);\n+\n+            // Configurations for DebugSegmentContainer\n+            final ContainerConfig containerConfig = ContainerConfig\n+                    .builder()\n+                    .with(ContainerConfig.SEGMENT_METADATA_EXPIRATION_SECONDS, (int) DEFAULT_CONFIG.getSegmentMetadataExpiration().getSeconds())\n+                    .with(ContainerConfig.MAX_ACTIVE_SEGMENT_COUNT, 100)\n+                    .build();\n+            final DurableLogConfig durableLogConfig = DurableLogConfig\n+                    .builder()\n+                    .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                    .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                    .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024)\n+                    .build();\n+\n+            // Create the environment for DebugSegmentContainer using the given storageFactory.\n+            @Cleanup TestContext context = createContext(getReadOnlyStorageFactory());\n+            OperationLogFactory localDurableLogFactory = new DurableLogFactory(durableLogConfig, context.dataLogFactory,\n+                    DataRecoveryTestUtils.createExecutorService(10));\n+\n+            for (int containerId = 0; containerId < containerCount; containerId++) {\n+                // start DebugSegmentContainer with given container Id.\n+                DebugStreamSegmentContainerTests.MetadataCleanupContainer localContainer = new\n+                        DebugStreamSegmentContainerTests.MetadataCleanupContainer(containerId, containerConfig, localDurableLogFactory,\n+                        context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, getReadOnlyStorageFactory(),\n+                        context.getDefaultExtensions(), DataRecoveryTestUtils.createExecutorService(10));\n+\n+                // Create all segments under the given container Id .\n+                Services.startAsync(localContainer, executorService)\n+                        .thenRun(new DataRecoveryTestUtils.Worker(localContainer, segments.get(containerId))).join();\n+\n+                // Verify if the segment details match.\n+                for (SegmentProperties segmentProperties : segments.get(containerId)) {\n+                    SegmentProperties props = localContainer.getStreamSegmentInfo(segmentProperties.getName(), TIMEOUT).join();\n+                    Assert.assertEquals(\"Segment length mismatch \", segmentProperties.getLength(), props.getLength());\n+                }\n+                Services.stopAsync(localContainer, executorService).join();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDY1MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764650", "bodyText": "Ok.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:32:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzM0OA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -179,8 +177,9 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     }\n \n     /**\n-     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments and then only \n-     * persisted storage is used to re-create all segments.\n+     * Tests an end-to-end scenario for the DebugSegmentContainer. SegmentStore creates some segments, and segments are let\n+     * to be flushed to the long term storage. And then just using the long persisted storage, debug segment container\n+     * registers all the segments.\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzQ2OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456607469", "bodyText": "Why do you need this?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:29:51Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -369,6 +492,10 @@ public void endToEndProcessWithFencing(boolean verifySegmentContent) throws Exce\n \n     //region Helpers\n \n+    private StorageFactory getReadOnlyStorageFactory() {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NDkyMg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459764922", "bodyText": "I need it got the storage used while the normal segment store is executing.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:33:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNzQ2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -492,12 +507,12 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n \n     //region Helpers\n \n-    private StorageFactory getReadOnlyStorageFactory() {\n-        return this.readOnlyStorageFactory;\n+    private StorageFactory getStorageFactory() {\n+        return this.storageFactory;\n     }\n \n-    private ServiceBuilder createBuilder(int instanceId) throws Exception {\n-        val builder = createBuilder(this.configBuilder, instanceId);\n+    private ServiceBuilder createBuilder(int instanceId, boolean useChunkedSegmentStorage) throws Exception {\n+        val builder = createBuilder(this.configBuilder, instanceId, useChunkedSegmentStorage);\n         try {\n             builder.initialize();\n         } catch (Throwable ex) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODEzOA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456608138", "bodyText": "This method has a side effect of setting readOnlyStorageFactory. This is not documented (the documentation says something opposite).\nI don't think you need this.readOnlyBuilder; please rework your code to fetch this value after creating it and then using it where you need it.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:31:10Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -405,6 +532,28 @@ private ServiceBuilder createReadOnlyBuilder(int instanceId) throws Exception {\n         return builder;\n     }\n \n+    /**\n+     * Creates a ServiceBuilder instance, but also gets the storage Factory used in creating.\n+     * @return              A newly created ServiceBuilder instance.\n+     * @throws Exception    In case of any exception occurred during execution.\n+     */\n+    private ServiceBuilder createReadOnlyBuilder() throws Exception {\n+        // Copy base config properties to a new object.\n+        val props = new Properties();\n+        this.configBuilder.build().forEach(props::put);\n+\n+        // Create a new config (so we don't alter the base one) and set the ReadOnlySegmentStore to true).\n+        val configBuilder = ServiceBuilderConfig.builder()\n+                .include(props)\n+                .include(ServiceConfig.builder()\n+                        .with(ServiceConfig.READONLY_SEGMENT_STORE, true));\n+\n+        val builder = createBuilder(configBuilder, 0);\n+        builder.initialize();\n+        this.readOnlyStorageFactory = builder.getStorageFactory();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1MjkzNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465352935", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-08-04T21:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODEzOA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -512,45 +527,25 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n      *\n      * @param builderConfig The configuration to use.\n      * @param instanceId    The Id of the ServiceBuilder to create. For least interference, these should be unique.\n+     * @param useChunkedSegmentStorage whether to use ChunkedSegmentStorage or instead use AsyncStorageWrapper.\n      * @return The ServiceBuilder.\n      */\n-    protected abstract ServiceBuilder createBuilder(ServiceBuilderConfig.Builder builderConfig, int instanceId);\n-\n-    private ServiceBuilder createReadOnlyBuilder(int instanceId) throws Exception {\n-        // Copy base config properties to a new object.\n-        val props = new Properties();\n-        this.configBuilder.build().forEach(props::put);\n-\n-        // Create a new config (so we don't alter the base one) and set the ReadOnlySegmentStore to true).\n-        val configBuilder = ServiceBuilderConfig.builder()\n-                                                .include(props)\n-                                                .include(ServiceConfig.builder()\n-                                                                      .with(ServiceConfig.READONLY_SEGMENT_STORE, true));\n-\n-        val builder = createBuilder(configBuilder, instanceId);\n-        builder.initialize();\n-        return builder;\n-    }\n+    protected abstract ServiceBuilder createBuilder(ServiceBuilderConfig.Builder builderConfig, int instanceId, boolean useChunkedSegmentStorage);\n \n     /**\n      * Creates a ServiceBuilder instance, but also gets the storage Factory used in creating.\n      * @return              A newly created ServiceBuilder instance.\n      * @throws Exception    In case of any exception occurred during execution.\n      */\n-    private ServiceBuilder createReadOnlyBuilder() throws Exception {\n-        // Copy base config properties to a new object.\n-        val props = new Properties();\n-        this.configBuilder.build().forEach(props::put);\n-\n-        // Create a new config (so we don't alter the base one) and set the ReadOnlySegmentStore to true).\n-        val configBuilder = ServiceBuilderConfig.builder()\n-                .include(props)\n-                .include(ServiceConfig.builder()\n-                        .with(ServiceConfig.READONLY_SEGMENT_STORE, true));\n-\n-        val builder = createBuilder(configBuilder, 0);\n-        builder.initialize();\n-        this.readOnlyStorageFactory = builder.getStorageFactory();\n+    private ServiceBuilder createBuilder(int instanceId) throws Exception {\n+        val builder = createBuilder(this.configBuilder, instanceId, false);\n+        try {\n+            builder.initialize();\n+            this.storageFactory = builder.getStorageFactory();\n+        } catch (Throwable ex) {\n+            builder.close();\n+            throw ex;\n+        }\n         return builder;\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODQ0NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456608445", "bodyText": "I've seen these configs somewhere else. Can you combine them into a single one?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:31:48Z", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -1009,4 +1158,60 @@ void createNewInstance() {\n     private interface StoreRequest {\n         CompletableFuture<Void> apply(StreamSegmentStore store);\n     }\n+\n+    public TestContext createContext(StorageFactory storageFactory) {\n+        return new TestContext(storageFactory);\n+    }\n+\n+    public class TestContext implements AutoCloseable {\n+        private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n+        private final StorageFactory storageFactory;\n+        private final DurableDataLogFactory dataLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheStorage cacheStorage;\n+        private final CacheManager cacheManager;\n+        private final ReadIndexConfig defaultReadIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+\n+        private final AttributeIndexConfig defaultAttributeIndexConfig = AttributeIndexConfig", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NjI5NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459766294", "bodyText": "Ok.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:37:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODQ0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\nindex a836ddc37..389589280 100644\n--- a/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n+++ b/segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java\n\n@@ -1158,60 +1173,4 @@ public abstract class StreamSegmentStoreTestBase extends ThreadPooledTestSuite {\n     private interface StoreRequest {\n         CompletableFuture<Void> apply(StreamSegmentStore store);\n     }\n-\n-    public TestContext createContext(StorageFactory storageFactory) {\n-        return new TestContext(storageFactory);\n-    }\n-\n-    public class TestContext implements AutoCloseable {\n-        private static final int MAX_DATA_LOG_APPEND_SIZE = 100 * 1024;\n-        private final StorageFactory storageFactory;\n-        private final DurableDataLogFactory dataLogFactory;\n-        private final ReadIndexFactory readIndexFactory;\n-        private final AttributeIndexFactory attributeIndexFactory;\n-        private final WriterFactory writerFactory;\n-        private final CacheStorage cacheStorage;\n-        private final CacheManager cacheManager;\n-        private final ReadIndexConfig defaultReadIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n-\n-        private final AttributeIndexConfig defaultAttributeIndexConfig = AttributeIndexConfig\n-                .builder()\n-                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n-                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n-                .build();\n-\n-        private final WriterConfig defaultWriterConfig = WriterConfig\n-                .builder()\n-                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n-                .with(WriterConfig.FLUSH_ATTRIBUTES_THRESHOLD, 3)\n-                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n-                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n-                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n-                .build();\n-        TestContext(StorageFactory storageFactory) {\n-            this.storageFactory = storageFactory;\n-            this.dataLogFactory = new InMemoryDurableDataLogFactory(MAX_DATA_LOG_APPEND_SIZE, executorService());\n-            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n-            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService());\n-            this.readIndexFactory = new ContainerReadIndexFactory(defaultReadIndexConfig, this.cacheManager, executorService());\n-            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(defaultAttributeIndexConfig, this.cacheManager, executorService());\n-            this.writerFactory = new StorageWriterFactory(defaultWriterConfig, executorService());\n-        }\n-\n-        SegmentContainerFactory.CreateExtensions getDefaultExtensions() {\n-            return (c, e) -> Collections.singletonMap(ContainerTableExtension.class, createTableExtension(c, e));\n-        }\n-\n-        private ContainerTableExtension createTableExtension(SegmentContainer c, ScheduledExecutorService e) {\n-            return new ContainerTableExtensionImpl(c, this.cacheManager, e);\n-        }\n-\n-        @Override\n-        public void close() {\n-            this.dataLogFactory.close();\n-            this.cacheManager.close();\n-            this.cacheStorage.close();\n-            this.readIndexFactory.close();\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODU5NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456608594", "bodyText": "I don't see unit tests for this.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:32:08Z", "path": "shared/protocol/src/main/java/io/pravega/shared/NameUtils.java", "diffHunk": "@@ -197,6 +197,16 @@ public static String getHeaderSegmentName(String segmentName) {\n         return segmentName + HEADER_SUFFIX;\n     }\n \n+    /**\n+     * Checks whether given name is an Attribute Segment.\n+     *\n+     * @param segmentName   The name of the segment.\n+     * @return              true if the name is Attribute Segment. False otherwise\n+     */\n+    public static boolean isAttributeSegment(String segmentName) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NjM0NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459766345", "bodyText": "Removed.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:37:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODU5NA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java b/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\nindex da7207176..bdaa4c37c 100644\n--- a/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\n+++ b/shared/protocol/src/main/java/io/pravega/shared/NameUtils.java\n\n@@ -197,16 +214,6 @@ public final class NameUtils {\n         return segmentName + HEADER_SUFFIX;\n     }\n \n-    /**\n-     * Checks whether given name is an Attribute Segment.\n-     *\n-     * @param segmentName   The name of the segment.\n-     * @return              true if the name is Attribute Segment. False otherwise\n-     */\n-    public static boolean isAttributeSegment(String segmentName) {\n-        return segmentName.endsWith(ATTRIBUTE_SUFFIX);\n-    }\n-  \n     /**\n      * Checks whether given name is a Header Segment.\n      *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODcwNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456608707", "bodyText": "Huge timeout", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:32:22Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NjQ0Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459766446", "bodyText": "Changed to 100 s.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:37:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODcwNw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODgwNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456608804", "bodyText": "provide a seed", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:32:32Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NjQ5MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459766490", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:37:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwODgwNA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTE5NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456609194", "bodyText": "Remove this.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:33:21Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NjUzNA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459766534", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:38:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTE5NA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTI5OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456609299", "bodyText": "private", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:33:33Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDg5NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456610895", "bodyText": "And what's the point of this if it's just invoking the constructor?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:36:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NzAzNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459767035", "bodyText": "Made private. It has a bunch of variables, and close method which is used to close BK/ZK.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:39:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTI5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTg1Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456609856", "bodyText": "Please clean this class up. There are a number of things you hardcoded in here and then you're just proliferating them.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:34:46Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDEyNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456610126", "bodyText": "For example, there is no need for security, Remove all that is related to that.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:35:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTg1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NzE4Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459767186", "bodyText": "Cleaned.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:40:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwOTg1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDI2OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456610269", "bodyText": "You only have 1 bookie. Simplify your code.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:35:34Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NzMzMQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459767331", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:40:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDI2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU3MDcwOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r469570709", "bodyText": "So then why do you still have a list of ports?", "author": "andreipaduroiu", "createdAt": "2020-08-12T21:59:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDI2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDU3Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456610576", "bodyText": "@Override", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:36:15Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2NzU1Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459767553", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:41:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDU3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDc2MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456610761", "bodyText": "What's the point of this if it's just invoking the constructor?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:36:36Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODIyNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768227", "bodyText": "Close method is used, and makes it easy to see through the variables used.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:43:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMDc2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTAyMQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456611021", "bodyText": "See if you can consolidate all these", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:37:08Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODMzMQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768331", "bodyText": "Couldn't do that.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:43:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTAyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM5NzUxNw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465397517", "bodyText": "Removed it.", "author": "ManishKumarKeshri", "createdAt": "2020-08-05T00:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTAyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTA4NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456611085", "bodyText": "Check for nulls.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:37:19Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODM3Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768373", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:43:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTA4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTUyOQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456611529", "bodyText": "This code looks copied from ServiceBuilder. Can you find a way to reuse that code? If we modify the extensions in ServiceBuilder, this code will break. Please try to reuse as much as you can from that class.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:38:19Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODU4OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768588", "bodyText": "Couldn't reuse. I will try again.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:44:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTUyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDY1Njg0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r460656842", "bodyText": "I am not able to reuse it.", "author": "ManishKumarKeshri", "createdAt": "2020-07-27T05:38:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTUyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM5NzEyNQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465397125", "bodyText": "Removed it all together.", "author": "ManishKumarKeshri", "createdAt": "2020-08-05T00:07:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMTUyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjA2NQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456612065", "bodyText": "You do not need a 2GB cache.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:39:26Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODY5Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768697", "bodyText": "Made it 1/5th..", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:44:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjA2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM5NzAxNg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r465397016", "bodyText": "Is it fine?", "author": "ManishKumarKeshri", "createdAt": "2020-08-05T00:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjA2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjI3MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456612271", "bodyText": "Verify that you are shutting down everything that needs to shut down.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:39:52Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();\n+            this.cacheManager.close();\n+            this.cacheStorage.close();\n+            this.dataLogFactory.close();\n+        }\n+    }\n+\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    }\n+\n+    /**\n+     * Creates a segment store server.\n+     */\n+    private static class SegmentStoreStarter {\n+        private final int servicePort = TestUtils.getAvailableListenPort();\n+        private ServiceBuilder serviceBuilder;\n+        private StreamSegmentStoreWrapper streamSegmentStoreWrapper;\n+        private AutoScaleMonitor monitor;\n+        private TableStoreWrapper tableStoreWrapper;\n+        private PravegaConnectionListener server;\n+\n+        SegmentStoreStarter(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+            if (storageFactory != null) {\n+                if (dataLogFactory != null) {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory)\n+                            .withDataLogFactory(setup -> dataLogFactory);\n+                } else {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory);\n+                }\n+            } else {\n+                this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig());\n+            }\n+            this.serviceBuilder.initialize();\n+            this.streamSegmentStoreWrapper = new StreamSegmentStoreWrapper(serviceBuilder.createStreamSegmentService());\n+            this.monitor = new AutoScaleMonitor(streamSegmentStoreWrapper, AutoScalerConfig.builder().build());\n+            this.tableStoreWrapper = new TableStoreWrapper(serviceBuilder.createTableStoreService());\n+            this.server = new PravegaConnectionListener(false, false, \"localhost\", servicePort, streamSegmentStoreWrapper,\n+                    tableStoreWrapper, monitor.getStatsRecorder(), monitor.getTableSegmentStatsRecorder(), new PassingTokenVerifier(),\n+                    null, null, true, serviceBuilder.getLowPriorityExecutor());\n+            this.server.startListening();\n+        }\n+\n+        public void close() {\n+            if (this.server != null) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDY1NjE1MA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r460656150", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-27T05:36:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjI3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjI5Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456612293", "bodyText": "Verify that you are shutting down everything that needs to shut down.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:39:55Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODc0Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768743", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:44:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjI5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjM1Ng==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456612356", "bodyText": "Verify that you are shutting down everything that needs to shut down.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:40:02Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();\n+            this.cacheManager.close();\n+            this.cacheStorage.close();\n+            this.dataLogFactory.close();\n+        }\n+    }\n+\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    }\n+\n+    /**\n+     * Creates a segment store server.\n+     */\n+    private static class SegmentStoreStarter {\n+        private final int servicePort = TestUtils.getAvailableListenPort();\n+        private ServiceBuilder serviceBuilder;\n+        private StreamSegmentStoreWrapper streamSegmentStoreWrapper;\n+        private AutoScaleMonitor monitor;\n+        private TableStoreWrapper tableStoreWrapper;\n+        private PravegaConnectionListener server;\n+\n+        SegmentStoreStarter(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+            if (storageFactory != null) {\n+                if (dataLogFactory != null) {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory)\n+                            .withDataLogFactory(setup -> dataLogFactory);\n+                } else {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory);\n+                }\n+            } else {\n+                this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig());\n+            }\n+            this.serviceBuilder.initialize();\n+            this.streamSegmentStoreWrapper = new StreamSegmentStoreWrapper(serviceBuilder.createStreamSegmentService());\n+            this.monitor = new AutoScaleMonitor(streamSegmentStoreWrapper, AutoScalerConfig.builder().build());\n+            this.tableStoreWrapper = new TableStoreWrapper(serviceBuilder.createTableStoreService());\n+            this.server = new PravegaConnectionListener(false, false, \"localhost\", servicePort, streamSegmentStoreWrapper,\n+                    tableStoreWrapper, monitor.getStatsRecorder(), monitor.getTableSegmentStatsRecorder(), new PassingTokenVerifier(),\n+                    null, null, true, serviceBuilder.getLowPriorityExecutor());\n+            this.server.startListening();\n+        }\n+\n+        public void close() {\n+            if (this.server != null) {\n+                this.server.close();\n+                this.server = null;\n+            }\n+\n+            if (this.monitor != null) {\n+                this.monitor.close();\n+                this.monitor = null;\n+            }\n+\n+            if (this.serviceBuilder != null) {\n+                this.serviceBuilder.close();\n+                this.serviceBuilder = null;\n+            }\n+        }\n+    }\n+\n+    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort);\n+    }\n+\n+    /**\n+     * Creates a controller instance and runs it.\n+     */\n+    private static class ControllerStarter {\n+        private final int controllerPort = TestUtils.getAvailableListenPort();\n+        private final String serviceHost = \"localhost\";\n+        private ControllerWrapper controllerWrapper = null;\n+        private Controller controller = null;\n+\n+        ControllerStarter(int bkPort, int servicePort) throws InterruptedException {\n+            this.controllerWrapper = new ControllerWrapper(\"localhost:\" + bkPort, false,\n+                    controllerPort, serviceHost, servicePort, CONTAINER_COUNT);\n+            this.controllerWrapper.awaitRunning();\n+            this.controller = controllerWrapper.getController();\n+        }\n+\n+        public void close() throws Exception {\n+            if (this.controller != null) {", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODc3OA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768778", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:44:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjM1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjg1NA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456612854", "bodyText": "Put @Cleanup on a different line. Below too", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:41:03Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();\n+            this.cacheManager.close();\n+            this.cacheStorage.close();\n+            this.dataLogFactory.close();\n+        }\n+    }\n+\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    }\n+\n+    /**\n+     * Creates a segment store server.\n+     */\n+    private static class SegmentStoreStarter {\n+        private final int servicePort = TestUtils.getAvailableListenPort();\n+        private ServiceBuilder serviceBuilder;\n+        private StreamSegmentStoreWrapper streamSegmentStoreWrapper;\n+        private AutoScaleMonitor monitor;\n+        private TableStoreWrapper tableStoreWrapper;\n+        private PravegaConnectionListener server;\n+\n+        SegmentStoreStarter(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+            if (storageFactory != null) {\n+                if (dataLogFactory != null) {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory)\n+                            .withDataLogFactory(setup -> dataLogFactory);\n+                } else {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory);\n+                }\n+            } else {\n+                this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig());\n+            }\n+            this.serviceBuilder.initialize();\n+            this.streamSegmentStoreWrapper = new StreamSegmentStoreWrapper(serviceBuilder.createStreamSegmentService());\n+            this.monitor = new AutoScaleMonitor(streamSegmentStoreWrapper, AutoScalerConfig.builder().build());\n+            this.tableStoreWrapper = new TableStoreWrapper(serviceBuilder.createTableStoreService());\n+            this.server = new PravegaConnectionListener(false, false, \"localhost\", servicePort, streamSegmentStoreWrapper,\n+                    tableStoreWrapper, monitor.getStatsRecorder(), monitor.getTableSegmentStatsRecorder(), new PassingTokenVerifier(),\n+                    null, null, true, serviceBuilder.getLowPriorityExecutor());\n+            this.server.startListening();\n+        }\n+\n+        public void close() {\n+            if (this.server != null) {\n+                this.server.close();\n+                this.server = null;\n+            }\n+\n+            if (this.monitor != null) {\n+                this.monitor.close();\n+                this.monitor = null;\n+            }\n+\n+            if (this.serviceBuilder != null) {\n+                this.serviceBuilder.close();\n+                this.serviceBuilder = null;\n+            }\n+        }\n+    }\n+\n+    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort);\n+    }\n+\n+    /**\n+     * Creates a controller instance and runs it.\n+     */\n+    private static class ControllerStarter {\n+        private final int controllerPort = TestUtils.getAvailableListenPort();\n+        private final String serviceHost = \"localhost\";\n+        private ControllerWrapper controllerWrapper = null;\n+        private Controller controller = null;\n+\n+        ControllerStarter(int bkPort, int servicePort) throws InterruptedException {\n+            this.controllerWrapper = new ControllerWrapper(\"localhost:\" + bkPort, false,\n+                    controllerPort, serviceHost, servicePort, CONTAINER_COUNT);\n+            this.controllerWrapper.awaitRunning();\n+            this.controller = controllerWrapper.getController();\n+        }\n+\n+        public void close() throws Exception {\n+            if (this.controller != null) {\n+                this.controller.close();\n+                this.controller = null;\n+            }\n+\n+            if (this.controllerWrapper != null) {\n+                this.controllerWrapper.close();\n+                this.controllerWrapper = null;\n+            }\n+        }\n+    }\n+\n+    @Test(timeout = 240000)\n+    public void testDurableDataLogFail() throws Exception {\n+        int instanceId = 0;\n+\n+        // Creating tier 2 only once here.\n+        this.baseDir = Files.createTempDirectory(\"test_nfs\").toFile().getAbsoluteFile();\n+        FileSystemStorageConfig fsConfig = FileSystemStorageConfig\n+                .builder()\n+                .with(FileSystemStorageConfig.ROOT, this.baseDir.getAbsolutePath())\n+                .build();\n+        this.storageFactory = new FileSystemStorageFactory(fsConfig, executorService);\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.segmentStoreStarter = startSegmentStore(this.storageFactory, null);\n+        @Cleanup ControllerStarter controllerStarter = startController(this.bkzk.bkPort, this.segmentStoreStarter.servicePort);", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2ODg4Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459768883", "bodyText": "Done.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:45:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMjg1NA=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzE5MQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456613191", "bodyText": "You need to figure out how to make this work without sleeping.", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:41:45Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();\n+            this.cacheManager.close();\n+            this.cacheStorage.close();\n+            this.dataLogFactory.close();\n+        }\n+    }\n+\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    }\n+\n+    /**\n+     * Creates a segment store server.\n+     */\n+    private static class SegmentStoreStarter {\n+        private final int servicePort = TestUtils.getAvailableListenPort();\n+        private ServiceBuilder serviceBuilder;\n+        private StreamSegmentStoreWrapper streamSegmentStoreWrapper;\n+        private AutoScaleMonitor monitor;\n+        private TableStoreWrapper tableStoreWrapper;\n+        private PravegaConnectionListener server;\n+\n+        SegmentStoreStarter(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+            if (storageFactory != null) {\n+                if (dataLogFactory != null) {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory)\n+                            .withDataLogFactory(setup -> dataLogFactory);\n+                } else {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory);\n+                }\n+            } else {\n+                this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig());\n+            }\n+            this.serviceBuilder.initialize();\n+            this.streamSegmentStoreWrapper = new StreamSegmentStoreWrapper(serviceBuilder.createStreamSegmentService());\n+            this.monitor = new AutoScaleMonitor(streamSegmentStoreWrapper, AutoScalerConfig.builder().build());\n+            this.tableStoreWrapper = new TableStoreWrapper(serviceBuilder.createTableStoreService());\n+            this.server = new PravegaConnectionListener(false, false, \"localhost\", servicePort, streamSegmentStoreWrapper,\n+                    tableStoreWrapper, monitor.getStatsRecorder(), monitor.getTableSegmentStatsRecorder(), new PassingTokenVerifier(),\n+                    null, null, true, serviceBuilder.getLowPriorityExecutor());\n+            this.server.startListening();\n+        }\n+\n+        public void close() {\n+            if (this.server != null) {\n+                this.server.close();\n+                this.server = null;\n+            }\n+\n+            if (this.monitor != null) {\n+                this.monitor.close();\n+                this.monitor = null;\n+            }\n+\n+            if (this.serviceBuilder != null) {\n+                this.serviceBuilder.close();\n+                this.serviceBuilder = null;\n+            }\n+        }\n+    }\n+\n+    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort);\n+    }\n+\n+    /**\n+     * Creates a controller instance and runs it.\n+     */\n+    private static class ControllerStarter {\n+        private final int controllerPort = TestUtils.getAvailableListenPort();\n+        private final String serviceHost = \"localhost\";\n+        private ControllerWrapper controllerWrapper = null;\n+        private Controller controller = null;\n+\n+        ControllerStarter(int bkPort, int servicePort) throws InterruptedException {\n+            this.controllerWrapper = new ControllerWrapper(\"localhost:\" + bkPort, false,\n+                    controllerPort, serviceHost, servicePort, CONTAINER_COUNT);\n+            this.controllerWrapper.awaitRunning();\n+            this.controller = controllerWrapper.getController();\n+        }\n+\n+        public void close() throws Exception {\n+            if (this.controller != null) {\n+                this.controller.close();\n+                this.controller = null;\n+            }\n+\n+            if (this.controllerWrapper != null) {\n+                this.controllerWrapper.close();\n+                this.controllerWrapper = null;\n+            }\n+        }\n+    }\n+\n+    @Test(timeout = 240000)\n+    public void testDurableDataLogFail() throws Exception {\n+        int instanceId = 0;\n+\n+        // Creating tier 2 only once here.\n+        this.baseDir = Files.createTempDirectory(\"test_nfs\").toFile().getAbsoluteFile();\n+        FileSystemStorageConfig fsConfig = FileSystemStorageConfig\n+                .builder()\n+                .with(FileSystemStorageConfig.ROOT, this.baseDir.getAbsolutePath())\n+                .build();\n+        this.storageFactory = new FileSystemStorageFactory(fsConfig, executorService);\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.segmentStoreStarter = startSegmentStore(this.storageFactory, null);\n+        @Cleanup ControllerStarter controllerStarter = startController(this.bkzk.bkPort, this.segmentStoreStarter.servicePort);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        @Cleanup ConnectionFactory connectionFactory = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+        @Cleanup ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory, connectionFactory);\n+\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n+        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+\n+        // Verify events write by reading them.\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+\n+        readerGroupManager.close();\n+        clientFactory.close();\n+\n+        controllerStarter.close(); // Shut down the controller\n+\n+        // Get names of all the segments created.\n+        HashSet<String> allSegments = new HashSet<>(this.segmentStoreStarter.streamSegmentStoreWrapper.getSegments());\n+        allSegments.addAll(this.segmentStoreStarter.tableStoreWrapper.getSegments());\n+        log.info(\"No. of segments created = {}\", allSegments.size());\n+\n+        // Get the long term storage from the running pravega instance\n+        @Cleanup Storage tier2 = new AsyncStorageWrapper(new RollingStorage(this.storageFactory.createSyncStorage(),\n+                new SegmentRollingPolicy(DEFAULT_ROLLING_SIZE)), DataRecoveryTestUtils.createExecutorService(1));\n+\n+        // wait for all segments to be flushed to the long term storage.\n+        waitForSegmentsInStorage(allSegments, this.segmentStoreStarter.streamSegmentStoreWrapper, tier2)\n+                .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        this.segmentStoreStarter.close(); // Shutdown SegmentStore\n+        this.segmentStoreStarter = null;\n+        log.info(\"Segment Store Shutdown\");\n+\n+        this.bkzk.close(); // Shutdown BookKeeper & ZooKeeper\n+        this.bkzk = null;\n+        log.info(\"BookKeeper & ZooKeeper shutdown\");\n+\n+        // start a new BookKeeper and ZooKeeper.\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.dataLogFactory = new BookKeeperLogFactory(this.bkzk.bkConfig.get(), this.bkzk.zkClient.get(),\n+                DataRecoveryTestUtils.createExecutorService(1));\n+        this.dataLogFactory.initialize();\n+\n+        // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+        DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, CONTAINER_ID);\n+\n+        // List all segments from the long term storage\n+        Map<Integer, List<SegmentProperties>> segmentsToCreate = DataRecoveryTestUtils.listAllSegments(tier2, CONTAINER_COUNT);\n+\n+        // Start debug segment container using dataLogFactory from new BK instance and old long term storageFactory.\n+        DebugTool debugTool = createDebugTool(this.dataLogFactory, this.storageFactory);\n+        DebugStreamSegmentContainer debugStreamSegmentContainer = (DebugStreamSegmentContainer)\n+                debugTool.containerFactory.createDebugStreamSegmentContainer(CONTAINER_ID);\n+\n+        // Re-create all segments which were listed.\n+        Services.startAsync(debugStreamSegmentContainer, executorService)\n+                .thenRun(new DataRecoveryTestUtils.Worker(debugStreamSegmentContainer, segmentsToCreate.get(CONTAINER_ID))).join();\n+        sleep(5000); // Without sleep the test fails sometimes complaining some segment offsets don't exist.", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2OTA3Nw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459769077", "bodyText": "Removed sleep. Doesn't fail on Travis, though fails locally sometimes. Will create an issue for it.", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:45:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzE5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDY1NTk0Mg==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r460655942", "bodyText": "It doesn't fail locally now even with multiple runs. Just added an extra line to wait for container metadata segment to be flushed to LTS, after debug segment container re-creates it in the Tier1.\nI saw that the test failed only when, debug segment container closed while storage writer has not completed some iterations.\nHere are snippets from two failure tests.\n2020-07-26 20:40:53,317 53008 [pool-2-thread-56] DEBUG i.p.s.server.writer.StorageWriter - StorageWriter[0]: Iteration[5].Finish (Elapsed 53ms).\n2020-07-26 20:40:53,317 53008 [pool-2-thread-23] ERROR i.p.s.s.writer.AttributeAggregator - AttributeAggregator[0-1]: Unable to persist root pointer RootPointer=2970, LastSeqNo=134.\njava.util.concurrent.CancellationException: OperationProcessor is shutting down.\n\tat io.pravega.segmentstore.server.logs.OperationProcessor.doStop(OperationProcessor.java:161)\n\tat com.google.common.util.concurrent.AbstractService.stopAsync(AbstractService.java:280)\n\tat io.pravega.common.concurrent.Services.stopAsync(Services.java:61)\n\tat io.pravega.segmentstore.server.logs.DurableLog.doStop(DurableLog.java:247)\n\tat com.google.common.util.concurrent.AbstractService.stopAsync(AbstractService.java:280)\n\tat io.pravega.common.concurrent.Services.stopAsync(Services.java:61)\n\tat io.pravega.segmentstore.server.containers.StreamSegmentContainer.doStop(StreamSegmentContainer.java:286)\n\tat io.pravega.segmentstore.server.containers.StreamSegmentContainer.doStop(StreamSegmentContainer.java:268)\n\tat com.google.common.util.concurrent.AbstractService.stopAsync(AbstractService.java:280)\n\tat io.pravega.common.concurrent.Services.stopAsync(Services.java:61)\n\tat io.pravega.test.integration.RestoreBackUpDataRecoveryTest.testDurableDataLogFail(RestoreBackUpDataRecoveryTest.java:474)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)\n\tat org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.lang.Thread.run(Thread.java:748)\n\nand another one:\n2020-07-26 12:47:51,375 96296 [pool-82-thread-70] DEBUG i.p.s.server.writer.StorageWriter - StorageWriter[0]: Iteration[6].InputRead (Count=38, Bytes=8769, LastReadSN=142).\n2020-07-26 12:47:51,376 96297 [pool-82-thread-70] ERROR i.p.s.server.writer.StorageWriter - StorageWriter[0]: Iteration[6].Error.\nio.pravega.segmentstore.server.IllegalContainerStateException: Container 0 is in an invalid state for this operation. Expected: RUNNING; Actual: STOPPING.\n\tat io.pravega.segmentstore.server.containers.StreamSegmentContainer.ensureRunning(StreamSegmentContainer.java:799)\n\tat io.pravega.segmentstore.server.containers.StreamSegmentContainer.forSegment(StreamSegmentContainer.java:553)\n\tat io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer.forSegment(DebugStreamSegmentContainer.java:28)\n\tat io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl$TableWriterConnectorImpl.getSegment(ContainerTableExtensionImpl.java:507)\n\tat io.pravega.segmentstore.server.tables.WriterTableProcessor.flush(WriterTableProcessor.java:162)\n\tat io.pravega.segmentstore.server.writer.StorageWriter$ProcessorCollection.lambda$flush$0(StorageWriter.java:646)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat io.pravega.segmentstore.server.writer.StorageWriter$ProcessorCollection.flush(StorageWriter.java:646)\n\tat io.pravega.segmentstore.server.writer.StorageWriter.lambda$flush$8(StorageWriter.java:314)\n\tat java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)\n\tat java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)\n\tat java.util.HashMap$ValueSpliterator.forEachRemaining(HashMap.java:1628)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)\n\tat java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)\n\tat java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n\tat java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566)\n\tat io.pravega.segmentstore.server.writer.StorageWriter.flush(StorageWriter.java:315)\n\tat java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:966)\n\tat java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:940)\n\tat java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:456)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n2020-07-26 12:47:51,376 96297 [pool-82-thread-70] DEBUG i.p.s.server.writer.StorageW\n\nAfter these errors, test starts complaining about some segment chunks being deleted.\nMaybe waiting for container metadata segment to be flushed, provides some time for iterations to finish.", "author": "ManishKumarKeshri", "createdAt": "2020-07-27T05:35:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzE5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzM3Mw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456613373", "bodyText": "Why not bubble up?", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:42:10Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();\n+            this.cacheManager.close();\n+            this.cacheStorage.close();\n+            this.dataLogFactory.close();\n+        }\n+    }\n+\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    }\n+\n+    /**\n+     * Creates a segment store server.\n+     */\n+    private static class SegmentStoreStarter {\n+        private final int servicePort = TestUtils.getAvailableListenPort();\n+        private ServiceBuilder serviceBuilder;\n+        private StreamSegmentStoreWrapper streamSegmentStoreWrapper;\n+        private AutoScaleMonitor monitor;\n+        private TableStoreWrapper tableStoreWrapper;\n+        private PravegaConnectionListener server;\n+\n+        SegmentStoreStarter(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+            if (storageFactory != null) {\n+                if (dataLogFactory != null) {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory)\n+                            .withDataLogFactory(setup -> dataLogFactory);\n+                } else {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory);\n+                }\n+            } else {\n+                this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig());\n+            }\n+            this.serviceBuilder.initialize();\n+            this.streamSegmentStoreWrapper = new StreamSegmentStoreWrapper(serviceBuilder.createStreamSegmentService());\n+            this.monitor = new AutoScaleMonitor(streamSegmentStoreWrapper, AutoScalerConfig.builder().build());\n+            this.tableStoreWrapper = new TableStoreWrapper(serviceBuilder.createTableStoreService());\n+            this.server = new PravegaConnectionListener(false, false, \"localhost\", servicePort, streamSegmentStoreWrapper,\n+                    tableStoreWrapper, monitor.getStatsRecorder(), monitor.getTableSegmentStatsRecorder(), new PassingTokenVerifier(),\n+                    null, null, true, serviceBuilder.getLowPriorityExecutor());\n+            this.server.startListening();\n+        }\n+\n+        public void close() {\n+            if (this.server != null) {\n+                this.server.close();\n+                this.server = null;\n+            }\n+\n+            if (this.monitor != null) {\n+                this.monitor.close();\n+                this.monitor = null;\n+            }\n+\n+            if (this.serviceBuilder != null) {\n+                this.serviceBuilder.close();\n+                this.serviceBuilder = null;\n+            }\n+        }\n+    }\n+\n+    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort);\n+    }\n+\n+    /**\n+     * Creates a controller instance and runs it.\n+     */\n+    private static class ControllerStarter {\n+        private final int controllerPort = TestUtils.getAvailableListenPort();\n+        private final String serviceHost = \"localhost\";\n+        private ControllerWrapper controllerWrapper = null;\n+        private Controller controller = null;\n+\n+        ControllerStarter(int bkPort, int servicePort) throws InterruptedException {\n+            this.controllerWrapper = new ControllerWrapper(\"localhost:\" + bkPort, false,\n+                    controllerPort, serviceHost, servicePort, CONTAINER_COUNT);\n+            this.controllerWrapper.awaitRunning();\n+            this.controller = controllerWrapper.getController();\n+        }\n+\n+        public void close() throws Exception {\n+            if (this.controller != null) {\n+                this.controller.close();\n+                this.controller = null;\n+            }\n+\n+            if (this.controllerWrapper != null) {\n+                this.controllerWrapper.close();\n+                this.controllerWrapper = null;\n+            }\n+        }\n+    }\n+\n+    @Test(timeout = 240000)\n+    public void testDurableDataLogFail() throws Exception {\n+        int instanceId = 0;\n+\n+        // Creating tier 2 only once here.\n+        this.baseDir = Files.createTempDirectory(\"test_nfs\").toFile().getAbsoluteFile();\n+        FileSystemStorageConfig fsConfig = FileSystemStorageConfig\n+                .builder()\n+                .with(FileSystemStorageConfig.ROOT, this.baseDir.getAbsolutePath())\n+                .build();\n+        this.storageFactory = new FileSystemStorageFactory(fsConfig, executorService);\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.segmentStoreStarter = startSegmentStore(this.storageFactory, null);\n+        @Cleanup ControllerStarter controllerStarter = startController(this.bkzk.bkPort, this.segmentStoreStarter.servicePort);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        @Cleanup ConnectionFactory connectionFactory = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+        @Cleanup ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory, connectionFactory);\n+\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n+        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+\n+        // Verify events write by reading them.\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+\n+        readerGroupManager.close();\n+        clientFactory.close();\n+\n+        controllerStarter.close(); // Shut down the controller\n+\n+        // Get names of all the segments created.\n+        HashSet<String> allSegments = new HashSet<>(this.segmentStoreStarter.streamSegmentStoreWrapper.getSegments());\n+        allSegments.addAll(this.segmentStoreStarter.tableStoreWrapper.getSegments());\n+        log.info(\"No. of segments created = {}\", allSegments.size());\n+\n+        // Get the long term storage from the running pravega instance\n+        @Cleanup Storage tier2 = new AsyncStorageWrapper(new RollingStorage(this.storageFactory.createSyncStorage(),\n+                new SegmentRollingPolicy(DEFAULT_ROLLING_SIZE)), DataRecoveryTestUtils.createExecutorService(1));\n+\n+        // wait for all segments to be flushed to the long term storage.\n+        waitForSegmentsInStorage(allSegments, this.segmentStoreStarter.streamSegmentStoreWrapper, tier2)\n+                .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        this.segmentStoreStarter.close(); // Shutdown SegmentStore\n+        this.segmentStoreStarter = null;\n+        log.info(\"Segment Store Shutdown\");\n+\n+        this.bkzk.close(); // Shutdown BookKeeper & ZooKeeper\n+        this.bkzk = null;\n+        log.info(\"BookKeeper & ZooKeeper shutdown\");\n+\n+        // start a new BookKeeper and ZooKeeper.\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.dataLogFactory = new BookKeeperLogFactory(this.bkzk.bkConfig.get(), this.bkzk.zkClient.get(),\n+                DataRecoveryTestUtils.createExecutorService(1));\n+        this.dataLogFactory.initialize();\n+\n+        // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+        DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, CONTAINER_ID);\n+\n+        // List all segments from the long term storage\n+        Map<Integer, List<SegmentProperties>> segmentsToCreate = DataRecoveryTestUtils.listAllSegments(tier2, CONTAINER_COUNT);\n+\n+        // Start debug segment container using dataLogFactory from new BK instance and old long term storageFactory.\n+        DebugTool debugTool = createDebugTool(this.dataLogFactory, this.storageFactory);\n+        DebugStreamSegmentContainer debugStreamSegmentContainer = (DebugStreamSegmentContainer)\n+                debugTool.containerFactory.createDebugStreamSegmentContainer(CONTAINER_ID);\n+\n+        // Re-create all segments which were listed.\n+        Services.startAsync(debugStreamSegmentContainer, executorService)\n+                .thenRun(new DataRecoveryTestUtils.Worker(debugStreamSegmentContainer, segmentsToCreate.get(CONTAINER_ID))).join();\n+        sleep(5000); // Without sleep the test fails sometimes complaining some segment offsets don't exist.\n+        Services.stopAsync(debugStreamSegmentContainer, executorService).join();\n+        debugStreamSegmentContainer.close();\n+        debugTool.close();\n+\n+        // Start a new segment store and controller\n+        this.segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory);\n+        controllerStarter = startController(this.bkzk.bkPort, this.segmentStoreStarter.servicePort);\n+\n+        connectionFactory = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory, connectionFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+    }\n+\n+    public void createScopeStream(Controller controller, String scopeName, String streamName) {\n+        try (ConnectionFactory cf = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+             StreamManager streamManager = new StreamManagerImpl(controller, cf)) {\n+            streamManager.createScope(scopeName);\n+            streamManager.createStream(scopeName, streamName, config);\n+        }\n+    }\n+\n+    private void writeEvents(String streamName, ClientFactoryImpl clientFactory) {\n+        EventStreamWriter<String> writer = clientFactory.createEventWriter(streamName,\n+                new UTF8StringSerializer(),\n+                EventWriterConfig.builder().build());\n+        for (int i = 0; i < TOTAL_NUM_EVENTS;) {\n+            try {\n+                writer.writeEvent(\"\", EVENT).join();\n+                i++;\n+            } catch (Throwable e) {\n+                Assert.fail(\"Error occurred while writing events.\");", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2OTEzMA==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459769130", "bodyText": "Ok", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:45:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzM3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzQzMw==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r456613433", "bodyText": "here too", "author": "andreipaduroiu", "createdAt": "2020-07-17T18:42:21Z", "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.test.integration;\n+\n+import io.pravega.client.ClientConfig;\n+import io.pravega.client.admin.ReaderGroupManager;\n+import io.pravega.client.admin.StreamManager;\n+import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n+import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.control.impl.Controller;\n+import io.pravega.client.netty.impl.ConnectionFactory;\n+import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n+import io.pravega.client.stream.EventStreamReader;\n+import io.pravega.client.stream.EventStreamWriter;\n+import io.pravega.client.stream.EventWriterConfig;\n+import io.pravega.client.stream.ReaderConfig;\n+import io.pravega.client.stream.ReaderGroupConfig;\n+import io.pravega.client.stream.ScalingPolicy;\n+import io.pravega.client.stream.Stream;\n+import io.pravega.client.stream.StreamConfiguration;\n+import io.pravega.client.stream.impl.ClientFactoryImpl;\n+import io.pravega.client.stream.impl.UTF8StringSerializer;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.concurrent.Services;\n+import io.pravega.common.io.FileHelpers;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentStore;\n+import io.pravega.segmentstore.contracts.StreamSegmentStoreWrapper;\n+import io.pravega.segmentstore.contracts.tables.TableStoreWrapper;\n+import io.pravega.segmentstore.server.CacheManager;\n+import io.pravega.segmentstore.server.CachePolicy;\n+import io.pravega.segmentstore.server.DataRecoveryTestUtils;\n+import io.pravega.segmentstore.server.OperationLogFactory;\n+import io.pravega.segmentstore.server.ReadIndexFactory;\n+import io.pravega.segmentstore.server.SegmentContainer;\n+import io.pravega.segmentstore.server.SegmentContainerExtension;\n+import io.pravega.segmentstore.server.WriterFactory;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexConfig;\n+import io.pravega.segmentstore.server.attributes.AttributeIndexFactory;\n+import io.pravega.segmentstore.server.attributes.ContainerAttributeIndexFactoryImpl;\n+import io.pravega.segmentstore.server.containers.ContainerConfig;\n+import io.pravega.segmentstore.server.containers.DebugStreamSegmentContainer;\n+import io.pravega.segmentstore.server.containers.StreamSegmentContainerFactory;\n+import io.pravega.segmentstore.server.host.delegationtoken.PassingTokenVerifier;\n+import io.pravega.segmentstore.server.host.handler.PravegaConnectionListener;\n+import io.pravega.segmentstore.server.host.stat.AutoScaleMonitor;\n+import io.pravega.segmentstore.server.host.stat.AutoScalerConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogConfig;\n+import io.pravega.segmentstore.server.logs.DurableLogFactory;\n+import io.pravega.segmentstore.server.reading.ContainerReadIndexFactory;\n+import io.pravega.segmentstore.server.reading.ReadIndexConfig;\n+import io.pravega.segmentstore.server.store.ServiceBuilder;\n+import io.pravega.segmentstore.server.store.ServiceBuilderConfig;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtension;\n+import io.pravega.segmentstore.server.tables.ContainerTableExtensionImpl;\n+import io.pravega.segmentstore.server.writer.StorageWriterFactory;\n+import io.pravega.segmentstore.server.writer.WriterConfig;\n+import io.pravega.segmentstore.storage.AsyncStorageWrapper;\n+import io.pravega.segmentstore.storage.DurableDataLogException;\n+import io.pravega.segmentstore.storage.SegmentRollingPolicy;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.cache.CacheStorage;\n+import io.pravega.segmentstore.storage.cache.DirectMemoryCache;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperConfig;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperLogFactory;\n+import io.pravega.segmentstore.storage.impl.bookkeeper.BookKeeperServiceRunner;\n+import io.pravega.segmentstore.storage.rolling.RollingStorage;\n+import io.pravega.shared.NameUtils;\n+import io.pravega.storage.filesystem.FileSystemStorageConfig;\n+import io.pravega.storage.filesystem.FileSystemStorageFactory;\n+import io.pravega.test.common.TestUtils;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import io.pravega.test.integration.demo.ControllerWrapper;\n+import lombok.Cleanup;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.retry.ExponentialBackoffRetry;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static java.lang.Thread.sleep;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+/**\n+ * Integration test to verify data recovery.\n+ * Recovery scenario: when data written to Pravega is already flushed to the long term storage.\n+ */\n+@Slf4j\n+public class RestoreBackUpDataRecoveryTest extends ThreadPooledTestSuite {\n+    protected static final Duration TIMEOUT = Duration.ofMillis(60000 * 1000);\n+\n+    private static final int CONTAINER_COUNT = 1;\n+    private static final int CONTAINER_ID = 0;\n+\n+    /**\n+     * Write 300 events to different segments.\n+     */\n+    private static final long TOTAL_NUM_EVENTS = 300;\n+\n+    private static final String APPEND_FORMAT = \"Segment_%s_Append_%d\";\n+    private static final long DEFAULT_ROLLING_SIZE = (int) (APPEND_FORMAT.length() * 1.5);\n+\n+    private static final Random RANDOM = new Random();\n+\n+    /**\n+     * Scope and streams to read and write events.\n+     */\n+    private static final String SCOPE = \"testMetricsScope\";\n+    private static final String STREAM1 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String STREAM2 = \"testMetricsStream\" + RANDOM.nextInt(Integer.MAX_VALUE);\n+    private static final String EVENT = \"12345\";\n+\n+    private final ScalingPolicy scalingPolicy = ScalingPolicy.fixed(1);\n+    private final StreamConfiguration config = StreamConfiguration.builder().scalingPolicy(scalingPolicy).build();\n+\n+    private ScheduledExecutorService executorService = DataRecoveryTestUtils.createExecutorService(100);\n+    private File baseDir;\n+    private FileSystemStorageFactory storageFactory;\n+    private BookKeeperLogFactory dataLogFactory;\n+    private SegmentStoreStarter segmentStoreStarter;\n+    private BKZK bkzk = null;\n+\n+    @After\n+    public void tearDown() throws Exception {\n+        if (this.dataLogFactory != null) {\n+            this.dataLogFactory.close();\n+            this.dataLogFactory = null;\n+        }\n+\n+        if (this.segmentStoreStarter != null) {\n+            this.segmentStoreStarter.close();\n+            this.segmentStoreStarter = null;\n+        }\n+\n+        if (this.bkzk != null) {\n+            this.bkzk.close();\n+            this.bkzk = null;\n+        }\n+\n+        if (this.baseDir != null) {\n+            FileHelpers.deleteFileOrDirectory(this.baseDir);\n+            this.baseDir = null;\n+        }\n+        executorService.shutdown();\n+    }\n+\n+    @Override\n+    protected int getThreadPoolSize() {\n+        return 100;\n+    }\n+\n+    BKZK setUpNewBK(int instanceId) throws Exception {\n+        return new BKZK(instanceId);\n+    }\n+\n+    /**\n+     * Sets up a new BookKeeper & ZooKeeper.\n+     */\n+    private static class BKZK implements AutoCloseable {\n+        private final int writeCount = 500;\n+        private final int maxWriteAttempts = 3;\n+        private final int maxLedgerSize = 200 * Math.max(10, writeCount / 20);\n+        private final AtomicBoolean secureBk = new AtomicBoolean();\n+        private final int bookieCount = 1;\n+        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+        private int bkPort;\n+\n+        BKZK(int instanceId) throws Exception {\n+            secureBk.set(false);\n+            bkPort = TestUtils.getAvailableListenPort();\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n+\n+            this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n+                    .startZk(true)\n+                    .zkPort(bkPort)\n+                    .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n+                    .secureBK(isSecure())\n+                    .secureZK(isSecure())\n+                    .tlsTrustStore(\"../segmentstore/config/bookie.truststore.jks\")\n+                    .tLSKeyStore(\"../segmentstore/config/bookie.keystore.jks\")\n+                    .tLSKeyStorePasswordPath(\"../segmentstore/config/bookie.keystore.jks.passwd\")\n+                    .bookiePorts(bookiePorts)\n+                    .build();\n+            this.bookKeeperServiceRunner.startAll();\n+            bkService.set(this.bookKeeperServiceRunner);\n+\n+            // Create a ZKClient with a unique namespace.\n+            String baseNamespace = \"pravega/\" + instanceId + \"_\" + Long.toHexString(System.nanoTime());\n+            this.zkClient.set(CuratorFrameworkFactory\n+                    .builder()\n+                    .connectString(\"localhost:\" + bkPort)\n+                    .namespace(baseNamespace)\n+                    .retryPolicy(new ExponentialBackoffRetry(1000, 5))\n+                    .connectionTimeoutMs(10000)\n+                    .sessionTimeoutMs(10000)\n+                    .build());\n+\n+            this.zkClient.get().start();\n+\n+            String logMetaNamespace = \"segmentstore/containers\" + instanceId;\n+            this.bkConfig.set(BookKeeperConfig\n+                    .builder()\n+                    .with(BookKeeperConfig.ZK_ADDRESS, \"localhost:\" + bkPort)\n+                    .with(BookKeeperConfig.MAX_WRITE_ATTEMPTS, maxWriteAttempts)\n+                    .with(BookKeeperConfig.BK_LEDGER_MAX_SIZE, maxLedgerSize)\n+                    .with(BookKeeperConfig.ZK_METADATA_PATH, logMetaNamespace)\n+                    .with(BookKeeperConfig.BK_LEDGER_PATH, \"/pravega/bookkeeper/ledgers\")\n+                    .with(BookKeeperConfig.BK_ENSEMBLE_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_WRITE_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_ACK_QUORUM_SIZE, bookieCount)\n+                    .with(BookKeeperConfig.BK_TLS_ENABLED, isSecure())\n+                    .with(BookKeeperConfig.BK_WRITE_TIMEOUT, 1000)\n+                    .build());\n+        }\n+\n+        public boolean isSecure() {\n+            return secureBk.get();\n+        }\n+\n+        public void close() throws Exception {\n+            val process = this.bkService.getAndSet(null);\n+            if (process != null) {\n+                process.close();\n+            }\n+\n+            val bk = this.bookKeeperServiceRunner;\n+            if (bk != null) {\n+                bk.close();\n+                this.bookKeeperServiceRunner = null;\n+            }\n+\n+            val zkClient = this.zkClient.getAndSet(null);\n+            if (zkClient != null) {\n+                zkClient.close();\n+            }\n+        }\n+    }\n+\n+    DebugTool createDebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+        return new DebugTool(dataLogFactory, storageFactory);\n+    }\n+\n+    /**\n+     * Sets up the environment for creating a DebugSegmentContainer.\n+     */\n+    private class DebugTool implements AutoCloseable {\n+        private final CacheStorage cacheStorage;\n+        private final OperationLogFactory operationLogFactory;\n+        private final ReadIndexFactory readIndexFactory;\n+        private final AttributeIndexFactory attributeIndexFactory;\n+        private final WriterFactory writerFactory;\n+        private final CacheManager cacheManager;\n+        private final StreamSegmentContainerFactory containerFactory;\n+        private final BookKeeperLogFactory dataLogFactory;\n+        private final StorageFactory storageFactory;\n+\n+        private final DurableLogConfig durableLogConfig = DurableLogConfig\n+                .builder()\n+                .with(DurableLogConfig.CHECKPOINT_MIN_COMMIT_COUNT, 1)\n+                .with(DurableLogConfig.CHECKPOINT_COMMIT_COUNT, 10)\n+                .with(DurableLogConfig.CHECKPOINT_TOTAL_COMMIT_LENGTH, 10L * 1024 * 1024L)\n+                .with(DurableLogConfig.START_RETRY_DELAY_MILLIS, 20)\n+                .build();\n+\n+        private final ReadIndexConfig readIndexConfig = ReadIndexConfig.builder().with(ReadIndexConfig.STORAGE_READ_ALIGNMENT, 1024).build();\n+        private final AttributeIndexConfig attributeIndexConfig = AttributeIndexConfig\n+                .builder()\n+                .with(AttributeIndexConfig.MAX_INDEX_PAGE_SIZE, 2 * 1024)\n+                .with(AttributeIndexConfig.ATTRIBUTE_SEGMENT_ROLLING_SIZE, 1000)\n+                .build();\n+        private final WriterConfig writerConfig = WriterConfig\n+                .builder()\n+                .with(WriterConfig.FLUSH_THRESHOLD_BYTES, 1)\n+                .with(WriterConfig.FLUSH_THRESHOLD_MILLIS, 25L)\n+                .with(WriterConfig.MIN_READ_TIMEOUT_MILLIS, 10L)\n+                .with(WriterConfig.MAX_READ_TIMEOUT_MILLIS, 250L)\n+                .build();\n+\n+        DebugTool(BookKeeperLogFactory dataLogFactory, StorageFactory storageFactory) {\n+            this.dataLogFactory = dataLogFactory;\n+            this.storageFactory = storageFactory;\n+            this.operationLogFactory = new DurableLogFactory(durableLogConfig, this.dataLogFactory, executorService);\n+\n+            this.cacheStorage = new DirectMemoryCache(Integer.MAX_VALUE);\n+            this.cacheManager = new CacheManager(CachePolicy.INFINITE, this.cacheStorage, executorService);\n+            this.readIndexFactory = new ContainerReadIndexFactory(readIndexConfig, this.cacheManager, executorService);\n+            this.attributeIndexFactory = new ContainerAttributeIndexFactoryImpl(attributeIndexConfig, this.cacheManager, executorService);\n+            this.writerFactory = new StorageWriterFactory(writerConfig, executorService);\n+\n+            ContainerConfig containerConfig = ServiceBuilderConfig.getDefaultConfig().getConfig(ContainerConfig::builder);\n+            this.containerFactory = new StreamSegmentContainerFactory(containerConfig, this.operationLogFactory,\n+                    this.readIndexFactory, this.attributeIndexFactory, this.writerFactory, this.storageFactory,\n+                    this::createContainerExtensions, executorService);\n+        }\n+\n+        private Map<Class<? extends SegmentContainerExtension>, SegmentContainerExtension> createContainerExtensions(\n+                SegmentContainer container, ScheduledExecutorService executor) {\n+            return Collections.singletonMap(ContainerTableExtension.class, new ContainerTableExtensionImpl(container, this.cacheManager, executor));\n+        }\n+\n+        @Override\n+        public void close() {\n+            this.readIndexFactory.close();\n+            this.cacheManager.close();\n+            this.cacheStorage.close();\n+            this.dataLogFactory.close();\n+        }\n+    }\n+\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    }\n+\n+    /**\n+     * Creates a segment store server.\n+     */\n+    private static class SegmentStoreStarter {\n+        private final int servicePort = TestUtils.getAvailableListenPort();\n+        private ServiceBuilder serviceBuilder;\n+        private StreamSegmentStoreWrapper streamSegmentStoreWrapper;\n+        private AutoScaleMonitor monitor;\n+        private TableStoreWrapper tableStoreWrapper;\n+        private PravegaConnectionListener server;\n+\n+        SegmentStoreStarter(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n+            if (storageFactory != null) {\n+                if (dataLogFactory != null) {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory)\n+                            .withDataLogFactory(setup -> dataLogFactory);\n+                } else {\n+                    this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig())\n+                            .withStorageFactory(setup -> storageFactory);\n+                }\n+            } else {\n+                this.serviceBuilder = ServiceBuilder.newInMemoryBuilder(ServiceBuilderConfig.getDefaultConfig());\n+            }\n+            this.serviceBuilder.initialize();\n+            this.streamSegmentStoreWrapper = new StreamSegmentStoreWrapper(serviceBuilder.createStreamSegmentService());\n+            this.monitor = new AutoScaleMonitor(streamSegmentStoreWrapper, AutoScalerConfig.builder().build());\n+            this.tableStoreWrapper = new TableStoreWrapper(serviceBuilder.createTableStoreService());\n+            this.server = new PravegaConnectionListener(false, false, \"localhost\", servicePort, streamSegmentStoreWrapper,\n+                    tableStoreWrapper, monitor.getStatsRecorder(), monitor.getTableSegmentStatsRecorder(), new PassingTokenVerifier(),\n+                    null, null, true, serviceBuilder.getLowPriorityExecutor());\n+            this.server.startListening();\n+        }\n+\n+        public void close() {\n+            if (this.server != null) {\n+                this.server.close();\n+                this.server = null;\n+            }\n+\n+            if (this.monitor != null) {\n+                this.monitor.close();\n+                this.monitor = null;\n+            }\n+\n+            if (this.serviceBuilder != null) {\n+                this.serviceBuilder.close();\n+                this.serviceBuilder = null;\n+            }\n+        }\n+    }\n+\n+    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort);\n+    }\n+\n+    /**\n+     * Creates a controller instance and runs it.\n+     */\n+    private static class ControllerStarter {\n+        private final int controllerPort = TestUtils.getAvailableListenPort();\n+        private final String serviceHost = \"localhost\";\n+        private ControllerWrapper controllerWrapper = null;\n+        private Controller controller = null;\n+\n+        ControllerStarter(int bkPort, int servicePort) throws InterruptedException {\n+            this.controllerWrapper = new ControllerWrapper(\"localhost:\" + bkPort, false,\n+                    controllerPort, serviceHost, servicePort, CONTAINER_COUNT);\n+            this.controllerWrapper.awaitRunning();\n+            this.controller = controllerWrapper.getController();\n+        }\n+\n+        public void close() throws Exception {\n+            if (this.controller != null) {\n+                this.controller.close();\n+                this.controller = null;\n+            }\n+\n+            if (this.controllerWrapper != null) {\n+                this.controllerWrapper.close();\n+                this.controllerWrapper = null;\n+            }\n+        }\n+    }\n+\n+    @Test(timeout = 240000)\n+    public void testDurableDataLogFail() throws Exception {\n+        int instanceId = 0;\n+\n+        // Creating tier 2 only once here.\n+        this.baseDir = Files.createTempDirectory(\"test_nfs\").toFile().getAbsoluteFile();\n+        FileSystemStorageConfig fsConfig = FileSystemStorageConfig\n+                .builder()\n+                .with(FileSystemStorageConfig.ROOT, this.baseDir.getAbsolutePath())\n+                .build();\n+        this.storageFactory = new FileSystemStorageFactory(fsConfig, executorService);\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.segmentStoreStarter = startSegmentStore(this.storageFactory, null);\n+        @Cleanup ControllerStarter controllerStarter = startController(this.bkzk.bkPort, this.segmentStoreStarter.servicePort);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        @Cleanup ConnectionFactory connectionFactory = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+        @Cleanup ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory, connectionFactory);\n+\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n+        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+\n+        // Verify events write by reading them.\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+\n+        readerGroupManager.close();\n+        clientFactory.close();\n+\n+        controllerStarter.close(); // Shut down the controller\n+\n+        // Get names of all the segments created.\n+        HashSet<String> allSegments = new HashSet<>(this.segmentStoreStarter.streamSegmentStoreWrapper.getSegments());\n+        allSegments.addAll(this.segmentStoreStarter.tableStoreWrapper.getSegments());\n+        log.info(\"No. of segments created = {}\", allSegments.size());\n+\n+        // Get the long term storage from the running pravega instance\n+        @Cleanup Storage tier2 = new AsyncStorageWrapper(new RollingStorage(this.storageFactory.createSyncStorage(),\n+                new SegmentRollingPolicy(DEFAULT_ROLLING_SIZE)), DataRecoveryTestUtils.createExecutorService(1));\n+\n+        // wait for all segments to be flushed to the long term storage.\n+        waitForSegmentsInStorage(allSegments, this.segmentStoreStarter.streamSegmentStoreWrapper, tier2)\n+                .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        this.segmentStoreStarter.close(); // Shutdown SegmentStore\n+        this.segmentStoreStarter = null;\n+        log.info(\"Segment Store Shutdown\");\n+\n+        this.bkzk.close(); // Shutdown BookKeeper & ZooKeeper\n+        this.bkzk = null;\n+        log.info(\"BookKeeper & ZooKeeper shutdown\");\n+\n+        // start a new BookKeeper and ZooKeeper.\n+        this.bkzk = setUpNewBK(instanceId++);\n+        this.dataLogFactory = new BookKeeperLogFactory(this.bkzk.bkConfig.get(), this.bkzk.zkClient.get(),\n+                DataRecoveryTestUtils.createExecutorService(1));\n+        this.dataLogFactory.initialize();\n+\n+        // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+        DataRecoveryTestUtils.deleteContainerMetadataSegments(tier2, CONTAINER_ID);\n+\n+        // List all segments from the long term storage\n+        Map<Integer, List<SegmentProperties>> segmentsToCreate = DataRecoveryTestUtils.listAllSegments(tier2, CONTAINER_COUNT);\n+\n+        // Start debug segment container using dataLogFactory from new BK instance and old long term storageFactory.\n+        DebugTool debugTool = createDebugTool(this.dataLogFactory, this.storageFactory);\n+        DebugStreamSegmentContainer debugStreamSegmentContainer = (DebugStreamSegmentContainer)\n+                debugTool.containerFactory.createDebugStreamSegmentContainer(CONTAINER_ID);\n+\n+        // Re-create all segments which were listed.\n+        Services.startAsync(debugStreamSegmentContainer, executorService)\n+                .thenRun(new DataRecoveryTestUtils.Worker(debugStreamSegmentContainer, segmentsToCreate.get(CONTAINER_ID))).join();\n+        sleep(5000); // Without sleep the test fails sometimes complaining some segment offsets don't exist.\n+        Services.stopAsync(debugStreamSegmentContainer, executorService).join();\n+        debugStreamSegmentContainer.close();\n+        debugTool.close();\n+\n+        // Start a new segment store and controller\n+        this.segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory);\n+        controllerStarter = startController(this.bkzk.bkPort, this.segmentStoreStarter.servicePort);\n+\n+        connectionFactory = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory, connectionFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+    }\n+\n+    public void createScopeStream(Controller controller, String scopeName, String streamName) {\n+        try (ConnectionFactory cf = new ConnectionFactoryImpl(ClientConfig.builder().build());\n+             StreamManager streamManager = new StreamManagerImpl(controller, cf)) {\n+            streamManager.createScope(scopeName);\n+            streamManager.createStream(scopeName, streamName, config);\n+        }\n+    }\n+\n+    private void writeEvents(String streamName, ClientFactoryImpl clientFactory) {\n+        EventStreamWriter<String> writer = clientFactory.createEventWriter(streamName,\n+                new UTF8StringSerializer(),\n+                EventWriterConfig.builder().build());\n+        for (int i = 0; i < TOTAL_NUM_EVENTS;) {\n+            try {\n+                writer.writeEvent(\"\", EVENT).join();\n+                i++;\n+            } catch (Throwable e) {\n+                Assert.fail(\"Error occurred while writing events.\");\n+                break;\n+            }\n+        }\n+        writer.flush();\n+        writer.close();\n+    }\n+\n+    private void readAllEvents(String streamName, ClientFactoryImpl clientFactory, ReaderGroupManager readerGroupManager,\n+                               String readerGroupName, String readerName) {\n+        readerGroupManager.createReaderGroup(readerGroupName,\n+                ReaderGroupConfig\n+                        .builder()\n+                        .stream(Stream.of(SCOPE, streamName))\n+                        .automaticCheckpointIntervalMillis(2000)\n+                        .build());\n+\n+        EventStreamReader<String> reader = clientFactory.createReader(readerName,\n+                readerGroupName,\n+                new UTF8StringSerializer(),\n+                ReaderConfig.builder().build());\n+\n+        for (int q = 0; q < TOTAL_NUM_EVENTS;) {\n+            try {\n+                String eventRead = reader.readNextEvent(SECONDS.toMillis(500)).getEvent();\n+                Assert.assertEquals(\"Event written and read back don't match\", EVENT, eventRead);\n+                q++;\n+            } catch (Exception e) {\n+                Assert.fail(\"Error occurred while reading the events.\");", "originalCommit": "43fa63bbd1203beb32d05f30adcb0c9674aa88bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTc2OTE2OQ==", "url": "https://github.com/pravega/pravega/pull/4716#discussion_r459769169", "bodyText": "Ok", "author": "ManishKumarKeshri", "createdAt": "2020-07-23T22:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYxMzQzMw=="}], "type": "inlineReview", "revised_code": {"commit": "3387f5b297c471c3a19a00bfc8615bad363b59f6", "chunk": "diff --git a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\nindex 3a13233f4..744f94790 100644\n--- a/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n+++ b/test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java\n\n@@ -14,9 +14,11 @@ import io.pravega.client.admin.ReaderGroupManager;\n import io.pravega.client.admin.StreamManager;\n import io.pravega.client.admin.impl.ReaderGroupManagerImpl;\n import io.pravega.client.admin.impl.StreamManagerImpl;\n+import io.pravega.client.connection.impl.ConnectionFactory;\n+import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.connection.impl.SocketConnectionFactoryImpl;\n import io.pravega.client.control.impl.Controller;\n-import io.pravega.client.netty.impl.ConnectionFactory;\n-import io.pravega.client.netty.impl.ConnectionFactoryImpl;\n import io.pravega.client.stream.EventStreamReader;\n import io.pravega.client.stream.EventStreamWriter;\n import io.pravega.client.stream.EventWriterConfig;\n"}}, {"oid": "94e3eeaf4c21c1b75cb38f15176f966edb350144", "url": "https://github.com/pravega/pravega/commit/94e3eeaf4c21c1b75cb38f15176f966edb350144", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-22T15:47:03Z", "type": "commit"}, {"oid": "332b6660ddb69407013c9e5ee73260fb513bd670", "url": "https://github.com/pravega/pravega/commit/332b6660ddb69407013c9e5ee73260fb513bd670", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T05:12:05Z", "type": "commit"}, {"oid": "23bdc636366e00446e7fec407be012efd4a3bd66", "url": "https://github.com/pravega/pravega/commit/23bdc636366e00446e7fec407be012efd4a3bd66", "message": "Fixing build fail.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T06:11:34Z", "type": "commit"}, {"oid": "1d4279efe75e07fcfa6ce79735d6024313e9dcbb", "url": "https://github.com/pravega/pravega/commit/1d4279efe75e07fcfa6ce79735d6024313e9dcbb", "message": "Update NameUtils\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T17:54:44Z", "type": "commit"}, {"oid": "8497d0d9be814f8fe37f900e0cad25b5993ca9fb", "url": "https://github.com/pravega/pravega/commit/8497d0d9be814f8fe37f900e0cad25b5993ca9fb", "message": "Chaning storageFactory type in DR integration test.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T19:35:39Z", "type": "commit"}, {"oid": "cbf145363ff7f9a3e493a9f048041e10bbbe3a02", "url": "https://github.com/pravega/pravega/commit/cbf145363ff7f9a3e493a9f048041e10bbbe3a02", "message": "Updating\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T21:42:57Z", "type": "commit"}, {"oid": "b30f9f0f5a60fcd8052b3a857ed3eff9a51737e8", "url": "https://github.com/pravega/pravega/commit/b30f9f0f5a60fcd8052b3a857ed3eff9a51737e8", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T21:56:56Z", "type": "commit"}, {"oid": "231974fa1f4a0218db8dba2f9168baa109247f21", "url": "https://github.com/pravega/pravega/commit/231974fa1f4a0218db8dba2f9168baa109247f21", "message": "Adding github link.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T22:03:12Z", "type": "commit"}, {"oid": "2135f6c57a3e4e67b5ed87bc496050fb517798fa", "url": "https://github.com/pravega/pravega/commit/2135f6c57a3e4e67b5ed87bc496050fb517798fa", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-23T22:48:36Z", "type": "commit"}, {"oid": "224aa05c74455448f987f7bd25780357f0ff2971", "url": "https://github.com/pravega/pravega/commit/224aa05c74455448f987f7bd25780357f0ff2971", "message": "Removed sleep.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-27T05:04:19Z", "type": "commit"}, {"oid": "b352b50826d7d414d97d216e85673d9221f7b7fe", "url": "https://github.com/pravega/pravega/commit/b352b50826d7d414d97d216e85673d9221f7b7fe", "message": "Change of access modifier.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-27T05:07:34Z", "type": "commit"}, {"oid": "946aec8ec5fa3deaff9ed04d60d44f38deec8c49", "url": "https://github.com/pravega/pravega/commit/946aec8ec5fa3deaff9ed04d60d44f38deec8c49", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-27T06:41:51Z", "type": "commit"}, {"oid": "afcb645114bae5df6cb72c64bacb382b54c68662", "url": "https://github.com/pravega/pravega/commit/afcb645114bae5df6cb72c64bacb382b54c68662", "message": "Updating StreamSegmentStoreTestBase.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-27T06:44:29Z", "type": "commit"}, {"oid": "6500dbb499e7a57fe7068897f0789cc3c1fba7f3", "url": "https://github.com/pravega/pravega/commit/6500dbb499e7a57fe7068897f0789cc3c1fba7f3", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-07-27T15:57:38Z", "type": "commit"}, {"oid": "d1ec73294c667871a7833ebcdbc8537667b0c261", "url": "https://github.com/pravega/pravega/commit/d1ec73294c667871a7833ebcdbc8537667b0c261", "message": "Merge branch 'feature-4938-dr-tools-base-case' into issue-4670-segment-continer-recovery-mode", "committedDate": "2020-08-04T16:00:51Z", "type": "commit"}, {"oid": "a4aed39cac856ee4999694059d16615569375e17", "url": "https://github.com/pravega/pravega/commit/a4aed39cac856ee4999694059d16615569375e17", "message": "Changes after merging master.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-04T22:22:44Z", "type": "commit"}, {"oid": "e646e962c5134e3f6fb0b8fc25343c0c1f237187", "url": "https://github.com/pravega/pravega/commit/e646e962c5134e3f6fb0b8fc25343c0c1f237187", "message": "Reusing code to start debug segment container.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-04T23:20:58Z", "type": "commit"}, {"oid": "033b52cfc45a389cb5ab1487e53a5102b0680b1b", "url": "https://github.com/pravega/pravega/commit/033b52cfc45a389cb5ab1487e53a5102b0680b1b", "message": "Change storage type.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-04T23:29:24Z", "type": "commit"}, {"oid": "7039b7492225227996b109126b762cbccdd431be", "url": "https://github.com/pravega/pravega/commit/7039b7492225227996b109126b762cbccdd431be", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-04T23:34:37Z", "type": "commit"}, {"oid": "0ac4ca2ae7219a13c67d66fb50ef1c01db586e7c", "url": "https://github.com/pravega/pravega/commit/0ac4ca2ae7219a13c67d66fb50ef1c01db586e7c", "message": "Spellings.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>", "committedDate": "2020-08-04T23:59:44Z", "type": "commit"}]}