{"pr_number": 5200, "pr_title": "Issue 5067: (SLTS) - Convert synchronous ChunkStorage and ChunkMetadataStore API into async", "pr_createdAt": "2020-09-17T23:42:11Z", "pr_url": "https://github.com/pravega/pravega/pull/5200", "timeline": [{"oid": "611a9cd6bf2580818c99c864184735b682439da8", "url": "https://github.com/pravega/pravega/commit/611a9cd6bf2580818c99c864184735b682439da8", "message": "Issue 5067: (SLTS) - Fix test issue after moving to java 11.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-02T21:23:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg4NzUwNg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499887506", "bodyText": "supply executor to this call.", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:39:37Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -279,11 +280,11 @@ protected void doStart() {\n \n     private CompletableFuture<Void> initializeSecondaryServices() {\n         try {\n-            initializeStorage();\n+            return initializeStorage()\n+                    .thenComposeAsync(v -> this.metadataStore.initialize(this.config.getMetadataStoreInitTimeout()));", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MjI2OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752269", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:47:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg4NzUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\nindex fef7672e37..a8dc47b0e0 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n\n@@ -281,7 +286,7 @@ class StreamSegmentContainer extends AbstractService implements SegmentContainer\n     private CompletableFuture<Void> initializeSecondaryServices() {\n         try {\n             return initializeStorage()\n-                    .thenComposeAsync(v -> this.metadataStore.initialize(this.config.getMetadataStoreInitTimeout()));\n+                    .thenComposeAsync(v -> this.metadataStore.initialize(this.config.getMetadataStoreInitTimeout()), this.executor);\n         } catch (Exception ex) {\n             return Futures.failedFuture(ex);\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg4ODM0Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499888346", "bodyText": "Same here.", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:41:36Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceConfig.java", "diffHunk": "@@ -54,7 +54,7 @@\n     public static final Property<String> CLUSTER_NAME = Property.named(\"clusterName\", \"pravega-cluster\");\n     public static final Property<DataLogType> DATALOG_IMPLEMENTATION = Property.named(\"dataLog.impl.name\", DataLogType.INMEMORY, \"dataLogImplementation\");\n     public static final Property<StorageType> STORAGE_IMPLEMENTATION = Property.named(\"storage.impl.name\", StorageType.HDFS, \"storageImplementation\");\n-    public static final Property<StorageLayoutType> STORAGE_LAYOUT = Property.named(\"storage.layout\", StorageLayoutType.ROLLING_STORAGE);\n+    public static final Property<StorageLayoutType> STORAGE_LAYOUT = Property.named(\"storage.layout\", StorageLayoutType.CHUNKED_STORAGE);", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY4NTQ5Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r521685496", "bodyText": "fixed.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T22:51:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg4ODM0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "292d54582f3915bbeed4871c334b3bdfea515082", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceConfig.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceConfig.java\nindex 90066443fb..8a5da52622 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceConfig.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/store/ServiceConfig.java\n\n@@ -54,7 +54,7 @@ public class ServiceConfig {\n     public static final Property<String> CLUSTER_NAME = Property.named(\"clusterName\", \"pravega-cluster\");\n     public static final Property<DataLogType> DATALOG_IMPLEMENTATION = Property.named(\"dataLog.impl.name\", DataLogType.INMEMORY, \"dataLogImplementation\");\n     public static final Property<StorageType> STORAGE_IMPLEMENTATION = Property.named(\"storage.impl.name\", StorageType.HDFS, \"storageImplementation\");\n-    public static final Property<StorageLayoutType> STORAGE_LAYOUT = Property.named(\"storage.layout\", StorageLayoutType.CHUNKED_STORAGE);\n+    public static final Property<StorageLayoutType> STORAGE_LAYOUT = Property.named(\"storage.layout\", StorageLayoutType.ROLLING_STORAGE);\n     public static final Property<Boolean> READONLY_SEGMENT_STORE = Property.named(\"readOnly.enable\", false, \"readOnlySegmentStore\");\n     public static final Property<Long> CACHE_POLICY_MAX_SIZE = Property.named(\"cache.size.max\", 4L * 1024 * 1024 * 1024, \"cacheMaxSize\");\n     public static final Property<Integer> CACHE_POLICY_TARGET_UTILIZATION = Property.named(\"cache.utilization.percent.target\", (int) (100 * CachePolicy.DEFAULT_TARGET_UTILIZATION), \"cacheTargetUtilizationPercent\");\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg4OTkwOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499889908", "bodyText": "Several calls in this class have extra spaces.  I see this in exists too .", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:45:14Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java", "diffHunk": "@@ -0,0 +1,637 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.InputStream;\n+import java.time.Duration;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * Base implementation of {@link ChunkStorage}.\n+ * It implements common functionality that can be used by derived classes.\n+ * Delegates to specific implementations by calling various abstract methods which must be overridden in derived classes.\n+ *\n+ * Below are minimum requirements that any implementation must provide.\n+ * Note that it is the responsibility of storage provider specific implementation to make sure following guarantees are provided even\n+ * though underlying storage may not provide all primitives or guarantees.\n+ * <ul>\n+ * <li>Once an operation is executed and acknowledged as successful then the effects must be permanent and consistent (as opposed to eventually consistent)</li>\n+ * <li>{@link ChunkStorage#create(String)}  and {@link ChunkStorage#delete(ChunkHandle)} are not idempotent.</li>\n+ * <li>{@link ChunkStorage#exists(String)} and {@link ChunkStorage#getInfo(String)} must reflect effects of most recent operation performed.</li>\n+ * </ul>\n+ *\n+ * There are a few different capabilities that ChunkStorage may provide.\n+ * <ul>\n+ * <li> Does {@link ChunkStorage} support appending to existing chunks?\n+ * This is indicated by {@link ChunkStorage#supportsAppend()}. For example S3 compatible Chunk Storage this would return false. </li>\n+ * <li> Does {@link ChunkStorage}  support for concatenating chunks? This is indicated by {@link ChunkStorage#supportsConcat()}.\n+ * If this is true then concat operation concat will be invoked otherwise append functionality is invoked.</li>\n+ * <li>In addition {@link ChunkStorage} may provide ability to truncate chunks at given offsets (either at front end or at tail end). This is indicated by {@link ChunkStorage#supportsTruncation()}. </li>\n+ * </ul>\n+ * There are some obvious constraints - If ChunkStorage supports concat but not natively then it must support append .\n+ *\n+ * For concats, {@link ChunkStorage} supports both native and append, ChunkedSegmentStorage will invoke appropriate method depending on size of target and source chunks. (Eg. ECS)\n+ *\n+ * The implementations in this repository are tested using following test suites.\n+ * <ul>\n+ * <li>SimpleStorageTests</li>\n+ * <li>ChunkedRollingStorageTests</li>\n+ * <li>ChunkStorageProviderTests</li>\n+ * <li>SystemJournalTests</li>\n+ * </ul>\n+ */\n+@Slf4j\n+@Beta\n+public abstract class AsyncBaseChunkStorage implements ChunkStorage {\n+\n+    private final AtomicBoolean closed;\n+\n+    private final Executor executor;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param executor  An Executor for async operations.\n+     */\n+    public AsyncBaseChunkStorage(Executor executor) {\n+        this.closed = new AtomicBoolean(false);\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports truncate operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsTruncation();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports append operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsAppend();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports merge operation either natively or through appends.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsConcat();\n+\n+    /**\n+     * Determines whether named file/object exists in underlying storage.\n+     *\n+     * @param chunkName Name of the chunk to check.\n+     * @return True if the object exists, false otherwise.\n+     */\n+    @Override\n+    final public CompletableFuture<Boolean> exists(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"exists\", chunkName);\n+        // Call concrete implementation.\n+        val returnFuture =  checkExistsAsync(chunkName);\n+        returnFuture.thenApplyAsync(retValue -> {\n+            LoggerHelpers.traceLeave(log, \"exists\", traceId, chunkName);\n+            return retValue;\n+        }, executor);\n+\n+        return returnFuture;\n+    }\n+\n+    /**\n+     * Creates a new chunk.\n+     *\n+     * @param chunkName Name of the chunk to create.\n+     * @return ChunkHandle A writable handle for the recently created chunk.\n+     * throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     */\n+    @Override\n+    final public CompletableFuture<ChunkHandle> create(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"create\", chunkName);\n+        Timer timer = new Timer();\n+\n+        // Call concrete implementation.\n+        val returnFuture =   doCreateAsync(chunkName);", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MjUyOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752528", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:48:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg4OTkwOA=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\nindex 14ed7e35d6..fb99a0217b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n\n@@ -19,7 +19,6 @@ import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n \n import java.io.InputStream;\n-import java.time.Duration;\n import java.util.concurrent.Callable;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MDEyMQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499890121", "bodyText": "thenAccept so you don't have to return something.", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:45:44Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java", "diffHunk": "@@ -0,0 +1,637 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.InputStream;\n+import java.time.Duration;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * Base implementation of {@link ChunkStorage}.\n+ * It implements common functionality that can be used by derived classes.\n+ * Delegates to specific implementations by calling various abstract methods which must be overridden in derived classes.\n+ *\n+ * Below are minimum requirements that any implementation must provide.\n+ * Note that it is the responsibility of storage provider specific implementation to make sure following guarantees are provided even\n+ * though underlying storage may not provide all primitives or guarantees.\n+ * <ul>\n+ * <li>Once an operation is executed and acknowledged as successful then the effects must be permanent and consistent (as opposed to eventually consistent)</li>\n+ * <li>{@link ChunkStorage#create(String)}  and {@link ChunkStorage#delete(ChunkHandle)} are not idempotent.</li>\n+ * <li>{@link ChunkStorage#exists(String)} and {@link ChunkStorage#getInfo(String)} must reflect effects of most recent operation performed.</li>\n+ * </ul>\n+ *\n+ * There are a few different capabilities that ChunkStorage may provide.\n+ * <ul>\n+ * <li> Does {@link ChunkStorage} support appending to existing chunks?\n+ * This is indicated by {@link ChunkStorage#supportsAppend()}. For example S3 compatible Chunk Storage this would return false. </li>\n+ * <li> Does {@link ChunkStorage}  support for concatenating chunks? This is indicated by {@link ChunkStorage#supportsConcat()}.\n+ * If this is true then concat operation concat will be invoked otherwise append functionality is invoked.</li>\n+ * <li>In addition {@link ChunkStorage} may provide ability to truncate chunks at given offsets (either at front end or at tail end). This is indicated by {@link ChunkStorage#supportsTruncation()}. </li>\n+ * </ul>\n+ * There are some obvious constraints - If ChunkStorage supports concat but not natively then it must support append .\n+ *\n+ * For concats, {@link ChunkStorage} supports both native and append, ChunkedSegmentStorage will invoke appropriate method depending on size of target and source chunks. (Eg. ECS)\n+ *\n+ * The implementations in this repository are tested using following test suites.\n+ * <ul>\n+ * <li>SimpleStorageTests</li>\n+ * <li>ChunkedRollingStorageTests</li>\n+ * <li>ChunkStorageProviderTests</li>\n+ * <li>SystemJournalTests</li>\n+ * </ul>\n+ */\n+@Slf4j\n+@Beta\n+public abstract class AsyncBaseChunkStorage implements ChunkStorage {\n+\n+    private final AtomicBoolean closed;\n+\n+    private final Executor executor;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param executor  An Executor for async operations.\n+     */\n+    public AsyncBaseChunkStorage(Executor executor) {\n+        this.closed = new AtomicBoolean(false);\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports truncate operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsTruncation();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports append operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsAppend();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports merge operation either natively or through appends.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsConcat();\n+\n+    /**\n+     * Determines whether named file/object exists in underlying storage.\n+     *\n+     * @param chunkName Name of the chunk to check.\n+     * @return True if the object exists, false otherwise.\n+     */\n+    @Override\n+    final public CompletableFuture<Boolean> exists(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"exists\", chunkName);\n+        // Call concrete implementation.\n+        val returnFuture =  checkExistsAsync(chunkName);\n+        returnFuture.thenApplyAsync(retValue -> {\n+            LoggerHelpers.traceLeave(log, \"exists\", traceId, chunkName);\n+            return retValue;\n+        }, executor);\n+\n+        return returnFuture;\n+    }\n+\n+    /**\n+     * Creates a new chunk.\n+     *\n+     * @param chunkName Name of the chunk to create.\n+     * @return ChunkHandle A writable handle for the recently created chunk.\n+     * throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     */\n+    @Override\n+    final public CompletableFuture<ChunkHandle> create(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"create\", chunkName);\n+        Timer timer = new Timer();\n+\n+        // Call concrete implementation.\n+        val returnFuture =   doCreateAsync(chunkName);\n+        returnFuture.thenApplyAsync(handle -> {", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MjU1Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752556", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:48:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MDEyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\nindex 14ed7e35d6..fb99a0217b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n\n@@ -19,7 +19,6 @@ import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n \n import java.io.InputStream;\n-import java.time.Duration;\n import java.util.concurrent.Callable;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MDg0MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499890841", "bodyText": "only attach this callback if log.isTraceEnabled is true. Otherwise it will be an expensive operation for no gain.\nPS: for something this small, no need to specify an executor. It may be more efficient to simply execute this on the same thread pool as whatever it's attached to, which will likely invoke it synchronously as well.\nPlease change this elsewhere too.", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:47:23Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java", "diffHunk": "@@ -0,0 +1,637 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.InputStream;\n+import java.time.Duration;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * Base implementation of {@link ChunkStorage}.\n+ * It implements common functionality that can be used by derived classes.\n+ * Delegates to specific implementations by calling various abstract methods which must be overridden in derived classes.\n+ *\n+ * Below are minimum requirements that any implementation must provide.\n+ * Note that it is the responsibility of storage provider specific implementation to make sure following guarantees are provided even\n+ * though underlying storage may not provide all primitives or guarantees.\n+ * <ul>\n+ * <li>Once an operation is executed and acknowledged as successful then the effects must be permanent and consistent (as opposed to eventually consistent)</li>\n+ * <li>{@link ChunkStorage#create(String)}  and {@link ChunkStorage#delete(ChunkHandle)} are not idempotent.</li>\n+ * <li>{@link ChunkStorage#exists(String)} and {@link ChunkStorage#getInfo(String)} must reflect effects of most recent operation performed.</li>\n+ * </ul>\n+ *\n+ * There are a few different capabilities that ChunkStorage may provide.\n+ * <ul>\n+ * <li> Does {@link ChunkStorage} support appending to existing chunks?\n+ * This is indicated by {@link ChunkStorage#supportsAppend()}. For example S3 compatible Chunk Storage this would return false. </li>\n+ * <li> Does {@link ChunkStorage}  support for concatenating chunks? This is indicated by {@link ChunkStorage#supportsConcat()}.\n+ * If this is true then concat operation concat will be invoked otherwise append functionality is invoked.</li>\n+ * <li>In addition {@link ChunkStorage} may provide ability to truncate chunks at given offsets (either at front end or at tail end). This is indicated by {@link ChunkStorage#supportsTruncation()}. </li>\n+ * </ul>\n+ * There are some obvious constraints - If ChunkStorage supports concat but not natively then it must support append .\n+ *\n+ * For concats, {@link ChunkStorage} supports both native and append, ChunkedSegmentStorage will invoke appropriate method depending on size of target and source chunks. (Eg. ECS)\n+ *\n+ * The implementations in this repository are tested using following test suites.\n+ * <ul>\n+ * <li>SimpleStorageTests</li>\n+ * <li>ChunkedRollingStorageTests</li>\n+ * <li>ChunkStorageProviderTests</li>\n+ * <li>SystemJournalTests</li>\n+ * </ul>\n+ */\n+@Slf4j\n+@Beta\n+public abstract class AsyncBaseChunkStorage implements ChunkStorage {\n+\n+    private final AtomicBoolean closed;\n+\n+    private final Executor executor;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param executor  An Executor for async operations.\n+     */\n+    public AsyncBaseChunkStorage(Executor executor) {\n+        this.closed = new AtomicBoolean(false);\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports truncate operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsTruncation();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports append operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsAppend();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports merge operation either natively or through appends.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsConcat();\n+\n+    /**\n+     * Determines whether named file/object exists in underlying storage.\n+     *\n+     * @param chunkName Name of the chunk to check.\n+     * @return True if the object exists, false otherwise.\n+     */\n+    @Override\n+    final public CompletableFuture<Boolean> exists(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"exists\", chunkName);\n+        // Call concrete implementation.\n+        val returnFuture =  checkExistsAsync(chunkName);\n+        returnFuture.thenApplyAsync(retValue -> {\n+            LoggerHelpers.traceLeave(log, \"exists\", traceId, chunkName);\n+            return retValue;\n+        }, executor);\n+\n+        return returnFuture;\n+    }\n+\n+    /**\n+     * Creates a new chunk.\n+     *\n+     * @param chunkName Name of the chunk to create.\n+     * @return ChunkHandle A writable handle for the recently created chunk.\n+     * throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     */\n+    @Override\n+    final public CompletableFuture<ChunkHandle> create(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"create\", chunkName);\n+        Timer timer = new Timer();\n+\n+        // Call concrete implementation.\n+        val returnFuture =   doCreateAsync(chunkName);\n+        returnFuture.thenApplyAsync(handle -> {\n+            // Record metrics.\n+            Duration elapsed = timer.getElapsed();\n+            ChunkStorageMetrics.CREATE_LATENCY.reportSuccessEvent(elapsed);\n+            ChunkStorageMetrics.CREATE_COUNT.inc();\n+\n+            log.debug(\"Create - chunk={}, latency={}.\", chunkName, elapsed.toMillis());\n+            LoggerHelpers.traceLeave(log, \"create\", traceId, chunkName);\n+\n+            return handle;\n+        }, executor);\n+\n+        return returnFuture;\n+    }\n+\n+    /**\n+     * Deletes a chunk.\n+     *\n+     * @param handle ChunkHandle of the chunk to delete.\n+     * throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     */\n+    @Override\n+    final public CompletableFuture<Void> delete(ChunkHandle handle) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        Preconditions.checkArgument(null != handle, \"handle must not be null\");\n+        checkChunkName(handle.getChunkName());\n+        Preconditions.checkArgument(!handle.isReadOnly(), \"handle must not be readonly\");\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"delete\", handle.getChunkName());\n+        Timer timer = new Timer();\n+\n+        // Call concrete implementation.\n+        val returnFuture = doDeleteAsync(handle);\n+        returnFuture.thenApplyAsync(v -> {\n+            // Record metrics.\n+            Duration elapsed = timer.getElapsed();\n+            ChunkStorageMetrics.DELETE_LATENCY.reportSuccessEvent(elapsed);\n+            ChunkStorageMetrics.DELETE_COUNT.inc();\n+\n+            log.debug(\"Delete - chunk={}, latency={}.\", handle.getChunkName(), elapsed.toMillis());\n+            LoggerHelpers.traceLeave(log, \"delete\", traceId, handle.getChunkName());\n+            return null;\n+        }, executor);\n+\n+        return returnFuture;\n+    }\n+\n+    /**\n+     * Opens chunk for Read.\n+     *\n+     * @param chunkName String name of the chunk to read from.\n+     * @return ChunkHandle A readable handle for the given chunk.\n+     * throws ChunkStorageException    Throws ChunkStorageException in case of I/O related exceptions.\n+     * throws IllegalArgumentException If argument is invalid.\n+     */\n+    @Override\n+    final public CompletableFuture<ChunkHandle> openRead(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        long traceId = LoggerHelpers.traceEnter(log, \"openRead\", chunkName);\n+\n+        // Call concrete implementation.\n+        val returnFuture = doOpenReadAsync(chunkName);\n+        returnFuture.thenApplyAsync(handle -> {", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5Mjc0Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516092747", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:26:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MDg0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\nindex 14ed7e35d6..fb99a0217b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n\n@@ -19,7 +19,6 @@ import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n \n import java.io.InputStream;\n-import java.time.Duration;\n import java.util.concurrent.Callable;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MjM3NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499892374", "bodyText": "It is true that Javadoc doesn't have a tag for CompletableFuture exceptions, but throughout the rest of our codebase we have (tried to) adopt the following convention:\n@return a CompletableFuture that will be completed with the result. If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n* {@link Exception1} ....\n* {@link Exception2) ...\n\nLet's try to follow this pattern here too.", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:50:56Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java", "diffHunk": "@@ -72,56 +73,56 @@\n      *\n      * @param chunkName Name of the storage object to check.\n      * @return True if the object exists, false otherwise.\n-     * @throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     * throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MjY2OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752669", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:49:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MjM3NA=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java\nindex 017cf367a8..f4c01c5dd3 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java\n\n@@ -73,7 +74,8 @@ public interface ChunkStorage extends AutoCloseable {\n      *\n      * @param chunkName Name of the storage object to check.\n      * @return True if the object exists, false otherwise.\n-     * throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link ChunkStorageException} In case of I/O related exceptions.\n      */\n     CompletableFuture<Boolean> exists(String chunkName);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MzI0Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499893242", "bodyText": "Isn't there something in Futures that can help with this syntax? Futures.exceptionallyExpecting or similar?", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:53:06Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -195,28 +199,39 @@ public void initialize(long containerEpoch) {\n     @Override\n     public CompletableFuture<SegmentHandle> openWrite(String streamSegmentName) {\n         checkInitialized();\n-        return execute(() -> {\n+        return executeAsync(() -> {\n             long traceId = LoggerHelpers.traceEnter(log, \"openWrite\", streamSegmentName);\n             Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n-                segmentMetadata.checkInvariants();\n-                // This segment was created by an older segment store. Need to start a fresh new chunk.\n-                if (segmentMetadata.getOwnerEpoch() < this.epoch) {\n-                    log.debug(\"{} openWrite - Segment needs ownership change - segment={}.\", logPrefix, segmentMetadata.getName());\n-                    claimOwnership(txn, segmentMetadata);\n-                }\n-                // If created by newer instance then abort.\n-                checkOwnership(streamSegmentName, segmentMetadata);\n-\n-                // This instance is the owner, return a handle.\n-                val retValue = SegmentStorageHandle.writeHandle(streamSegmentName);\n-                LoggerHelpers.traceLeave(log, \"openWrite\", traceId, retValue);\n-                return retValue;\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(streamSegmentName, ex);\n-            }\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName),\n+                    txn -> txn.get(streamSegmentName)\n+                            .thenComposeAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                checkSegmentExists(streamSegmentName, segmentMetadata);\n+                                segmentMetadata.checkInvariants();\n+                                // This segment was created by an older segment store. Need to start a fresh new chunk.\n+                                CompletableFuture<Void> f = CompletableFuture.completedFuture(null);\n+                                if (segmentMetadata.getOwnerEpoch() < this.epoch) {\n+                                    log.debug(\"{} openWrite - Segment needs ownership change - segment={}.\", logPrefix, segmentMetadata.getName());\n+                                    f = claimOwnership(txn, segmentMetadata)", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNDgzMQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r517034831", "bodyText": "Expected behavior slightly different, I'm not sure those two are exactly equivalent.", "author": "sachin-j-joshi", "createdAt": "2020-11-04T00:37:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5MzI0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\nindex 04901c3ae4..1393c4314b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n\n@@ -200,16 +199,16 @@ public class ChunkedSegmentStorage implements Storage {\n     public CompletableFuture<SegmentHandle> openWrite(String streamSegmentName) {\n         checkInitialized();\n         return executeAsync(() -> {\n-            long traceId = LoggerHelpers.traceEnter(log, \"openWrite\", streamSegmentName);\n+            val traceId = LoggerHelpers.traceEnter(log, \"openWrite\", streamSegmentName);\n             Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n             return tryWith(metadataStore.beginTransaction(streamSegmentName),\n                     txn -> txn.get(streamSegmentName)\n                             .thenComposeAsync(storageMetadata -> {\n-                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                val segmentMetadata = (SegmentMetadata) storageMetadata;\n                                 checkSegmentExists(streamSegmentName, segmentMetadata);\n                                 segmentMetadata.checkInvariants();\n                                 // This segment was created by an older segment store. Need to start a fresh new chunk.\n-                                CompletableFuture<Void> f = CompletableFuture.completedFuture(null);\n+                                final CompletableFuture<Void> f;\n                                 if (segmentMetadata.getOwnerEpoch() < this.epoch) {\n                                     log.debug(\"{} openWrite - Segment needs ownership change - segment={}.\", logPrefix, segmentMetadata.getName());\n                                     f = claimOwnership(txn, segmentMetadata)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5Mzc5MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499893791", "bodyText": "I think exceptionallyExpecting may work well here.", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:54:22Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -225,324 +240,132 @@ public void initialize(long containerEpoch) {\n      *\n      * @param txn             Active {@link MetadataTransaction}.\n      * @param segmentMetadata {@link SegmentMetadata} for the segment to change ownership for.\n-     * @throws ChunkStorageException In case of any chunk storage related errors.\n-     * @throws StorageMetadataException In case of any chunk metadata store related errors.\n+     *                        throws ChunkStorageException    In case of any chunk storage related errors.\n+     *                        throws StorageMetadataException In case of any chunk metadata store related errors.\n      */\n-    private void claimOwnership(MetadataTransaction txn, SegmentMetadata segmentMetadata) throws ChunkStorageException, StorageMetadataException {\n-\n+    private CompletableFuture<Void> claimOwnership(MetadataTransaction txn, SegmentMetadata segmentMetadata) {\n         // Get the last chunk\n         String lastChunkName = segmentMetadata.getLastChunk();\n+        CompletableFuture<Boolean> f = CompletableFuture.completedFuture(true);\n         if (null != lastChunkName) {\n-            ChunkMetadata lastChunk = (ChunkMetadata) txn.get(lastChunkName);\n-            log.debug(\"{} claimOwnership - current last chunk - segment={}, last chunk={}, Length={}.\",\n-                    logPrefix,\n-                    segmentMetadata.getName(),\n-                    lastChunk.getName(),\n-                    lastChunk.getLength());\n-            try {\n-                ChunkInfo chunkInfo = chunkStorage.getInfo(lastChunkName);\n-                Preconditions.checkState(chunkInfo != null);\n-                Preconditions.checkState(lastChunk != null);\n-                // Adjust its length;\n-                if (chunkInfo.getLength() != lastChunk.getLength()) {\n-                    Preconditions.checkState(chunkInfo.getLength() > lastChunk.getLength());\n-                    // Whatever length you see right now is the final \"sealed\" length of the last chunk.\n-                    lastChunk.setLength(chunkInfo.getLength());\n-                    segmentMetadata.setLength(segmentMetadata.getLastChunkStartOffset() + lastChunk.getLength());\n-                    txn.update(lastChunk);\n-                    log.debug(\"{} claimOwnership - Length of last chunk adjusted - segment={}, last chunk={}, Length={}.\",\n-                            logPrefix,\n-                            segmentMetadata.getName(),\n-                            lastChunk.getName(),\n-                            chunkInfo.getLength());\n-                }\n-            } catch (ChunkNotFoundException e) {\n-                // This probably means that this instance is fenced out and newer instance truncated this segment.\n-                // Try a commit of unmodified data to fail fast.\n-                log.debug(\"{} claimOwnership - Last chunk was missing, failing fast - segment={}, last chunk={}.\",\n-                        logPrefix,\n-                        segmentMetadata.getName(),\n-                        lastChunk.getName());\n-                txn.update(segmentMetadata);\n-                txn.commit();\n-                throw e;\n-            }\n+            f = txn.get(lastChunkName)\n+                    .thenComposeAsync(storageMetadata -> {\n+                        ChunkMetadata lastChunk = (ChunkMetadata) storageMetadata;\n+                        log.debug(\"{} claimOwnership - current last chunk - segment={}, last chunk={}, Length={}.\",\n+                                logPrefix,\n+                                segmentMetadata.getName(),\n+                                lastChunk.getName(),\n+                                lastChunk.getLength());\n+                        return chunkStorage.getInfo(lastChunkName)\n+                                .thenComposeAsync(chunkInfo -> {\n+                                    Preconditions.checkState(chunkInfo != null);\n+                                    Preconditions.checkState(lastChunk != null);\n+                                    // Adjust its length;\n+                                    if (chunkInfo.getLength() != lastChunk.getLength()) {\n+                                        Preconditions.checkState(chunkInfo.getLength() > lastChunk.getLength());\n+                                        // Whatever length you see right now is the final \"sealed\" length of the last chunk.\n+                                        lastChunk.setLength(chunkInfo.getLength());\n+                                        segmentMetadata.setLength(segmentMetadata.getLastChunkStartOffset() + lastChunk.getLength());\n+                                        txn.update(lastChunk);\n+                                        log.debug(\"{} claimOwnership - Length of last chunk adjusted - segment={}, last chunk={}, Length={}.\",\n+                                                logPrefix,\n+                                                segmentMetadata.getName(),\n+                                                lastChunk.getName(),\n+                                                chunkInfo.getLength());\n+                                    }\n+                                    return CompletableFuture.completedFuture(true);\n+                                }, executor)\n+                                .exceptionally(e -> {", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNDg4OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r517034889", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-11-04T00:37:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5Mzc5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\nindex 04901c3ae4..1393c4314b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n\n@@ -245,12 +246,14 @@ public class ChunkedSegmentStorage implements Storage {\n      */\n     private CompletableFuture<Void> claimOwnership(MetadataTransaction txn, SegmentMetadata segmentMetadata) {\n         // Get the last chunk\n-        String lastChunkName = segmentMetadata.getLastChunk();\n-        CompletableFuture<Boolean> f = CompletableFuture.completedFuture(true);\n+        val lastChunkName = segmentMetadata.getLastChunk();\n+        final CompletableFuture<Boolean> f;\n         if (null != lastChunkName) {\n             f = txn.get(lastChunkName)\n                     .thenComposeAsync(storageMetadata -> {\n-                        ChunkMetadata lastChunk = (ChunkMetadata) storageMetadata;\n+                        val lastChunk = (ChunkMetadata) storageMetadata;\n+                        Preconditions.checkState(null != lastChunk);\n+                        Preconditions.checkState(null != lastChunk.getName());\n                         log.debug(\"{} claimOwnership - current last chunk - segment={}, last chunk={}, Length={}.\",\n                                 logPrefix,\n                                 segmentMetadata.getName(),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NTM5OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499895398", "bodyText": "Can e merge these 2 catch blocks into one?", "author": "andreipaduroiu", "createdAt": "2020-10-05T21:58:08Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -555,575 +378,700 @@ private boolean isStorageSystemSegment(SegmentMetadata segmentMetadata) {\n         return null != systemJournal && segmentMetadata.isStorageSystemSegment();\n     }\n \n-    /**\n-     * Adds a system log.\n-     *\n-     * @param systemLogRecords\n-     * @param streamSegmentName Name of the segment.\n-     * @param offset            Offset at which new chunk was added.\n-     * @param oldChunkName      Name of the previous last chunk.\n-     * @param newChunkName      Name of the new last chunk.\n-     */\n-    private void addSystemLogRecord(ArrayList<SystemJournal.SystemJournalRecord> systemLogRecords, String streamSegmentName, long offset, String oldChunkName, String newChunkName) {\n-        systemLogRecords.add(\n-                SystemJournal.ChunkAddedRecord.builder()\n-                        .segmentName(streamSegmentName)\n-                        .offset(offset)\n-                        .oldChunkName(oldChunkName == null ? null : oldChunkName)\n-                        .newChunkName(newChunkName)\n-                        .build());\n-    }\n-\n     /**\n      * Delete the garbage chunks.\n      *\n      * @param chunksTodelete List of chunks to delete.\n      */\n-    private void collectGarbage(Collection<String> chunksTodelete) {\n+    private CompletableFuture<Void> collectGarbage(Collection<String> chunksTodelete) {\n+        CompletableFuture[] futures = new CompletableFuture[chunksTodelete.size()];\n+        int i = 0;\n         for (val chunkTodelete : chunksTodelete) {\n-            try {\n-                chunkStorage.delete(chunkStorage.openWrite(chunkTodelete));\n-                log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkTodelete);\n-            } catch (ChunkNotFoundException e) {\n-                log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n-            } catch (Exception e) {\n-                log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n-                // Add it to garbage chunks.\n-                synchronized (garbageChunks) {\n-                    garbageChunks.add(chunkTodelete);\n-                }\n-            }\n+            futures[i++] = chunkStorage.openWrite(chunkTodelete)\n+                    .thenComposeAsync(chunkStorage::delete, executor)\n+                    .thenRunAsync(() -> log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkTodelete), executor)\n+                    .exceptionally(e -> {\n+                        val ex = Exceptions.unwrap(e);\n+                        if (ex instanceof ChunkNotFoundException) {\n+                            log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                        } else {\n+                            log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                            // Add it to garbage chunks.\n+                            synchronized (garbageChunks) {\n+                                garbageChunks.add(chunkTodelete);\n+                            }\n+                        }\n+                        return null;\n+                    });\n         }\n+        return CompletableFuture.allOf(futures);\n     }\n \n     @Override\n     public CompletableFuture<Void> seal(SegmentHandle handle, Duration timeout) {\n         checkInitialized();\n-        return execute(() -> {\n+        return executeAsync(() -> {\n             long traceId = LoggerHelpers.traceEnter(log, \"seal\", handle);\n             Preconditions.checkNotNull(handle, \"handle\");\n             String streamSegmentName = handle.getSegmentName();\n             Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n             Preconditions.checkArgument(!handle.isReadOnly(), \"handle\");\n \n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n-                // Validate preconditions.\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n-                checkOwnership(streamSegmentName, segmentMetadata);\n-\n-                // seal if it is not already sealed.\n-                if (!segmentMetadata.isSealed()) {\n-                    segmentMetadata.setSealed(true);\n-                    txn.update(segmentMetadata);\n-                    txn.commit();\n-                }\n-\n-                log.debug(\"{} seal - segment={}.\", logPrefix, handle.getSegmentName());\n-                LoggerHelpers.traceLeave(log, \"seal\", traceId, handle);\n-                return null;\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(streamSegmentName, ex);\n-            }\n+            return tryWith(metadataStore.beginTransaction(handle.getSegmentName()), txn ->\n+                    txn.get(streamSegmentName)\n+                            .thenComposeAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                // Validate preconditions.\n+                                checkSegmentExists(streamSegmentName, segmentMetadata);\n+                                checkOwnership(streamSegmentName, segmentMetadata);\n+\n+                                // seal if it is not already sealed.\n+                                if (!segmentMetadata.isSealed()) {\n+                                    segmentMetadata.setSealed(true);\n+                                    txn.update(segmentMetadata);\n+                                    return txn.commit();\n+                                }\n+                                return CompletableFuture.completedFuture(null);\n+                            }, executor)\n+                            .thenRunAsync(() -> {\n+                                log.debug(\"{} seal - segment={}.\", logPrefix, handle.getSegmentName());\n+                                LoggerHelpers.traceLeave(log, \"seal\", traceId, handle);\n+                            }, executor)\n+                            .exceptionally(e -> {\n+                                val ex = Exceptions.unwrap(e);\n+                                if (ex instanceof StorageMetadataWritesFencedOutException) {\n+                                    throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n+                                }\n+                                throw new CompletionException(ex);\n+                            }), executor);\n         });\n     }\n \n     @Override\n     public CompletableFuture<Void> concat(SegmentHandle targetHandle, long offset, String sourceSegment, Duration timeout) {\n         checkInitialized();\n-        return execute(() -> {\n-            long traceId = LoggerHelpers.traceEnter(log, \"concat\", targetHandle, offset, sourceSegment);\n-            Timer timer = new Timer();\n-\n-            Preconditions.checkArgument(null != targetHandle, \"targetHandle\");\n-            Preconditions.checkArgument(!targetHandle.isReadOnly(), \"targetHandle\");\n-            Preconditions.checkArgument(null != sourceSegment, \"targetHandle\");\n-            Preconditions.checkArgument(offset >= 0, \"offset\");\n-            String targetSegmentName = targetHandle.getSegmentName();\n-\n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-\n-                SegmentMetadata targetSegmentMetadata = (SegmentMetadata) txn.get(targetSegmentName);\n-\n-                // Validate preconditions.\n-                checkSegmentExists(targetSegmentName, targetSegmentMetadata);\n-                targetSegmentMetadata.checkInvariants();\n-                checkNotSealed(targetSegmentName, targetSegmentMetadata);\n-\n-                SegmentMetadata sourceSegmentMetadata = (SegmentMetadata) txn.get(sourceSegment);\n-                checkSegmentExists(sourceSegment, sourceSegmentMetadata);\n-                sourceSegmentMetadata.checkInvariants();\n-\n-                // This is a critical assumption at this point which should not be broken,\n-                Preconditions.checkState(!targetSegmentMetadata.isStorageSystemSegment(), \"Storage system segments cannot be concatenated.\");\n-                Preconditions.checkState(!sourceSegmentMetadata.isStorageSystemSegment(), \"Storage system segments cannot be concatenated.\");\n-\n-                checkSealed(sourceSegmentMetadata);\n-                checkOwnership(targetSegmentMetadata.getName(), targetSegmentMetadata);\n-\n-                if (sourceSegmentMetadata.getStartOffset() != 0) {\n-                    throw new StreamSegmentTruncatedException(sourceSegment, sourceSegmentMetadata.getLength(), 0);\n-                }\n-\n-                if (offset != targetSegmentMetadata.getLength()) {\n-                    throw new BadOffsetException(targetHandle.getSegmentName(), targetSegmentMetadata.getLength(), offset);\n-                }\n-\n-                // Update list of chunks by appending sources list of chunks.\n-                ChunkMetadata targetLastChunk = (ChunkMetadata) txn.get(targetSegmentMetadata.getLastChunk());\n-                ChunkMetadata sourceFirstChunk = (ChunkMetadata) txn.get(sourceSegmentMetadata.getFirstChunk());\n-\n-                if (targetLastChunk != null) {\n-                    targetLastChunk.setNextChunk(sourceFirstChunk.getName());\n-                    txn.update(targetLastChunk);\n-                } else {\n-                    if (sourceFirstChunk != null) {\n-                        targetSegmentMetadata.setFirstChunk(sourceFirstChunk.getName());\n-                        txn.update(sourceFirstChunk);\n-                    }\n-                }\n-\n-                // Update segments's last chunk to point to the sources last segment.\n-                targetSegmentMetadata.setLastChunk(sourceSegmentMetadata.getLastChunk());\n-\n-                // Update the length of segment.\n-                targetSegmentMetadata.setLastChunkStartOffset(targetSegmentMetadata.getLength() + sourceSegmentMetadata.getLastChunkStartOffset());\n-                targetSegmentMetadata.setLength(targetSegmentMetadata.getLength() + sourceSegmentMetadata.getLength() - sourceSegmentMetadata.getStartOffset());\n-\n-                targetSegmentMetadata.setChunkCount(targetSegmentMetadata.getChunkCount() + sourceSegmentMetadata.getChunkCount());\n-\n-                txn.update(targetSegmentMetadata);\n-                txn.delete(sourceSegment);\n-\n-                // Finally defrag immediately.\n-                ArrayList<String> chunksToDelete = new ArrayList<>();\n-                if (shouldDefrag() && null != targetLastChunk) {\n-                    defrag(txn, targetSegmentMetadata, targetLastChunk.getName(), null, chunksToDelete);\n-                }\n-\n-                targetSegmentMetadata.checkInvariants();\n-\n-                // Finally commit transaction.\n-                txn.commit();\n-\n-                // Collect garbage.\n-                collectGarbage(chunksToDelete);\n-\n-                // Update the read index.\n-                readIndexCache.remove(sourceSegment);\n-\n-                Duration elapsed = timer.getElapsed();\n-                log.debug(\"{} concat - target={}, source={}, offset={}, latency={}.\", logPrefix, targetHandle.getSegmentName(), sourceSegment, offset, elapsed.toMillis());\n-                LoggerHelpers.traceLeave(log, \"concat\", traceId, targetHandle, offset, sourceSegment);\n-\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(targetSegmentName, ex);\n-            }\n-\n-            return null;\n-        });\n+        return executeAsync(new ConcatOperation(this, targetHandle, offset, sourceSegment));\n     }\n \n     private boolean shouldAppend() {\n         return chunkStorage.supportsAppend() && config.isAppendEnabled();\n     }\n \n-    private boolean shouldDefrag() {\n-        return shouldAppend() || chunkStorage.supportsConcat();\n-    }\n-\n     /**\n      * Defragments the list of chunks for a given segment.\n      * It finds eligible consecutive chunks that can be merged together.\n      * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n      * Conceptually this is like deleting nodes from middle of the list of chunks.\n      *\n-     * <Ul>\n-     * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n-     * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n-     * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n-     * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n-     * each write becomes a separate chunk.\n-     * </li>\n-     * <li>\n-     * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n-     * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n-     * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n-     * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n-     * whereas NFS has no concept of merging natively.\n-     *\n-     * As chunks become larger, append writes (read source completely and append it back at the end of target)\n-     * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n-     * when available, and if not available, then we use appends.\n-     * </li>\n-     * <li>\n-     * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n-     * We can then fine tune that background task to run optimally with low overhead.\n-     * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n-     * </li>\n-     * <li>\n-     * <li>\n-     * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n-     * </li>\n-     * </ul>\n-     *\n-     * What controls whether we invoke concat or simulate through appends?\n-     * There are a few different capabilities that ChunkStorage needs to provide.\n-     * <ul>\n-     * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.\n-     * This is indicated by supportsAppend.</li>\n-     * <li>Does ChunkStorage support for concatenating chunks ? This is indicated by supportsConcat.\n-     * If this is true then concat operation will be invoked otherwise chunks will be appended.</li>\n-     * <li>There are some obvious constraints - For ChunkStorage support any concat functionality it must support either\n-     * append or concat.</li>\n-     * <li>Also when ChunkStorage supports both concat and append, ChunkedSegmentStorage will invoke appropriate method\n-     * depending on size of target and source chunks. (Eg. ECS)</li>\n-     * </ul>\n-     *\n-     * <li>\n-     * What controls defrag?\n-     * There are two additional parameters that control when concat\n-     * <li>minSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered a small object.\n-     * For small source objects, append is used instead of using concat. (For really small txn it is rather efficient to use append than MPU).</li>\n-     * <li>maxSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered for concat. (Eg S3 might have max limit on chunk size).</li>\n-     * In short there is a size beyond which using append is not advisable. Conversely there is a size below which concat is not efficient.(minSizeLimitForConcat )\n-     * Then there is limit which concating does not make sense maxSizeLimitForConcat\n-     * </li>\n-     * <li>\n-     * What is the defrag algorithm\n-     * <pre>\n-     * While(segment.hasConcatableChunks()){\n-     *     Set<List<Chunk>> s = FindConsecutiveConcatableChunks();\n-     *     For (List<chunk> list : s){\n-     *        ConcatChunks (list);\n-     *     }\n-     * }\n-     * </pre>\n-     * </li>\n-     * </ul>\n-     *\n      * @param txn             Active {@link MetadataTransaction}.\n      * @param segmentMetadata {@link SegmentMetadata} for the segment to defrag.\n      * @param startChunkName  Name of the first chunk to start defragmentation.\n      * @param lastChunkName   Name of the last chunk before which to stop defragmentation. (last chunk is not concatenated).\n      * @param chunksToDelete  List of chunks to which names of chunks to be deleted are added. It is the responsibility\n      *                        of caller to garbage collect these chunks.\n-     * @throws ChunkStorageException In case of any chunk storage related errors.\n-     * @throws StorageMetadataException In case of any chunk metadata store related errors.\n+     *                        throws ChunkStorageException    In case of any chunk storage related errors.\n+     *                        throws StorageMetadataException In case of any chunk metadata store related errors.\n      */\n-    private void defrag(MetadataTransaction txn, SegmentMetadata segmentMetadata,\n-                        String startChunkName,\n-                        String lastChunkName,\n-                        ArrayList<String> chunksToDelete)\n-            throws StorageMetadataException, ChunkStorageException {\n-        // The algorithm is actually very simple.\n-        // It tries to concat all small chunks using appends first.\n-        // Then it tries to concat remaining chunks using concat if available.\n-        // To implement it using single loop we toggle between concat with append and concat modes. (Instead of two passes.)\n-        boolean useAppend = true;\n-        String targetChunkName = startChunkName;\n-\n-        // Iterate through chunk list\n-        while (null != targetChunkName && !targetChunkName.equals(lastChunkName)) {\n-            ChunkMetadata target = (ChunkMetadata) txn.get(targetChunkName);\n-\n-            ArrayList<ChunkInfo> chunksToConcat = new ArrayList<>();\n-            long targetSizeAfterConcat = target.getLength();\n-\n-            // Add target to the list of chunks\n-            chunksToConcat.add(new ChunkInfo(targetSizeAfterConcat, targetChunkName));\n-\n-            String nextChunkName = target.getNextChunk();\n-            ChunkMetadata next = null;\n-\n-            // Gather list of chunks that can be appended together.\n-            while (null != nextChunkName) {\n-                next = (ChunkMetadata) txn.get(nextChunkName);\n-\n-                if (useAppend && config.getMinSizeLimitForConcat() < next.getLength()) {\n-                    break;\n-                }\n+    private CompletableFuture<Void> defrag(MetadataTransaction txn, SegmentMetadata segmentMetadata,\n+                                           String startChunkName,\n+                                           String lastChunkName,\n+                                           ArrayList<String> chunksToDelete) {\n+        return new DefragmentOperation(this, txn, segmentMetadata, startChunkName, lastChunkName, chunksToDelete).call();\n+    }\n \n-                if (targetSizeAfterConcat + next.getLength() > segmentMetadata.getMaxRollinglength() || next.getLength() > config.getMaxSizeLimitForConcat()) {\n-                    break;\n-                }\n+    @Override\n+    public CompletableFuture<Void> delete(SegmentHandle handle, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"delete\", handle);\n+            Timer timer = new Timer();\n \n-                chunksToConcat.add(new ChunkInfo(next.getLength(), nextChunkName));\n-                targetSizeAfterConcat += next.getLength();\n+            String streamSegmentName = handle.getSegmentName();\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName), txn -> txn.get(streamSegmentName)\n+                    .thenComposeAsync(storageMetadata -> {\n+                        SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                        // Check preconditions\n+                        checkSegmentExists(streamSegmentName, segmentMetadata);\n+                        checkOwnership(streamSegmentName, segmentMetadata);\n+\n+                        segmentMetadata.setActive(false);\n+\n+                        // Delete chunks\n+                        ArrayList<String> chunksToDelete = new ArrayList<>();\n+                        return new ChunkIterator(txn, segmentMetadata)\n+                                .forEach((metadata, name) -> {\n+                                    txn.delete(name);\n+                                    chunksToDelete.add(name);\n+                                })\n+                                .thenRunAsync(() -> txn.delete(streamSegmentName), executor)\n+                                .thenComposeAsync(v ->\n+                                        txn.commit()\n+                                                .thenComposeAsync(vv -> {\n+                                                    // Collect garbage.\n+                                                    return collectGarbage(chunksToDelete);\n+                                                }, executor)\n+                                                .thenRunAsync(() -> {\n+                                                    // Update the read index.\n+                                                    readIndexCache.remove(streamSegmentName);\n+\n+                                                    Duration elapsed = timer.getElapsed();\n+                                                    log.debug(\"{} delete - segment={}, latency={}.\", logPrefix, handle.getSegmentName(), elapsed.toMillis());\n+                                                    LoggerHelpers.traceLeave(log, \"delete\", traceId, handle);\n+                                                }, executor)\n+                                                .exceptionally(e -> {\n+                                                    val ex = Exceptions.unwrap(e);\n+                                                    if (ex instanceof StorageMetadataWritesFencedOutException) {\n+                                                        throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n+                                                    }\n+                                                    throw new CompletionException(ex);\n+                                                }), executor);\n+                    }, executor), executor);\n+        });\n+    }\n \n-                nextChunkName = next.getNextChunk();\n-            }\n-            // Note - After above while loop is exited nextChunkName points to chunk next to last one to be concat.\n-            // Which means target should now point to it as next after concat is complete.\n+    @Override\n+    public CompletableFuture<Void> truncate(SegmentHandle handle, long offset, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(new TruncateOperation(this, handle, offset));\n+    }\n \n-            // If there are chunks that can be appended together then concat them.\n-            if (chunksToConcat.size() > 1) {\n-                // Concat\n+    @Override\n+    public boolean supportsTruncation() {\n+        return true;\n+    }\n \n-                ConcatArgument[] concatArgs = new ConcatArgument[chunksToConcat.size()];\n-                for (int i = 0; i < chunksToConcat.size(); i++) {\n-                    concatArgs[i] = ConcatArgument.fromChunkInfo(chunksToConcat.get(i));\n-                }\n+    @Override\n+    public Iterator<SegmentProperties> listSegments() {\n+        throw new UnsupportedOperationException(\"listSegments is not yet supported\");\n+    }\n \n-                if (!useAppend && chunkStorage.supportsConcat()) {\n-                    int length = chunkStorage.concat(concatArgs);\n-                } else {\n-                    concatUsingAppend(concatArgs);\n-                }\n+    @Override\n+    public CompletableFuture<SegmentHandle> openRead(String streamSegmentName) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"openRead\", streamSegmentName);\n+            // Validate preconditions and return handle.\n+            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName), txn ->\n+                            txn.get(streamSegmentName).thenComposeAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                checkSegmentExists(streamSegmentName, segmentMetadata);\n+                                segmentMetadata.checkInvariants();\n+                                // This segment was created by an older segment store. Then claim ownership and adjust length.\n+                                CompletableFuture<Void> f = CompletableFuture.completedFuture(null);\n+                                if (segmentMetadata.getOwnerEpoch() < this.epoch) {\n+                                    log.debug(\"{} openRead - Segment needs ownership change. segment={}.\", logPrefix, segmentMetadata.getName());\n+                                    // In case of a failover, length recorded in metadata will be lagging behind its actual length in the storage.\n+                                    // This can happen with lazy commits that were still not committed at the time of failover.\n+                                    f = claimOwnership(txn, segmentMetadata);\n+                                }\n+                                return f.thenApplyAsync(v -> {\n+                                    val retValue = SegmentStorageHandle.readHandle(streamSegmentName);\n+                                    LoggerHelpers.traceLeave(log, \"openRead\", traceId, retValue);\n+                                    return retValue;\n+                                }, executor);\n+                            }, executor),\n+                    executor);\n+        });\n+    }\n \n-                // Delete chunks.\n-                for (int i = 1; i < chunksToConcat.size(); i++) {\n-                    chunksToDelete.add(chunksToConcat.get(i).getName());\n-                }\n+    @Override\n+    public CompletableFuture<Integer> read(SegmentHandle handle, long offset, byte[] buffer, int bufferOffset, int length, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(new ReadOperation(this, handle, offset, buffer, bufferOffset, length));\n+    }\n \n-                // Set the pointers\n-                target.setLength(targetSizeAfterConcat);\n-                target.setNextChunk(nextChunkName);\n+    @Override\n+    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"getStreamSegmentInfo\", streamSegmentName);\n+            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName), txn ->\n+                    txn.get(streamSegmentName)\n+                            .thenApplyAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                if (null == segmentMetadata) {\n+                                    throw new CompletionException(new StreamSegmentNotExistsException(streamSegmentName));\n+                                }\n+                                segmentMetadata.checkInvariants();\n+\n+                                val retValue = StreamSegmentInformation.builder()\n+                                        .name(streamSegmentName)\n+                                        .sealed(segmentMetadata.isSealed())\n+                                        .length(segmentMetadata.getLength())\n+                                        .startOffset(segmentMetadata.getStartOffset())\n+                                        .lastModified(new ImmutableDate(segmentMetadata.getLastModified()))\n+                                        .build();\n+                                LoggerHelpers.traceLeave(log, \"getStreamSegmentInfo\", traceId, retValue);\n+                                return retValue;\n+                            }, executor), executor);\n+        });\n+    }\n \n-                // If target is the last chunk after this then update metadata accordingly\n-                if (null == nextChunkName) {\n-                    segmentMetadata.setLastChunk(target.getName());\n-                    segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength() - target.getLength());\n-                }\n+    @Override\n+    public CompletableFuture<Boolean> exists(String streamSegmentName, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"exists\", streamSegmentName);\n+            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName),\n+                    txn -> txn.get(streamSegmentName)\n+                            .thenApplyAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                val retValue = segmentMetadata != null && segmentMetadata.isActive();\n+                                LoggerHelpers.traceLeave(log, \"exists\", traceId, retValue);\n+                                return retValue;\n+                            }, executor),\n+                    executor);\n+        });\n+    }\n \n-                // Update metadata for affected chunks.\n-                for (int i = 1; i < concatArgs.length; i++) {\n-                    txn.delete(concatArgs[i].getName());\n-                    segmentMetadata.decrementChunkCount();\n-                }\n-                txn.update(target);\n-                txn.update(segmentMetadata);\n+    @Override\n+    public void close() {\n+        try {\n+            if (null != this.metadataStore) {\n+                this.metadataStore.close();\n             }\n+        } catch (Exception e) {\n+            log.warn(\"Error during close\", e);\n+        }\n+        this.closed.set(true);\n+    }\n \n-            // Move on to next place in list where we can concat if we are done with append based concats.\n-            if (!useAppend) {\n-                targetChunkName = nextChunkName;\n+    /**\n+     * Executes the given Callable and returns its result, while translating any Exceptions bubbling out of it into\n+     * StreamSegmentExceptions.\n+     *\n+     * @param operation The function to execute.\n+     * @param <R>       Return type of the operation.\n+     * @return CompletableFuture<R> of the return type of the operation.\n+     */\n+    private <R> CompletableFuture<R> executeAsync(Callable<CompletableFuture<R>> operation) {\n+        return CompletableFuture.completedFuture(null).thenComposeAsync(v -> {\n+            Exceptions.checkNotClosed(this.closed.get(), this);\n+            try {\n+                return operation.call();\n+            } catch (CompletionException e) {\n+                throw new CompletionException(Exceptions.unwrap(e));\n+            } catch (Exception e) {", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNTA1NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r517035054", "bodyText": "why unwrap when you know it is not really required?", "author": "sachin-j-joshi", "createdAt": "2020-11-04T00:38:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NTM5OA=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\nindex 04901c3ae4..1393c4314b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n\n@@ -371,34 +376,34 @@ public class ChunkedSegmentStorage implements Storage {\n     /**\n      * Gets whether given segment is a critical storage system segment.\n      *\n-     * @param segmentMetadata Meatadata for the segment.\n+     * @param segmentMetadata Metadata for the segment.\n      * @return True if this is a storage system segment.\n      */\n-    private boolean isStorageSystemSegment(SegmentMetadata segmentMetadata) {\n+    boolean isStorageSystemSegment(SegmentMetadata segmentMetadata) {\n         return null != systemJournal && segmentMetadata.isStorageSystemSegment();\n     }\n \n     /**\n      * Delete the garbage chunks.\n      *\n-     * @param chunksTodelete List of chunks to delete.\n+     * @param chunksToDelete List of chunks to delete.\n      */\n-    private CompletableFuture<Void> collectGarbage(Collection<String> chunksTodelete) {\n-        CompletableFuture[] futures = new CompletableFuture[chunksTodelete.size()];\n+    CompletableFuture<Void> collectGarbage(Collection<String> chunksToDelete) {\n+        CompletableFuture[] futures = new CompletableFuture[chunksToDelete.size()];\n         int i = 0;\n-        for (val chunkTodelete : chunksTodelete) {\n-            futures[i++] = chunkStorage.openWrite(chunkTodelete)\n+        for (val chunkToDelete : chunksToDelete) {\n+            futures[i++] = chunkStorage.openWrite(chunkToDelete)\n                     .thenComposeAsync(chunkStorage::delete, executor)\n-                    .thenRunAsync(() -> log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkTodelete), executor)\n+                    .thenRunAsync(() -> log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkToDelete), executor)\n                     .exceptionally(e -> {\n                         val ex = Exceptions.unwrap(e);\n                         if (ex instanceof ChunkNotFoundException) {\n-                            log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                            log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkToDelete);\n                         } else {\n-                            log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                            log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkToDelete);\n                             // Add it to garbage chunks.\n                             synchronized (garbageChunks) {\n-                                garbageChunks.add(chunkTodelete);\n+                                garbageChunks.add(chunkToDelete);\n                             }\n                         }\n                         return null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NjkyMw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499896923", "bodyText": "This is not thread safe. Here (and in other classes within this big class) you use a number of non-final fields which you frequently modify using different threads. While even though you do it in sequence, due to thread local caching of memory addresses, such modifications may not be immediately visible to other threads, and hence even for subsequent iterations of this loop.", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:01:52Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -555,575 +378,700 @@ private boolean isStorageSystemSegment(SegmentMetadata segmentMetadata) {\n         return null != systemJournal && segmentMetadata.isStorageSystemSegment();\n     }\n \n-    /**\n-     * Adds a system log.\n-     *\n-     * @param systemLogRecords\n-     * @param streamSegmentName Name of the segment.\n-     * @param offset            Offset at which new chunk was added.\n-     * @param oldChunkName      Name of the previous last chunk.\n-     * @param newChunkName      Name of the new last chunk.\n-     */\n-    private void addSystemLogRecord(ArrayList<SystemJournal.SystemJournalRecord> systemLogRecords, String streamSegmentName, long offset, String oldChunkName, String newChunkName) {\n-        systemLogRecords.add(\n-                SystemJournal.ChunkAddedRecord.builder()\n-                        .segmentName(streamSegmentName)\n-                        .offset(offset)\n-                        .oldChunkName(oldChunkName == null ? null : oldChunkName)\n-                        .newChunkName(newChunkName)\n-                        .build());\n-    }\n-\n     /**\n      * Delete the garbage chunks.\n      *\n      * @param chunksTodelete List of chunks to delete.\n      */\n-    private void collectGarbage(Collection<String> chunksTodelete) {\n+    private CompletableFuture<Void> collectGarbage(Collection<String> chunksTodelete) {\n+        CompletableFuture[] futures = new CompletableFuture[chunksTodelete.size()];\n+        int i = 0;\n         for (val chunkTodelete : chunksTodelete) {\n-            try {\n-                chunkStorage.delete(chunkStorage.openWrite(chunkTodelete));\n-                log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkTodelete);\n-            } catch (ChunkNotFoundException e) {\n-                log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n-            } catch (Exception e) {\n-                log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n-                // Add it to garbage chunks.\n-                synchronized (garbageChunks) {\n-                    garbageChunks.add(chunkTodelete);\n-                }\n-            }\n+            futures[i++] = chunkStorage.openWrite(chunkTodelete)\n+                    .thenComposeAsync(chunkStorage::delete, executor)\n+                    .thenRunAsync(() -> log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkTodelete), executor)\n+                    .exceptionally(e -> {\n+                        val ex = Exceptions.unwrap(e);\n+                        if (ex instanceof ChunkNotFoundException) {\n+                            log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                        } else {\n+                            log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                            // Add it to garbage chunks.\n+                            synchronized (garbageChunks) {\n+                                garbageChunks.add(chunkTodelete);\n+                            }\n+                        }\n+                        return null;\n+                    });\n         }\n+        return CompletableFuture.allOf(futures);\n     }\n \n     @Override\n     public CompletableFuture<Void> seal(SegmentHandle handle, Duration timeout) {\n         checkInitialized();\n-        return execute(() -> {\n+        return executeAsync(() -> {\n             long traceId = LoggerHelpers.traceEnter(log, \"seal\", handle);\n             Preconditions.checkNotNull(handle, \"handle\");\n             String streamSegmentName = handle.getSegmentName();\n             Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n             Preconditions.checkArgument(!handle.isReadOnly(), \"handle\");\n \n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n-                // Validate preconditions.\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n-                checkOwnership(streamSegmentName, segmentMetadata);\n-\n-                // seal if it is not already sealed.\n-                if (!segmentMetadata.isSealed()) {\n-                    segmentMetadata.setSealed(true);\n-                    txn.update(segmentMetadata);\n-                    txn.commit();\n-                }\n-\n-                log.debug(\"{} seal - segment={}.\", logPrefix, handle.getSegmentName());\n-                LoggerHelpers.traceLeave(log, \"seal\", traceId, handle);\n-                return null;\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(streamSegmentName, ex);\n-            }\n+            return tryWith(metadataStore.beginTransaction(handle.getSegmentName()), txn ->\n+                    txn.get(streamSegmentName)\n+                            .thenComposeAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                // Validate preconditions.\n+                                checkSegmentExists(streamSegmentName, segmentMetadata);\n+                                checkOwnership(streamSegmentName, segmentMetadata);\n+\n+                                // seal if it is not already sealed.\n+                                if (!segmentMetadata.isSealed()) {\n+                                    segmentMetadata.setSealed(true);\n+                                    txn.update(segmentMetadata);\n+                                    return txn.commit();\n+                                }\n+                                return CompletableFuture.completedFuture(null);\n+                            }, executor)\n+                            .thenRunAsync(() -> {\n+                                log.debug(\"{} seal - segment={}.\", logPrefix, handle.getSegmentName());\n+                                LoggerHelpers.traceLeave(log, \"seal\", traceId, handle);\n+                            }, executor)\n+                            .exceptionally(e -> {\n+                                val ex = Exceptions.unwrap(e);\n+                                if (ex instanceof StorageMetadataWritesFencedOutException) {\n+                                    throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n+                                }\n+                                throw new CompletionException(ex);\n+                            }), executor);\n         });\n     }\n \n     @Override\n     public CompletableFuture<Void> concat(SegmentHandle targetHandle, long offset, String sourceSegment, Duration timeout) {\n         checkInitialized();\n-        return execute(() -> {\n-            long traceId = LoggerHelpers.traceEnter(log, \"concat\", targetHandle, offset, sourceSegment);\n-            Timer timer = new Timer();\n-\n-            Preconditions.checkArgument(null != targetHandle, \"targetHandle\");\n-            Preconditions.checkArgument(!targetHandle.isReadOnly(), \"targetHandle\");\n-            Preconditions.checkArgument(null != sourceSegment, \"targetHandle\");\n-            Preconditions.checkArgument(offset >= 0, \"offset\");\n-            String targetSegmentName = targetHandle.getSegmentName();\n-\n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-\n-                SegmentMetadata targetSegmentMetadata = (SegmentMetadata) txn.get(targetSegmentName);\n-\n-                // Validate preconditions.\n-                checkSegmentExists(targetSegmentName, targetSegmentMetadata);\n-                targetSegmentMetadata.checkInvariants();\n-                checkNotSealed(targetSegmentName, targetSegmentMetadata);\n-\n-                SegmentMetadata sourceSegmentMetadata = (SegmentMetadata) txn.get(sourceSegment);\n-                checkSegmentExists(sourceSegment, sourceSegmentMetadata);\n-                sourceSegmentMetadata.checkInvariants();\n-\n-                // This is a critical assumption at this point which should not be broken,\n-                Preconditions.checkState(!targetSegmentMetadata.isStorageSystemSegment(), \"Storage system segments cannot be concatenated.\");\n-                Preconditions.checkState(!sourceSegmentMetadata.isStorageSystemSegment(), \"Storage system segments cannot be concatenated.\");\n-\n-                checkSealed(sourceSegmentMetadata);\n-                checkOwnership(targetSegmentMetadata.getName(), targetSegmentMetadata);\n-\n-                if (sourceSegmentMetadata.getStartOffset() != 0) {\n-                    throw new StreamSegmentTruncatedException(sourceSegment, sourceSegmentMetadata.getLength(), 0);\n-                }\n-\n-                if (offset != targetSegmentMetadata.getLength()) {\n-                    throw new BadOffsetException(targetHandle.getSegmentName(), targetSegmentMetadata.getLength(), offset);\n-                }\n-\n-                // Update list of chunks by appending sources list of chunks.\n-                ChunkMetadata targetLastChunk = (ChunkMetadata) txn.get(targetSegmentMetadata.getLastChunk());\n-                ChunkMetadata sourceFirstChunk = (ChunkMetadata) txn.get(sourceSegmentMetadata.getFirstChunk());\n-\n-                if (targetLastChunk != null) {\n-                    targetLastChunk.setNextChunk(sourceFirstChunk.getName());\n-                    txn.update(targetLastChunk);\n-                } else {\n-                    if (sourceFirstChunk != null) {\n-                        targetSegmentMetadata.setFirstChunk(sourceFirstChunk.getName());\n-                        txn.update(sourceFirstChunk);\n-                    }\n-                }\n-\n-                // Update segments's last chunk to point to the sources last segment.\n-                targetSegmentMetadata.setLastChunk(sourceSegmentMetadata.getLastChunk());\n-\n-                // Update the length of segment.\n-                targetSegmentMetadata.setLastChunkStartOffset(targetSegmentMetadata.getLength() + sourceSegmentMetadata.getLastChunkStartOffset());\n-                targetSegmentMetadata.setLength(targetSegmentMetadata.getLength() + sourceSegmentMetadata.getLength() - sourceSegmentMetadata.getStartOffset());\n-\n-                targetSegmentMetadata.setChunkCount(targetSegmentMetadata.getChunkCount() + sourceSegmentMetadata.getChunkCount());\n-\n-                txn.update(targetSegmentMetadata);\n-                txn.delete(sourceSegment);\n-\n-                // Finally defrag immediately.\n-                ArrayList<String> chunksToDelete = new ArrayList<>();\n-                if (shouldDefrag() && null != targetLastChunk) {\n-                    defrag(txn, targetSegmentMetadata, targetLastChunk.getName(), null, chunksToDelete);\n-                }\n-\n-                targetSegmentMetadata.checkInvariants();\n-\n-                // Finally commit transaction.\n-                txn.commit();\n-\n-                // Collect garbage.\n-                collectGarbage(chunksToDelete);\n-\n-                // Update the read index.\n-                readIndexCache.remove(sourceSegment);\n-\n-                Duration elapsed = timer.getElapsed();\n-                log.debug(\"{} concat - target={}, source={}, offset={}, latency={}.\", logPrefix, targetHandle.getSegmentName(), sourceSegment, offset, elapsed.toMillis());\n-                LoggerHelpers.traceLeave(log, \"concat\", traceId, targetHandle, offset, sourceSegment);\n-\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(targetSegmentName, ex);\n-            }\n-\n-            return null;\n-        });\n+        return executeAsync(new ConcatOperation(this, targetHandle, offset, sourceSegment));\n     }\n \n     private boolean shouldAppend() {\n         return chunkStorage.supportsAppend() && config.isAppendEnabled();\n     }\n \n-    private boolean shouldDefrag() {\n-        return shouldAppend() || chunkStorage.supportsConcat();\n-    }\n-\n     /**\n      * Defragments the list of chunks for a given segment.\n      * It finds eligible consecutive chunks that can be merged together.\n      * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n      * Conceptually this is like deleting nodes from middle of the list of chunks.\n      *\n-     * <Ul>\n-     * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n-     * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n-     * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n-     * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n-     * each write becomes a separate chunk.\n-     * </li>\n-     * <li>\n-     * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n-     * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n-     * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n-     * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n-     * whereas NFS has no concept of merging natively.\n-     *\n-     * As chunks become larger, append writes (read source completely and append it back at the end of target)\n-     * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n-     * when available, and if not available, then we use appends.\n-     * </li>\n-     * <li>\n-     * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n-     * We can then fine tune that background task to run optimally with low overhead.\n-     * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n-     * </li>\n-     * <li>\n-     * <li>\n-     * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n-     * </li>\n-     * </ul>\n-     *\n-     * What controls whether we invoke concat or simulate through appends?\n-     * There are a few different capabilities that ChunkStorage needs to provide.\n-     * <ul>\n-     * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.\n-     * This is indicated by supportsAppend.</li>\n-     * <li>Does ChunkStorage support for concatenating chunks ? This is indicated by supportsConcat.\n-     * If this is true then concat operation will be invoked otherwise chunks will be appended.</li>\n-     * <li>There are some obvious constraints - For ChunkStorage support any concat functionality it must support either\n-     * append or concat.</li>\n-     * <li>Also when ChunkStorage supports both concat and append, ChunkedSegmentStorage will invoke appropriate method\n-     * depending on size of target and source chunks. (Eg. ECS)</li>\n-     * </ul>\n-     *\n-     * <li>\n-     * What controls defrag?\n-     * There are two additional parameters that control when concat\n-     * <li>minSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered a small object.\n-     * For small source objects, append is used instead of using concat. (For really small txn it is rather efficient to use append than MPU).</li>\n-     * <li>maxSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered for concat. (Eg S3 might have max limit on chunk size).</li>\n-     * In short there is a size beyond which using append is not advisable. Conversely there is a size below which concat is not efficient.(minSizeLimitForConcat )\n-     * Then there is limit which concating does not make sense maxSizeLimitForConcat\n-     * </li>\n-     * <li>\n-     * What is the defrag algorithm\n-     * <pre>\n-     * While(segment.hasConcatableChunks()){\n-     *     Set<List<Chunk>> s = FindConsecutiveConcatableChunks();\n-     *     For (List<chunk> list : s){\n-     *        ConcatChunks (list);\n-     *     }\n-     * }\n-     * </pre>\n-     * </li>\n-     * </ul>\n-     *\n      * @param txn             Active {@link MetadataTransaction}.\n      * @param segmentMetadata {@link SegmentMetadata} for the segment to defrag.\n      * @param startChunkName  Name of the first chunk to start defragmentation.\n      * @param lastChunkName   Name of the last chunk before which to stop defragmentation. (last chunk is not concatenated).\n      * @param chunksToDelete  List of chunks to which names of chunks to be deleted are added. It is the responsibility\n      *                        of caller to garbage collect these chunks.\n-     * @throws ChunkStorageException In case of any chunk storage related errors.\n-     * @throws StorageMetadataException In case of any chunk metadata store related errors.\n+     *                        throws ChunkStorageException    In case of any chunk storage related errors.\n+     *                        throws StorageMetadataException In case of any chunk metadata store related errors.\n      */\n-    private void defrag(MetadataTransaction txn, SegmentMetadata segmentMetadata,\n-                        String startChunkName,\n-                        String lastChunkName,\n-                        ArrayList<String> chunksToDelete)\n-            throws StorageMetadataException, ChunkStorageException {\n-        // The algorithm is actually very simple.\n-        // It tries to concat all small chunks using appends first.\n-        // Then it tries to concat remaining chunks using concat if available.\n-        // To implement it using single loop we toggle between concat with append and concat modes. (Instead of two passes.)\n-        boolean useAppend = true;\n-        String targetChunkName = startChunkName;\n-\n-        // Iterate through chunk list\n-        while (null != targetChunkName && !targetChunkName.equals(lastChunkName)) {\n-            ChunkMetadata target = (ChunkMetadata) txn.get(targetChunkName);\n-\n-            ArrayList<ChunkInfo> chunksToConcat = new ArrayList<>();\n-            long targetSizeAfterConcat = target.getLength();\n-\n-            // Add target to the list of chunks\n-            chunksToConcat.add(new ChunkInfo(targetSizeAfterConcat, targetChunkName));\n-\n-            String nextChunkName = target.getNextChunk();\n-            ChunkMetadata next = null;\n-\n-            // Gather list of chunks that can be appended together.\n-            while (null != nextChunkName) {\n-                next = (ChunkMetadata) txn.get(nextChunkName);\n-\n-                if (useAppend && config.getMinSizeLimitForConcat() < next.getLength()) {\n-                    break;\n-                }\n+    private CompletableFuture<Void> defrag(MetadataTransaction txn, SegmentMetadata segmentMetadata,\n+                                           String startChunkName,\n+                                           String lastChunkName,\n+                                           ArrayList<String> chunksToDelete) {\n+        return new DefragmentOperation(this, txn, segmentMetadata, startChunkName, lastChunkName, chunksToDelete).call();\n+    }\n \n-                if (targetSizeAfterConcat + next.getLength() > segmentMetadata.getMaxRollinglength() || next.getLength() > config.getMaxSizeLimitForConcat()) {\n-                    break;\n-                }\n+    @Override\n+    public CompletableFuture<Void> delete(SegmentHandle handle, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"delete\", handle);\n+            Timer timer = new Timer();\n \n-                chunksToConcat.add(new ChunkInfo(next.getLength(), nextChunkName));\n-                targetSizeAfterConcat += next.getLength();\n+            String streamSegmentName = handle.getSegmentName();\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName), txn -> txn.get(streamSegmentName)\n+                    .thenComposeAsync(storageMetadata -> {\n+                        SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                        // Check preconditions\n+                        checkSegmentExists(streamSegmentName, segmentMetadata);\n+                        checkOwnership(streamSegmentName, segmentMetadata);\n+\n+                        segmentMetadata.setActive(false);\n+\n+                        // Delete chunks\n+                        ArrayList<String> chunksToDelete = new ArrayList<>();\n+                        return new ChunkIterator(txn, segmentMetadata)\n+                                .forEach((metadata, name) -> {\n+                                    txn.delete(name);\n+                                    chunksToDelete.add(name);\n+                                })\n+                                .thenRunAsync(() -> txn.delete(streamSegmentName), executor)\n+                                .thenComposeAsync(v ->\n+                                        txn.commit()\n+                                                .thenComposeAsync(vv -> {\n+                                                    // Collect garbage.\n+                                                    return collectGarbage(chunksToDelete);\n+                                                }, executor)\n+                                                .thenRunAsync(() -> {\n+                                                    // Update the read index.\n+                                                    readIndexCache.remove(streamSegmentName);\n+\n+                                                    Duration elapsed = timer.getElapsed();\n+                                                    log.debug(\"{} delete - segment={}, latency={}.\", logPrefix, handle.getSegmentName(), elapsed.toMillis());\n+                                                    LoggerHelpers.traceLeave(log, \"delete\", traceId, handle);\n+                                                }, executor)\n+                                                .exceptionally(e -> {\n+                                                    val ex = Exceptions.unwrap(e);\n+                                                    if (ex instanceof StorageMetadataWritesFencedOutException) {\n+                                                        throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n+                                                    }\n+                                                    throw new CompletionException(ex);\n+                                                }), executor);\n+                    }, executor), executor);\n+        });\n+    }\n \n-                nextChunkName = next.getNextChunk();\n-            }\n-            // Note - After above while loop is exited nextChunkName points to chunk next to last one to be concat.\n-            // Which means target should now point to it as next after concat is complete.\n+    @Override\n+    public CompletableFuture<Void> truncate(SegmentHandle handle, long offset, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(new TruncateOperation(this, handle, offset));\n+    }\n \n-            // If there are chunks that can be appended together then concat them.\n-            if (chunksToConcat.size() > 1) {\n-                // Concat\n+    @Override\n+    public boolean supportsTruncation() {\n+        return true;\n+    }\n \n-                ConcatArgument[] concatArgs = new ConcatArgument[chunksToConcat.size()];\n-                for (int i = 0; i < chunksToConcat.size(); i++) {\n-                    concatArgs[i] = ConcatArgument.fromChunkInfo(chunksToConcat.get(i));\n-                }\n+    @Override\n+    public Iterator<SegmentProperties> listSegments() {\n+        throw new UnsupportedOperationException(\"listSegments is not yet supported\");\n+    }\n \n-                if (!useAppend && chunkStorage.supportsConcat()) {\n-                    int length = chunkStorage.concat(concatArgs);\n-                } else {\n-                    concatUsingAppend(concatArgs);\n-                }\n+    @Override\n+    public CompletableFuture<SegmentHandle> openRead(String streamSegmentName) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"openRead\", streamSegmentName);\n+            // Validate preconditions and return handle.\n+            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName), txn ->\n+                            txn.get(streamSegmentName).thenComposeAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                checkSegmentExists(streamSegmentName, segmentMetadata);\n+                                segmentMetadata.checkInvariants();\n+                                // This segment was created by an older segment store. Then claim ownership and adjust length.\n+                                CompletableFuture<Void> f = CompletableFuture.completedFuture(null);\n+                                if (segmentMetadata.getOwnerEpoch() < this.epoch) {\n+                                    log.debug(\"{} openRead - Segment needs ownership change. segment={}.\", logPrefix, segmentMetadata.getName());\n+                                    // In case of a failover, length recorded in metadata will be lagging behind its actual length in the storage.\n+                                    // This can happen with lazy commits that were still not committed at the time of failover.\n+                                    f = claimOwnership(txn, segmentMetadata);\n+                                }\n+                                return f.thenApplyAsync(v -> {\n+                                    val retValue = SegmentStorageHandle.readHandle(streamSegmentName);\n+                                    LoggerHelpers.traceLeave(log, \"openRead\", traceId, retValue);\n+                                    return retValue;\n+                                }, executor);\n+                            }, executor),\n+                    executor);\n+        });\n+    }\n \n-                // Delete chunks.\n-                for (int i = 1; i < chunksToConcat.size(); i++) {\n-                    chunksToDelete.add(chunksToConcat.get(i).getName());\n-                }\n+    @Override\n+    public CompletableFuture<Integer> read(SegmentHandle handle, long offset, byte[] buffer, int bufferOffset, int length, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(new ReadOperation(this, handle, offset, buffer, bufferOffset, length));\n+    }\n \n-                // Set the pointers\n-                target.setLength(targetSizeAfterConcat);\n-                target.setNextChunk(nextChunkName);\n+    @Override\n+    public CompletableFuture<SegmentProperties> getStreamSegmentInfo(String streamSegmentName, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"getStreamSegmentInfo\", streamSegmentName);\n+            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName), txn ->\n+                    txn.get(streamSegmentName)\n+                            .thenApplyAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                if (null == segmentMetadata) {\n+                                    throw new CompletionException(new StreamSegmentNotExistsException(streamSegmentName));\n+                                }\n+                                segmentMetadata.checkInvariants();\n+\n+                                val retValue = StreamSegmentInformation.builder()\n+                                        .name(streamSegmentName)\n+                                        .sealed(segmentMetadata.isSealed())\n+                                        .length(segmentMetadata.getLength())\n+                                        .startOffset(segmentMetadata.getStartOffset())\n+                                        .lastModified(new ImmutableDate(segmentMetadata.getLastModified()))\n+                                        .build();\n+                                LoggerHelpers.traceLeave(log, \"getStreamSegmentInfo\", traceId, retValue);\n+                                return retValue;\n+                            }, executor), executor);\n+        });\n+    }\n \n-                // If target is the last chunk after this then update metadata accordingly\n-                if (null == nextChunkName) {\n-                    segmentMetadata.setLastChunk(target.getName());\n-                    segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength() - target.getLength());\n-                }\n+    @Override\n+    public CompletableFuture<Boolean> exists(String streamSegmentName, Duration timeout) {\n+        checkInitialized();\n+        return executeAsync(() -> {\n+            long traceId = LoggerHelpers.traceEnter(log, \"exists\", streamSegmentName);\n+            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n+            return tryWith(metadataStore.beginTransaction(streamSegmentName),\n+                    txn -> txn.get(streamSegmentName)\n+                            .thenApplyAsync(storageMetadata -> {\n+                                SegmentMetadata segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                val retValue = segmentMetadata != null && segmentMetadata.isActive();\n+                                LoggerHelpers.traceLeave(log, \"exists\", traceId, retValue);\n+                                return retValue;\n+                            }, executor),\n+                    executor);\n+        });\n+    }\n \n-                // Update metadata for affected chunks.\n-                for (int i = 1; i < concatArgs.length; i++) {\n-                    txn.delete(concatArgs[i].getName());\n-                    segmentMetadata.decrementChunkCount();\n-                }\n-                txn.update(target);\n-                txn.update(segmentMetadata);\n+    @Override\n+    public void close() {\n+        try {\n+            if (null != this.metadataStore) {\n+                this.metadataStore.close();\n             }\n+        } catch (Exception e) {\n+            log.warn(\"Error during close\", e);\n+        }\n+        this.closed.set(true);\n+    }\n \n-            // Move on to next place in list where we can concat if we are done with append based concats.\n-            if (!useAppend) {\n-                targetChunkName = nextChunkName;\n+    /**\n+     * Executes the given Callable and returns its result, while translating any Exceptions bubbling out of it into\n+     * StreamSegmentExceptions.\n+     *\n+     * @param operation The function to execute.\n+     * @param <R>       Return type of the operation.\n+     * @return CompletableFuture<R> of the return type of the operation.\n+     */\n+    private <R> CompletableFuture<R> executeAsync(Callable<CompletableFuture<R>> operation) {\n+        return CompletableFuture.completedFuture(null).thenComposeAsync(v -> {\n+            Exceptions.checkNotClosed(this.closed.get(), this);\n+            try {\n+                return operation.call();\n+            } catch (CompletionException e) {\n+                throw new CompletionException(Exceptions.unwrap(e));\n+            } catch (Exception e) {\n+                throw new CompletionException(e);\n             }\n+        }, this.executor);\n+    }\n \n-            // Toggle\n-            useAppend = !useAppend;\n-        }\n-\n-        // Make sure no invariants are broken.\n-        segmentMetadata.checkInvariants();\n+    private static <T extends AutoCloseable, R> CompletableFuture<R> tryWith(T closeable, Function<T, CompletableFuture<R>> function, Executor executor) {\n+        return function.apply(closeable)\n+                    .whenCompleteAsync((v, ex) -> {\n+                        try {\n+                            closeable.close();\n+                        } catch (Exception e) {\n+                            throw new CompletionException(e);\n+                        }\n+                    }, executor);\n     }\n \n-    private void concatUsingAppend(ConcatArgument[] concatArgs) throws ChunkStorageException {\n-        long writeAtOffset = concatArgs[0].getLength();\n-        val writeHandle = ChunkHandle.writeHandle(concatArgs[0].getName());\n-        for (int i = 1; i < concatArgs.length; i++) {\n-            int readAtOffset = 0;\n-            val arg = concatArgs[i];\n-            int bytesToRead = Math.toIntExact(arg.getLength());\n-\n-            while (bytesToRead > 0) {\n-                byte[] buffer = new byte[Math.min(config.getMaxBufferSizeForChunkDataTransfer(), bytesToRead)];\n-                int size = chunkStorage.read(ChunkHandle.readHandle(arg.getName()), readAtOffset, buffer.length, buffer, 0);\n-                bytesToRead -= size;\n-                readAtOffset += size;\n-                writeAtOffset += chunkStorage.write(writeHandle, writeAtOffset, size, new ByteArrayInputStream(buffer, 0, size));\n-            }\n+    private void checkSegmentExists(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+        if (null == segmentMetadata || !segmentMetadata.isActive()) {\n+            throw new CompletionException(new StreamSegmentNotExistsException(streamSegmentName));\n         }\n     }\n \n-    @Override\n-    public CompletableFuture<Void> delete(SegmentHandle handle, Duration timeout) {\n-        checkInitialized();\n-        return execute(() -> {\n-            long traceId = LoggerHelpers.traceEnter(log, \"delete\", handle);\n-            Timer timer = new Timer();\n+    private void checkOwnership(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+        if (segmentMetadata.getOwnerEpoch() > this.epoch) {\n+            throw new CompletionException(new StorageNotPrimaryException(streamSegmentName));\n+        }\n+    }\n \n-            String streamSegmentName = handle.getSegmentName();\n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n-\n-                // Check preconditions\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n-                checkOwnership(streamSegmentName, segmentMetadata);\n-\n-                segmentMetadata.setActive(false);\n-\n-                // Delete chunks\n-                String currentChunkName = segmentMetadata.getFirstChunk();\n-                ChunkMetadata currentMetadata;\n-                ArrayList<String> chunksToDelete = new ArrayList<>();\n-                while (currentChunkName != null) {\n-                    currentMetadata = (ChunkMetadata) txn.get(currentChunkName);\n-                    // Delete underlying file.\n-                    chunksToDelete.add(currentChunkName);\n-                    currentChunkName = currentMetadata.getNextChunk();\n-                    txn.delete(currentMetadata.getName());\n-                }\n+    private void checkNotSealed(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+        if (segmentMetadata.isSealed()) {\n+            throw new CompletionException(new StreamSegmentSealedException(streamSegmentName));\n+        }\n+    }\n \n-                // Commit.\n-                txn.delete(streamSegmentName);\n-                txn.commit();\n+    private void checkInitialized() {\n+        Preconditions.checkState(null != this.metadataStore);\n+        Preconditions.checkState(0 != this.epoch);\n+        Preconditions.checkState(!closed.get());\n+    }\n \n-                // Collect garbage.\n-                collectGarbage(chunksToDelete);\n+    private class ChunkIterator {\n+        private final MetadataTransaction txn;\n+        private String currentChunkName;\n+        private ChunkMetadata currentMetadata;\n \n-                // Update the read index.\n-                readIndexCache.remove(streamSegmentName);\n+        ChunkIterator(MetadataTransaction txn, SegmentMetadata segmentMetadata) {\n+            this.txn = txn;\n+            currentChunkName = segmentMetadata.getFirstChunk();\n+        }\n \n-                Duration elapsed = timer.getElapsed();\n-                log.debug(\"{} delete - segment={}, latency={}.\", logPrefix, handle.getSegmentName(), elapsed.toMillis());\n-                LoggerHelpers.traceLeave(log, \"delete\", traceId, handle);\n-                return null;\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(streamSegmentName, ex);\n-            }\n-        });\n+        public CompletableFuture<Void> forEach(BiConsumer<ChunkMetadata, String> consumer) {\n+            return Futures.loop(\n+                    () -> currentChunkName != null,\n+                    () -> txn.get(currentChunkName)\n+                            .thenApplyAsync(storageMetadata -> {\n+                                currentMetadata = (ChunkMetadata) storageMetadata;\n+                                consumer.accept(currentMetadata, currentChunkName);\n+                                // Move next\n+                                currentChunkName = currentMetadata.getNextChunk();\n+                                return null;\n+                            }, executor),\n+                    executor);\n+        }\n     }\n \n-    @Override\n-    public CompletableFuture<Void> truncate(SegmentHandle handle, long offset, Duration timeout) {\n-        checkInitialized();\n-        return execute(() -> {\n-            long traceId = LoggerHelpers.traceEnter(log, \"truncate\", handle, offset);\n-            Timer timer = new Timer();\n+    private static class TruncateOperation implements Callable<CompletableFuture<Void>> {\n+        private final SegmentHandle handle;\n+        private final long offset;\n+        private final ChunkedSegmentStorage chunkedSegmentStorage;\n+\n+        private String currentChunkName;\n+        private ChunkMetadata currentMetadata;\n+        private long oldLength;\n+        private long startOffset;\n+        private ArrayList<String> chunksToDelete = new ArrayList<>();\n+        private SegmentMetadata segmentMetadata;\n+        private String streamSegmentName;\n+\n+        private boolean isLoopExited;\n+        private long traceId;\n+        private Timer timer;\n+\n+        TruncateOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle handle, long offset) {\n+            this.handle = handle;\n+            this.offset = offset;\n+            this.chunkedSegmentStorage = chunkedSegmentStorage;\n+        }\n \n-            Preconditions.checkArgument(null != handle, \"handle\");\n-            Preconditions.checkArgument(!handle.isReadOnly(), \"handle\");\n-            Preconditions.checkArgument(offset >= 0, \"offset\");\n+        public CompletableFuture<Void> call() {\n+            traceId = LoggerHelpers.traceEnter(log, \"truncate\", handle, offset);\n+            timer = new Timer();\n+\n+            checkPreconditions();\n+\n+            streamSegmentName = handle.getSegmentName();\n+            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(streamSegmentName), txn ->\n+                    txn.get(streamSegmentName)\n+                            .thenComposeAsync(storageMetadata -> {\n+                                segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                // Check preconditions\n+                                checkPreconditions(streamSegmentName, segmentMetadata);\n+\n+                                if (segmentMetadata.getStartOffset() == offset) {\n+                                    // Nothing to do\n+                                    return CompletableFuture.completedFuture(null);\n+                                }\n+\n+                                return updateFirstChunk(txn)\n+                                        .thenComposeAsync(v -> {\n+                                            deleteChunks(txn);\n+\n+                                            txn.update(segmentMetadata);\n+\n+                                            // Check invariants.\n+                                            Preconditions.checkState(segmentMetadata.getLength() == oldLength, \"truncate should not change segment length\");\n+                                            segmentMetadata.checkInvariants();\n+\n+                                            // Finally commit.\n+                                            return commit(txn)\n+                                                    .handleAsync(this::handleException, chunkedSegmentStorage.executor)\n+                                                    .thenComposeAsync(vv ->\n+                                                                    chunkedSegmentStorage.collectGarbage(chunksToDelete).thenApplyAsync(vvv -> {\n+                                                                        postCommit();\n+                                                                        return null;\n+                                                                    }, chunkedSegmentStorage.executor),\n+                                                            chunkedSegmentStorage.executor);\n+                                        }, chunkedSegmentStorage.executor);\n+                            }, chunkedSegmentStorage.executor), chunkedSegmentStorage.executor);\n+        }\n \n-            String streamSegmentName = handle.getSegmentName();\n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n+        private void postCommit() {\n+            // Update the read index by removing all entries below truncate offset.\n+            chunkedSegmentStorage.readIndexCache.truncateReadIndex(streamSegmentName, segmentMetadata.getStartOffset());\n \n-                // Check preconditions\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n-                checkNotSealed(streamSegmentName, segmentMetadata);\n-                checkOwnership(streamSegmentName, segmentMetadata);\n+            logEnd();\n+        }\n+\n+        private void logEnd() {\n+            Duration elapsed = timer.getElapsed();\n+            log.debug(\"{} truncate - segment={}, offset={}, latency={}.\", chunkedSegmentStorage.logPrefix, handle.getSegmentName(), offset, elapsed.toMillis());\n+            LoggerHelpers.traceLeave(log, \"truncate\", traceId, handle, offset);\n+        }\n \n-                if (segmentMetadata.getLength() < offset || segmentMetadata.getStartOffset() > offset) {\n-                    throw new IllegalArgumentException(String.format(\"offset %d is outside of valid range [%d, %d) for segment %s\",\n-                            offset, segmentMetadata.getStartOffset(), segmentMetadata.getLength(), streamSegmentName));\n+        private Void handleException(Void value, Throwable e) {\n+            if (null != e) {\n+                val ex = Exceptions.unwrap(e);\n+                if (ex instanceof StorageMetadataWritesFencedOutException) {\n+                    throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n                 }\n+                throw new CompletionException(ex);\n+            }\n+            return value;\n+        }\n \n-                if (segmentMetadata.getStartOffset() == offset) {\n-                    // Nothing to do\n+        private CompletableFuture<Void> commit(MetadataTransaction txn) {\n+            // Commit system logs.\n+            if (chunkedSegmentStorage.isStorageSystemSegment(segmentMetadata)) {\n+                val finalStartOffset = startOffset;\n+                txn.setExternalCommitStep(() -> {\n+                    chunkedSegmentStorage.systemJournal.commitRecord(\n+                            SystemJournal.TruncationRecord.builder()\n+                                    .segmentName(streamSegmentName)\n+                                    .offset(offset)\n+                                    .firstChunkName(segmentMetadata.getFirstChunk())\n+                                    .startOffset(finalStartOffset)\n+                                    .build());\n                     return null;\n-                }\n+                });\n+            }\n \n-                String currentChunkName = segmentMetadata.getFirstChunk();\n-                ChunkMetadata currentMetadata;\n-                long oldLength = segmentMetadata.getLength();\n-                long startOffset = segmentMetadata.getFirstChunkStartOffset();\n-                ArrayList<String> chunksToDelete = new ArrayList<>();\n-                while (currentChunkName != null) {\n-                    currentMetadata = (ChunkMetadata) txn.get(currentChunkName);\n-                    Preconditions.checkState(null != currentMetadata, \"currentMetadata is null.\");\n-\n-                    // If for given chunk start <= offset < end  then we have found the chunk that will be the first chunk.\n-                    if ((startOffset <= offset) && (startOffset + currentMetadata.getLength() > offset)) {\n-                        break;\n-                    }\n-\n-                    startOffset += currentMetadata.getLength();\n-                    chunksToDelete.add(currentMetadata.getName());\n-                    segmentMetadata.decrementChunkCount();\n+            // Finally commit.\n+            return txn.commit();\n+        }\n \n-                    // move to next chunk\n-                    currentChunkName = currentMetadata.getNextChunk();\n-                }\n+        private CompletableFuture<Void> updateFirstChunk(MetadataTransaction txn) {\n+            currentChunkName = segmentMetadata.getFirstChunk();\n+            oldLength = segmentMetadata.getLength();\n+            startOffset = segmentMetadata.getFirstChunkStartOffset();\n+            return Futures.loop(\n+                    () -> currentChunkName != null && !isLoopExited,\n+                    () -> txn.get(currentChunkName)\n+                            .thenApplyAsync(storageMetadata -> {\n+                                currentMetadata = (ChunkMetadata) storageMetadata;\n+                                Preconditions.checkState(null != currentMetadata, \"currentMetadata is null.\");\n+\n+                                // If for given chunk start <= offset < end  then we have found the chunk that will be the first chunk.\n+                                if ((startOffset <= offset) && (startOffset + currentMetadata.getLength() > offset)) {\n+                                    isLoopExited = true;\n+                                    return null;\n+                                }\n+\n+                                startOffset += currentMetadata.getLength();\n+                                chunksToDelete.add(currentMetadata.getName());\n+                                segmentMetadata.decrementChunkCount();\n+\n+                                // move to next chunk\n+                                currentChunkName = currentMetadata.getNextChunk();\n+                                return null;\n+                            }, chunkedSegmentStorage.executor),\n+                    chunkedSegmentStorage.executor\n+            ).thenApplyAsync(v -> {\n                 segmentMetadata.setFirstChunk(currentChunkName);\n                 segmentMetadata.setStartOffset(offset);\n                 segmentMetadata.setFirstChunkStartOffset(startOffset);\n-                for (String toDelete : chunksToDelete) {\n-                    txn.delete(toDelete);\n-                    // Adjust last chunk if required.\n-                    if (toDelete.equals(segmentMetadata.getLastChunk())) {\n-                        segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength());\n-                        segmentMetadata.setLastChunk(null);\n-                    }\n-                }\n-                txn.update(segmentMetadata);\n+                return null;\n+            }, chunkedSegmentStorage.executor);\n+        }\n \n-                // Check invariants.\n-                Preconditions.checkState(segmentMetadata.getLength() == oldLength, \"truncate should not change segment length\");\n-                segmentMetadata.checkInvariants();\n-\n-                // Commit system logs.\n-                if (isStorageSystemSegment(segmentMetadata)) {\n-                    val finalStartOffset = startOffset;\n-                    txn.setExternalCommitStep(() -> {\n-                        systemJournal.commitRecord(\n-                                SystemJournal.TruncationRecord.builder()\n-                                        .segmentName(streamSegmentName)\n-                                        .offset(offset)\n-                                        .firstChunkName(segmentMetadata.getFirstChunk())\n-                                        .startOffset(finalStartOffset)\n-                                        .build());\n-                        return null;\n-                    });\n+        private void deleteChunks(MetadataTransaction txn) {\n+            for (String toDelete : chunksToDelete) {\n+                txn.delete(toDelete);\n+                // Adjust last chunk if required.\n+                if (toDelete.equals(segmentMetadata.getLastChunk())) {\n+                    segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength());\n+                    segmentMetadata.setLastChunk(null);\n                 }\n+            }\n+        }\n \n-                // Finally commit.\n-                txn.commit();\n-\n-                collectGarbage(chunksToDelete);\n-\n-                // Update the read index by removing all entries below truncate offset.\n-                readIndexCache.truncateReadIndex(streamSegmentName, segmentMetadata.getStartOffset());\n+        private void checkPreconditions(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+            chunkedSegmentStorage.checkSegmentExists(streamSegmentName, segmentMetadata);\n+            chunkedSegmentStorage.checkNotSealed(streamSegmentName, segmentMetadata);\n+            chunkedSegmentStorage.checkOwnership(streamSegmentName, segmentMetadata);\n \n-                Duration elapsed = timer.getElapsed();\n-                log.debug(\"{} truncate - segment={}, offset={}, latency={}.\", logPrefix, handle.getSegmentName(), offset, elapsed.toMillis());\n-                LoggerHelpers.traceLeave(log, \"truncate\", traceId, handle, offset);\n-                return null;\n-            } catch (StorageMetadataWritesFencedOutException ex) {\n-                throw new StorageNotPrimaryException(streamSegmentName, ex);\n+            if (segmentMetadata.getLength() < offset || segmentMetadata.getStartOffset() > offset) {\n+                throw new IllegalArgumentException(String.format(\"offset %d is outside of valid range [%d, %d) for segment %s\",\n+                        offset, segmentMetadata.getStartOffset(), segmentMetadata.getLength(), streamSegmentName));\n             }\n-        });\n-    }\n+        }\n \n-    @Override\n-    public boolean supportsTruncation() {\n-        return true;\n+        private void checkPreconditions() {\n+            Preconditions.checkArgument(null != handle, \"handle\");\n+            Preconditions.checkArgument(!handle.isReadOnly(), \"handle\");\n+            Preconditions.checkArgument(offset >= 0, \"offset\");\n+        }\n     }\n \n-    @Override\n-    public Iterator<SegmentProperties> listSegments() throws IOException {\n-        throw new UnsupportedOperationException(\"listSegments is not yet supported\");\n-    }\n+    private static class ReadOperation implements Callable<CompletableFuture<Integer>> {\n+        private final SegmentHandle handle;\n+        private final long offset;\n+        private final byte[] buffer;\n+        private final int bufferOffset;\n+        private final int length;\n+        private final ChunkedSegmentStorage chunkedSegmentStorage;\n+        private long traceId;\n+        private Timer timer;\n+        private String streamSegmentName;\n+        private SegmentMetadata segmentMetadata;\n+        private int bytesRemaining;\n+        private int currentBufferOffset;\n+        private long currentOffset;\n+        private int totalBytesRead = 0;\n+        private long startOffsetForCurrentChunk;\n+        private String currentChunkName;\n+        private ChunkMetadata chunkToReadFrom = null;\n+        private boolean isLoopExited;\n+        private int cntScanned = 0;\n+        private int bytesToRead;\n+\n+        ReadOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle handle, long offset, byte[] buffer, int bufferOffset, int length) {\n+            this.handle = handle;\n+            this.offset = offset;\n+            this.buffer = buffer;\n+            this.bufferOffset = bufferOffset;\n+            this.length = length;\n+            this.chunkedSegmentStorage = chunkedSegmentStorage;\n+        }\n \n-    @Override\n-    public CompletableFuture<SegmentHandle> openRead(String streamSegmentName) {\n-        checkInitialized();\n-        return execute(() -> {\n-            long traceId = LoggerHelpers.traceEnter(log, \"openRead\", streamSegmentName);\n-            // Validate preconditions and return handle.\n-            Preconditions.checkNotNull(streamSegmentName, \"streamSegmentName\");\n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n-                segmentMetadata.checkInvariants();\n-                // This segment was created by an older segment store. Then claim ownership and adjust length.\n-                if (segmentMetadata.getOwnerEpoch() < this.epoch) {\n-                    log.debug(\"{} openRead - Segment needs ownership change. segment={}.\", logPrefix, segmentMetadata.getName());\n-                    // In case of a failover, length recorded in metadata will be lagging behind its actual length in the storage.\n-                    // This can happen with lazy commits that were still not committed at the time of failover.\n-                    claimOwnership(txn, segmentMetadata);\n-                }\n-                val retValue = SegmentStorageHandle.readHandle(streamSegmentName);\n-                LoggerHelpers.traceLeave(log, \"openRead\", traceId, retValue);\n-                return retValue;\n+        public CompletableFuture<Integer> call() {\n+            traceId = LoggerHelpers.traceEnter(log, \"read\", handle, offset, length);\n+            timer = new Timer();\n+\n+            // Validate preconditions.\n+            checkPreconditions();\n+            streamSegmentName = handle.getSegmentName();\n+            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(streamSegmentName),\n+                    txn -> txn.get(streamSegmentName)\n+                            .thenComposeAsync(storageMetadata -> {\n+                                segmentMetadata = (SegmentMetadata) storageMetadata;\n+\n+                                // Validate preconditions.\n+                                checkState();\n+\n+                                if (length == 0) {\n+                                    return CompletableFuture.completedFuture(0);\n+                                }\n+\n+                                return findChunkForOffset(txn)\n+                                        .thenComposeAsync(v -> {\n+                                            // Now read.\n+                                            return readData(txn);\n+                                        }, chunkedSegmentStorage.executor)\n+                                        .thenApplyAsync(v -> {\n+                                            logEnd();\n+                                            return totalBytesRead;\n+                                        }, chunkedSegmentStorage.executor);\n+                            }, chunkedSegmentStorage.executor),\n+                    chunkedSegmentStorage.executor);\n+        }\n+\n+        private void logEnd() {\n+            Duration elapsed = timer.getElapsed();\n+            log.debug(\"{} read - segment={}, offset={}, bytesRead={}, latency={}.\", chunkedSegmentStorage.logPrefix, handle.getSegmentName(), offset, totalBytesRead, elapsed.toMillis());\n+            LoggerHelpers.traceLeave(log, \"read\", traceId, handle, offset, totalBytesRead);\n+        }\n+\n+        private CompletableFuture<Void> readData(MetadataTransaction txn) {\n+            return Futures.loop(\n+                    () -> bytesRemaining > 0 && null != currentChunkName,", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MzQ2OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506753468", "bodyText": "These methods are called on a single object one after another - so there is no possibility of concurrent modifications.  But there may be visibility problems. Making the mutable fields volatile and other fields final solves the visibility problem.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:52:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NjkyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MzcxMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506753712", "bodyText": "Also now I have split big bad class into smaller classes.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:53:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NjkyMw=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\nindex 04901c3ae4..1393c4314b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n\n@@ -371,34 +376,34 @@ public class ChunkedSegmentStorage implements Storage {\n     /**\n      * Gets whether given segment is a critical storage system segment.\n      *\n-     * @param segmentMetadata Meatadata for the segment.\n+     * @param segmentMetadata Metadata for the segment.\n      * @return True if this is a storage system segment.\n      */\n-    private boolean isStorageSystemSegment(SegmentMetadata segmentMetadata) {\n+    boolean isStorageSystemSegment(SegmentMetadata segmentMetadata) {\n         return null != systemJournal && segmentMetadata.isStorageSystemSegment();\n     }\n \n     /**\n      * Delete the garbage chunks.\n      *\n-     * @param chunksTodelete List of chunks to delete.\n+     * @param chunksToDelete List of chunks to delete.\n      */\n-    private CompletableFuture<Void> collectGarbage(Collection<String> chunksTodelete) {\n-        CompletableFuture[] futures = new CompletableFuture[chunksTodelete.size()];\n+    CompletableFuture<Void> collectGarbage(Collection<String> chunksToDelete) {\n+        CompletableFuture[] futures = new CompletableFuture[chunksToDelete.size()];\n         int i = 0;\n-        for (val chunkTodelete : chunksTodelete) {\n-            futures[i++] = chunkStorage.openWrite(chunkTodelete)\n+        for (val chunkToDelete : chunksToDelete) {\n+            futures[i++] = chunkStorage.openWrite(chunkToDelete)\n                     .thenComposeAsync(chunkStorage::delete, executor)\n-                    .thenRunAsync(() -> log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkTodelete), executor)\n+                    .thenRunAsync(() -> log.debug(\"{} collectGarbage - deleted chunk={}.\", logPrefix, chunkToDelete), executor)\n                     .exceptionally(e -> {\n                         val ex = Exceptions.unwrap(e);\n                         if (ex instanceof ChunkNotFoundException) {\n-                            log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                            log.debug(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkToDelete);\n                         } else {\n-                            log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkTodelete);\n+                            log.warn(\"{} collectGarbage - Could not delete garbage chunk {}.\", logPrefix, chunkToDelete);\n                             // Add it to garbage chunks.\n                             synchronized (garbageChunks) {\n-                                garbageChunks.add(chunkTodelete);\n+                                garbageChunks.add(chunkToDelete);\n                             }\n                         }\n                         return null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NzMyNQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499897325", "bodyText": "Is there another way to format this method? My head hurts :)", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:02:58Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -1132,207 +1080,792 @@ public boolean supportsTruncation() {\n                         \"Offset (%s) must be non-negative, and bufferOffset (%s) and length (%s) must be valid indices into buffer of size %s.\",\n                         offset, bufferOffset, length, buffer.length));\n             }\n+        }\n+    }\n \n-            try (MetadataTransaction txn = metadataStore.beginTransaction()) {\n-                SegmentMetadata segmentMetadata = (SegmentMetadata) txn.get(streamSegmentName);\n+    /**\n+     * Implements the write operation.\n+     */\n+    private static class WriteOperation implements Callable<CompletableFuture<Void>> {\n+        private final SegmentHandle handle;\n+        private final long offset;\n+        private final InputStream data;\n+        private final int length;\n+        private final ChunkedSegmentStorage chunkedSegmentStorage;\n+\n+        private final ArrayList<SystemJournal.SystemJournalRecord> systemLogRecords = new ArrayList<>();\n+        private final List<ChunkNameOffsetPair> newReadIndexEntries = new ArrayList<>();\n+        private int chunksAddedCount = 0;\n+        private boolean isCommited = false;\n+\n+        private long traceId;\n+        private Timer timer;\n+\n+        private String streamSegmentName;\n+        private SegmentMetadata segmentMetadata;\n+\n+        private boolean isSystemSegment;\n+\n+        // Check if this is a first write after ownership changed.\n+        private boolean isFirstWriteAfterFailover;\n+\n+        private ChunkMetadata lastChunkMetadata = null;\n+        private ChunkHandle chunkHandle = null;\n+        private int bytesRemaining;\n+        private long currentOffset;\n+\n+        private boolean didSegmentLayoutChange = false;\n+\n+        WriteOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle handle, long offset, InputStream data, int length) {\n+            this.handle = handle;\n+            this.offset = offset;\n+            this.data = data;\n+            this.length = length;\n+            this.chunkedSegmentStorage = chunkedSegmentStorage;\n+        }\n \n-                // Validate preconditions.\n-                checkSegmentExists(streamSegmentName, segmentMetadata);\n+        public CompletableFuture<Void> call() {\n+            traceId = LoggerHelpers.traceEnter(log, \"write\", handle, offset, length);\n+            timer = new Timer();\n \n-                segmentMetadata.checkInvariants();\n+            // Validate preconditions.\n+            checkPreconditions();\n+\n+            streamSegmentName = handle.getSegmentName();\n+            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(handle.getSegmentName()),\n+                    txn -> {\n+                        didSegmentLayoutChange = false;\n+\n+                        // Retrieve metadata.\n+                        return txn.get(streamSegmentName)\n+                                .thenComposeAsync(storageMetadata -> {\n+                                    segmentMetadata = (SegmentMetadata) storageMetadata;\n+                                    // Validate preconditions.\n+                                    checkState();\n+\n+                                    isSystemSegment = chunkedSegmentStorage.isStorageSystemSegment(segmentMetadata);\n+\n+                                    // Check if this is a first write after ownership changed.\n+                                    isFirstWriteAfterFailover = segmentMetadata.isOwnershipChanged();\n+\n+                                    lastChunkMetadata = null;\n+                                    chunkHandle = null;\n+                                    bytesRemaining = length;\n+                                    currentOffset = offset;\n+\n+                                    // Get the last chunk segmentMetadata for the segment.\n+\n+                                    return getLastChunk(txn)\n+                                            .thenComposeAsync(v ->", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1Mjg1OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752858", "bodyText": "mine too \ud83d\udc4d", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:50:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5NzMyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\nindex 04901c3ae4..1393c4314b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n\n@@ -671,1201 +681,27 @@ public class ChunkedSegmentStorage implements Storage {\n                     }, executor);\n     }\n \n-    private void checkSegmentExists(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+    final void checkSegmentExists(String streamSegmentName, SegmentMetadata segmentMetadata) {\n         if (null == segmentMetadata || !segmentMetadata.isActive()) {\n             throw new CompletionException(new StreamSegmentNotExistsException(streamSegmentName));\n         }\n     }\n \n-    private void checkOwnership(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+    final void checkOwnership(String streamSegmentName, SegmentMetadata segmentMetadata) {\n         if (segmentMetadata.getOwnerEpoch() > this.epoch) {\n             throw new CompletionException(new StorageNotPrimaryException(streamSegmentName));\n         }\n     }\n \n-    private void checkNotSealed(String streamSegmentName, SegmentMetadata segmentMetadata) {\n+    final void checkNotSealed(String streamSegmentName, SegmentMetadata segmentMetadata) {\n         if (segmentMetadata.isSealed()) {\n             throw new CompletionException(new StreamSegmentSealedException(streamSegmentName));\n         }\n     }\n \n-    private void checkInitialized() {\n+    final private void checkInitialized() {\n         Preconditions.checkState(null != this.metadataStore);\n         Preconditions.checkState(0 != this.epoch);\n         Preconditions.checkState(!closed.get());\n     }\n-\n-    private class ChunkIterator {\n-        private final MetadataTransaction txn;\n-        private String currentChunkName;\n-        private ChunkMetadata currentMetadata;\n-\n-        ChunkIterator(MetadataTransaction txn, SegmentMetadata segmentMetadata) {\n-            this.txn = txn;\n-            currentChunkName = segmentMetadata.getFirstChunk();\n-        }\n-\n-        public CompletableFuture<Void> forEach(BiConsumer<ChunkMetadata, String> consumer) {\n-            return Futures.loop(\n-                    () -> currentChunkName != null,\n-                    () -> txn.get(currentChunkName)\n-                            .thenApplyAsync(storageMetadata -> {\n-                                currentMetadata = (ChunkMetadata) storageMetadata;\n-                                consumer.accept(currentMetadata, currentChunkName);\n-                                // Move next\n-                                currentChunkName = currentMetadata.getNextChunk();\n-                                return null;\n-                            }, executor),\n-                    executor);\n-        }\n-    }\n-\n-    private static class TruncateOperation implements Callable<CompletableFuture<Void>> {\n-        private final SegmentHandle handle;\n-        private final long offset;\n-        private final ChunkedSegmentStorage chunkedSegmentStorage;\n-\n-        private String currentChunkName;\n-        private ChunkMetadata currentMetadata;\n-        private long oldLength;\n-        private long startOffset;\n-        private ArrayList<String> chunksToDelete = new ArrayList<>();\n-        private SegmentMetadata segmentMetadata;\n-        private String streamSegmentName;\n-\n-        private boolean isLoopExited;\n-        private long traceId;\n-        private Timer timer;\n-\n-        TruncateOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle handle, long offset) {\n-            this.handle = handle;\n-            this.offset = offset;\n-            this.chunkedSegmentStorage = chunkedSegmentStorage;\n-        }\n-\n-        public CompletableFuture<Void> call() {\n-            traceId = LoggerHelpers.traceEnter(log, \"truncate\", handle, offset);\n-            timer = new Timer();\n-\n-            checkPreconditions();\n-\n-            streamSegmentName = handle.getSegmentName();\n-            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(streamSegmentName), txn ->\n-                    txn.get(streamSegmentName)\n-                            .thenComposeAsync(storageMetadata -> {\n-                                segmentMetadata = (SegmentMetadata) storageMetadata;\n-                                // Check preconditions\n-                                checkPreconditions(streamSegmentName, segmentMetadata);\n-\n-                                if (segmentMetadata.getStartOffset() == offset) {\n-                                    // Nothing to do\n-                                    return CompletableFuture.completedFuture(null);\n-                                }\n-\n-                                return updateFirstChunk(txn)\n-                                        .thenComposeAsync(v -> {\n-                                            deleteChunks(txn);\n-\n-                                            txn.update(segmentMetadata);\n-\n-                                            // Check invariants.\n-                                            Preconditions.checkState(segmentMetadata.getLength() == oldLength, \"truncate should not change segment length\");\n-                                            segmentMetadata.checkInvariants();\n-\n-                                            // Finally commit.\n-                                            return commit(txn)\n-                                                    .handleAsync(this::handleException, chunkedSegmentStorage.executor)\n-                                                    .thenComposeAsync(vv ->\n-                                                                    chunkedSegmentStorage.collectGarbage(chunksToDelete).thenApplyAsync(vvv -> {\n-                                                                        postCommit();\n-                                                                        return null;\n-                                                                    }, chunkedSegmentStorage.executor),\n-                                                            chunkedSegmentStorage.executor);\n-                                        }, chunkedSegmentStorage.executor);\n-                            }, chunkedSegmentStorage.executor), chunkedSegmentStorage.executor);\n-        }\n-\n-        private void postCommit() {\n-            // Update the read index by removing all entries below truncate offset.\n-            chunkedSegmentStorage.readIndexCache.truncateReadIndex(streamSegmentName, segmentMetadata.getStartOffset());\n-\n-            logEnd();\n-        }\n-\n-        private void logEnd() {\n-            Duration elapsed = timer.getElapsed();\n-            log.debug(\"{} truncate - segment={}, offset={}, latency={}.\", chunkedSegmentStorage.logPrefix, handle.getSegmentName(), offset, elapsed.toMillis());\n-            LoggerHelpers.traceLeave(log, \"truncate\", traceId, handle, offset);\n-        }\n-\n-        private Void handleException(Void value, Throwable e) {\n-            if (null != e) {\n-                val ex = Exceptions.unwrap(e);\n-                if (ex instanceof StorageMetadataWritesFencedOutException) {\n-                    throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n-                }\n-                throw new CompletionException(ex);\n-            }\n-            return value;\n-        }\n-\n-        private CompletableFuture<Void> commit(MetadataTransaction txn) {\n-            // Commit system logs.\n-            if (chunkedSegmentStorage.isStorageSystemSegment(segmentMetadata)) {\n-                val finalStartOffset = startOffset;\n-                txn.setExternalCommitStep(() -> {\n-                    chunkedSegmentStorage.systemJournal.commitRecord(\n-                            SystemJournal.TruncationRecord.builder()\n-                                    .segmentName(streamSegmentName)\n-                                    .offset(offset)\n-                                    .firstChunkName(segmentMetadata.getFirstChunk())\n-                                    .startOffset(finalStartOffset)\n-                                    .build());\n-                    return null;\n-                });\n-            }\n-\n-            // Finally commit.\n-            return txn.commit();\n-        }\n-\n-        private CompletableFuture<Void> updateFirstChunk(MetadataTransaction txn) {\n-            currentChunkName = segmentMetadata.getFirstChunk();\n-            oldLength = segmentMetadata.getLength();\n-            startOffset = segmentMetadata.getFirstChunkStartOffset();\n-            return Futures.loop(\n-                    () -> currentChunkName != null && !isLoopExited,\n-                    () -> txn.get(currentChunkName)\n-                            .thenApplyAsync(storageMetadata -> {\n-                                currentMetadata = (ChunkMetadata) storageMetadata;\n-                                Preconditions.checkState(null != currentMetadata, \"currentMetadata is null.\");\n-\n-                                // If for given chunk start <= offset < end  then we have found the chunk that will be the first chunk.\n-                                if ((startOffset <= offset) && (startOffset + currentMetadata.getLength() > offset)) {\n-                                    isLoopExited = true;\n-                                    return null;\n-                                }\n-\n-                                startOffset += currentMetadata.getLength();\n-                                chunksToDelete.add(currentMetadata.getName());\n-                                segmentMetadata.decrementChunkCount();\n-\n-                                // move to next chunk\n-                                currentChunkName = currentMetadata.getNextChunk();\n-                                return null;\n-                            }, chunkedSegmentStorage.executor),\n-                    chunkedSegmentStorage.executor\n-            ).thenApplyAsync(v -> {\n-                segmentMetadata.setFirstChunk(currentChunkName);\n-                segmentMetadata.setStartOffset(offset);\n-                segmentMetadata.setFirstChunkStartOffset(startOffset);\n-                return null;\n-            }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private void deleteChunks(MetadataTransaction txn) {\n-            for (String toDelete : chunksToDelete) {\n-                txn.delete(toDelete);\n-                // Adjust last chunk if required.\n-                if (toDelete.equals(segmentMetadata.getLastChunk())) {\n-                    segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength());\n-                    segmentMetadata.setLastChunk(null);\n-                }\n-            }\n-        }\n-\n-        private void checkPreconditions(String streamSegmentName, SegmentMetadata segmentMetadata) {\n-            chunkedSegmentStorage.checkSegmentExists(streamSegmentName, segmentMetadata);\n-            chunkedSegmentStorage.checkNotSealed(streamSegmentName, segmentMetadata);\n-            chunkedSegmentStorage.checkOwnership(streamSegmentName, segmentMetadata);\n-\n-            if (segmentMetadata.getLength() < offset || segmentMetadata.getStartOffset() > offset) {\n-                throw new IllegalArgumentException(String.format(\"offset %d is outside of valid range [%d, %d) for segment %s\",\n-                        offset, segmentMetadata.getStartOffset(), segmentMetadata.getLength(), streamSegmentName));\n-            }\n-        }\n-\n-        private void checkPreconditions() {\n-            Preconditions.checkArgument(null != handle, \"handle\");\n-            Preconditions.checkArgument(!handle.isReadOnly(), \"handle\");\n-            Preconditions.checkArgument(offset >= 0, \"offset\");\n-        }\n-    }\n-\n-    private static class ReadOperation implements Callable<CompletableFuture<Integer>> {\n-        private final SegmentHandle handle;\n-        private final long offset;\n-        private final byte[] buffer;\n-        private final int bufferOffset;\n-        private final int length;\n-        private final ChunkedSegmentStorage chunkedSegmentStorage;\n-        private long traceId;\n-        private Timer timer;\n-        private String streamSegmentName;\n-        private SegmentMetadata segmentMetadata;\n-        private int bytesRemaining;\n-        private int currentBufferOffset;\n-        private long currentOffset;\n-        private int totalBytesRead = 0;\n-        private long startOffsetForCurrentChunk;\n-        private String currentChunkName;\n-        private ChunkMetadata chunkToReadFrom = null;\n-        private boolean isLoopExited;\n-        private int cntScanned = 0;\n-        private int bytesToRead;\n-\n-        ReadOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle handle, long offset, byte[] buffer, int bufferOffset, int length) {\n-            this.handle = handle;\n-            this.offset = offset;\n-            this.buffer = buffer;\n-            this.bufferOffset = bufferOffset;\n-            this.length = length;\n-            this.chunkedSegmentStorage = chunkedSegmentStorage;\n-        }\n-\n-        public CompletableFuture<Integer> call() {\n-            traceId = LoggerHelpers.traceEnter(log, \"read\", handle, offset, length);\n-            timer = new Timer();\n-\n-            // Validate preconditions.\n-            checkPreconditions();\n-            streamSegmentName = handle.getSegmentName();\n-            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(streamSegmentName),\n-                    txn -> txn.get(streamSegmentName)\n-                            .thenComposeAsync(storageMetadata -> {\n-                                segmentMetadata = (SegmentMetadata) storageMetadata;\n-\n-                                // Validate preconditions.\n-                                checkState();\n-\n-                                if (length == 0) {\n-                                    return CompletableFuture.completedFuture(0);\n-                                }\n-\n-                                return findChunkForOffset(txn)\n-                                        .thenComposeAsync(v -> {\n-                                            // Now read.\n-                                            return readData(txn);\n-                                        }, chunkedSegmentStorage.executor)\n-                                        .thenApplyAsync(v -> {\n-                                            logEnd();\n-                                            return totalBytesRead;\n-                                        }, chunkedSegmentStorage.executor);\n-                            }, chunkedSegmentStorage.executor),\n-                    chunkedSegmentStorage.executor);\n-        }\n-\n-        private void logEnd() {\n-            Duration elapsed = timer.getElapsed();\n-            log.debug(\"{} read - segment={}, offset={}, bytesRead={}, latency={}.\", chunkedSegmentStorage.logPrefix, handle.getSegmentName(), offset, totalBytesRead, elapsed.toMillis());\n-            LoggerHelpers.traceLeave(log, \"read\", traceId, handle, offset, totalBytesRead);\n-        }\n-\n-        private CompletableFuture<Void> readData(MetadataTransaction txn) {\n-            return Futures.loop(\n-                    () -> bytesRemaining > 0 && null != currentChunkName,\n-                    () -> {\n-                        bytesToRead = Math.min(bytesRemaining, Math.toIntExact(chunkToReadFrom.getLength() - (currentOffset - startOffsetForCurrentChunk)));\n-                        if (currentOffset >= startOffsetForCurrentChunk + chunkToReadFrom.getLength()) {\n-                            // The current chunk is over. Move to the next one.\n-                            currentChunkName = chunkToReadFrom.getNextChunk();\n-                            if (null != currentChunkName) {\n-                                startOffsetForCurrentChunk += chunkToReadFrom.getLength();\n-                                return txn.get(currentChunkName)\n-                                        .thenApplyAsync(storageMetadata -> {\n-                                            chunkToReadFrom = (ChunkMetadata) storageMetadata;\n-                                            log.debug(\"{} read - reading from next chunk - segment={}, chunk={}\", chunkedSegmentStorage.logPrefix, streamSegmentName, chunkToReadFrom);\n-                                            return null;\n-                                        }, chunkedSegmentStorage.executor);\n-                            }\n-                        } else {\n-                            Preconditions.checkState(bytesToRead != 0, \"bytesToRead is 0\");\n-                            // Read data from the chunk.\n-                            return chunkedSegmentStorage.chunkStorage.openRead(chunkToReadFrom.getName())\n-                                    .thenComposeAsync(chunkHandle ->\n-                                            chunkedSegmentStorage.chunkStorage.read(chunkHandle,\n-                                                    currentOffset - startOffsetForCurrentChunk,\n-                                                    bytesToRead,\n-                                                    buffer,\n-                                                    currentBufferOffset)\n-                                                    .thenApplyAsync(bytesRead -> {\n-                                                        bytesRemaining -= bytesRead;\n-                                                        currentOffset += bytesRead;\n-                                                        currentBufferOffset += bytesRead;\n-                                                        totalBytesRead += bytesRead;\n-                                                        return null;\n-                                                    }, chunkedSegmentStorage.executor), chunkedSegmentStorage.executor);\n-                        }\n-                        return CompletableFuture.completedFuture(null);\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private CompletableFuture<Void> findChunkForOffset(MetadataTransaction txn) {\n-\n-            currentChunkName = segmentMetadata.getFirstChunk();\n-            chunkToReadFrom = null;\n-\n-            Preconditions.checkState(null != currentChunkName);\n-\n-            bytesRemaining = length;\n-            currentBufferOffset = bufferOffset;\n-            currentOffset = offset;\n-            totalBytesRead = 0;\n-\n-            // Find the first chunk that contains the data.\n-            startOffsetForCurrentChunk = segmentMetadata.getFirstChunkStartOffset();\n-            Timer timer1 = new Timer();\n-            // Find the name of the chunk in the cached read index that is floor to required offset.\n-            val floorEntry = chunkedSegmentStorage.readIndexCache.findFloor(streamSegmentName, offset);\n-            if (null != floorEntry) {\n-                startOffsetForCurrentChunk = floorEntry.getOffset();\n-                currentChunkName = floorEntry.getChunkName();\n-            }\n-\n-            // Navigate to the chunk that contains the first byte of requested data.\n-            return Futures.loop(\n-                    () -> currentChunkName != null && !isLoopExited,\n-                    () -> txn.get(currentChunkName)\n-                            .thenApplyAsync(storageMetadata -> {\n-                                chunkToReadFrom = (ChunkMetadata) storageMetadata;\n-                                Preconditions.checkState(null != chunkToReadFrom, \"chunkToReadFrom is null\");\n-                                if (startOffsetForCurrentChunk <= currentOffset\n-                                        && startOffsetForCurrentChunk + chunkToReadFrom.getLength() > currentOffset) {\n-                                    // we have found a chunk that contains first byte we want to read\n-                                    log.debug(\"{} read - found chunk to read - segment={}, chunk={}, startOffset={}, length={}, readOffset={}.\",\n-                                            chunkedSegmentStorage.logPrefix, streamSegmentName, chunkToReadFrom, startOffsetForCurrentChunk, chunkToReadFrom.getLength(), currentOffset);\n-                                    isLoopExited = true;\n-                                    return null;\n-                                }\n-                                currentChunkName = chunkToReadFrom.getNextChunk();\n-                                startOffsetForCurrentChunk += chunkToReadFrom.getLength();\n-\n-                                // Update read index with newly visited chunk.\n-                                if (null != currentChunkName) {\n-                                    chunkedSegmentStorage.readIndexCache.addIndexEntry(streamSegmentName, currentChunkName, startOffsetForCurrentChunk);\n-                                }\n-                                cntScanned++;\n-                                return null;\n-                            }, chunkedSegmentStorage.executor)\n-                            .thenApplyAsync(v -> {\n-                                log.debug(\"{} read - chunk lookup - segment={}, offset={}, scanned={}, latency={}.\",\n-                                    chunkedSegmentStorage.logPrefix, handle.getSegmentName(), offset, cntScanned, timer1.getElapsed().toMillis());\n-                                return null;\n-                            }, chunkedSegmentStorage.executor),\n-                    chunkedSegmentStorage.executor);\n-        }\n-\n-        private void checkState() {\n-            chunkedSegmentStorage.checkSegmentExists(streamSegmentName, segmentMetadata);\n-\n-            segmentMetadata.checkInvariants();\n-\n-            Preconditions.checkArgument(offset < segmentMetadata.getLength(), \"Offset %s is beyond the last offset %s of the segment %s.\",\n-                    offset, segmentMetadata.getLength(), streamSegmentName);\n-\n-            if (offset < segmentMetadata.getStartOffset()) {\n-                throw new CompletionException(new StreamSegmentTruncatedException(streamSegmentName, segmentMetadata.getStartOffset(), offset));\n-            }\n-        }\n-\n-        private void checkPreconditions() {\n-            Preconditions.checkNotNull(handle, \"handle\");\n-            Preconditions.checkNotNull(buffer, \"buffer\");\n-            Preconditions.checkNotNull(handle.getSegmentName(), \"streamSegmentName\");\n-\n-            Exceptions.checkArrayRange(bufferOffset, length, buffer.length, \"bufferOffset\", \"length\");\n-\n-            if (offset < 0 || bufferOffset < 0 || length < 0 || buffer.length < bufferOffset + length) {\n-                throw new ArrayIndexOutOfBoundsException(String.format(\n-                        \"Offset (%s) must be non-negative, and bufferOffset (%s) and length (%s) must be valid indices into buffer of size %s.\",\n-                        offset, bufferOffset, length, buffer.length));\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Implements the write operation.\n-     */\n-    private static class WriteOperation implements Callable<CompletableFuture<Void>> {\n-        private final SegmentHandle handle;\n-        private final long offset;\n-        private final InputStream data;\n-        private final int length;\n-        private final ChunkedSegmentStorage chunkedSegmentStorage;\n-\n-        private final ArrayList<SystemJournal.SystemJournalRecord> systemLogRecords = new ArrayList<>();\n-        private final List<ChunkNameOffsetPair> newReadIndexEntries = new ArrayList<>();\n-        private int chunksAddedCount = 0;\n-        private boolean isCommited = false;\n-\n-        private long traceId;\n-        private Timer timer;\n-\n-        private String streamSegmentName;\n-        private SegmentMetadata segmentMetadata;\n-\n-        private boolean isSystemSegment;\n-\n-        // Check if this is a first write after ownership changed.\n-        private boolean isFirstWriteAfterFailover;\n-\n-        private ChunkMetadata lastChunkMetadata = null;\n-        private ChunkHandle chunkHandle = null;\n-        private int bytesRemaining;\n-        private long currentOffset;\n-\n-        private boolean didSegmentLayoutChange = false;\n-\n-        WriteOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle handle, long offset, InputStream data, int length) {\n-            this.handle = handle;\n-            this.offset = offset;\n-            this.data = data;\n-            this.length = length;\n-            this.chunkedSegmentStorage = chunkedSegmentStorage;\n-        }\n-\n-        public CompletableFuture<Void> call() {\n-            traceId = LoggerHelpers.traceEnter(log, \"write\", handle, offset, length);\n-            timer = new Timer();\n-\n-            // Validate preconditions.\n-            checkPreconditions();\n-\n-            streamSegmentName = handle.getSegmentName();\n-            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(handle.getSegmentName()),\n-                    txn -> {\n-                        didSegmentLayoutChange = false;\n-\n-                        // Retrieve metadata.\n-                        return txn.get(streamSegmentName)\n-                                .thenComposeAsync(storageMetadata -> {\n-                                    segmentMetadata = (SegmentMetadata) storageMetadata;\n-                                    // Validate preconditions.\n-                                    checkState();\n-\n-                                    isSystemSegment = chunkedSegmentStorage.isStorageSystemSegment(segmentMetadata);\n-\n-                                    // Check if this is a first write after ownership changed.\n-                                    isFirstWriteAfterFailover = segmentMetadata.isOwnershipChanged();\n-\n-                                    lastChunkMetadata = null;\n-                                    chunkHandle = null;\n-                                    bytesRemaining = length;\n-                                    currentOffset = offset;\n-\n-                                    // Get the last chunk segmentMetadata for the segment.\n-\n-                                    return getLastChunk(txn)\n-                                            .thenComposeAsync(v ->\n-                                                            writeData(txn)\n-                                                                    .thenComposeAsync(vv ->\n-                                                                                    commit(txn)\n-                                                                                            .thenApplyAsync(vvvv ->\n-                                                                                                    postCommit(), chunkedSegmentStorage.executor)\n-                                                                                            .exceptionally(this::handleException),\n-                                                                            chunkedSegmentStorage.executor)\n-                                                                    .whenCompleteAsync((value, e) -> collectGarbage(), chunkedSegmentStorage.executor)\n-                                                                    .thenApplyAsync(vvv -> {\n-                                                                        logEnd();\n-                                                                        return null;\n-                                                                    }, chunkedSegmentStorage.executor),\n-                                                    chunkedSegmentStorage.executor);\n-                                }, chunkedSegmentStorage.executor);\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private Object handleException(Throwable e) {\n-            val ex = Exceptions.unwrap(e);\n-            if (ex instanceof StorageMetadataWritesFencedOutException) {\n-                throw new CompletionException(new StorageNotPrimaryException(streamSegmentName, ex));\n-            }\n-            throw new CompletionException(ex);\n-        }\n-\n-        private Object postCommit() {\n-            // Post commit actions.\n-            // Update the read index.\n-            chunkedSegmentStorage.readIndexCache.addIndexEntries(streamSegmentName, newReadIndexEntries);\n-            return null;\n-        }\n-\n-        private CompletableFuture<Void> getLastChunk(MetadataTransaction txn) {\n-            CompletableFuture<Void> f = CompletableFuture.completedFuture(null);\n-            if (null != segmentMetadata.getLastChunk()) {\n-                f = txn.get(segmentMetadata.getLastChunk())\n-                        .thenApplyAsync(storageMetadata1 -> {\n-                            lastChunkMetadata = (ChunkMetadata) storageMetadata1;\n-                            return null;\n-                        }, chunkedSegmentStorage.executor);\n-            }\n-            return f;\n-        }\n-\n-        private void logEnd() {\n-            Duration elapsed = timer.getElapsed();\n-            log.debug(\"{} write - segment={}, offset={}, length={}, latency={}.\", chunkedSegmentStorage.logPrefix, handle.getSegmentName(), offset, length, elapsed.toMillis());\n-            LoggerHelpers.traceLeave(log, \"write\", traceId, handle, offset);\n-        }\n-\n-        private void collectGarbage() {\n-            if (!isCommited && chunksAddedCount > 0) {\n-                // Collect garbage.\n-                chunkedSegmentStorage.collectGarbage(newReadIndexEntries.stream().map(ChunkNameOffsetPair::getChunkName).collect(Collectors.toList()));\n-            }\n-        }\n-\n-        private CompletableFuture<Void> commit(MetadataTransaction txn) {\n-            // commit all system log records if required.\n-            if (isSystemSegment && chunksAddedCount > 0) {\n-                // commit all system log records.\n-                Preconditions.checkState(chunksAddedCount == systemLogRecords.size());\n-                txn.setExternalCommitStep(() -> {\n-                    chunkedSegmentStorage.systemJournal.commitRecords(systemLogRecords);\n-                    return null;\n-                });\n-            }\n-\n-            // if layout did not change then commit with lazyWrite.\n-            return txn.commit(!didSegmentLayoutChange &&  chunkedSegmentStorage.config.isLazyCommitEnabled())\n-                    .thenApplyAsync(v -> {\n-                        isCommited = true;\n-                        return null;\n-                    }, chunkedSegmentStorage.executor);\n-\n-        }\n-\n-        private CompletableFuture<Void> writeData(MetadataTransaction txn) {\n-            return Futures.loop(\n-                    () -> bytesRemaining > 0,\n-                    () -> {\n-                        // Check if new chunk needs to be added.\n-                        // This could be either because there are no existing chunks or last chunk has reached max rolling length.\n-                        return openChunkToWrite(txn)\n-                                .thenComposeAsync(v -> {\n-                                    // Calculate the data that needs to be written.\n-                                    long offsetToWriteAt = currentOffset - segmentMetadata.getLastChunkStartOffset();\n-                                    int writeSize = (int) Math.min(bytesRemaining, segmentMetadata.getMaxRollinglength() - offsetToWriteAt);\n-\n-                                    // Write data to last chunk.\n-                                    return writeToChunk(txn,\n-                                            segmentMetadata,\n-                                            data,\n-                                            chunkHandle,\n-                                            lastChunkMetadata,\n-                                            offsetToWriteAt,\n-                                            writeSize)\n-                                            .thenApplyAsync(bytesWritten -> {\n-                                                // Update the counts\n-                                                bytesRemaining -= bytesWritten;\n-                                                currentOffset += bytesWritten;\n-                                                return null;\n-                                            }, chunkedSegmentStorage.executor);\n-                                }, chunkedSegmentStorage.executor);\n-                    }, chunkedSegmentStorage.executor)\n-                    .thenApplyAsync(v -> {\n-                        // Check invariants.\n-                        segmentMetadata.checkInvariants();\n-                        return null;\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private CompletableFuture<Void> openChunkToWrite(MetadataTransaction txn) {\n-            if (null == lastChunkMetadata\n-                    || (lastChunkMetadata.getLength() >= segmentMetadata.getMaxRollinglength())\n-                    || isFirstWriteAfterFailover\n-                    || !chunkedSegmentStorage.shouldAppend()) {\n-                return addNewChunk(txn);\n-\n-            } else {\n-                // No new chunk needed just write data to existing chunk.\n-                return chunkedSegmentStorage.chunkStorage.openWrite(lastChunkMetadata.getName())\n-                        .thenApplyAsync(h -> {\n-                            chunkHandle = h;\n-                            return null;\n-                        }, chunkedSegmentStorage.executor);\n-            }\n-        }\n-\n-        private CompletableFuture<Void> addNewChunk(MetadataTransaction txn) {\n-            // Create new chunk\n-            String newChunkName = getNewChunkName(streamSegmentName,\n-                    segmentMetadata.getLength());\n-            return chunkedSegmentStorage.chunkStorage.create(newChunkName)\n-                    .thenApplyAsync(h -> {\n-                        chunkHandle = h;\n-                        String previousLastChunkName = lastChunkMetadata == null ? null : lastChunkMetadata.getName();\n-\n-                        // update first and last chunks.\n-                        lastChunkMetadata = updateMetadataForChunkAddition(txn,\n-                                segmentMetadata,\n-                                newChunkName,\n-                                isFirstWriteAfterFailover,\n-                                lastChunkMetadata);\n-\n-                        // Record the creation of new chunk.\n-                        if (isSystemSegment) {\n-                            addSystemLogRecord(systemLogRecords,\n-                                    streamSegmentName,\n-                                    segmentMetadata.getLength(),\n-                                    previousLastChunkName,\n-                                    newChunkName);\n-                            txn.markPinned(lastChunkMetadata);\n-                        }\n-                        // Update read index.\n-                        newReadIndexEntries.add(new ChunkNameOffsetPair(segmentMetadata.getLength(), newChunkName));\n-\n-                        isFirstWriteAfterFailover = false;\n-                        didSegmentLayoutChange = true;\n-                        chunksAddedCount++;\n-\n-                        log.debug(\"{} write - New chunk added - segment={}, chunk={}, offset={}.\",\n-                                chunkedSegmentStorage.logPrefix, streamSegmentName, newChunkName, segmentMetadata.getLength());\n-                        return null;\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private void checkState() {\n-            chunkedSegmentStorage.checkSegmentExists(streamSegmentName, segmentMetadata);\n-            segmentMetadata.checkInvariants();\n-            chunkedSegmentStorage.checkNotSealed(streamSegmentName, segmentMetadata);\n-            chunkedSegmentStorage.checkOwnership(streamSegmentName, segmentMetadata);\n-\n-            // Validate that offset is correct.\n-            if ((segmentMetadata.getLength()) != offset) {\n-                throw new CompletionException(new BadOffsetException(streamSegmentName, segmentMetadata.getLength(), offset));\n-            }\n-        }\n-\n-        private void checkPreconditions() {\n-            Preconditions.checkArgument(null != handle, \"handle\");\n-            Preconditions.checkArgument(null != data, \"data\");\n-            Preconditions.checkArgument(null != handle.getSegmentName(), \"streamSegmentName\");\n-            Preconditions.checkArgument(!handle.isReadOnly(), \"handle\");\n-            Preconditions.checkArgument(offset >= 0, \"offset\");\n-            Preconditions.checkArgument(length >= 0, \"length\");\n-        }\n-\n-        private String getNewChunkName(String segmentName, long offset) {\n-            return NameUtils.getSegmentChunkName(segmentName, chunkedSegmentStorage.epoch, offset);\n-        }\n-\n-        /**\n-         * Updates the segment metadata for the newly added chunk.\n-         */\n-        private ChunkMetadata updateMetadataForChunkAddition(MetadataTransaction txn,\n-                                                             SegmentMetadata segmentMetadata,\n-                                                             String newChunkName,\n-                                                             boolean isFirstWriteAfterFailover,\n-                                                             ChunkMetadata lastChunkMetadata) {\n-            ChunkMetadata newChunkMetadata = ChunkMetadata.builder()\n-                    .name(newChunkName)\n-                    .build();\n-            segmentMetadata.setLastChunk(newChunkName);\n-            if (lastChunkMetadata == null) {\n-                segmentMetadata.setFirstChunk(newChunkName);\n-            } else {\n-                lastChunkMetadata.setNextChunk(newChunkName);\n-                txn.update(lastChunkMetadata);\n-            }\n-            segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength());\n-\n-            // Reset ownershipChanged flag after first write is done.\n-            if (isFirstWriteAfterFailover) {\n-                segmentMetadata.setOwnerEpoch(chunkedSegmentStorage.epoch);\n-                segmentMetadata.setOwnershipChanged(false);\n-                log.debug(\"{} write - First write after failover - segment={}.\", chunkedSegmentStorage.logPrefix, segmentMetadata.getName());\n-            }\n-            segmentMetadata.incrementChunkCount();\n-\n-            // Update the transaction.\n-            txn.update(newChunkMetadata);\n-            txn.update(segmentMetadata);\n-            return newChunkMetadata;\n-        }\n-\n-        /**\n-         * Adds a system log.\n-         *\n-         * @param systemLogRecords  List of system records.\n-         * @param streamSegmentName Name of the segment.\n-         * @param offset            Offset at which new chunk was added.\n-         * @param oldChunkName      Name of the previous last chunk.\n-         * @param newChunkName      Name of the new last chunk.\n-         */\n-        private void addSystemLogRecord(ArrayList<SystemJournal.SystemJournalRecord> systemLogRecords, String streamSegmentName, long offset, String oldChunkName, String newChunkName) {\n-            systemLogRecords.add(\n-                    SystemJournal.ChunkAddedRecord.builder()\n-                            .segmentName(streamSegmentName)\n-                            .offset(offset)\n-                            .oldChunkName(oldChunkName)\n-                            .newChunkName(newChunkName)\n-                            .build());\n-        }\n-\n-        /**\n-         * Write to chunk.\n-         */\n-        private CompletableFuture<Integer> writeToChunk(MetadataTransaction txn,\n-                                                        SegmentMetadata segmentMetadata,\n-                                                        InputStream data,\n-                                                        ChunkHandle chunkHandle,\n-                                                        ChunkMetadata chunkWrittenMetadata,\n-                                                        long offsetToWriteAt,\n-                                                        int bytesCount) {\n-            Preconditions.checkState(0 != bytesCount, \"Attempt to write zero bytes\");\n-            // Finally write the data.\n-            BoundedInputStream bis = new BoundedInputStream(data, bytesCount);\n-            return chunkedSegmentStorage.chunkStorage.write(chunkHandle, offsetToWriteAt, bytesCount, bis)\n-                    .thenApplyAsync(bytesWritten -> {\n-                        // Update the metadata for segment and chunk.\n-                        Preconditions.checkState(bytesWritten >= 0);\n-                        segmentMetadata.setLength(segmentMetadata.getLength() + bytesWritten);\n-                        chunkWrittenMetadata.setLength(chunkWrittenMetadata.getLength() + bytesWritten);\n-                        txn.update(chunkWrittenMetadata);\n-                        txn.update(segmentMetadata);\n-                        return bytesWritten;\n-                    }, chunkedSegmentStorage.executor)\n-                    .exceptionally(e -> {\n-                        val ex = Exceptions.unwrap(e);\n-                        if (ex instanceof InvalidOffsetException) {\n-                            throw new CompletionException(new BadOffsetException(segmentMetadata.getName(),\n-                                    ((InvalidOffsetException) ex).getExpectedOffset(),\n-                                    ((InvalidOffsetException) ex).getGivenOffset()));\n-                        }\n-                        if (ex instanceof ChunkStorageException) {\n-                            throw new CompletionException(ex);\n-                        }\n-\n-                        throw new CompletionException(ex);\n-                    });\n-        }\n-    }\n-\n-    /**\n-     * Defragments the list of chunks for a given segment.\n-     * It finds eligible consecutive chunks that can be merged together.\n-     * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n-     * Conceptually this is like deleting nodes from middle of the list of chunks.\n-     *\n-     * <Ul>\n-     * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n-     * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n-     * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n-     * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n-     * each write becomes a separate chunk.\n-     * </li>\n-     * <li>\n-     * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n-     * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n-     * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n-     * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n-     * whereas NFS has no concept of merging natively.\n-     *\n-     * As chunks become larger, append writes (read source completely and append it back at the end of target)\n-     * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n-     * when available, and if not available, then we use appends.\n-     * </li>\n-     * <li>\n-     * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n-     * We can then fine tune that background task to run optimally with low overhead.\n-     * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n-     * </li>\n-     * <li>\n-     * <li>\n-     * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n-     * </li>\n-     * </ul>\n-     *\n-     * What controls whether we invoke concat or simulate through appends?\n-     * There are a few different capabilities that ChunkStorage needs to provide.\n-     * <ul>\n-     * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.\n-     * This is indicated by supportsAppend.</li>\n-     * <li>Does ChunkStorage support for concatenating chunks ? This is indicated by supportsConcat.\n-     * If this is true then concat operation will be invoked otherwise chunks will be appended.</li>\n-     * <li>There are some obvious constraints - For ChunkStorage support any concat functionality it must support either\n-     * append or concat.</li>\n-     * <li>Also when ChunkStorage supports both concat and append, ChunkedSegmentStorage will invoke appropriate method\n-     * depending on size of target and source chunks. (Eg. ECS)</li>\n-     * </ul>\n-     *\n-     * <li>\n-     * What controls defrag?\n-     * There are two additional parameters that control when concat\n-     * <li>minSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered a small object.\n-     * For small source objects, append is used instead of using concat. (For really small txn it is rather efficient to use append than MPU).</li>\n-     * <li>maxSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered for concat. (Eg S3 might have max limit on chunk size).</li>\n-     * In short there is a size beyond which using append is not advisable. Conversely there is a size below which concat is not efficient.(minSizeLimitForConcat )\n-     * Then there is limit which concating does not make sense maxSizeLimitForConcat\n-     * </li>\n-     * <li>\n-     * What is the defrag algorithm\n-     * <pre>\n-     * While(segment.hasConcatableChunks()){\n-     *     Set<List<Chunk>> s = FindConsecutiveConcatableChunks();\n-     *     For (List<chunk> list : s){\n-     *        ConcatChunks (list);\n-     *     }\n-     * }\n-     * </pre>\n-     * </li>\n-     * </ul>\n-     */\n-    private static class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n-        private final MetadataTransaction txn;\n-        private final SegmentMetadata segmentMetadata;\n-        private final String startChunkName;\n-        private final String lastChunkName;\n-        private final ArrayList<String> chunksToDelete;\n-        private final ChunkedSegmentStorage chunkedSegmentStorage;\n-\n-        private ArrayList<ChunkInfo> chunksToConcat = new ArrayList<>();\n-\n-        private ChunkMetadata target;\n-        private String targetChunkName;\n-        private boolean useAppend;\n-        private long targetSizeAfterConcat;\n-        private String nextChunkName;\n-        private ChunkMetadata next = null;\n-\n-        private long writeAtOffset;\n-        private int readAtOffset = 0;\n-        private int bytesToRead;\n-        private int currentArgIndex;\n-\n-        DefragmentOperation(ChunkedSegmentStorage chunkedSegmentStorage, MetadataTransaction txn, SegmentMetadata segmentMetadata, String startChunkName, String lastChunkName, ArrayList<String> chunksToDelete) {\n-            this.txn = txn;\n-            this.segmentMetadata = segmentMetadata;\n-            this.startChunkName = startChunkName;\n-            this.lastChunkName = lastChunkName;\n-            this.chunksToDelete = chunksToDelete;\n-            this.chunkedSegmentStorage = chunkedSegmentStorage;\n-        }\n-\n-        public CompletableFuture<Void> call() {\n-            // The algorithm is actually very simple.\n-            // It tries to concat all small chunks using appends first.\n-            // Then it tries to concat remaining chunks using concat if available.\n-            // To implement it using single loop we toggle between concat with append and concat modes. (Instead of two passes.)\n-            useAppend = true;\n-            targetChunkName = startChunkName;\n-\n-            // Iterate through chunk list\n-            return Futures.loop(\n-                    () -> null != targetChunkName && !targetChunkName.equals(lastChunkName),\n-                    () -> gatherChunks()\n-                            .thenComposeAsync(v -> {\n-                                // Note - After above while loop is exited nextChunkName points to chunk next to last one to be concat.\n-                                // Which means target should now point to it as next after concat is complete.\n-\n-                                // If there are chunks that can be appended together then concat them.\n-                                CompletableFuture<Void> f;\n-                                if (chunksToConcat.size() > 1) {\n-                                    // Concat\n-                                    f = concatChunks();\n-                                } else {\n-                                    f = CompletableFuture.completedFuture(null);\n-                                }\n-                                return f.thenApplyAsync(vv -> {\n-                                    // Move on to next place in list where we can concat if we are done with append based concats.\n-                                    if (!useAppend) {\n-                                        targetChunkName = nextChunkName;\n-                                    }\n-                                    // Toggle\n-                                    useAppend = !useAppend;\n-                                    return null;\n-                                }, chunkedSegmentStorage.executor);\n-                            }, chunkedSegmentStorage.executor),\n-                    chunkedSegmentStorage.executor)\n-                    .thenApplyAsync(vv -> {\n-                        // Make sure no invariants are broken.\n-                        segmentMetadata.checkInvariants();\n-                        return null;\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private CompletableFuture<Void> concatChunks() {\n-            ConcatArgument[] concatArgs = new ConcatArgument[chunksToConcat.size()];\n-            for (int i = 0; i < chunksToConcat.size(); i++) {\n-                concatArgs[i] = ConcatArgument.fromChunkInfo(chunksToConcat.get(i));\n-            }\n-            CompletableFuture<Integer> f;\n-            if (!useAppend && chunkedSegmentStorage.chunkStorage.supportsConcat()) {\n-                f = chunkedSegmentStorage.chunkStorage.concat(concatArgs);\n-            } else {\n-                f = concatUsingAppend(concatArgs);\n-            }\n-\n-            return f.thenApplyAsync(v -> {\n-                // Delete chunks.\n-                for (int i = 1; i < chunksToConcat.size(); i++) {\n-                    chunksToDelete.add(chunksToConcat.get(i).getName());\n-                }\n-\n-                // Set the pointers\n-                target.setLength(targetSizeAfterConcat);\n-                target.setNextChunk(nextChunkName);\n-\n-                // If target is the last chunk after this then update metadata accordingly\n-                if (null == nextChunkName) {\n-                    segmentMetadata.setLastChunk(target.getName());\n-                    segmentMetadata.setLastChunkStartOffset(segmentMetadata.getLength() - target.getLength());\n-                }\n-\n-                // Update metadata for affected chunks.\n-                for (int i = 1; i < concatArgs.length; i++) {\n-                    txn.delete(concatArgs[i].getName());\n-                    segmentMetadata.decrementChunkCount();\n-                }\n-                txn.update(target);\n-                txn.update(segmentMetadata);\n-                return null;\n-            }, chunkedSegmentStorage.executor);\n-\n-        }\n-\n-        private CompletableFuture<Void> gatherChunks() {\n-            return txn.get(targetChunkName)\n-                    .thenComposeAsync(storageMetadata -> {\n-                        target = (ChunkMetadata) storageMetadata;\n-                        chunksToConcat = new ArrayList<>();\n-                        targetSizeAfterConcat = target.getLength();\n-\n-                        // Add target to the list of chunks\n-                        chunksToConcat.add(new ChunkInfo(targetSizeAfterConcat, targetChunkName));\n-\n-                        nextChunkName = target.getNextChunk();\n-                        return txn.get(nextChunkName)\n-                                .thenComposeAsync(storageMetadata1 -> {\n-\n-                                    next = (ChunkMetadata) storageMetadata1;\n-                                    // Gather list of chunks that can be appended together.\n-                                    return Futures.loop(\n-                                            () ->\n-                                                    null != nextChunkName\n-                                                            && !(useAppend && chunkedSegmentStorage.config.getMinSizeLimitForConcat() < next.getLength())\n-                                                            && !(targetSizeAfterConcat + next.getLength() > segmentMetadata.getMaxRollinglength() || next.getLength() > chunkedSegmentStorage.config.getMaxSizeLimitForConcat()),\n-                                            () -> txn.get(nextChunkName)\n-                                                    .thenApplyAsync(storageMetadata2 -> {\n-                                                        next = (ChunkMetadata) storageMetadata2;\n-                                                        chunksToConcat.add(new ChunkInfo(next.getLength(), nextChunkName));\n-                                                        targetSizeAfterConcat += next.getLength();\n-\n-                                                        nextChunkName = next.getNextChunk();\n-                                                        return null;\n-                                                    }, chunkedSegmentStorage.executor),\n-                                            chunkedSegmentStorage.executor);\n-\n-                                }, chunkedSegmentStorage.executor);\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private CompletableFuture<Integer> concatUsingAppend(ConcatArgument[] concatArgs) {\n-            writeAtOffset = concatArgs[0].getLength();\n-            val writeHandle = ChunkHandle.writeHandle(concatArgs[0].getName());\n-            currentArgIndex = 1;\n-            return Futures.loop(() -> currentArgIndex < concatArgs.length,\n-                    () -> {\n-                        readAtOffset = 0;\n-                        val arg = concatArgs[currentArgIndex];\n-                        bytesToRead = Math.toIntExact(arg.getLength());\n-\n-                        return copyBytes(writeHandle, arg)\n-                                .thenApplyAsync(v -> {\n-                                    currentArgIndex++;\n-                                    return null;\n-                                }, chunkedSegmentStorage.executor);\n-                    },\n-                    chunkedSegmentStorage.executor)\n-                    .thenApplyAsync(v -> 0, chunkedSegmentStorage.executor);\n-        }\n-\n-        private CompletableFuture<Void> copyBytes(ChunkHandle writeHandle, ConcatArgument arg) {\n-            return Futures.loop(\n-                    () -> bytesToRead > 0,\n-                    () -> {\n-                        byte[] buffer = new byte[Math.min(chunkedSegmentStorage.config.getMaxBufferSizeForChunkDataTransfer(), bytesToRead)];\n-                        return chunkedSegmentStorage.chunkStorage.read(ChunkHandle.readHandle(arg.getName()), readAtOffset, buffer.length, buffer, 0)\n-                                .thenComposeAsync(size -> {\n-                                    bytesToRead -= size;\n-                                    readAtOffset += size;\n-                                    return chunkedSegmentStorage.chunkStorage.write(writeHandle, writeAtOffset, size, new ByteArrayInputStream(buffer, 0, size))\n-                                            .thenApplyAsync(written -> {\n-                                                writeAtOffset += written;\n-                                                return null;\n-                                            }, chunkedSegmentStorage.executor);\n-                                }, chunkedSegmentStorage.executor);\n-                    },\n-                    chunkedSegmentStorage.executor\n-            );\n-        }\n-    }\n-\n-    /**\n-     * Implements the concat operation.\n-     */\n-    private static class ConcatOperation implements Callable<CompletableFuture<Void>> {\n-        private final long traceId;\n-        private final SegmentHandle targetHandle;\n-        private final long offset;\n-        private final String sourceSegment;\n-        private final ChunkedSegmentStorage chunkedSegmentStorage;\n-        private final ArrayList<String> chunksToDelete = new ArrayList<>();\n-\n-        private Timer timer;\n-        private String targetSegmentName;\n-        private SegmentMetadata targetSegmentMetadata;\n-        private SegmentMetadata sourceSegmentMetadata;\n-        private ChunkMetadata targetLastChunk;\n-        private ChunkMetadata sourceFirstChunk;\n-\n-        ConcatOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle targetHandle, long offset, String sourceSegment) {\n-            this.targetHandle = targetHandle;\n-            this.offset = offset;\n-            this.sourceSegment = sourceSegment;\n-            this.chunkedSegmentStorage = chunkedSegmentStorage;\n-            traceId = LoggerHelpers.traceEnter(log, \"concat\", targetHandle, offset, sourceSegment);\n-        }\n-\n-        public CompletableFuture<Void> call() {\n-            timer = new Timer();\n-\n-            checkPreconditions();\n-            targetSegmentName = targetHandle.getSegmentName();\n-\n-            return tryWith(chunkedSegmentStorage.metadataStore.beginTransaction(targetHandle.getSegmentName(), sourceSegment),\n-                    txn -> txn.get(targetSegmentName)\n-                            .thenComposeAsync(storageMetadata1 -> {\n-                                targetSegmentMetadata = (SegmentMetadata) storageMetadata1;\n-                                return txn.get(sourceSegment)\n-                                        .thenComposeAsync(storageMetadata2 -> {\n-                                            sourceSegmentMetadata = (SegmentMetadata) storageMetadata2;\n-                                            return performConcat(txn);\n-                                        }, chunkedSegmentStorage.executor);\n-                            }, chunkedSegmentStorage.executor), chunkedSegmentStorage.executor);\n-        }\n-\n-        private CompletionStage<Void> performConcat(MetadataTransaction txn) {\n-            // Validate preconditions.\n-            checkState();\n-\n-            // Update list of chunks by appending sources list of chunks.\n-            return updateMetadata(txn).thenComposeAsync(v -> {\n-                // Finally defrag immediately.\n-                CompletableFuture<Void> f = CompletableFuture.completedFuture(null);\n-                if (shouldDefrag() && null != targetLastChunk) {\n-                    f = chunkedSegmentStorage.defrag(txn, targetSegmentMetadata, targetLastChunk.getName(), null, chunksToDelete);\n-                }\n-                return f.thenComposeAsync(v2 -> {\n-                    targetSegmentMetadata.checkInvariants();\n-\n-                    // Finally commit transaction.\n-                    return txn.commit()\n-                            .exceptionally(this::handleException)\n-                            .thenComposeAsync(v3 -> postCommit(), chunkedSegmentStorage.executor);\n-                }, chunkedSegmentStorage.executor);\n-            }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private Void handleException(Throwable e) {\n-            val ex = Exceptions.unwrap(e);\n-            if (ex instanceof StorageMetadataWritesFencedOutException) {\n-                throw new CompletionException(new StorageNotPrimaryException(targetSegmentName, ex));\n-            }\n-            throw new CompletionException(ex);\n-        }\n-\n-        private CompletionStage<Void> postCommit() {\n-            // Collect garbage.\n-            return chunkedSegmentStorage.collectGarbage(chunksToDelete)\n-                    .thenApplyAsync(v4 -> {\n-                        // Update the read index.\n-                        chunkedSegmentStorage.readIndexCache.remove(sourceSegment);\n-                        logEnd();\n-                        return null;\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private void logEnd() {\n-            Duration elapsed = timer.getElapsed();\n-            log.debug(\"{} concat - target={}, source={}, offset={}, latency={}.\", chunkedSegmentStorage.logPrefix, targetHandle.getSegmentName(), sourceSegment, offset, elapsed.toMillis());\n-            LoggerHelpers.traceLeave(log, \"concat\", traceId, targetHandle, offset, sourceSegment);\n-        }\n-\n-        private CompletableFuture<Void> updateMetadata(MetadataTransaction txn) {\n-            return txn.get(targetSegmentMetadata.getLastChunk())\n-                    .thenComposeAsync(storageMetadata1 -> {\n-                        targetLastChunk = (ChunkMetadata) storageMetadata1;\n-                        return txn.get(sourceSegmentMetadata.getFirstChunk())\n-                                .thenApplyAsync(storageMetadata2 -> {\n-                                    sourceFirstChunk = (ChunkMetadata) storageMetadata2;\n-\n-                                    if (targetLastChunk != null) {\n-                                        targetLastChunk.setNextChunk(sourceFirstChunk.getName());\n-                                        txn.update(targetLastChunk);\n-                                    } else {\n-                                        if (sourceFirstChunk != null) {\n-                                            targetSegmentMetadata.setFirstChunk(sourceFirstChunk.getName());\n-                                            txn.update(sourceFirstChunk);\n-                                        }\n-                                    }\n-\n-                                    // Update segments's last chunk to point to the sources last segment.\n-                                    targetSegmentMetadata.setLastChunk(sourceSegmentMetadata.getLastChunk());\n-\n-                                    // Update the length of segment.\n-                                    targetSegmentMetadata.setLastChunkStartOffset(targetSegmentMetadata.getLength() + sourceSegmentMetadata.getLastChunkStartOffset());\n-                                    targetSegmentMetadata.setLength(targetSegmentMetadata.getLength() + sourceSegmentMetadata.getLength() - sourceSegmentMetadata.getStartOffset());\n-\n-                                    targetSegmentMetadata.setChunkCount(targetSegmentMetadata.getChunkCount() + sourceSegmentMetadata.getChunkCount());\n-\n-                                    txn.update(targetSegmentMetadata);\n-                                    txn.delete(sourceSegment);\n-                                    return null;\n-                                }, chunkedSegmentStorage.executor);\n-                    }, chunkedSegmentStorage.executor);\n-        }\n-\n-        private void checkState() {\n-            chunkedSegmentStorage.checkSegmentExists(targetSegmentName, targetSegmentMetadata);\n-            targetSegmentMetadata.checkInvariants();\n-            chunkedSegmentStorage.checkNotSealed(targetSegmentName, targetSegmentMetadata);\n-\n-            chunkedSegmentStorage.checkSegmentExists(sourceSegment, sourceSegmentMetadata);\n-            sourceSegmentMetadata.checkInvariants();\n-\n-            // This is a critical assumption at this point which should not be broken,\n-            Preconditions.checkState(!targetSegmentMetadata.isStorageSystemSegment(), \"Storage system segments cannot be concatenated.\");\n-            Preconditions.checkState(!sourceSegmentMetadata.isStorageSystemSegment(), \"Storage system segments cannot be concatenated.\");\n-\n-            checkSealed(sourceSegmentMetadata);\n-            chunkedSegmentStorage.checkOwnership(targetSegmentMetadata.getName(), targetSegmentMetadata);\n-\n-            if (sourceSegmentMetadata.getStartOffset() != 0) {\n-                throw new CompletionException(new StreamSegmentTruncatedException(sourceSegment, sourceSegmentMetadata.getLength(), 0));\n-            }\n-\n-            if (offset != targetSegmentMetadata.getLength()) {\n-                throw new CompletionException(new BadOffsetException(targetHandle.getSegmentName(), targetSegmentMetadata.getLength(), offset));\n-            }\n-        }\n-\n-        private void checkPreconditions() {\n-            Preconditions.checkArgument(null != targetHandle, \"targetHandle\");\n-            Preconditions.checkArgument(!targetHandle.isReadOnly(), \"targetHandle\");\n-            Preconditions.checkArgument(null != sourceSegment, \"targetHandle\");\n-            Preconditions.checkArgument(offset >= 0, \"offset\");\n-        }\n-\n-        private void checkSealed(SegmentMetadata sourceSegmentMetadata) {\n-            if (!sourceSegmentMetadata.isSealed()) {\n-                throw new IllegalStateException(\"Source segment must be sealed.\");\n-            }\n-        }\n-\n-        private boolean shouldDefrag() {\n-            return (chunkedSegmentStorage.shouldAppend() || chunkedSegmentStorage.chunkStorage.supportsConcat())\n-                    && chunkedSegmentStorage.config.isInlineDefragEnabled();\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5OTQ0OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499899448", "bodyText": "This has become the biggest class in the whole project. Can we do something to make it smaller? Can we move each of those operations in their own, separate files?", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:08:29Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -171,7 +173,7 @@ public ChunkedSegmentStorage(ChunkStorage chunkStorage, ChunkMetadataStore metad\n      * @param containerId   container id.\n      * @throws Exception In case of any errors.\n      */\n-    public void bootstrap(int containerId, ChunkMetadataStore metadataStore) throws Exception {\n+    public CompletableFuture<Void> bootstrap(int containerId, ChunkMetadataStore metadataStore) throws Exception {", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1Mzg4NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506753884", "bodyText": "now I have split big bad class into smaller classes.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:53:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5OTQ0OA=="}], "type": "inlineReview", "revised_code": {"commit": "ca3cc947fa9a5051b397e0e9c305f2481e2ffcaa", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\nindex 04901c3ae4..ad863bad6a 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java\n\n@@ -163,29 +147,26 @@ public class ChunkedSegmentStorage implements Storage {\n         this.readIndexCache = new ReadIndexCache(config.getMaxIndexedSegments(),\n                 config.getMaxIndexedChunksPerSegment(),\n                 config.getMaxIndexedChunks());\n+        this.systemJournal = new SystemJournal(containerId,\n+                chunkStorage,\n+                metadataStore,\n+                config);\n+\n         this.closed = new AtomicBoolean(false);\n     }\n \n     /**\n      * Initializes the ChunkedSegmentStorage and bootstrap the metadata about storage metadata segments by reading and processing the journal.\n      *\n-     * @param metadataStore Metadata store.\n-     * @param containerId   container id.\n      * @throws Exception In case of any errors.\n      */\n-    public CompletableFuture<Void> bootstrap(int containerId, ChunkMetadataStore metadataStore) throws Exception {\n-        this.containerId = containerId;\n+    public CompletableFuture<Void> bootstrap() throws Exception {\n+\n         this.logPrefix = String.format(\"ChunkedSegmentStorage[%d]\", containerId);\n-        this.metadataStore = Preconditions.checkNotNull(metadataStore, \"metadataStore\");\n-        this.systemJournal = new SystemJournal(containerId,\n-                epoch,\n-                chunkStorage,\n-                metadataStore,\n-                config);\n \n         // Now bootstrap\n         log.info(\"{} STORAGE BOOT: Started.\", logPrefix);\n-        return this.systemJournal.bootstrap().thenApplyAsync(v -> {\n+        return this.systemJournal.bootstrap(epoch).thenApplyAsync(v -> {\n             log.info(\"{} STORAGE BOOT: Ended.\", logPrefix);\n             return null;\n         }, executor);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5OTg3MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499899871", "bodyText": "Is there a plan to fix these?", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:09:41Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/SystemJournal.java", "diffHunk": "@@ -140,7 +150,7 @@ public SystemJournal(int containerId, long epoch, ChunkStorage chunkStorage, Chu\n         this.systemSegments = getChunkStorageSystemSegments(containerId);\n         this.systemSegmentsPrefix = NameUtils.INTERNAL_SCOPE_NAME;\n \n-        Preconditions.checkState(!chunkStorage.exists(getSystemJournalChunkName()));\n+        Preconditions.checkState(!chunkStorage.exists(getSystemJournalChunkName()).get());", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1NDM3Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506754376", "bodyText": "not yet. This happens at the very beginning when these are the only SLTS operations at the bootstrap time. There is no table store access here.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:55:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTg5OTg3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "ca3cc947fa9a5051b397e0e9c305f2481e2ffcaa", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/SystemJournal.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/SystemJournal.java\nindex 7612d775c5..a02914dc79 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/SystemJournal.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/SystemJournal.java\n\n@@ -135,22 +135,17 @@ public class SystemJournal {\n      * Constructs an instance of {@link SystemJournal}.\n      *\n      * @param containerId   Container id of the owner container.\n-     * @param epoch         Epoch of the current container instance.\n      * @param chunkStorage  ChunkStorage instance to use for writing all logs.\n      * @param metadataStore ChunkMetadataStore for owner container.\n      * @param config        Configuration options for this ChunkedSegmentStorage instance.\n-     * @throws Exception In case of any errors.\n      */\n-    public SystemJournal(int containerId, long epoch, ChunkStorage chunkStorage, ChunkMetadataStore metadataStore, ChunkedSegmentStorageConfig config) throws Exception {\n+    public SystemJournal(int containerId, ChunkStorage chunkStorage, ChunkMetadataStore metadataStore, ChunkedSegmentStorageConfig config) {\n         this.chunkStorage = Preconditions.checkNotNull(chunkStorage, \"chunkStorage\");\n         this.metadataStore = Preconditions.checkNotNull(metadataStore, \"metadataStore\");\n         this.config = Preconditions.checkNotNull(config, \"config\");\n         this.containerId = containerId;\n-        this.epoch = epoch;\n         this.systemSegments = getChunkStorageSystemSegments(containerId);\n         this.systemSegmentsPrefix = NameUtils.INTERNAL_SCOPE_NAME;\n-\n-        Preconditions.checkState(!chunkStorage.exists(getSystemJournalChunkName()).get());\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMTM2MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499901361", "bodyText": "You are not holding a lock here while accessing activeKeys while below you do. Please be consistent (and correct).", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:13:37Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -299,110 +487,169 @@ public void abort(MetadataTransaction txn) throws StorageMetadataException {\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n      * @return Metadata for given key. Null if key was not found.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public StorageMetadata get(MetadataTransaction txn, String key) throws StorageMetadataException {\n+    public CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key) {\n         Preconditions.checkArgument(null != txn);\n-        TransactionData dataFromBuffer = null;\n         if (null == key) {\n-            return null;\n+            return CompletableFuture.completedFuture(null);\n         }\n-        StorageMetadata retValue = null;\n \n         Map<String, TransactionData> txnData = txn.getData();\n+\n+        // Record is found in transaction data itself.\n         TransactionData data = txnData.get(key);\n+        if (null != data) {\n+            return CompletableFuture.completedFuture(data.getValue());\n+        }\n \n-        // Search in the buffer.\n-        if (null == data) {\n-            synchronized (lock) {\n-                dataFromBuffer = bufferedTxnData.get(key);\n-            }\n-            // If we did not find in buffer then load it from store\n-            if (null == dataFromBuffer) {\n-                // NOTE: This call to read MUST be outside the lock, it is most likely cause re-entry.\n-                loadFromStore(key);\n-                dataFromBuffer = bufferedTxnData.get(key);\n-                Preconditions.checkState(null != dataFromBuffer);\n-            }\n+        // Prevent the key from getting evicted.\n+        addToActiveKeySet(key);\n+\n+        // Try to find it in buffer. Access buffer using reader lock.\n+        val readLock = scheduler.getReadLock(new String[]{key});\n+        return readLock.lock()\n+                .thenApplyAsync(v -> bufferedTxnData.get(key), executor)\n+                .thenApplyAsync(dataFromBuffer -> {\n+                    if (dataFromBuffer != null) {\n+                        // Make sure it is a deep copy.\n+                        val retValue = dataFromBuffer.getValue();\n+                        if (null != retValue) {\n+                            return retValue.deepCopy();\n+                        }\n+                        return null;\n+                    }\n+                    return null;\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> readLock.unlock(), executor)\n+                .thenComposeAsync(retValue -> {\n+                    if (retValue != null) {\n+                        return CompletableFuture.completedFuture(retValue);\n+                    }\n+                    // We did not find it in the buffer either.\n+                    // Try to find it in store.\n+                    return loadFromStore(key, false)\n+                            .thenApplyAsync(TransactionData::getValue, executor);\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> removeFromActiveKeySet(key), executor);\n+    }\n \n-            if (null != dataFromBuffer && null != dataFromBuffer.getValue()) {\n-                // Make copy.\n-                data = dataFromBuffer.toBuilder()\n-                        .key(key)\n-                        .value(dataFromBuffer.getValue().deepCopy())\n-                        .build();\n-                txnData.put(key, data);\n+    private void removeFromActiveKeySet(String key) {\n+        activeKeys.remove(key);", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1NDc4Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506754783", "bodyText": "activeKeys is concurrent multi hash - so addition/deleting is safe in this context.\nadded comment explaining why not having lock here is safe.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:56:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMTM2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 5a9e153991..a4b71121e0 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -487,7 +503,8 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n      * @return Metadata for given key. Null if key was not found.\n-     * throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n     @Override\n     public CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMTQ1NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499901454", "bodyText": "here too", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:13:54Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -299,110 +487,169 @@ public void abort(MetadataTransaction txn) throws StorageMetadataException {\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n      * @return Metadata for given key. Null if key was not found.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public StorageMetadata get(MetadataTransaction txn, String key) throws StorageMetadataException {\n+    public CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key) {\n         Preconditions.checkArgument(null != txn);\n-        TransactionData dataFromBuffer = null;\n         if (null == key) {\n-            return null;\n+            return CompletableFuture.completedFuture(null);\n         }\n-        StorageMetadata retValue = null;\n \n         Map<String, TransactionData> txnData = txn.getData();\n+\n+        // Record is found in transaction data itself.\n         TransactionData data = txnData.get(key);\n+        if (null != data) {\n+            return CompletableFuture.completedFuture(data.getValue());\n+        }\n \n-        // Search in the buffer.\n-        if (null == data) {\n-            synchronized (lock) {\n-                dataFromBuffer = bufferedTxnData.get(key);\n-            }\n-            // If we did not find in buffer then load it from store\n-            if (null == dataFromBuffer) {\n-                // NOTE: This call to read MUST be outside the lock, it is most likely cause re-entry.\n-                loadFromStore(key);\n-                dataFromBuffer = bufferedTxnData.get(key);\n-                Preconditions.checkState(null != dataFromBuffer);\n-            }\n+        // Prevent the key from getting evicted.\n+        addToActiveKeySet(key);\n+\n+        // Try to find it in buffer. Access buffer using reader lock.\n+        val readLock = scheduler.getReadLock(new String[]{key});\n+        return readLock.lock()\n+                .thenApplyAsync(v -> bufferedTxnData.get(key), executor)\n+                .thenApplyAsync(dataFromBuffer -> {\n+                    if (dataFromBuffer != null) {\n+                        // Make sure it is a deep copy.\n+                        val retValue = dataFromBuffer.getValue();\n+                        if (null != retValue) {\n+                            return retValue.deepCopy();\n+                        }\n+                        return null;\n+                    }\n+                    return null;\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> readLock.unlock(), executor)\n+                .thenComposeAsync(retValue -> {\n+                    if (retValue != null) {\n+                        return CompletableFuture.completedFuture(retValue);\n+                    }\n+                    // We did not find it in the buffer either.\n+                    // Try to find it in store.\n+                    return loadFromStore(key, false)\n+                            .thenApplyAsync(TransactionData::getValue, executor);\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> removeFromActiveKeySet(key), executor);\n+    }\n \n-            if (null != dataFromBuffer && null != dataFromBuffer.getValue()) {\n-                // Make copy.\n-                data = dataFromBuffer.toBuilder()\n-                        .key(key)\n-                        .value(dataFromBuffer.getValue().deepCopy())\n-                        .build();\n-                txnData.put(key, data);\n+    private void removeFromActiveKeySet(String key) {\n+        activeKeys.remove(key);\n+    }\n+\n+    private void addToActiveKeySet(String key) {\n+        // No need to synchronize if the eviction is not running.\n+        if (isEvictionRunning.get()) {\n+            synchronized (evictionLock) {\n+                activeKeys.add(key);\n             }\n+        } else {\n+            activeKeys.add(key);", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1NDg0Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506754847", "bodyText": "activeKeys is concurrent multi hash - so addition/deleting is safe in this context.\nadded comment explaining why not having lock here is safe.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:57:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMTQ1NA=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 5a9e153991..a4b71121e0 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -487,7 +503,8 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n      * @return Metadata for given key. Null if key was not found.\n-     * throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n     @Override\n     public CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMjY0Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499902642", "bodyText": "Please use @GuardedBy on the fields that need synchronization on, then in your IDE settings, make sure you enable Concurrency warnings. The IDE will tell you every single invocation where you accessing this outside of declared guards.", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:17:13Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A scheduler utility that implements pattern similar to Multiple Readers - Single Writer pattern.\n+ */\n+public class MultiKeyReaderWriterScheduler {\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private final HashMap<String, SchedulerData> keyToDataMap = new HashMap<>();", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MjE4Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752186", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:47:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMjY0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\nindex b4c3ff2b99..c47d267f50 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n\n@@ -13,6 +13,7 @@ import lombok.Getter;\n import lombok.RequiredArgsConstructor;\n import lombok.val;\n \n+import javax.annotation.concurrent.GuardedBy;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.concurrent.CompletableFuture;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMjczOQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499902739", "bodyText": "Why aren't any of these fields final?", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:17:33Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A scheduler utility that implements pattern similar to Multiple Readers - Single Writer pattern.\n+ */\n+public class MultiKeyReaderWriterScheduler {\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private final HashMap<String, SchedulerData> keyToDataMap = new HashMap<>();\n+\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private static class SchedulerData {\n+        int count;", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1MjAwOQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506752009", "bodyText": "It is modified later.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T22:46:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMjczOQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\nindex b4c3ff2b99..c47d267f50 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n\n@@ -13,6 +13,7 @@ import lombok.Getter;\n import lombok.RequiredArgsConstructor;\n import lombok.val;\n \n+import javax.annotation.concurrent.GuardedBy;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.concurrent.CompletableFuture;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMzM1OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499903359", "bodyText": "Futures.allOf?", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:19:17Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A scheduler utility that implements pattern similar to Multiple Readers - Single Writer pattern.\n+ */\n+public class MultiKeyReaderWriterScheduler {\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private final HashMap<String, SchedulerData> keyToDataMap = new HashMap<>();\n+\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private static class SchedulerData {\n+        int count;\n+        CompletableFuture blockingFuture = CompletableFuture.completedFuture(null);\n+        ArrayList<CompletableFuture> readerFutures = new ArrayList<>();\n+    }\n+\n+    /**\n+     * Represents a lock.\n+     */\n+    @RequiredArgsConstructor\n+    static class MultiKeyReaderWriterAsyncLock {\n+        /**\n+         * Keys to synchronize on.\n+         */\n+        @Getter\n+        private final String[] keys;\n+\n+        /**\n+         * Indicates whether the lock is a reader lock or a writer lock.\n+         */\n+        @Getter\n+        private final boolean isReadonly;\n+\n+        /**\n+         * Reference to the scheduler.\n+         */\n+        private final MultiKeyReaderWriterScheduler scheduler;\n+\n+        /**\n+         * The future is completed when all keys for this lock become available.\n+         */\n+        private CompletableFuture<Void> readyFuture;\n+\n+        /**\n+         * The future which is completed when lock is released.\n+         */\n+        @Getter\n+        private CompletableFuture<Void> doneFuture = new CompletableFuture<>();\n+\n+        CompletableFuture<Void> lock() {\n+            if (isReadonly) {\n+                return scheduler.scheduleForRead(this);\n+            } else {\n+                return scheduler.scheduleForWrite(this);\n+            }\n+        }\n+\n+        void unlock() {\n+            scheduler.release(this);\n+        }\n+    }\n+\n+    /**\n+     * Adds a reference for the key.\n+     */\n+    private SchedulerData addReference(String key) {\n+        SchedulerData schedulerData;\n+        synchronized (keyToDataMap) {\n+            schedulerData = keyToDataMap.get(key);\n+            // Add if this is a new key.\n+            if (null == schedulerData) {\n+                schedulerData = new SchedulerData();\n+                keyToDataMap.put(key, schedulerData);\n+            }\n+            // Increment ref count.\n+            schedulerData.count++;\n+        }\n+        return schedulerData;\n+    }\n+\n+    /**\n+     * Releases a reference for the key.\n+     */\n+    private void releaseReference(String key) {\n+        synchronized (keyToDataMap) {\n+            SchedulerData schedulerData = keyToDataMap.get(key);\n+            // Decrement ref count.\n+            schedulerData.count--;\n+            // clean up if required.\n+            if (0 == schedulerData.count) {\n+                keyToDataMap.remove(key);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Gets a read lock over given set of keys.\n+     */\n+    MultiKeyReaderWriterAsyncLock getReadLock(String[] keys) {\n+        return new MultiKeyReaderWriterAsyncLock(keys, true, this);\n+    }\n+\n+    /**\n+     * Gets a write lock over given set of keys.\n+     */\n+    MultiKeyReaderWriterAsyncLock getWriteLock(String[] keys) {\n+        return new MultiKeyReaderWriterAsyncLock(keys, false, this);\n+    }\n+\n+    /**\n+     * Schedules the lock for read.\n+     */\n+    private synchronized CompletableFuture<Void> scheduleForRead(MultiKeyReaderWriterAsyncLock lock) {\n+        CompletableFuture[] futuresToBlockOn = new CompletableFuture[lock.getKeys().length];\n+        for (int i = 0; i < lock.getKeys().length; i++) {\n+            val key = lock.getKeys()[i];\n+            SchedulerData schedulerData = addReference(key);\n+\n+            futuresToBlockOn[i] = schedulerData.blockingFuture;\n+            // Add this as reader\n+            schedulerData.readerFutures.add(lock.doneFuture);\n+        }\n+        lock.readyFuture = CompletableFuture.allOf(futuresToBlockOn);\n+        return lock.readyFuture;\n+    }\n+\n+    /**\n+     * Schedules the lock for write.\n+     */\n+    private synchronized CompletableFuture<Void> scheduleForWrite(MultiKeyReaderWriterAsyncLock lock) {\n+        CompletableFuture[] futuresToBlockOn = new CompletableFuture[lock.getKeys().length];\n+        for (int i = 0; i < lock.getKeys().length; i++) {\n+            val key = lock.getKeys()[i];\n+            // Get existing data.\n+            SchedulerData schedulerData = addReference(key);\n+\n+            // If there are outstanding readers then first \"drain\" all readers by making this write wait on them.\n+            if (schedulerData.readerFutures.size() > 0) {\n+                CompletableFuture[] readFutures = schedulerData.readerFutures.toArray(new CompletableFuture[schedulerData.readerFutures.size()]);\n+                schedulerData.blockingFuture = CompletableFuture.allOf(readFutures);", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5MzkwMQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516093901", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:27:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMzM1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\nindex b4c3ff2b99..c47d267f50 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n\n@@ -13,6 +13,7 @@ import lombok.Getter;\n import lombok.RequiredArgsConstructor;\n import lombok.val;\n \n+import javax.annotation.concurrent.GuardedBy;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.concurrent.CompletableFuture;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMzUwMQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499903501", "bodyText": "final", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:19:40Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A scheduler utility that implements pattern similar to Multiple Readers - Single Writer pattern.\n+ */\n+public class MultiKeyReaderWriterScheduler {\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private final HashMap<String, SchedulerData> keyToDataMap = new HashMap<>();\n+\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private static class SchedulerData {\n+        int count;\n+        CompletableFuture blockingFuture = CompletableFuture.completedFuture(null);\n+        ArrayList<CompletableFuture> readerFutures = new ArrayList<>();\n+    }\n+\n+    /**\n+     * Represents a lock.\n+     */\n+    @RequiredArgsConstructor\n+    static class MultiKeyReaderWriterAsyncLock {\n+        /**\n+         * Keys to synchronize on.\n+         */\n+        @Getter\n+        private final String[] keys;\n+\n+        /**\n+         * Indicates whether the lock is a reader lock or a writer lock.\n+         */\n+        @Getter\n+        private final boolean isReadonly;\n+\n+        /**\n+         * Reference to the scheduler.\n+         */\n+        private final MultiKeyReaderWriterScheduler scheduler;\n+\n+        /**\n+         * The future is completed when all keys for this lock become available.\n+         */\n+        private CompletableFuture<Void> readyFuture;\n+\n+        /**\n+         * The future which is completed when lock is released.\n+         */\n+        @Getter\n+        private CompletableFuture<Void> doneFuture = new CompletableFuture<>();", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1NTk1Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506755952", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-10-16T23:02:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwMzUwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\nindex b4c3ff2b99..c47d267f50 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n\n@@ -13,6 +13,7 @@ import lombok.Getter;\n import lombok.RequiredArgsConstructor;\n import lombok.val;\n \n+import javax.annotation.concurrent.GuardedBy;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.concurrent.CompletableFuture;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwNDA0NQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r499904045", "bodyText": "This is a very complex class with a lot of things that can go wrong, so it will be a likely candidate for tasks to \"hang indefinitely\". Is there a reason why:\n\nThis is needed?\nA reader-writer lock is needed? Can MultiKeyAsyncSequentialProcessor be used instead (it also serializes based on arbitrary string keys).", "author": "andreipaduroiu", "createdAt": "2020-10-05T22:21:09Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A scheduler utility that implements pattern similar to Multiple Readers - Single Writer pattern.\n+ */\n+public class MultiKeyReaderWriterScheduler {", "originalCommit": "611a9cd6bf2580818c99c864184735b682439da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc1NTYxMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r506755612", "bodyText": "This data structure is used to control concurrent access to the SLTS metadata cache. We need to be able to have multiple reader/single writer access to the metadata in order to avoid deadlocks that we saw during 0.8 testing.\nThe use case is bit different", "author": "sachin-j-joshi", "createdAt": "2020-10-16T23:00:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkwNDA0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "646036c36cf9842d27a608b7897b86105b9bc7e7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\nindex b4c3ff2b99..c47d267f50 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n\n@@ -13,6 +13,7 @@ import lombok.Getter;\n import lombok.RequiredArgsConstructor;\n import lombok.val;\n \n+import javax.annotation.concurrent.GuardedBy;\n import java.util.ArrayList;\n import java.util.HashMap;\n import java.util.concurrent.CompletableFuture;\n"}}, {"oid": "646036c36cf9842d27a608b7897b86105b9bc7e7", "url": "https://github.com/pravega/pravega/commit/646036c36cf9842d27a608b7897b86105b9bc7e7", "message": "Issue 5067: (SLTS) - Convert synchronous ChunkStorage and ChunkMetadataStore API into async\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-16T22:27:53Z", "type": "forcePushed"}, {"oid": "73d0607f4c0c059c91da707c940eb541267cd961", "url": "https://github.com/pravega/pravega/commit/73d0607f4c0c059c91da707c940eb541267cd961", "message": "Issue 5067: (SLTS) - Convert synchronous ChunkStorage and ChunkMetadataStore API into async\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-20T16:34:24Z", "type": "commit"}, {"oid": "73d0607f4c0c059c91da707c940eb541267cd961", "url": "https://github.com/pravega/pravega/commit/73d0607f4c0c059c91da707c940eb541267cd961", "message": "Issue 5067: (SLTS) - Convert synchronous ChunkStorage and ChunkMetadataStore API into async\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-20T16:34:24Z", "type": "forcePushed"}, {"oid": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "url": "https://github.com/pravega/pravega/commit/c6be777f67dd855512f0bdfbf4a21e69c2939104", "message": "Merge branch 'master' into issue-5067-make-slts-api-async", "committedDate": "2020-10-30T14:53:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE1ODkzNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515158934", "bodyText": "This is not an atomic operation. Can we change the putObject below to incorporate this? You may need to build a PutRequest object.", "author": "andreipaduroiu", "createdAt": "2020-10-30T14:55:16Z", "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3ChunkStorage.java", "diffHunk": "@@ -133,7 +136,10 @@ protected int doWrite(ChunkHandle handle, long offset, int length, InputStream d\n         try {\n             val objectPath = getObjectPath(handle.getChunkName());\n             // Check object exists.\n-            client.getObjectMetadata(config.getBucket(), objectPath);\n+            val metadata = client.getObjectMetadata(config.getBucket(), objectPath);", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTQzOTYxNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515439614", "bodyText": "There is no need to fence as only this instance should be accessing this chunk\nThere is pending work #4967 which will be done later.\nIn general converting this code to \"optimistic\" version will be done later.", "author": "sachin-j-joshi", "createdAt": "2020-10-31T01:28:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE1ODkzNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2Mjg1Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515162857", "bodyText": "Let's refactor this so we only pass the TableMetadataStore via this class' constructor.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:00:58Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -195,11 +196,16 @@ private void initializeStorage() throws Exception {\n             ContainerTableExtension tableExtension = getExtension(ContainerTableExtension.class);\n             String s = NameUtils.getStorageMetadataSegmentName(this.metadata.getContainerId());\n \n-            val metadata = new TableBasedMetadataStore(s, tableExtension);\n+            val metadataStore = new TableBasedMetadataStore(s, tableExtension, chunkedStorage.getExecutor());\n \n             // Bootstrap\n-            chunkedStorage.bootstrap(this.metadata.getContainerId(), metadata);\n+            return chunkedStorage.bootstrap(this.metadata.getContainerId(), metadataStore)", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA4MTYxMw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516081613", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:10:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2Mjg1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "ca3cc947fa9a5051b397e0e9c305f2481e2ffcaa", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\nindex a8dc47b0e0..c75859d7cf 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n\n@@ -192,14 +208,8 @@ class StreamSegmentContainer extends AbstractService implements SegmentContainer\n         if (this.storage instanceof ChunkedSegmentStorage) {\n             ChunkedSegmentStorage chunkedStorage = (ChunkedSegmentStorage) this.storage;\n \n-            // Initialize storage metadata table segment\n-            ContainerTableExtension tableExtension = getExtension(ContainerTableExtension.class);\n-            String s = NameUtils.getStorageMetadataSegmentName(this.metadata.getContainerId());\n-\n-            val metadataStore = new TableBasedMetadataStore(s, tableExtension, chunkedStorage.getExecutor());\n-\n             // Bootstrap\n-            return chunkedStorage.bootstrap(this.metadata.getContainerId(), metadataStore)\n+            return chunkedStorage.bootstrap()\n                     .thenApplyAsync( v -> {\n                         log.info(\"{}: Storage initialization done.\", this.traceObjectId);\n                         return null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2MzUwNg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515163506", "bodyText": "thenAcceptAsync. That way you can get rid of that return null at the end.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:01:55Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiConsumer;\n+\n+/**\n+ * Helper class for iterating over list of chunks.\n+ */\n+class ChunkIterator {\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+    private final MetadataTransaction txn;\n+    private volatile String currentChunkName;\n+    private volatile ChunkMetadata currentMetadata;\n+\n+    ChunkIterator(ChunkedSegmentStorage chunkedSegmentStorage, MetadataTransaction txn, SegmentMetadata segmentMetadata) {\n+        this.chunkedSegmentStorage = chunkedSegmentStorage;\n+        this.txn = txn;\n+        currentChunkName = segmentMetadata.getFirstChunk();\n+    }\n+\n+    public CompletableFuture<Void> forEach(BiConsumer<ChunkMetadata, String> consumer) {\n+        return Futures.loop(\n+                () -> currentChunkName != null,\n+                () -> txn.get(currentChunkName)\n+                        .thenApplyAsync(storageMetadata -> {", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjEzNzg5OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516137898", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-11-02T17:26:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2MzUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "3d091788890883720b2d9ce81830f3b63e2be8df", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java\nindex ce3149cdac..45b7fc5042 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java\n\n@@ -36,12 +36,11 @@ class ChunkIterator {\n         return Futures.loop(\n                 () -> currentChunkName != null,\n                 () -> txn.get(currentChunkName)\n-                        .thenApplyAsync(storageMetadata -> {\n+                        .thenAcceptAsync(storageMetadata -> {\n                             currentMetadata = (ChunkMetadata) storageMetadata;\n                             consumer.accept(currentMetadata, currentChunkName);\n                             // Move next\n                             currentChunkName = currentMetadata.getNextChunk();\n-                            return null;\n                         }, chunkedSegmentStorage.getExecutor()),\n                 chunkedSegmentStorage.getExecutor());\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NDg2OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515164868", "bodyText": "BTW, you're already executing on this executor and your callback is very insignificant in terms of CPU requirements. In this case, it is advisable to not use Async (i.e., thenAccept is enough) which will force this callback on the same thread the previous call was working, thus saving a thread context change.\nFYI: For other scenarios, please be very careful when deciding whether or not to do this. A very valid scenario where you do want to keep the Async variant is when you want to switch executors. However in this particular case, we do not need that.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:04:03Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.BiConsumer;\n+\n+/**\n+ * Helper class for iterating over list of chunks.\n+ */\n+class ChunkIterator {\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+    private final MetadataTransaction txn;\n+    private volatile String currentChunkName;\n+    private volatile ChunkMetadata currentMetadata;\n+\n+    ChunkIterator(ChunkedSegmentStorage chunkedSegmentStorage, MetadataTransaction txn, SegmentMetadata segmentMetadata) {\n+        this.chunkedSegmentStorage = chunkedSegmentStorage;\n+        this.txn = txn;\n+        currentChunkName = segmentMetadata.getFirstChunk();\n+    }\n+\n+    public CompletableFuture<Void> forEach(BiConsumer<ChunkMetadata, String> consumer) {\n+        return Futures.loop(\n+                () -> currentChunkName != null,\n+                () -> txn.get(currentChunkName)\n+                        .thenApplyAsync(storageMetadata -> {\n+                            currentMetadata = (ChunkMetadata) storageMetadata;\n+                            consumer.accept(currentMetadata, currentChunkName);\n+                            // Move next\n+                            currentChunkName = currentMetadata.getNextChunk();\n+                            return null;\n+                        }, chunkedSegmentStorage.getExecutor()),", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5NjIzNg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516096236", "bodyText": "I think The reason for not using non-async overload is that they can end up running on some Fork Join pool or caller pool.\nBy providing the same executor we are sure it will only run on given thread pool, which is what we want.", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:31:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NDg2OA=="}], "type": "inlineReview", "revised_code": {"commit": "3d091788890883720b2d9ce81830f3b63e2be8df", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java\nindex ce3149cdac..45b7fc5042 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkIterator.java\n\n@@ -36,12 +36,11 @@ class ChunkIterator {\n         return Futures.loop(\n                 () -> currentChunkName != null,\n                 () -> txn.get(currentChunkName)\n-                        .thenApplyAsync(storageMetadata -> {\n+                        .thenAcceptAsync(storageMetadata -> {\n                             currentMetadata = (ChunkMetadata) storageMetadata;\n                             consumer.accept(currentMetadata, currentChunkName);\n                             // Move next\n                             currentChunkName = currentMetadata.getNextChunk();\n-                            return null;\n                         }, chunkedSegmentStorage.getExecutor()),\n                 chunkedSegmentStorage.getExecutor());\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NjEyMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515166122", "bodyText": "This doesn't throw a CompletionException. In either case, the CompletionException is just a wrapper for some other exception, so I wouldn't bother documenting it here.\nPlease fix the Javadoc throughout this class to reflect that you are returning CompletableFutures and not plain old booleans. In the @return tag, you can mention any notable exceptions that may be thrown within the future itself (search for \"Notable Exceptions\" within the codebase for examples).", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:05:58Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java", "diffHunk": "@@ -72,56 +74,62 @@\n      *\n      * @param chunkName Name of the storage object to check.\n      * @return True if the object exists, false otherwise.\n-     * @throws ChunkStorageException Throws ChunkStorageException in case of I/O related exceptions.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNDI4NQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r517034285", "bodyText": "Some of these methods throw other exceptions and while it declare in CompletionException signature, putting only that one in return seems  odd. Putting it in a throws is not incorrect either.", "author": "sachin-j-joshi", "createdAt": "2020-11-04T00:35:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NjEyMg=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java\nindex f4c01c5dd3..b96edee5cc 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorage.java\n\n@@ -73,9 +73,9 @@ public interface ChunkStorage extends AutoCloseable {\n      * Determines whether named file/object exists in underlying storage.\n      *\n      * @param chunkName Name of the storage object to check.\n-     * @return True if the object exists, false otherwise.\n+     * @return A CompletableFuture that, when completed, will contain True if the object exists, false otherwise.\n      * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n-     * {@link ChunkStorageException} In case of I/O related exceptions.\n+     *                             {@link ChunkStorageException} In case of I/O related exceptions.\n      */\n     CompletableFuture<Boolean> exists(String chunkName);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NzE4Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515167182", "bodyText": "Why do we duplicate metrics? Can't we just reuse the same ones as before? All except one are the same.\nIf you duplicate them, you'll introduce debt that has to be fixed later. Plus anyone who has a metrics dashboard UI already set up will not be able to see these without some work there too.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:07:42Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkStorageMetrics.java", "diffHunk": "@@ -27,6 +27,14 @@\n     static final OpStatsLogger DELETE_LATENCY = STATS_LOGGER.createStats(MetricsNames.STORAGE_DELETE_LATENCY);\n     static final OpStatsLogger CONCAT_LATENCY = STATS_LOGGER.createStats(MetricsNames.STORAGE_CONCAT_LATENCY);\n \n+    static final OpStatsLogger SLTS_READ_LATENCY = STATS_LOGGER.createStats(MetricsNames.SLTS_READ_LATENCY);", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIyMDg3MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515220871", "bodyText": "These are two different metrics\n\nSLTS_READ_LATENCY - The end to end overall time Storage call takes (inclusive of all possible multiple calls to table segment + chunkstorage)\nREAD_LATENCY - The overall time , the individual chunk storage call takes.\n\nWe did not have this second set of metrics before. I find this second set of metrics are independent and very useful.", "author": "sachin-j-joshi", "createdAt": "2020-10-30T16:25:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NzE4Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NzcyMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515167722", "bodyText": "It would be nice to document what lazy and defrag mean. If already documented somewhere else, a Javadoc link would suffice too.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:08:34Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageConfig.java", "diffHunk": "@@ -100,13 +108,36 @@\n     @Getter\n     final private boolean appendEnabled;\n \n+    /**\n+     * Whether the lazy commit functionality is enabled or disabled.", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1OTg1OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518459859", "bodyText": "Ping!", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NzcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MjQ2Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520162466", "bodyText": "Fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:30:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2NzcyMg=="}], "type": "inlineReview", "revised_code": {"commit": "88aedf6d24adf406e2fb8fb0a0e7655a44edfb64", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageConfig.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageConfig.java\nindex e1e2fc7220..a4ed3edfad 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageConfig.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageConfig.java\n\n@@ -120,12 +118,6 @@ public class ChunkedSegmentStorageConfig {\n     @Getter\n     final private boolean inlineDefragEnabled;\n \n-    /**\n-     * Level of self check functionality enabled.\n-     */\n-    @Getter\n-    final private int selfCheckLevel;\n-\n     @Getter\n     final private int lateWarningThresholdInMillis;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2ODkzMA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515168930", "bodyText": "You do not need this. You can always get it from the target handle.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:10:18Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import io.pravega.segmentstore.contracts.BadOffsetException;\n+import io.pravega.segmentstore.contracts.StreamSegmentTruncatedException;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.StorageNotPrimaryException;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import io.pravega.segmentstore.storage.metadata.StorageMetadataWritesFencedOutException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.CompletionStage;\n+\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_CONCAT_COUNT;\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_CONCAT_LATENCY;\n+\n+/**\n+ * Implements the concat operation.\n+ */\n+@Slf4j\n+class ConcatOperation implements Callable<CompletableFuture<Void>> {\n+    private final long traceId;\n+    private final SegmentHandle targetHandle;\n+    private final long offset;\n+    private final String sourceSegment;\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+    private final ArrayList<String> chunksToDelete = new ArrayList<>();\n+\n+    private volatile Timer timer;\n+    private volatile String targetSegmentName;", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5NjYwMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516096602", "bodyText": "fixed.", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:31:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2ODkzMA=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\nindex b0d2865411..f6728dcb23 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\n\n@@ -44,9 +44,8 @@ class ConcatOperation implements Callable<CompletableFuture<Void>> {\n     private final String sourceSegment;\n     private final ChunkedSegmentStorage chunkedSegmentStorage;\n     private final ArrayList<String> chunksToDelete = new ArrayList<>();\n+    private final Timer timer;\n \n-    private volatile Timer timer;\n-    private volatile String targetSegmentName;\n     private volatile SegmentMetadata targetSegmentMetadata;\n     private volatile SegmentMetadata sourceSegmentMetadata;\n     private volatile ChunkMetadata targetLastChunk;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2OTU0OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515169549", "bodyText": "These look like they can be transformed to local variables which you can pass along as needed.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:11:13Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import io.pravega.segmentstore.contracts.BadOffsetException;\n+import io.pravega.segmentstore.contracts.StreamSegmentTruncatedException;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.StorageNotPrimaryException;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import io.pravega.segmentstore.storage.metadata.StorageMetadataWritesFencedOutException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.CompletionStage;\n+\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_CONCAT_COUNT;\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_CONCAT_LATENCY;\n+\n+/**\n+ * Implements the concat operation.\n+ */\n+@Slf4j\n+class ConcatOperation implements Callable<CompletableFuture<Void>> {\n+    private final long traceId;\n+    private final SegmentHandle targetHandle;\n+    private final long offset;\n+    private final String sourceSegment;\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+    private final ArrayList<String> chunksToDelete = new ArrayList<>();\n+\n+    private volatile Timer timer;\n+    private volatile String targetSegmentName;\n+    private volatile SegmentMetadata targetSegmentMetadata;", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMzU0Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r517033546", "bodyText": "This should not matter as much, I used operation class so that I don't have to pass lots of parameters around. passing parameters becomes troublesome specially when multiple values need to be returned. These field are modified and then used in next step.", "author": "sachin-j-joshi", "createdAt": "2020-11-04T00:32:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2OTU0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\nindex b0d2865411..f6728dcb23 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\n\n@@ -44,9 +44,8 @@ class ConcatOperation implements Callable<CompletableFuture<Void>> {\n     private final String sourceSegment;\n     private final ChunkedSegmentStorage chunkedSegmentStorage;\n     private final ArrayList<String> chunksToDelete = new ArrayList<>();\n+    private final Timer timer;\n \n-    private volatile Timer timer;\n-    private volatile String targetSegmentName;\n     private volatile SegmentMetadata targetSegmentMetadata;\n     private volatile SegmentMetadata sourceSegmentMetadata;\n     private volatile ChunkMetadata targetLastChunk;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MDUwMA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515170500", "bodyText": "accept", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:12:40Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import io.pravega.segmentstore.contracts.BadOffsetException;\n+import io.pravega.segmentstore.contracts.StreamSegmentTruncatedException;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.StorageNotPrimaryException;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import io.pravega.segmentstore.storage.metadata.StorageMetadataWritesFencedOutException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.CompletionStage;\n+\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_CONCAT_COUNT;\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_CONCAT_LATENCY;\n+\n+/**\n+ * Implements the concat operation.\n+ */\n+@Slf4j\n+class ConcatOperation implements Callable<CompletableFuture<Void>> {\n+    private final long traceId;\n+    private final SegmentHandle targetHandle;\n+    private final long offset;\n+    private final String sourceSegment;\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+    private final ArrayList<String> chunksToDelete = new ArrayList<>();\n+\n+    private volatile Timer timer;\n+    private volatile String targetSegmentName;\n+    private volatile SegmentMetadata targetSegmentMetadata;\n+    private volatile SegmentMetadata sourceSegmentMetadata;\n+    private volatile ChunkMetadata targetLastChunk;\n+    private volatile ChunkMetadata sourceFirstChunk;\n+\n+    ConcatOperation(ChunkedSegmentStorage chunkedSegmentStorage, SegmentHandle targetHandle, long offset, String sourceSegment) {\n+        this.targetHandle = targetHandle;\n+        this.offset = offset;\n+        this.sourceSegment = sourceSegment;\n+        this.chunkedSegmentStorage = chunkedSegmentStorage;\n+        traceId = LoggerHelpers.traceEnter(log, \"concat\", targetHandle, offset, sourceSegment);\n+    }\n+\n+    public CompletableFuture<Void> call() {\n+        timer = new Timer();\n+        checkPreconditions();\n+        log.debug(\"{} concat - started op={}, target={}, source={}, offset={}.\",\n+                chunkedSegmentStorage.getLogPrefix(), System.identityHashCode(this), targetHandle.getSegmentName(), sourceSegment, offset);\n+\n+        targetSegmentName = targetHandle.getSegmentName();\n+\n+        return ChunkedSegmentStorage.tryWith(chunkedSegmentStorage.getMetadataStore().beginTransaction(targetHandle.getSegmentName(), sourceSegment),\n+                txn -> txn.get(targetSegmentName)\n+                        .thenComposeAsync(storageMetadata1 -> {\n+                            targetSegmentMetadata = (SegmentMetadata) storageMetadata1;\n+                            return txn.get(sourceSegment)\n+                                    .thenComposeAsync(storageMetadata2 -> {\n+                                        sourceSegmentMetadata = (SegmentMetadata) storageMetadata2;\n+                                        return performConcat(txn);\n+                                    }, chunkedSegmentStorage.getExecutor());\n+                        }, chunkedSegmentStorage.getExecutor()), chunkedSegmentStorage.getExecutor());\n+    }\n+\n+    private CompletionStage<Void> performConcat(MetadataTransaction txn) {\n+        // Validate preconditions.\n+        checkState();\n+\n+        // Update list of chunks by appending sources list of chunks.\n+        return updateMetadata(txn).thenComposeAsync(v -> {\n+            // Finally defrag immediately.\n+            final CompletableFuture<Void> f;\n+            if (shouldDefrag() && null != targetLastChunk) {\n+                f = chunkedSegmentStorage.defrag(txn, targetSegmentMetadata, targetLastChunk.getName(), null, chunksToDelete);\n+            } else {\n+                f = CompletableFuture.completedFuture(null);\n+            }\n+            return f.thenComposeAsync(v2 -> {\n+                targetSegmentMetadata.checkInvariants();\n+\n+                // Finally commit transaction.\n+                return txn.commit()\n+                        .exceptionally(this::handleException)\n+                        .thenComposeAsync(v3 -> postCommit(), chunkedSegmentStorage.getExecutor());\n+            }, chunkedSegmentStorage.getExecutor());\n+        }, chunkedSegmentStorage.getExecutor());\n+    }\n+\n+    private Void handleException(Throwable e) {\n+        log.debug(\"{} concat - exception op={}, target={}, source={}, offset={}.\",\n+                chunkedSegmentStorage.getLogPrefix(), System.identityHashCode(this), targetHandle.getSegmentName(), sourceSegment, offset);\n+        val ex = Exceptions.unwrap(e);\n+        if (ex instanceof StorageMetadataWritesFencedOutException) {\n+            throw new CompletionException(new StorageNotPrimaryException(targetSegmentName, ex));\n+        }\n+        throw new CompletionException(ex);\n+    }\n+\n+    private CompletionStage<Void> postCommit() {\n+        // Collect garbage.\n+        return chunkedSegmentStorage.collectGarbage(chunksToDelete)\n+                .thenApplyAsync(v4 -> {", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5Nzk2Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516097963", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:33:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MDUwMA=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\nindex b0d2865411..f6728dcb23 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ConcatOperation.java\n\n@@ -44,9 +44,8 @@ class ConcatOperation implements Callable<CompletableFuture<Void>> {\n     private final String sourceSegment;\n     private final ChunkedSegmentStorage chunkedSegmentStorage;\n     private final ArrayList<String> chunksToDelete = new ArrayList<>();\n+    private final Timer timer;\n \n-    private volatile Timer timer;\n-    private volatile String targetSegmentName;\n     private volatile SegmentMetadata targetSegmentMetadata;\n     private volatile SegmentMetadata sourceSegmentMetadata;\n     private volatile ChunkMetadata targetLastChunk;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MTk2Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515171967", "bodyText": "Please check your phrasing in this Javadoc. I found at least one sentence (such as this one) that aren't well formed. This includes grammar and singular/plurals.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:14:51Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import lombok.val;\n+\n+import java.io.ByteArrayInputStream;\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Defragments the list of chunks for a given segment.\n+ * It finds eligible consecutive chunks that can be merged together.\n+ * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjEzODU3MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516138571", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T17:27:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MTk2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex bc2f3cbb86..1e54365abd 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -24,14 +24,14 @@ import java.util.concurrent.atomic.AtomicInteger;\n /**\n  * Defragments the list of chunks for a given segment.\n  * It finds eligible consecutive chunks that can be merged together.\n- * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n- * Conceptually this is like deleting nodes from middle of the list of chunks.\n- *\n+ * The sublist of such eligible chunks is replaced with single new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks and replacing them with one or more nodes.\n+ * <ul>\n  * <Ul>\n  * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n  * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n  * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n- * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., non-extended S3) and\n  * each write becomes a separate chunk.\n  * </li>\n  * <li>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MzY5NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515173694", "bodyText": "you use vanilla s3 here but block s3 above. Please be consistent.", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:17:37Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import lombok.val;\n+\n+import java.io.ByteArrayInputStream;\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Defragments the list of chunks for a given segment.\n+ * It finds eligible consecutive chunks that can be merged together.\n+ * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks.\n+ *\n+ * <Ul>\n+ * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n+ * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n+ * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * each write becomes a separate chunk.\n+ * </li>\n+ * <li>\n+ * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n+ * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n+ * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n+ * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n+ * whereas NFS has no concept of merging natively.\n+ *\n+ * As chunks become larger, append writes (read source completely and append it back at the end of target)\n+ * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n+ * when available, and if not available, then we use appends.\n+ * </li>\n+ * <li>\n+ * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n+ * We can then fine tune that background task to run optimally with low overhead.\n+ * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n+ * </li>\n+ * <li>\n+ * <li>\n+ * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n+ * </li>\n+ * </ul>\n+ *\n+ * What controls whether we invoke concat or simulate through appends?\n+ * There are a few different capabilities that ChunkStorage needs to provide.\n+ * <ul>\n+ * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjEzODY4NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516138684", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T17:27:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MzY5NA=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex bc2f3cbb86..1e54365abd 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -24,14 +24,14 @@ import java.util.concurrent.atomic.AtomicInteger;\n /**\n  * Defragments the list of chunks for a given segment.\n  * It finds eligible consecutive chunks that can be merged together.\n- * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n- * Conceptually this is like deleting nodes from middle of the list of chunks.\n- *\n+ * The sublist of such eligible chunks is replaced with single new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks and replacing them with one or more nodes.\n+ * <ul>\n  * <Ul>\n  * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n  * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n  * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n- * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., non-extended S3) and\n  * each write becomes a separate chunk.\n  * </li>\n  * <li>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3NDYzOQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515174639", "bodyText": "incomplete sentence", "author": "andreipaduroiu", "createdAt": "2020-10-30T15:18:52Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import lombok.val;\n+\n+import java.io.ByteArrayInputStream;\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Defragments the list of chunks for a given segment.\n+ * It finds eligible consecutive chunks that can be merged together.\n+ * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks.\n+ *\n+ * <Ul>\n+ * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n+ * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n+ * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * each write becomes a separate chunk.\n+ * </li>\n+ * <li>\n+ * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n+ * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n+ * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n+ * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n+ * whereas NFS has no concept of merging natively.\n+ *\n+ * As chunks become larger, append writes (read source completely and append it back at the end of target)\n+ * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n+ * when available, and if not available, then we use appends.\n+ * </li>\n+ * <li>\n+ * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n+ * We can then fine tune that background task to run optimally with low overhead.\n+ * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n+ * </li>\n+ * <li>\n+ * <li>\n+ * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n+ * </li>\n+ * </ul>\n+ *\n+ * What controls whether we invoke concat or simulate through appends?\n+ * There are a few different capabilities that ChunkStorage needs to provide.\n+ * <ul>\n+ * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.\n+ * This is indicated by supportsAppend.</li>\n+ * <li>Does ChunkStorage support for concatenating chunks ? This is indicated by supportsConcat.\n+ * If this is true then concat operation will be invoked otherwise chunks will be appended.</li>\n+ * <li>There are some obvious constraints - For ChunkStorage support any concat functionality it must support either\n+ * append or concat.</li>\n+ * <li>Also when ChunkStorage supports both concat and append, ChunkedSegmentStorage will invoke appropriate method\n+ * depending on size of target and source chunks. (Eg. ECS)</li>\n+ * </ul>\n+ *\n+ * <li>\n+ * What controls defrag?\n+ * There are two additional parameters that control when concat", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjEzODc4Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516138786", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T17:27:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3NDYzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex bc2f3cbb86..1e54365abd 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -24,14 +24,14 @@ import java.util.concurrent.atomic.AtomicInteger;\n /**\n  * Defragments the list of chunks for a given segment.\n  * It finds eligible consecutive chunks that can be merged together.\n- * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n- * Conceptually this is like deleting nodes from middle of the list of chunks.\n- *\n+ * The sublist of such eligible chunks is replaced with single new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks and replacing them with one or more nodes.\n+ * <ul>\n  * <Ul>\n  * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n  * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n  * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n- * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., non-extended S3) and\n  * each write becomes a separate chunk.\n  * </li>\n  * <li>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNjIxMQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515206211", "bodyText": "You can get these names from the handles. No need to store them separately.", "author": "andreipaduroiu", "createdAt": "2020-10-30T16:01:15Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import lombok.val;\n+\n+import java.io.ByteArrayInputStream;\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Defragments the list of chunks for a given segment.\n+ * It finds eligible consecutive chunks that can be merged together.\n+ * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks.\n+ *\n+ * <Ul>\n+ * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n+ * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n+ * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * each write becomes a separate chunk.\n+ * </li>\n+ * <li>\n+ * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n+ * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n+ * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n+ * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n+ * whereas NFS has no concept of merging natively.\n+ *\n+ * As chunks become larger, append writes (read source completely and append it back at the end of target)\n+ * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n+ * when available, and if not available, then we use appends.\n+ * </li>\n+ * <li>\n+ * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n+ * We can then fine tune that background task to run optimally with low overhead.\n+ * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n+ * </li>\n+ * <li>\n+ * <li>\n+ * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n+ * </li>\n+ * </ul>\n+ *\n+ * What controls whether we invoke concat or simulate through appends?\n+ * There are a few different capabilities that ChunkStorage needs to provide.\n+ * <ul>\n+ * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.\n+ * This is indicated by supportsAppend.</li>\n+ * <li>Does ChunkStorage support for concatenating chunks ? This is indicated by supportsConcat.\n+ * If this is true then concat operation will be invoked otherwise chunks will be appended.</li>\n+ * <li>There are some obvious constraints - For ChunkStorage support any concat functionality it must support either\n+ * append or concat.</li>\n+ * <li>Also when ChunkStorage supports both concat and append, ChunkedSegmentStorage will invoke appropriate method\n+ * depending on size of target and source chunks. (Eg. ECS)</li>\n+ * </ul>\n+ *\n+ * <li>\n+ * What controls defrag?\n+ * There are two additional parameters that control when concat\n+ * <li>minSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered a small object.\n+ * For small source objects, append is used instead of using concat. (For really small txn it is rather efficient to use append than MPU).</li>\n+ * <li>maxSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered for concat. (Eg S3 might have max limit on chunk size).</li>\n+ * In short there is a size beyond which using append is not advisable. Conversely there is a size below which concat is not efficient.(minSizeLimitForConcat )\n+ * Then there is limit which concating does not make sense maxSizeLimitForConcat\n+ * </li>\n+ * <li>\n+ * What is the defrag algorithm\n+ * <pre>\n+ * While(segment.hasConcatableChunks()){\n+ *     Set<List<Chunk>> s = FindConsecutiveConcatableChunks();\n+ *     For (List<chunk> list : s){\n+ *        ConcatChunks (list);\n+ *     }\n+ * }\n+ * </pre>\n+ * </li>\n+ * </ul>\n+ */\n+class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n+    private final MetadataTransaction txn;\n+    private final SegmentMetadata segmentMetadata;\n+    private final String startChunkName;\n+    private final String lastChunkName;\n+    private final ArrayList<String> chunksToDelete;\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+\n+    private volatile ArrayList<ChunkInfo> chunksToConcat = new ArrayList<>();\n+\n+    private volatile ChunkMetadata target;\n+    private volatile String targetChunkName;", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5OTA3Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516099073", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:34:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNjIxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex bc2f3cbb86..1e54365abd 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -24,14 +24,14 @@ import java.util.concurrent.atomic.AtomicInteger;\n /**\n  * Defragments the list of chunks for a given segment.\n  * It finds eligible consecutive chunks that can be merged together.\n- * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n- * Conceptually this is like deleting nodes from middle of the list of chunks.\n- *\n+ * The sublist of such eligible chunks is replaced with single new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks and replacing them with one or more nodes.\n+ * <ul>\n  * <Ul>\n  * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n  * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n  * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n- * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., non-extended S3) and\n  * each write becomes a separate chunk.\n  * </li>\n  * <li>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNjQ5MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515206490", "bodyText": "Please try to either make these final or pass them along as arguments to your method calls.", "author": "andreipaduroiu", "createdAt": "2020-10-30T16:01:43Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import lombok.val;\n+\n+import java.io.ByteArrayInputStream;\n+import java.util.ArrayList;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * Defragments the list of chunks for a given segment.\n+ * It finds eligible consecutive chunks that can be merged together.\n+ * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks.\n+ *\n+ * <Ul>\n+ * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n+ * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n+ * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * each write becomes a separate chunk.\n+ * </li>\n+ * <li>\n+ * If the underlying storage provides some facility to stitch together smaller chunk into larger chunks, then we do\n+ * actually want to exploit that, specially when the underlying implementation is only a metadata operation. We want\n+ * to leverage multi-part uploads in object stores that support it (e.g., AWS S3, Dell EMC ECS) as they are typically\n+ * only metadata operations, reducing the overall cost of the merging them together. HDFS also supports merges,\n+ * whereas NFS has no concept of merging natively.\n+ *\n+ * As chunks become larger, append writes (read source completely and append it back at the end of target)\n+ * become inefficient. Consequently, a native option for merging is desirable. We use such native merge capability\n+ * when available, and if not available, then we use appends.\n+ * </li>\n+ * <li>\n+ * Ideally we want the defrag to be run in the background periodically and not on the write/concat path.\n+ * We can then fine tune that background task to run optimally with low overhead.\n+ * We might be able to give more knobs to tune its parameters (Eg. threshold on number of chunks).\n+ * </li>\n+ * <li>\n+ * <li>\n+ * Defrag operation will respect max rolling size and will not create chunks greater than that size.\n+ * </li>\n+ * </ul>\n+ *\n+ * What controls whether we invoke concat or simulate through appends?\n+ * There are a few different capabilities that ChunkStorage needs to provide.\n+ * <ul>\n+ * <li>Does ChunkStorage support appending to existing chunks? For vanilla S3 compatible this would return false.\n+ * This is indicated by supportsAppend.</li>\n+ * <li>Does ChunkStorage support for concatenating chunks ? This is indicated by supportsConcat.\n+ * If this is true then concat operation will be invoked otherwise chunks will be appended.</li>\n+ * <li>There are some obvious constraints - For ChunkStorage support any concat functionality it must support either\n+ * append or concat.</li>\n+ * <li>Also when ChunkStorage supports both concat and append, ChunkedSegmentStorage will invoke appropriate method\n+ * depending on size of target and source chunks. (Eg. ECS)</li>\n+ * </ul>\n+ *\n+ * <li>\n+ * What controls defrag?\n+ * There are two additional parameters that control when concat\n+ * <li>minSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered a small object.\n+ * For small source objects, append is used instead of using concat. (For really small txn it is rather efficient to use append than MPU).</li>\n+ * <li>maxSizeLimitForConcat: Size of chunk in bytes above which it is no longer considered for concat. (Eg S3 might have max limit on chunk size).</li>\n+ * In short there is a size beyond which using append is not advisable. Conversely there is a size below which concat is not efficient.(minSizeLimitForConcat )\n+ * Then there is limit which concating does not make sense maxSizeLimitForConcat\n+ * </li>\n+ * <li>\n+ * What is the defrag algorithm\n+ * <pre>\n+ * While(segment.hasConcatableChunks()){\n+ *     Set<List<Chunk>> s = FindConsecutiveConcatableChunks();\n+ *     For (List<chunk> list : s){\n+ *        ConcatChunks (list);\n+ *     }\n+ * }\n+ * </pre>\n+ * </li>\n+ * </ul>\n+ */\n+class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n+    private final MetadataTransaction txn;\n+    private final SegmentMetadata segmentMetadata;\n+    private final String startChunkName;\n+    private final String lastChunkName;\n+    private final ArrayList<String> chunksToDelete;\n+    private final ChunkedSegmentStorage chunkedSegmentStorage;\n+\n+    private volatile ArrayList<ChunkInfo> chunksToConcat = new ArrayList<>();\n+\n+    private volatile ChunkMetadata target;\n+    private volatile String targetChunkName;\n+    private volatile boolean useAppend;\n+    private volatile long targetSizeAfterConcat;\n+    private volatile String nextChunkName;\n+    private volatile ChunkMetadata next = null;\n+\n+    private volatile long writeAtOffset;", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMzM3MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r517033371", "bodyText": "This should not matter as much, I used operation class so that I don't have to pass lots of parameters around. passing parameters becomes troublesome specially when multiple values need to be returned. These field are modified and then used in next step.", "author": "sachin-j-joshi", "createdAt": "2020-11-04T00:32:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNjQ5MA=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex bc2f3cbb86..1e54365abd 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -24,14 +24,14 @@ import java.util.concurrent.atomic.AtomicInteger;\n /**\n  * Defragments the list of chunks for a given segment.\n  * It finds eligible consecutive chunks that can be merged together.\n- * The sublist such elgible chunks is replaced with single new chunk record corresponding to new large chunk.\n- * Conceptually this is like deleting nodes from middle of the list of chunks.\n- *\n+ * The sublist of such eligible chunks is replaced with single new large chunk.\n+ * Conceptually this is like deleting nodes from middle of the list of chunks and replacing them with one or more nodes.\n+ * <ul>\n  * <Ul>\n  * <li> In the absence of defragmentation, the number of chunks for individual segments keeps on increasing.\n  * When we have too many small chunks (say because many transactions with little data on some segments), the segment\n  * is fragmented - this may impact both the read throughput and the performance of the metadata store.\n- * This problem is further intensified when we have stores that do not support append semantics (e.g., stock S3) and\n+ * This problem is further intensified when we have stores that do not support append semantics (e.g., non-extended S3) and\n  * each write becomes a separate chunk.\n  * </li>\n  * <li>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzE3OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515207178", "bodyText": "Same comments here. And in all the other operations below.", "author": "andreipaduroiu", "createdAt": "2020-10-30T16:02:45Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.StreamSegmentTruncatedException;\n+import io.pravega.segmentstore.storage.SegmentHandle;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadata;\n+import io.pravega.segmentstore.storage.metadata.MetadataTransaction;\n+import io.pravega.segmentstore.storage.metadata.SegmentMetadata;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_READ_BYTES;\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_READ_LATENCY;\n+import static io.pravega.segmentstore.storage.chunklayer.ChunkStorageMetrics.SLTS_READ_INDEX_SCAN_LATENCY;\n+\n+@Slf4j\n+class ReadOperation implements Callable<CompletableFuture<Integer>> {\n+    private final SegmentHandle handle;", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA5OTIwNQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516099205", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:34:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzE3OA=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java\nindex fe44761abd..263b110eb1 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java\n\n@@ -40,9 +40,8 @@ class ReadOperation implements Callable<CompletableFuture<Integer>> {\n     private final int bufferOffset;\n     private final int length;\n     private final ChunkedSegmentStorage chunkedSegmentStorage;\n-    private volatile long traceId;\n-    private volatile Timer timer;\n-    private volatile String streamSegmentName;\n+    private final long traceId;\n+    private final Timer timer;\n     private volatile SegmentMetadata segmentMetadata;\n     private volatile int bytesRemaining;\n     private volatile int currentBufferOffset;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzYyNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515207624", "bodyText": "Update Javadoc to reflect that you're returning a future.", "author": "andreipaduroiu", "createdAt": "2020-10-30T16:03:28Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java", "diffHunk": "@@ -78,107 +81,116 @@\n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of {@link MetadataTransaction}.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n-    MetadataTransaction beginTransaction() throws StorageMetadataException;\n+    MetadataTransaction beginTransaction(String... keysToLock);\n \n     /**\n      * Retrieves the metadata for given key.\n      *\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n      * @return Metadata for given key. Null if key was not found.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n-    StorageMetadata get(MetadataTransaction txn, String key) throws StorageMetadataException;\n+    CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key);", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA4MDk4MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516080981", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:09:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzYyNA=="}], "type": "inlineReview", "revised_code": {"commit": "3046d85c5dc38c736c6326c204ec45c9abd2d1ab", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java\nindex 81255f6e62..2651158dae 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java\n\n@@ -82,9 +82,10 @@ public interface ChunkMetadataStore extends AutoCloseable {\n      * Begins a new transaction.\n      *\n      * @param keysToLock Array of keys to lock for this transaction.\n+     * @param isReadonly Whether transaction is read only or not.\n      * @return Returns a new instance of {@link MetadataTransaction}.\n      */\n-    MetadataTransaction beginTransaction(String... keysToLock);\n+    MetadataTransaction beginTransaction(boolean isReadonly, String... keysToLock);\n \n     /**\n      * Retrieves the metadata for given key.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzc1MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515207750", "bodyText": "and here, and below too.", "author": "andreipaduroiu", "createdAt": "2020-10-30T16:03:39Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java", "diffHunk": "@@ -78,107 +81,116 @@\n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of {@link MetadataTransaction}.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n-    MetadataTransaction beginTransaction() throws StorageMetadataException;\n+    MetadataTransaction beginTransaction(String... keysToLock);\n \n     /**\n      * Retrieves the metadata for given key.\n      *\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n      * @return Metadata for given key. Null if key was not found.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n-    StorageMetadata get(MetadataTransaction txn, String key) throws StorageMetadataException;\n+    CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key);\n \n     /**\n      * Updates existing metadata.\n      *\n      * @param txn      Transaction.\n      * @param metadata metadata record.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n-    void update(MetadataTransaction txn, StorageMetadata metadata) throws StorageMetadataException;\n+    void update(MetadataTransaction txn, StorageMetadata metadata);\n \n     /**\n      * Creates a new metadata record.\n      *\n      * @param txn      Transaction.\n      * @param metadata metadata record.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n-    void create(MetadataTransaction txn, StorageMetadata metadata) throws StorageMetadataException;\n+    void create(MetadataTransaction txn, StorageMetadata metadata);\n \n     /**\n      * Marks given single record as pinned.\n      * Pinned records are not evicted from memory and are not written to the underlying storage.\n      *\n      * @param txn      Transaction.\n      * @param metadata metadata record.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n-    void markPinned(MetadataTransaction txn, StorageMetadata metadata) throws StorageMetadataException;\n+    void markPinned(MetadataTransaction txn, StorageMetadata metadata);\n \n     /**\n      * Deletes a metadata record given the key.\n-     * The transaction data is validated and changes are commited to underlying storage.\n+     * The transaction data is validated and changes are committed to underlying storage.\n      * This call blocks until write to underlying storage is confirmed.\n      *\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n-    void delete(MetadataTransaction txn, String key) throws StorageMetadataException;\n+    void delete(MetadataTransaction txn, String key);\n \n     /**\n      * Commits given transaction.\n-     * If  skipStoreCheck is set to true then the transaction data is validated without realoding.\n+     * If  skipStoreCheck is set to true then the transaction data is validated without reloading.\n      * This call blocks until write to underlying storage is confirmed. This helps avoid circular dependency on storage\n      * system segments.\n-     * If lazyWrite is true then the transaction data is validated but the changes are not commited to underlying storage.\n+     * If lazyWrite is true then the transaction data is validated but the changes are not committed to underlying storage.\n      * Changes are put in the in memory buffer only. Note that in case of crash, the changes in the in buffer are lost.\n-     * In this case the state must be re-created using application specific recovery/failover logic.\n+     * In this case the state must be re-created using application specific recovery/fail-over logic.\n      * Do not commit lazily if such recovery is not possible.\n      * This call does not blocks until write to underlying storage is confirmed if lazyWrite is true.\n      *\n      * @param txn            transaction to commit.\n      * @param lazyWrite      true if data can be written lazily.\n      * @param skipStoreCheck true if data is not to be reloaded from store.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link StorageMetadataException} If transaction can not be committed.\n      */\n-    void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException;\n+    CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck);", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA3MjU5MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516072591", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-02T15:57:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwNzc1MA=="}], "type": "inlineReview", "revised_code": {"commit": "3046d85c5dc38c736c6326c204ec45c9abd2d1ab", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java\nindex 81255f6e62..2651158dae 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/ChunkMetadataStore.java\n\n@@ -82,9 +82,10 @@ public interface ChunkMetadataStore extends AutoCloseable {\n      * Begins a new transaction.\n      *\n      * @param keysToLock Array of keys to lock for this transaction.\n+     * @param isReadonly Whether transaction is read only or not.\n      * @return Returns a new instance of {@link MetadataTransaction}.\n      */\n-    MetadataTransaction beginTransaction(String... keysToLock);\n+    MetadataTransaction beginTransaction(boolean isReadonly, String... keysToLock);\n \n     /**\n      * Retrieves the metadata for given key.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwOTE5NQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r515209195", "bodyText": "What are you synchronizing this on? Why does it need to be different than keysToLock?", "author": "andreipaduroiu", "createdAt": "2020-10-30T16:05:58Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * A scheduler utility that implements pattern similar to Multiple Readers - Single Writer pattern.\n+ */\n+public class MultiKeyReaderWriterScheduler {\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    @GuardedBy(\"keyToDataMap\")\n+    private final HashMap<String, SchedulerData> keyToDataMap = new HashMap<>();\n+\n+    /**\n+     * Scheduler data for each key.\n+     */\n+    private static class SchedulerData {\n+        int count;\n+        CompletableFuture blockingFuture = CompletableFuture.completedFuture(null);\n+        ArrayList<CompletableFuture> readerFutures = new ArrayList<>();\n+    }\n+\n+    /**\n+     * Represents a lock.\n+     */\n+    @RequiredArgsConstructor\n+    static class MultiKeyReaderWriterAsyncLock {\n+        /**\n+         * Keys to synchronize on.\n+         */\n+        @Getter\n+        private final String[] keys;\n+\n+        /**\n+         * Indicates whether the lock is a reader lock or a writer lock.\n+         */\n+        @Getter\n+        private final boolean isReadonly;\n+\n+        /**\n+         * Reference to the scheduler.\n+         */\n+        private final MultiKeyReaderWriterScheduler scheduler;\n+\n+        /**\n+         * The future is completed when all keys for this lock become available.\n+         */\n+        private CompletableFuture<Void> readyFuture;\n+\n+        /**\n+         * The future which is completed when lock is released.\n+         */\n+        @Getter\n+        private final CompletableFuture<Void> doneFuture = new CompletableFuture<>();\n+\n+        /**\n+         * Returns a CompletableFuture that will be completed when the lock is obtained.\n+         * @return CompletableFuture which will be complete when the lock is obtained.\n+         */\n+        CompletableFuture<Void> lock() {\n+            if (isReadonly) {\n+                return scheduler.scheduleForRead(this);\n+            } else {\n+                return scheduler.scheduleForWrite(this);\n+            }\n+        }\n+\n+        /**\n+         * Releases the lock.\n+         */\n+        void unlock() {\n+            scheduler.release(this);\n+        }\n+    }\n+\n+    /**\n+     * Adds a reference for the key.\n+     */\n+    private SchedulerData addReference(String key) {\n+        synchronized (keyToDataMap) {\n+            SchedulerData schedulerData = keyToDataMap.get(key);\n+            // Add if this is a new key.\n+            if (null == schedulerData) {\n+                schedulerData = new SchedulerData();\n+                keyToDataMap.put(key, schedulerData);\n+            }\n+            // Increment ref count.\n+            schedulerData.count++;\n+            return schedulerData;\n+        }\n+    }\n+\n+    /**\n+     * Releases a reference for the key.\n+     */\n+    private void releaseReference(String key) {\n+        synchronized (keyToDataMap) {\n+            SchedulerData schedulerData = keyToDataMap.get(key);\n+            // Decrement ref count.\n+            schedulerData.count--;\n+            // clean up if required.\n+            if (0 == schedulerData.count) {\n+                keyToDataMap.remove(key);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Gets a read lock over given set of keys.\n+     */\n+    MultiKeyReaderWriterAsyncLock getReadLock(String[] keys) {\n+        return new MultiKeyReaderWriterAsyncLock(keys, true, this);\n+    }\n+\n+    /**\n+     * Gets a write lock over given set of keys.\n+     */\n+    MultiKeyReaderWriterAsyncLock getWriteLock(String[] keys) {\n+        return new MultiKeyReaderWriterAsyncLock(keys, false, this);\n+    }\n+\n+    /**\n+     * Schedules the lock for read.\n+     */\n+    private synchronized CompletableFuture<Void> scheduleForRead(MultiKeyReaderWriterAsyncLock lock) {", "originalCommit": "c6be777f67dd855512f0bdfbf4a21e69c2939104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjA4MDc4MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r516080781", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-02T16:09:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIwOTE5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\nindex c47d267f50..b7f4ce8b7e 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/MultiKeyReaderWriterScheduler.java\n\n@@ -9,6 +9,7 @@\n  */\n package io.pravega.segmentstore.storage.metadata;\n \n+import io.pravega.common.concurrent.Futures;\n import lombok.Getter;\n import lombok.RequiredArgsConstructor;\n import lombok.val;\n"}}, {"oid": "a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "url": "https://github.com/pravega/pravega/commit/a8fa2cc062a2076a0e42590fc5b2bbda40306f95", "message": "Issue 5067: (SLTS) - Address review comments\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-30T19:21:58Z", "type": "commit"}, {"oid": "33c45b5fed370bdc9723ba6a8bf0aeb8fc114ba1", "url": "https://github.com/pravega/pravega/commit/33c45b5fed370bdc9723ba6a8bf0aeb8fc114ba1", "message": "Issue 5067: (SLTS) - Code clean up. Remove/rename references to old names StorageManager and ChunkStorageProvider.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-30T22:14:08Z", "type": "commit"}, {"oid": "ca3cc947fa9a5051b397e0e9c305f2481e2ffcaa", "url": "https://github.com/pravega/pravega/commit/ca3cc947fa9a5051b397e0e9c305f2481e2ffcaa", "message": "Issue 5067: (SLTS) - Keep only single constructor for ChunkedSegmentStorage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-10-31T00:06:52Z", "type": "commit"}, {"oid": "3d091788890883720b2d9ce81830f3b63e2be8df", "url": "https://github.com/pravega/pravega/commit/3d091788890883720b2d9ce81830f3b63e2be8df", "message": "Issue 5067: (SLTS) - More code cleanup.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-02T17:02:48Z", "type": "commit"}, {"oid": "88aedf6d24adf406e2fb8fb0a0e7655a44edfb64", "url": "https://github.com/pravega/pravega/commit/88aedf6d24adf406e2fb8fb0a0e7655a44edfb64", "message": "Issue 5067: (SLTS) - Remove separate global self check config.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-03T19:35:44Z", "type": "commit"}, {"oid": "c0e6d46571d0587f612b2fcc5ba7c73ef568cb32", "url": "https://github.com/pravega/pravega/commit/c0e6d46571d0587f612b2fcc5ba7c73ef568cb32", "message": "Issue 5067: (SLTS) - Bug fixes.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-05T03:09:55Z", "type": "commit"}, {"oid": "38d8555180cb0817ada7e00278e2238baaa75a77", "url": "https://github.com/pravega/pravega/commit/38d8555180cb0817ada7e00278e2238baaa75a77", "message": "Issue 5067: (SLTS) - Use MultiKeySequentialProcessor.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-05T15:51:01Z", "type": "commit"}, {"oid": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "url": "https://github.com/pravega/pravega/commit/a20fa7dac8368d64152b32f47aba6f5d675401c6", "message": "Merge branch 'master' of https://github.com/pravega/pravega into issue-5067-make-slts-api-async\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>\n\n# Conflicts:\n#\tsegmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\n#\tsegmentstore/storage/src/test/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStoreMockTests.java", "committedDate": "2020-11-05T17:20:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1ODc5Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518458793", "bodyText": "debug for both of these. We only need them for debugging; otherwise we will pollute the logs every time we boot up the container for your average user.", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:50:08Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -190,21 +206,21 @@ private MetadataStore createMetadataStore() {\n      *\n      * @throws Exception\n      */\n-    private void initializeStorage() throws Exception {\n+    private CompletableFuture<Void> initializeStorage() throws Exception {\n+        log.info(\"{}: Storage initialization started.\", this.traceObjectId);", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MTQ5NQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520161495", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1ODc5Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\nindex babd549018..bc18c0b772 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n\n@@ -207,18 +207,14 @@ class StreamSegmentContainer extends AbstractService implements SegmentContainer\n      * @throws Exception\n      */\n     private CompletableFuture<Void> initializeStorage() throws Exception {\n-        log.info(\"{}: Storage initialization started.\", this.traceObjectId);\n+        log.info(\"{}: Initializing storage.\", this.traceObjectId);\n         this.storage.initialize(this.metadata.getContainerEpoch());\n \n         if (this.storage instanceof ChunkedSegmentStorage) {\n             ChunkedSegmentStorage chunkedStorage = (ChunkedSegmentStorage) this.storage;\n \n             // Bootstrap\n-            return chunkedStorage.bootstrap()\n-                    .thenApplyAsync( v -> {\n-                        log.info(\"{}: Storage initialization done.\", this.traceObjectId);\n-                        return null;\n-                    }, this.executor);\n+            return chunkedStorage.bootstrap();\n         }\n         return CompletableFuture.completedFuture(null);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1ODg0OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518458849", "bodyText": "thenRunAsync", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:50:21Z", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -190,21 +206,21 @@ private MetadataStore createMetadataStore() {\n      *\n      * @throws Exception\n      */\n-    private void initializeStorage() throws Exception {\n+    private CompletableFuture<Void> initializeStorage() throws Exception {\n+        log.info(\"{}: Storage initialization started.\", this.traceObjectId);\n         this.storage.initialize(this.metadata.getContainerEpoch());\n \n         if (this.storage instanceof ChunkedSegmentStorage) {\n             ChunkedSegmentStorage chunkedStorage = (ChunkedSegmentStorage) this.storage;\n \n-            // Initialize storage metadata table segment\n-            ContainerTableExtension tableExtension = getExtension(ContainerTableExtension.class);\n-            String s = NameUtils.getStorageMetadataSegmentName(this.metadata.getContainerId());\n-\n-            val metadata = new TableBasedMetadataStore(s, tableExtension);\n-\n             // Bootstrap\n-            chunkedStorage.bootstrap(this.metadata.getContainerId(), metadata);\n+            return chunkedStorage.bootstrap()\n+                    .thenApplyAsync( v -> {", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1OTMzMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518459332", "bodyText": "Alternatively you can delete this whole callback and do a simple log.debug at line 304, saying \"Initializing Metadata Store\". That will imply both of these and it won't look like we're over-logging in some areas while neglecting others.", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:51:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1ODg0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MTU2OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520161569", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:28:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1ODg0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\nindex babd549018..bc18c0b772 100644\n--- a/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n+++ b/segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java\n\n@@ -207,18 +207,14 @@ class StreamSegmentContainer extends AbstractService implements SegmentContainer\n      * @throws Exception\n      */\n     private CompletableFuture<Void> initializeStorage() throws Exception {\n-        log.info(\"{}: Storage initialization started.\", this.traceObjectId);\n+        log.info(\"{}: Initializing storage.\", this.traceObjectId);\n         this.storage.initialize(this.metadata.getContainerEpoch());\n \n         if (this.storage instanceof ChunkedSegmentStorage) {\n             ChunkedSegmentStorage chunkedStorage = (ChunkedSegmentStorage) this.storage;\n \n             // Bootstrap\n-            return chunkedStorage.bootstrap()\n-                    .thenApplyAsync( v -> {\n-                        log.info(\"{}: Storage initialization done.\", this.traceObjectId);\n-                        return null;\n-                    }, this.executor);\n+            return chunkedStorage.bootstrap();\n         }\n         return CompletableFuture.completedFuture(null);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1OTU1OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518459558", "bodyText": "What exactly is a simple storage adapter?", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:52:45Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/SimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage;\n+\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadataStore;\n+\n+import java.util.concurrent.Executor;\n+\n+/**\n+ * Defines a Factory for Simple Storage Adapters.", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MjU2OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520162568", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:30:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ1OTU1OA=="}], "type": "inlineReview", "revised_code": {"commit": "3046d85c5dc38c736c6326c204ec45c9abd2d1ab", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/SimpleStorageFactory.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/SimpleStorageFactory.java\nindex 055f896873..ca5252c7c6 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/SimpleStorageFactory.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/SimpleStorageFactory.java\n\n@@ -14,7 +14,7 @@ import io.pravega.segmentstore.storage.metadata.ChunkMetadataStore;\n import java.util.concurrent.Executor;\n \n /**\n- * Defines a Factory for Simple Storage Adapters.\n+ * Defines a Factory that creates an instance of {@link io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage}.\n  */\n public interface SimpleStorageFactory extends StorageFactory {\n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MDUxOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518460518", "bodyText": "Just put this line of code inside the metrics future callback . No need to create yet another callback.\nIf you do that you can even get rid of the if(log.isTraceEnabled())", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:56:00Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java", "diffHunk": "@@ -0,0 +1,650 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.chunklayer;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import com.google.common.base.Strings;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.LoggerHelpers;\n+import io.pravega.common.Timer;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.InputStream;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * Base implementation of {@link ChunkStorage}.\n+ * It implements common functionality that can be used by derived classes.\n+ * Delegates to specific implementations by calling various abstract methods which must be overridden in derived classes.\n+ *\n+ * Below are minimum requirements that any implementation must provide.\n+ * Note that it is the responsibility of storage provider specific implementation to make sure following guarantees are provided even\n+ * though underlying storage may not provide all primitives or guarantees.\n+ * <ul>\n+ * <li>Once an operation is executed and acknowledged as successful then the effects must be permanent and consistent (as opposed to eventually consistent)</li>\n+ * <li>{@link ChunkStorage#create(String)}  and {@link ChunkStorage#delete(ChunkHandle)} are not idempotent.</li>\n+ * <li>{@link ChunkStorage#exists(String)} and {@link ChunkStorage#getInfo(String)} must reflect effects of most recent operation performed.</li>\n+ * </ul>\n+ *\n+ * There are a few different capabilities that ChunkStorage may provide.\n+ * <ul>\n+ * <li> Does {@link ChunkStorage} support appending to existing chunks?\n+ * This is indicated by {@link ChunkStorage#supportsAppend()}. For example S3 compatible Chunk Storage this would return false. </li>\n+ * <li> Does {@link ChunkStorage}  support for concatenating chunks? This is indicated by {@link ChunkStorage#supportsConcat()}.\n+ * If this is true then concat operation concat will be invoked otherwise append functionality is invoked.</li>\n+ * <li>In addition {@link ChunkStorage} may provide ability to truncate chunks at given offsets (either at front end or at tail end). This is indicated by {@link ChunkStorage#supportsTruncation()}. </li>\n+ * </ul>\n+ * There are some obvious constraints - If ChunkStorage supports concat but not natively then it must support append .\n+ *\n+ * For concats, {@link ChunkStorage} supports both native and append, ChunkedSegmentStorage will invoke appropriate method depending on size of target and source chunks. (Eg. ECS)\n+ *\n+ * The implementations in this repository are tested using following test suites.\n+ * <ul>\n+ * <li>SimpleStorageTests</li>\n+ * <li>ChunkedRollingStorageTests</li>\n+ * <li>ChunkStorageTests</li>\n+ * <li>SystemJournalTests</li>\n+ * </ul>\n+ */\n+@Slf4j\n+@Beta\n+public abstract class AsyncBaseChunkStorage implements ChunkStorage {\n+\n+    private final AtomicBoolean closed;\n+\n+    private final Executor executor;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param executor  An Executor for async operations.\n+     */\n+    public AsyncBaseChunkStorage(Executor executor) {\n+        this.closed = new AtomicBoolean(false);\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports truncate operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsTruncation();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports append operation on chunks.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsAppend();\n+\n+    /**\n+     * Gets a value indicating whether this Storage implementation supports merge operation either natively or through appends.\n+     *\n+     * @return True or false.\n+     */\n+    @Override\n+    abstract public boolean supportsConcat();\n+\n+    /**\n+     * Determines whether named file/object exists in underlying storage.\n+     *\n+     * @param chunkName Name of the chunk to check.\n+     * @return A CompletableFuture that, when completed, will contain True if the object exists, False otherwise.\n+     */\n+    @Override\n+    final public CompletableFuture<Boolean> exists(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        val traceId = LoggerHelpers.traceEnter(log, \"exists\", chunkName);\n+        // Call concrete implementation.\n+        val returnFuture = checkExistsAsync(chunkName);\n+        if (log.isTraceEnabled()) {\n+            returnFuture.thenAcceptAsync(retValue -> LoggerHelpers.traceLeave(log, \"exists\", traceId, chunkName), executor);\n+        }\n+\n+        return returnFuture;\n+    }\n+\n+    /**\n+     * Creates a new chunk.\n+     *\n+     * @param chunkName Name of the chunk to create.\n+     * @return A CompletableFuture that, when completed, will contain a writable handle for the recently created chunk.\n+     * If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     * {@link ChunkStorageException} In case of I/O related exceptions.\n+     */\n+    @Override\n+    final public CompletableFuture<ChunkHandle> create(String chunkName) {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        // Validate parameters\n+        checkChunkName(chunkName);\n+\n+        val traceId = LoggerHelpers.traceEnter(log, \"create\", chunkName);\n+        val timer = new Timer();\n+\n+        // Call concrete implementation.\n+        val returnFuture = doCreateAsync(chunkName);\n+        val metricsFuture = returnFuture.thenAcceptAsync(handle -> {\n+            // Record metrics.\n+            val elapsed = timer.getElapsed();\n+            ChunkStorageMetrics.CREATE_LATENCY.reportSuccessEvent(elapsed);\n+            ChunkStorageMetrics.CREATE_COUNT.inc();\n+            log.debug(\"Create - chunk={}, latency={}.\", chunkName, elapsed.toMillis());\n+        }, executor);\n+        if (log.isTraceEnabled()) {", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MDU4MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518460581", "bodyText": "Same everywhere below.", "author": "andreipaduroiu", "createdAt": "2020-11-06T00:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MDUxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MTIwMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520161202", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:27:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MDUxOA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\nindex 719fa4caa2..b678470a6d 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n\n@@ -142,16 +142,16 @@ public abstract class AsyncBaseChunkStorage implements ChunkStorage {\n \n         // Call concrete implementation.\n         val returnFuture = doCreateAsync(chunkName);\n-        val metricsFuture = returnFuture.thenAcceptAsync(handle -> {\n+        returnFuture.thenAcceptAsync(handle -> {\n             // Record metrics.\n             val elapsed = timer.getElapsed();\n             ChunkStorageMetrics.CREATE_LATENCY.reportSuccessEvent(elapsed);\n             ChunkStorageMetrics.CREATE_COUNT.inc();\n             log.debug(\"Create - chunk={}, latency={}.\", chunkName, elapsed.toMillis());\n+            if (log.isTraceEnabled()) {\n+                LoggerHelpers.traceLeave(log, \"create\", traceId, chunkName);\n+            }\n         }, executor);\n-        if (log.isTraceEnabled()) {\n-            metricsFuture.thenAcceptAsync(v -> LoggerHelpers.traceLeave(log, \"create\", traceId, chunkName), executor);\n-        }\n         return returnFuture;\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MTg2OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518461869", "bodyText": "You can rewrite this as\nif(fenced.get()){\nretval = Futures.failedFuture(new StorageMetadataWritesFencedOutException(...)) ;\n}else{\n .. put the `thenComposeAsync` body in here\n}", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:00:37Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjExNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518462114", "bodyText": "This may require a bit more fiddling around with that whenComplete, but at least it should look a bit better.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MTg2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjMxOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518462318", "bodyText": "runAsync if you do not take any args and not return anything. Looks prettier.\nPlease sweep your code to use thenRunAsync, thenAcceptAsync or thenApplyAsync as appropriate.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:02:08Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MTA0MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520161041", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:27:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjMxOA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjU5Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518462597", "bodyText": "Can you please put a message with all these exceptions. If they fire and you see a stack in the logs you won't know where it came from. Put as much info in these messages as you can. It WILL help you in debugging these in the field.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:03:01Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NjA1MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520186050", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-11-09T23:27:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjU5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjczOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518462738", "bodyText": "Where is step 1?", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:03:25Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MzA2MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520163060", "bodyText": "above line 285", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:31:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjczOA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjgwNg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518462806", "bodyText": "formatting please", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:03:38Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MzE2Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520163162", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:31:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MjgwNg=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2Mjk2MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518462960", "bodyText": "You can delete this line. IT will fall through to the end.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:04:15Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzE1OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518463159", "bodyText": "Messages. Please do this everywhere else in your code.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:04:52Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTkyOQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520185929", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-11-09T23:26:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzE1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzM3NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518463374", "bodyText": "You can either declare this as throws or use @SneakyThrows(StorageMetadataVersionMismatchException.class) on the method to avoid having do to this ugly wrapping.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:05:36Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzQ4Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518463483", "bodyText": "Yes. Why, oh why are we here?\n(How is this useful in a production log?)", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:06:01Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(\n+                            String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n+                                    key, dataFromBuffer.getVersion(), txnData.get(key).getVersion())));\n+                }\n+\n+                // Pin it if it is already pinned.\n+                transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n \n-            // If we reach here then it means transaction is safe to commit.\n-            // Step 4: Insert\n-            long committedVersion = version.incrementAndGet();\n-            HashMap<String, TransactionData> toAdd = new HashMap<String, TransactionData>();\n-            for (String key : modifiedKeys) {\n-                TransactionData data = txnData.get(key);\n-                data.setVersion(committedVersion);\n-                toAdd.put(key, data);\n+                // Set the database object.\n+                transactionData.setDbObject(dataFromBuffer.getDbObject());\n+            } else {\n+                Preconditions.checkState(entry.getValue().isPinned(), \"Why are we here??\");", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MDcwOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520160708", "bodyText": ":) fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:26:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzQ4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzY2NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518463664", "bodyText": "count ?", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:06:42Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(\n+                            String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n+                                    key, dataFromBuffer.getVersion(), txnData.get(key).getVersion())));\n+                }\n+\n+                // Pin it if it is already pinned.\n+                transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n \n-            // If we reach here then it means transaction is safe to commit.\n-            // Step 4: Insert\n-            long committedVersion = version.incrementAndGet();\n-            HashMap<String, TransactionData> toAdd = new HashMap<String, TransactionData>();\n-            for (String key : modifiedKeys) {\n-                TransactionData data = txnData.get(key);\n-                data.setVersion(committedVersion);\n-                toAdd.put(key, data);\n+                // Set the database object.\n+                transactionData.setDbObject(dataFromBuffer.getDbObject());\n+            } else {\n+                Preconditions.checkState(entry.getValue().isPinned(), \"Why are we here??\");\n             }\n-            bufferedTxnData.putAll(toAdd);\n         }\n+    }\n \n-        //  Step 5 : evict if required.\n-        if (bufferedTxnData.size() > maxEntriesInTxnBuffer) {\n-            bufferedTxnData.entrySet().removeIf(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned());\n+    /**\n+     * Evict entries if needed.\n+     * Only evict keys that are persisted, not pinned or active.\n+     */\n+    private CompletableFuture<Void> evictIfNeeded() {\n+        if (isEvictionRunning.compareAndSet(false, true)) {\n+            val limit = 1 + maxEntriesInTxnBuffer / CACHE_EVICTION_RATIO;\n+            if (bufferCount.get() > maxEntriesInTxnBuffer) {\n+                val toEvict = bufferedTxnData.entrySet().parallelStream()\n+                        .filter(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned()\n+                                && !activeKeys.contains(entry.getKey()))\n+                        .map(Map.Entry::getKey)\n+                        .limit(limit)\n+                        .collect(Collectors.toList());\n+                int i = 0;", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTgwNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520185804", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T23:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzY2NA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzczNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518463734", "bodyText": "Maybe log the number of evicted entries?", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:06:54Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(\n+                            String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n+                                    key, dataFromBuffer.getVersion(), txnData.get(key).getVersion())));\n+                }\n+\n+                // Pin it if it is already pinned.\n+                transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n \n-            // If we reach here then it means transaction is safe to commit.\n-            // Step 4: Insert\n-            long committedVersion = version.incrementAndGet();\n-            HashMap<String, TransactionData> toAdd = new HashMap<String, TransactionData>();\n-            for (String key : modifiedKeys) {\n-                TransactionData data = txnData.get(key);\n-                data.setVersion(committedVersion);\n-                toAdd.put(key, data);\n+                // Set the database object.\n+                transactionData.setDbObject(dataFromBuffer.getDbObject());\n+            } else {\n+                Preconditions.checkState(entry.getValue().isPinned(), \"Why are we here??\");\n             }\n-            bufferedTxnData.putAll(toAdd);\n         }\n+    }\n \n-        //  Step 5 : evict if required.\n-        if (bufferedTxnData.size() > maxEntriesInTxnBuffer) {\n-            bufferedTxnData.entrySet().removeIf(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned());\n+    /**\n+     * Evict entries if needed.\n+     * Only evict keys that are persisted, not pinned or active.\n+     */\n+    private CompletableFuture<Void> evictIfNeeded() {\n+        if (isEvictionRunning.compareAndSet(false, true)) {\n+            val limit = 1 + maxEntriesInTxnBuffer / CACHE_EVICTION_RATIO;\n+            if (bufferCount.get() > maxEntriesInTxnBuffer) {\n+                val toEvict = bufferedTxnData.entrySet().parallelStream()\n+                        .filter(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned()\n+                                && !activeKeys.contains(entry.getKey()))\n+                        .map(Map.Entry::getKey)\n+                        .limit(limit)\n+                        .collect(Collectors.toList());\n+                int i = 0;\n+                for (val key : toEvict) {\n+                    // synchronize so that we don't accidentally delete a key that becomes active after check here.\n+                    synchronized (evictionLock) {\n+                        if (0 == activeKeys.count(key)) {\n+                            // Synchronization prevents error when key becomes active between the check and remove.\n+                            // Move the key to cache\n+                            cache.put(key, bufferedTxnData.get(key));\n+                            // Remove from buffer.\n+                            bufferedTxnData.remove(key);\n+                            i++;\n+                        }\n+                    }\n+                }\n+                bufferCount.addAndGet(-1 * i);\n+            }\n+            isEvictionRunning.set(false);\n+            log.debug(\"Entries evicted from transaction buffer.\");", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE4NTc3MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520185770", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T23:26:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2MzczNA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2Mzg2OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518463868", "bodyText": "Why do you return a CompletableFuture? Make your method return void if it's not async.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:07:23Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(\n+                            String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n+                                    key, dataFromBuffer.getVersion(), txnData.get(key).getVersion())));\n+                }\n+\n+                // Pin it if it is already pinned.\n+                transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n \n-            // If we reach here then it means transaction is safe to commit.\n-            // Step 4: Insert\n-            long committedVersion = version.incrementAndGet();\n-            HashMap<String, TransactionData> toAdd = new HashMap<String, TransactionData>();\n-            for (String key : modifiedKeys) {\n-                TransactionData data = txnData.get(key);\n-                data.setVersion(committedVersion);\n-                toAdd.put(key, data);\n+                // Set the database object.\n+                transactionData.setDbObject(dataFromBuffer.getDbObject());\n+            } else {\n+                Preconditions.checkState(entry.getValue().isPinned(), \"Why are we here??\");\n             }\n-            bufferedTxnData.putAll(toAdd);\n         }\n+    }\n \n-        //  Step 5 : evict if required.\n-        if (bufferedTxnData.size() > maxEntriesInTxnBuffer) {\n-            bufferedTxnData.entrySet().removeIf(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned());\n+    /**\n+     * Evict entries if needed.\n+     * Only evict keys that are persisted, not pinned or active.\n+     */\n+    private CompletableFuture<Void> evictIfNeeded() {\n+        if (isEvictionRunning.compareAndSet(false, true)) {\n+            val limit = 1 + maxEntriesInTxnBuffer / CACHE_EVICTION_RATIO;\n+            if (bufferCount.get() > maxEntriesInTxnBuffer) {\n+                val toEvict = bufferedTxnData.entrySet().parallelStream()\n+                        .filter(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned()\n+                                && !activeKeys.contains(entry.getKey()))\n+                        .map(Map.Entry::getKey)\n+                        .limit(limit)\n+                        .collect(Collectors.toList());\n+                int i = 0;\n+                for (val key : toEvict) {\n+                    // synchronize so that we don't accidentally delete a key that becomes active after check here.\n+                    synchronized (evictionLock) {\n+                        if (0 == activeKeys.count(key)) {\n+                            // Synchronization prevents error when key becomes active between the check and remove.\n+                            // Move the key to cache\n+                            cache.put(key, bufferedTxnData.get(key));\n+                            // Remove from buffer.\n+                            bufferedTxnData.remove(key);\n+                            i++;\n+                        }\n+                    }\n+                }\n+                bufferCount.addAndGet(-1 * i);\n+            }\n+            isEvictionRunning.set(false);\n+            log.debug(\"Entries evicted from transaction buffer.\");\n         }\n-\n-        //  Step 6: finally clear\n-        txnData.clear();\n+        return CompletableFuture.completedFuture(null);", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MDM4Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520160383", "bodyText": "fixed", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:25:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2Mzg2OA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NDAxMw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518464013", "bodyText": "I assume that some subclass will override this?", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:07:55Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(\n+                            String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n+                                    key, dataFromBuffer.getVersion(), txnData.get(key).getVersion())));\n+                }\n+\n+                // Pin it if it is already pinned.\n+                transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n \n-            // If we reach here then it means transaction is safe to commit.\n-            // Step 4: Insert\n-            long committedVersion = version.incrementAndGet();\n-            HashMap<String, TransactionData> toAdd = new HashMap<String, TransactionData>();\n-            for (String key : modifiedKeys) {\n-                TransactionData data = txnData.get(key);\n-                data.setVersion(committedVersion);\n-                toAdd.put(key, data);\n+                // Set the database object.\n+                transactionData.setDbObject(dataFromBuffer.getDbObject());\n+            } else {\n+                Preconditions.checkState(entry.getValue().isPinned(), \"Why are we here??\");\n             }\n-            bufferedTxnData.putAll(toAdd);\n         }\n+    }\n \n-        //  Step 5 : evict if required.\n-        if (bufferedTxnData.size() > maxEntriesInTxnBuffer) {\n-            bufferedTxnData.entrySet().removeIf(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned());\n+    /**\n+     * Evict entries if needed.\n+     * Only evict keys that are persisted, not pinned or active.\n+     */\n+    private CompletableFuture<Void> evictIfNeeded() {\n+        if (isEvictionRunning.compareAndSet(false, true)) {\n+            val limit = 1 + maxEntriesInTxnBuffer / CACHE_EVICTION_RATIO;\n+            if (bufferCount.get() > maxEntriesInTxnBuffer) {\n+                val toEvict = bufferedTxnData.entrySet().parallelStream()\n+                        .filter(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned()\n+                                && !activeKeys.contains(entry.getKey()))\n+                        .map(Map.Entry::getKey)\n+                        .limit(limit)\n+                        .collect(Collectors.toList());\n+                int i = 0;\n+                for (val key : toEvict) {\n+                    // synchronize so that we don't accidentally delete a key that becomes active after check here.\n+                    synchronized (evictionLock) {\n+                        if (0 == activeKeys.count(key)) {\n+                            // Synchronization prevents error when key becomes active between the check and remove.\n+                            // Move the key to cache\n+                            cache.put(key, bufferedTxnData.get(key));\n+                            // Remove from buffer.\n+                            bufferedTxnData.remove(key);\n+                            i++;\n+                        }\n+                    }\n+                }\n+                bufferCount.addAndGet(-1 * i);\n+            }\n+            isEvictionRunning.set(false);\n+            log.debug(\"Entries evicted from transaction buffer.\");\n         }\n-\n-        //  Step 6: finally clear\n-        txnData.clear();\n+        return CompletableFuture.completedFuture(null);\n     }\n \n     /**\n      * Aborts given transaction.\n      *\n      * @param txn transaction to abort.\n-     * @throws StorageMetadataException If there are any errors.\n+     *            throws StorageMetadataException If there are any errors.\n      */\n-    public void abort(MetadataTransaction txn) throws StorageMetadataException {\n+    public CompletableFuture<Void> abort(MetadataTransaction txn) {\n         // Do nothing\n+        return CompletableFuture.completedFuture(null);", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MDI1MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520160251", "bodyText": "yes", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:25:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NDAxMw=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NDM5Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518464392", "bodyText": "Ouch. This String.join will ALWAYS be evaluated even if debug logging is off. Do not do this. Just pass in the collection and the logger will convert that to something nice.\nPlease fix this elsewhere if you did similar things. I see some below.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:09:17Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java", "diffHunk": "@@ -120,295 +139,572 @@\n     /**\n      * Buffer for reading and writing transaction data entries to underlying KV store.\n      * This allows lazy storing and avoiding unnecessary load for recently/frequently updated key value pairs.\n+     * Note that entries in this buffer should not be evicted while transaction using them are in flight.\n      */\n-    @GuardedBy(\"lock\")\n     private final ConcurrentHashMap<String, TransactionData> bufferedTxnData;\n \n+    /**\n+     * Set of active records from commits that are in-flight. These records should not be evicted until the active commits finish.\n+     */\n+    private final ConcurrentHashMultiset<String> activeKeys;\n+\n+    /**\n+     * Cache for reading and writing transaction data entries to underlying KV store.\n+     */\n+    private final Cache<String, TransactionData> cache;\n+\n+    /**\n+     * {@link MultiKeyReaderWriterScheduler} instance.\n+     */\n+    private final MultiKeyReaderWriterScheduler scheduler = new MultiKeyReaderWriterScheduler();\n+\n+    /**\n+     * Storage executor object.\n+     */\n+    @Getter(AccessLevel.PROTECTED)\n+    private final Executor executor;\n+\n     /**\n      * Maximum number of metadata entries to keep in recent transaction buffer.\n      */\n     @Getter\n     @Setter\n     int maxEntriesInTxnBuffer = MAX_ENTRIES_IN_TXN_BUFFER;\n \n+    /**\n+     * Maximum number of metadata entries to keep in recent transaction buffer.\n+     */\n+    @Getter\n+    @Setter\n+    int maxEntriesInCache = MAX_ENTRIES_IN_CACHE;\n+\n+    /**\n+     * Keep count of records in buffer. ConcurrentHashMap.size() is an expensive operation.\n+     */\n+    private final AtomicInteger bufferCount = new AtomicInteger(0);\n+\n+    /**\n+     * Flag to keep track of whether the eviction is currently running.\n+     */\n+    private final AtomicBoolean isEvictionRunning = new AtomicBoolean();\n+\n+    /**\n+     * Lock object to synchronize on during eviction.\n+     */\n+    private final Object evictionLock = new Object();\n+\n     /**\n      * Constructs a BaseMetadataStore object.\n+     *\n+     * @param executor Executor to use for async operations.\n      */\n-    public BaseMetadataStore() {\n+    public BaseMetadataStore(Executor executor) {\n         version = new AtomicLong(System.currentTimeMillis()); // Start with unique number.\n         fenced = new AtomicBoolean(false);\n         bufferedTxnData = new ConcurrentHashMap<>(); // Don't think we need anything fancy here. But we'll measure and see.\n+        activeKeys = ConcurrentHashMultiset.create();\n+        cache = CacheBuilder.newBuilder()\n+                .maximumSize(maxEntriesInCache)\n+                .build();\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n     }\n \n     /**\n      * Begins a new transaction.\n      *\n+     * @param keysToLock Array of keys to lock for this transaction.\n      * @return Returns a new instance of MetadataTransaction.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    public MetadataTransaction beginTransaction() throws StorageMetadataException {\n-        // Each transaction gets a unique number which is monotinically increasing.\n-        return new MetadataTransaction(this, version.incrementAndGet());\n+    public MetadataTransaction beginTransaction(String... keysToLock) {\n+        // Each transaction gets a unique number which is monotonically increasing.\n+        return new MetadataTransaction(this, version.incrementAndGet(), keysToLock);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite) throws StorageMetadataException {\n-        commit(txn, lazyWrite, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite) {\n+        return commit(txn, lazyWrite, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn transaction to commit.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn) throws StorageMetadataException {\n-        commit(txn, false, false);\n+    public CompletableFuture<Void> commit(MetadataTransaction txn) {\n+        return commit(txn, false, false);\n     }\n \n     /**\n      * Commits given transaction.\n      *\n      * @param txn       transaction to commit.\n      * @param lazyWrite true if data can be written lazily.\n-     * @throws StorageMetadataException StorageMetadataVersionMismatchException if transaction can not be commited.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed.\n+     * If the operation failed, it will contain the cause of the failure. Notable exceptions:\n+     * {@link StorageMetadataException} if transaction can not be committed.\n      */\n     @Override\n-    public void commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) throws StorageMetadataException {\n+    public CompletableFuture<Void> commit(MetadataTransaction txn, boolean lazyWrite, boolean skipStoreCheck) {\n         Preconditions.checkArgument(null != txn);\n-        if (fenced.get()) {\n-            throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\");\n-        }\n-\n-        Map<String, TransactionData> txnData = txn.getData();\n+        val txnData = txn.getData();\n+\n+        val modifiedKeys = new ArrayList<String>();\n+        val modifiedValues = new ArrayList<TransactionData>();\n+        val t = new Timer();\n+        val retValue = CompletableFuture.runAsync(() -> {\n+            if (fenced.get()) {\n+                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+            }\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Mark keys in transaction as active to prevent their eviction.\n+                    txn.getData().keySet().forEach(this::addToActiveKeySet);\n+\n+                    // Acquire a write lock over segment.\n+                    val tLock = new Timer();\n+                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n+                    return writeLock.lock()\n+                            .thenComposeAsync(v0 -> {\n+                                // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n+                                // This step is kind of thread safe\n+                                val elapsed = tLock.getElapsed();\n+                                WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n+                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                return loadMissingKeys(txn, skipStoreCheck, txnData);\n+                            }, executor)\n+                            .thenComposeAsync(v1 -> {\n+                                // This check needs to be atomic, with absolutely no possibility of re-entry\n+                                return performCommit(txn, lazyWrite, txnData, modifiedKeys, modifiedValues);\n+                            }, executor)\n+                            .whenCompleteAsync((v2, ex) -> writeLock.unlock(), executor);\n+                }, executor)\n+                .thenRunAsync(() -> {\n+                    //  Step 5 : evict if required.\n+                    txn.setCommitted();\n+                    txnData.clear();\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    // Remove keys from active set.\n+                    txn.getData().keySet().forEach(this::removeFromActiveKeySet);\n+                    COMMIT_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+\n+        // Trigger evict\n+        retValue.thenComposeAsync(v4 -> {\n+            //  Step 6 : evict if required.\n+            return evictIfNeeded();\n+        }, executor);\n \n-        ArrayList<String> modifiedKeys = new ArrayList<>();\n-        ArrayList<TransactionData> modifiedValues = new ArrayList<>();\n+        return retValue;\n+    }\n \n-        // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-        // This step is kind of thread safe\n+    /**\n+     * Loads missing keys.\n+     */\n+    private CompletableFuture<Void> loadMissingKeys(MetadataTransaction txn, boolean skipStoreCheck, Map<String, TransactionData> txnData) {\n+        val loadFutures = new ArrayList<CompletableFuture<TransactionData>>();\n         for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-            String key = entry.getKey();\n+            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+            val key = entry.getKey();\n             if (skipStoreCheck || entry.getValue().isPinned()) {\n                 log.trace(\"Skipping loading key from the store key = {}\", key);\n             } else {\n                 // This check is safe to be outside the lock\n-                if (!bufferedTxnData.containsKey(key)) {\n-                    loadFromStore(key);\n+                val dataFromBuffer = bufferedTxnData.get(key);\n+                if (null == dataFromBuffer) {\n+                    loadFutures.add(loadFromStore(txn, key, true));\n                 }\n             }\n         }\n-        // Step 2 : Check whether transaction is safe to commit.\n-        // This check needs to be atomic, with absolutely no possibility of re-entry\n-        synchronized (lock) {\n-            for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n-                String key = entry.getKey();\n-                val transactionData = entry.getValue();\n-                Preconditions.checkState(null != transactionData.getKey());\n-\n-                // See if this entry was modified in this transaction.\n-                if (transactionData.getVersion() == txn.getVersion()) {\n-                    modifiedKeys.add(key);\n-                    transactionData.setPersisted(false);\n-                    modifiedValues.add(transactionData);\n-                }\n-                // make sure none of the keys used in this transaction have changed.\n-                TransactionData dataFromBuffer = bufferedTxnData.get(key);\n-                if (null != dataFromBuffer) {\n-                    if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n-                        throw new StorageMetadataVersionMismatchException(\n-                                String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n-                                        key, dataFromBuffer.getVersion(), txnData.get(key).getVersion()));\n+        return Futures.allOf(loadFutures)\n+                .thenApplyAsync(v4 -> {\n+                    // validate everything is alright.\n+                    for (Map.Entry<String, TransactionData> entry : txnData.entrySet()) {\n+                        val dataFromBuffer = bufferedTxnData.get(entry.getKey());\n+                        if (!(entry.getValue().isPinned())) {\n+                            Preconditions.checkState(activeKeys.contains(entry.getKey()));\n+                            Preconditions.checkState(null != dataFromBuffer);\n+                            if (!dataFromBuffer.isPinned()) {\n+                                Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                            }\n+                        }\n                     }\n+                    return null;\n+                }, executor);\n+    }\n \n-                    // Pin it if it is already pinned.\n-                    transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n+    /**\n+     * Performs commit.\n+     */\n+    private CompletableFuture<Void> performCommit(MetadataTransaction txn, boolean lazyWrite, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        return CompletableFuture.runAsync(() -> {\n+            // Step 2 : Check whether transaction is safe to commit.\n+            validateCommit(txn, txnData, modifiedKeys, modifiedValues);\n+        }, executor)\n+                .thenComposeAsync(v -> {\n+                    // Step 3: Commit externally.\n+                    // This operation may call external storage.\n+                    return writeToMetadataStore(lazyWrite, modifiedValues);\n+                }, executor)\n+                .thenComposeAsync(v ->\n+                                executeExternalCommitAction(txn),\n+                        executor)\n+                .thenRunAsync(() -> {\n+                    // If we reach here then it means transaction is safe to commit.\n+                    // Step 4: Update buffer.\n+                    val committedVersion = version.incrementAndGet();\n+                    val toAdd = new HashMap<String, TransactionData>();\n+                    for (String key : modifiedKeys) {\n+                        TransactionData data = txnData.get(key);\n+                        data.setVersion(committedVersion);\n+                        toAdd.put(key, data);\n+                    }\n+                    bufferedTxnData.putAll(toAdd);\n+                    bufferCount.addAndGet(toAdd.size());\n+                }, executor);\n+    }\n \n-                    // Set the database object.\n-                    transactionData.setDbObject(dataFromBuffer.getDbObject());\n-                }\n+    /**\n+     * Writes modified values to the metadata store.\n+     */\n+    private CompletableFuture<Void> writeToMetadataStore(boolean lazyWrite, ArrayList<TransactionData> modifiedValues) {\n+        if (!lazyWrite || (bufferCount.get() > maxEntriesInTxnBuffer)) {\n+            log.trace(\"Persisting all modified keys (except pinned)\");\n+            val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n+            if (toWriteList.size() > 0) {\n+                return writeAll(toWriteList)\n+                        .thenRunAsync(() -> {\n+                            log.trace(\"Done persisting all modified keys\");\n+                            for (val writtenData : toWriteList) {\n+                                // Mark written keys as persisted.\n+                                writtenData.setPersisted(true);\n+                                // Put it in cache.\n+                                cache.put(writtenData.getKey(), writtenData);\n+                            }\n+                        }, executor);\n+            } else {\n+                return CompletableFuture.completedFuture(null);\n             }\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Step 3: Commit externally.\n-            // This operation may call external storage.\n-            if (!lazyWrite || (bufferedTxnData.size() > maxEntriesInTxnBuffer)) {\n-                log.trace(\"Persisting all modified keys (except pinned)\");\n-                val toWriteList = modifiedValues.stream().filter(entry -> !entry.isPinned()).collect(Collectors.toList());\n-                writeAll(toWriteList);\n-                log.trace(\"Done persisting all modified keys\");\n-\n-                // Mark written keys as persisted.\n-                for (val writtenData : toWriteList) {\n-                    writtenData.setPersisted(true);\n-                }\n+    /**\n+     * Executes external commit step.\n+     */\n+    private CompletableFuture<Void> executeExternalCommitAction(MetadataTransaction txn) {\n+        // Execute external commit step.\n+        try {\n+            if (null != txn.getExternalCommitStep()) {\n+                txn.getExternalCommitStep().call();\n             }\n+        } catch (Exception e) {\n+            log.error(\"Exception during execution of external commit step\", e);\n+            throw new CompletionException(new StorageMetadataException(\"Exception during execution of external commit step\", e));\n+        }\n+        return CompletableFuture.completedFuture(null);\n+    }\n \n-            // Execute external commit step.\n-            try {\n-                if (null != txn.getExternalCommitStep()) {\n-                    txn.getExternalCommitStep().call();\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Exception during execution of external commit step\", e);\n-                throw new StorageMetadataException(\"Exception during execution of external commit step\", e);\n+    private void validateCommit(MetadataTransaction txn, Map<String, TransactionData> txnData, ArrayList<String> modifiedKeys, ArrayList<TransactionData> modifiedValues) {\n+        for (val entry : txnData.entrySet()) {\n+            val key = entry.getKey();\n+            val transactionData = entry.getValue();\n+            Preconditions.checkState(null != transactionData.getKey());\n+\n+            // See if this entry was modified in this transaction.\n+            if (transactionData.getVersion() == txn.getVersion()) {\n+                modifiedKeys.add(key);\n+                transactionData.setPersisted(false);\n+                modifiedValues.add(transactionData);\n             }\n+            // make sure none of the keys used in this transaction have changed.\n+            val dataFromBuffer = bufferedTxnData.get(key);\n+            if (null != dataFromBuffer) {\n+                if (!dataFromBuffer.isPinned()) {\n+                    Preconditions.checkState(null != dataFromBuffer.getDbObject());\n+                }\n+                if (dataFromBuffer.getVersion() > transactionData.getVersion()) {\n+                    throw new CompletionException(new StorageMetadataVersionMismatchException(\n+                            String.format(\"Transaction uses stale data. Key version changed key:%s buffer:%s transaction:%s\",\n+                                    key, dataFromBuffer.getVersion(), txnData.get(key).getVersion())));\n+                }\n+\n+                // Pin it if it is already pinned.\n+                transactionData.setPinned(transactionData.isPinned() || dataFromBuffer.isPinned());\n \n-            // If we reach here then it means transaction is safe to commit.\n-            // Step 4: Insert\n-            long committedVersion = version.incrementAndGet();\n-            HashMap<String, TransactionData> toAdd = new HashMap<String, TransactionData>();\n-            for (String key : modifiedKeys) {\n-                TransactionData data = txnData.get(key);\n-                data.setVersion(committedVersion);\n-                toAdd.put(key, data);\n+                // Set the database object.\n+                transactionData.setDbObject(dataFromBuffer.getDbObject());\n+            } else {\n+                Preconditions.checkState(entry.getValue().isPinned(), \"Why are we here??\");\n             }\n-            bufferedTxnData.putAll(toAdd);\n         }\n+    }\n \n-        //  Step 5 : evict if required.\n-        if (bufferedTxnData.size() > maxEntriesInTxnBuffer) {\n-            bufferedTxnData.entrySet().removeIf(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned());\n+    /**\n+     * Evict entries if needed.\n+     * Only evict keys that are persisted, not pinned or active.\n+     */\n+    private CompletableFuture<Void> evictIfNeeded() {\n+        if (isEvictionRunning.compareAndSet(false, true)) {\n+            val limit = 1 + maxEntriesInTxnBuffer / CACHE_EVICTION_RATIO;\n+            if (bufferCount.get() > maxEntriesInTxnBuffer) {\n+                val toEvict = bufferedTxnData.entrySet().parallelStream()\n+                        .filter(entry -> entry.getValue().isPersisted() && !entry.getValue().isPinned()\n+                                && !activeKeys.contains(entry.getKey()))\n+                        .map(Map.Entry::getKey)\n+                        .limit(limit)\n+                        .collect(Collectors.toList());\n+                int i = 0;\n+                for (val key : toEvict) {\n+                    // synchronize so that we don't accidentally delete a key that becomes active after check here.\n+                    synchronized (evictionLock) {\n+                        if (0 == activeKeys.count(key)) {\n+                            // Synchronization prevents error when key becomes active between the check and remove.\n+                            // Move the key to cache\n+                            cache.put(key, bufferedTxnData.get(key));\n+                            // Remove from buffer.\n+                            bufferedTxnData.remove(key);\n+                            i++;\n+                        }\n+                    }\n+                }\n+                bufferCount.addAndGet(-1 * i);\n+            }\n+            isEvictionRunning.set(false);\n+            log.debug(\"Entries evicted from transaction buffer.\");\n         }\n-\n-        //  Step 6: finally clear\n-        txnData.clear();\n+        return CompletableFuture.completedFuture(null);\n     }\n \n     /**\n      * Aborts given transaction.\n      *\n      * @param txn transaction to abort.\n-     * @throws StorageMetadataException If there are any errors.\n+     *            throws StorageMetadataException If there are any errors.\n      */\n-    public void abort(MetadataTransaction txn) throws StorageMetadataException {\n+    public CompletableFuture<Void> abort(MetadataTransaction txn) {\n         // Do nothing\n+        return CompletableFuture.completedFuture(null);\n     }\n \n     /**\n      * Retrieves the metadata for given key.\n      *\n      * @param txn Transaction.\n      * @param key key to use to retrieve metadata.\n-     * @return Metadata for given key. Null if key was not found.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     * @return A CompletableFuture that, when completed, will contain metadata for given key. Null if key was not found.\n+     * @throws CompletionException If the operation failed, it will be completed with the appropriate exception. Notable Exceptions:\n+     *                             {@link StorageMetadataException} Exception related to storage metadata operations.\n      */\n     @Override\n-    public StorageMetadata get(MetadataTransaction txn, String key) throws StorageMetadataException {\n+    public CompletableFuture<StorageMetadata> get(MetadataTransaction txn, String key) {\n         Preconditions.checkArgument(null != txn);\n-        TransactionData dataFromBuffer = null;\n         if (null == key) {\n-            return null;\n+            return CompletableFuture.completedFuture(null);\n         }\n-        StorageMetadata retValue = null;\n+        val t = new Timer();\n+        val txnData = txn.getData();\n \n-        Map<String, TransactionData> txnData = txn.getData();\n+        // Record is found in transaction data itself.\n         TransactionData data = txnData.get(key);\n+        if (null != data) {\n+            GET_LATENCY.reportSuccessEvent(t.getElapsed());\n+            return CompletableFuture.completedFuture(data.getValue());\n+        }\n \n-        // Search in the buffer.\n-        if (null == data) {\n-            synchronized (lock) {\n-                dataFromBuffer = bufferedTxnData.get(key);\n-            }\n-            // If we did not find in buffer then load it from store\n-            if (null == dataFromBuffer) {\n-                // NOTE: This call to read MUST be outside the lock, it is most likely cause re-entry.\n-                loadFromStore(key);\n-                dataFromBuffer = bufferedTxnData.get(key);\n-                Preconditions.checkState(null != dataFromBuffer);\n-            }\n+        // Prevent the key from getting evicted.\n+        addToActiveKeySet(key);\n+\n+        // Try to find it in buffer. Access buffer using reader lock.\n+        val tLock = new Timer();\n+        log.debug(\"Acquiring read lock for {}\", key);\n+        val readLock = scheduler.getReadLock(txn.getKeysToLock());\n+        return readLock.lock()\n+                .thenApplyAsync(v -> {\n+                    val elapsed = tLock.getElapsed();\n+                    READ_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n+                    log.debug(\"Acquired read lock for {}, wait time: {} ms\",\n+                            String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                    return bufferedTxnData.get(key);\n+                }, executor)\n+                .thenApplyAsync(dataFromBuffer -> {\n+                    if (dataFromBuffer != null) {\n+                        // Make sure it is a deep copy.\n+                        val retValue = dataFromBuffer.getValue();\n+                        if (null != retValue) {\n+                            return retValue.deepCopy();\n+                        }\n+                        return null;\n+                    }\n+                    return null;\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> readLock.unlock(), executor)\n+                .thenComposeAsync(retValue -> {\n+                    if (retValue != null) {\n+                        return CompletableFuture.completedFuture(retValue);\n+                    }\n+                    // We did not find it in the buffer either.\n+                    // Try to find it in store.\n+                    return loadFromStore(txn, key, false)\n+                            .thenApplyAsync(TransactionData::getValue, executor);\n+                }, executor)\n+                .whenCompleteAsync((v, ex) -> {\n+                    removeFromActiveKeySet(key);\n+                    GET_LATENCY.reportSuccessEvent(t.getElapsed());\n+                }, executor);\n+    }\n+\n+    private void removeFromActiveKeySet(String key) {\n+        // No need to synchronize as activeKeys is already a ConcurrentHashMultiset.\n+        // In case of any race with eviction logic, the key will simply be evicted next iteration.\n+        // This is not incorrect and the race should be rare.\n+        activeKeys.remove(key);\n+    }\n \n-            if (null != dataFromBuffer && null != dataFromBuffer.getValue()) {\n-                // Make copy.\n-                data = dataFromBuffer.toBuilder()\n-                        .key(key)\n-                        .value(dataFromBuffer.getValue().deepCopy())\n-                        .build();\n-                txnData.put(key, data);\n+    private void addToActiveKeySet(String key) {\n+        // No need to synchronize if the eviction is not running as activeKeys is ConcurrentHashMultiset\n+        if (isEvictionRunning.get()) {\n+            // However this is required when eviction is happening in background because eviction code checks the count\n+            // and should evict key only if the count is zero.\n+            // These two steps are not atomic hence the use of synchronized in this narrow case to prevent race.\n+            synchronized (evictionLock) {\n+                activeKeys.add(key);\n             }\n+        } else {\n+            activeKeys.add(key);\n         }\n+    }\n \n-        if (data != null) {\n-            retValue = data.getValue();\n+    /**\n+     * Loads value from store.\n+     */\n+    private CompletableFuture<TransactionData> loadFromStore(MetadataTransaction txn, String key, boolean isReenterant) {\n+        log.trace(\"Loading key from the store key = {}\", key);\n+        return readFromStore(key)\n+                .thenApplyAsync(this::makeCopyForBuffer, executor)\n+                .thenComposeAsync(copyForBuffer -> {\n+                    Preconditions.checkState(null != copyForBuffer);\n+                    Preconditions.checkState(null != copyForBuffer.getDbObject());\n+                    if (!isReenterant) {\n+                        val t = new Timer();\n+                        log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MDE3NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520160174", "bodyText": "gone", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:25:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NDM5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\nindex 9cb25598e3..6c6bb06c32 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/BaseMetadataStore.java\n\n@@ -266,26 +266,25 @@ abstract public class BaseMetadataStore implements ChunkMetadataStore {\n         val modifiedValues = new ArrayList<TransactionData>();\n         val t = new Timer();\n         val retValue = CompletableFuture.runAsync(() -> {\n-            if (fenced.get()) {\n-                throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n-            }\n-        }, executor)\n+                    if (fenced.get()) {\n+                        throw new CompletionException(new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\"));\n+                    }\n+                }, executor)\n                 .thenComposeAsync(v -> {\n                     // Mark keys in transaction as active to prevent their eviction.\n                     txn.getData().keySet().forEach(this::addToActiveKeySet);\n \n                     // Acquire a write lock over segment.\n                     val tLock = new Timer();\n-                    log.debug(\"Acquiring write lock for {}\", String.join(\", \", txn.getKeysToLock()));\n+                    //log.debug(\"Acquiring write lock for {}\", txn.getKeysToLock());\n                     val writeLock = scheduler.getWriteLock(txn.getKeysToLock());\n                     return writeLock.lock()\n                             .thenComposeAsync(v0 -> {\n                                 // Step 1 : If bufferedTxnData data was flushed, then read it back from external source and re-insert in bufferedTxnData buffer.\n-                                // This step is kind of thread safe\n                                 val elapsed = tLock.getElapsed();\n                                 WRITE_LOCK_LATENCY.reportSuccessEvent(t.getElapsed());\n-                                log.debug(\"Acquired write lock for {}, wait time: {} ms\",\n-                                        String.join(\", \", txn.getKeysToLock()), elapsed.toMillis());\n+                                //log.debug(\"Acquired write lock for {}, wait time: {} ms\", txn.getKeysToLock());\n+                                //log.debug(\"Acquired write wait time: {} ms\", elapsed.toMillis());\n                                 return loadMissingKeys(txn, skipStoreCheck, txnData);\n                             }, executor)\n                             .thenComposeAsync(v1 -> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NDgwMA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518464800", "bodyText": "retValue -> entries ?\nGive your args a meaningful name.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:10:30Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -69,95 +77,110 @@ public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n      *\n      * @param key Key for the metadata record.\n      * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n-     * @throws StorageMetadataException Exception related to storage metadata operations.\n      */\n     @Override\n-    protected TransactionData read(String key) throws StorageMetadataException {\n-        ensureInitialized();\n-        List<BufferView> keys = new ArrayList<>();\n+    protected CompletableFuture<TransactionData> read(String key) {\n+        val keys = new ArrayList<BufferView>();\n         keys.add(new ByteArraySegment(key.getBytes(Charsets.UTF_8)));\n-        try {\n-            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n-            Preconditions.checkState(retValue.size() == 1, \"Unexpected number of values returned.\");\n-            TableEntry entry = retValue.get(0);\n-            if (null != entry) {\n-                val arr = entry.getValue();\n-                TransactionData txnData = serializer.deserialize(arr);\n-                txnData.setDbObject(entry.getKey().getVersion());\n-                txnData.setPersisted(true);\n-                return txnData;\n-            }\n-        } catch (IllegalStateException e) {\n-            throw e;\n-        } catch (Exception e) {\n-            throw new StorageMetadataException(\"Error while reading\", e);\n-        }\n-\n-        return TransactionData.builder()\n-                .key(key)\n-                .persisted(true)\n-                .dbObject(TableKey.NOT_EXISTS)\n-                .build();\n+        val t = new Timer();\n+        return ensureInitialized()\n+                .thenComposeAsync(v -> this.tableStore.get(tableName, keys, timeout)\n+                        .thenApplyAsync(retValue -> {", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MDEwNQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520160105", "bodyText": "done", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:25:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NDgwMA=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\nindex e4d84cad13..454f6b818c 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\n\n@@ -85,10 +85,10 @@ public class TableBasedMetadataStore extends BaseMetadataStore {\n         val t = new Timer();\n         return ensureInitialized()\n                 .thenComposeAsync(v -> this.tableStore.get(tableName, keys, timeout)\n-                        .thenApplyAsync(retValue -> {\n+                        .thenApplyAsync(entries -> {\n                             try {\n-                                Preconditions.checkState(retValue.size() == 1, \"Unexpected number of values returned.\");\n-                                val entry = retValue.get(0);\n+                                Preconditions.checkState(entries.size() == 1, \"Unexpected number of values returned.\");\n+                                val entry = entries.get(0);\n                                 if (null != entry) {\n                                     val arr = entry.getValue();\n                                     TransactionData txnData = serializer.deserialize(arr);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NTE5Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r518465196", "bodyText": "debug. I don't need to see this upon every container boot.\nThe one above where you create is OK to be info. It should only happen once.", "author": "andreipaduroiu", "createdAt": "2020-11-06T01:11:48Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -167,29 +190,36 @@ private StorageMetadataException handleException(Throwable e) throws StorageMeta\n         return new StorageMetadataException(\"Transaction failed\", e);\n     }\n \n-    private void ensureInitialized() {\n+    private CompletableFuture<Void> ensureInitialized() {\n         if (!isTableInitialized.get()) {\n             // Storage Metadata Segment is a System, Internal Segment. It must also be designated as Critical since the\n             // Segment Store may not function properly without it performing well. The Critical designation will cause\n             // all of its \"modify\" operations to bypass any ingestion pipeline throttling and be expedited for processing.\n             val segmentType = SegmentType.builder().tableSegment().system().critical().internal().build();\n-            try {\n-                this.tableStore.createSegment(tableName, segmentType, timeout).join();\n-                log.info(\"Created table segment {}\", tableName);\n-            } catch (CompletionException e) {\n-                if (e.getCause() instanceof StreamSegmentExistsException) {\n-                    log.info(\"Table segment {} already exists.\", tableName);\n-                }\n-            }\n-            isTableInitialized.set(true);\n+            return this.tableStore.createSegment(tableName, segmentType, timeout)\n+                    .thenRunAsync(() -> {\n+                        log.info(\"Created table segment {}\", tableName);\n+                        isTableInitialized.set(true);\n+                    }, getExecutor())\n+                    .exceptionally(e -> {\n+                        val ex = Exceptions.unwrap(e);\n+                        if (e.getCause() instanceof StreamSegmentExistsException) {\n+                            log.info(\"Table segment {} already exists.\", tableName);", "originalCommit": "a20fa7dac8368d64152b32f47aba6f5d675401c6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE2MDA0MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520160041", "bodyText": "done.", "author": "sachin-j-joshi", "createdAt": "2020-11-09T22:25:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ2NTE5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\nindex e4d84cad13..454f6b818c 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java\n\n@@ -198,13 +198,13 @@ public class TableBasedMetadataStore extends BaseMetadataStore {\n             val segmentType = SegmentType.builder().tableSegment().system().critical().internal().build();\n             return this.tableStore.createSegment(tableName, segmentType, timeout)\n                     .thenRunAsync(() -> {\n-                        log.info(\"Created table segment {}\", tableName);\n+                        log.debug(\"Created table segment {}\", tableName);\n                         isTableInitialized.set(true);\n                     }, getExecutor())\n                     .exceptionally(e -> {\n                         val ex = Exceptions.unwrap(e);\n                         if (e.getCause() instanceof StreamSegmentExistsException) {\n-                            log.info(\"Table segment {} already exists.\", tableName);\n+                            log.debug(\"Table segment {} already exists.\", tableName);\n                             isTableInitialized.set(true);\n                             return null;\n                         }\n"}}, {"oid": "2e7d9d077510dd0493c7e6c004833457e55f7d5f", "url": "https://github.com/pravega/pravega/commit/2e7d9d077510dd0493c7e6c004833457e55f7d5f", "message": "Issue 5067: (SLTS) - Code cleanup.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-06T22:26:01Z", "type": "commit"}, {"oid": "3046d85c5dc38c736c6326c204ec45c9abd2d1ab", "url": "https://github.com/pravega/pravega/commit/3046d85c5dc38c736c6326c204ec45c9abd2d1ab", "message": "Issue 5067: (SLTS) - Prevent concurrent transactions in BaseMetadataStore.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-09T22:13:26Z", "type": "commit"}, {"oid": "e1bfba0723965a09ac56ee1dbf4afdf95a3243f5", "url": "https://github.com/pravega/pravega/commit/e1bfba0723965a09ac56ee1dbf4afdf95a3243f5", "message": "Issue 5067: (SLTS) - Code cleanup - add messages to precondition checks.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-09T23:20:47Z", "type": "commit"}, {"oid": "26167f653eb6ccaef2b11021bbbac5538a137129", "url": "https://github.com/pravega/pravega/commit/26167f653eb6ccaef2b11021bbbac5538a137129", "message": "Merge branch 'master' of https://github.com/pravega/pravega into issue-5067-make-slts-api-async", "committedDate": "2020-11-09T23:23:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxOTg4NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520919884", "bodyText": "this check is not needed. log.trace will be a no-op in that case. The whole point of doing the check originally was not to add yet another callback to the Future. In this refactored code, it is no longer an issue.", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:40:01Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java", "diffHunk": "@@ -142,16 +142,16 @@ public AsyncBaseChunkStorage(Executor executor) {\n \n         // Call concrete implementation.\n         val returnFuture = doCreateAsync(chunkName);\n-        val metricsFuture = returnFuture.thenAcceptAsync(handle -> {\n+        returnFuture.thenAcceptAsync(handle -> {\n             // Record metrics.\n             val elapsed = timer.getElapsed();\n             ChunkStorageMetrics.CREATE_LATENCY.reportSuccessEvent(elapsed);\n             ChunkStorageMetrics.CREATE_COUNT.inc();\n             log.debug(\"Create - chunk={}, latency={}.\", chunkName, elapsed.toMillis());\n+            if (log.isTraceEnabled()) {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxOTk1Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520919952", "bodyText": "same below", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:40:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxOTg4NA=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\nindex b678470a6d..2cc70efe38 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/AsyncBaseChunkStorage.java\n\n@@ -148,9 +148,7 @@ public abstract class AsyncBaseChunkStorage implements ChunkStorage {\n             ChunkStorageMetrics.CREATE_LATENCY.reportSuccessEvent(elapsed);\n             ChunkStorageMetrics.CREATE_COUNT.inc();\n             log.debug(\"Create - chunk={}, latency={}.\", chunkName, elapsed.toMillis());\n-            if (log.isTraceEnabled()) {\n-                LoggerHelpers.traceLeave(log, \"create\", traceId, chunkName);\n-            }\n+            LoggerHelpers.traceLeave(log, \"create\", traceId, chunkName);\n         }, executor);\n         return returnFuture;\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMTE2NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520921164", "bodyText": "Same thing with log.debug. DEBUG logging is not a common occurrence, so only add a callback if debug logging is enabled.\nPlus, there is absolutely no reason to do ...Async on these ones. These one-liners will eat up more CPU resources doing context switching than what they actually do need to execute. Just turn this one into thenRun() with no executor. It will be executed on the same thread the previous callback finished.\nWhile this doesn't matter in this particular case, since this is a very infrequent operation, for others it does matter and we don't want to flood the threadpool with useless callbacks like this one.", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:42:53Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -173,11 +178,8 @@ public ChunkedSegmentStorage(int containerId, ChunkStorage chunkStorage, ChunkMe\n         this.logPrefix = String.format(\"ChunkedSegmentStorage[%d]\", containerId);\n \n         // Now bootstrap\n-        log.info(\"{} STORAGE BOOT: Started.\", logPrefix);\n-        return this.systemJournal.bootstrap(epoch).thenApplyAsync(v -> {\n-            log.info(\"{} STORAGE BOOT: Ended.\", logPrefix);\n-            return null;\n-        }, executor);\n+        log.debug(\"{} STORAGE BOOT: Started.\", logPrefix);\n+        return this.systemJournal.bootstrap(epoch).thenRunAsync(() -> log.debug(\"{} STORAGE BOOT: Ended.\", logPrefix), executor);", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk5Njg4OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520996889", "bodyText": "fixed.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T01:31:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMTE2NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMTgwOQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520921809", "bodyText": "You can rewrite this as CompletableFuture.runAsync. Why do you create a completed future just to have an async continuation?", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:44:27Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -681,17 +684,24 @@ public void close() {\n      * */\n     private <R> CompletableFuture<R> executeSerialized(Callable<CompletableFuture<R>> operation, String... segmentNames) {\n         Exceptions.checkNotClosed(this.closed.get(), this);\n-        return this.taskProcessor.add(Arrays.asList(segmentNames), () -> executeAsync(operation));\n+        return this.taskProcessor.add(Arrays.asList(segmentNames), () -> executeExclusive(operation, segmentNames));\n     }\n \n     /**\n-     * Executes the given Callable and returns its result.\n+     * Executes the given Callable asynchronously and exclusively.\n+     * It returns a CompletableFuture that will be completed with the result.\n+     * The operations are not allowed to be concurrent.\n      *\n-     * @param operation The Callable to execute.\n+     * @param operation    The Callable to execute.\n      * @param <R>       Return type of the operation.\n-     * @return CompletableFuture<R> of the return type of the operation.\n-     */\n-    private <R> CompletableFuture<R> executeAsync(Callable<CompletableFuture<R>> operation) {\n+     * @param segmentNames The names of the Segments involved in this operation (for sequencing purposes).\n+     * @return A CompletableFuture that, when completed, will contain the result of the operation.\n+     * If the operation failed, it will contain the cause of the failure.\n+     * */\n+    private <R> CompletableFuture<R> executeExclusive(Callable<CompletableFuture<R>> operation, String... segmentNames) {\n+        val shouldRelease = new AtomicBoolean(false);\n+        acquire(segmentNames);\n+        shouldRelease.set(true);\n         return CompletableFuture.completedFuture(null).thenComposeAsync(v -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk2NTY3Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520965676", "bodyText": "There is no composeAsync equivalent to supplyAsync", "author": "sachin-j-joshi", "createdAt": "2020-11-11T00:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMTgwOQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjA1MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520922050", "bodyText": "This is a good example of when Async is not needed.", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:44:57Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -701,9 +711,48 @@ public void close() {\n             } catch (Exception e) {\n                 throw new CompletionException(e);\n             }\n+        }, this.executor)\n+        .whenCompleteAsync((v, e) -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0MzIyMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520943222", "bodyText": "In general any whenCompleteAsync without executor will eat up processing from core thread pool and also there is no guarantee that it won't run on fork join pool. (The documentation say this can run on fork join pool).\nStorage I/O thread pool is very IO heavy - these few lines and waiting on IO is all these threads are doing.\nPlus it is using the same thread pool every where so there is actually no context switching.", "author": "sachin-j-joshi", "createdAt": "2020-11-10T23:38:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk2NDI5OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520964298", "bodyText": "http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/687fd7c7986d/src/share/classes/java/util/concurrent/CompletableFuture.java#l2372 This stuff scared me.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T00:40:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjA1MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjE1MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520922150", "bodyText": "When is this ever not true?", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:45:07Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -701,9 +711,48 @@ public void close() {\n             } catch (Exception e) {\n                 throw new CompletionException(e);\n             }\n+        }, this.executor)\n+        .whenCompleteAsync((v, e) -> {\n+            if (shouldRelease.get()) {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0NDAyNQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520944025", "bodyText": "when we throw and exception because of Concurrent access . We don't want it to clear up the entry for inflight valid call and unintentionally allow concurrent calls.", "author": "sachin-j-joshi", "createdAt": "2020-11-10T23:40:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjE1MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjgxMQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520922811", "bodyText": "This is another example of when Async is expected to cause more perf harm than not.", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:46:39Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -145,21 +145,19 @@\n                             } else {\n                                 f = CompletableFuture.completedFuture(null);\n                             }\n-                            return f.thenApplyAsync(vv -> {\n+                            return f.thenRunAsync(() -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk2NTkxMw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520965913", "bodyText": "same as above.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T00:45:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMjgxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex 4be40b007d..4bb5a8bb90 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -147,18 +150,15 @@ class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n                             }\n                             return f.thenRunAsync(() -> {\n                                 // Move on to next place in list where we can concat if we are done with append based concatenations.\n-                                if (!useAppend) {\n+                                if (!useAppend.get()) {\n                                     targetChunkName = nextChunkName;\n                                 }\n                                 // Toggle\n-                                useAppend = !useAppend;\n+                                useAppend.set(!useAppend.get());\n                             }, chunkedSegmentStorage.getExecutor());\n                         }, chunkedSegmentStorage.getExecutor()),\n                 chunkedSegmentStorage.getExecutor())\n-                .thenRunAsync(() -> {\n-                    // Make sure no invariants are broken.\n-                    segmentMetadata.checkInvariants();\n-                }, chunkedSegmentStorage.getExecutor());\n+                .thenRunAsync(segmentMetadata::checkInvariants, chunkedSegmentStorage.getExecutor());\n     }\n \n     private CompletableFuture<Void> concatChunks() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMzcxNA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520923714", "bodyText": "And here", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:48:44Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -145,21 +145,19 @@\n                             } else {\n                                 f = CompletableFuture.completedFuture(null);\n                             }\n-                            return f.thenApplyAsync(vv -> {\n+                            return f.thenRunAsync(() -> {\n                                 // Move on to next place in list where we can concat if we are done with append based concatenations.\n                                 if (!useAppend) {\n                                     targetChunkName = nextChunkName;\n                                 }\n                                 // Toggle\n                                 useAppend = !useAppend;\n-                                return null;\n                             }, chunkedSegmentStorage.getExecutor());\n                         }, chunkedSegmentStorage.getExecutor()),\n                 chunkedSegmentStorage.getExecutor())\n-                .thenApplyAsync(vv -> {\n+                .thenRunAsync(() -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0NDA5OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520944098", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-11-10T23:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMzcxNA=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex 4be40b007d..4bb5a8bb90 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -147,18 +150,15 @@ class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n                             }\n                             return f.thenRunAsync(() -> {\n                                 // Move on to next place in list where we can concat if we are done with append based concatenations.\n-                                if (!useAppend) {\n+                                if (!useAppend.get()) {\n                                     targetChunkName = nextChunkName;\n                                 }\n                                 // Toggle\n-                                useAppend = !useAppend;\n+                                useAppend.set(!useAppend.get());\n                             }, chunkedSegmentStorage.getExecutor());\n                         }, chunkedSegmentStorage.getExecutor()),\n                 chunkedSegmentStorage.getExecutor())\n-                .thenRunAsync(() -> {\n-                    // Make sure no invariants are broken.\n-                    segmentMetadata.checkInvariants();\n-                }, chunkedSegmentStorage.getExecutor());\n+                .thenRunAsync(segmentMetadata::checkInvariants, chunkedSegmentStorage.getExecutor());\n     }\n \n     private CompletableFuture<Void> concatChunks() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMzgyOA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520923828", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:49:00Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -250,9 +246,8 @@\n                     bytesToRead = Math.toIntExact(arg.getLength());\n \n                     return copyBytes(writeHandle, arg)\n-                            .thenApplyAsync(v -> {\n+                            .thenRunAsync(() -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0NDE5Mw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520944193", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-11-10T23:41:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyMzgyOA=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex 4be40b007d..4bb5a8bb90 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -236,19 +236,17 @@ class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n     }\n \n     private CompletableFuture<Integer> concatUsingAppend(ConcatArgument[] concatArgs) {\n-        writeAtOffset = concatArgs[0].getLength();\n+        writeAtOffset.set(concatArgs[0].getLength());\n         val writeHandle = ChunkHandle.writeHandle(concatArgs[0].getName());\n         currentArgIndex.set(1);\n         return Futures.loop(() -> currentArgIndex.get() < concatArgs.length,\n                 () -> {\n-                    readAtOffset = 0;\n+                    readAtOffset.set(0);\n                     val arg = concatArgs[currentArgIndex.get()];\n-                    bytesToRead = Math.toIntExact(arg.getLength());\n+                    bytesToRead.set(Math.toIntExact(arg.getLength()));\n \n                     return copyBytes(writeHandle, arg)\n-                            .thenRunAsync(() -> {\n-                                currentArgIndex.incrementAndGet();\n-                            }, chunkedSegmentStorage.getExecutor());\n+                            .thenRunAsync(currentArgIndex::incrementAndGet, chunkedSegmentStorage.getExecutor());\n                 },\n                 chunkedSegmentStorage.getExecutor())\n                 .thenApplyAsync(v -> 0, chunkedSegmentStorage.getExecutor());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNDI3Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520924277", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:50:02Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -269,9 +264,8 @@\n                                 bytesToRead -= size;\n                                 readAtOffset += size;\n                                 return chunkedSegmentStorage.getChunkStorage().write(writeHandle, writeAtOffset, size, new ByteArrayInputStream(buffer, 0, size))\n-                                        .thenApplyAsync(written -> {\n+                                        .thenAcceptAsync(written -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk2NTk5MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520965990", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-11-11T00:45:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNDI3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex 4be40b007d..4bb5a8bb90 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -256,17 +254,15 @@ class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n \n     private CompletableFuture<Void> copyBytes(ChunkHandle writeHandle, ConcatArgument arg) {\n         return Futures.loop(\n-                () -> bytesToRead > 0,\n+                () -> bytesToRead.get() > 0,\n                 () -> {\n-                    val buffer = new byte[Math.min(chunkedSegmentStorage.getConfig().getMaxBufferSizeForChunkDataTransfer(), bytesToRead)];\n-                    return chunkedSegmentStorage.getChunkStorage().read(ChunkHandle.readHandle(arg.getName()), readAtOffset, buffer.length, buffer, 0)\n+                    val buffer = new byte[Math.min(chunkedSegmentStorage.getConfig().getMaxBufferSizeForChunkDataTransfer(), bytesToRead.get())];\n+                    return chunkedSegmentStorage.getChunkStorage().read(ChunkHandle.readHandle(arg.getName()), readAtOffset.get(), buffer.length, buffer, 0)\n                             .thenComposeAsync(size -> {\n-                                bytesToRead -= size;\n-                                readAtOffset += size;\n-                                return chunkedSegmentStorage.getChunkStorage().write(writeHandle, writeAtOffset, size, new ByteArrayInputStream(buffer, 0, size))\n-                                        .thenAcceptAsync(written -> {\n-                                            writeAtOffset += written;\n-                                        }, chunkedSegmentStorage.getExecutor());\n+                                bytesToRead.addAndGet(-size);\n+                                readAtOffset.addAndGet(size);\n+                                return chunkedSegmentStorage.getChunkStorage().write(writeHandle, writeAtOffset.get(), size, new ByteArrayInputStream(buffer, 0, size))\n+                                        .thenAcceptAsync(writeAtOffset::addAndGet, chunkedSegmentStorage.getExecutor());\n                             }, chunkedSegmentStorage.getExecutor());\n                 },\n                 chunkedSegmentStorage.getExecutor()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNDQ0Nw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520924447", "bodyText": "This is not thread safe. Use AtomicLong.\nWhile volatile is atomic with respect to get and set, it is not with respect to modification. Your addition is a read-modify-update operation which is not atomic.\nPlease fix this everywhere in your code.", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:50:22Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java", "diffHunk": "@@ -269,9 +264,8 @@\n                                 bytesToRead -= size;\n                                 readAtOffset += size;\n                                 return chunkedSegmentStorage.getChunkStorage().write(writeHandle, writeAtOffset, size, new ByteArrayInputStream(buffer, 0, size))\n-                                        .thenApplyAsync(written -> {\n+                                        .thenAcceptAsync(written -> {\n                                             writeAtOffset += written;", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk2NzA1Mg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520967052", "bodyText": "Based to application logic they are thread safe as only one lambda from this method executes at a time.  However to avoid future bugs and confusion I'll fix where values are modified. (based on code warning in IDE)", "author": "sachin-j-joshi", "createdAt": "2020-11-11T00:47:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNDQ0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk5NjI2NA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520996264", "bodyText": "ok updated.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T01:30:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNDQ0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\nindex 4be40b007d..4bb5a8bb90 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/DefragmentOperation.java\n\n@@ -256,17 +254,15 @@ class DefragmentOperation implements Callable<CompletableFuture<Void>> {\n \n     private CompletableFuture<Void> copyBytes(ChunkHandle writeHandle, ConcatArgument arg) {\n         return Futures.loop(\n-                () -> bytesToRead > 0,\n+                () -> bytesToRead.get() > 0,\n                 () -> {\n-                    val buffer = new byte[Math.min(chunkedSegmentStorage.getConfig().getMaxBufferSizeForChunkDataTransfer(), bytesToRead)];\n-                    return chunkedSegmentStorage.getChunkStorage().read(ChunkHandle.readHandle(arg.getName()), readAtOffset, buffer.length, buffer, 0)\n+                    val buffer = new byte[Math.min(chunkedSegmentStorage.getConfig().getMaxBufferSizeForChunkDataTransfer(), bytesToRead.get())];\n+                    return chunkedSegmentStorage.getChunkStorage().read(ChunkHandle.readHandle(arg.getName()), readAtOffset.get(), buffer.length, buffer, 0)\n                             .thenComposeAsync(size -> {\n-                                bytesToRead -= size;\n-                                readAtOffset += size;\n-                                return chunkedSegmentStorage.getChunkStorage().write(writeHandle, writeAtOffset, size, new ByteArrayInputStream(buffer, 0, size))\n-                                        .thenAcceptAsync(written -> {\n-                                            writeAtOffset += written;\n-                                        }, chunkedSegmentStorage.getExecutor());\n+                                bytesToRead.addAndGet(-size);\n+                                readAtOffset.addAndGet(size);\n+                                return chunkedSegmentStorage.getChunkStorage().write(writeHandle, writeAtOffset.get(), size, new ByteArrayInputStream(buffer, 0, size))\n+                                        .thenAcceptAsync(writeAtOffset::addAndGet, chunkedSegmentStorage.getExecutor());\n                             }, chunkedSegmentStorage.getExecutor());\n                 },\n                 chunkedSegmentStorage.getExecutor()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNTMzMw==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520925333", "bodyText": "and here", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:52:24Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java", "diffHunk": "@@ -145,12 +144,11 @@ private void logEnd() {\n                                                 bytesToRead,\n                                                 buffer,\n                                                 currentBufferOffset)\n-                                                .thenApplyAsync(bytesRead -> {\n+                                                .thenAcceptAsync(bytesRead -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0NDY3OQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520944679", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-11-10T23:42:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNTMzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk2NTA4MQ==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520965081", "bodyText": "same as above", "author": "sachin-j-joshi", "createdAt": "2020-11-11T00:42:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNTMzMw=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java\nindex 3c2ed4beaf..d38132e3a8 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java\n\n@@ -140,15 +141,15 @@ class ReadOperation implements Callable<CompletableFuture<Integer>> {\n                         return chunkedSegmentStorage.getChunkStorage().openRead(chunkToReadFrom.getName())\n                                 .thenComposeAsync(chunkHandle ->\n                                         chunkedSegmentStorage.getChunkStorage().read(chunkHandle,\n-                                                currentOffset - startOffsetForCurrentChunk,\n+                                                currentOffset.get() - startOffsetForCurrentChunk.get(),\n                                                 bytesToRead,\n                                                 buffer,\n-                                                currentBufferOffset)\n+                                                currentBufferOffset.get())\n                                                 .thenAcceptAsync(bytesRead -> {\n-                                                    bytesRemaining -= bytesRead;\n-                                                    currentOffset += bytesRead;\n-                                                    currentBufferOffset += bytesRead;\n-                                                    totalBytesRead += bytesRead;\n+                                                    bytesRemaining.addAndGet(-bytesRead);\n+                                                    currentOffset.addAndGet(bytesRead);\n+                                                    currentBufferOffset.addAndGet(bytesRead);\n+                                                    totalBytesRead.addAndGet(bytesRead);\n                                                 }, chunkedSegmentStorage.getExecutor()),\n                                         chunkedSegmentStorage.getExecutor());\n                     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNTY0Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520925646", "bodyText": "FYI, Java allows you to compress this syntax into thenRunAsync(this::postCommit, executor)", "author": "andreipaduroiu", "createdAt": "2020-11-10T22:53:12Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/TruncateOperation.java", "diffHunk": "@@ -90,9 +90,8 @@\n                                         return commit(txn)\n                                                 .handleAsync(this::handleException, chunkedSegmentStorage.getExecutor())\n                                                 .thenComposeAsync(vv ->\n-                                                                chunkedSegmentStorage.collectGarbage(chunksToDelete).thenApplyAsync(vvv -> {\n+                                                                chunkedSegmentStorage.collectGarbage(chunksToDelete).thenRunAsync(() -> {", "originalCommit": "26167f653eb6ccaef2b11021bbbac5538a137129", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk5NjM1OA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r520996358", "bodyText": "fixed.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T01:31:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkyNTY0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/TruncateOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/TruncateOperation.java\nindex a1b85d7c24..bfb6b57c83 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/TruncateOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/TruncateOperation.java\n\n@@ -90,9 +90,8 @@ class TruncateOperation implements Callable<CompletableFuture<Void>> {\n                                         return commit(txn)\n                                                 .handleAsync(this::handleException, chunkedSegmentStorage.getExecutor())\n                                                 .thenComposeAsync(vv ->\n-                                                                chunkedSegmentStorage.collectGarbage(chunksToDelete).thenRunAsync(() -> {\n-                                                                    postCommit();\n-                                                                }, chunkedSegmentStorage.getExecutor()),\n+                                                                chunkedSegmentStorage.collectGarbage(chunksToDelete)\n+                                                                        .thenRunAsync(this::postCommit, chunkedSegmentStorage.getExecutor()),\n                                                         chunkedSegmentStorage.getExecutor());\n                                     }, chunkedSegmentStorage.getExecutor());\n                         }, chunkedSegmentStorage.getExecutor()),\n"}}, {"oid": "ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "url": "https://github.com/pravega/pravega/commit/ef6e77b75dce4fed4dfb4ceaac60964de51284b7", "message": "Issue 5067: (SLTS) - Address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-11T00:54:21Z", "type": "commit"}, {"oid": "67058bf16cdff32e0d7baa52d5c22339086c8ac5", "url": "https://github.com/pravega/pravega/commit/67058bf16cdff32e0d7baa52d5c22339086c8ac5", "message": "Issue 5067: (SLTS) - Ignore stale value in BaseMetadataStore::insertInBuffer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-11T01:14:07Z", "type": "commit"}, {"oid": "38c5a9883187d142407cd7dba6e53bbb2fdc3078", "url": "https://github.com/pravega/pravega/commit/38c5a9883187d142407cd7dba6e53bbb2fdc3078", "message": "Issue 5067: (SLTS) - revert 67058bf16. Earlier code is correct.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-11T01:40:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyODc4MA==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r521628780", "bodyText": "Do you really need to run this on another thread? thenRun will suffice.\nEverywhere else too.", "author": "andreipaduroiu", "createdAt": "2020-11-11T20:47:01Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/WriteOperation.java", "diffHunk": "@@ -188,30 +187,28 @@ private void collectGarbage() {\n \n         // if layout did not change then commit with lazyWrite.\n         return txn.commit(!didSegmentLayoutChange && chunkedSegmentStorage.getConfig().isLazyCommitEnabled())\n-                .thenRunAsync(() -> {\n-                    isCommitted = true;\n-                }, chunkedSegmentStorage.getExecutor());\n+                .thenRunAsync(() -> isCommitted = true, chunkedSegmentStorage.getExecutor());", "originalCommit": "38c5a9883187d142407cd7dba6e53bbb2fdc3078", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY1NzU2Ng==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r521657566", "bodyText": "thenRun will potentially run on callers thread which may or may not include segment store core threads.\nI do want Storage code to always run on storage pool.\nWith thread pools the number of threads are fixed and we are not switching threads explicitly here. Framework is free to schedule any task on any free thread- including then thenRun. It uses variant of work stealing which will greedily execute next available task.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T21:46:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyODc4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTY1ODAyMg==", "url": "https://github.com/pravega/pravega/pull/5200#discussion_r521658022", "bodyText": "There is no extra overhead here.", "author": "sachin-j-joshi", "createdAt": "2020-11-11T21:46:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyODc4MA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "292d54582f3915bbeed4871c334b3bdfea515082", "url": "https://github.com/pravega/pravega/commit/292d54582f3915bbeed4871c334b3bdfea515082", "message": "Issue 5067: (SLTS) - SLTS is disabled by default.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-11-11T22:38:04Z", "type": "commit"}]}