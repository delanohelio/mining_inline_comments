{"pr_number": 5412, "pr_title": "Issue 5390: SLTS - Improve logging. Shortcut findChunk for reading last chunk.", "pr_createdAt": "2020-12-09T07:14:41Z", "pr_url": "https://github.com/pravega/pravega/pull/5412", "timeline": [{"oid": "5a7ad77f0b1affe79ed740809899420afde7fdab", "url": "https://github.com/pravega/pravega/commit/5a7ad77f0b1affe79ed740809899420afde7fdab", "message": "Issue 5390: SLTS - Improve logging. Shortcut findChunk for reading last chunk\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-12-09T07:06:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ4MDY4NA==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r539480684", "bodyText": "how is this helpful to identify it? Also, what's wrong with this.hashcode()?", "author": "andreipaduroiu", "createdAt": "2020-12-09T16:59:51Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/WriteOperation.java", "diffHunk": "@@ -265,8 +265,8 @@ private void collectGarbage() {\n                     didSegmentLayoutChange = true;\n                     chunksAddedCount.incrementAndGet();\n \n-                    log.debug(\"{} write - New chunk added - segment={}, chunk={}, offset={}.\",\n-                            chunkedSegmentStorage.getLogPrefix(), handle.getSegmentName(), newChunkName, segmentMetadata.getLength());\n+                    log.debug(\"{} write - New chunk added - op={}, segment={}, chunk={}, offset={}.\",\n+                            chunkedSegmentStorage.getLogPrefix(), System.identityHashCode(this), handle.getSegmentName(), newChunkName, segmentMetadata.getLength());", "originalCommit": "5a7ad77f0b1affe79ed740809899420afde7fdab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ4NzIwNw==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r539487207", "bodyText": "I needed some unique id for for each request - doesn't matter what as long as I can identify all logs from a single operation.\nEach operation invocation is a new object and it's hashcode is good enough to for debug purpose.\nSystem.identityHashCode(this) is more \"stable\", can't be overridden by implementation and more likely to be unique than HashCode.", "author": "sachin-j-joshi", "createdAt": "2020-12-09T17:08:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ4MDY4NA=="}], "type": "inlineReview", "revised_code": {"commit": "c758486ef0d16f5310a4a5c216796c6651baabe3", "chunk": "diff --git a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/WriteOperation.java b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/WriteOperation.java\nindex 5d4875b497..2835e8359b 100644\n--- a/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/WriteOperation.java\n+++ b/segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/WriteOperation.java\n\n@@ -262,6 +264,7 @@ class WriteOperation implements Callable<CompletableFuture<Void>> {\n                     newReadIndexEntries.add(new ChunkNameOffsetPair(segmentMetadata.getLength(), newChunkName));\n \n                     isFirstWriteAfterFailover = false;\n+                    skipOverFailedChunk = false;\n                     didSegmentLayoutChange = true;\n                     chunksAddedCount.incrementAndGet();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ4MDc0MA==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r539480740", "bodyText": "Why async? Those operations should be quick. No need to add a new task in the executor queue.", "author": "andreipaduroiu", "createdAt": "2020-12-09T16:59:55Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java", "diffHunk": "@@ -202,14 +211,15 @@ private void logEnd() {\n                                 chunkedSegmentStorage.getReadIndexCache().addIndexEntry(handle.getSegmentName(), currentChunkName, startOffsetForCurrentChunk.get());\n                             }\n                             cntScanned.incrementAndGet();\n-                        }, chunkedSegmentStorage.getExecutor())\n-                        .thenAcceptAsync(v -> {\n-                            val elapsed = readIndexTimer.getElapsed();\n-                            SLTS_READ_INDEX_SCAN_LATENCY.reportSuccessEvent(elapsed);\n-                            log.debug(\"{} read - chunk lookup - segment={}, offset={}, scanned={}, latency={}.\",\n-                                    chunkedSegmentStorage.getLogPrefix(), handle.getSegmentName(), offset, cntScanned.get(), elapsed.toMillis());\n                         }, chunkedSegmentStorage.getExecutor()),\n-                chunkedSegmentStorage.getExecutor());\n+                chunkedSegmentStorage.getExecutor())\n+                .thenAcceptAsync(v -> {", "originalCommit": "5a7ad77f0b1affe79ed740809899420afde7fdab", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxNDU3Nw==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r539514577", "bodyText": "The java documentation is ambiguous about it whether it is guaranteed to be run on same thread.\nIt seems it can run on this thread pool or thread pool of the caller. (in this case that would be possibly core thread).\nHence to be careful not to hijack core threads I choose to explicitly provide thread pool I want this to be run on. (which is same thread pool anyway).\nHere I'm just maintaining consistency with rest of the code in this file by using Async.\nI do plan to use non async overload if it can be guaranteed that FJ or other thread pools don't get used accidently or a more likely case when storage thread pool is super busy.", "author": "sachin-j-joshi", "createdAt": "2020-12-09T17:43:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ4MDc0MA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "e9094932efa8e104cab16c918e7b6500e55306ce", "url": "https://github.com/pravega/pravega/commit/e9094932efa8e104cab16c918e7b6500e55306ce", "message": "Issue 5390: SLTS - greater than equal to.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>", "committedDate": "2020-12-10T06:15:24Z", "type": "commit"}, {"oid": "c758486ef0d16f5310a4a5c216796c6651baabe3", "url": "https://github.com/pravega/pravega/commit/c758486ef0d16f5310a4a5c216796c6651baabe3", "message": "Merge branch 'master' into issue-5411-SLTS-better-logging", "committedDate": "2020-12-10T09:08:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk5ODE1NA==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r539998154", "bodyText": "If this is an exception, why it is in debug level? In general, we want to keep track of relevant exceptions in production systems, which requires this to be at least info level, if not warn or error. As SLTS is a new piece of code, let's keep high the log level of exceptions so we can debug problems quickly without needed to repeat experiments with debug level logs.", "author": "RaulGracia", "createdAt": "2020-12-10T09:13:02Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java", "diffHunk": "@@ -90,7 +90,7 @@\n                                         return readData(txn);\n                                     }, chunkedSegmentStorage.getExecutor())\n                                     .exceptionally(ex -> {\n-                                        log.debug(\"{} read - started op={}, segment={}, offset={}, bytesRead={}.\",\n+                                        log.debug(\"{} read - exception op={}, segment={}, offset={}, bytesRead={}.\",", "originalCommit": "c758486ef0d16f5310a4a5c216796c6651baabe3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE2ODc0Nw==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r540168747", "bodyText": "We do throw this exception which the caller will log appropriately.\nThis is just additional debug information that exception does not contain.", "author": "sachin-j-joshi", "createdAt": "2020-12-10T13:29:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk5ODE1NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDAxMDc1Mw==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r540010753", "bodyText": "Maybe not related to the PR, but the way chunkToReadFrom (and other variables) is set and checked here and there looks hard to track in case we face a race conditions. Even tough a variable is declared as volatile, the point is that if multiple methods (perhaps executed by different threads) are setting and reading this variable throughout the class, it increases considerably the complexity of debugging it in case of problems. Perhaps this was the only way, I don't know, but maybe in the future we can reconsider this pattern to see if there is an alternative that simplifies the code.", "author": "RaulGracia", "createdAt": "2020-12-10T09:30:30Z", "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ReadOperation.java", "diffHunk": "@@ -132,7 +133,9 @@ private void logEnd() {\n                             return txn.get(currentChunkName)\n                                     .thenAcceptAsync(storageMetadata -> {\n                                         chunkToReadFrom = (ChunkMetadata) storageMetadata;\n-                                        log.debug(\"{} read - reading from next chunk - segment={}, chunk={}\", chunkedSegmentStorage.getLogPrefix(), handle.getSegmentName(), chunkToReadFrom);\n+                                        Preconditions.checkState(null != chunkToReadFrom, \"chunkToReadFrom is null\");", "originalCommit": "c758486ef0d16f5310a4a5c216796c6651baabe3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE4MzMwNg==", "url": "https://github.com/pravega/pravega/pull/5412#discussion_r540183306", "bodyText": "Generic answer to your question -\nUnfortunately java does not have Async/Await syntax suger that generates all the future based  (Task parallel library) lambdas for your code.\nSo we have to do it by hand. Having done lots TPL based programming in the past, I was sort of reluctant to rewrite this code for async knowing it makes very difficult to maintain spaghetti code with lots of lambdas.\nHowever we absolutely do need it here.\nThe general pattern that I have here for thread safety is as follows\n\nEach major function in linear non-async code becomes a method object. Each invocation is a separate object. So separate invocations share nothing.\nAll members must be either final or volatile\nIf you need to use any arithmetic then it is better to use Atomic variables (which actually just volatile variables with additional safety added for atomic addition/subtraction)\nThe labmdas are executed in series by java sdk (i.e CompletableFuture framework) one lambda at a time.\nThe JVM memory model guarantees that reads and writes to volatile variable are thread safe.\n\nWriting all this async code by hand and yet keeping it understandable is not easy. But hopefully code gets better, faster and also cleaner as we go.", "author": "sachin-j-joshi", "createdAt": "2020-12-10T13:50:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDAxMDc1Mw=="}], "type": "inlineReview", "revised_code": null}]}