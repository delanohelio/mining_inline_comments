{"pr_number": 679, "pr_title": "PHOENIX-5645 - BaseScannerRegionObserver should prevent compaction from purg\u2026", "pr_createdAt": "2020-01-13T21:56:32Z", "pr_url": "https://github.com/apache/phoenix/pull/679", "timeline": [{"oid": "d6db13289202c5c2ae4a8f59e3f6c57b8f20d179", "url": "https://github.com/apache/phoenix/commit/d6db13289202c5c2ae4a8f59e3f6c57b8f20d179", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-13T23:03:25Z", "type": "forcePushed"}, {"oid": "986bd50c2f8518b61afc4613438d39ee485b3c80", "url": "https://github.com/apache/phoenix/commit/986bd50c2f8518b61afc4613438d39ee485b3c80", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-14T19:00:06Z", "type": "forcePushed"}, {"oid": "28edd1500a192ab700a56569f074503db7e409d4", "url": "https://github.com/apache/phoenix/commit/28edd1500a192ab700a56569f074503db7e409d4", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-14T21:44:21Z", "type": "commit"}, {"oid": "28edd1500a192ab700a56569f074503db7e409d4", "url": "https://github.com/apache/phoenix/commit/28edd1500a192ab700a56569f074503db7e409d4", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-14T21:44:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTI2NQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366589265", "bodyText": "Can we write the unit as part of const name?", "author": "gokceni", "createdAt": "2020-01-14T21:46:35Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -59,10 +57,31 @@\n @NeedsOwnMiniClusterTest\n public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n     private static final Log LOG = LogFactory.getLog(MaxLookbackIT.class);\n-    private static final int MAX_LOOKBACK_AGE = 10;\n+    private static final int MAX_LOOKBACK_AGE = 15;\n     private static final int ROWS_POPULATED = 2;\n+    public static final int WAIT_AFTER_TABLE_CREATION = 600000;", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjM5NA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622394", "bodyText": "Suggest setting WAIT_AFTER_TABLE_CREATION = MAX_LOOKBACK_AGE * 100 ... just in case someone increases MAX_LOOKBACK_AGE and leaves WAIT_AFTER_TABLE_CREATION as is.", "author": "priyankporwal", "createdAt": "2020-01-14T23:13:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTI2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -59,7 +61,7 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n     private static final Log LOG = LogFactory.getLog(MaxLookbackIT.class);\n     private static final int MAX_LOOKBACK_AGE = 15;\n     private static final int ROWS_POPULATED = 2;\n-    public static final int WAIT_AFTER_TABLE_CREATION = 600000;\n+    public static final int WAIT_AFTER_TABLE_CREATION_MILLIS = 1;\n     private String tableDDLOptions;\n     private StringBuilder optionBuilder;\n     ManualEnvironmentEdge injectEdge;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTk0Mg==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366589942", "bodyText": "nit: remove commented code", "author": "gokceni", "createdAt": "2020-01-14T21:48:13Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY0OTE4MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366649181", "bodyText": "Not commented out anymore. :-)", "author": "gjacoby126", "createdAt": "2020-01-15T00:53:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU4OTk0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -184,54 +204,67 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            //increment by 10 min to make sure we don't \"look back\" past table creation\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            //increment to make sure we don't \"look back\" past table creation\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n-            injectEdge.incValue(1);\n+            createIndex(dataTableName, indexName, 1);\n+            injectEdge.incrementValue(1);\n             long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n+            TableName indexTable = TableName.valueOf(indexName);\n             assertTableHasTtl(conn, dataTable, ttl);\n+            assertTableHasTtl(conn, indexTable, ttl);\n             //first make sure we inserted correctly\n             String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n-          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String indexSql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(),indexSql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //force a flush\n             flush(dataTable);\n+            flush(indexTable);\n             //flush shouldn't have changed it\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            long timeToAdvance = (MAX_LOOKBACK_AGE * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n-                //Thread.sleep(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure it's still on disk\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-            injectEdge.incValue(1); //get a new timestamp for compaction\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            injectEdge.incrementValue(1); //get a new timestamp for compaction\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //nothing should have been purged by this major compaction\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //now wait the TTL\n-            timeToSleep = (ttl * 1000) -\n+            timeToAdvance = (ttl * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure that we can compact away the now-expired rows\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //note that before HBase 1.4, we don't have HBASE-17956\n             // and this will always return 0 whether it's still on-disk or not\n             assertRawRowCount(conn, dataTable, 0);\n+            assertRawRowCount(conn, indexTable, 0);\n         } finally{\n             conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, oldMemstoreFlushInterval);\n         }\n     }\n \n-    @Test\n+    @Test(timeout=60000)\n     public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         int versions = 2;\n         optionBuilder.append(\"VERSIONS=\" + versions);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU5Mzk1Nw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366593957", "bodyText": "nit: remove commented code", "author": "gokceni", "createdAt": "2020-01-14T21:57:29Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //force a flush\n-            flush(indexTable);\n+            flush(dataTable);\n             //flush shouldn't have changed it\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY0OTExMw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366649113", "bodyText": "Not commented out anymore. :-)", "author": "gjacoby126", "createdAt": "2020-01-15T00:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU5Mzk1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -184,54 +204,67 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            //increment by 10 min to make sure we don't \"look back\" past table creation\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            //increment to make sure we don't \"look back\" past table creation\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n-            injectEdge.incValue(1);\n+            createIndex(dataTableName, indexName, 1);\n+            injectEdge.incrementValue(1);\n             long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n+            TableName indexTable = TableName.valueOf(indexName);\n             assertTableHasTtl(conn, dataTable, ttl);\n+            assertTableHasTtl(conn, indexTable, ttl);\n             //first make sure we inserted correctly\n             String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n-          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String indexSql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(),indexSql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //force a flush\n             flush(dataTable);\n+            flush(indexTable);\n             //flush shouldn't have changed it\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            long timeToAdvance = (MAX_LOOKBACK_AGE * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n-                //Thread.sleep(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure it's still on disk\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-            injectEdge.incValue(1); //get a new timestamp for compaction\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            injectEdge.incrementValue(1); //get a new timestamp for compaction\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //nothing should have been purged by this major compaction\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //now wait the TTL\n-            timeToSleep = (ttl * 1000) -\n+            timeToAdvance = (ttl * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure that we can compact away the now-expired rows\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //note that before HBase 1.4, we don't have HBASE-17956\n             // and this will always return 0 whether it's still on-disk or not\n             assertRawRowCount(conn, dataTable, 0);\n+            assertRawRowCount(conn, indexTable, 0);\n         } finally{\n             conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, oldMemstoreFlushInterval);\n         }\n     }\n \n-    @Test\n+    @Test(timeout=60000)\n     public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         int versions = 2;\n         optionBuilder.append(\"VERSIONS=\" + versions);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjU5NDA2MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366594061", "bodyText": "nit: remove commented code", "author": "gokceni", "createdAt": "2020-01-14T21:57:43Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //force a flush\n-            flush(indexTable);\n+            flush(dataTable);\n             //flush shouldn't have changed it\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+                (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n+            if (timeToSleep > 0) {\n+                injectEdge.incValue(timeToSleep);\n+                //Thread.sleep(timeToSleep);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -184,54 +204,67 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            //increment by 10 min to make sure we don't \"look back\" past table creation\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            //increment to make sure we don't \"look back\" past table creation\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n-            injectEdge.incValue(1);\n+            createIndex(dataTableName, indexName, 1);\n+            injectEdge.incrementValue(1);\n             long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n+            TableName indexTable = TableName.valueOf(indexName);\n             assertTableHasTtl(conn, dataTable, ttl);\n+            assertTableHasTtl(conn, indexTable, ttl);\n             //first make sure we inserted correctly\n             String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n-          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String indexSql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(),indexSql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //force a flush\n             flush(dataTable);\n+            flush(indexTable);\n             //flush shouldn't have changed it\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            long timeToAdvance = (MAX_LOOKBACK_AGE * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n-                //Thread.sleep(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure it's still on disk\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-            injectEdge.incValue(1); //get a new timestamp for compaction\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            injectEdge.incrementValue(1); //get a new timestamp for compaction\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //nothing should have been purged by this major compaction\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //now wait the TTL\n-            timeToSleep = (ttl * 1000) -\n+            timeToAdvance = (ttl * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure that we can compact away the now-expired rows\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //note that before HBase 1.4, we don't have HBASE-17956\n             // and this will always return 0 whether it's still on-disk or not\n             assertRawRowCount(conn, dataTable, 0);\n+            assertRawRowCount(conn, indexTable, 0);\n         } finally{\n             conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, oldMemstoreFlushInterval);\n         }\n     }\n \n-    @Test\n+    @Test(timeout=60000)\n     public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         int versions = 2;\n         optionBuilder.append(\"VERSIONS=\" + versions);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366619860", "bodyText": "does this value change now?", "author": "swaroopak", "createdAt": "2020-01-14T23:05:57Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -105,60 +129,52 @@ public void testTooLowSCNWithMaxLookbackAge() throws Exception {\n     public void testRecentlyDeletedRowsNotCompactedAway() throws Exception {\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            String fullIndexName = indexStem + \"1\";\n+            createTable(dataTableName);\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n             TableName dataTable = TableName.valueOf(dataTableName);\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n-            assertTableHasTtl(conn, indexTable, Integer.MAX_VALUE);\n-            long beforeDeleteSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n-            Thread.sleep(1); //make sure we delete at a different ts\n+            populateTable(dataTableName);\n+            //make sure we're after the inserts have been committed\n+            injectEdge.incValue(1);\n+            long beforeDeleteSCN = EnvironmentEdgeManager.currentTimeMillis();\n+            injectEdge.incValue(10); //make sure we delete at a different ts\n             Statement stmt = conn.createStatement();\n             stmt.execute(\"DELETE FROM \" + dataTableName + \" WHERE \" + \" id = 'a'\");\n             Assert.assertEquals(1, stmt.getUpdateCount());\n             conn.commit();\n             //select stmt to get row we deleted\n-            String sql = String.format(\"SELECT * FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT * FROM %s WHERE id = 'a'\", dataTableName);\n             int rowsPlusDeleteMarker = ROWS_POPULATED;\n-            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n             flush(dataTable);\n-            flush(indexTable);\n-            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n-            long beforeFirstCompactSCN = EnvironmentEdgeManager.currentTime();\n-            Thread.sleep(1);\n-            majorCompact(indexTable, beforeFirstCompactSCN);\n-            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n+            long beforeFirstCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n+            injectEdge.incValue(1); //new ts for major compaction\n+            majorCompact(dataTable, beforeFirstCompactSCN);\n+            assertRawRowCount(conn, dataTable, rowsPlusDeleteMarker);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n             //wait for the lookback time. After this compactions should purge the deleted row\n-            Thread.sleep(MAX_LOOKBACK_AGE * 1000);\n-            long beforeSecondCompactSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            injectEdge.incValue(MAX_LOOKBACK_AGE * 1000);\n+            long beforeSecondCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n             String notDeletedRowSql =\n-                String.format(\"SELECT * FROM %s WHERE val1 = 'bc'\", dataTableName);\n-            assertExplainPlan(conn, notDeletedRowSql, dataTableName, fullIndexName);\n+                String.format(\"SELECT * FROM %s WHERE id = 'b'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n-            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n             conn.createStatement().execute(\"upsert into \" + dataTableName +\n                 \" values ('c', 'cd', 'cde', 'cdef')\");\n             conn.commit();\n-            majorCompact(indexTable, beforeSecondCompactSCN);\n             majorCompact(dataTable, beforeSecondCompactSCN);\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n             //deleted row should be gone, but not deleted row should still be there.\n             assertRowExistsAtSCN(getUrl(), sql, beforeSecondCompactSCN, false);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n             //1 deleted row should be gone\n-            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n+            assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n         }\n     }\n \n     @Test(timeout=60000L)", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjExOA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622118", "bodyText": "Not sure exactly what the question means? Before it was testing the cleanup of the delete markers in an index, now it's testing the cleanup of the delete markers in a base table. The same code's getting exercised either way.", "author": "gjacoby126", "createdAt": "2020-01-14T23:12:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNTAwMA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366625000", "bodyText": "aah! my bad, I misunderstood this.", "author": "swaroopak", "createdAt": "2020-01-14T23:21:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTMyNw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366671327", "bodyText": "And now we're testing both.", "author": "gjacoby126", "createdAt": "2020-01-15T02:34:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxOTg2MA=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -129,46 +131,64 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n     public void testRecentlyDeletedRowsNotCompactedAway() throws Exception {\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             TableName dataTable = TableName.valueOf(dataTableName);\n             populateTable(dataTableName);\n+            createIndex(dataTableName, indexName, 1);\n+            TableName indexTable = TableName.valueOf(indexName);\n             //make sure we're after the inserts have been committed\n-            injectEdge.incValue(1);\n+            injectEdge.incrementValue(1);\n             long beforeDeleteSCN = EnvironmentEdgeManager.currentTimeMillis();\n-            injectEdge.incValue(10); //make sure we delete at a different ts\n+            injectEdge.incrementValue(10); //make sure we delete at a different ts\n             Statement stmt = conn.createStatement();\n             stmt.execute(\"DELETE FROM \" + dataTableName + \" WHERE \" + \" id = 'a'\");\n             Assert.assertEquals(1, stmt.getUpdateCount());\n             conn.commit();\n             //select stmt to get row we deleted\n             String sql = String.format(\"SELECT * FROM %s WHERE id = 'a'\", dataTableName);\n+            String indexSql = String.format(\"SELECT * FROM %s WHERE val1 = 'ab'\", dataTableName);\n             int rowsPlusDeleteMarker = ROWS_POPULATED;\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(), indexSql, beforeDeleteSCN, true);\n             flush(dataTable);\n+            flush(indexTable);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n+            assertRowExistsAtSCN(getUrl(), indexSql, beforeDeleteSCN, true);\n             long beforeFirstCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n-            injectEdge.incValue(1); //new ts for major compaction\n+            injectEdge.incrementValue(1); //new ts for major compaction\n             majorCompact(dataTable, beforeFirstCompactSCN);\n+            majorCompact(indexTable, beforeFirstCompactSCN);\n             assertRawRowCount(conn, dataTable, rowsPlusDeleteMarker);\n-            assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n+            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n             //wait for the lookback time. After this compactions should purge the deleted row\n-            injectEdge.incValue(MAX_LOOKBACK_AGE * 1000);\n+            injectEdge.incrementValue(MAX_LOOKBACK_AGE * 1000);\n             long beforeSecondCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n             String notDeletedRowSql =\n                 String.format(\"SELECT * FROM %s WHERE id = 'b'\", dataTableName);\n+            String notDeletedIndexRowSql =\n+                String.format(\"SELECT * FROM %s WHERE val1 = 'bc'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n+            assertRowExistsAtSCN(getUrl(), notDeletedIndexRowSql, beforeSecondCompactSCN, true);\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n+            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n             conn.createStatement().execute(\"upsert into \" + dataTableName +\n                 \" values ('c', 'cd', 'cde', 'cdef')\");\n             conn.commit();\n             majorCompact(dataTable, beforeSecondCompactSCN);\n+            majorCompact(indexTable, beforeSecondCompactSCN);\n+            //should still be ROWS_POPULATED because we added one and deleted one\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n+            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n+\n             //deleted row should be gone, but not deleted row should still be there.\n             assertRowExistsAtSCN(getUrl(), sql, beforeSecondCompactSCN, false);\n+            assertRowExistsAtSCN(getUrl(), indexSql, beforeSecondCompactSCN, false);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n-            //1 deleted row should be gone\n-            assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n+            assertRowExistsAtSCN(getUrl(), notDeletedIndexRowSql, beforeSecondCompactSCN, true);\n+\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMDA3Nw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366620077", "bodyText": "nit : timeToAdvance sounds better than timeToSleep to me", "author": "kadirozde", "createdAt": "2020-01-14T23:06:38Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1);\n+            long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasTtl(conn, dataTable, ttl);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);\n-            assertTableHasTtl(conn, indexTable, ttl);\n-\n             //first make sure we inserted correctly\n-            String sql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //force a flush\n-            flush(indexTable);\n+            flush(dataTable);\n             //flush shouldn't have changed it\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+                (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n+            if (timeToSleep > 0) {\n+                injectEdge.incValue(timeToSleep);\n+                //Thread.sleep(timeToSleep);\n+            }\n+            //make sure it's still on disk\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n+            injectEdge.incValue(1); //get a new timestamp for compaction\n+            majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            //nothing should have been purged by this major compaction\n+            assertRawRowCount(conn, dataTable, originalRowCount);\n             //now wait the TTL\n-            Thread.sleep((ttl +1) * 1000);\n-            long afterTTLExpiresSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n-            assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            //make sure we can't see it after expiration from masking\n-            assertRowExistsAtSCN(getUrl(), sql, afterTTLExpiresSCN, false);\n-            //but it's still on disk\n-            assertRawRowCount(conn, indexTable, originalRowCount);\n-            long beforeMajorCompactSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n-            majorCompact(indexTable, beforeMajorCompactSCN);\n-            assertRawRowCount(conn, indexTable, 0);\n+            timeToSleep = (ttl * 1000) -", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -184,54 +204,67 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            //increment by 10 min to make sure we don't \"look back\" past table creation\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            //increment to make sure we don't \"look back\" past table creation\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n-            injectEdge.incValue(1);\n+            createIndex(dataTableName, indexName, 1);\n+            injectEdge.incrementValue(1);\n             long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n+            TableName indexTable = TableName.valueOf(indexName);\n             assertTableHasTtl(conn, dataTable, ttl);\n+            assertTableHasTtl(conn, indexTable, ttl);\n             //first make sure we inserted correctly\n             String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n-          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String indexSql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(),indexSql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //force a flush\n             flush(dataTable);\n+            flush(indexTable);\n             //flush shouldn't have changed it\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            long timeToAdvance = (MAX_LOOKBACK_AGE * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n-                //Thread.sleep(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure it's still on disk\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-            injectEdge.incValue(1); //get a new timestamp for compaction\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            injectEdge.incrementValue(1); //get a new timestamp for compaction\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //nothing should have been purged by this major compaction\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //now wait the TTL\n-            timeToSleep = (ttl * 1000) -\n+            timeToAdvance = (ttl * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure that we can compact away the now-expired rows\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //note that before HBase 1.4, we don't have HBASE-17956\n             // and this will always return 0 whether it's still on-disk or not\n             assertRawRowCount(conn, dataTable, 0);\n+            assertRawRowCount(conn, indexTable, 0);\n         } finally{\n             conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, oldMemstoreFlushInterval);\n         }\n     }\n \n-    @Test\n+    @Test(timeout=60000)\n     public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         int versions = 2;\n         optionBuilder.append(\"VERSIONS=\" + versions);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMTYzNA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366621634", "bodyText": "nit: increamentValue", "author": "swaroopak", "createdAt": "2020-01-14T23:11:06Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -105,60 +129,52 @@ public void testTooLowSCNWithMaxLookbackAge() throws Exception {\n     public void testRecentlyDeletedRowsNotCompactedAway() throws Exception {\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            String fullIndexName = indexStem + \"1\";\n+            createTable(dataTableName);\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjYyOQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622629", "bodyText": "The ManualEnvironmentEdge is copied from HBase code, where that's the method name. I couldn't use the HBase class because Phoenix's EEM is odd and requires a specific abstract subclass of Edge", "author": "gjacoby126", "createdAt": "2020-01-14T23:14:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMTYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNDczNA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366624734", "bodyText": "Given that code does not override the method, it makes sense to rename the method.", "author": "swaroopak", "createdAt": "2020-01-14T23:21:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMTYzNA=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -129,46 +131,64 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n     public void testRecentlyDeletedRowsNotCompactedAway() throws Exception {\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             TableName dataTable = TableName.valueOf(dataTableName);\n             populateTable(dataTableName);\n+            createIndex(dataTableName, indexName, 1);\n+            TableName indexTable = TableName.valueOf(indexName);\n             //make sure we're after the inserts have been committed\n-            injectEdge.incValue(1);\n+            injectEdge.incrementValue(1);\n             long beforeDeleteSCN = EnvironmentEdgeManager.currentTimeMillis();\n-            injectEdge.incValue(10); //make sure we delete at a different ts\n+            injectEdge.incrementValue(10); //make sure we delete at a different ts\n             Statement stmt = conn.createStatement();\n             stmt.execute(\"DELETE FROM \" + dataTableName + \" WHERE \" + \" id = 'a'\");\n             Assert.assertEquals(1, stmt.getUpdateCount());\n             conn.commit();\n             //select stmt to get row we deleted\n             String sql = String.format(\"SELECT * FROM %s WHERE id = 'a'\", dataTableName);\n+            String indexSql = String.format(\"SELECT * FROM %s WHERE val1 = 'ab'\", dataTableName);\n             int rowsPlusDeleteMarker = ROWS_POPULATED;\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(), indexSql, beforeDeleteSCN, true);\n             flush(dataTable);\n+            flush(indexTable);\n             assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n+            assertRowExistsAtSCN(getUrl(), indexSql, beforeDeleteSCN, true);\n             long beforeFirstCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n-            injectEdge.incValue(1); //new ts for major compaction\n+            injectEdge.incrementValue(1); //new ts for major compaction\n             majorCompact(dataTable, beforeFirstCompactSCN);\n+            majorCompact(indexTable, beforeFirstCompactSCN);\n             assertRawRowCount(conn, dataTable, rowsPlusDeleteMarker);\n-            assertRowExistsAtSCN(getUrl(), sql, beforeDeleteSCN, true);\n+            assertRawRowCount(conn, indexTable, rowsPlusDeleteMarker);\n             //wait for the lookback time. After this compactions should purge the deleted row\n-            injectEdge.incValue(MAX_LOOKBACK_AGE * 1000);\n+            injectEdge.incrementValue(MAX_LOOKBACK_AGE * 1000);\n             long beforeSecondCompactSCN = EnvironmentEdgeManager.currentTimeMillis();\n             String notDeletedRowSql =\n                 String.format(\"SELECT * FROM %s WHERE id = 'b'\", dataTableName);\n+            String notDeletedIndexRowSql =\n+                String.format(\"SELECT * FROM %s WHERE val1 = 'bc'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n+            assertRowExistsAtSCN(getUrl(), notDeletedIndexRowSql, beforeSecondCompactSCN, true);\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n+            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n             conn.createStatement().execute(\"upsert into \" + dataTableName +\n                 \" values ('c', 'cd', 'cde', 'cdef')\");\n             conn.commit();\n             majorCompact(dataTable, beforeSecondCompactSCN);\n+            majorCompact(indexTable, beforeSecondCompactSCN);\n+            //should still be ROWS_POPULATED because we added one and deleted one\n             assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n+            assertRawRowCount(conn, indexTable, ROWS_POPULATED);\n+\n             //deleted row should be gone, but not deleted row should still be there.\n             assertRowExistsAtSCN(getUrl(), sql, beforeSecondCompactSCN, false);\n+            assertRowExistsAtSCN(getUrl(), indexSql, beforeSecondCompactSCN, false);\n             assertRowExistsAtSCN(getUrl(), notDeletedRowSql, beforeSecondCompactSCN, true);\n-            //1 deleted row should be gone\n-            assertRawRowCount(conn, dataTable, ROWS_POPULATED);\n+            assertRowExistsAtSCN(getUrl(), notDeletedIndexRowSql, beforeSecondCompactSCN, true);\n+\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622507", "bodyText": "What was the reason for eliminating index tables from the tests? Was not this JIRA originally about index tables?", "author": "kadirozde", "createdAt": "2020-01-14T23:13:54Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -213,62 +241,49 @@ public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         String thirdValue = \"ghi\";\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem, versions);\n-            long afterInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            populateTable(dataTableName);\n+            injectEdge.incValue(1); //increment by 1 so we can see our write\n+            long afterInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             //make sure table and index metadata is set up right for versions\n             TableName dataTable = TableName.valueOf(dataTableName);\n             assertTableHasVersions(conn, dataTable, versions);\n-            String fullIndexName = indexStem + \"1\";\n-            TableName indexTable = TableName.valueOf(fullIndexName);", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNTA2OQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366625069", "bodyText": "It was originally about index tables, but I eventually realized that this needed to apply to all tables in order for SCN to work properly, so there's nothing \"index specific\" about the functionality anymore.\nIf the consensus is that we should have specific index cases in here to make sure nothing in the indexing coprocs break the general behavior, I'll put some (back) in.", "author": "gjacoby126", "createdAt": "2020-01-14T23:22:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNzI3Ng==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366627276", "bodyText": "I suggest including indexes back and applying the same operations/checks to the index tables along with their data tables.", "author": "kadirozde", "createdAt": "2020-01-14T23:29:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYzNDE1MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366634151", "bodyText": "All right, will do.", "author": "gjacoby126", "createdAt": "2020-01-14T23:55:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUwNw=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -241,49 +274,68 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n         String thirdValue = \"ghi\";\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n             //increment by 10 min to make sure we don't \"look back\" past table creation\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n-            injectEdge.incValue(1); //increment by 1 so we can see our write\n+            createIndex(dataTableName, indexName, versions);\n+            injectEdge.incrementValue(1); //increment by 1 so we can see our write\n             long afterInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             //make sure table and index metadata is set up right for versions\n             TableName dataTable = TableName.valueOf(dataTableName);\n+            TableName indexTable = TableName.valueOf(indexName);\n             assertTableHasVersions(conn, dataTable, versions);\n+            assertTableHasVersions(conn, indexTable, versions);\n             //check query optimizer is doing what we expect\n             String dataTableSelectSql =\n                 String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n+            String indexTableSelectSql =\n+                String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n+            assertExplainPlan(conn, indexTableSelectSql, dataTableName, indexName);\n             //make sure the data was inserted correctly in the first place\n             assertRowHasExpectedValueAtSCN(getUrl(), dataTableSelectSql, afterInsertSCN, firstValue);\n+            assertRowHasExpectedValueAtSCN(getUrl(), indexTableSelectSql, afterInsertSCN, firstValue);\n             //force first update to get a distinct ts\n-            injectEdge.incValue(1);\n+            injectEdge.incrementValue(1);\n             updateColumn(conn, dataTableName, \"id\", \"a\", \"val2\", secondValue);\n-            injectEdge.incValue(1); //now make update visible\n+            injectEdge.incrementValue(1); //now make update visible\n             long afterFirstUpdateSCN = EnvironmentEdgeManager.currentTimeMillis();\n             //force second update to get a distinct ts\n-            injectEdge.incValue(1);\n+            injectEdge.incrementValue(1);\n             updateColumn(conn, dataTableName, \"id\", \"a\", \"val2\", thirdValue);\n-            injectEdge.incValue(1);\n+            injectEdge.incrementValue(1);\n             long afterSecondUpdateSCN = EnvironmentEdgeManager.currentTimeMillis();\n-            injectEdge.incValue(1);\n+            injectEdge.incrementValue(1);\n             //check to make sure we can see all three versions at the appropriate times\n             String[] allValues = {firstValue, secondValue, thirdValue};\n             long[] allSCNs = {afterInsertSCN, afterFirstUpdateSCN, afterSecondUpdateSCN};\n             assertMultiVersionLookbacks(dataTableSelectSql, allValues, allSCNs);\n+            assertMultiVersionLookbacks(indexTableSelectSql, allValues, allSCNs);\n             flush(dataTable);\n+            flush(indexTable);\n             //after flush, check to make sure we can see all three versions at the appropriate times\n             assertMultiVersionLookbacks(dataTableSelectSql, allValues, allSCNs);\n+            assertMultiVersionLookbacks(indexTableSelectSql, allValues, allSCNs);\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //after major compaction, check to make sure we can see all three versions\n             // at the appropriate times\n             assertMultiVersionLookbacks(dataTableSelectSql, allValues, allSCNs);\n-            injectEdge.incValue(MAX_LOOKBACK_AGE * 1000);\n+            assertMultiVersionLookbacks(indexTableSelectSql, allValues, allSCNs);\n+            injectEdge.incrementValue(MAX_LOOKBACK_AGE * 1000);\n             long afterLookbackAgeSCN = EnvironmentEdgeManager.currentTimeMillis();\n             majorCompact(dataTable, afterLookbackAgeSCN);\n+            majorCompact(indexTable, afterLookbackAgeSCN);\n             //empty column, 1 version of val 1, 3 versions of val2, 1 version of val3 = 6\n             assertRawCellCount(conn, dataTable, Bytes.toBytes(\"a\"), 6);\n+            //2 versions of empty column, 2 versions of val2,\n+            // 2 versions of val3 (since we write whole rows to index) = 6\n+            assertRawCellCount(conn, indexTable, Bytes.toBytes(\"ab\\u0000a\"), 6);\n             //empty column + 1 version each of val1,2 and 3 = 4\n             assertRawCellCount(conn, dataTable, Bytes.toBytes(\"b\"), 4);\n+            //1 version of empty column, 1 version of val2, 1 version of val3 = 3\n+            assertRawCellCount(conn, indexTable, Bytes.toBytes(\"bc\\u0000b\"), 3);\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366622515", "bodyText": "Nit: consistent comment here", "author": "priyankporwal", "createdAt": "2020-01-14T23:13:55Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -168,36 +184,48 @@ public void testTTLAndMaxLookbackAge() throws Exception {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem);\n-            long afterFirstInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation", "originalCommit": "28edd1500a192ab700a56569f074503db7e409d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNjQzOA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366626438", "bodyText": "WAIT_AFTER_TABLE_CREATION isn't meant to be a factor of MAX_LOOKBACK_AGE -- it's just an arbitrarily large number to make sure that all the metadata is older than the current timestamp. It could probably be lower, but since the size doesn't cost us anything I didn't spend too much time trying to optimize it.", "author": "gjacoby126", "createdAt": "2020-01-14T23:26:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNzQ3Ng==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366627476", "bodyText": "Turns out any value >= 1 works. I'll just switch it to 1", "author": "gjacoby126", "createdAt": "2020-01-14T23:30:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYzNDA0MA==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366634040", "bodyText": "The suggestion was not to have WAIT_AFTER_TABLE_CREATION be a multiple of MAX_LOOKBACK_AGE necessarily, but something larger than MAX_LOOKBACK_AGE  -- just something so that if you did (now - MAX_LOOKBACK_AGE) it didn't go before table creation time.", "author": "priyankporwal", "createdAt": "2020-01-14T23:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY0OTM0MQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366649341", "bodyText": "That's not necessary because we always advance time by MAX_LOOKBACK_AGE before trying to look back that far.", "author": "gjacoby126", "createdAt": "2020-01-15T00:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyMjUxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "c1a379096486f55a77859eeea676c23f0e677914", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex 33f9ca019..a0add7d6c 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -184,54 +204,67 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n         conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, 0L);\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n+            String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            //increment by 10 min to make sure we don't \"look back\" past table creation\n-            injectEdge.incValue(WAIT_AFTER_TABLE_CREATION);\n+            //increment to make sure we don't \"look back\" past table creation\n+            injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n-            injectEdge.incValue(1);\n+            createIndex(dataTableName, indexName, 1);\n+            injectEdge.incrementValue(1);\n             long afterFirstInsertSCN = EnvironmentEdgeManager.currentTimeMillis();\n             TableName dataTable = TableName.valueOf(dataTableName);\n+            TableName indexTable = TableName.valueOf(indexName);\n             assertTableHasTtl(conn, dataTable, ttl);\n+            assertTableHasTtl(conn, indexTable, ttl);\n             //first make sure we inserted correctly\n             String sql = String.format(\"SELECT val2 FROM %s WHERE id = 'a'\", dataTableName);\n-          //  assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n+            String indexSql = String.format(\"SELECT val2 FROM %s WHERE val1 = 'ab'\", dataTableName);\n             assertRowExistsAtSCN(getUrl(),sql, afterFirstInsertSCN, true);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            assertRowExistsAtSCN(getUrl(),indexSql, afterFirstInsertSCN, true);\n             int originalRowCount = 2;\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //force a flush\n             flush(dataTable);\n+            flush(indexTable);\n             //flush shouldn't have changed it\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-                      // assertExplainPlan(conn, sql, dataTableName, fullIndexName);\n-            long timeToSleep = (MAX_LOOKBACK_AGE * 1000) -\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            assertExplainPlan(conn, indexSql, dataTableName, indexName);\n+            long timeToAdvance = (MAX_LOOKBACK_AGE * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n-                //Thread.sleep(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure it's still on disk\n             assertRawRowCount(conn, dataTable, originalRowCount);\n-            injectEdge.incValue(1); //get a new timestamp for compaction\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n+            injectEdge.incrementValue(1); //get a new timestamp for compaction\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //nothing should have been purged by this major compaction\n             assertRawRowCount(conn, dataTable, originalRowCount);\n+            assertRawRowCount(conn, indexTable, originalRowCount);\n             //now wait the TTL\n-            timeToSleep = (ttl * 1000) -\n+            timeToAdvance = (ttl * 1000) -\n                 (EnvironmentEdgeManager.currentTimeMillis() - afterFirstInsertSCN);\n-            if (timeToSleep > 0) {\n-                injectEdge.incValue(timeToSleep);\n+            if (timeToAdvance > 0) {\n+                injectEdge.incrementValue(timeToAdvance);\n             }\n             //make sure that we can compact away the now-expired rows\n             majorCompact(dataTable, EnvironmentEdgeManager.currentTimeMillis());\n+            majorCompact(indexTable, EnvironmentEdgeManager.currentTimeMillis());\n             //note that before HBase 1.4, we don't have HBASE-17956\n             // and this will always return 0 whether it's still on-disk or not\n             assertRawRowCount(conn, dataTable, 0);\n+            assertRawRowCount(conn, indexTable, 0);\n         } finally{\n             conf.setLong(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, oldMemstoreFlushInterval);\n         }\n     }\n \n-    @Test\n+    @Test(timeout=60000)\n     public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         int versions = 2;\n         optionBuilder.append(\"VERSIONS=\" + versions);\n"}}, {"oid": "c1a379096486f55a77859eeea676c23f0e677914", "url": "https://github.com/apache/phoenix/commit/c1a379096486f55a77859eeea676c23f0e677914", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-15T00:51:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY1MzUxMQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366653511", "bodyText": "Nit: the comment is not right (nothing here equals 10mins).. wait is only 1 ms now", "author": "priyankporwal", "createdAt": "2020-01-15T01:10:56Z", "path": "phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java", "diffHunk": "@@ -213,51 +274,57 @@ public void testRecentMaxVersionsNotCompactedAway() throws Exception {\n         String thirdValue = \"ghi\";\n         try (Connection conn = DriverManager.getConnection(getUrl())) {\n             String dataTableName = generateUniqueName();\n-            String indexStem = generateUniqueName();\n-            createTableAndIndexes(conn, dataTableName, indexStem, versions);\n-            long afterInsertSCN = org.apache.phoenix.util.EnvironmentEdgeManager.currentTimeMillis();\n+            String indexName = generateUniqueName();\n+            createTable(dataTableName);\n+            //increment by 10 min to make sure we don't \"look back\" past table creation", "originalCommit": "c1a379096486f55a77859eeea676c23f0e677914", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTExMQ==", "url": "https://github.com/apache/phoenix/pull/679#discussion_r366671111", "bodyText": "Thanks, good catch. Fixed.", "author": "gjacoby126", "createdAt": "2020-01-15T02:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY1MzUxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "6f94f04345f37e091f04241090f0b03256b63ad6", "chunk": "diff --git a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\nindex a0add7d6c..37a3c81d8 100644\n--- a/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n+++ b/phoenix-core/src/it/java/org/apache/phoenix/end2end/MaxLookbackIT.java\n\n@@ -276,7 +276,7 @@ public class MaxLookbackIT extends BaseUniqueNamesOwnClusterIT {\n             String dataTableName = generateUniqueName();\n             String indexName = generateUniqueName();\n             createTable(dataTableName);\n-            //increment by 10 min to make sure we don't \"look back\" past table creation\n+            //increment to make sure we don't \"look back\" past table creation\n             injectEdge.incrementValue(WAIT_AFTER_TABLE_CREATION_MILLIS);\n             populateTable(dataTableName);\n             createIndex(dataTableName, indexName, versions);\n"}}, {"oid": "6f94f04345f37e091f04241090f0b03256b63ad6", "url": "https://github.com/apache/phoenix/commit/6f94f04345f37e091f04241090f0b03256b63ad6", "message": "PHOENIX-5645 - GlobalIndexChecker should prevent compaction from purging very recently deleted cells (addendum)", "committedDate": "2020-01-15T02:33:10Z", "type": "commit"}]}