{"pr_number": 474, "pr_title": "Optimize hive metadata", "pr_createdAt": "2020-10-28T22:37:53Z", "pr_url": "https://github.com/greenplum-db/pxf/pull/474", "timeline": [{"oid": "cfbed494ab4a14389a910eb2073f4ada4aa230cb", "url": "https://github.com/greenplum-db/pxf/commit/cfbed494ab4a14389a910eb2073f4ada4aa230cb", "message": "HiveUserData: Remove filterInFragmenter\n\nThe `filterInFragmenter` field is not being consumed by anyone. Removing\nit.", "committedDate": "2020-10-27T18:18:03Z", "type": "commit"}, {"oid": "a83dad1d78965b554db404324d9fa2ef1916d2ef", "url": "https://github.com/greenplum-db/pxf/commit/a83dad1d78965b554db404324d9fa2ef1916d2ef", "message": "HiveUserData: Remove allColumnTypes from HiveUserData", "committedDate": "2020-10-27T21:40:19Z", "type": "commit"}, {"oid": "06d27a386f36597572cb13021a1c81b6600ba1ec", "url": "https://github.com/greenplum-db/pxf/commit/06d27a386f36597572cb13021a1c81b6600ba1ec", "message": "Parse HiveUserData once\n\nParse the HiveUserData object once during the accessor call. The parsed\nHiveUserData is then shipped to the resolver using the\nRequestContext#metadata field.", "committedDate": "2020-10-28T15:03:00Z", "type": "commit"}, {"oid": "e6c8963fd226403abb89ba550d3a6f800a5c3881", "url": "https://github.com/greenplum-db/pxf/commit/e6c8963fd226403abb89ba550d3a6f800a5c3881", "message": "HiveUserData: Remove serdeClassName from HiveUserData\n\nThe serde class name is available in the properties used for serde.", "committedDate": "2020-10-28T15:33:12Z", "type": "commit"}, {"oid": "c75fa0ed6455ff49e0ef33e06448746a4f0b0673", "url": "https://github.com/greenplum-db/pxf/commit/c75fa0ed6455ff49e0ef33e06448746a4f0b0673", "message": "HiveUserData: Remove inputFormatName from HiveUserData\n\nThe input format class name can be retrieved from the serde properties\nby accessing the \"file.inputformat\" property.", "committedDate": "2020-10-28T16:02:03Z", "type": "commit"}, {"oid": "f525f932bfc61acbc7b7d2a5c86480ebfbb8b633", "url": "https://github.com/greenplum-db/pxf/commit/f525f932bfc61acbc7b7d2a5c86480ebfbb8b633", "message": "HiveUserData: Remove allColumnNames from HiveUserData\n\nThe same information is retrieved from the \"columns\" property of the\nmetadata properties that were retrieved during fragmentation.", "committedDate": "2020-10-28T16:51:22Z", "type": "commit"}, {"oid": "197f0fcb8f31bf037749471576c816b8543fc5e4", "url": "https://github.com/greenplum-db/pxf/commit/197f0fcb8f31bf037749471576c816b8543fc5e4", "message": "HiveUserData: Remove colTypes from HiveUserData\n\nThe column types can be retrieved from the metadata properties that are\nshipped by the Fragmenter.", "committedDate": "2020-10-28T17:02:32Z", "type": "commit"}, {"oid": "a70b39b7ec0760c88defa1f7064c3be00bd6222d", "url": "https://github.com/greenplum-db/pxf/commit/a70b39b7ec0760c88defa1f7064c3be00bd6222d", "message": "HiveUserData: Remove skipHeader from HiveUserData\n\nThe skip header property is part of the metadata properties that we ship\nfrom the fragmenter call.", "committedDate": "2020-10-28T17:32:44Z", "type": "commit"}, {"oid": "9e92c418df222b53ef558c13afea77526d832a2c", "url": "https://github.com/greenplum-db/pxf/commit/9e92c418df222b53ef558c13afea77526d832a2c", "message": "HiveUserData: Remove delimiter property from HiveUserData\n\nMerge map where the property is coming from with the properties. Parse\ndelimiter at the Resolver only if needed.", "committedDate": "2020-10-28T19:20:39Z", "type": "commit"}, {"oid": "d620da574ba1358ff201820b1d1b04f1c406398a", "url": "https://github.com/greenplum-db/pxf/commit/d620da574ba1358ff201820b1d1b04f1c406398a", "message": "wip", "committedDate": "2020-10-28T21:36:28Z", "type": "commit"}, {"oid": "8946796f68374e6f5dbefcd114742a8ca074e025", "url": "https://github.com/greenplum-db/pxf/commit/8946796f68374e6f5dbefcd114742a8ca074e025", "message": "Remove HiveUserData\n\nOnly pass the schema properties from the fragmenter to the\naccessor/resolver.", "committedDate": "2020-10-28T22:19:01Z", "type": "commit"}, {"oid": "c74d01774bb9a178efa22b42afcbeb5bf916e734", "url": "https://github.com/greenplum-db/pxf/commit/c74d01774bb9a178efa22b42afcbeb5bf916e734", "message": "Fix automation tests", "committedDate": "2020-10-28T23:03:25Z", "type": "commit"}, {"oid": "35000a43efada854dc90818031757f6d59c988b8", "url": "https://github.com/greenplum-db/pxf/commit/35000a43efada854dc90818031757f6d59c988b8", "message": "Hardcode HOSTS as it is no longer being used", "committedDate": "2020-10-29T01:55:06Z", "type": "commit"}, {"oid": "60e9443f2f7fc61b9e443900163ee86e5f05cc0b", "url": "https://github.com/greenplum-db/pxf/commit/60e9443f2f7fc61b9e443900163ee86e5f05cc0b", "message": "Remove properties not used", "committedDate": "2020-10-29T17:51:58Z", "type": "commit"}, {"oid": "30df0fe477ccf2e8d6a9ad51e7d448774bcd7d40", "url": "https://github.com/greenplum-db/pxf/commit/30df0fe477ccf2e8d6a9ad51e7d448774bcd7d40", "message": "Use Kryo to serialize properties", "committedDate": "2020-10-29T21:13:14Z", "type": "commit"}, {"oid": "3b5fe26b39b798e016031cf1ab39b2836930c380", "url": "https://github.com/greenplum-db/pxf/commit/3b5fe26b39b798e016031cf1ab39b2836930c380", "message": "Use a custom Properties serializer", "committedDate": "2020-10-30T00:41:53Z", "type": "commit"}, {"oid": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "url": "https://github.com/greenplum-db/pxf/commit/e431cec5e4393405c20fa37d1b3155a6ab8b711b", "message": "Add javadocs and tests", "committedDate": "2020-10-30T22:46:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE4Mjg4NQ==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516182885", "bodyText": "why do we need ThreadLocal, is it very expensive to build ? Seems like a pre-mature optimization.", "author": "denalex", "createdAt": "2020-11-02T18:44:47Z", "path": "automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java", "diffHunk": "@@ -36,10 +37,11 @@\n public class MultipleHiveFragmentsPerFileFragmenter extends BaseFragmenter {\n     private static final Log LOG = LogFactory.getLog(MultipleHiveFragmentsPerFileFragmenter.class);\n \n+    private static final ThreadLocal<Kryo> kryo = ThreadLocal.withInitial(Kryo::new);", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMDI5MQ==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516210291", "bodyText": "it's very expensive to build and not thread-safe. I have a comment somewhere else for that. It is also the way it's used in Hive.", "author": "frankgh", "createdAt": "2020-11-02T19:38:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE4Mjg4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java b/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java\nindex 1bef7fc3..f9d7731c 100755\n--- a/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java\n+++ b/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java\n\n@@ -37,7 +37,6 @@ import java.util.Properties;\n public class MultipleHiveFragmentsPerFileFragmenter extends BaseFragmenter {\n     private static final Log LOG = LogFactory.getLog(MultipleHiveFragmentsPerFileFragmenter.class);\n \n-    private static final ThreadLocal<Kryo> kryo = ThreadLocal.withInitial(Kryo::new);\n     private static final long SPLIT_SIZE = 1024;\n     private JobConf jobConf;\n     private IMetaStoreClient client;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE4ODUxMQ==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516188511", "bodyText": "this function is repeated elsewhere, can it go into Utilities ?", "author": "denalex", "createdAt": "2020-11-02T18:55:15Z", "path": "automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java", "diffHunk": "@@ -113,10 +109,16 @@ private String getFilePath(Table tbl) throws Exception {\n \n         for (InputSplit split : splits) {\n             FileSplit fsp = (FileSplit) split;\n-            String[] hosts = fsp.getLocations();\n-            String filepath = fsp.getPath().toString();\n-            return filepath;\n+            return fsp.getPath().toString();\n         }\n         throw new RuntimeException(\"Unable to get file path for table.\");\n     }\n+\n+    /* Turns a Properties class into a string */\n+    private byte[] serializeProperties(Properties properties) {\n+        Output out = new Output(4 * 1024, 10 * 1024 * 1024);\n+        kryo.get().writeObject(out, properties);\n+        out.close();\n+        return out.toBytes();", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java b/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java\nindex 1bef7fc3..f9d7731c 100755\n--- a/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java\n+++ b/automation/src/main/java/org/greenplum/pxf/automation/testplugin/MultipleHiveFragmentsPerFileFragmenter.java\n\n@@ -113,12 +112,4 @@ public class MultipleHiveFragmentsPerFileFragmenter extends BaseFragmenter {\n         }\n         throw new RuntimeException(\"Unable to get file path for table.\");\n     }\n-\n-    /* Turns a Properties class into a string */\n-    private byte[] serializeProperties(Properties properties) {\n-        Output out = new Output(4 * 1024, 10 * 1024 * 1024);\n-        kryo.get().writeObject(out, properties);\n-        out.close();\n-        return out.toBytes();\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE4OTYwNg==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516189606", "bodyText": "this is the 3rd use of ThreadLocal, I believe", "author": "denalex", "createdAt": "2020-11-02T18:57:22Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java", "diffHunk": "@@ -46,7 +52,15 @@\n     private static final Logger LOG = LoggerFactory.getLogger(HiveClientWrapper.class);\n \n     private static final String WILDCARD = \"*\";\n-    private static final int DEFAULT_DELIMITER_CODE = 44;\n+\n+    // The Kryo instance is not thread safe, and quite expensive to build,\n+    // storing it on a ThreadLocal is a recommended way to make sure that the\n+    // serializer is thread safe.\n+    private static final ThreadLocal<Kryo> kryo = ThreadLocal.withInitial(() -> {\n+        Kryo k = new Kryo();\n+        k.addDefaultSerializer(Map.class, PropertiesSerializer.class);\n+        return k;\n+    });", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java\nindex 6d1f9028..62f767c2 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java\n\n@@ -53,15 +50,6 @@ public class HiveClientWrapper {\n \n     private static final String WILDCARD = \"*\";\n \n-    // The Kryo instance is not thread safe, and quite expensive to build,\n-    // storing it on a ThreadLocal is a recommended way to make sure that the\n-    // serializer is thread safe.\n-    private static final ThreadLocal<Kryo> kryo = ThreadLocal.withInitial(() -> {\n-        Kryo k = new Kryo();\n-        k.addDefaultSerializer(Map.class, PropertiesSerializer.class);\n-        return k;\n-    });\n-\n     private static final String STR_RC_FILE_INPUT_FORMAT = \"org.apache.hadoop.hive.ql.io.RCFileInputFormat\";\n     private static final String STR_TEXT_FILE_INPUT_FORMAT = \"org.apache.hadoop.mapred.TextInputFormat\";\n     private static final String STR_ORC_FILE_INPUT_FORMAT = \"org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\";\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE4OTgyNA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516189824", "bodyText": "move to Utilities ?", "author": "denalex", "createdAt": "2020-11-02T18:57:47Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java", "diffHunk": "@@ -318,68 +315,55 @@ private HiveConf getHiveConf(Configuration configuration) {\n     }\n \n     /* Turns a Properties class into a string */\n-    private String serializeProperties(Properties props) throws Exception {\n-        ByteArrayOutputStream outStream = new ByteArrayOutputStream();\n-        props.store(outStream, \"\"/* comments */);\n-        return outStream.toString();\n+    private byte[] serializeProperties(Properties properties) {\n+        Output out = new Output(4 * 1024, 10 * 1024 * 1024);\n+        kryo.get().writeObject(out, properties);\n+        out.close();\n+        return out.toBytes();", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java\nindex 6d1f9028..62f767c2 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveClientWrapper.java\n\n@@ -314,14 +302,6 @@ public class HiveClientWrapper {\n         return hiveConf;\n     }\n \n-    /* Turns a Properties class into a string */\n-    private byte[] serializeProperties(Properties properties) {\n-        Output out = new Output(4 * 1024, 10 * 1024 * 1024);\n-        kryo.get().writeObject(out, properties);\n-        out.close();\n-        return out.toBytes();\n-    }\n-\n     /* Turns the partition values into a string and adds them to the properties */\n     private void addPartitionValuesInformation(Properties properties, HiveTablePartition partData) {\n         if (partData.partition != null) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5MDkzMw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516190933", "bodyText": "there was lowerCase() in the old logic. maybe it is taken care of somewhere else", "author": "denalex", "createdAt": "2020-11-02T18:59:55Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveColumnarSerdeResolver.java", "diffHunk": "@@ -109,15 +95,8 @@ void initPartitionFields() {\n      */\n     @Override\n     void initTextPartitionFields(StringBuilder parts) {\n-        if (partitionKeys.equals(HiveDataFragmenter.HIVE_NO_PART_TBL)) {\n-            return;\n-        }\n-\n-        String[] partitionLevels = partitionKeys.split(HiveDataFragmenter.HIVE_PARTITIONS_DELIM);\n-        for (String partLevel : partitionLevels) {\n-            String[] levelKey = partLevel.split(HiveDataFragmenter.HIVE_1_PART_DELIM);\n-            partitionColumnNames.put(StringUtils.lowerCase(levelKey[0]), levelKey);\n-        }\n+        partitionColumnNames = metadata.getPartitions().stream()\n+                .collect(Collectors.toMap(HivePartition::getName, partition -> partition));", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0MjA4Ng==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516242086", "bodyText": "good catch. Adding it back", "author": "frankgh", "createdAt": "2020-11-02T20:42:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5MDkzMw=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveColumnarSerdeResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveColumnarSerdeResolver.java\nindex af45ad49..fc58fce3 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveColumnarSerdeResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveColumnarSerdeResolver.java\n\n@@ -96,7 +95,8 @@ public class HiveColumnarSerdeResolver extends HiveResolver {\n     @Override\n     void initTextPartitionFields(StringBuilder parts) {\n         partitionColumnNames = metadata.getPartitions().stream()\n-                .collect(Collectors.toMap(HivePartition::getName, partition -> partition));\n+                .collect(Collectors.toMap(partition -> StringUtils.lowerCase(partition.getName()),\n+                        partition -> partition));\n     }\n \n     /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5NjUwNw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516196507", "bodyText": "why shorten the variable name ?", "author": "denalex", "createdAt": "2020-11-02T19:11:00Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -78,23 +77,28 @@\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n+import static org.apache.hadoop.hive.serde.serdeConstants.SERIALIZATION_LIB;\n+\n /**\n  * Class HiveResolver handles deserialization of records that were serialized\n  * using Hadoop's Hive serialization framework.\n  */\n public class HiveResolver extends HivePlugin implements Resolver {\n+\n     private static final Logger LOG = LoggerFactory.getLogger(HiveResolver.class);\n+\n     protected static final String MAPKEY_DELIM = \":\";\n     protected static final String COLLECTION_DELIM = \",\";\n     protected static final String nullChar = \"\\\\N\";\n+\n     protected char delimiter;\n     protected String collectionDelim;\n     protected String mapkeyDelim;\n-    protected Deserializer deserializer;\n+    protected Deserializer d;", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMTIzNA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516211234", "bodyText": "ahh! good catch. I changed this variable name so I can identify what breaks. I forgot to restore it after I fixed all problems", "author": "frankgh", "createdAt": "2020-11-02T19:40:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5NjUwNw=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\nindex 71830ec7..9ee512ca 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n\n@@ -94,7 +94,7 @@ public class HiveResolver extends HivePlugin implements Resolver {\n     protected char delimiter;\n     protected String collectionDelim;\n     protected String mapkeyDelim;\n-    protected Deserializer d;\n+    protected Deserializer deserializer;\n     protected String serdeClassName;\n     protected List<Integer> hiveIndexes;\n     protected Properties metastoreProperties;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5NzQ0NA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516197444", "bodyText": "isn't this also a class field ?", "author": "denalex", "createdAt": "2020-11-02T19:13:00Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -105,25 +109,17 @@\n      * obtaining the serde class name, the serde properties string and the\n      * partition keys.\n      *\n-     * @param requestContext request context\n+     * @param context request context\n      */\n     @Override\n-    public void initialize(RequestContext requestContext) {\n-        super.initialize(requestContext);\n-\n+    public void initialize(RequestContext context) {\n+        super.initialize(context);\n         hiveDefaultPartName = HiveConf.getVar(configuration, HiveConf.ConfVars.DEFAULTPARTITIONNAME);\n-\n-        try {\n-            parseUserData(context);\n-            initPartitionFields();\n-            initSerde(context);\n-        } catch (Exception e) {\n-            throw new RuntimeException(\"Failed to initialize HiveResolver\", e);\n-        }\n     }\n \n     @Override\n     public List<OneField> getFields(OneRow onerow) throws Exception {\n+        Deserializer deserializer = getDeserializer();", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMjE0NA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516212144", "bodyText": "it's lazily instantiated, that's why I use getDeserializer. The issue lies in timing of the \"metadata\" being available in the RequestContext. The metadata is only populated after openForRead. Which is why we can't access it earlier", "author": "frankgh", "createdAt": "2020-11-02T19:42:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5NzQ0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0MjY0Mg==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516242642", "bodyText": "I was wrong, we can access it from RequestContext. Removing the getDeserializer method", "author": "frankgh", "createdAt": "2020-11-02T20:43:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5NzQ0NA=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\nindex 71830ec7..9ee512ca 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n\n@@ -115,11 +115,18 @@ public class HiveResolver extends HivePlugin implements Resolver {\n     public void initialize(RequestContext context) {\n         super.initialize(context);\n         hiveDefaultPartName = HiveConf.getVar(configuration, HiveConf.ConfVars.DEFAULTPARTITIONNAME);\n+\n+        try {\n+            parseUserData(context);\n+            initPartitionFields();\n+            initSerde();\n+        } catch (Exception e) {\n+            throw new RuntimeException(\"Failed to initialize HiveResolver\", e);\n+        }\n     }\n \n     @Override\n     public List<OneField> getFields(OneRow onerow) throws Exception {\n-        Deserializer deserializer = getDeserializer();\n         Object tuple = deserializer.deserialize((Writable) onerow.getData());\n         // Each Hive record is a Struct\n         StructObjectInspector soi = (StructObjectInspector) deserializer.getObjectInspector();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5ODEyNw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516198127", "bodyText": "are we removing  HIVE_NO_PART_TBL altogether ?", "author": "denalex", "createdAt": "2020-11-02T19:14:24Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -279,25 +255,18 @@ void initPartitionFields() {\n         numberOfPartitions = partitionColumnNames.size();\n     }\n \n-    private boolean columnDescriptorContainsColumn(String columnName) {\n-        return context.getTupleDescription()\n-                .stream()\n-                .anyMatch(cd -> columnName.equals(cd.columnName()));\n-    }\n-\n     /*\n      * The partition fields are initialized one time based on userData provided\n      * by the fragmenter.\n      */\n     void initTextPartitionFields(StringBuilder parts) {\n-        if (partitionKeys.equals(HiveDataFragmenter.HIVE_NO_PART_TBL)) {\n+        List<HivePartition> hivePartitionList = metadata.getPartitions();", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMjUzMg==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516212532", "bodyText": "yes, that was a way to serialize partition information. That serialization was removed.", "author": "frankgh", "createdAt": "2020-11-02T19:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5ODEyNw=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\nindex 71830ec7..9ee512ca 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n\n@@ -249,7 +271,8 @@ public class HiveResolver extends HivePlugin implements Resolver {\n             }\n \n             if (columnDescriptorContainsColumn(columnName)) {\n-                partitionColumnNames.put(columnName, new OneField(convertedType.getOID(), convertedValue));\n+                partitionColumnNames.put(StringUtils.lowerCase(columnName),\n+                        new OneField(convertedType.getOID(), convertedValue));\n             }\n         }\n         numberOfPartitions = partitionColumnNames.size();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5ODk0NA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516198944", "bodyText": "are we deprecating DELIMITER user option (if it was used) ?", "author": "denalex", "createdAt": "2020-11-02T19:16:07Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -681,11 +650,7 @@ void parseDelimiterChar(RequestContext input) {\n \n         if (userDelim == null) {\n             /* No DELIMITER in URL, try to get it from fragment's user data*/\n-            HiveUserData hiveUserData = HiveUtilities.parseHiveUserData(input);\n-            if (hiveUserData.getDelimiter() == null) {\n-                throw new IllegalArgumentException(\"DELIMITER is a required option\");\n-            }\n-            delimiter = (char) Integer.valueOf(hiveUserData.getDelimiter()).intValue();\n+            delimiter = (char) HiveUtilities.getDelimiterCode(metastoreProperties);", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI2ODcyMw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516268723", "bodyText": "we probably don't need this branch of the code. I will add a TODO, but we might not want to remove this code as part of this PR", "author": "frankgh", "createdAt": "2020-11-02T21:37:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjE5ODk0NA=="}], "type": "inlineReview", "revised_code": {"commit": "d3981280aa02862e1ceb5464ba328216493c57dd", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\nindex 71830ec7..aa6efbd0 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n\n@@ -649,6 +672,7 @@ public class HiveResolver extends HivePlugin implements Resolver {\n                 String.valueOf(input.getGreenplumCSV().getDelimiter()) : null;\n \n         if (userDelim == null) {\n+            // TODO: this code path does not seem to be ever executed. Remove if unnecessary\n             /* No DELIMITER in URL, try to get it from fragment's user data*/\n             delimiter = (char) HiveUtilities.getDelimiterCode(metastoreProperties);\n         } else {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMDExOA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516200118", "bodyText": "this is a bit clunky how this works with protected fields, let's discuss", "author": "denalex", "createdAt": "2020-11-02T19:18:40Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -717,4 +682,35 @@ void parseDelimiterChar(RequestContext input) {\n             delimiter = userDelim.charAt(0);\n         }\n     }\n+\n+    protected Properties getSerdeProperties() {\n+        return metadata.getProperties();\n+    }\n+\n+    protected Deserializer getDeserializer() {\n+        if (d == null) {\n+            // HiveUserData is passed from accessor\n+            metadata = (HiveMetadata) context.getMetadata();\n+            if (metadata == null) {\n+                throw new RuntimeException(\"No hive metadata detected in request context\");\n+            }\n+\n+            try {\n+                parseUserData(context);\n+                initPartitionFields();\n+                Class<?> c = Class.forName(serdeClassName, true, JavaUtils.getClassLoader());\n+                d = (Deserializer) c.getDeclaredConstructor().newInstance();\n+                d.initialize(getJobConf(), metastoreProperties);\n+            } catch (Exception e) {\n+                throw new RuntimeException(\"Failed to initialize HiveResolver\", e);\n+            }\n+        }\n+        return d;", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0MjgwNQ==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516242805", "bodyText": "removed this method", "author": "frankgh", "createdAt": "2020-11-02T20:43:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMDExOA=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\nindex 71830ec7..9ee512ca 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n\n@@ -687,30 +710,9 @@ public class HiveResolver extends HivePlugin implements Resolver {\n         return metadata.getProperties();\n     }\n \n-    protected Deserializer getDeserializer() {\n-        if (d == null) {\n-            // HiveUserData is passed from accessor\n-            metadata = (HiveMetadata) context.getMetadata();\n-            if (metadata == null) {\n-                throw new RuntimeException(\"No hive metadata detected in request context\");\n-            }\n-\n-            try {\n-                parseUserData(context);\n-                initPartitionFields();\n-                Class<?> c = Class.forName(serdeClassName, true, JavaUtils.getClassLoader());\n-                d = (Deserializer) c.getDeclaredConstructor().newInstance();\n-                d.initialize(getJobConf(), metastoreProperties);\n-            } catch (Exception e) {\n-                throw new RuntimeException(\"Failed to initialize HiveResolver\", e);\n-            }\n-        }\n-        return d;\n-    }\n-\n     private boolean columnDescriptorContainsColumn(String columnName) {\n         return context.getTupleDescription()\n                 .stream()\n-                .anyMatch(cd -> columnName.equals(cd.columnName()));\n+                .anyMatch(cd -> StringUtils.equalsIgnoreCase(columnName, cd.columnName()));\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMDQ2NQ==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516200465", "bodyText": "do we care about case insensitivity ?", "author": "denalex", "createdAt": "2020-11-02T19:19:21Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java", "diffHunk": "@@ -717,4 +682,35 @@ void parseDelimiterChar(RequestContext input) {\n             delimiter = userDelim.charAt(0);\n         }\n     }\n+\n+    protected Properties getSerdeProperties() {\n+        return metadata.getProperties();\n+    }\n+\n+    protected Deserializer getDeserializer() {\n+        if (d == null) {\n+            // HiveUserData is passed from accessor\n+            metadata = (HiveMetadata) context.getMetadata();\n+            if (metadata == null) {\n+                throw new RuntimeException(\"No hive metadata detected in request context\");\n+            }\n+\n+            try {\n+                parseUserData(context);\n+                initPartitionFields();\n+                Class<?> c = Class.forName(serdeClassName, true, JavaUtils.getClassLoader());\n+                d = (Deserializer) c.getDeclaredConstructor().newInstance();\n+                d.initialize(getJobConf(), metastoreProperties);\n+            } catch (Exception e) {\n+                throw new RuntimeException(\"Failed to initialize HiveResolver\", e);\n+            }\n+        }\n+        return d;\n+    }\n+\n+    private boolean columnDescriptorContainsColumn(String columnName) {\n+        return context.getTupleDescription()\n+                .stream()\n+                .anyMatch(cd -> columnName.equals(cd.columnName()));", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxNDU0Ng==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516214546", "bodyText": "probably not, this method was just moved to the bottom since it's a private method.", "author": "frankgh", "createdAt": "2020-11-02T19:46:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMDQ2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI3MTI3NA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516271274", "bodyText": "yes, I will take care of it. Thanks!", "author": "frankgh", "createdAt": "2020-11-02T21:42:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMDQ2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\nindex 71830ec7..9ee512ca 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveResolver.java\n\n@@ -687,30 +710,9 @@ public class HiveResolver extends HivePlugin implements Resolver {\n         return metadata.getProperties();\n     }\n \n-    protected Deserializer getDeserializer() {\n-        if (d == null) {\n-            // HiveUserData is passed from accessor\n-            metadata = (HiveMetadata) context.getMetadata();\n-            if (metadata == null) {\n-                throw new RuntimeException(\"No hive metadata detected in request context\");\n-            }\n-\n-            try {\n-                parseUserData(context);\n-                initPartitionFields();\n-                Class<?> c = Class.forName(serdeClassName, true, JavaUtils.getClassLoader());\n-                d = (Deserializer) c.getDeclaredConstructor().newInstance();\n-                d.initialize(getJobConf(), metastoreProperties);\n-            } catch (Exception e) {\n-                throw new RuntimeException(\"Failed to initialize HiveResolver\", e);\n-            }\n-        }\n-        return d;\n-    }\n-\n     private boolean columnDescriptorContainsColumn(String columnName) {\n         return context.getTupleDescription()\n                 .stream()\n-                .anyMatch(cd -> columnName.equals(cd.columnName()));\n+                .anyMatch(cd -> StringUtils.equalsIgnoreCase(columnName, cd.columnName()));\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTE4Nw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516201187", "bodyText": "are we losing the logic to not init serde on TEXT output format ?", "author": "denalex", "createdAt": "2020-11-02T19:20:43Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java", "diffHunk": "@@ -39,24 +38,10 @@\n     private StringBuilder parts;\n \n     @Override\n-    void parseUserData(RequestContext input) throws Exception {\n-        HiveUserData hiveUserData = HiveUtilities.parseHiveUserData(input);\n-        parseDelimiterChar(input);\n+    void parseUserData(RequestContext context) {\n+        super.parseUserData(context);\n+        parseDelimiterChar(context);\n         parts = new StringBuilder();\n-        partitionKeys = hiveUserData.getPartitionKeys();\n-        serdeClassName = hiveUserData.getSerdeClassName();\n-\n-        /* Needed only for GPDBWritable format*/\n-        if (context.getOutputFormat() == OutputFormat.GPDBWritable) {\n-            propsString = hiveUserData.getPropertiesString();\n-        }\n-    }\n-\n-    @Override\n-    void initSerde(RequestContext input) throws Exception {\n-        if (context.getOutputFormat() == OutputFormat.GPDBWritable) {\n-            super.initSerde(input);\n-        }", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzMyOQ==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516213329", "bodyText": "serde gets initialized during getDeserializer which is not called for the TEXT case", "author": "frankgh", "createdAt": "2020-11-02T19:44:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTE4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NDU4Mg==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516244582", "bodyText": "I am changing this code anyway because of the way we initialize, so it will look more like the version from master", "author": "frankgh", "createdAt": "2020-11-02T20:47:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTE4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java\nindex a659ca13..367221d3 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java\n\n@@ -44,6 +44,13 @@ public class HiveStringPassResolver extends HiveResolver {\n         parts = new StringBuilder();\n     }\n \n+    @Override\n+    void initSerde() throws Exception {\n+        if (context.getOutputFormat() == OutputFormat.GPDBWritable) {\n+            super.initSerde();\n+        }\n+    }\n+\n     @Override\n     void initPartitionFields() {\n         if (context.getOutputFormat() == OutputFormat.TEXT) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTc4NA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516201784", "bodyText": "kinda feels this belongs in a superclass", "author": "denalex", "createdAt": "2020-11-02T19:21:55Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java", "diffHunk": "@@ -84,4 +70,23 @@ void initPartitionFields() {\n         }\n     }\n \n+    /**\n+     * Make sure the required fields have been initialized\n+     */\n+    private void ensureInitialized() {", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzQ1Ng==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516213456", "bodyText": "it only applies to TEXT", "author": "frankgh", "createdAt": "2020-11-02T19:44:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTc4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0ODI1NA==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516248254", "bodyText": "removed", "author": "frankgh", "createdAt": "2020-11-02T20:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTc4NA=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java\nindex a659ca13..367221d3 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/HiveStringPassResolver.java\n\n@@ -69,24 +75,4 @@ public class HiveStringPassResolver extends HiveResolver {\n             return super.getFields(onerow);\n         }\n     }\n-\n-    /**\n-     * Make sure the required fields have been initialized\n-     */\n-    private void ensureInitialized() {\n-        if (metadata != null) return;\n-        // HiveMetadata is passed from accessor\n-        metadata = (HiveMetadata) context.getMetadata();\n-        if (metadata == null) {\n-            throw new RuntimeException(\"No hive metadata detected in request context\");\n-        }\n-\n-        try {\n-            parseUserData(context);\n-            initPartitionFields();\n-        } catch (Exception e) {\n-            throw new RuntimeException(\"Failed to initialize HiveStringPassResolver\", e);\n-        }\n-    }\n-\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMjU5Nw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516202597", "bodyText": "not sure this method belongs here, it is very context heavy", "author": "denalex", "createdAt": "2020-11-02T19:23:37Z", "path": "server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/utilities/HiveUtilities.java", "diffHunk": "@@ -204,68 +199,62 @@ public static void validateTypeCompatible(DataType gpdbDataType, Integer[] gpdbT\n     }\n \n     /**\n-     * The method parses raw user data into HiveUserData class\n+     * Creates ORC file reader.\n      *\n-     * @param context input data\n-     * @return instance of HiveUserData class\n-     * @throws IllegalArgumentException when incorrect number of tokens in Hive user data received\n+     * @param requestContext input data with given data source\n+     * @return ORC file reader\n      */\n-    public static HiveUserData parseHiveUserData(RequestContext context) throws IllegalArgumentException {\n-        String userData = new String(context.getFragmentUserData());\n-        String[] toks = userData.split(HiveUserData.HIVE_UD_DELIM, HiveUserData.getNumOfTokens());\n-\n-        if (toks.length != (HiveUserData.getNumOfTokens())) {\n-            throw new IllegalArgumentException(\"HiveInputFormatFragmenter expected \"\n-                    + HiveUserData.getNumOfTokens() + \" tokens, but got \" + toks.length);\n-        }\n-\n-        String indexesStr = toks[8];\n-        List<Integer> indexes = null;\n-\n-        if (indexesStr != null && !\"null\".equals(indexesStr)) {\n-            indexes = Stream.of(indexesStr.split(\",\"))\n-                    .map(s -> \"null\".equals(s) ? null : Integer.parseInt(s))\n-                    .collect(Collectors.toList());\n+    public static Reader getOrcReader(Configuration configuration, RequestContext requestContext) {", "originalCommit": "e431cec5e4393405c20fa37d1b3155a6ab8b711b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NTMxNw==", "url": "https://github.com/greenplum-db/pxf/pull/474#discussion_r516245317", "bodyText": "you mentioned you refactored this code, so I am hoping this will be resolved in your branch?", "author": "frankgh", "createdAt": "2020-11-02T20:48:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMjU5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "chunk": "diff --git a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/utilities/HiveUtilities.java b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/utilities/HiveUtilities.java\nindex ebe8d3ac..35c5b3dd 100644\n--- a/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/utilities/HiveUtilities.java\n+++ b/server/pxf-hive/src/main/java/org/greenplum/pxf/plugins/hive/utilities/HiveUtilities.java\n\n@@ -257,4 +268,27 @@ public class HiveUtilities {\n \n         return DEFAULT_DELIMITER_CODE;\n     }\n+\n+    /**\n+     * Returns a new Kryo from ThreadLocal\n+     *\n+     * @return a new Kryo from ThreadLocal\n+     */\n+    public static Kryo getKryo() {\n+        return kryo.get();\n+    }\n+\n+\n+    /**\n+     * Serializer a {@link Properties} object into a byte array\n+     *\n+     * @param properties the properties to serialize\n+     * @return the serialized properties as a byte array\n+     */\n+    public static byte[] serializeProperties(Properties properties) {\n+        Output out = new Output(4 * 1024, 10 * 1024 * 1024);\n+        getKryo().writeObject(out, properties);\n+        out.close();\n+        return out.toBytes();\n+    }\n }\n"}}, {"oid": "4de9989ff194b6450a58d0cf7992c02e48051d9a", "url": "https://github.com/greenplum-db/pxf/commit/4de9989ff194b6450a58d0cf7992c02e48051d9a", "message": "Address PR feedback", "committedDate": "2020-11-02T21:45:34Z", "type": "commit"}, {"oid": "d3981280aa02862e1ceb5464ba328216493c57dd", "url": "https://github.com/greenplum-db/pxf/commit/d3981280aa02862e1ceb5464ba328216493c57dd", "message": "add todo", "committedDate": "2020-11-02T21:53:31Z", "type": "commit"}, {"oid": "b0078f438cfbc023a37576876d5901b2f657203e", "url": "https://github.com/greenplum-db/pxf/commit/b0078f438cfbc023a37576876d5901b2f657203e", "message": "Remove delimiter code", "committedDate": "2020-11-02T22:10:17Z", "type": "commit"}]}