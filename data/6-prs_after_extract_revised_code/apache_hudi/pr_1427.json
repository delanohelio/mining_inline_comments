{"pr_number": 1427, "pr_title": "[HUDI-727]: Copy default values of fields if not present when rewriting incoming record with new schema", "pr_createdAt": "2020-03-20T11:53:48Z", "pr_url": "https://github.com/apache/hudi/pull/1427", "timeline": [{"oid": "b3ce0737300e21642afafaeba3362de8af14fa9d", "url": "https://github.com/apache/hudi/commit/b3ce0737300e21642afafaeba3362de8af14fa9d", "message": "[HUDI-727]: Copy default values of fields if not present when rewriting incoming record with new schema", "committedDate": "2020-03-20T11:50:30Z", "type": "commit"}, {"oid": "704ac03e9ed9bd777774068f732f0ca9b9e79f94", "url": "https://github.com/apache/hudi/commit/704ac03e9ed9bd777774068f732f0ca9b9e79f94", "message": "[HUDI-727]: small indentation fixes", "committedDate": "2020-03-20T12:12:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3NzM1MQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r396877351", "bodyText": "So the issue seems to be that in the original record created in this way, the default values shows up as null. Even though you have specified default: dummy_val it still is showing up as null in the original record.\nDo you know why that is the case ? When we have specified the default value, why doesn't Avro put it in the record when the field is missing ?\nI tried using the builder, but that expects default values to be specified for each and every field else throws an excpetion:\nGenericRecord rec = new GenericRecordBuilder(new Schema.Parser().parse(EXAMPLE_SCHEMA)).build();\n\nDo you have more research points around why this is the case with Avro ?", "author": "umehrot2", "createdAt": "2020-03-24T03:03:04Z", "path": "hudi-common/src/test/java/org/apache/hudi/common/util/TestHoodieAvroUtils.java", "diffHunk": "@@ -57,4 +60,16 @@ public void testPropsPresent() {\n     }\n     Assert.assertTrue(\"column pii_col doesn't show up\", piiPresent);\n   }\n+\n+  @Test\n+  public void testDefaultValue() {\n+    GenericRecord rec = new GenericData.Record(new Schema.Parser().parse(EXAMPLE_SCHEMA));\n+    rec.put(\"_row_key\", \"key1\");\n+    rec.put(\"non_pii_col\", \"val1\");\n+    rec.put(\"pii_col\", \"val2\");\n+    rec.put(\"timestamp\", 3.5);", "originalCommit": "704ac03e9ed9bd777774068f732f0ca9b9e79f94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk5MjM3OA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r396992378", "bodyText": "No its not that the original record has default values as null. Its just while getting the values from the record, default values are not considered. Please have a look at this function from avro-1.8.2 library -\n@OverRide public Object get(String key) {\nField field = schema.getField(key);\nif (field == null) return null;\nreturn values[field.pos()];\n}\nIdeally the above function should return field.defaultVal() in case values[field.pos()] is null, but that is not the case.", "author": "pratyakshsharma", "createdAt": "2020-03-24T08:59:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3NzM1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzAzNzI0NA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r397037244", "bodyText": "Can you help me understand how you are running into this issue with default values ?\nBased on my understanding, conversion to avro is internal to Hudi and a custom avro schema (with default values) is not something that user can themselves pass. And how spark-avro converts struct schema to avro there is no special handling there from default value perspective. So I guess I am not sure whether this is an issue in the first place.", "author": "umehrot2", "createdAt": "2020-03-24T10:10:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3NzM1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY1ODIxNw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r397658217", "bodyText": "conversion to avro is internal to Hudi and a custom avro schema (with default values) is not something that user can themselves pass\n\nI did not understand this. As a user I can always specify the schema that is to be used either via FileBasedSchemaProvider or using schema registry.\nLet me give you an example. Suppose there is some table with schema S1 and you have published some records (R1 and R2) with this schema into kafka. Next you evolve the schema (it now becomes S2) and a new nullable field is added as below ->\n{\"name\": \"col1\", \"type\":[\"string\", \"null\"], \"default\": \"dummy\"}\nyou again publish some records (R3 and R4) with S2 and now start consuming with delta streamer. So your kafka topic is having records with both the schemas and delta streamer is using S2 as target schema. Now while writing to parquet, I want R1 and R2 to be written with this default value \"dummy\" for field \"col1\", which is a pretty common case. Generally users prefer to have some default value for newly added fields rather than having written them as null. How do you achieve this without this PR?\nOpen to hearing your thoughts on this.", "author": "pratyakshsharma", "createdAt": "2020-03-25T07:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3NzM1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzY5OTQ4OA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r397699488", "bodyText": "My bad I was thinking only from DataSource's HoodieSparkSqlWriter writer point of view, where the schema is determined automatically from the DataFrame and converted to avro schema. Missed that DeltaStreamer uses the schema provider which the users can pass it directly to the HoodieWriteClient. Thanks for details !\nI have a question for the schema evolution example you provided. The rewriteRecord() you are testing here uses the schema from the old record, and re-writes by setting only the fields found in the old schema. So if you rewrite R1 and R2 record, there schema will not have the new col1 field right ? Hence, your code of populating default values will not get executed because col1 is not present in the old schema fields.\nIt seems this test case works because you are not evolving the schema here. Your old and new record both have the same schema. But if your old record schema is different I think you will run into the same issue. Am I missing something here ?", "author": "umehrot2", "createdAt": "2020-03-25T09:06:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3NzM1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ5MDA2Mg==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399490062", "bodyText": "My bad. You raised a valid point there. Have made few changes and added more test cases to cover schema evolution scenario as well. Please take a pass @umehrot2", "author": "pratyakshsharma", "createdAt": "2020-03-27T19:21:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3NzM1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "chunk": "diff --git a/hudi-common/src/test/java/org/apache/hudi/common/util/TestHoodieAvroUtils.java b/hudi-common/src/test/java/org/apache/hudi/common/util/TestHoodieAvroUtils.java\nindex e10e128e9..b2c13f8ec 100644\n--- a/hudi-common/src/test/java/org/apache/hudi/common/util/TestHoodieAvroUtils.java\n+++ b/hudi-common/src/test/java/org/apache/hudi/common/util/TestHoodieAvroUtils.java\n\n@@ -63,13 +75,36 @@ public class TestHoodieAvroUtils {\n \n   @Test\n   public void testDefaultValue() {\n+    GenericRecord rec = new GenericData.Record(new Schema.Parser().parse(EVOLVED_SCHEMA));\n+    rec.put(\"_row_key\", \"key1\");\n+    rec.put(\"non_pii_col\", \"val1\");\n+    rec.put(\"pii_col\", \"val2\");\n+    rec.put(\"timestamp\", 3.5);\n+    GenericRecord rec1 = HoodieAvroUtils.rewriteRecord(rec, new Schema.Parser().parse(EVOLVED_SCHEMA));\n+    Assert.assertEquals(rec1.get(\"new_col1\"), \"dummy_val\");\n+    Assert.assertNull(rec1.get(\"new_col2\"));\n+  }\n+\n+  @Test\n+  public void testDefaultValueWithSchemaEvolution() {\n     GenericRecord rec = new GenericData.Record(new Schema.Parser().parse(EXAMPLE_SCHEMA));\n     rec.put(\"_row_key\", \"key1\");\n     rec.put(\"non_pii_col\", \"val1\");\n     rec.put(\"pii_col\", \"val2\");\n     rec.put(\"timestamp\", 3.5);\n-    GenericRecord rec1 = HoodieAvroUtils.rewriteRecord(rec, new Schema.Parser().parse(EXAMPLE_SCHEMA));\n+    GenericRecord rec1 = HoodieAvroUtils.rewriteRecord(rec, new Schema.Parser().parse(EVOLVED_SCHEMA));\n     Assert.assertEquals(rec1.get(\"new_col1\"), \"dummy_val\");\n     Assert.assertNull(rec1.get(\"new_col2\"));\n   }\n+\n+  @Test\n+  public void testMetadataField() {\n+    GenericRecord rec = new GenericData.Record(new Schema.Parser().parse(EXAMPLE_SCHEMA));\n+    rec.put(\"_row_key\", \"key1\");\n+    rec.put(\"non_pii_col\", \"val1\");\n+    rec.put(\"pii_col\", \"val2\");\n+    rec.put(\"timestamp\", 3.5);\n+    GenericRecord rec1 = HoodieAvroUtils.rewriteRecord(rec, new Schema.Parser().parse(SCHEMA_WITH_METADATA_FIELD));\n+    Assert.assertNull(rec1.get(\"_hoodie_commit_time\"));\n+  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3Nzc2Nw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r396877767", "bodyText": "Are you making these changes to avoid use of deprecated APIs ?", "author": "umehrot2", "createdAt": "2020-03-24T03:04:57Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -104,15 +103,15 @@ public static Schema addMetadataFields(Schema schema) {\n     List<Schema.Field> parentFields = new ArrayList<>();\n \n     Schema.Field commitTimeField =\n-        new Schema.Field(HoodieRecord.COMMIT_TIME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance());\n+        new Schema.Field(HoodieRecord.COMMIT_TIME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", null);", "originalCommit": "704ac03e9ed9bd777774068f732f0ca9b9e79f94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2NTY2MQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r396965661", "bodyText": "yeah.", "author": "pratyakshsharma", "createdAt": "2020-03-24T08:10:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3Nzc2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcxODk5OA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399718998", "bodyText": "Minor: we probably should do (Object) null to force it to resolve to the new API that accepts object, because null by itself can either refer to JsonNode or an Object", "author": "umehrot2", "createdAt": "2020-03-28T22:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3Nzc2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTc3NjgyNg==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399776826", "bodyText": "Valid point. I was already thinking of doing this.", "author": "pratyakshsharma", "createdAt": "2020-03-29T10:25:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg3Nzc2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex 48b5a5c63..b6c5ab544 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -103,15 +104,15 @@ public class HoodieAvroUtils {\n     List<Schema.Field> parentFields = new ArrayList<>();\n \n     Schema.Field commitTimeField =\n-        new Schema.Field(HoodieRecord.COMMIT_TIME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", null);\n+        new Schema.Field(HoodieRecord.COMMIT_TIME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n     Schema.Field commitSeqnoField =\n-        new Schema.Field(HoodieRecord.COMMIT_SEQNO_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", null);\n+        new Schema.Field(HoodieRecord.COMMIT_SEQNO_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n     Schema.Field recordKeyField =\n-        new Schema.Field(HoodieRecord.RECORD_KEY_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", null);\n+        new Schema.Field(HoodieRecord.RECORD_KEY_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n     Schema.Field partitionPathField =\n-        new Schema.Field(HoodieRecord.PARTITION_PATH_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", null);\n+        new Schema.Field(HoodieRecord.PARTITION_PATH_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n     Schema.Field fileNameField =\n-        new Schema.Field(HoodieRecord.FILENAME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", null);\n+        new Schema.Field(HoodieRecord.FILENAME_METADATA_FIELD, METADATA_FIELD_SCHEMA, \"\", (Object) null);\n \n     parentFields.add(commitTimeField);\n     parentFields.add(commitSeqnoField);\n"}}, {"oid": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "url": "https://github.com/apache/hudi/commit/cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "message": "[HUDI-727]: Added more test cases", "committedDate": "2020-03-27T15:32:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcxOTExOQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399719119", "bodyText": "Shall we change this line as well to consistently use the object API ?", "author": "umehrot2", "createdAt": "2020-03-28T22:52:15Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -168,7 +169,7 @@ public static GenericRecord addHoodieKeyToRecord(GenericRecord record, String re\n    */\n   public static Schema appendNullSchemaFields(Schema schema, List<String> newFieldNames) {\n     List<Field> newFields = schema.getFields().stream()\n-        .map(field -> new Field(field.name(), field.schema(), field.doc(), field.defaultValue())).collect(Collectors.toList());\n+        .map(field -> new Field(field.name(), field.schema(), field.doc(), field.defaultVal())).collect(Collectors.toList());\n     for (String newField : newFieldNames) {\n       newFields.add(new Schema.Field(newField, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance()));", "originalCommit": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTc3NjkwOQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399776909", "bodyText": "missed this one. Changed now.", "author": "pratyakshsharma", "createdAt": "2020-03-29T10:26:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcxOTExOQ=="}], "type": "inlineReview", "revised_code": {"commit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex 208c0a5d9..b6c5ab544 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -171,7 +170,7 @@ public class HoodieAvroUtils {\n     List<Field> newFields = schema.getFields().stream()\n         .map(field -> new Field(field.name(), field.schema(), field.doc(), field.defaultVal())).collect(Collectors.toList());\n     for (String newField : newFieldNames) {\n-      newFields.add(new Schema.Field(newField, METADATA_FIELD_SCHEMA, \"\", NullNode.getInstance()));\n+      newFields.add(new Schema.Field(newField, METADATA_FIELD_SCHEMA, \"\", (Object) null));\n     }\n     Schema newSchema = Schema.createRecord(schema.getName(), schema.getDoc(), schema.getNamespace(), schema.isError());\n     newSchema.setFields(newFields);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMTAxNw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399721017", "bodyText": "This is an internal function call that is being used by both rewriteRecordWithOnlyNewSchemaFields and rewriteRecord. getAllFieldsToWrite does not really make sense in case of rewriteRecordWithOnlyNewSchemaFields and won't really do anything in that case because old and new schema is same.\nI think it would be better to refactor rewrite to receive List<Schema.Field> fieldsToWrite as a parameter instead of schemaWithFields. In case of rewriteRecord we can call  getAllFieldsToWrite and pass its value in the parameter, while in case of rewriteRecordWithOnlyNewSchemaFields just pass schema.getFields() here.", "author": "umehrot2", "createdAt": "2020-03-28T23:15:52Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -204,8 +205,13 @@ public static GenericRecord rewriteRecordWithOnlyNewSchemaFields(GenericRecord r\n \n   private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFields, Schema newSchema) {\n     GenericRecord newRecord = new GenericData.Record(newSchema);\n-    for (Schema.Field f : schemaWithFields.getFields()) {\n-      newRecord.put(f.name(), record.get(f.name()));\n+    //get union of both the schemas, and then populate the fields in the new record\n+    for (Schema.Field f : getAllFieldsToWrite(schemaWithFields, newSchema)) {", "originalCommit": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTc3ODMyOA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399778328", "bodyText": "Done.", "author": "pratyakshsharma", "createdAt": "2020-03-29T10:39:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMTAxNw=="}], "type": "inlineReview", "revised_code": {"commit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex 208c0a5d9..b6c5ab544 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -200,15 +199,14 @@ public class HoodieAvroUtils {\n    * schema.\n    */\n   public static GenericRecord rewriteRecordWithOnlyNewSchemaFields(GenericRecord record, Schema newSchema) {\n-    return rewrite(record, newSchema, newSchema);\n+    return rewrite(record, newSchema.getFields(), newSchema);\n   }\n \n-  private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFields, Schema newSchema) {\n+  private static GenericRecord rewrite(GenericRecord record, List<Field> fieldsToWrite, Schema newSchema) {\n     GenericRecord newRecord = new GenericData.Record(newSchema);\n-    //get union of both the schemas, and then populate the fields in the new record\n-    for (Schema.Field f : getAllFieldsToWrite(schemaWithFields, newSchema)) {\n+    for (Schema.Field f : fieldsToWrite) {\n       if (record.get(f.name()) == null) {\n-        populateNewRecordAsPerDataType(newRecord, f);\n+        newRecord.put(f.name(), f.defaultVal());\n       } else {\n         newRecord.put(f.name(), record.get(f.name()));\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMjExNQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399722115", "bodyText": "Why do we need this casting of individual data types ? It seems we can just pass field.defaultVal() as it is because it expects an Object, and field.defaultVal() returns exactly that.", "author": "umehrot2", "createdAt": "2020-03-28T23:29:16Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +220,63 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n+    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+    for (Schema.Field f : newSchema.getFields()) {\n+      if (!allFields.contains(f) && !isMetadataField(f.name())) {\n+        fields.add(f);\n+      }\n+    }\n+\n+    return fields;\n+  }\n+\n+  private static void populateNewRecordAsPerDataType(GenericRecord record, Field field) {\n+    switch (getSchemaTypeForField(field)) {\n+      case STRING:\n+      case BYTES:\n+      case ENUM:\n+      case FIXED:\n+        record.put(field.name(), field.defaultVal() == null ? null : (String) field.defaultVal());", "originalCommit": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTc3NzQzMw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399777433", "bodyText": "Done.", "author": "pratyakshsharma", "createdAt": "2020-03-29T10:31:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMjExNQ=="}], "type": "inlineReview", "revised_code": {"commit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex 208c0a5d9..b6c5ab544 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -235,48 +233,6 @@ public class HoodieAvroUtils {\n     return fields;\n   }\n \n-  private static void populateNewRecordAsPerDataType(GenericRecord record, Field field) {\n-    switch (getSchemaTypeForField(field)) {\n-      case STRING:\n-      case BYTES:\n-      case ENUM:\n-      case FIXED:\n-        record.put(field.name(), field.defaultVal() == null ? null : (String) field.defaultVal());\n-        break;\n-      case LONG:\n-        record.put(field.name(), field.defaultVal() == null ? null : (long) field.defaultVal());\n-        break;\n-      case INT:\n-        record.put(field.name(), field.defaultVal() == null ? null : (int) field.defaultVal());\n-        break;\n-      case FLOAT:\n-        record.put(field.name(), field.defaultVal() == null ? null : (float) field.defaultVal());\n-        break;\n-      case DOUBLE:\n-        record.put(field.name(), field.defaultVal() == null ? null : (double) field.defaultVal());\n-        break;\n-      case BOOLEAN:\n-        record.put(field.name(), field.defaultVal() == null ? null : (boolean) field.defaultVal());\n-        break;\n-      default:\n-        record.put(field.name(), field.defaultVal());\n-    }\n-  }\n-\n-  private static Schema.Type getSchemaTypeForField(Field field) {\n-    if (!field.schema().getType().equals(Schema.Type.UNION)) {\n-      return field.schema().getType();\n-    }\n-\n-    for (Schema schema : field.schema().getTypes()) {\n-      if (!schema.getType().equals(Schema.Type.NULL)) {\n-        return schema.getType();\n-      }\n-    }\n-\n-    return Schema.Type.STRING;\n-  }\n-\n   public static byte[] compress(String text) {\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMjMwNQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399722305", "bodyText": "Shouldn't we return Schema.Type.NULL here ? Seems like the only case where we will reach this line is when type is null.", "author": "umehrot2", "createdAt": "2020-03-28T23:31:46Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +220,63 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n+    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+    for (Schema.Field f : newSchema.getFields()) {\n+      if (!allFields.contains(f) && !isMetadataField(f.name())) {\n+        fields.add(f);\n+      }\n+    }\n+\n+    return fields;\n+  }\n+\n+  private static void populateNewRecordAsPerDataType(GenericRecord record, Field field) {\n+    switch (getSchemaTypeForField(field)) {\n+      case STRING:\n+      case BYTES:\n+      case ENUM:\n+      case FIXED:\n+        record.put(field.name(), field.defaultVal() == null ? null : (String) field.defaultVal());\n+        break;\n+      case LONG:\n+        record.put(field.name(), field.defaultVal() == null ? null : (long) field.defaultVal());\n+        break;\n+      case INT:\n+        record.put(field.name(), field.defaultVal() == null ? null : (int) field.defaultVal());\n+        break;\n+      case FLOAT:\n+        record.put(field.name(), field.defaultVal() == null ? null : (float) field.defaultVal());\n+        break;\n+      case DOUBLE:\n+        record.put(field.name(), field.defaultVal() == null ? null : (double) field.defaultVal());\n+        break;\n+      case BOOLEAN:\n+        record.put(field.name(), field.defaultVal() == null ? null : (boolean) field.defaultVal());\n+        break;\n+      default:\n+        record.put(field.name(), field.defaultVal());\n+    }\n+  }\n+\n+  private static Schema.Type getSchemaTypeForField(Field field) {\n+    if (!field.schema().getType().equals(Schema.Type.UNION)) {\n+      return field.schema().getType();\n+    }\n+\n+    for (Schema schema : field.schema().getTypes()) {\n+      if (!schema.getType().equals(Schema.Type.NULL)) {\n+        return schema.getType();\n+      }\n+    }\n+\n+    return Schema.Type.STRING;", "originalCommit": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTc3NzQ1Mw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399777453", "bodyText": "Removed this function itself.", "author": "pratyakshsharma", "createdAt": "2020-03-29T10:31:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMjMwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex 208c0a5d9..b6c5ab544 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -235,48 +233,6 @@ public class HoodieAvroUtils {\n     return fields;\n   }\n \n-  private static void populateNewRecordAsPerDataType(GenericRecord record, Field field) {\n-    switch (getSchemaTypeForField(field)) {\n-      case STRING:\n-      case BYTES:\n-      case ENUM:\n-      case FIXED:\n-        record.put(field.name(), field.defaultVal() == null ? null : (String) field.defaultVal());\n-        break;\n-      case LONG:\n-        record.put(field.name(), field.defaultVal() == null ? null : (long) field.defaultVal());\n-        break;\n-      case INT:\n-        record.put(field.name(), field.defaultVal() == null ? null : (int) field.defaultVal());\n-        break;\n-      case FLOAT:\n-        record.put(field.name(), field.defaultVal() == null ? null : (float) field.defaultVal());\n-        break;\n-      case DOUBLE:\n-        record.put(field.name(), field.defaultVal() == null ? null : (double) field.defaultVal());\n-        break;\n-      case BOOLEAN:\n-        record.put(field.name(), field.defaultVal() == null ? null : (boolean) field.defaultVal());\n-        break;\n-      default:\n-        record.put(field.name(), field.defaultVal());\n-    }\n-  }\n-\n-  private static Schema.Type getSchemaTypeForField(Field field) {\n-    if (!field.schema().getType().equals(Schema.Type.UNION)) {\n-      return field.schema().getType();\n-    }\n-\n-    for (Schema schema : field.schema().getTypes()) {\n-      if (!schema.getType().equals(Schema.Type.NULL)) {\n-        return schema.getType();\n-      }\n-    }\n-\n-    return Schema.Type.STRING;\n-  }\n-\n   public static byte[] compress(String text) {\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n     try {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMjYyMg==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399722622", "bodyText": "nit: May be rename this to populateFieldWithDefaultValue as that seems to be the intent of this function.", "author": "umehrot2", "createdAt": "2020-03-28T23:36:07Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +220,63 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n+    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+    for (Schema.Field f : newSchema.getFields()) {\n+      if (!allFields.contains(f) && !isMetadataField(f.name())) {\n+        fields.add(f);\n+      }\n+    }\n+\n+    return fields;\n+  }\n+\n+  private static void populateNewRecordAsPerDataType(GenericRecord record, Field field) {", "originalCommit": "cc3ec6e97f9b29831032eb3ed20605f9a12d5e5e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTc3NzUwMQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r399777501", "bodyText": "Removed this function also.", "author": "pratyakshsharma", "createdAt": "2020-03-29T10:31:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTcyMjYyMg=="}], "type": "inlineReview", "revised_code": {"commit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex 208c0a5d9..b6c5ab544 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -235,48 +233,6 @@ public class HoodieAvroUtils {\n     return fields;\n   }\n \n-  private static void populateNewRecordAsPerDataType(GenericRecord record, Field field) {\n-    switch (getSchemaTypeForField(field)) {\n-      case STRING:\n-      case BYTES:\n-      case ENUM:\n-      case FIXED:\n-        record.put(field.name(), field.defaultVal() == null ? null : (String) field.defaultVal());\n-        break;\n-      case LONG:\n-        record.put(field.name(), field.defaultVal() == null ? null : (long) field.defaultVal());\n-        break;\n-      case INT:\n-        record.put(field.name(), field.defaultVal() == null ? null : (int) field.defaultVal());\n-        break;\n-      case FLOAT:\n-        record.put(field.name(), field.defaultVal() == null ? null : (float) field.defaultVal());\n-        break;\n-      case DOUBLE:\n-        record.put(field.name(), field.defaultVal() == null ? null : (double) field.defaultVal());\n-        break;\n-      case BOOLEAN:\n-        record.put(field.name(), field.defaultVal() == null ? null : (boolean) field.defaultVal());\n-        break;\n-      default:\n-        record.put(field.name(), field.defaultVal());\n-    }\n-  }\n-\n-  private static Schema.Type getSchemaTypeForField(Field field) {\n-    if (!field.schema().getType().equals(Schema.Type.UNION)) {\n-      return field.schema().getType();\n-    }\n-\n-    for (Schema schema : field.schema().getTypes()) {\n-      if (!schema.getType().equals(Schema.Type.NULL)) {\n-        return schema.getType();\n-      }\n-    }\n-\n-    return Schema.Type.STRING;\n-  }\n-\n   public static byte[] compress(String text) {\n     ByteArrayOutputStream baos = new ByteArrayOutputStream();\n     try {\n"}}, {"oid": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "url": "https://github.com/apache/hudi/commit/74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "message": "[HUDI-727]: addressed code review comments", "committedDate": "2020-03-29T10:42:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxODI4Nw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r400418287", "bodyText": "nit: extra line", "author": "vinothchandar", "createdAt": "2020-03-30T18:52:02Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +218,21 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n+    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+    for (Schema.Field f : newSchema.getFields()) {\n+      if (!allFields.contains(f) && !isMetadataField(f.name())) {\n+        fields.add(f);\n+      }\n+    }\n+", "originalCommit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcxNTYyOQ==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r403715629", "bodyText": "fixed.", "author": "pratyakshsharma", "createdAt": "2020-04-05T15:16:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxODI4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "dbb962e49f0a641a0bb1f6acce37547b5fe04831", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex b6c5ab544..04fce6cb4 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -229,7 +229,6 @@ public class HoodieAvroUtils {\n         fields.add(f);\n       }\n     }\n-\n     return fields;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQyMDEyNg==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r400420126", "bodyText": "rename : getNewFieldsToWrite()?", "author": "vinothchandar", "createdAt": "2020-03-30T18:54:55Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +218,21 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {", "originalCommit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcxNTk2NA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r403715964", "bodyText": "actually here it is a union of old and new fields. That is why I kept this name. If you strongly feel about changing the name, let me know.", "author": "pratyakshsharma", "createdAt": "2020-04-05T15:18:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQyMDEyNg=="}], "type": "inlineReview", "revised_code": {"commit": "dbb962e49f0a641a0bb1f6acce37547b5fe04831", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nindex b6c5ab544..04fce6cb4 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n\n@@ -229,7 +229,6 @@ public class HoodieAvroUtils {\n         fields.add(f);\n       }\n     }\n-\n     return fields;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQyMjQ4Mw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r400422483", "bodyText": "for my understanding, I would expect the default value to be handed to us here, already right?\nIs this a avro bug/quirk? How exactly does one use the default value if get() won't hand it. avro expects users to manually fetch it from the schema?", "author": "vinothchandar", "createdAt": "2020-03-30T18:58:45Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java", "diffHunk": "@@ -191,21 +191,25 @@ public static GenericRecord addCommitMetadataToRecord(GenericRecord record, Stri\n    * schema.\n    */\n   public static GenericRecord rewriteRecord(GenericRecord record, Schema newSchema) {\n-    return rewrite(record, record.getSchema(), newSchema);\n+    return rewrite(record, getAllFieldsToWrite(record.getSchema(), newSchema), newSchema);\n   }\n \n   /**\n    * Given a avro record with a given schema, rewrites it into the new schema while setting fields only from the new\n    * schema.\n    */\n   public static GenericRecord rewriteRecordWithOnlyNewSchemaFields(GenericRecord record, Schema newSchema) {\n-    return rewrite(record, newSchema, newSchema);\n+    return rewrite(record, newSchema.getFields(), newSchema);\n   }\n \n-  private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFields, Schema newSchema) {\n+  private static GenericRecord rewrite(GenericRecord record, List<Field> fieldsToWrite, Schema newSchema) {\n     GenericRecord newRecord = new GenericData.Record(newSchema);\n-    for (Schema.Field f : schemaWithFields.getFields()) {\n-      newRecord.put(f.name(), record.get(f.name()));\n+    for (Schema.Field f : fieldsToWrite) {\n+      if (record.get(f.name()) == null) {", "originalCommit": "74b8da1566f84ee5aa58a7b09ca2098f2a4abd8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzczOTAwMg==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r403739002", "bodyText": "Actually in avro, actual field value is maintained with the GenericData.Record class but defaultValue is maintained with Schema.Field. So I guess Avro expects users to fetch them separately.", "author": "pratyakshsharma", "createdAt": "2020-04-05T18:24:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQyMjQ4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "a32f701e40fc66e1178b9ca1e86e244e9c5c8430", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\nsimilarity index 91%\nrename from hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\nrename to hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\nindex b6c5ab544..7c15c2a6e 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n\n@@ -191,7 +190,7 @@ public class HoodieAvroUtils {\n    * schema.\n    */\n   public static GenericRecord rewriteRecord(GenericRecord record, Schema newSchema) {\n-    return rewrite(record, getAllFieldsToWrite(record.getSchema(), newSchema), newSchema);\n+    return rewrite(record, getCombinedFieldsToWrite(record.getSchema(), newSchema), newSchema);\n   }\n \n   /**\n"}}, {"oid": "dbb962e49f0a641a0bb1f6acce37547b5fe04831", "url": "https://github.com/apache/hudi/commit/dbb962e49f0a641a0bb1f6acce37547b5fe04831", "message": "[HUDI-727]: code review comments addressed", "committedDate": "2020-04-05T18:26:51Z", "type": "commit"}, {"oid": "89d2bf43eeae07d9dedd19f857f1ae83f26ab38e", "url": "https://github.com/apache/hudi/commit/89d2bf43eeae07d9dedd19f857f1ae83f26ab38e", "message": "Merge branch 'master' of https://github.com/apache/incubator-hudi into hudi-727", "committedDate": "2020-04-05T18:27:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNTQwNA==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r404235404", "bodyText": "nit: formatting , missing *", "author": "vinothchandar", "createdAt": "2020-04-06T16:42:46Z", "path": "hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +218,20 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields", "originalCommit": "89d2bf43eeae07d9dedd19f857f1ae83f26ab38e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNzYxNw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r404237617", "bodyText": "let's avoid overloading the term \"union\" here.. \"Generates a super set of fields from both old and new schema\"", "author": "vinothchandar", "createdAt": "2020-04-06T16:46:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzNTQwNA=="}], "type": "inlineReview", "revised_code": {"commit": "a32f701e40fc66e1178b9ca1e86e244e9c5c8430", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\nindex ab23c4239..7c15c2a6e 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n\n@@ -218,18 +217,17 @@ public class HoodieAvroUtils {\n     return newRecord;\n   }\n \n-  /*\n-  This function takes the union of all the fields except hoodie metadata fields\n+  /**\n+   * Generates a super set of fields from both old and new schema.\n    */\n-  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n-    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n-    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+  private static LinkedHashSet<Field> getCombinedFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    LinkedHashSet<Field> allFields = new LinkedHashSet<>(oldSchema.getFields());\n     for (Schema.Field f : newSchema.getFields()) {\n       if (!allFields.contains(f) && !isMetadataField(f.name())) {\n-        fields.add(f);\n+        allFields.add(f);\n       }\n     }\n-    return fields;\n+    return allFields;\n   }\n \n   public static byte[] compress(String text) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODE5Nw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r404238197", "bodyText": "in that case, let have the name reflect that.. getCombinedFields().. All does not bring out what this is doing IMO.", "author": "vinothchandar", "createdAt": "2020-04-06T16:47:00Z", "path": "hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +218,20 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {", "originalCommit": "89d2bf43eeae07d9dedd19f857f1ae83f26ab38e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA4MDQyMg==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r407080422", "bodyText": "Changed it to getCombinedFieldsToWrite()", "author": "pratyakshsharma", "createdAt": "2020-04-11T16:04:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODE5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "a32f701e40fc66e1178b9ca1e86e244e9c5c8430", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\nindex ab23c4239..7c15c2a6e 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n\n@@ -218,18 +217,17 @@ public class HoodieAvroUtils {\n     return newRecord;\n   }\n \n-  /*\n-  This function takes the union of all the fields except hoodie metadata fields\n+  /**\n+   * Generates a super set of fields from both old and new schema.\n    */\n-  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n-    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n-    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+  private static LinkedHashSet<Field> getCombinedFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    LinkedHashSet<Field> allFields = new LinkedHashSet<>(oldSchema.getFields());\n     for (Schema.Field f : newSchema.getFields()) {\n       if (!allFields.contains(f) && !isMetadataField(f.name())) {\n-        fields.add(f);\n+        allFields.add(f);\n       }\n     }\n-    return fields;\n+    return allFields;\n   }\n \n   public static byte[] compress(String text) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODk4Nw==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r404238987", "bodyText": "would a LinkedHashSet eliminate the need for a set and a list?", "author": "vinothchandar", "createdAt": "2020-04-06T16:48:12Z", "path": "hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java", "diffHunk": "@@ -214,6 +218,20 @@ private static GenericRecord rewrite(GenericRecord record, Schema schemaWithFiel\n     return newRecord;\n   }\n \n+  /*\n+  This function takes the union of all the fields except hoodie metadata fields\n+   */\n+  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n+    List<Field> fields = new ArrayList<>(oldSchema.getFields());", "originalCommit": "89d2bf43eeae07d9dedd19f857f1ae83f26ab38e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE5OTE2Ng==", "url": "https://github.com/apache/hudi/pull/1427#discussion_r407199166", "bodyText": "Yes it helps. Thank you for suggesting this :)", "author": "pratyakshsharma", "createdAt": "2020-04-12T13:34:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIzODk4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "a32f701e40fc66e1178b9ca1e86e244e9c5c8430", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\nindex ab23c4239..7c15c2a6e 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/avro/HoodieAvroUtils.java\n\n@@ -218,18 +217,17 @@ public class HoodieAvroUtils {\n     return newRecord;\n   }\n \n-  /*\n-  This function takes the union of all the fields except hoodie metadata fields\n+  /**\n+   * Generates a super set of fields from both old and new schema.\n    */\n-  private static List<Field> getAllFieldsToWrite(Schema oldSchema, Schema newSchema) {\n-    Set<Field> allFields = new HashSet<>(oldSchema.getFields());\n-    List<Field> fields = new ArrayList<>(oldSchema.getFields());\n+  private static LinkedHashSet<Field> getCombinedFieldsToWrite(Schema oldSchema, Schema newSchema) {\n+    LinkedHashSet<Field> allFields = new LinkedHashSet<>(oldSchema.getFields());\n     for (Schema.Field f : newSchema.getFields()) {\n       if (!allFields.contains(f) && !isMetadataField(f.name())) {\n-        fields.add(f);\n+        allFields.add(f);\n       }\n     }\n-    return fields;\n+    return allFields;\n   }\n \n   public static byte[] compress(String text) {\n"}}, {"oid": "a32f701e40fc66e1178b9ca1e86e244e9c5c8430", "url": "https://github.com/apache/hudi/commit/a32f701e40fc66e1178b9ca1e86e244e9c5c8430", "message": "[HUDI-727]: integ tests failing", "committedDate": "2020-04-11T16:55:14Z", "type": "commit"}, {"oid": "0a8e421b802a21c40629ec41659ab55305479a93", "url": "https://github.com/apache/hudi/commit/0a8e421b802a21c40629ec41659ab55305479a93", "message": "[HUDI-727]: fixed integ tests", "committedDate": "2020-04-12T13:33:33Z", "type": "commit"}, {"oid": "1a8d429b2f222615d618a22067d3ed60eadc9a33", "url": "https://github.com/apache/hudi/commit/1a8d429b2f222615d618a22067d3ed60eadc9a33", "message": "[HUDI-727]: fixed test case", "committedDate": "2020-04-12T17:25:59Z", "type": "commit"}]}