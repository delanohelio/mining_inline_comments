{"pr_number": 2343, "pr_title": "[HUDI-1469] Faster initialization of metadata table using parallelized listing.", "pr_createdAt": "2020-12-17T22:31:29Z", "pr_url": "https://github.com/apache/hudi/pull/2343", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU0NjY0Ng==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r545546646", "bodyText": "Perhaps name it getPartitionsToFilesMapping() ?\nIdeally, it would have been good to have it as a utility in FsUtils but because of our current structure we can't move it, since FsUtils is in hudi-common which we don't want to depend on spark.", "author": "umehrot2", "createdAt": "2020-12-18T03:16:00Z", "path": "hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -369,10 +343,56 @@ private void bootstrapFromFilesystem(JavaSparkContext jsc, HoodieTableMetaClient\n       }\n     });\n \n-    LOG.info(\"Committing \" + partitionFileList.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n+    LOG.info(\"Committing \" + partitionToFileStatus.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n     update(commitMetadata, createInstantTime);\n   }\n \n+  /**\n+   * Function to find hoodie partitions and list files in them in parallel.\n+   *\n+   * @param jsc\n+   * @param datasetMetaClient\n+   * @return Map of partition names to a list of FileStatus for all the files in the partition\n+   */\n+  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,", "originalCommit": "374bbb61592137feab4fb56ad540700cbc9e7373", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExOTA1OQ==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546119059", "bodyText": "Done", "author": "prashantwason", "createdAt": "2020-12-18T22:23:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU0NjY0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "b7fc074f0534c2be891a0c144ac70a73ede79e46", "chunk": "diff --git a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 6603ec3e57..4ef3aef31b 100644\n--- a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n\n@@ -354,18 +355,20 @@ public class HoodieBackedTableMetadataWriter implements HoodieTableMetadataWrite\n    * @param datasetMetaClient\n    * @return Map of partition names to a list of FileStatus for all the files in the partition\n    */\n-  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(JavaSparkContext jsc,\n       HoodieTableMetaClient datasetMetaClient) {\n     List<Path> pathsToList = new LinkedList<>();\n     pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n     Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n+    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n \n     while (!pathsToList.isEmpty()) {\n+      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n       // List all directories in parallel\n-      List<Pair<Path, FileStatus[]>> dirToFileListing =\n-          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))\n+      List<Pair<Path, FileStatus[]>> dirToFileListing = jsc.parallelize(pathsToList, listingParallelism)\n             .map(path -> {\n-              FileSystem fs = datasetMetaClient.getFs();\n+              FileSystem fs = path.getFileSystem(conf.get());\n               return Pair.of(path, fs.listStatus(path));\n             }).collect();\n       pathsToList.clear();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU0ODM3NA==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r545548374", "bodyText": "I think we should introduce like a LISTING_PARALLELISM property with a default of 1500 and use it here. (https://github.com/apache/hudi/blob/rfc-15/hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java#L70)", "author": "umehrot2", "createdAt": "2020-12-18T03:22:33Z", "path": "hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -369,10 +343,56 @@ private void bootstrapFromFilesystem(JavaSparkContext jsc, HoodieTableMetaClient\n       }\n     });\n \n-    LOG.info(\"Committing \" + partitionFileList.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n+    LOG.info(\"Committing \" + partitionToFileStatus.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n     update(commitMetadata, createInstantTime);\n   }\n \n+  /**\n+   * Function to find hoodie partitions and list files in them in parallel.\n+   *\n+   * @param jsc\n+   * @param datasetMetaClient\n+   * @return Map of partition names to a list of FileStatus for all the files in the partition\n+   */\n+  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+      HoodieTableMetaClient datasetMetaClient) {\n+    List<Path> pathsToList = new LinkedList<>();\n+    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n+    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+\n+    while (!pathsToList.isEmpty()) {\n+      // List all directories in parallel\n+      List<Pair<Path, FileStatus[]>> dirToFileListing =\n+          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))", "originalCommit": "374bbb61592137feab4fb56ad540700cbc9e7373", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExOTA0Ng==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546119046", "bodyText": "Done", "author": "prashantwason", "createdAt": "2020-12-18T22:23:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU0ODM3NA=="}], "type": "inlineReview", "revised_code": {"commit": "b7fc074f0534c2be891a0c144ac70a73ede79e46", "chunk": "diff --git a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 6603ec3e57..4ef3aef31b 100644\n--- a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n\n@@ -354,18 +355,20 @@ public class HoodieBackedTableMetadataWriter implements HoodieTableMetadataWrite\n    * @param datasetMetaClient\n    * @return Map of partition names to a list of FileStatus for all the files in the partition\n    */\n-  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(JavaSparkContext jsc,\n       HoodieTableMetaClient datasetMetaClient) {\n     List<Path> pathsToList = new LinkedList<>();\n     pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n     Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n+    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n \n     while (!pathsToList.isEmpty()) {\n+      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n       // List all directories in parallel\n-      List<Pair<Path, FileStatus[]>> dirToFileListing =\n-          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))\n+      List<Pair<Path, FileStatus[]>> dirToFileListing = jsc.parallelize(pathsToList, listingParallelism)\n             .map(path -> {\n-              FileSystem fs = datasetMetaClient.getFs();\n+              FileSystem fs = path.getFileSystem(conf.get());\n               return Pair.of(path, fs.listStatus(path));\n             }).collect();\n       pathsToList.clear();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1MDM5OA==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r545550398", "bodyText": "This adds unnecessary overhead of serialization/deserialization of HoodieTableMetaClient. Instead, we can  do:\npath.getFileSystem(new Configuration());\n\nto get the file system.", "author": "umehrot2", "createdAt": "2020-12-18T03:29:41Z", "path": "hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -369,10 +343,56 @@ private void bootstrapFromFilesystem(JavaSparkContext jsc, HoodieTableMetaClient\n       }\n     });\n \n-    LOG.info(\"Committing \" + partitionFileList.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n+    LOG.info(\"Committing \" + partitionToFileStatus.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n     update(commitMetadata, createInstantTime);\n   }\n \n+  /**\n+   * Function to find hoodie partitions and list files in them in parallel.\n+   *\n+   * @param jsc\n+   * @param datasetMetaClient\n+   * @return Map of partition names to a list of FileStatus for all the files in the partition\n+   */\n+  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+      HoodieTableMetaClient datasetMetaClient) {\n+    List<Path> pathsToList = new LinkedList<>();\n+    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n+    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+\n+    while (!pathsToList.isEmpty()) {\n+      // List all directories in parallel\n+      List<Pair<Path, FileStatus[]>> dirToFileListing =\n+          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))\n+            .map(path -> {\n+              FileSystem fs = datasetMetaClient.getFs();", "originalCommit": "374bbb61592137feab4fb56ad540700cbc9e7373", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEyMDE4OA==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546120188", "bodyText": "Better.\nExcept for new Configuration() I think its better to pass in the current configuration (from datasetMetaClient) so that any production configs can be carried over.", "author": "prashantwason", "createdAt": "2020-12-18T22:26:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1MDM5OA=="}], "type": "inlineReview", "revised_code": {"commit": "b7fc074f0534c2be891a0c144ac70a73ede79e46", "chunk": "diff --git a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 6603ec3e57..4ef3aef31b 100644\n--- a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n\n@@ -354,18 +355,20 @@ public class HoodieBackedTableMetadataWriter implements HoodieTableMetadataWrite\n    * @param datasetMetaClient\n    * @return Map of partition names to a list of FileStatus for all the files in the partition\n    */\n-  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(JavaSparkContext jsc,\n       HoodieTableMetaClient datasetMetaClient) {\n     List<Path> pathsToList = new LinkedList<>();\n     pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n     Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n+    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n \n     while (!pathsToList.isEmpty()) {\n+      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n       // List all directories in parallel\n-      List<Pair<Path, FileStatus[]>> dirToFileListing =\n-          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))\n+      List<Pair<Path, FileStatus[]>> dirToFileListing = jsc.parallelize(pathsToList, listingParallelism)\n             .map(path -> {\n-              FileSystem fs = datasetMetaClient.getFs();\n+              FileSystem fs = path.getFileSystem(conf.get());\n               return Pair.of(path, fs.listStatus(path));\n             }).collect();\n       pathsToList.clear();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1MTE2MA==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r545551160", "bodyText": "May be Arrays.stream().parallel() ? This can be a huge list to go through for large datasets.", "author": "umehrot2", "createdAt": "2020-12-18T03:32:42Z", "path": "hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -369,10 +343,56 @@ private void bootstrapFromFilesystem(JavaSparkContext jsc, HoodieTableMetaClient\n       }\n     });\n \n-    LOG.info(\"Committing \" + partitionFileList.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n+    LOG.info(\"Committing \" + partitionToFileStatus.size() + \" partitions and \" + stats[0] + \" files to metadata\");\n     update(commitMetadata, createInstantTime);\n   }\n \n+  /**\n+   * Function to find hoodie partitions and list files in them in parallel.\n+   *\n+   * @param jsc\n+   * @param datasetMetaClient\n+   * @return Map of partition names to a list of FileStatus for all the files in the partition\n+   */\n+  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+      HoodieTableMetaClient datasetMetaClient) {\n+    List<Path> pathsToList = new LinkedList<>();\n+    pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n+    Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+\n+    while (!pathsToList.isEmpty()) {\n+      // List all directories in parallel\n+      List<Pair<Path, FileStatus[]>> dirToFileListing =\n+          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))\n+            .map(path -> {\n+              FileSystem fs = datasetMetaClient.getFs();\n+              return Pair.of(path, fs.listStatus(path));\n+            }).collect();\n+      pathsToList.clear();\n+\n+      // If the listing reveals a directory, add it to queue. If the listing reveals a hoodie partition, add it to\n+      // the results.\n+      dirToFileListing.forEach(p -> {\n+        List<FileStatus> filesInDir = Arrays.stream(p.getRight())\n+            .filter(fs -> !fs.getPath().getName().equals(HoodiePartitionMetadata.HOODIE_PARTITION_METAFILE))\n+            .collect(Collectors.toList());", "originalCommit": "374bbb61592137feab4fb56ad540700cbc9e7373", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExOTAyMQ==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546119021", "bodyText": "Done.", "author": "prashantwason", "createdAt": "2020-12-18T22:23:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1MTE2MA=="}], "type": "inlineReview", "revised_code": {"commit": "b7fc074f0534c2be891a0c144ac70a73ede79e46", "chunk": "diff --git a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 6603ec3e57..4ef3aef31b 100644\n--- a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n\n@@ -354,18 +355,20 @@ public class HoodieBackedTableMetadataWriter implements HoodieTableMetadataWrite\n    * @param datasetMetaClient\n    * @return Map of partition names to a list of FileStatus for all the files in the partition\n    */\n-  private Map<String, List<FileStatus>> parallelFileSystemListing(JavaSparkContext jsc,\n+  private Map<String, List<FileStatus>> getPartitionsToFilesMapping(JavaSparkContext jsc,\n       HoodieTableMetaClient datasetMetaClient) {\n     List<Path> pathsToList = new LinkedList<>();\n     pathsToList.add(new Path(datasetWriteConfig.getBasePath()));\n     Map<String, List<FileStatus>> partitionToFileStatus = new HashMap<>();\n+    final int fileListingParallelism = metadataWriteConfig.getFileListingParallelism();\n+    SerializableConfiguration conf = new SerializableConfiguration(datasetMetaClient.getHadoopConf());\n \n     while (!pathsToList.isEmpty()) {\n+      int listingParallelism = Math.min(fileListingParallelism, pathsToList.size());\n       // List all directories in parallel\n-      List<Pair<Path, FileStatus[]>> dirToFileListing =\n-          jsc.parallelize(pathsToList, Math.min(pathsToList.size(), jsc.defaultParallelism()))\n+      List<Pair<Path, FileStatus[]>> dirToFileListing = jsc.parallelize(pathsToList, listingParallelism)\n             .map(path -> {\n-              FileSystem fs = datasetMetaClient.getFs();\n+              FileSystem fs = path.getFileSystem(conf.get());\n               return Pair.of(path, fs.listStatus(path));\n             }).collect();\n       pathsToList.clear();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NDAyOA==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r545554028", "bodyText": "Can you re-use this same thing to getAllPartitionPaths() here: https://github.com/apache/hudi/blob/rfc-15/hudi-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadata.java#L149\nThe default mechanism is really slow. I investigated FsUtils.getAllPartitionPaths() is also used at multiple places across Hudi code-base which can benefit from RFC-15. So, what I am thinking is by default we can let FsUtils.getAllPartitionPaths() always default to the metadata table, and internally if the table is not present, it will use this default parallelized/optimized listing of partition paths.\nSo, it benefits both customers who use metadata table and who don't.", "author": "umehrot2", "createdAt": "2020-12-18T03:43:14Z", "path": "hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -51,6 +51,7 @@\n import org.apache.hudi.common.util.HoodieTimer;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.common.util.collection.Pair;", "originalCommit": "374bbb61592137feab4fb56ad540700cbc9e7373", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTk3NjQ5MQ==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r545976491", "bodyText": "So, what I am thinking is by default we can let FsUtils.getAllPartitionPaths() always default to the metadata table, and internally if the table is not present, it will use this default parallelized/optimized listing of partition paths.\n\n+1 on this. There is a JIRA to track this specifically", "author": "vinothchandar", "createdAt": "2020-12-18T17:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NDAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjExOTAwMQ==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546119001", "bodyText": "I wanted to do that but noticed that HoodieBackedTableMetadata is in hudi-common which does not have spark.\nSome new interface / refactoring will be required. Can handle this in a different ticket.", "author": "prashantwason", "createdAt": "2020-12-18T22:23:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NDAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMxMzE5Mw==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546313193", "bodyText": "We can pass in the HoodieEngineContext which can also be plain old java if needed. I ll take a closer look in #2351 and how best we can do this. We can scope this PR to just what you just fixed now", "author": "vinothchandar", "createdAt": "2020-12-20T03:05:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NDAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjQxNjQzMg==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546416432", "bodyText": "https://issues.apache.org/jira/browse/HUDI-1479 filed to track follow up. This needs to be done on master, since it has HoodieEngineContext abstraction that can be moved to hudi-common.", "author": "vinothchandar", "createdAt": "2020-12-20T19:09:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NDAyOA=="}], "type": "inlineReview", "revised_code": {"commit": "828a51ae04eeb41582a13a1f1b78c432134056f1", "chunk": "diff --git a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 6603ec3e57..622ee01720 100644\n--- a/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n\n@@ -53,7 +54,6 @@ import org.apache.hudi.common.util.Option;\n import org.apache.hudi.common.util.ValidationUtils;\n import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieCompactionConfig;\n-import org.apache.hudi.config.HoodieMetadataConfig;\n import org.apache.hudi.config.HoodieMetricsConfig;\n import org.apache.hudi.config.HoodieWriteConfig;\n import org.apache.hudi.exception.HoodieException;\n"}}, {"oid": "b7fc074f0534c2be891a0c144ac70a73ede79e46", "url": "https://github.com/apache/hudi/commit/b7fc074f0534c2be891a0c144ac70a73ede79e46", "message": "[HUDI-1469] Faster initialization of metadata table using parallelized listing which finds partitions and files in a single scan.", "committedDate": "2020-12-18T23:06:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMxMzA1Nw==", "url": "https://github.com/apache/hudi/pull/2343#discussion_r546313057", "bodyText": "I think we can drop .shuffle", "author": "vinothchandar", "createdAt": "2020-12-20T03:03:50Z", "path": "hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -72,6 +72,7 @@\n   public static final String BULKINSERT_USER_DEFINED_PARTITIONER_CLASS = \"hoodie.bulkinsert.user.defined.partitioner.class\";\n   public static final String UPSERT_PARALLELISM = \"hoodie.upsert.shuffle.parallelism\";\n   public static final String DELETE_PARALLELISM = \"hoodie.delete.shuffle.parallelism\";\n+  public static final String FILE_LISTING_PARALLELISM = \"hoodie.file.listing.shuffle.parallelism\";", "originalCommit": "b7fc074f0534c2be891a0c144ac70a73ede79e46", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d71922dd72c2437e20863db924c5b20fad2150f4", "chunk": "diff --git a/hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 6ad567b0dc..bf8295330f 100644\n--- a/hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n\n@@ -72,7 +73,7 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   public static final String BULKINSERT_USER_DEFINED_PARTITIONER_CLASS = \"hoodie.bulkinsert.user.defined.partitioner.class\";\n   public static final String UPSERT_PARALLELISM = \"hoodie.upsert.shuffle.parallelism\";\n   public static final String DELETE_PARALLELISM = \"hoodie.delete.shuffle.parallelism\";\n-  public static final String FILE_LISTING_PARALLELISM = \"hoodie.file.listing.shuffle.parallelism\";\n+  public static final String FILE_LISTING_PARALLELISM = \"hoodie.file.listing.parallelism\";\n   public static final String DEFAULT_ROLLBACK_PARALLELISM = \"100\";\n   public static final String ROLLBACK_PARALLELISM = \"hoodie.rollback.parallelism\";\n   public static final String WRITE_BUFFER_LIMIT_BYTES = \"hoodie.write.buffer.limit.bytes\";\n"}}, {"oid": "828a51ae04eeb41582a13a1f1b78c432134056f1", "url": "https://github.com/apache/hudi/commit/828a51ae04eeb41582a13a1f1b78c432134056f1", "message": "[HUDI-1469] Faster initialization of metadata table using parallelized listing which finds partitions and files in a single scan.", "committedDate": "2020-12-20T19:33:34Z", "type": "commit"}, {"oid": "d71922dd72c2437e20863db924c5b20fad2150f4", "url": "https://github.com/apache/hudi/commit/d71922dd72c2437e20863db924c5b20fad2150f4", "message": "MINOR fixes", "committedDate": "2020-12-21T18:00:35Z", "type": "commit"}, {"oid": "d71922dd72c2437e20863db924c5b20fad2150f4", "url": "https://github.com/apache/hudi/commit/d71922dd72c2437e20863db924c5b20fad2150f4", "message": "MINOR fixes", "committedDate": "2020-12-21T18:00:35Z", "type": "forcePushed"}]}