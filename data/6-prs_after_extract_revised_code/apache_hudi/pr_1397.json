{"pr_number": 1397, "pr_title": "[HUDI-692] Add delete savepoint for cli", "pr_createdAt": "2020-03-11T06:35:02Z", "pr_url": "https://github.com/apache/hudi/pull/1397", "timeline": [{"oid": "c2807199e76b1f789c7ed1929b394313c4f59dd8", "url": "https://github.com/apache/hudi/commit/c2807199e76b1f789c7ed1929b394313c4f59dd8", "message": "Add delete savepoint for cli", "committedDate": "2020-03-11T06:33:13Z", "type": "commit"}, {"oid": "24b6039bffa904b91fa3dcb99705e50e4c9c364d", "url": "https://github.com/apache/hudi/commit/24b6039bffa904b91fa3dcb99705e50e4c9c364d", "message": "Add check", "committedDate": "2020-03-11T07:33:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgzMzIzMQ==", "url": "https://github.com/apache/hudi/pull/1397#discussion_r390833231", "bodyText": "JavaSparkContext implements AutoCloseable interface, can we use try-with-resource here to avoid the resource leak?", "author": "yanghua", "createdAt": "2020-03-11T09:15:34Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/SavepointsCommand.java", "diffHunk": "@@ -127,6 +127,26 @@ public String refreshMetaClient() {\n     return \"Metadata for table \" + HoodieCLI.getTableMetaClient().getTableConfig().getTableName() + \" refreshed.\";\n   }\n \n+  @CliCommand(value = \"savepoint delete\", help = \"Delete the savepoint\")\n+  public String deleteSavepoint(@CliOption(key = {\"commit\"}, help = \"Delete a savepoint\") final String commitTime) throws Exception {\n+    HoodieTableMetaClient metaClient = HoodieCLI.getTableMetaClient();\n+    HoodieTimeline completedInstants = metaClient.getActiveTimeline().getSavePointTimeline().filterCompletedInstants();\n+    if (completedInstants.empty()) {\n+      throw new HoodieException(\"There are no completed savepoint to run delete\");\n+    }\n+    HoodieInstant savePoint = new HoodieInstant(false, HoodieTimeline.SAVEPOINT_ACTION, commitTime);\n+\n+    if (!completedInstants.containsInstant(savePoint)) {\n+      return \"Commit \" + commitTime + \" not found in Commits \" + completedInstants;\n+    }\n+\n+    JavaSparkContext jsc = SparkUtil.initJavaSparkConf(\"Delete Savepoint\");\n+    HoodieWriteClient client = createHoodieClient(jsc, metaClient.getBasePath());\n+    client.deleteSavepoint(commitTime);\n+    jsc.close();", "originalCommit": "24b6039bffa904b91fa3dcb99705e50e4c9c364d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e6fe5b93dc4674a896eb1e7ec6ec79ce33940d7e", "chunk": "diff --git a/hudi-cli/src/main/java/org/apache/hudi/cli/commands/SavepointsCommand.java b/hudi-cli/src/main/java/org/apache/hudi/cli/commands/SavepointsCommand.java\nindex f9142138a..9ef15ac80 100644\n--- a/hudi-cli/src/main/java/org/apache/hudi/cli/commands/SavepointsCommand.java\n+++ b/hudi-cli/src/main/java/org/apache/hudi/cli/commands/SavepointsCommand.java\n\n@@ -140,10 +140,11 @@ public class SavepointsCommand implements CommandMarker {\n       return \"Commit \" + commitTime + \" not found in Commits \" + completedInstants;\n     }\n \n-    JavaSparkContext jsc = SparkUtil.initJavaSparkConf(\"Delete Savepoint\");\n-    HoodieWriteClient client = createHoodieClient(jsc, metaClient.getBasePath());\n-    client.deleteSavepoint(commitTime);\n-    jsc.close();\n+    try (JavaSparkContext jsc = SparkUtil.initJavaSparkConf(\"Delete Savepoint\")) {\n+      HoodieWriteClient client = createHoodieClient(jsc, metaClient.getBasePath());\n+      client.deleteSavepoint(commitTime);\n+      refreshMetaClient();\n+    }\n     return \"Savepoint \" + commitTime + \" deleted\";\n   }\n \n"}}, {"oid": "e6fe5b93dc4674a896eb1e7ec6ec79ce33940d7e", "url": "https://github.com/apache/hudi/commit/e6fe5b93dc4674a896eb1e7ec6ec79ce33940d7e", "message": "Move JavaSparkContext to try", "committedDate": "2020-03-11T10:35:55Z", "type": "commit"}]}