{"pr_number": 2195, "pr_title": "[MINOR] Fix caller to SparkBulkInsertCommitActionExecutor", "pr_createdAt": "2020-10-22T00:24:51Z", "pr_url": "https://github.com/apache/hudi/pull/2195", "timeline": [{"oid": "d409850b1c8795039cce68de1354f790b1c5c8e1", "url": "https://github.com/apache/hudi/commit/d409850b1c8795039cce68de1354f790b1c5c8e1", "message": "[MINOR] Fix caller to SparkBulkInsertCommitActionExecutor\n\nFixed calling the wrong constructor", "committedDate": "2020-10-22T00:24:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTgwOTc3MQ==", "url": "https://github.com/apache/hudi/pull/2195#discussion_r509809771", "bodyText": "this results in error  \"java.util.HashMap cannot be cast to org.apache.hudi.table.BulkInsertPartitioner\"", "author": "xushiyan", "createdAt": "2020-10-22T00:25:34Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/bootstrap/SparkBootstrapCommitActionExecutor.java", "diffHunk": "@@ -284,7 +284,7 @@ protected void commit(Option<Map<String, String>> extraMetadata, HoodieWriteMeta\n   protected BaseSparkCommitActionExecutor<T> getBulkInsertActionExecutor(JavaRDD<HoodieRecord> inputRecordsRDD) {\n     return new SparkBulkInsertCommitActionExecutor((HoodieSparkEngineContext) context, new HoodieWriteConfig.Builder().withProps(config.getProps())\n         .withSchema(bootstrapSchema).build(), table, HoodieTimeline.FULL_BOOTSTRAP_INSTANT_TS,\n-        inputRecordsRDD, extraMetadata);\n+        inputRecordsRDD, Option.empty(), extraMetadata);", "originalCommit": "d409850b1c8795039cce68de1354f790b1c5c8e1", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}