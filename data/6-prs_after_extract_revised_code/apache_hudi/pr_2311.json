{"pr_number": 2311, "pr_title": "[HUDI-115] Adding DefaultHoodieRecordPayload to honor ordering with combineAndGetUpdateValue", "pr_createdAt": "2020-12-09T07:50:08Z", "pr_url": "https://github.com/apache/hudi/pull/2311", "timeline": [{"oid": "d637a728505792fdd5ca184877b12a918aeb3314", "url": "https://github.com/apache/hudi/commit/d637a728505792fdd5ca184877b12a918aeb3314", "message": "Adding OverwriteWithLatestAvroPayloadV1 to honor ordering while merging two records", "committedDate": "2020-12-09T07:52:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzMDU3OA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539130578", "bodyText": "should we use a string to save storage? Looks like this will create a map for every record.", "author": "garyli1019", "createdAt": "2020-12-09T09:08:37Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n+ */\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n+    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n+\n+  private Map<String, String> props;", "originalCommit": "d637a728505792fdd5ca184877b12a918aeb3314", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MTk1OA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r540541958", "bodyText": "yeah. lets wait to hear from @vinothchandar . Previous impl was sending in this map as arg to combineAndGetUpdateValue rather than storing it as instance var. may be thats better in terms of storage cost. I thought we could avoid making changes to all callers of combineAndGetUpdateValue.", "author": "nsivabalan", "createdAt": "2020-12-10T22:25:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzMDU3OA=="}], "type": "inlineReview", "revised_code": {"commit": "13e1417ae2653aa649598bf539767f7cefef75e9", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java b/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nsimilarity index 79%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nindex 8a20fedf37..3dcb8b79e0 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\n\n@@ -30,29 +30,27 @@ import org.apache.avro.generic.GenericRecord;\n import org.apache.avro.generic.IndexedRecord;\n \n import java.io.IOException;\n+import java.util.Properties;\n \n /**\n  * Default payload used for delta streamer.\n  * <p>\n- * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n- * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n  */\n-public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n-    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload\n+    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n \n-  private Map<String, String> props;\n-\n-  public OverwriteWithLatestAvroPayloadV1(GenericRecord record, Comparable orderingVal, Map<String, String> props) {\n+  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n     super(record, orderingVal);\n-    this.props = props;\n   }\n \n-  public OverwriteWithLatestAvroPayloadV1(Option<GenericRecord> record) {\n-    this(record.isPresent() ? record.get() : null, (record1) -> 0, Collections.EMPTY_MAP); // natural order\n+  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n   }\n \n   @Override\n-  public OverwriteWithLatestAvroPayloadV1 preCombine(OverwriteWithLatestAvroPayloadV1 another) {\n+  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n     // pick the payload with greatest ordering value\n     if (another.orderingVal.compareTo(orderingVal) > 0) {\n       return another;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzMzI4NA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539133284", "bodyText": "Is there any reason we need a different config from the pre-combine field? IIUC we wanna make the merging logic consistent, so preCombine and combineAndGetUpdateValue should produce the same result?", "author": "garyli1019", "createdAt": "2020-12-09T09:12:18Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -121,6 +121,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // payload ordering field\n+  private static final String PAYLOAD_ORDERING_FIELD_PROP = \"hoodie.payload.ordering.field\";", "originalCommit": "d637a728505792fdd5ca184877b12a918aeb3314", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "13e1417ae2653aa649598bf539767f7cefef75e9", "chunk": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 8d5ce14d3b..b19d7c6659 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n\n@@ -121,10 +121,6 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n-  // payload ordering field\n-  private static final String PAYLOAD_ORDERING_FIELD_PROP = \"hoodie.payload.ordering.field\";\n-  private static String DEFAULT_PAYLOAD_ORDERING_FIELD_VAL = \"\";\n-\n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n    * multiple write operations (upsert/buk-insert/...) to be executed within a single commit.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzNTgxNQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r539135815", "bodyText": "naming is hard... how about CombineWithLargestOrderingValPayload?", "author": "garyli1019", "createdAt": "2020-12-09T09:15:52Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n+ */\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload", "originalCommit": "d637a728505792fdd5ca184877b12a918aeb3314", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MjQ5Nw==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r540542497", "bodyText": "yeah. Ideally existing one should have been OverwriteWithIncomingAvroPayload and this new one should be OverwriteWithLatestAvroPayload.", "author": "nsivabalan", "createdAt": "2020-12-10T22:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEzNTgxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "13e1417ae2653aa649598bf539767f7cefef75e9", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java b/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nsimilarity index 79%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nindex 8a20fedf37..3dcb8b79e0 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\n\n@@ -30,29 +30,27 @@ import org.apache.avro.generic.GenericRecord;\n import org.apache.avro.generic.IndexedRecord;\n \n import java.io.IOException;\n+import java.util.Properties;\n \n /**\n  * Default payload used for delta streamer.\n  * <p>\n- * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n- * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n  */\n-public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n-    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload\n+    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n \n-  private Map<String, String> props;\n-\n-  public OverwriteWithLatestAvroPayloadV1(GenericRecord record, Comparable orderingVal, Map<String, String> props) {\n+  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n     super(record, orderingVal);\n-    this.props = props;\n   }\n \n-  public OverwriteWithLatestAvroPayloadV1(Option<GenericRecord> record) {\n-    this(record.isPresent() ? record.get() : null, (record1) -> 0, Collections.EMPTY_MAP); // natural order\n+  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n   }\n \n   @Override\n-  public OverwriteWithLatestAvroPayloadV1 preCombine(OverwriteWithLatestAvroPayloadV1 another) {\n+  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n     // pick the payload with greatest ordering value\n     if (another.orderingVal.compareTo(orderingVal) > 0) {\n       return another;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc3MTMwOQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r540771309", "bodyText": "@nsivabalan  won't this break for an existing payloadClass (user defined), that does have this three member constructor?", "author": "vinothchandar", "createdAt": "2020-12-11T08:26:48Z", "path": "hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java", "diffHunk": "@@ -142,6 +142,20 @@ public static HoodieRecordPayload createPayload(String payloadClass, GenericReco\n     }\n   }\n \n+  /**\n+   * Create a payload class via reflection, passing in an ordering/precombine value.\n+   */\n+  public static HoodieRecordPayload createPayload(String payloadClass, GenericRecord record, Comparable orderingVal,", "originalCommit": "d637a728505792fdd5ca184877b12a918aeb3314", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "13e1417ae2653aa649598bf539767f7cefef75e9", "chunk": "diff --git a/hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java b/hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java\nindex 0a92d4c3b9..8d3e81b0b2 100644\n--- a/hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java\n+++ b/hudi-spark/src/main/java/org/apache/hudi/DataSourceUtils.java\n\n@@ -142,20 +143,6 @@ public class DataSourceUtils {\n     }\n   }\n \n-  /**\n-   * Create a payload class via reflection, passing in an ordering/precombine value.\n-   */\n-  public static HoodieRecordPayload createPayload(String payloadClass, GenericRecord record, Comparable orderingVal,\n-      Map<String, String> props)\n-      throws IOException {\n-    try {\n-      return (HoodieRecordPayload) ReflectionUtils.loadClass(payloadClass,\n-          new Class<?>[] {GenericRecord.class, Comparable.class}, record, orderingVal, props);\n-    } catch (Throwable e) {\n-      throw new IOException(\"Could not create payload for class: \" + payloadClass, e);\n-    }\n-  }\n-\n   /**\n    * Create a payload class via reflection, do not ordering/precombine value.\n    */\n"}}, {"oid": "13e1417ae2653aa649598bf539767f7cefef75e9", "url": "https://github.com/apache/hudi/commit/13e1417ae2653aa649598bf539767f7cefef75e9", "message": "Fixing default payload based on feedback", "committedDate": "2020-12-12T20:42:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ2NjAyNg==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543466026", "bodyText": "rename: getPayloadConfig()", "author": "vinothchandar", "createdAt": "2020-12-15T15:54:01Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -729,6 +731,10 @@ public FileSystemViewStorageConfig getClientSpecifiedViewStorageConfig() {\n     return clientSpecifiedViewStorageConfig;\n   }\n \n+  public HoodiePayloadConfig getHoodiePayloadConfig() {", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex b19d7c6659..6760e561cf 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n\n@@ -731,10 +752,6 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return clientSpecifiedViewStorageConfig;\n   }\n \n-  public HoodiePayloadConfig getHoodiePayloadConfig() {\n-    return hoodiePayloadConfig;\n-  }\n-\n   /**\n    * Commit call back configs.\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ2Njc5Ng==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543466796", "bodyText": "nit: extra line", "author": "vinothchandar", "createdAt": "2020-12-15T15:54:56Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/BaseAvroPayload.java", "diffHunk": "@@ -29,6 +29,7 @@\n  * Base class for all AVRO record based payloads, that can be ordered based on a field.\n  */\n public abstract class BaseAvroPayload implements Serializable {\n+  ", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/BaseAvroPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/BaseAvroPayload.java\nindex f739134e09..4bdb15fb48 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/BaseAvroPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/BaseAvroPayload.java\n\n@@ -29,7 +29,9 @@ import java.io.Serializable;\n  * Base class for all AVRO record based payloads, that can be ordered based on a field.\n  */\n public abstract class BaseAvroPayload implements Serializable {\n-  \n+\n+  public static final String ORDERING_FIELD_OPT_KEY = \"ordering.field\";\n+\n   /**\n    * Avro data extracted from the source converted to bytes.\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ2Nzk2NA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543467964", "bodyText": "more descriptive doc?", "author": "vinothchandar", "createdAt": "2020-12-15T15:56:28Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodiePayloadProps.java", "diffHunk": "@@ -0,0 +1,12 @@\n+package org.apache.hudi.common.model;\n+\n+/**\n+ * Since both payload classes and HoodiePayloadConfig needs to access these props, storing it here.\n+ */\n+public class HoodiePayloadProps {\n+\n+  // payload ordering field", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodiePayloadProps.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodiePayloadProps.java\ndeleted file mode 100644\nindex 93ab5b8c3b..0000000000\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodiePayloadProps.java\n+++ /dev/null\n\n@@ -1,12 +0,0 @@\n-package org.apache.hudi.common.model;\n-\n-/**\n- * Since both payload classes and HoodiePayloadConfig needs to access these props, storing it here.\n- */\n-public class HoodiePayloadProps {\n-\n-  // payload ordering field\n-  public static final String PAYLOAD_ORDERING_FIELD_PROP = \"hoodie.payload.ordering.field\";\n-  public static String DEFAULT_PAYLOAD_ORDERING_FIELD_VAL = \"ts\";\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3MDE2MQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543470161", "bodyText": "mark all deprecated methods with the right ApiMaturityLevel.DEPRECATED?", "author": "vinothchandar", "createdAt": "2020-12-15T15:58:53Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\nindex f29216d50b..1afdd1b59a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n\n@@ -29,93 +29,47 @@ import org.apache.avro.generic.IndexedRecord;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n-import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n+ * depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n+   * insert/upsert (if combining turned on in HoodieClientConfig).\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n-   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the combined value\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default T preCombine(T another, Properties properties) {\n-    return preCombine(another);\n-  }\n-\n-  /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n+   * storage and whats contained in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n+   * may be reading DB redo logs, and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n-   *    * on some properties set.\n-   * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n-   *\n-   * @param currentValue Current value in storage, to merge/combine this payload with\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n+   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n+   * insert) Return EMPTY to skip writing this record.\n    */\n-  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n-    return combineAndGetUpdateValue(currentValue, schema);\n-  }\n-\n-  /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * @param schema Schema used for record\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n-    return getInsertValue(schema);\n-  }\n-\n-  /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and\n-   * {@code WriteStatus.markFailure()} in order to compute some aggregate metrics using the metadata in the context of a write success or failure.\n-   * @return the metadata in the form of Map<String, String> if any.\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n+   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n+   * using the metadata in the context of a write success or failure.\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   default Option<Map<String, String>> getMetadata() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3MjMxMQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543472311", "bodyText": "this is not just for delta streamer.", "author": "vinothchandar", "createdAt": "2020-12-15T16:01:24Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nsimilarity index 79%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nindex 3dcb8b79e0..8a20fedf37 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\n\n@@ -30,27 +30,29 @@ import org.apache.avro.generic.GenericRecord;\n import org.apache.avro.generic.IndexedRecord;\n \n import java.io.IOException;\n-import java.util.Properties;\n \n /**\n  * Default payload used for delta streamer.\n  * <p>\n- * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n- * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n  */\n-public class DefaultHoodieRecordPayload extends BaseAvroPayload\n-    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n+    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n \n-  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+  private Map<String, String> props;\n+\n+  public OverwriteWithLatestAvroPayloadV1(GenericRecord record, Comparable orderingVal, Map<String, String> props) {\n     super(record, orderingVal);\n+    this.props = props;\n   }\n \n-  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n-    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  public OverwriteWithLatestAvroPayloadV1(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0, Collections.EMPTY_MAP); // natural order\n   }\n \n   @Override\n-  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+  public OverwriteWithLatestAvroPayloadV1 preCombine(OverwriteWithLatestAvroPayloadV1 another) {\n     // pick the payload with greatest ordering value\n     if (another.orderingVal.compareTo(orderingVal) > 0) {\n       return another;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NDE3MQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543474171", "bodyText": "is this class pretty much a modified version of OverwriteWithLatestAvroPayload?  if so, can we reuse some code by having that extend from this, and override methods as needed?", "author": "vinothchandar", "createdAt": "2020-12-15T16:03:44Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ */\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nsimilarity index 79%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nindex 3dcb8b79e0..8a20fedf37 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\n\n@@ -30,27 +30,29 @@ import org.apache.avro.generic.GenericRecord;\n import org.apache.avro.generic.IndexedRecord;\n \n import java.io.IOException;\n-import java.util.Properties;\n \n /**\n  * Default payload used for delta streamer.\n  * <p>\n- * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n- * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n  */\n-public class DefaultHoodieRecordPayload extends BaseAvroPayload\n-    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n+    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n \n-  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+  private Map<String, String> props;\n+\n+  public OverwriteWithLatestAvroPayloadV1(GenericRecord record, Comparable orderingVal, Map<String, String> props) {\n     super(record, orderingVal);\n+    this.props = props;\n   }\n \n-  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n-    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  public OverwriteWithLatestAvroPayloadV1(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0, Collections.EMPTY_MAP); // natural order\n   }\n \n   @Override\n-  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+  public OverwriteWithLatestAvroPayloadV1 preCombine(OverwriteWithLatestAvroPayloadV1 another) {\n     // pick the payload with greatest ordering value\n     if (another.orderingVal.compareTo(orderingVal) > 0) {\n       return another;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NTQxMA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543475410", "bodyText": "just do the Comparable cast here itself?", "author": "vinothchandar", "createdAt": "2020-12-15T16:05:12Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ */\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload\n+    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+\n+  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+    super(record, orderingVal);\n+  }\n+\n+  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  }\n+\n+  @Override\n+  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+    // pick the payload with greatest ordering value\n+    if (another.orderingVal.compareTo(orderingVal) > 0) {\n+      return another;\n+    } else {\n+      return this;\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> getInsertValue(Schema schema) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    IndexedRecord indexedRecord = bytesToAvro(recordBytes, schema);\n+    if (isDeleteRecord((GenericRecord) indexedRecord)) {\n+      return Option.empty();\n+    } else {\n+      return Option.of(indexedRecord);\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException{\n+    return getInsertValue(schema);\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    GenericRecord incomingRecord = bytesToAvro(recordBytes, schema);\n+    /*\n+     * Combining strategy here returns currentValue on disk if incoming record is older.\n+     * The incoming record can be either a delete (sent as an upsert with _hoodie_is_deleted set to true)\n+     * or an insert/update record. In any case, if it is older than the record in disk, the currentValue\n+     * in disk is returned (to be rewritten with new commit time).\n+     *\n+     * NOTE: Deletes sent via EmptyHoodieRecordPayload and/or Delete operation type do not hit this code path\n+     * and need to be dealt with separately.\n+     */\n+    Object persistedOrderingVal = getNestedFieldVal((GenericRecord) currentValue, properties.getProperty(HoodiePayloadProps.PAYLOAD_ORDERING_FIELD_PROP), true);", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk3Mjg4Mg==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543972882", "bodyText": "I thought you had already reviewed previous PR and hence just copied as is. Will fix it.", "author": "nsivabalan", "createdAt": "2020-12-16T05:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NTQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk3MzU0OQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543973549", "bodyText": "actually we can't do that. it could be null.", "author": "nsivabalan", "createdAt": "2020-12-16T05:23:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NTQxMA=="}], "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nsimilarity index 79%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nindex 3dcb8b79e0..8a20fedf37 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\n\n@@ -30,27 +30,29 @@ import org.apache.avro.generic.GenericRecord;\n import org.apache.avro.generic.IndexedRecord;\n \n import java.io.IOException;\n-import java.util.Properties;\n \n /**\n  * Default payload used for delta streamer.\n  * <p>\n- * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n- * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n  */\n-public class DefaultHoodieRecordPayload extends BaseAvroPayload\n-    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n+    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n \n-  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+  private Map<String, String> props;\n+\n+  public OverwriteWithLatestAvroPayloadV1(GenericRecord record, Comparable orderingVal, Map<String, String> props) {\n     super(record, orderingVal);\n+    this.props = props;\n   }\n \n-  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n-    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  public OverwriteWithLatestAvroPayloadV1(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0, Collections.EMPTY_MAP); // natural order\n   }\n \n   @Override\n-  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+  public OverwriteWithLatestAvroPayloadV1 preCombine(OverwriteWithLatestAvroPayloadV1 another) {\n     // pick the payload with greatest ordering value\n     if (another.orderingVal.compareTo(orderingVal) > 0) {\n       return another;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NzI3Nw==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543477277", "bodyText": "nts: the check means persistedOrderingVal > incomingOrderingVal i.e we should retain the value on disk", "author": "vinothchandar", "createdAt": "2020-12-15T16:07:28Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import static org.apache.hudi.avro.HoodieAvroUtils.bytesToAvro;\n+import static org.apache.hudi.avro.HoodieAvroUtils.getNestedFieldVal;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import org.apache.hudi.common.util.Option;\n+\n+import org.apache.avro.Schema;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.avro.generic.IndexedRecord;\n+\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+/**\n+ * Default payload used for delta streamer.\n+ * <p>\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n+ * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ */\n+public class DefaultHoodieRecordPayload extends BaseAvroPayload\n+    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+\n+  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+    super(record, orderingVal);\n+  }\n+\n+  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  }\n+\n+  @Override\n+  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+    // pick the payload with greatest ordering value\n+    if (another.orderingVal.compareTo(orderingVal) > 0) {\n+      return another;\n+    } else {\n+      return this;\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> getInsertValue(Schema schema) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    IndexedRecord indexedRecord = bytesToAvro(recordBytes, schema);\n+    if (isDeleteRecord((GenericRecord) indexedRecord)) {\n+      return Option.empty();\n+    } else {\n+      return Option.of(indexedRecord);\n+    }\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException{\n+    return getInsertValue(schema);\n+  }\n+\n+  @Override\n+  public Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    if (recordBytes.length == 0) {\n+      return Option.empty();\n+    }\n+    GenericRecord incomingRecord = bytesToAvro(recordBytes, schema);\n+    /*\n+     * Combining strategy here returns currentValue on disk if incoming record is older.\n+     * The incoming record can be either a delete (sent as an upsert with _hoodie_is_deleted set to true)\n+     * or an insert/update record. In any case, if it is older than the record in disk, the currentValue\n+     * in disk is returned (to be rewritten with new commit time).\n+     *\n+     * NOTE: Deletes sent via EmptyHoodieRecordPayload and/or Delete operation type do not hit this code path\n+     * and need to be dealt with separately.\n+     */\n+    Object persistedOrderingVal = getNestedFieldVal((GenericRecord) currentValue, properties.getProperty(HoodiePayloadProps.PAYLOAD_ORDERING_FIELD_PROP), true);\n+    Comparable incomingOrderingVal = (Comparable) getNestedFieldVal(incomingRecord, properties.getProperty(HoodiePayloadProps.PAYLOAD_ORDERING_FIELD_PROP), false);\n+\n+    // Null check is needed here to support schema evolution. The record in storage may be from old schema where\n+    // the new ordering column might not be present and hence returns null.\n+    if (persistedOrderingVal != null && ((Comparable) persistedOrderingVal).compareTo(incomingOrderingVal) > 0) {", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk3NDA2Mg==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543974062", "bodyText": "sorry, you wanted to confirm this behavior? can you please clarify.", "author": "nsivabalan", "createdAt": "2020-12-16T05:24:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NzI3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzk3NjUyMQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543976521", "bodyText": "yes . nts = note to self. sorry :/", "author": "vinothchandar", "createdAt": "2020-12-16T05:27:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3NzI3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nsimilarity index 79%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\nindex 3dcb8b79e0..8a20fedf37 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/DefaultHoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/OverwriteWithLatestAvroPayloadV1.java\n\n@@ -30,27 +30,29 @@ import org.apache.avro.generic.GenericRecord;\n import org.apache.avro.generic.IndexedRecord;\n \n import java.io.IOException;\n-import java.util.Properties;\n \n /**\n  * Default payload used for delta streamer.\n  * <p>\n- * 1. preCombine - Picks the latest delta record for a key, based on an ordering field\n- * 2. combineAndGetUpdateValue/getInsertValue - Chooses the latest record based on ordering field value.\n+ * 1. preCombine - Picks the latest delta record for a key, based on an ordering field 2.\n+ * combineAndGetUpdateValue/getInsertValue - Simply overwrites storage with latest delta record\n  */\n-public class DefaultHoodieRecordPayload extends BaseAvroPayload\n-    implements HoodieRecordPayload<DefaultHoodieRecordPayload> {\n+public class OverwriteWithLatestAvroPayloadV1 extends BaseAvroPayload\n+    implements HoodieRecordPayload<OverwriteWithLatestAvroPayloadV1> {\n \n-  public DefaultHoodieRecordPayload(GenericRecord record, Comparable orderingVal) {\n+  private Map<String, String> props;\n+\n+  public OverwriteWithLatestAvroPayloadV1(GenericRecord record, Comparable orderingVal, Map<String, String> props) {\n     super(record, orderingVal);\n+    this.props = props;\n   }\n \n-  public DefaultHoodieRecordPayload(Option<GenericRecord> record) {\n-    this(record.isPresent() ? record.get() : null, (record1) -> 0); // natural order\n+  public OverwriteWithLatestAvroPayloadV1(Option<GenericRecord> record) {\n+    this(record.isPresent() ? record.get() : null, (record1) -> 0, Collections.EMPTY_MAP); // natural order\n   }\n \n   @Override\n-  public DefaultHoodieRecordPayload preCombine(DefaultHoodieRecordPayload another) {\n+  public OverwriteWithLatestAvroPayloadV1 preCombine(OverwriteWithLatestAvroPayloadV1 another) {\n     // pick the payload with greatest ordering value\n     if (another.orderingVal.compareTo(orderingVal) > 0) {\n       return another;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3ODU4NQ==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543478585", "bodyText": "please remove \"if combinng turned on ...\" comment. we should ideally refrain from referring to higher level constructs from lower layers.", "author": "vinothchandar", "createdAt": "2020-12-15T16:09:10Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\nindex f29216d50b..1afdd1b59a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n\n@@ -29,93 +29,47 @@ import org.apache.avro.generic.IndexedRecord;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n-import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n+ * depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n+   * insert/upsert (if combining turned on in HoodieClientConfig).\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n-   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the combined value\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default T preCombine(T another, Properties properties) {\n-    return preCombine(another);\n-  }\n-\n-  /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n+   * storage and whats contained in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n+   * may be reading DB redo logs, and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n-   *    * on some properties set.\n-   * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n-   *\n-   * @param currentValue Current value in storage, to merge/combine this payload with\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n+   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n+   * insert) Return EMPTY to skip writing this record.\n    */\n-  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n-    return combineAndGetUpdateValue(currentValue, schema);\n-  }\n-\n-  /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * @param schema Schema used for record\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n-    return getInsertValue(schema);\n-  }\n-\n-  /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and\n-   * {@code WriteStatus.markFailure()} in order to compute some aggregate metrics using the metadata in the context of a write success or failure.\n-   * @return the metadata in the form of Map<String, String> if any.\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n+   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n+   * using the metadata in the context of a write success or failure.\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   default Option<Map<String, String>> getMetadata() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTE2Mw==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543479163", "bodyText": "same here", "author": "vinothchandar", "createdAt": "2020-12-15T16:09:51Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\nindex f29216d50b..1afdd1b59a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n\n@@ -29,93 +29,47 @@ import org.apache.avro.generic.IndexedRecord;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n-import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n+ * depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n+   * insert/upsert (if combining turned on in HoodieClientConfig).\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n-   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the combined value\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default T preCombine(T another, Properties properties) {\n-    return preCombine(another);\n-  }\n-\n-  /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n+   * storage and whats contained in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n+   * may be reading DB redo logs, and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n-   *    * on some properties set.\n-   * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n-   *\n-   * @param currentValue Current value in storage, to merge/combine this payload with\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n+   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n+   * insert) Return EMPTY to skip writing this record.\n    */\n-  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n-    return combineAndGetUpdateValue(currentValue, schema);\n-  }\n-\n-  /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * @param schema Schema used for record\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n-    return getInsertValue(schema);\n-  }\n-\n-  /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and\n-   * {@code WriteStatus.markFailure()} in order to compute some aggregate metrics using the metadata in the context of a write success or failure.\n-   * @return the metadata in the form of Map<String, String> if any.\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n+   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n+   * using the metadata in the context of a write success or failure.\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   default Option<Map<String, String>> getMetadata() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTUwNA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543479504", "bodyText": "place 2 on a newline?", "author": "vinothchandar", "createdAt": "2020-12-15T16:10:19Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTY4Mg==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543479682", "bodyText": "close the </p>", "author": "vinothchandar", "createdAt": "2020-12-15T16:10:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTUwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4MTU0NA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543481544", "bodyText": "I think we should just refer to the other method here in the javadoc, instead of repeating the entire description here again.", "author": "vinothchandar", "createdAt": "2020-12-15T16:12:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ3OTUwNA=="}], "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\nindex f29216d50b..1afdd1b59a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n\n@@ -29,93 +29,47 @@ import org.apache.avro.generic.IndexedRecord;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n-import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n+ * depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n+   * insert/upsert (if combining turned on in HoodieClientConfig).\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n-   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the combined value\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default T preCombine(T another, Properties properties) {\n-    return preCombine(another);\n-  }\n-\n-  /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n+   * storage and whats contained in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n+   * may be reading DB redo logs, and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n-   *    * on some properties set.\n-   * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n-   *\n-   * @param currentValue Current value in storage, to merge/combine this payload with\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n+   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n+   * insert) Return EMPTY to skip writing this record.\n    */\n-  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n-    return combineAndGetUpdateValue(currentValue, schema);\n-  }\n-\n-  /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * @param schema Schema used for record\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n-    return getInsertValue(schema);\n-  }\n-\n-  /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and\n-   * {@code WriteStatus.markFailure()} in order to compute some aggregate metrics using the metadata in the context of a write success or failure.\n-   * @return the metadata in the form of Map<String, String> if any.\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n+   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n+   * using the metadata in the context of a write success or failure.\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   default Option<Map<String, String>> getMetadata() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4MzI2Mw==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543483263", "bodyText": "this line can be bit pithy?", "author": "vinothchandar", "createdAt": "2020-12-15T16:14:53Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n-   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n-   * insert) Return EMPTY to skip writing this record.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n+   *    * on some properties set.\n+   * <p>\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n+   *\n+   * @param currentValue Current value in storage, to merge/combine this payload with\n+   * @param schema Schema used for record\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    return combineAndGetUpdateValue(currentValue, schema);\n+  }\n+\n+  /**\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * @param schema Schema used for record\n+   * @return the {@link IndexedRecord} to be inserted.\n+   */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n-   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n-   * using the metadata in the context of a write success or failure.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\nindex f29216d50b..1afdd1b59a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n\n@@ -29,93 +29,47 @@ import org.apache.avro.generic.IndexedRecord;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n-import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n+ * depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n+   * insert/upsert (if combining turned on in HoodieClientConfig).\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n-   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the combined value\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default T preCombine(T another, Properties properties) {\n-    return preCombine(another);\n-  }\n-\n-  /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n+   * storage and whats contained in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n+   * may be reading DB redo logs, and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n-   *    * on some properties set.\n-   * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n-   *\n-   * @param currentValue Current value in storage, to merge/combine this payload with\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n+   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n+   * insert) Return EMPTY to skip writing this record.\n    */\n-  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n-    return combineAndGetUpdateValue(currentValue, schema);\n-  }\n-\n-  /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * @param schema Schema used for record\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n-    return getInsertValue(schema);\n-  }\n-\n-  /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and\n-   * {@code WriteStatus.markFailure()} in order to compute some aggregate metrics using the metadata in the context of a write success or failure.\n-   * @return the metadata in the form of Map<String, String> if any.\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n+   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n+   * using the metadata in the context of a write success or failure.\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   default Option<Map<String, String>> getMetadata() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4MzQ0MA==", "url": "https://github.com/apache/hudi/pull/2311#discussion_r543483440", "bodyText": "thanks for fixing this", "author": "vinothchandar", "createdAt": "2020-12-15T16:15:08Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java", "diffHunk": "@@ -29,47 +29,93 @@\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n+import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n- * depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n-   * insert/upsert (if combining turned on in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig).\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n-   * storage and whats contained in this object.\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n+   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n+   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the combined value\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default T preCombine(T another, Properties properties) {\n+    return preCombine(another);\n+  }\n+\n+  /**\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n-   * may be reading DB redo logs, and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n-   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n-   * insert) Return EMPTY to skip writing this record.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n+   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n+   *    * on some properties set.\n+   * <p>\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n+   * and merge them with current image for a database row on storage\n+   *\n+   * @param currentValue Current value in storage, to merge/combine this payload with\n+   * @param schema Schema used for record\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n+  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n+    return combineAndGetUpdateValue(currentValue, schema);\n+  }\n+\n+  /**\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * @param schema Schema used for record\n+   * @return the {@link IndexedRecord} to be inserted.\n+   */\n+  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n-   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n-   * using the metadata in the context of a write success or failure.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n+   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n+   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n+   * @param schema Schema used for record\n+   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n+   * @return the {@link IndexedRecord} to be inserted.\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n+  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n+    return getInsertValue(schema);\n+  }\n+\n+  /**\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and", "originalCommit": "13e1417ae2653aa649598bf539767f7cefef75e9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\nindex f29216d50b..1afdd1b59a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieRecordPayload.java\n\n@@ -29,93 +29,47 @@ import org.apache.avro.generic.IndexedRecord;\n import java.io.IOException;\n import java.io.Serializable;\n import java.util.Map;\n-import java.util.Properties;\n \n /**\n- * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which depend on record specific logic.\n+ * Every Hoodie table has an implementation of the <code>HoodieRecordPayload</code> This abstracts out callbacks which\n+ * depend on record specific logic.\n  */\n @PublicAPIClass(maturity = ApiMaturityLevel.STABLE)\n public interface HoodieRecordPayload<T extends HoodieRecordPayload> extends Serializable {\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig).\n+   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to\n+   * insert/upsert (if combining turned on in HoodieClientConfig).\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   T preCombine(T another);\n \n   /**\n-   * When more than one HoodieRecord have the same HoodieKey, this function combines them before attempting to insert/upsert (if combining turned on\n-   * in HoodieClientConfig) by taking in a property map. Implementation can leverage the property to decide their business logic to do preCombine.\n-   * @param another instance of another {@link HoodieRecordPayload} to be combined with.\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the combined value\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default T preCombine(T another, Properties properties) {\n-    return preCombine(another);\n-  }\n-\n-  /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object.\n+   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on\n+   * storage and whats contained in this object.\n    * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n+   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You\n+   * may be reading DB redo logs, and merge them with current image for a database row on storage\n    *\n    * @param currentValue Current value in storage, to merge/combine this payload with\n    * @param schema Schema used for record\n    * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n    */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema) throws IOException;\n \n   /**\n-   * This methods lets you write custom merging/combining logic to produce new values as a function of current value on storage and whats contained\n-   * in this object. This method takes in a property map as an arg so that implementation can decide their business logic based\n-   *    * on some properties set.\n-   * <p>\n-   * eg: 1) You are updating counters, you may want to add counts to currentValue and write back updated counts 2) You may be reading DB redo logs,\n-   * and merge them with current image for a database row on storage\n-   *\n-   * @param currentValue Current value in storage, to merge/combine this payload with\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return new combined/merged value to be written back to storage. EMPTY to skip writing this record.\n+   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a\n+   * new value for the given HoodieKey, wherein there is no existing record in storage to be combined against. (i.e\n+   * insert) Return EMPTY to skip writing this record.\n    */\n-  default Option<IndexedRecord> combineAndGetUpdateValue(IndexedRecord currentValue, Schema schema, Properties properties) throws IOException {\n-    return combineAndGetUpdateValue(currentValue, schema);\n-  }\n-\n-  /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * @param schema Schema used for record\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @Deprecated\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   Option<IndexedRecord> getInsertValue(Schema schema) throws IOException;\n \n   /**\n-   * Generates an avro record out of the given HoodieRecordPayload, to be written out to storage. Called when writing a new value for the given\n-   * HoodieKey, wherein there is no existing record in storage to be combined against. (i.e insert) Return EMPTY to skip writing this record.\n-   * This method takes in a property map as an arg so that implementation can decide their business logic based on some properties set.\n-   * @param schema Schema used for record\n-   * @param properties Payload related properties. For example pass the ordering field(s) name to extract from value in storage.\n-   * @return the {@link IndexedRecord} to be inserted.\n-   */\n-  @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n-  default Option<IndexedRecord> getInsertValue(Schema schema, Properties properties) throws IOException {\n-    return getInsertValue(schema);\n-  }\n-\n-  /**\n-   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to {@code WriteStatus.markSuccess()} and\n-   * {@code WriteStatus.markFailure()} in order to compute some aggregate metrics using the metadata in the context of a write success or failure.\n-   * @return the metadata in the form of Map<String, String> if any.\n+   * This method can be used to extract some metadata from HoodieRecordPayload. The metadata is passed to\n+   * {@code WriteStatus.markSuccess()} and {@code WriteStatus.markFailure()} in order to compute some aggregate metrics\n+   * using the metadata in the context of a write success or failure.\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.STABLE)\n   default Option<Map<String, String>> getMetadata() {\n"}}, {"oid": "9238696e84b3aeb54a821fd85cdda37e642c8f21", "url": "https://github.com/apache/hudi/commit/9238696e84b3aeb54a821fd85cdda37e642c8f21", "message": "Adding OverwriteWithLatestAvroPayloadV1 to honor ordering while merging two records", "committedDate": "2020-12-16T06:28:29Z", "type": "commit"}, {"oid": "f759074310296e064012dc95dcadb622b7a36ce9", "url": "https://github.com/apache/hudi/commit/f759074310296e064012dc95dcadb622b7a36ce9", "message": "Fixing default payload based on feedback", "committedDate": "2020-12-16T06:29:24Z", "type": "commit"}, {"oid": "f4f529e1a9e045e417151c78e3333de0cd3c274f", "url": "https://github.com/apache/hudi/commit/f4f529e1a9e045e417151c78e3333de0cd3c274f", "message": "Addressing feedback", "committedDate": "2020-12-16T06:29:42Z", "type": "commit"}, {"oid": "f4f529e1a9e045e417151c78e3333de0cd3c274f", "url": "https://github.com/apache/hudi/commit/f4f529e1a9e045e417151c78e3333de0cd3c274f", "message": "Addressing feedback", "committedDate": "2020-12-16T06:29:42Z", "type": "forcePushed"}, {"oid": "d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "url": "https://github.com/apache/hudi/commit/d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "message": "Fixing build issues", "committedDate": "2020-12-18T02:00:40Z", "type": "commit"}, {"oid": "d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "url": "https://github.com/apache/hudi/commit/d9327235f3ebc1b40fb76c7162fac7dd5b9f2726", "message": "Fixing build issues", "committedDate": "2020-12-18T02:00:40Z", "type": "forcePushed"}]}