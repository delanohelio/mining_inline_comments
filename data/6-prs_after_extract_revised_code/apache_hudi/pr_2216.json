{"pr_number": 2216, "pr_title": "[HUDI-1357] Added a check to ensure no records are lost during updates.", "pr_createdAt": "2020-10-29T19:30:44Z", "pr_url": "https://github.com/apache/hudi/pull/2216", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkzOTI3Ng==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r520939276", "bodyText": "as far as I can tell, we only use this within HoodieMergeHandle.  Can we avoid adding the extra member here and simply use a local variable? I am trying to understand the use-case for logging this in stat.", "author": "vinothchandar", "createdAt": "2020-11-10T23:27:39Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java", "diffHunk": "@@ -49,6 +49,12 @@\n    */\n   private String prevCommit;\n \n+  /**\n+   * Total number of records written to the previous version of the file slice.\n+   * If inflight commit is c2, then number of records present in f1_w1_c1.parquet.\n+   */\n+  private long oldNumWrites;", "originalCommit": "15a7807cce0f4e8347cb24b7c855431ef6fb92fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxMjE1Mg==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r524812152", "bodyText": "@nbalajee Do you have a reason for this requirement? Seems ok to remove saving it.", "author": "prashantwason", "createdAt": "2020-11-17T00:48:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkzOTI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxMzgwNQ==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r524813805", "bodyText": "@vinothchandar - This check can be toggled on/off on a per table basis.  When debugging an actual incident,  where the commit metadata files have been archived, older snapshots of data files have been cleaned up by the cleaner,  having \"oldNumWrites\" metadata is of great help in identifying the instance that resulted in a smaller parquet file by inspecting the archived commit metadata (Especially when the check is turned off and wouldn't throw an exception).\nFor example, if the file were to evolve  from f1_c1.parquet to f1_c10.parquet, then without this \"oldNumWrites\" information, we have hunt down all the the older archived commits, in search of the commit that had touched the data file.\n@prashantwason  - in performDatalossCheck(), we should move this out side of the isDatalossCheckEnabled() condition, so that we will record this info, irrespective of whether the flag is enabled or not.", "author": "nbalajee", "createdAt": "2020-11-17T00:53:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkzOTI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjE0MjQzOQ==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r526142439", "bodyText": "@nbalajee If we move this outside of  isDatalossCheckEnabled() condition, then wont it always read the older parquet files each time before commit? If so, there is not much to the setting anyways because the overhead of this feature is reading the older parquet each time before merge.", "author": "prashantwason", "createdAt": "2020-11-18T14:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkzOTI3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODQ0MjgxMw==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r528442813", "bodyText": "@nbalajee I totally understand. but we could log this out and use elastic search or some other infrastructure to debug right. I would really love to not mix debug information with something as critical as commit metadata.\nThis sets a precedent that we cannot follow going forward :)", "author": "vinothchandar", "createdAt": "2020-11-23T02:06:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkzOTI3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "c8f05c953beff33ac0dd174dee3edd52e2c37caa", "chunk": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java\nindex 98d8607c6..97288dfe0 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieWriteStat.java\n\n@@ -49,12 +49,6 @@ public class HoodieWriteStat implements Serializable {\n    */\n   private String prevCommit;\n \n-  /**\n-   * Total number of records written to the previous version of the file slice.\n-   * If inflight commit is c2, then number of records present in f1_w1_c1.parquet.\n-   */\n-  private long oldNumWrites;\n-\n   /**\n    * Total number of records written for this file. - for updates, its the entire number of records in the file - for\n    * inserts, its the actual number of records inserted.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkzOTY0NQ==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r520939645", "bodyText": "sweet. I was going to suggest this. you are ahead!", "author": "vinothchandar", "createdAt": "2020-11-10T23:28:38Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/ParquetUtils.java", "diffHunk": "@@ -261,6 +262,22 @@ public static BloomFilter readBloomFilterFromParquetMetadata(Configuration confi\n     return records;\n   }\n \n+  /**\n+   * Returns the number of records in the parquet file.\n+   *\n+   * @param conf Configuration\n+   * @param parquetFilePath path of the file\n+   */\n+  public static long getRowCount(Configuration conf, Path parquetFilePath) {\n+    ParquetMetadata footer;\n+    long rowCount = 0;\n+    footer = readMetadata(conf, parquetFilePath);", "originalCommit": "15a7807cce0f4e8347cb24b7c855431ef6fb92fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0MDQxMw==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r520940413", "bodyText": "let's name this specific to real purpose like. hoodie.merge.data.validation.enabled , avoiding the calling this loss checking etc, which can be rather disconcerting to users, when they read this.", "author": "vinothchandar", "createdAt": "2020-11-10T23:30:38Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -117,6 +117,10 @@\n   public static final String MAX_CONSISTENCY_CHECKS_PROP = \"hoodie.consistency.check.max_checks\";\n   public static int DEFAULT_MAX_CONSISTENCY_CHECKS = 7;\n \n+  // Data loss check before commits\n+  private static final String DATALOSS_CHECK_ENABLED = \"hoodie.dataloss.check.enabled\";", "originalCommit": "15a7807cce0f4e8347cb24b7c855431ef6fb92fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDYxMjE4OQ==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r524612189", "bodyText": "+1", "author": "nbalajee", "createdAt": "2020-11-16T21:35:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0MDQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxMTk3OQ==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r524811979", "bodyText": "Good suggestion.", "author": "prashantwason", "createdAt": "2020-11-17T00:47:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0MDQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxNDA1Ng==", "url": "https://github.com/apache/hudi/pull/2216#discussion_r524814056", "bodyText": "+1", "author": "nbalajee", "createdAt": "2020-11-17T00:53:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk0MDQxMw=="}], "type": "inlineReview", "revised_code": {"commit": "da2ff4596c8492212ec25047b9c30f818aa8a250", "chunk": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex cd5943ba9..b06f994b0 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n\n@@ -117,9 +117,9 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   public static final String MAX_CONSISTENCY_CHECKS_PROP = \"hoodie.consistency.check.max_checks\";\n   public static int DEFAULT_MAX_CONSISTENCY_CHECKS = 7;\n \n-  // Data loss check before commits\n-  private static final String DATALOSS_CHECK_ENABLED = \"hoodie.dataloss.check.enabled\";\n-  private static final String DEFAULT_DATALOSS_CHECK_ENABLED = \"false\";\n+  // Data validation check performed during merges before actual commits\n+  private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n+  private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n"}}, {"oid": "da2ff4596c8492212ec25047b9c30f818aa8a250", "url": "https://github.com/apache/hudi/commit/da2ff4596c8492212ec25047b9c30f818aa8a250", "message": "[HUDI-1357] Added a check to ensure no records are lost during updates.", "committedDate": "2020-11-18T14:45:53Z", "type": "forcePushed"}, {"oid": "d89cde4edf7ce2f09555622888d1b86f2d5f2015", "url": "https://github.com/apache/hudi/commit/d89cde4edf7ce2f09555622888d1b86f2d5f2015", "message": "[HUDI-1357] Added a check to ensure no records are lost during updates.", "committedDate": "2020-11-18T22:19:29Z", "type": "forcePushed"}, {"oid": "c8f05c953beff33ac0dd174dee3edd52e2c37caa", "url": "https://github.com/apache/hudi/commit/c8f05c953beff33ac0dd174dee3edd52e2c37caa", "message": "[HUDI-1357] Added a check to ensure no records are lost during updates.", "committedDate": "2020-11-24T12:54:00Z", "type": "commit"}, {"oid": "c8f05c953beff33ac0dd174dee3edd52e2c37caa", "url": "https://github.com/apache/hudi/commit/c8f05c953beff33ac0dd174dee3edd52e2c37caa", "message": "[HUDI-1357] Added a check to ensure no records are lost during updates.", "committedDate": "2020-11-24T12:54:00Z", "type": "forcePushed"}]}