{"pr_number": 2319, "pr_title": "[MINOR] Improve code readability by passing in the fileComparisonsRDD in bloom index", "pr_createdAt": "2020-12-10T03:40:28Z", "pr_url": "https://github.com/apache/hudi/pull/2319", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE2NjUzOQ==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540166539", "bodyText": "@shenh062326 FYI, related to your Tuple2 refactoring PR \ud83d\ude09 .", "author": "garyli1019", "createdAt": "2020-12-10T13:26:25Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java", "diffHunk": "@@ -252,11 +252,9 @@ public boolean isImplicitWithStorage() {\n    * Make sure the parallelism is atleast the groupby parallelism for tagging location\n    */\n   JavaPairRDD<HoodieKey, HoodieRecordLocation> findMatchingFilesForRecordKeys(\n-      final Map<String, List<BloomIndexFileInfo>> partitionToFileIndexInfo,\n-      JavaPairRDD<String, String> partitionRecordKeyPairRDD, int shuffleParallelism, HoodieTable hoodieTable,\n+      JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD,", "originalCommit": "0c991a84ad90fcb7226ee60a0fa2c89d6ffa4f17", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDY2MzQxOA==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540663418", "bodyText": "I am removing the scala dependency from hudl-client-common, it seems no relationship to with this PR, since it depends on scala.Tuple2 in hudi-spark-client.", "author": "shenh062326", "createdAt": "2020-12-11T03:27:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDE2NjUzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "861fbe0d0fd396b5caaf81df510952103ba5070a", "chunk": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\nindex ec5884d23..1b4592b37 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\n\n@@ -253,7 +253,8 @@ public class SparkHoodieBloomIndex<T extends HoodieRecordPayload> extends SparkH\n    */\n   JavaPairRDD<HoodieKey, HoodieRecordLocation> findMatchingFilesForRecordKeys(\n       JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD,\n-      int shuffleParallelism, HoodieTable hoodieTable,\n+      int shuffleParallelism,\n+\t  HoodieTable hoodieTable,\n       Map<String, Long> fileGroupToComparisons) {\n \n     if (config.useBloomIndexBucketizedChecking()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNDMzOQ==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540224339", "bodyText": "Maybe we can move fileGroupToComparisons  into this line or break the hoodieTable  to the next line. It would be better?", "author": "yanghua", "createdAt": "2020-12-10T14:44:02Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java", "diffHunk": "@@ -252,11 +252,9 @@ public boolean isImplicitWithStorage() {\n    * Make sure the parallelism is atleast the groupby parallelism for tagging location\n    */\n   JavaPairRDD<HoodieKey, HoodieRecordLocation> findMatchingFilesForRecordKeys(\n-      final Map<String, List<BloomIndexFileInfo>> partitionToFileIndexInfo,\n-      JavaPairRDD<String, String> partitionRecordKeyPairRDD, int shuffleParallelism, HoodieTable hoodieTable,\n+      JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD,\n+      int shuffleParallelism, HoodieTable hoodieTable,", "originalCommit": "0c991a84ad90fcb7226ee60a0fa2c89d6ffa4f17", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDY0NDA3NQ==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540644075", "bodyText": "Thanks, agree ~", "author": "danny0405", "createdAt": "2020-12-11T02:29:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDIyNDMzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "861fbe0d0fd396b5caaf81df510952103ba5070a", "chunk": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\nindex ec5884d23..1b4592b37 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\n\n@@ -253,7 +253,8 @@ public class SparkHoodieBloomIndex<T extends HoodieRecordPayload> extends SparkH\n    */\n   JavaPairRDD<HoodieKey, HoodieRecordLocation> findMatchingFilesForRecordKeys(\n       JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD,\n-      int shuffleParallelism, HoodieTable hoodieTable,\n+      int shuffleParallelism,\n+\t  HoodieTable hoodieTable,\n       Map<String, Long> fileGroupToComparisons) {\n \n     if (config.useBloomIndexBucketizedChecking()) {\n"}}, {"oid": "861fbe0d0fd396b5caaf81df510952103ba5070a", "url": "https://github.com/apache/hudi/commit/861fbe0d0fd396b5caaf81df510952103ba5070a", "message": "[MINOR] Improve to only compute fileComparisonsRDD once when 'hoodie.bloom.index.prune.by.ranges' is set to true\n\nThe option 'hoodie.bloom.index.prune.by.ranges' is default true, so it\nexpects to be an improvement.", "committedDate": "2020-12-11T02:45:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODEwMg==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540738102", "bodyText": "nit: wondering how checkstyle is happy with the indentation here. :)", "author": "vinothchandar", "createdAt": "2020-12-11T07:16:50Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java", "diffHunk": "@@ -252,11 +252,10 @@ public boolean isImplicitWithStorage() {\n    * Make sure the parallelism is atleast the groupby parallelism for tagging location\n    */\n   JavaPairRDD<HoodieKey, HoodieRecordLocation> findMatchingFilesForRecordKeys(\n-      final Map<String, List<BloomIndexFileInfo>> partitionToFileIndexInfo,\n-      JavaPairRDD<String, String> partitionRecordKeyPairRDD, int shuffleParallelism, HoodieTable hoodieTable,\n+      JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD,\n+      int shuffleParallelism,\n+\t  HoodieTable hoodieTable,", "originalCommit": "861fbe0d0fd396b5caaf81df510952103ba5070a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1MTQzMw==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540751433", "bodyText": "Thanks, i just notice that Hoodie use the whitespace for indentation.", "author": "danny0405", "createdAt": "2020-12-11T07:48:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODEwMg=="}], "type": "inlineReview", "revised_code": {"commit": "622c3c7ce63a2536e6fd6274dcf0c2e552015d32", "chunk": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\nindex 1b4592b37..7316043eb 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java\n\n@@ -254,7 +254,7 @@ public class SparkHoodieBloomIndex<T extends HoodieRecordPayload> extends SparkH\n   JavaPairRDD<HoodieKey, HoodieRecordLocation> findMatchingFilesForRecordKeys(\n       JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD,\n       int shuffleParallelism,\n-\t  HoodieTable hoodieTable,\n+      HoodieTable hoodieTable,\n       Map<String, Long> fileGroupToComparisons) {\n \n     if (config.useBloomIndexBucketizedChecking()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODg1NA==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540738854", "bodyText": "do you actually see from the Spark UI that its not computed twice? I ask because, fileComparisonsRDD is not cached and thus even though this is declared only once, during runtime, Spark will lazily recompute fileComparisonsRDD once for each method that uses it.", "author": "vinothchandar", "createdAt": "2020-12-11T07:18:45Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/index/bloom/SparkHoodieBloomIndex.java", "diffHunk": "@@ -122,13 +122,15 @@ public SparkHoodieBloomIndex(HoodieWriteConfig config) {\n \n     // Step 3: Obtain a RDD, for each incoming record, that already exists, with the file id,\n     // that contains it.\n+    JavaRDD<Tuple2<String, HoodieKey>> fileComparisonsRDD =", "originalCommit": "861fbe0d0fd396b5caaf81df510952103ba5070a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc1MTE1OQ==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540751159", "bodyText": "I didn't check the Spark UI yet, just a simple analyze the process of data writing. For each batch of records to write, the SparkHoodieBloomIndex.lookupIndex was expected to be invoked once so the fileComparisonsRDD should only be evaluated only once, is there other invocation for SparkHoodieBloomIndex.lookupIndex ? Maybe i missed something.", "author": "danny0405", "createdAt": "2020-12-11T07:47:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODg1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDc2NzMyMA==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540767320", "bodyText": "So Spark does lazy evaluation of an RDD. If the RDD is not persisted to disk/cache, it simply recomputes it. In this case, fileComparisonsRDD would be recomputed twice during runtime. the method explodeRecordRDDWithFileComparisons() will only be called once, but it does nothing in practice except \"define\" the RDD it returns.\nIn contrast, if you notice this line of code at the start of tagLocation\n// Step 0: cache the input record RDD\n    if (config.getBloomIndexUseCaching()) {\n      recordRDD.persist(SparkMemoryUtils.getBloomIndexInputStorageLevel(config.getProps()));\n    }\n\nThis caches the incoming recordRDD and thus however many times this RDD is used in the indexing DAG, it will not go to the previous stage. if we did not have the .persist() in here, then everytime an RDD derived off this recordRDD is needed for a Spark action, it will keep reading from source and compute the recordRDD again.\nApologies, if you knew all this already. :) and I am failing to see how this wont happen. but at-least you get my concern with this explanation.", "author": "vinothchandar", "createdAt": "2020-12-11T08:19:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODg1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDgwODIyNA==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r540808224", "bodyText": "Thanks for the explanation, the recordRDD may be persisted, but the computation in explodeRecordRDDWithFileComparisons still need to do 2 times, right ? Sorry, i'm not that familiar with the RDD thing.", "author": "danny0405", "createdAt": "2020-12-11T09:28:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODg1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTA1OTc2Ng==", "url": "https://github.com/apache/hudi/pull/2319#discussion_r541059766", "bodyText": "Correct. That's what i think will happen", "author": "vinothchandar", "createdAt": "2020-12-11T16:13:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDczODg1NA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "622c3c7ce63a2536e6fd6274dcf0c2e552015d32", "url": "https://github.com/apache/hudi/commit/622c3c7ce63a2536e6fd6274dcf0c2e552015d32", "message": "[MINOR] Improve to only compute fileComparisonsRDD once when 'hoodie.bloom.index.prune.by.ranges' is set to true\n\nThe option 'hoodie.bloom.index.prune.by.ranges' is default true, so it\nexpects to be an improvement.", "committedDate": "2020-12-11T07:52:34Z", "type": "commit"}, {"oid": "622c3c7ce63a2536e6fd6274dcf0c2e552015d32", "url": "https://github.com/apache/hudi/commit/622c3c7ce63a2536e6fd6274dcf0c2e552015d32", "message": "[MINOR] Improve to only compute fileComparisonsRDD once when 'hoodie.bloom.index.prune.by.ranges' is set to true\n\nThe option 'hoodie.bloom.index.prune.by.ranges' is default true, so it\nexpects to be an improvement.", "committedDate": "2020-12-11T07:52:34Z", "type": "forcePushed"}]}