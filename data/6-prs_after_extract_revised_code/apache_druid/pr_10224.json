{"pr_number": 10224, "pr_title": "Segment backed broadcast join IndexedTable", "pr_createdAt": "2020-07-29T20:43:31Z", "pr_url": "https://github.com/apache/druid/pull/10224", "timeline": [{"oid": "bad671b38e5015e7a3b5abe0be4cd0d898a3cb80", "url": "https://github.com/apache/druid/commit/bad671b38e5015e7a3b5abe0be4cd0d898a3cb80", "message": "Segment backed broadcast join IndexedTable", "committedDate": "2020-07-29T12:41:26Z", "type": "commit"}, {"oid": "4574c5f801d907dc10bab85e3006ab8e500db0b4", "url": "https://github.com/apache/druid/commit/4574c5f801d907dc10bab85e3006ab8e500db0b4", "message": "fix comments", "committedDate": "2020-07-29T20:39:11Z", "type": "commit"}, {"oid": "86717ea3d16c7b28c587311a5136c4deb8311efb", "url": "https://github.com/apache/druid/commit/86717ea3d16c7b28c587311a5136c4deb8311efb", "message": "fix tests", "committedDate": "2020-07-30T01:41:08Z", "type": "commit"}, {"oid": "77552c3d3b4939fb99766f15565698f051f0a899", "url": "https://github.com/apache/druid/commit/77552c3d3b4939fb99766f15565698f051f0a899", "message": "sharing is caring", "committedDate": "2020-07-30T01:50:51Z", "type": "commit"}, {"oid": "fa164df4ce2de3aab94328e74c56942625259f6a", "url": "https://github.com/apache/druid/commit/fa164df4ce2de3aab94328e74c56942625259f6a", "message": "fix test", "committedDate": "2020-07-30T07:40:12Z", "type": "commit"}, {"oid": "744c4a6631aa7d65b39e609056920d20baa31100", "url": "https://github.com/apache/druid/commit/744c4a6631aa7d65b39e609056920d20baa31100", "message": "i hope this doesnt fix it", "committedDate": "2020-07-30T10:11:40Z", "type": "commit"}, {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf", "url": "https://github.com/apache/druid/commit/6b4621a619b369a05cd828404afcbe9cc36ebaaf", "message": "filter by schema to maybe fix test", "committedDate": "2020-07-30T18:19:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNDkxNw==", "url": "https://github.com/apache/druid/pull/10224#discussion_r463924917", "bodyText": "Should these be debug logs?", "author": "jihoonson", "createdAt": "2020-08-01T05:21:27Z", "path": "processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join.table;\n+\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.guava.Sequences;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.segment.BaseObjectColumnValueSelector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.DimensionHandlerUtils;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexSegment;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.SimpleAscendingOffset;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.column.RowSignature;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.Filters;\n+import org.joda.time.chrono.ISOChronology;\n+\n+import javax.annotation.Nullable;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class BroadcastSegmentIndexedTable implements IndexedTable\n+{\n+  private static final Logger LOG = new Logger(BroadcastSegmentIndexedTable.class);\n+\n+  private final QueryableIndexSegment segment;\n+  private final QueryableIndexStorageAdapter adapter;\n+  private final QueryableIndex queryableIndex;\n+  private final Set<String> keyColumns;\n+  private final RowSignature rowSignature;\n+  private final String version;\n+  private final List<Map<Object, IntList>> keyColumnsIndex;\n+\n+  public BroadcastSegmentIndexedTable(final QueryableIndexSegment theSegment, final Set<String> keyColumns, final String version)\n+  {\n+    this.keyColumns = keyColumns;\n+    this.version = version;\n+    this.segment = theSegment;\n+    this.adapter = (QueryableIndexStorageAdapter) segment.asStorageAdapter();\n+    this.queryableIndex = segment.asQueryableIndex();\n+\n+    RowSignature.Builder sigBuilder = RowSignature.builder();\n+    sigBuilder.add(ColumnHolder.TIME_COLUMN_NAME, ValueType.LONG);\n+    for (String column : queryableIndex.getColumnNames()) {\n+      sigBuilder.add(column, adapter.getColumnCapabilities(column).getType());\n+    }\n+    this.rowSignature = sigBuilder.build();\n+\n+    // initialize keycolumn index maps\n+    this.keyColumnsIndex = new ArrayList<>(rowSignature.size());\n+    final List<String> keyColumnNames = new ArrayList<>(keyColumns.size());\n+    for (int i = 0; i < rowSignature.size(); i++) {\n+      final Map<Object, IntList> m;\n+      final String columnName = rowSignature.getColumnName(i);\n+      if (keyColumns.contains(columnName)) {\n+        m = new HashMap<>();\n+        keyColumnNames.add(columnName);\n+      } else {\n+        m = null;\n+      }\n+      keyColumnsIndex.add(m);\n+    }\n+\n+    // sort of like the dump segment tool, but build key column indexes when reading the segment\n+    final Sequence<Cursor> cursors = adapter.makeCursors(\n+        Filters.toFilter(null),\n+        queryableIndex.getDataInterval().withChronology(ISOChronology.getInstanceUTC()),\n+        VirtualColumns.EMPTY,\n+        Granularities.ALL,\n+        false,\n+        null\n+    );\n+\n+    final Sequence<Integer> sequence = Sequences.map(\n+        cursors,\n+        cursor -> {\n+          int rowNumber = 0;\n+          ColumnSelectorFactory columnSelectorFactory = cursor.getColumnSelectorFactory();\n+\n+          // this should really be optimized to use dimension selectors where possible to populate indexes from bitmap\n+          // indexes, but, an optimization for another day\n+          final List<BaseObjectColumnValueSelector> selectors = keyColumnNames\n+              .stream()\n+              .map(columnSelectorFactory::makeColumnValueSelector)\n+              .collect(Collectors.toList());\n+\n+          while (!cursor.isDone()) {\n+            for (int keyColumnSelectorIndex = 0; keyColumnSelectorIndex < selectors.size(); keyColumnSelectorIndex++) {\n+              final String keyColumnName = keyColumnNames.get(keyColumnSelectorIndex);\n+              final int columnPosition = rowSignature.indexOf(keyColumnName);\n+              final Map<Object, IntList> keyColumnValueIndex = keyColumnsIndex.get(columnPosition);\n+\n+              final Object value = selectors.get(keyColumnSelectorIndex).getObject();\n+              final ValueType keyType = rowSignature.getColumnType(keyColumnName)\n+                                                    .orElse(IndexedTableJoinMatcher.DEFAULT_KEY_TYPE);\n+              // is this actually necessary or is value already cool? (RowBasedIndexedTable cargo cult represent)\n+              final Object key = DimensionHandlerUtils.convertObjectToType(value, keyType);\n+\n+              if (key != null) {\n+                final IntList array = keyColumnValueIndex.computeIfAbsent(key, k -> new IntArrayList());\n+                array.add(rowNumber);\n+              }\n+            }\n+\n+            if (rowNumber % 100_000 == 0) {\n+              if (rowNumber == 0) {\n+                LOG.info(\"Indexed first row for table %s\", theSegment.getId());\n+              } else {\n+                LOG.info(\"Indexed row %s for table %s\", rowNumber, theSegment.getId());", "originalCommit": "6b4621a619b369a05cd828404afcbe9cc36ebaaf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2724bbe2f90261375c4429867125e3cacef3be67", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java b/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java\nindex 6ce3ec4117..eeb8ba6093 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java\n\n@@ -19,6 +19,7 @@\n \n package org.apache.druid.segment.join.table;\n \n+import com.google.common.base.Preconditions;\n import it.unimi.dsi.fastutil.ints.IntArrayList;\n import it.unimi.dsi.fastutil.ints.IntList;\n import org.apache.druid.java.util.common.IAE;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNjE5OQ==", "url": "https://github.com/apache/druid/pull/10224#discussion_r463926199", "bodyText": "Unused variable.", "author": "jihoonson", "createdAt": "2020-08-01T05:38:56Z", "path": "server/src/main/java/org/apache/druid/server/SegmentManager.java", "diffHunk": "@@ -155,13 +172,44 @@ public boolean isSegmentCached(final DataSegment segment)\n    */\n   public Optional<VersionedIntervalTimeline<String, ReferenceCountingSegment>> getTimeline(DataSourceAnalysis analysis)\n   {\n-    final TableDataSource tableDataSource =\n-        analysis.getBaseTableDataSource()\n-                .orElseThrow(() -> new ISE(\"Cannot handle datasource: %s\", analysis.getDataSource()));\n-\n+    final TableDataSource tableDataSource = getTableDataSource(analysis);\n     return Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTimeline);\n   }\n \n+  public List<ReferenceCountingIndexedTable> getIndexedTables(\n+      DataSourceAnalysis analysis,\n+      JoinConditionAnalysis joinCondition", "originalCommit": "6b4621a619b369a05cd828404afcbe9cc36ebaaf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2724bbe2f90261375c4429867125e3cacef3be67", "chunk": "diff --git a/server/src/main/java/org/apache/druid/server/SegmentManager.java b/server/src/main/java/org/apache/druid/server/SegmentManager.java\nindex 9d2637fd40..c3eab1412d 100644\n--- a/server/src/main/java/org/apache/druid/server/SegmentManager.java\n+++ b/server/src/main/java/org/apache/druid/server/SegmentManager.java\n\n@@ -176,24 +173,24 @@ public class SegmentManager\n     return Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTimeline);\n   }\n \n-  public List<ReferenceCountingIndexedTable> getIndexedTables(\n-      DataSourceAnalysis analysis,\n-      JoinConditionAnalysis joinCondition\n-  )\n+  /**\n+   * Returns the collection of {@link IndexedTable} for the entire timeline (since join conditions do not currently\n+   * consider the queries intervals), if the timeline exists for each of its segments that are joinable.\n+   */\n+  public Optional<Stream<ReferenceCountingIndexedTable>> getIndexedTables(DataSourceAnalysis analysis)\n   {\n     return getTimeline(analysis).map(timeline -> {\n       // join doesn't currently consider intervals, so just consider all segments\n-      final Collection<ReferenceCountingSegment> segments =\n+      final Stream<ReferenceCountingSegment> segments =\n           timeline.lookup(Intervals.ETERNITY)\n                   .stream()\n-                  .flatMap(x -> StreamSupport.stream(x.getObject().payloads().spliterator(), false))\n-                  .collect(Collectors.toList());\n+                  .flatMap(x -> StreamSupport.stream(x.getObject().payloads().spliterator(), false));\n       final TableDataSource tableDataSource = getTableDataSource(analysis);\n       ConcurrentHashMap<SegmentId, ReferenceCountingIndexedTable> tables =\n           Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTablesLookup)\n                   .orElseThrow(() -> new ISE(\"Datasource %s does not have IndexedTables\", tableDataSource.getName()));\n-      return segments.stream().map(segment -> tables.get(segment.getId())).collect(Collectors.toList());\n-    }).orElseGet(() -> ImmutableList.of());\n+      return segments.map(segment -> tables.get(segment.getId())).filter(Objects::nonNull);\n+    });\n   }\n \n   public boolean hasIndexedTables(String dataSourceName)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNjc3Mw==", "url": "https://github.com/apache/druid/pull/10224#discussion_r463926773", "bodyText": "nit: you don't have to materialize segments here. Instead, you can call map on the stream directly in the below.", "author": "jihoonson", "createdAt": "2020-08-01T05:46:20Z", "path": "server/src/main/java/org/apache/druid/server/SegmentManager.java", "diffHunk": "@@ -155,13 +172,44 @@ public boolean isSegmentCached(final DataSegment segment)\n    */\n   public Optional<VersionedIntervalTimeline<String, ReferenceCountingSegment>> getTimeline(DataSourceAnalysis analysis)\n   {\n-    final TableDataSource tableDataSource =\n-        analysis.getBaseTableDataSource()\n-                .orElseThrow(() -> new ISE(\"Cannot handle datasource: %s\", analysis.getDataSource()));\n-\n+    final TableDataSource tableDataSource = getTableDataSource(analysis);\n     return Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTimeline);\n   }\n \n+  public List<ReferenceCountingIndexedTable> getIndexedTables(\n+      DataSourceAnalysis analysis,\n+      JoinConditionAnalysis joinCondition\n+  )\n+  {\n+    return getTimeline(analysis).map(timeline -> {\n+      // join doesn't currently consider intervals, so just consider all segments\n+      final Collection<ReferenceCountingSegment> segments =\n+          timeline.lookup(Intervals.ETERNITY)\n+                  .stream()\n+                  .flatMap(x -> StreamSupport.stream(x.getObject().payloads().spliterator(), false))\n+                  .collect(Collectors.toList());", "originalCommit": "6b4621a619b369a05cd828404afcbe9cc36ebaaf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2724bbe2f90261375c4429867125e3cacef3be67", "chunk": "diff --git a/server/src/main/java/org/apache/druid/server/SegmentManager.java b/server/src/main/java/org/apache/druid/server/SegmentManager.java\nindex 9d2637fd40..c3eab1412d 100644\n--- a/server/src/main/java/org/apache/druid/server/SegmentManager.java\n+++ b/server/src/main/java/org/apache/druid/server/SegmentManager.java\n\n@@ -176,24 +173,24 @@ public class SegmentManager\n     return Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTimeline);\n   }\n \n-  public List<ReferenceCountingIndexedTable> getIndexedTables(\n-      DataSourceAnalysis analysis,\n-      JoinConditionAnalysis joinCondition\n-  )\n+  /**\n+   * Returns the collection of {@link IndexedTable} for the entire timeline (since join conditions do not currently\n+   * consider the queries intervals), if the timeline exists for each of its segments that are joinable.\n+   */\n+  public Optional<Stream<ReferenceCountingIndexedTable>> getIndexedTables(DataSourceAnalysis analysis)\n   {\n     return getTimeline(analysis).map(timeline -> {\n       // join doesn't currently consider intervals, so just consider all segments\n-      final Collection<ReferenceCountingSegment> segments =\n+      final Stream<ReferenceCountingSegment> segments =\n           timeline.lookup(Intervals.ETERNITY)\n                   .stream()\n-                  .flatMap(x -> StreamSupport.stream(x.getObject().payloads().spliterator(), false))\n-                  .collect(Collectors.toList());\n+                  .flatMap(x -> StreamSupport.stream(x.getObject().payloads().spliterator(), false));\n       final TableDataSource tableDataSource = getTableDataSource(analysis);\n       ConcurrentHashMap<SegmentId, ReferenceCountingIndexedTable> tables =\n           Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTablesLookup)\n                   .orElseThrow(() -> new ISE(\"Datasource %s does not have IndexedTables\", tableDataSource.getName()));\n-      return segments.stream().map(segment -> tables.get(segment.getId())).collect(Collectors.toList());\n-    }).orElseGet(() -> ImmutableList.of());\n+      return segments.map(segment -> tables.get(segment.getId())).filter(Objects::nonNull);\n+    });\n   }\n \n   public boolean hasIndexedTables(String dataSourceName)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkzMTcwNA==", "url": "https://github.com/apache/druid/pull/10224#discussion_r463931704", "bodyText": "Seems unnecessary since this test extends InitializeNullHandlingTest.", "author": "jihoonson", "createdAt": "2020-08-01T06:52:05Z", "path": "processing/src/test/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTableTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join.table;\n+\n+import com.fasterxml.jackson.databind.InjectableValues;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+import org.apache.druid.jackson.SegmentizerModule;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.java.util.common.Intervals;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.math.expr.ExprMacroTable;\n+import org.apache.druid.query.expression.TestExprMacroTable;\n+import org.apache.druid.segment.BaseObjectColumnValueSelector;\n+import org.apache.druid.segment.IndexIO;\n+import org.apache.druid.segment.IndexMerger;\n+import org.apache.druid.segment.IndexMergerV9;\n+import org.apache.druid.segment.IndexSpec;\n+import org.apache.druid.segment.QueryableIndexSegment;\n+import org.apache.druid.segment.SimpleAscendingOffset;\n+import org.apache.druid.segment.TestIndex;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.incremental.IncrementalIndex;\n+import org.apache.druid.segment.loading.MMappedQueryableSegmentizerFactory;\n+import org.apache.druid.segment.loading.SegmentLoadingException;\n+import org.apache.druid.segment.loading.SegmentizerFactory;\n+import org.apache.druid.segment.writeout.OffHeapMemorySegmentWriteOutMediumFactory;\n+import org.apache.druid.testing.InitializedNullHandlingTest;\n+import org.apache.druid.timeline.DataSegment;\n+import org.joda.time.Interval;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+import org.junit.rules.TemporaryFolder;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Set;\n+\n+public class BroadcastSegmentIndexedTableTest extends InitializedNullHandlingTest\n+{\n+  private static final String STRING_COL_1 = \"market\";\n+  private static final String LONG_COL_1 = \"longNumericNull\";\n+  private static final String DOUBLE_COL_1 = \"doubleNumericNull\";\n+  private static final String FLOAT_COL_1 = \"floatNumericNull\";\n+  private static final String STRING_COL_2 = \"partial_null_column\";\n+  private static final String MULTI_VALUE_COLUMN = \"placementish\";\n+  private static final String DIM_NOT_EXISTS = \"DIM_NOT_EXISTS\";\n+  private static final String DATASOURCE = \"DATASOURCE\";\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+  @Rule\n+  public ExpectedException expectedException = ExpectedException.none();\n+\n+  private QueryableIndexSegment backingSegment;\n+  private BroadcastSegmentIndexedTable broadcastTable;\n+  private List<String> columnNames;\n+  private final Set<String> keyColumns = ImmutableSet.<String>builder()\n+                                                     .add(STRING_COL_1)\n+                                                     .add(STRING_COL_2)\n+                                                     .add(LONG_COL_1)\n+                                                     .add(DOUBLE_COL_1)\n+                                                     .add(FLOAT_COL_1)\n+                                                     .add(MULTI_VALUE_COLUMN)\n+                                                     .add(DIM_NOT_EXISTS)\n+                                                     .build();\n+\n+  @Before\n+  public void setup() throws IOException, SegmentLoadingException\n+  {\n+    NullHandling.initializeForTests();", "originalCommit": "6b4621a619b369a05cd828404afcbe9cc36ebaaf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2724bbe2f90261375c4429867125e3cacef3be67", "chunk": "diff --git a/processing/src/test/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTableTest.java b/processing/src/test/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTableTest.java\nindex 20d8371cc5..75a0a3580b 100644\n--- a/processing/src/test/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTableTest.java\n+++ b/processing/src/test/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTableTest.java\n\n@@ -166,8 +166,8 @@ public class BroadcastSegmentIndexedTableTest extends InitializedNullHandlingTes\n   @Test\n   public void testMultiValueStringKeyColumn()\n   {\n-    final Object[] vals = new Object[] {ImmutableList.of(\"a\", \"preferred\")};\n-    checkIndexAndReader(MULTI_VALUE_COLUMN, vals);\n+    final Object[] nonMatchingVals = new Object[] {ImmutableList.of(\"a\", \"preferred\")};\n+    checkIndexAndReader(MULTI_VALUE_COLUMN, new Object[0], nonMatchingVals);\n   }\n \n   @Test\n"}}, {"oid": "2724bbe2f90261375c4429867125e3cacef3be67", "url": "https://github.com/apache/druid/commit/2724bbe2f90261375c4429867125e3cacef3be67", "message": "changes", "committedDate": "2020-08-01T13:18:54Z", "type": "commit"}, {"oid": "188c760c11e1e5952d70c87f77e06e00b4cf9e4e", "url": "https://github.com/apache/druid/commit/188c760c11e1e5952d70c87f77e06e00b4cf9e4e", "message": "close join stuffs so it does not leak, allow table to directly make selector factory", "committedDate": "2020-08-04T13:03:32Z", "type": "commit"}, {"oid": "0349d184da095a91740c737a1e19dc8dee81fd2e", "url": "https://github.com/apache/druid/commit/0349d184da095a91740c737a1e19dc8dee81fd2e", "message": "oops", "committedDate": "2020-08-04T19:33:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYxOTUzMA==", "url": "https://github.com/apache/druid/pull/10224#discussion_r466619530", "bodyText": "Should this sanity check be retained?", "author": "jon-wei", "createdAt": "2020-08-06T18:54:10Z", "path": "processing/src/main/java/org/apache/druid/segment/join/table/RowBasedIndexedTable.java", "diffHunk": "@@ -69,10 +68,6 @@ public RowBasedIndexedTable(\n     this.keyColumns = keyColumns;\n     this.version = version;\n \n-    if (new HashSet<>(keyColumns).size() != keyColumns.size()) {", "originalCommit": "0349d184da095a91740c737a1e19dc8dee81fd2e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwOTA1MQ==", "url": "https://github.com/apache/druid/pull/10224#discussion_r466709051", "bodyText": "Ah, no, #9287 refactored the signature from using a List<String> to a Set<String>, which I think makes this check pointless.", "author": "clintropolis", "createdAt": "2020-08-06T21:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYxOTUzMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYyNTQ1Nw==", "url": "https://github.com/apache/druid/pull/10224#discussion_r466625457", "bodyText": "Can you explain why this is an error condition? From the comment at https://github.com/apache/druid/pull/10224/files#diff-51b09b44a8330d19728379390eef60a0R35 it sounds like multiple valid should be okay", "author": "jon-wei", "createdAt": "2020-08-06T19:05:10Z", "path": "processing/src/main/java/org/apache/druid/segment/join/MapJoinableFactory.java", "diffHunk": "@@ -19,49 +19,64 @@\n \n package org.apache.druid.segment.join;\n \n+import com.google.common.collect.HashMultimap;\n+import com.google.common.collect.SetMultimap;\n import com.google.inject.Inject;\n+import org.apache.druid.java.util.common.ISE;\n import org.apache.druid.query.DataSource;\n \n-import java.util.IdentityHashMap;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.Set;\n \n /**\n  * A {@link JoinableFactory} that delegates to the appropriate factory based on the type of the datasource.\n  *\n- * Datasources can register a factory via a DruidBinder\n+ * Datasources can register a factory via a DruidBinder. Any number of factories can be bound to a datasource, the\n+ * 'first' that matches will be returned to the caller, or none if no matches.\n  */\n public class MapJoinableFactory implements JoinableFactory\n {\n-  private final Map<Class<? extends DataSource>, JoinableFactory> joinableFactories;\n+  private final SetMultimap<Class<? extends DataSource>, JoinableFactory> joinableFactories;\n \n   @Inject\n-  public MapJoinableFactory(Map<Class<? extends DataSource>, JoinableFactory> joinableFactories)\n+  public MapJoinableFactory(\n+      Set<JoinableFactory> factories,\n+      Map<Class<? extends JoinableFactory>, Class<? extends DataSource>> factoryToDataSource\n+  )\n   {\n-    // Accesses to IdentityHashMap should be faster than to HashMap or ImmutableMap.\n-    // Class doesn't override Object.equals().\n-    this.joinableFactories = new IdentityHashMap<>(joinableFactories);\n+    this.joinableFactories = HashMultimap.create();\n+    factories.forEach(joinableFactory -> {\n+      joinableFactories.put(factoryToDataSource.get(joinableFactory.getClass()), joinableFactory);\n+    });\n   }\n \n   @Override\n   public boolean isDirectlyJoinable(DataSource dataSource)\n   {\n-    JoinableFactory factory = joinableFactories.get(dataSource.getClass());\n-    if (factory == null) {\n-      return false;\n-    } else {\n-      return factory.isDirectlyJoinable(dataSource);\n+    Set<JoinableFactory> factories = joinableFactories.get(dataSource.getClass());\n+    for (JoinableFactory factory : factories) {\n+      if (factory.isDirectlyJoinable(dataSource)) {\n+        return true;\n+      }\n     }\n+    return false;\n   }\n \n   @Override\n   public Optional<Joinable> build(DataSource dataSource, JoinConditionAnalysis condition)\n   {\n-    JoinableFactory factory = joinableFactories.get(dataSource.getClass());\n-    if (factory == null) {\n-      return Optional.empty();\n-    } else {\n-      return factory.build(dataSource, condition);\n+    Set<JoinableFactory> factories = joinableFactories.get(dataSource.getClass());\n+    Optional<Joinable> maybeJoinable = Optional.empty();\n+    for (JoinableFactory factory : factories) {\n+      Optional<Joinable> candidate = factory.build(dataSource, condition);\n+      if (candidate.isPresent()) {\n+        if (maybeJoinable.isPresent()) {\n+          throw new ISE(\"Multiple joinable factories are valid for table[%s]\", dataSource);", "originalCommit": "0349d184da095a91740c737a1e19dc8dee81fd2e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcxMTU4OA==", "url": "https://github.com/apache/druid/pull/10224#discussion_r466711588", "bodyText": "That comment isn't super clear, will add some more details. Multiple factories can be bound to the same class of datasource (because factory is an extension point), but not to the same exact datasource (because only 1 factory can create the joinable to use in the query). Having a mix of joinables in the same datasource is an invalid state, so this explodes to prevent undefined behavior instead of just using whichever is first in the set.", "author": "clintropolis", "createdAt": "2020-08-06T22:06:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYyNTQ1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/MapJoinableFactory.java b/processing/src/main/java/org/apache/druid/segment/join/MapJoinableFactory.java\nindex 9014033d7a..904433f8b4 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/MapJoinableFactory.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/MapJoinableFactory.java\n\n@@ -30,10 +30,11 @@ import java.util.Optional;\n import java.util.Set;\n \n /**\n- * A {@link JoinableFactory} that delegates to the appropriate factory based on the type of the datasource.\n+ * A {@link JoinableFactory} that delegates to the appropriate factory based on the datasource.\n  *\n- * Datasources can register a factory via a DruidBinder. Any number of factories can be bound to a datasource, the\n- * 'first' that matches will be returned to the caller, or none if no matches.\n+ * Any number of {@link JoinableFactory} may be associated to the same class of {@link DataSource}, but for a specific\n+ * datasource only a single {@link JoinableFactory} should be able to create a {@link Joinable} in the {@link #build}\n+ * method.\n  */\n public class MapJoinableFactory implements JoinableFactory\n {\n"}}, {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "url": "https://github.com/apache/druid/commit/3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "message": "update comment", "committedDate": "2020-08-07T08:32:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIzNzQxMA==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470237410", "bodyText": "super nit: would you add final for descending as well just to be consistent?", "author": "jihoonson", "createdAt": "2020-08-13T20:44:59Z", "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinEngine.java", "diffHunk": "@@ -51,14 +52,16 @@ private HashJoinEngine()\n    * not be queryable through the returned Cursor. This happens even if the right-hand joinable doesn't actually have a\n    * column with this name.\n    */\n-  public static Cursor makeJoinCursor(final Cursor leftCursor, final JoinableClause joinableClause)\n+  public static Cursor makeJoinCursor(final Cursor leftCursor, final JoinableClause joinableClause, boolean descending, final Closer closer)", "originalCommit": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI4NTkzMg==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470285932", "bodyText": "changed, also fixed formatting because line was too long", "author": "clintropolis", "createdAt": "2020-08-13T22:35:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIzNzQxMA=="}], "type": "inlineReview", "revised_code": {"commit": "dfcb58473bc88536de4c941b28c23d697f1a9494", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/HashJoinEngine.java b/processing/src/main/java/org/apache/druid/segment/join/HashJoinEngine.java\nindex 1fae0044b2..40582eee77 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/HashJoinEngine.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/HashJoinEngine.java\n\n@@ -52,7 +52,12 @@ public class HashJoinEngine\n    * not be queryable through the returned Cursor. This happens even if the right-hand joinable doesn't actually have a\n    * column with this name.\n    */\n-  public static Cursor makeJoinCursor(final Cursor leftCursor, final JoinableClause joinableClause, boolean descending, final Closer closer)\n+  public static Cursor makeJoinCursor(\n+      final Cursor leftCursor,\n+      final JoinableClause joinableClause,\n+      final boolean descending,\n+      final Closer closer\n+  )\n   {\n     final ColumnSelectorFactory leftColumnSelectorFactory = leftCursor.getColumnSelectorFactory();\n     final JoinMatcher joinMatcher = joinableClause.getJoinable()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NjQ1Nw==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470266457", "bodyText": "Can we use try-with-resources instead of CloseQuiently? It would be more aligned with #10247 as well.", "author": "jihoonson", "createdAt": "2020-08-13T21:44:34Z", "path": "processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java", "diffHunk": "@@ -97,41 +103,49 @@ public JoinMatcher makeJoinMatcher(\n     if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n       return Optional.empty();\n     }\n+    Closer closer = Closer.create();\n+    try {\n+      Set<String> correlatedValues = new HashSet<>();\n+      if (table.keyColumns().contains(searchColumnName)) {\n+        IndexedTable.Index index = table.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = table.columnReader(correlatedColumnPosition);\n+        closer.register(reader);\n+        IntList rowIndex = index.find(searchColumnValue);\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          String correlatedDimVal = Objects.toString(reader.read(rowNum), null);\n+          correlatedValues.add(correlatedDimVal);\n \n-    Set<String> correlatedValues = new HashSet<>();\n-    if (table.keyColumns().contains(searchColumnName)) {\n-      IndexedTable.Index index = table.columnIndex(filterColumnPosition);\n-      IndexedTable.Reader reader = table.columnReader(correlatedColumnPosition);\n-      IntList rowIndex = index.find(searchColumnValue);\n-      for (int i = 0; i < rowIndex.size(); i++) {\n-        int rowNum = rowIndex.getInt(i);\n-        String correlatedDimVal = Objects.toString(reader.read(rowNum), null);\n-        correlatedValues.add(correlatedDimVal);\n-\n-        if (correlatedValues.size() > maxCorrelationSetSize) {\n+          if (correlatedValues.size() > maxCorrelationSetSize) {\n+            return Optional.empty();\n+          }\n+        }\n+        return Optional.of(correlatedValues);\n+      } else {\n+        if (!allowNonKeyColumnSearch) {\n           return Optional.empty();\n         }\n-      }\n-      return Optional.of(correlatedValues);\n-    } else {\n-      if (!allowNonKeyColumnSearch) {\n-        return Optional.empty();\n-      }\n \n-      IndexedTable.Reader dimNameReader = table.columnReader(filterColumnPosition);\n-      IndexedTable.Reader correlatedColumnReader = table.columnReader(correlatedColumnPosition);\n-      for (int i = 0; i < table.numRows(); i++) {\n-        String dimVal = Objects.toString(dimNameReader.read(i), null);\n-        if (searchColumnValue.equals(dimVal)) {\n-          String correlatedDimVal = Objects.toString(correlatedColumnReader.read(i), null);\n-          correlatedValues.add(correlatedDimVal);\n-          if (correlatedValues.size() > maxCorrelationSetSize) {\n-            return Optional.empty();\n+        IndexedTable.Reader dimNameReader = table.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = table.columnReader(correlatedColumnPosition);\n+        closer.register(dimNameReader);\n+        closer.register(correlatedColumnReader);\n+        for (int i = 0; i < table.numRows(); i++) {\n+          String dimVal = Objects.toString(dimNameReader.read(i), null);\n+          if (searchColumnValue.equals(dimVal)) {\n+            String correlatedDimVal = Objects.toString(correlatedColumnReader.read(i), null);\n+            correlatedValues.add(correlatedDimVal);\n+            if (correlatedValues.size() > maxCorrelationSetSize) {\n+              return Optional.empty();\n+            }\n           }\n         }\n-      }\n \n-      return Optional.of(correlatedValues);\n+        return Optional.of(correlatedValues);\n+      }\n+    }\n+    finally {\n+      CloseQuietly.close(closer);", "originalCommit": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI4NTk4Ng==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470285986", "bodyText": "removed all usage of CloseQuietly in this PR", "author": "clintropolis", "createdAt": "2020-08-13T22:35:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NjQ1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "dfcb58473bc88536de4c941b28c23d697f1a9494", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java b/processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java\nindex a7512dccfe..4faaf549cd 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java\n\n@@ -103,8 +103,7 @@ public class IndexedTableJoinable implements Joinable\n     if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n       return Optional.empty();\n     }\n-    Closer closer = Closer.create();\n-    try {\n+    try (final Closer closer = Closer.create()) {\n       Set<String> correlatedValues = new HashSet<>();\n       if (table.keyColumns().contains(searchColumnName)) {\n         IndexedTable.Index index = table.columnIndex(filterColumnPosition);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NzE4Mg==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470267182", "bodyText": "Should it return Optional.empty() instead?", "author": "jihoonson", "createdAt": "2020-08-13T21:46:16Z", "path": "server/src/main/java/org/apache/druid/segment/join/BroadcastTableJoinableFactory.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.Iterators;\n+import com.google.inject.Inject;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.query.DataSource;\n+import org.apache.druid.query.GlobalTableDataSource;\n+import org.apache.druid.query.planning.DataSourceAnalysis;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.join.table.ReferenceCountingIndexedTable;\n+import org.apache.druid.server.SegmentManager;\n+\n+import java.util.Iterator;\n+import java.util.Optional;\n+\n+public class BroadcastTableJoinableFactory implements JoinableFactory\n+{\n+  private final SegmentManager segmentManager;\n+\n+  @Inject\n+  public BroadcastTableJoinableFactory(SegmentManager segmentManager)\n+  {\n+    this.segmentManager = segmentManager;\n+  }\n+\n+  @Override\n+  public boolean isDirectlyJoinable(DataSource dataSource)\n+  {\n+    GlobalTableDataSource broadcastDatasource = (GlobalTableDataSource) dataSource;\n+    return broadcastDatasource != null && segmentManager.hasIndexedTables(broadcastDatasource.getName());\n+  }\n+\n+  @Override\n+  public Optional<Joinable> build(\n+      DataSource dataSource,\n+      JoinConditionAnalysis condition\n+  )\n+  {\n+    GlobalTableDataSource broadcastDatasource = (GlobalTableDataSource) dataSource;\n+    if (condition.canHashJoin()) {\n+      DataSourceAnalysis analysis = DataSourceAnalysis.forDataSource(broadcastDatasource);\n+      return segmentManager.getIndexedTables(analysis).map(tables -> {\n+        Iterator<ReferenceCountingIndexedTable> tableIterator = tables.iterator();\n+        if (!tableIterator.hasNext()) {\n+          return null;", "originalCommit": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI4NTU2Ng==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470285566", "bodyText": "No, since this is inside a Optional.map, the function needs to return the thing that goes in the Optional", "author": "clintropolis", "createdAt": "2020-08-13T22:34:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NzE4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDMwMDgzMg==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470300832", "bodyText": "Oops, you are correct.", "author": "jihoonson", "createdAt": "2020-08-13T23:21:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NzE4Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2OTEzMg==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470269132", "bodyText": "Hmm, should we use Closer to close oldTable and oldQueryable so that both can be closed even when any potential errors is thrown?", "author": "jihoonson", "createdAt": "2020-08-13T21:50:59Z", "path": "server/src/main/java/org/apache/druid/server/SegmentManager.java", "diffHunk": "@@ -258,6 +316,11 @@ public void dropSegment(final DataSegment segment)\n \n               log.info(\"Attempting to close segment %s\", segment.getId());\n               oldQueryable.close();\n+\n+              final ReferenceCountingIndexedTable oldTable = dataSourceState.tablesLookup.remove(segment.getId());\n+              if (oldTable != null) {\n+                oldTable.close();", "originalCommit": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI4NTM4Nw==", "url": "https://github.com/apache/druid/pull/10224#discussion_r470285387", "bodyText": "changed to use Closer", "author": "clintropolis", "createdAt": "2020-08-13T22:33:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2OTEzMg=="}], "type": "inlineReview", "revised_code": {"commit": "dfcb58473bc88536de4c941b28c23d697f1a9494", "chunk": "diff --git a/server/src/main/java/org/apache/druid/server/SegmentManager.java b/server/src/main/java/org/apache/druid/server/SegmentManager.java\nindex c3eab1412d..3b3d891596 100644\n--- a/server/src/main/java/org/apache/druid/server/SegmentManager.java\n+++ b/server/src/main/java/org/apache/druid/server/SegmentManager.java\n\n@@ -312,14 +314,17 @@ public class SegmentManager\n             final ReferenceCountingSegment oldQueryable = (removed == null) ? null : removed.getObject();\n \n             if (oldQueryable != null) {\n-              dataSourceState.removeSegment(segment);\n-\n-              log.info(\"Attempting to close segment %s\", segment.getId());\n-              oldQueryable.close();\n-\n-              final ReferenceCountingIndexedTable oldTable = dataSourceState.tablesLookup.remove(segment.getId());\n-              if (oldTable != null) {\n-                oldTable.close();\n+              try (final Closer closer = Closer.create()) {\n+                dataSourceState.removeSegment(segment);\n+                closer.register(oldQueryable);\n+                log.info(\"Attempting to close segment %s\", segment.getId());\n+                final ReferenceCountingIndexedTable oldTable = dataSourceState.tablesLookup.remove(segment.getId());\n+                if (oldTable != null) {\n+                  closer.register(oldTable);\n+                }\n+              }\n+              catch (IOException e) {\n+                throw new RuntimeException(e);\n               }\n             } else {\n               log.info(\n"}}, {"oid": "dfcb58473bc88536de4c941b28c23d697f1a9494", "url": "https://github.com/apache/druid/commit/dfcb58473bc88536de4c941b28c23d697f1a9494", "message": "review stuffs", "committedDate": "2020-08-13T22:33:04Z", "type": "commit"}, {"oid": "680000a9965f5f82f4c15e3f56d7a396f2f43711", "url": "https://github.com/apache/druid/commit/680000a9965f5f82f4c15e3f56d7a396f2f43711", "message": "Merge remote-tracking branch 'upstream/master' into simple-broadcast-join-implementation", "committedDate": "2020-08-13T22:33:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTMxMzU3OA==", "url": "https://github.com/apache/druid/pull/10224#discussion_r471313578", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (column < 0 || rowSignature.getColumnName(0) == null) {\n          \n          \n            \n                if (column < 0 || rowSignature.getColumnName(column) == null) {", "author": "abhishekagarwal87", "createdAt": "2020-08-17T08:12:37Z", "path": "processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java", "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join.table;\n+\n+import com.google.common.base.Preconditions;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.guava.Sequences;\n+import org.apache.druid.java.util.common.io.Closer;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.segment.BaseObjectColumnValueSelector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexColumnSelectorFactory;\n+import org.apache.druid.segment.QueryableIndexSegment;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.SimpleAscendingOffset;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.BaseColumn;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.column.RowSignature;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.data.ReadableOffset;\n+import org.apache.druid.segment.filter.Filters;\n+import org.joda.time.chrono.ISOChronology;\n+\n+import javax.annotation.Nullable;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class BroadcastSegmentIndexedTable implements IndexedTable\n+{\n+  private static final Logger LOG = new Logger(BroadcastSegmentIndexedTable.class);\n+\n+  private final QueryableIndexSegment segment;\n+  private final QueryableIndexStorageAdapter adapter;\n+  private final QueryableIndex queryableIndex;\n+  private final Set<String> keyColumns;\n+  private final RowSignature rowSignature;\n+  private final String version;\n+  private final List<Map<Object, IntList>> keyColumnsIndex;\n+\n+  public BroadcastSegmentIndexedTable(final QueryableIndexSegment theSegment, final Set<String> keyColumns, final String version)\n+  {\n+    this.keyColumns = keyColumns;\n+    this.version = version;\n+    this.segment = Preconditions.checkNotNull(theSegment, \"Segment must not be null\");\n+    this.adapter = Preconditions.checkNotNull(\n+        (QueryableIndexStorageAdapter) segment.asStorageAdapter(),\n+        \"Segment[%s] must have a QueryableIndexStorageAdapter\",\n+        segment.getId()\n+    );\n+    this.queryableIndex = Preconditions.checkNotNull(\n+        segment.asQueryableIndex(),\n+        \"Segment[%s] must have a QueryableIndexSegment\",\n+        segment.getId()\n+    );\n+\n+    RowSignature.Builder sigBuilder = RowSignature.builder();\n+    sigBuilder.add(ColumnHolder.TIME_COLUMN_NAME, ValueType.LONG);\n+    for (String column : queryableIndex.getColumnNames()) {\n+      sigBuilder.add(column, adapter.getColumnCapabilities(column).getType());\n+    }\n+    this.rowSignature = sigBuilder.build();\n+\n+    // initialize keycolumn index maps\n+    this.keyColumnsIndex = new ArrayList<>(rowSignature.size());\n+    final List<String> keyColumnNames = new ArrayList<>(keyColumns.size());\n+    for (int i = 0; i < rowSignature.size(); i++) {\n+      final Map<Object, IntList> m;\n+      final String columnName = rowSignature.getColumnName(i);\n+      if (keyColumns.contains(columnName)) {\n+        m = new HashMap<>();\n+        keyColumnNames.add(columnName);\n+      } else {\n+        m = null;\n+      }\n+      keyColumnsIndex.add(m);\n+    }\n+\n+    // sort of like the dump segment tool, but build key column indexes when reading the segment\n+    final Sequence<Cursor> cursors = adapter.makeCursors(\n+        Filters.toFilter(null),\n+        queryableIndex.getDataInterval().withChronology(ISOChronology.getInstanceUTC()),\n+        VirtualColumns.EMPTY,\n+        Granularities.ALL,\n+        false,\n+        null\n+    );\n+\n+    final Sequence<Integer> sequence = Sequences.map(\n+        cursors,\n+        cursor -> {\n+          if (cursor == null) {\n+            return 0;\n+          }\n+          int rowNumber = 0;\n+          ColumnSelectorFactory columnSelectorFactory = cursor.getColumnSelectorFactory();\n+\n+          // this should really be optimized to use dimension selectors where possible to populate indexes from bitmap\n+          // indexes, but, an optimization for another day\n+          final List<BaseObjectColumnValueSelector> selectors = keyColumnNames\n+              .stream()\n+              .map(columnName -> {\n+                // multi-value dimensions are not currently supported\n+                if (adapter.getColumnCapabilities(columnName).hasMultipleValues().isMaybeTrue()) {\n+                  return NilColumnValueSelector.instance();\n+                }\n+                return columnSelectorFactory.makeColumnValueSelector(columnName);\n+              })\n+              .collect(Collectors.toList());\n+\n+          while (!cursor.isDone()) {\n+            for (int keyColumnSelectorIndex = 0; keyColumnSelectorIndex < selectors.size(); keyColumnSelectorIndex++) {\n+              final String keyColumnName = keyColumnNames.get(keyColumnSelectorIndex);\n+              final int columnPosition = rowSignature.indexOf(keyColumnName);\n+              final Map<Object, IntList> keyColumnValueIndex = keyColumnsIndex.get(columnPosition);\n+              final Object key = selectors.get(keyColumnSelectorIndex).getObject();\n+              if (key != null) {\n+                final IntList array = keyColumnValueIndex.computeIfAbsent(key, k -> new IntArrayList());\n+                array.add(rowNumber);\n+              }\n+            }\n+\n+            if (rowNumber % 100_000 == 0) {\n+              if (rowNumber == 0) {\n+                LOG.debug(\"Indexed first row for table %s\", theSegment.getId());\n+              } else {\n+                LOG.debug(\"Indexed row %s for table %s\", rowNumber, theSegment.getId());\n+              }\n+            }\n+            rowNumber++;\n+            cursor.advance();\n+          }\n+          return rowNumber;\n+        }\n+    );\n+\n+    Integer totalRows = sequence.accumulate(0, (accumulated, in) -> accumulated += in);\n+    LOG.info(\"Created BroadcastSegmentIndexedTable with %s rows.\", totalRows);\n+  }\n+\n+  @Override\n+  public String version()\n+  {\n+    return version;\n+  }\n+\n+  @Override\n+  public Set<String> keyColumns()\n+  {\n+    return keyColumns;\n+  }\n+\n+  @Override\n+  public RowSignature rowSignature()\n+  {\n+    return rowSignature;\n+  }\n+\n+  @Override\n+  public int numRows()\n+  {\n+    return adapter.getNumRows();\n+  }\n+\n+  @Override\n+  public Index columnIndex(int column)\n+  {\n+    return RowBasedIndexedTable.getKeyColumnIndex(column, keyColumnsIndex, rowSignature);\n+  }\n+\n+  @Override\n+  public Reader columnReader(int column)\n+  {\n+    if (column < 0 || rowSignature.getColumnName(0) == null) {", "originalCommit": "680000a9965f5f82f4c15e3f56d7a396f2f43711", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTc1Nzc5Mw==", "url": "https://github.com/apache/druid/pull/10224#discussion_r471757793", "bodyText": "oops, good catch, though it accidentally will throw the same index out of bounds exception a few lines later\n    final BaseColumn baseColumn = queryableIndex.getColumnHolder(rowSignature.getColumnName(column)).getColumn();\nHowever, this check isn't really a good check since it is inconsistent which exception will be thrown, so I've added a contains method to RowSignature that works with column position to ensure that the index is in range so the exception can be consistently be the IAE being thrown here.", "author": "clintropolis", "createdAt": "2020-08-17T20:30:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTMxMzU3OA=="}], "type": "inlineReview", "revised_code": {"commit": "230995f1845b2300e8bdb35a500cc38f0355fc17", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java b/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java\nindex dcdee16eed..113bf3d5a2 100644\n--- a/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java\n+++ b/processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java\n\n@@ -202,7 +202,7 @@ public class BroadcastSegmentIndexedTable implements IndexedTable\n   @Override\n   public Reader columnReader(int column)\n   {\n-    if (column < 0 || rowSignature.getColumnName(0) == null) {\n+    if (!rowSignature.contains(column)) {\n       throw new IAE(\"Column[%d] is not a valid column for segment[%s]\", column, segment.getId());\n     }\n     final SimpleAscendingOffset offset = new SimpleAscendingOffset(adapter.getNumRows());\n"}}, {"oid": "230995f1845b2300e8bdb35a500cc38f0355fc17", "url": "https://github.com/apache/druid/commit/230995f1845b2300e8bdb35a500cc38f0355fc17", "message": "better check", "committedDate": "2020-08-17T20:28:48Z", "type": "commit"}]}