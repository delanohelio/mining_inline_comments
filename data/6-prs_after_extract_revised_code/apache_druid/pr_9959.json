{"pr_number": 9959, "pr_title": "Fix Subquery could not be converted to groupBy query", "pr_createdAt": "2020-06-01T02:59:30Z", "pr_url": "https://github.com/apache/druid/pull/9959", "timeline": [{"oid": "c35242a3786adcbfbc90f1b22ef1017b3f3ca10c", "url": "https://github.com/apache/druid/commit/c35242a3786adcbfbc90f1b22ef1017b3f3ca10c", "message": "Fix join", "committedDate": "2020-05-29T11:52:01Z", "type": "commit"}, {"oid": "e9d549ab1c6895c3f3e4dd5af02021a75884c035", "url": "https://github.com/apache/druid/commit/e9d549ab1c6895c3f3e4dd5af02021a75884c035", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-05-31T15:06:42Z", "type": "commit"}, {"oid": "7fbffc2cb429431b12972a378751d5c31e06b6a7", "url": "https://github.com/apache/druid/commit/7fbffc2cb429431b12972a378751d5c31e06b6a7", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-01T02:45:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r433381288", "bodyText": "I think you diagnosed the bug right but the fix is a bit sketchy. If the Timeseries query accepts a DimensionSpec but then only uses it in the array signature, the following problems occur:\n\nThe input field, extractionFn, and decoration logic of the DimensionSpec are ignored.\nThe type might not actually be correct here; it will use the type from the DimensionSpec, but that might not match the actual type of the field, because the query engine isn't enforcing it.\nThe array signature should also match the maps returned from normal map-based responses, but this won't.\n\nI think the idea of a special parameter to the Timeseries query that makes the time column have a different name is a good idea, though. Maybe instead this would work:\n\nAdd an undocumented timeseries context parameter like timestampResultField that adds a new field containing the timestamp as a long, with the given name, to both the map and array responses.\nModify the SQL layer to generate this context parameter for timeseries queries when there is a time floor dimension.", "author": "gianm", "createdAt": "2020-06-01T17:31:15Z", "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java", "diffHunk": "@@ -404,11 +407,16 @@ public boolean isCacheable(TimeseriesQuery query, boolean willMergeRunners)\n   @Override\n   public RowSignature resultArraySignature(TimeseriesQuery query)\n   {\n-    return RowSignature.builder()\n-                       .addTimeColumn()\n-                       .addAggregators(query.getAggregatorSpecs())\n-                       .addPostAggregators(query.getPostAggregatorSpecs())\n-                       .build();\n+\n+    RowSignature.Builder rowSignatureBuilder = RowSignature.builder();\n+    if (query.getDimensionSpec() != null) {\n+      rowSignatureBuilder.addDimensions(Collections.singletonList(query.getDimensionSpec()));", "originalCommit": "7fbffc2cb429431b12972a378751d5c31e06b6a7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4NzYwOQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r433387609", "bodyText": "Thank you for the review. I think your suggestion with using a special parameter sounds good to me. Initially, I added dimensionSpec just to be similar to groupBy and TopN but you are right that we do not need dimensionSpec and it is confusing with how timeseries is using it compare to groupBy and TopN. All we need is a special field/parameter to know when we are doing time floor dimension.\nCan you explain a little bit about your first point with adds a new field containing the timestamp as a long, with the given name? What do you mean by the given name and do you mean the field containing the floor(timestamp) not the actual timestamp? Thanks!", "author": "maytasm", "createdAt": "2020-06-01T17:43:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU4MDUwNg==", "url": "https://github.com/apache/druid/pull/9959#discussion_r433580506", "bodyText": "What do you mean by the given name and do you mean the field containing the floor(timestamp) not the actual timestamp?\n\nBy \"the given name\" I meant the timestampResultField. (I was thinking you would do something like \"timestampResultField\": \"d0\".)\nIt should contain the floored timestamp, which at the point the query results are being returned, is the same as the timestamp in the response (it has already been floored).", "author": "gianm", "createdAt": "2020-06-02T02:00:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDMzNDIwNw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434334207", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T06:25:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA=="}], "type": "inlineReview", "revised_code": {"commit": "4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java b/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java\nindex 4e53109dca..05411c68f3 100644\n--- a/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java\n+++ b/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java\n\n@@ -409,10 +414,12 @@ public class TimeseriesQueryQueryToolChest extends QueryToolChest<Result<Timeser\n   {\n \n     RowSignature.Builder rowSignatureBuilder = RowSignature.builder();\n-    if (query.getDimensionSpec() != null) {\n-      rowSignatureBuilder.addDimensions(Collections.singletonList(query.getDimensionSpec()));\n-    } else {\n-      rowSignatureBuilder.addTimeColumn();\n+    rowSignatureBuilder.addTimeColumn();\n+    if (query.getContext() != null\n+        && query.getTimestampResultField() != null\n+        && query.getTimestampResultField().lhs != null\n+        && query.getTimestampResultField().rhs != null) {\n+      rowSignatureBuilder.add(query.getTimestampResultField().lhs, query.getTimestampResultField().rhs);\n     }\n     rowSignatureBuilder.addAggregators(query.getAggregatorSpecs());\n     rowSignatureBuilder.addPostAggregators(query.getPostAggregatorSpecs());\n"}}, {"oid": "4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "url": "https://github.com/apache/druid/commit/4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T04:47:20Z", "type": "commit"}, {"oid": "2b6fbd30a8272b3451e7fdc51fbbea1b8c2f3cac", "url": "https://github.com/apache/druid/commit/2b6fbd30a8272b3451e7fdc51fbbea1b8c2f3cac", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T05:20:33Z", "type": "commit"}, {"oid": "7af85ca9867df65962ffd9e24e86b7a2303a7bdc", "url": "https://github.com/apache/druid/commit/7af85ca9867df65962ffd9e24e86b7a2303a7bdc", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T06:25:09Z", "type": "commit"}, {"oid": "1b769953ce6a32b0998b7f30de386447bef51b2a", "url": "https://github.com/apache/druid/commit/1b769953ce6a32b0998b7f30de386447bef51b2a", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T07:09:42Z", "type": "commit"}, {"oid": "688878433a579efa34c61582ffa7e188fd2dbf2f", "url": "https://github.com/apache/druid/commit/688878433a579efa34c61582ffa7e188fd2dbf2f", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T07:43:14Z", "type": "commit"}, {"oid": "11d082761739f010652c188fcd0e15f94eb07e1c", "url": "https://github.com/apache/druid/commit/11d082761739f010652c188fcd0e15f94eb07e1c", "message": "Fix Subquery could not be converted to groupBy query", "committedDate": "2020-06-03T09:31:01Z", "type": "commit"}, {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "url": "https://github.com/apache/druid/commit/7c11456fe1a622c0d3202e0c0ed1675bc6220338", "message": "add tests", "committedDate": "2020-06-03T12:14:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1OTcyMw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434759723", "bodyText": "nit: there's an unmatched parenthesis here.", "author": "gianm", "createdAt": "2020-06-03T18:09:43Z", "path": "processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java", "diffHunk": "@@ -235,4 +235,11 @@ public void testTimeseriesWithFilterOnNonExistentDimension()\n     // Skip this test because the timeseries test expects a day that doesn't have a filter match to be filled in,\n     // but group by just doesn't return a value if the filter doesn't match.\n   }\n+\n+  @Override\n+  public void testTimeseriesWithTimestampResultFieldContext()\n+  {\n+    // Skip this test because the timeseries test expects an extra column to be created (map from the timestamp_floor", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgyMjAzOQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434822039", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T20:03:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1OTcyMw=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java b/processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java\nindex 785471ef9c..9e7b45a58b 100644\n--- a/processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java\n+++ b/processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java\n\n@@ -237,9 +237,16 @@ public class GroupByTimeseriesQueryRunnerTest extends TimeseriesQueryRunnerTest\n   }\n \n   @Override\n-  public void testTimeseriesWithTimestampResultFieldContext()\n+  public void testTimeseriesWithTimestampResultFieldContextForArrayResponse()\n   {\n     // Skip this test because the timeseries test expects an extra column to be created (map from the timestamp_floor\n-    // of the timestamp dimension but group by doesn't do this.\n+    // of the timestamp dimension) but group by doesn't do this.\n+  }\n+\n+  @Override\n+  public void testTimeseriesWithTimestampResultFieldContextForMapResponse()\n+  {\n+    // Skip this test because the timeseries test expects an extra column to be created (map from the timestamp_floor\n+    // of the timestamp dimension) but group by doesn't do this.\n   }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTIzNQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434761235", "bodyText": "\"testResultArraySignatureWithTimestampResultField\" would be a better name, because that's the feature we're testing from the TimeseriesQuery point of view (the fact that it's useful for SQL time floor groupings is more of a concern of the SQL layer).", "author": "gianm", "createdAt": "2020-06-03T18:12:32Z", "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java", "diffHunk": "@@ -388,6 +389,33 @@ public void testResultArraySignature()\n     );\n   }\n \n+  @Test\n+  public void testResultArraySignatureWithFloorTime()", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgyMjM2Mg==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434822362", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T20:04:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTIzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java b/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java\nindex d7a404aa7e..b7bc426f8f 100644\n--- a/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java\n+++ b/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java\n\n@@ -390,7 +390,7 @@ public class TimeseriesQueryQueryToolChestTest\n   }\n \n   @Test\n-  public void testResultArraySignatureWithFloorTime()\n+  public void testResultArraySignatureWithTimestampResultField()\n   {\n     final TimeseriesQuery query =\n         Druids.newTimeseriesQueryBuilder()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTMzNQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434761335", "bodyText": "\"testResultArraySignatureWithoutTimestampResultField\" would be a better name.", "author": "gianm", "createdAt": "2020-06-03T18:12:43Z", "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java", "diffHunk": "@@ -364,7 +365,7 @@ public void testResultLevelCacheKeyWithGrandTotal()\n   }\n \n   @Test\n-  public void testResultArraySignature()\n+  public void testResultArraySignatureWithoutFloorTime()", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDgyMjY4OQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434822689", "bodyText": "Done", "author": "maytasm", "createdAt": "2020-06-03T20:05:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTMzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java b/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java\nindex d7a404aa7e..b7bc426f8f 100644\n--- a/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java\n+++ b/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java\n\n@@ -365,7 +365,7 @@ public class TimeseriesQueryQueryToolChestTest\n   }\n \n   @Test\n-  public void testResultArraySignatureWithoutFloorTime()\n+  public void testResultArraySignatureWithoutTimestampResultField()\n   {\n     final TimeseriesQuery query =\n         Druids.newTimeseriesQueryBuilder()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2NDE4NQ==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434764185", "bodyText": "You should include a test that verifies behavior for the resultsAsArrays result type as well.", "author": "gianm", "createdAt": "2020-06-03T18:17:53Z", "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java", "diffHunk": "@@ -2471,6 +2472,123 @@ public void testTimeseriesWithBoundFilter1()\n     TestHelper.assertExpectedResults(expectedResults, results);\n   }\n \n+  @Test\n+  public void testTimeseriesWithTimestampResultFieldContext()", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MTkzMw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434841933", "bodyText": "Done. See testTimeseriesWithTimestampResultFieldContextForArrayResponse", "author": "maytasm", "createdAt": "2020-06-03T20:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2NDE4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java b/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java\nindex 1ec236b2bf..991554a998 100644\n--- a/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java\n+++ b/processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java\n\n@@ -2473,7 +2475,133 @@ public class TimeseriesQueryRunnerTest extends InitializedNullHandlingTest\n   }\n \n   @Test\n-  public void testTimeseriesWithTimestampResultFieldContext()\n+  public void testTimeseriesWithTimestampResultFieldContextForArrayResponse()\n+  {\n+    Granularity gran = Granularities.DAY;\n+    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n+                                  .dataSource(QueryRunnerTestHelper.DATA_SOURCE)\n+                                  .granularity(gran)\n+                                  .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)\n+                                  .aggregators(\n+                                      QueryRunnerTestHelper.ROWS_COUNT,\n+                                      QueryRunnerTestHelper.INDEX_DOUBLE_SUM,\n+                                      QueryRunnerTestHelper.QUALITY_UNIQUES\n+                                  )\n+                                  .postAggregators(QueryRunnerTestHelper.ADD_ROWS_INDEX_CONSTANT)\n+                                  .descending(descending)\n+                                  .context(ImmutableMap.of(\n+                                      TimeseriesQuery.CTX_TIMESTAMP_RESULT_FIELD, TIMESTAMP_RESULT_FIELD_NAME\n+                                  ))\n+                                  .build();\n+\n+    Assert.assertEquals(TIMESTAMP_RESULT_FIELD_NAME, query.getTimestampResultField());\n+\n+    QueryToolChest<Result<TimeseriesResultValue>, TimeseriesQuery> toolChest = new TimeseriesQueryQueryToolChest();\n+\n+    RowSignature rowSignature = toolChest.resultArraySignature(query);\n+    Assert.assertNotNull(rowSignature);\n+    List<String> columnNames = rowSignature.getColumnNames();\n+    Assert.assertNotNull(columnNames);\n+    Assert.assertEquals(6, columnNames.size());\n+    Assert.assertEquals(\"__time\", columnNames.get(0));\n+    Assert.assertEquals(TIMESTAMP_RESULT_FIELD_NAME, columnNames.get(1));\n+    Assert.assertEquals(\"rows\", columnNames.get(2));\n+    Assert.assertEquals(\"index\", columnNames.get(3));\n+    Assert.assertEquals(\"uniques\", columnNames.get(4));\n+    Assert.assertEquals(\"addRowsIndexConstant\", columnNames.get(5));\n+\n+    Sequence<Result<TimeseriesResultValue>> results = runner.run(QueryPlus.wrap(query));\n+    Sequence<Object[]> resultsAsArrays = toolChest.resultsAsArrays(query, results);\n+\n+    Assert.assertNotNull(resultsAsArrays);\n+\n+    final String[] expectedIndex = descending ?\n+                                   QueryRunnerTestHelper.EXPECTED_FULL_ON_INDEX_VALUES_DESC :\n+                                   QueryRunnerTestHelper.EXPECTED_FULL_ON_INDEX_VALUES;\n+\n+    final Long expectedLast = descending ?\n+                                  QueryRunnerTestHelper.EARLIEST.getMillis() :\n+                                  QueryRunnerTestHelper.LAST.getMillis();\n+\n+    int count = 0;\n+    Object[] lastResult = null;\n+    for (Object[] result : resultsAsArrays.toList()) {\n+      Long current = (Long) result[0];\n+      Assert.assertFalse(\n+          StringUtils.format(\"Timestamp[%s] > expectedLast[%s]\", current, expectedLast),\n+          descending ? current < expectedLast : current > expectedLast\n+      );\n+\n+      Assert.assertEquals(\n+          (Long) result[1],\n+          current,\n+          0\n+      );\n+\n+      Assert.assertEquals(\n+          QueryRunnerTestHelper.SKIPPED_DAY.getMillis() == current ? (Long) 0L : (Long) 13L,\n+          result[2]\n+      );\n+\n+      if (QueryRunnerTestHelper.SKIPPED_DAY.getMillis() != current) {\n+        Assert.assertEquals(\n+            Doubles.tryParse(expectedIndex[count]).doubleValue(),\n+            (Double) result[3],\n+            (Double) result[3] * 1e-6\n+        );\n+        Assert.assertEquals(\n+            (Double) result[4],\n+            9.0d,\n+            0.02\n+        );\n+        Assert.assertEquals(\n+            new Double(expectedIndex[count]) + 13L + 1L,\n+            (Double) result[5],\n+            (Double) result[5] * 1e-6\n+        );\n+      } else {\n+        if (NullHandling.replaceWithDefault()) {\n+          Assert.assertEquals(\n+              0.0D,\n+              (Double) result[3],\n+              (Double) result[3] * 1e-6\n+          );\n+          Assert.assertEquals(\n+              0.0D,\n+              (Double) result[4],\n+              0.02\n+          );\n+          Assert.assertEquals(\n+              new Double(expectedIndex[count]) + 1L,\n+              (Double) result[5],\n+              (Double) result[5] * 1e-6\n+          );\n+        } else {\n+          Assert.assertNull(\n+              result[3]\n+          );\n+          Assert.assertEquals(\n+              (Integer) result[4],\n+              0.0,\n+              0.02\n+          );\n+          Assert.assertNull(\n+              result[5]\n+          );\n+        }\n+      }\n+\n+      lastResult = result;\n+      ++count;\n+    }\n+\n+    Assert.assertEquals(expectedLast, lastResult[0]);\n+\n+\n+  }\n+\n+  @Test\n+  public void testTimeseriesWithTimestampResultFieldContextForMapResponse()\n   {\n     Granularity gran = Granularities.DAY;\n     TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MjM2MA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434772360", "bodyText": "I think we usually don't do import static like this, but if checkstyle was ok with it, then you can keep it.", "author": "gianm", "createdAt": "2020-06-03T18:32:04Z", "path": "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java", "diffHunk": "@@ -90,6 +94,8 @@\n import java.util.List;\n import java.util.Map;\n \n+import static org.apache.druid.sql.calcite.BaseCalciteQueryTest.TIMESERIES_CONTEXT_DEFAULT;", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MjgwNw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434842807", "bodyText": "It was unused. Removed", "author": "maytasm", "createdAt": "2020-06-03T20:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MjM2MA=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java b/extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java\nindex 5a0f7e50c3..6f4c8b6a9a 100644\n--- a/extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java\n+++ b/extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java\n\n@@ -94,8 +92,6 @@ import java.util.Collections;\n import java.util.List;\n import java.util.Map;\n \n-import static org.apache.druid.sql.calcite.BaseCalciteQueryTest.TIMESERIES_CONTEXT_DEFAULT;\n-\n public class HllSketchSqlAggregatorTest extends CalciteTestBase\n {\n   private static final String DATA_SOURCE = \"foo\";\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NDI0Mg==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434774242", "bodyText": "This comment doesn't make a lot of sense to me. How about something like this instead:\n\nIf \"timestampResultField\" is set, we must include a copy of the timestamp in the result. This is used by the SQL layer when it generates a Timeseries query for a group-by-time-floor SQL query. The SQL layer expects the result of the time-floor to have a specific name that is not going to be \"__time\".", "author": "gianm", "createdAt": "2020-06-03T18:35:19Z", "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java", "diffHunk": "@@ -447,13 +454,21 @@ public RowSignature resultArraySignature(TimeseriesQuery query)\n     return result -> {\n       final TimeseriesResultValue holder = result.getValue();\n       final Map<String, Object> values = new HashMap<>(holder.getBaseObject());\n-      if (calculatePostAggs && !query.getPostAggregatorSpecs().isEmpty()) {\n-        // put non finalized aggregators for calculating dependent post Aggregators\n-        for (AggregatorFactory agg : query.getAggregatorSpecs()) {\n-          values.put(agg.getName(), holder.getMetric(agg.getName()));\n+      if (calculatePostAggs) {\n+        if (!query.getPostAggregatorSpecs().isEmpty()) {\n+          // put non finalized aggregators for calculating dependent post Aggregators\n+          for (AggregatorFactory agg : query.getAggregatorSpecs()) {\n+            values.put(agg.getName(), holder.getMetric(agg.getName()));\n+          }\n+          for (PostAggregator postAgg : query.getPostAggregatorSpecs()) {\n+            values.put(postAgg.getName(), postAgg.compute(values));\n+          }\n         }\n-        for (PostAggregator postAgg : query.getPostAggregatorSpecs()) {\n-          values.put(postAgg.getName(), postAgg.compute(values));\n+        // Timeseries query has timestamp_floor expression on the timestamp dimension so we need to\n+        // map the results to another dimension using the name (String) supplied by context key", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MzMwNA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434843304", "bodyText": "Sounds good. Done", "author": "maytasm", "createdAt": "2020-06-03T20:46:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NDI0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java b/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java\nindex bd9e0740bf..2ce7e3b346 100644\n--- a/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java\n+++ b/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java\n\n@@ -464,8 +464,9 @@ public class TimeseriesQueryQueryToolChest extends QueryToolChest<Result<Timeser\n             values.put(postAgg.getName(), postAgg.compute(values));\n           }\n         }\n-        // Timeseries query has timestamp_floor expression on the timestamp dimension so we need to\n-        // map the results to another dimension using the name (String) supplied by context key\n+        // If \"timestampResultField\" is set, we must include a copy of the timestamp in the result.\n+        // This is used by the SQL layer when it generates a Timeseries query for a group-by-time-floor SQL query.\n+        // The SQL layer expects the result of the time-floor to have a specific name that is not going to be \"__time\".\n         if (StringUtils.isNotEmpty(query.getTimestampResultField()) && result.getTimestamp() != null) {\n           final DateTime timestamp = result.getTimestamp();\n           values.put(query.getTimestampResultField(), timestamp.getMillis());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NTA2NA==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434775064", "bodyText": "I think this could be clearer. How about:\n\n\"timestampResultField\" is an undocumented parameter used internally by the SQL layer. It is necessary because when the SQL layer generates a Timeseries query for a group-by-time-floor SQL query, it expects the result of the time-floor to have a specific name. That name is provided using this parameter.", "author": "gianm", "createdAt": "2020-06-03T18:36:50Z", "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java", "diffHunk": "@@ -50,6 +50,12 @@\n {\n   public static final String CTX_GRAND_TOTAL = \"grandTotal\";\n   public static final String SKIP_EMPTY_BUCKETS = \"skipEmptyBuckets\";\n+  // This context parameter is an undocumented parameter, used internally, to allow timeseries query with", "originalCommit": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg0MzY5Nw==", "url": "https://github.com/apache/druid/pull/9959#discussion_r434843697", "bodyText": "Sounds good. Done", "author": "maytasm", "createdAt": "2020-06-03T20:47:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NTA2NA=="}], "type": "inlineReview", "revised_code": {"commit": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java b/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java\nindex e075307b45..47ab8a8c67 100644\n--- a/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java\n+++ b/processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java\n\n@@ -50,10 +50,9 @@ public class TimeseriesQuery extends BaseQuery<Result<TimeseriesResultValue>>\n {\n   public static final String CTX_GRAND_TOTAL = \"grandTotal\";\n   public static final String SKIP_EMPTY_BUCKETS = \"skipEmptyBuckets\";\n-  // This context parameter is an undocumented parameter, used internally, to allow timeseries query with\n-  // timestamp_floor expression on the timestamp dimension to map the results to another dimension using the\n-  // name (String) supplied by this context key. The reason this is needed is because timeseries query\n-  // with timestamp_floor expression translates the timestamp_floor expression dimension into a 'granularity'.\n+  // \"timestampResultField\" is an undocumented parameter used internally by the SQL layer.\n+  // It is necessary because when the SQL layer generates a Timeseries query for a group-by-time-floor SQL query,\n+  // it expects the result of the time-floor to have a specific name. That name is provided using this parameter.\n   // TODO: We can remove this once https://github.com/apache/druid/issues/9974 is done.\n   public static final String CTX_TIMESTAMP_RESULT_FIELD = \"timestampResultField\";\n \n"}}, {"oid": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "url": "https://github.com/apache/druid/commit/eff405be76ceff3079cc342e5f8293b3ae2500e1", "message": "address comments", "committedDate": "2020-06-03T20:47:49Z", "type": "commit"}, {"oid": "865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589", "url": "https://github.com/apache/druid/commit/865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589", "message": "fix failing tests", "committedDate": "2020-06-03T22:16:43Z", "type": "commit"}]}