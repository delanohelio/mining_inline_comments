{"pr_number": 10053, "pr_title": "fix topn on string columns with non-sorted or non-unique dictionaries", "pr_createdAt": "2020-06-19T02:02:29Z", "pr_url": "https://github.com/apache/druid/pull/10053", "timeline": [{"oid": "3e5ef132b61a85f509bbce6445bd94e34f77743b", "url": "https://github.com/apache/druid/commit/3e5ef132b61a85f509bbce6445bd94e34f77743b", "message": "fix topn on string columns with non-sorted or non-unique dictionaries", "committedDate": "2020-06-19T01:56:04Z", "type": "commit"}, {"oid": "d2dfcc2b2d1514e7175e693dbc74592b83cf4d9e", "url": "https://github.com/apache/druid/commit/d2dfcc2b2d1514e7175e693dbc74592b83cf4d9e", "message": "fix metadata tests", "committedDate": "2020-06-19T02:22:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjYwNTQ4Ng==", "url": "https://github.com/apache/druid/pull/10053#discussion_r442605486", "bodyText": "Can you update the comments and also mention why we can/want to use HeapBasedTopNAlgorithm for each of those conditions (not sorted, not unique, etc)", "author": "maytasm", "createdAt": "2020-06-19T03:00:09Z", "path": "processing/src/main/java/org/apache/druid/query/topn/TopNQueryEngine.java", "diffHunk": "@@ -126,14 +126,20 @@ private TopNMapFn getMapFn(\n         // Once we have arbitrary dimension types following check should be replaced by checking\n         // that the column is of type long and single-value.\n         dimension.equals(ColumnHolder.TIME_COLUMN_NAME)\n-        ) {\n+    ) {\n       // A special TimeExtractionTopNAlgorithm is required, since DimExtractionTopNAlgorithm\n       // currently relies on the dimension cardinality to support lexicographic sorting\n       topNAlgorithm = new TimeExtractionTopNAlgorithm(adapter, query);\n     } else if (selector.isHasExtractionFn()) {\n       topNAlgorithm = new HeapBasedTopNAlgorithm(adapter, query);\n-    } else if (columnCapabilities == null || !(columnCapabilities.getType() == ValueType.STRING\n-                                               && columnCapabilities.isDictionaryEncoded())) {\n+    } else if (\n+        columnCapabilities == null ||\n+        !(columnCapabilities.getType() == ValueType.STRING &&\n+          columnCapabilities.isDictionaryEncoded() &&\n+          columnCapabilities.areDictionaryValuesSorted().isTrue() &&\n+          columnCapabilities.areDictionaryValuesUnique().isTrue()\n+        )\n+    ) {\n       // Use HeapBasedTopNAlgorithm for non-Strings and for non-dictionary-encoded Strings, and for things we don't know", "originalCommit": "d2dfcc2b2d1514e7175e693dbc74592b83cf4d9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "18c06a37a4975c410f80e447eeba35cecac4cb26", "chunk": "diff --git a/processing/src/main/java/org/apache/druid/query/topn/TopNQueryEngine.java b/processing/src/main/java/org/apache/druid/query/topn/TopNQueryEngine.java\nindex 804a093849..f1eab7fe26 100644\n--- a/processing/src/main/java/org/apache/druid/query/topn/TopNQueryEngine.java\n+++ b/processing/src/main/java/org/apache/druid/query/topn/TopNQueryEngine.java\n\n@@ -120,42 +120,34 @@ public class TopNQueryEngine\n \n \n     final TopNAlgorithm<?, ?> topNAlgorithm;\n-    if (\n-        selector.isHasExtractionFn() &&\n+    if (requiresHeapAlgorithm(selector, query, columnCapabilities)) {\n+      // heap based algorithm selection\n+      if (selector.isHasExtractionFn() && dimension.equals(ColumnHolder.TIME_COLUMN_NAME)) {\n         // TimeExtractionTopNAlgorithm can work on any single-value dimension of type long.\n-        // Once we have arbitrary dimension types following check should be replaced by checking\n-        // that the column is of type long and single-value.\n-        dimension.equals(ColumnHolder.TIME_COLUMN_NAME)\n-    ) {\n-      // A special TimeExtractionTopNAlgorithm is required, since DimExtractionTopNAlgorithm\n-      // currently relies on the dimension cardinality to support lexicographic sorting\n-      topNAlgorithm = new TimeExtractionTopNAlgorithm(adapter, query);\n-    } else if (selector.isHasExtractionFn()) {\n-      topNAlgorithm = new HeapBasedTopNAlgorithm(adapter, query);\n-    } else if (\n-        columnCapabilities == null ||\n-        !(columnCapabilities.getType() == ValueType.STRING &&\n-          columnCapabilities.isDictionaryEncoded() &&\n-          columnCapabilities.areDictionaryValuesSorted().isTrue() &&\n-          columnCapabilities.areDictionaryValuesUnique().isTrue()\n-        )\n-    ) {\n-      // Use HeapBasedTopNAlgorithm for non-Strings and for non-dictionary-encoded Strings, and for things we don't know\n-      // which can happen for 'inline' data sources when this is run on the broker\n-      topNAlgorithm = new HeapBasedTopNAlgorithm(adapter, query);\n-    } else if (query.getDimensionSpec().getOutputType() != ValueType.STRING) {\n-      // Use HeapBasedTopNAlgorithm when the dimension output type is a non-String. (It's like an extractionFn: there can be\n-      // a many-to-one mapping, since numeric types can't represent all possible values of other types.)\n-      topNAlgorithm = new HeapBasedTopNAlgorithm(adapter, query);\n-    } else if (selector.isAggregateAllMetrics()) {\n-      // sorted by dimension\n-      topNAlgorithm = new PooledTopNAlgorithm(adapter, query, bufferPool);\n-    } else if (selector.isAggregateTopNMetricFirst() || query.getContextBoolean(\"doAggregateTopNMetricFirst\", false)) {\n-      // high cardinality dimensions with larger result sets\n-      topNAlgorithm = new AggregateTopNMetricFirstAlgorithm(adapter, query, bufferPool);\n+        // We might be able to use this for any long column with an extraction function, that is\n+        //  ValueType.LONG.equals(columnCapabilities.getType())\n+        // but this needs investigation to ensure that it is an improvement over HeapBasedTopNAlgorithm\n+\n+        // A special TimeExtractionTopNAlgorithm is required since DimExtractionTopNAlgorithm\n+        // currently relies on the dimension cardinality to support lexicographic sorting\n+        topNAlgorithm = new TimeExtractionTopNAlgorithm(adapter, query);\n+      } else {\n+        topNAlgorithm = new HeapBasedTopNAlgorithm(adapter, query);\n+      }\n     } else {\n-      // anything else\n-      topNAlgorithm = new PooledTopNAlgorithm(adapter, query, bufferPool);\n+      // pool based algorithm selection\n+      if (selector.isAggregateAllMetrics()) {\n+        // if sorted by dimension we should aggregate all metrics in a single pass, use the regular pooled algorithm for\n+        // this\n+        topNAlgorithm = new PooledTopNAlgorithm(adapter, query, bufferPool);\n+      } else if (selector.isAggregateTopNMetricFirst() || query.getContextBoolean(\"doAggregateTopNMetricFirst\", false)) {\n+        // for high cardinality dimensions with larger result sets we aggregate with only the ordering aggregation to\n+        // compute the first 'n' values, and then for the rest of the metrics but for only the 'n' values\n+        topNAlgorithm = new AggregateTopNMetricFirstAlgorithm(adapter, query, bufferPool);\n+      } else {\n+        // anything else, use the regular pooled algorithm\n+        topNAlgorithm = new PooledTopNAlgorithm(adapter, query, bufferPool);\n+      }\n     }\n     if (queryMetrics != null) {\n       queryMetrics.algorithm(topNAlgorithm);\n"}}, {"oid": "18c06a37a4975c410f80e447eeba35cecac4cb26", "url": "https://github.com/apache/druid/commit/18c06a37a4975c410f80e447eeba35cecac4cb26", "message": "refactor, clarify comments and code, fix ci failures", "committedDate": "2020-06-19T06:12:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4ODk0Nw==", "url": "https://github.com/apache/druid/pull/10053#discussion_r442988947", "bodyText": "I think this method would be easier to read if it was called canUsePooledAlgorithm and the checks were all flipped. This is because IMO it makes sense to view the heap algorithm as the base case, and the pooled algorithm as a special case, meaning the logic should be \"can we do the special case\".", "author": "gianm", "createdAt": "2020-06-19T18:30:30Z", "path": "processing/src/main/java/org/apache/druid/query/topn/TopNQueryEngine.java", "diffHunk": "@@ -158,6 +156,40 @@ private TopNMapFn getMapFn(\n     return new TopNMapFn(query, topNAlgorithm);\n   }\n \n+  /**\n+   * {@link PooledTopNAlgorithm} (and {@link AggregateTopNMetricFirstAlgorithm} which utilizes the pooled\n+   * algorithm) are optimized off-heap algorithms for aggregating dictionary encoded string columns. These algorithms\n+   * rely on dictionary ids being unique so to aggregate on the dictionary ids directly and defer\n+   * {@link org.apache.druid.segment.DimensionSelector#lookupName(int)} until as late as possible in query processing.\n+   *\n+   * When these conditions are not true, we have an on-heap fall-back algorithm, the {@link HeapBasedTopNAlgorithm}\n+   * (and {@link TimeExtractionTopNAlgorithm} for a specialized form for long columns) which aggregates on values of\n+   * selectors.\n+   */\n+  private static boolean requiresHeapAlgorithm(", "originalCommit": "18c06a37a4975c410f80e447eeba35cecac4cb26", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA4NDgxOA==", "url": "https://github.com/apache/druid/pull/10053#discussion_r443084818", "bodyText": "Ha, that was the original name of this method and it was flipped, but I second guessed myself at the last minute and swapped when I noticed only 1 clause could return true. The javadocs still talk about the pooled algorithm first.\nStill, I agree and think canUsePooledAlgorithm is better, I'll switch it back \ud83d\udc4d", "author": "clintropolis", "createdAt": "2020-06-20T00:34:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4ODk0Nw=="}], "type": "inlineReview", "revised_code": null}]}