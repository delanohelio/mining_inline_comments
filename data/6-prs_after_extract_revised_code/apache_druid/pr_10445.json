{"pr_number": 10445, "pr_title": "Fix the task id creation in CompactionTask", "pr_createdAt": "2020-09-28T16:34:13Z", "pr_url": "https://github.com/apache/druid/pull/10445", "timeline": [{"oid": "dbda34be64b709f3c5dd55c30ac4fe78daf05907", "url": "https://github.com/apache/druid/commit/dbda34be64b709f3c5dd55c30ac4fe78daf05907", "message": "Fix the task id creation in CompactionTask", "committedDate": "2020-09-28T16:28:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzA5OTgzNw==", "url": "https://github.com/apache/druid/pull/10445#discussion_r497099837", "bodyText": "nit: Can you create a static method useRangePartitions that takes in tuningConfig as argument to avoid repeating code/logic", "author": "maytasm", "createdAt": "2020-09-29T22:35:36Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java", "diffHunk": "@@ -466,13 +466,20 @@ private void initializeSubTaskCleaner()\n     registerResourceCloserOnAbnormalExit(currentSubTaskHolder);\n   }\n \n-  private boolean isParallelMode()\n+  public static boolean isParallelMode(InputSource inputSource, @Nullable ParallelIndexTuningConfig tuningConfig)\n   {\n+    if (null == tuningConfig) {\n+      return false;\n+    }\n+    boolean useRangePartitions = tuningConfig.getGivenOrDefaultPartitionsSpec() instanceof SingleDimensionPartitionsSpec;", "originalCommit": "dbda34be64b709f3c5dd55c30ac4fe78daf05907", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java\nindex 5192b55c29..4a218a0b26 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java\n\n@@ -471,20 +471,20 @@ public class ParallelIndexSupervisorTask extends AbstractBatchIndexTask implemen\n     if (null == tuningConfig) {\n       return false;\n     }\n-    boolean useRangePartitions = tuningConfig.getGivenOrDefaultPartitionsSpec() instanceof SingleDimensionPartitionsSpec;\n+    boolean useRangePartitions = useRangePartitions(tuningConfig);\n     // Range partitioning is not implemented for runSequential() (but hash partitioning is)\n     int minRequiredNumConcurrentSubTasks = useRangePartitions ? 1 : 2;\n     return inputSource.isSplittable() && tuningConfig.getMaxNumConcurrentSubTasks() >= minRequiredNumConcurrentSubTasks;\n   }\n \n-  private boolean isParallelMode()\n+  private static boolean useRangePartitions(ParallelIndexTuningConfig tuningConfig)\n   {\n-    return isParallelMode(baseInputSource, ingestionSchema.getTuningConfig());\n+    return tuningConfig.getGivenOrDefaultPartitionsSpec() instanceof SingleDimensionPartitionsSpec;\n   }\n \n-  private boolean useRangePartitions()\n+  private boolean isParallelMode()\n   {\n-    return ingestionSchema.getTuningConfig().getGivenOrDefaultPartitionsSpec() instanceof SingleDimensionPartitionsSpec;\n+    return isParallelMode(baseInputSource, ingestionSchema.getTuningConfig());\n   }\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEwMDEyMQ==", "url": "https://github.com/apache/druid/pull/10445#discussion_r497100121", "bodyText": "nit: You can use ingestionSpec here (instead of repeating ingestionSpecs.get(i))", "author": "maytasm", "createdAt": "2020-09-29T22:36:30Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java", "diffHunk": "@@ -361,9 +362,13 @@ public TaskStatus runTask(TaskToolbox toolbox) throws Exception\n           // a new Appenderator on its own instead. As a result, they should use different sequence names to allocate\n           // new segmentIds properly. See IndexerSQLMetadataStorageCoordinator.allocatePendingSegments() for details.\n           // In this case, we use different fake IDs for each created index task.\n-          final String subtaskId = tuningConfig == null || tuningConfig.getMaxNumConcurrentSubTasks() == 1\n-                                   ? createIndexTaskSpecId(i)\n-                                   : getId();\n+          ParallelIndexIngestionSpec ingestionSpec = ingestionSpecs.get(i);\n+          InputSource inputSource = ingestionSpec.getIOConfig().getNonNullInputSource(\n+              ingestionSpec.getDataSchema().getParser()\n+          );\n+          final String subtaskId = ParallelIndexSupervisorTask.isParallelMode(inputSource, tuningConfig)\n+                                   ? getId()\n+                                   : createIndexTaskSpecId(i);\n           return newTask(subtaskId, ingestionSpecs.get(i));", "originalCommit": "dbda34be64b709f3c5dd55c30ac4fe78daf05907", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI4NTc4OA==", "url": "https://github.com/apache/druid/pull/10445#discussion_r497285788", "bodyText": "Done", "author": "abhishekagarwal87", "createdAt": "2020-09-30T07:05:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEwMDEyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java\nindex 15cc1d8af0..ba2502f197 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java\n\n@@ -369,7 +369,7 @@ public class CompactionTask extends AbstractBatchIndexTask\n           final String subtaskId = ParallelIndexSupervisorTask.isParallelMode(inputSource, tuningConfig)\n                                    ? getId()\n                                    : createIndexTaskSpecId(i);\n-          return newTask(subtaskId, ingestionSpecs.get(i));\n+          return newTask(subtaskId, ingestionSpec);\n         })\n         .collect(Collectors.toList());\n \n"}}, {"oid": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0", "url": "https://github.com/apache/druid/commit/7322fbee6dc13d6013408a34e20ee1dd0ccb83e0", "message": "review comments", "committedDate": "2020-09-30T07:04:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0MDk4Mg==", "url": "https://github.com/apache/druid/pull/10445#discussion_r497840982", "bodyText": "There's at least one typo in this comment", "author": "ccaominh", "createdAt": "2020-09-30T22:41:55Z", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java", "diffHunk": "@@ -219,6 +219,37 @@ public void testRunParallelWithRangePartitioning()\n     }\n   }\n \n+  @Test\n+  public void testRunParallelWithRangePartitioningWithSingleTask()\n+  {\n+    // Range partitioning is not supported with segment lock yet\n+    if (lockGranularity == LockGranularity.SEGMENT) {\n+      return;\n+    }\n+    runIndexTask(null, true);\n+\n+    final Builder builder = new Builder(\n+        DATA_SOURCE,\n+        getSegmentLoaderFactory(),\n+        RETRY_POLICY_FACTORY\n+    );\n+    final CompactionTask compactionTask = builder\n+        .inputSpec(new CompactionIntervalSpec(INTERVAL_TO_INDEX, null))\n+        .tuningConfig(newTuningConfig(new SingleDimensionPartitionsSpec(7, null, \"dim\", false), 1, true))\n+        .build();\n+\n+    final Set<DataSegment> compactedSegments = runTask(compactionTask);\n+    final CompactionState expectedState = new CompactionState(\n+        new SingleDimensionPartitionsSpec(7, null, \"dim\", false),\n+        compactionTask.getTuningConfig().getIndexSpec().asMap(getObjectMapper())\n+    );\n+    for (DataSegment segment : compactedSegments) {\n+      // Expecte compaction state to exist as store compaction state by default", "originalCommit": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b6056de793d119e4ab83daf7fc6c67030e2c61eb", "chunk": "diff --git a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java\nindex fc18f9a35c..7b7005bcbd 100644\n--- a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java\n+++ b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java\n\n@@ -213,7 +210,7 @@ public class CompactionTaskParallelRunTest extends AbstractParallelIndexSupervis\n         compactionTask.getTuningConfig().getIndexSpec().asMap(getObjectMapper())\n     );\n     for (DataSegment segment : compactedSegments) {\n-      // Expecte compaction state to exist as store compaction state by default\n+      // Expect compaction state to exist as store compaction state by default\n       Assert.assertSame(SingleDimensionShardSpec.class, segment.getShardSpec().getClass());\n       Assert.assertEquals(expectedState, segment.getLastCompactionState());\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0MDk5MQ==", "url": "https://github.com/apache/druid/pull/10445#discussion_r497840991", "bodyText": "JUnit has an Assume API, which could be a good fit here.", "author": "ccaominh", "createdAt": "2020-09-30T22:41:55Z", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java", "diffHunk": "@@ -219,6 +219,37 @@ public void testRunParallelWithRangePartitioning()\n     }\n   }\n \n+  @Test\n+  public void testRunParallelWithRangePartitioningWithSingleTask()\n+  {\n+    // Range partitioning is not supported with segment lock yet\n+    if (lockGranularity == LockGranularity.SEGMENT) {\n+      return;\n+    }", "originalCommit": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b6056de793d119e4ab83daf7fc6c67030e2c61eb", "chunk": "diff --git a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java\nindex fc18f9a35c..7b7005bcbd 100644\n--- a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java\n+++ b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java\n\n@@ -213,7 +210,7 @@ public class CompactionTaskParallelRunTest extends AbstractParallelIndexSupervis\n         compactionTask.getTuningConfig().getIndexSpec().asMap(getObjectMapper())\n     );\n     for (DataSegment segment : compactedSegments) {\n-      // Expecte compaction state to exist as store compaction state by default\n+      // Expect compaction state to exist as store compaction state by default\n       Assert.assertSame(SingleDimensionShardSpec.class, segment.getShardSpec().getClass());\n       Assert.assertEquals(expectedState, segment.getLastCompactionState());\n     }\n"}}, {"oid": "b6056de793d119e4ab83daf7fc6c67030e2c61eb", "url": "https://github.com/apache/druid/commit/b6056de793d119e4ab83daf7fc6c67030e2c61eb", "message": "Ignore test for range partitioning and segment lock", "committedDate": "2020-10-01T07:28:15Z", "type": "commit"}]}