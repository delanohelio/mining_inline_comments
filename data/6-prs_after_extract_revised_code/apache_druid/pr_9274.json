{"pr_number": 9274, "pr_title": "Refactoring some codes around ingestion", "pr_createdAt": "2020-01-28T21:57:39Z", "pr_url": "https://github.com/apache/druid/pull/9274", "timeline": [{"oid": "81b2884208abd1692573c838e2dd7023b892cf68", "url": "https://github.com/apache/druid/commit/81b2884208abd1692573c838e2dd7023b892cf68", "message": "Refactoring codes around ingestion:\n\n- Parallel index task and simple task now use the same segment allocator implementation. This is reusable for the future implementation as well.\n- Added PartitionAnalysis to store the analysis of the partitioning\n- Move some util methods to SegmentLockHelper and rename it to TaskLockHelper", "committedDate": "2020-01-28T21:54:03Z", "type": "commit"}, {"oid": "9a230a398d7ac88f7d2932495a3b1c0a389b0e2a", "url": "https://github.com/apache/druid/commit/9a230a398d7ac88f7d2932495a3b1c0a389b0e2a", "message": "fix build", "committedDate": "2020-01-28T22:21:32Z", "type": "commit"}, {"oid": "407c40273cdaa29a8af60fbf68f009710897c138", "url": "https://github.com/apache/druid/commit/407c40273cdaa29a8af60fbf68f009710897c138", "message": "fix SingleDimensionShardSpecFactory", "committedDate": "2020-01-28T23:13:31Z", "type": "commit"}, {"oid": "1713e791a4dfa3ae5bea40095e7bc4a35cf3cd47", "url": "https://github.com/apache/druid/commit/1713e791a4dfa3ae5bea40095e7bc4a35cf3cd47", "message": "optimize SingledimensionShardSpecFactory", "committedDate": "2020-01-28T23:17:28Z", "type": "commit"}, {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "url": "https://github.com/apache/druid/commit/b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "message": "fix test", "committedDate": "2020-01-28T23:37:43Z", "type": "commit"}, {"oid": "bf54438f363d097f685744463e63f663327053f0", "url": "https://github.com/apache/druid/commit/bf54438f363d097f685744463e63f663327053f0", "message": "shard spec builder", "committedDate": "2020-01-29T03:21:32Z", "type": "commit"}, {"oid": "afc16f14650bb6f335b4d2fecd1b44534a8e9172", "url": "https://github.com/apache/druid/commit/afc16f14650bb6f335b4d2fecd1b44534a8e9172", "message": "import order", "committedDate": "2020-01-29T16:22:17Z", "type": "commit"}, {"oid": "9062b6952f4ab156dddc7a033b6f3945df412067", "url": "https://github.com/apache/druid/commit/9062b6952f4ab156dddc7a033b6f3945df412067", "message": "shardSpecBuilder -> partialShardSpec", "committedDate": "2020-01-30T08:12:24Z", "type": "commit"}, {"oid": "58998ac74be63ce92e375d8d605daf35e69da637", "url": "https://github.com/apache/druid/commit/58998ac74be63ce92e375d8d605daf35e69da637", "message": "build -> complete", "committedDate": "2020-01-30T20:17:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNjQzMg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372136432", "bodyText": "Maybe change to {@link GranularitySpec#getSegmentGranularity}", "author": "ccaominh", "createdAt": "2020-01-29T00:40:37Z", "path": "core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexer.partitions;\n+\n+/**\n+ * In Druid, ingested data are primarily partitioned based on time range (GranularitySpec#getSegmentGranularity),", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDkzNQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924935", "bodyText": "GranularitySpec is in the server module and cannot be linked here.", "author": "jihoonson", "createdAt": "2020-02-03T05:15:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNjQzMg=="}], "type": "inlineReview", "revised_code": {"commit": "09f1776133ef6f437bb809a15e75b7bf0449aaef", "chunk": "diff --git a/core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java b/core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java\nindex a0dab9cb61..a8f1a1f853 100644\n--- a/core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java\n+++ b/core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java\n\n@@ -20,7 +20,7 @@\n package org.apache.druid.indexer.partitions;\n \n /**\n- * In Druid, ingested data are primarily partitioned based on time range (GranularitySpec#getSegmentGranularity),\n+ * In Druid, ingested data are primarily partitioned based on time range (@link GranularitySpec#getSegmentGranularity),\n  * and then secondly partitioned based on the given {@link PartitionsSpec}. This enum lists all supported types for the\n  * secondary partitioning.\n  */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372137230", "bodyText": "Perhaps rename to getNumBuckets()", "author": "ccaominh", "createdAt": "2020-01-29T00:43:54Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "diffHunk": "@@ -74,4 +74,9 @@ public PartitionBoundaries(String... partitions)\n   {\n     return delegate;\n   }\n+\n+  public int numBuckets()", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0MjQ5Mw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372142493", "bodyText": "Can also add the respective unit test to PartitionBoundariesTest", "author": "ccaominh", "createdAt": "2020-01-29T01:04:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk0OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924948", "bodyText": "Renamed and added a unit test. This class will be modified in my next PR. I'll add more tests especially for failure cases in it.", "author": "jihoonson", "createdAt": "2020-02-03T05:15:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA=="}], "type": "inlineReview", "revised_code": {"commit": "09f1776133ef6f437bb809a15e75b7bf0449aaef", "chunk": "diff --git a/core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java b/core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java\nindex 6c1293d743..7cd11bf72f 100644\n--- a/core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java\n+++ b/core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java\n\n@@ -75,8 +76,30 @@ public class PartitionBoundaries extends ForwardingList<String> implements List<\n     return delegate;\n   }\n \n-  public int numBuckets()\n+  public int getNumBuckets()\n   {\n     return delegate.size() - 1;\n   }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    if (!super.equals(o)) {\n+      return false;\n+    }\n+    PartitionBoundaries strings = (PartitionBoundaries) o;\n+    return Objects.equals(delegate, strings.delegate);\n+  }\n+\n+  @Override\n+  public int hashCode()\n+  {\n+    return Objects.hash(super.hashCode(), delegate);\n+  }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzgyMA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372137820", "bodyText": "Update the error message to say \"taskLockHelper\" instead of \"segmentLockHelper\"", "author": "ccaominh", "createdAt": "2020-01-29T00:46:19Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java", "diffHunk": "@@ -194,14 +179,9 @@ public int getPriority()\n     return getContextValue(Tasks.PRIORITY_KEY, Tasks.DEFAULT_BATCH_INDEX_TASK_PRIORITY);\n   }\n \n-  public boolean isUseSegmentLock()\n-  {\n-    return useSegmentLock;\n-  }\n-\n-  public SegmentLockHelper getSegmentLockHelper()\n+  public TaskLockHelper getTaskLockHelper()\n   {\n-    return segmentLockHelper;\n+    return Preconditions.checkNotNull(taskLockHelper, \"segmentLockHelper is not initialized yet\");", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk1OQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924959", "bodyText": "Good catch! Fixed.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzgyMA=="}], "type": "inlineReview", "revised_code": {"commit": "09f1776133ef6f437bb809a15e75b7bf0449aaef", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java\nindex 1c1e818b8b..a77fe40920 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java\n\n@@ -181,7 +181,7 @@ public abstract class AbstractBatchIndexTask extends AbstractTask\n \n   public TaskLockHelper getTaskLockHelper()\n   {\n-    return Preconditions.checkNotNull(taskLockHelper, \"segmentLockHelper is not initialized yet\");\n+    return Preconditions.checkNotNull(taskLockHelper, \"taskLockHelper is not initialized yet\");\n   }\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTIyNw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372145227", "bodyText": "PartitionBoundaries should probably override equals for this. Can use EqualsVerifier to add a unit test.", "author": "ccaominh", "createdAt": "2020-01-29T01:15:49Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;\n+    } else {\n+      partitionId = 0;\n+    }\n+    return create(objectMapper, partitionId);\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, int partitionId)\n+  {\n+    // TODO: numBuckets should be added to SingleDimensionShardSpec in a follow-up PR.\n+    return new SingleDimensionShardSpec(\n+        partitionDimension,\n+        partitionBoundaries.get(partitionId),\n+        partitionBoundaries.get(partitionId + 1),\n+        partitionId\n+    );\n+  }\n+\n+  @Override\n+  public Class<? extends ShardSpec> getShardSpecClass()\n+  {\n+    return SingleDimensionShardSpec.class;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n+    return Objects.equals(partitionDimension, that.partitionDimension) &&\n+           Objects.equals(partitionBoundaries, that.partitionBoundaries);", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk2Nw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924967", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTIyNw=="}], "type": "inlineReview", "revised_code": {"commit": "bf54438f363d097f685744463e63f663327053f0", "chunk": "diff --git a/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java b/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecBuilder.java\nsimilarity index 60%\nrename from core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java\nrename to core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecBuilder.java\nindex eb3d14b3cf..17f6346660 100644\n--- a/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java\n+++ b/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecBuilder.java\n\n@@ -24,21 +24,31 @@ import com.fasterxml.jackson.annotation.JsonProperty;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n-import java.util.Objects;\n \n-public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+public class SingleDimensionShardSpecBuilder implements ShardSpecBuilder\n {\n   private final String partitionDimension;\n-  private final PartitionBoundaries partitionBoundaries;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n \n   @JsonCreator\n-  public SingleDimensionShardSpecFactory(\n+  public SingleDimensionShardSpecBuilder(\n       @JsonProperty(\"partitionDimension\") String partitionDimension,\n-      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n   )\n   {\n     this.partitionDimension = partitionDimension;\n-    this.partitionBoundaries = partitionBoundaries;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n   }\n \n   @JsonProperty\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTQyNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372145426", "bodyText": "Please add unit tests for the two create methods", "author": "ccaominh", "createdAt": "2020-01-29T01:16:37Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk3NA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924974", "bodyText": "There will be a pretty big change for these methods in my next PR. I'll add tests later.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTQyNg=="}], "type": "inlineReview", "revised_code": {"commit": "bf54438f363d097f685744463e63f663327053f0", "chunk": "diff --git a/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java b/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecBuilder.java\nsimilarity index 60%\nrename from core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java\nrename to core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecBuilder.java\nindex eb3d14b3cf..17f6346660 100644\n--- a/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java\n+++ b/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecBuilder.java\n\n@@ -24,21 +24,31 @@ import com.fasterxml.jackson.annotation.JsonProperty;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n-import java.util.Objects;\n \n-public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+public class SingleDimensionShardSpecBuilder implements ShardSpecBuilder\n {\n   private final String partitionDimension;\n-  private final PartitionBoundaries partitionBoundaries;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n \n   @JsonCreator\n-  public SingleDimensionShardSpecFactory(\n+  public SingleDimensionShardSpecBuilder(\n       @JsonProperty(\"partitionDimension\") String partitionDimension,\n-      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n   )\n   {\n     this.partitionDimension = partitionDimension;\n-    this.partitionBoundaries = partitionBoundaries;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n   }\n \n   @JsonProperty\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODIxNw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372148217", "bodyText": "What do you think about adding a method to the partition spec interface so that future addition of partition specs do not potentially require modification to this code?", "author": "ccaominh", "createdAt": "2020-01-29T01:28:23Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -598,59 +612,74 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n    *\n    * @return a map indicating how many shardSpecs need to be created per interval.\n    */\n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> determineShardSpecs(\n+  private PartitionAnalysis determineShardSpecs(\n       final TaskToolbox toolbox,\n       final InputSource inputSource,\n       final File tmpDir,\n-      final PartitionsSpec nonNullPartitionsSpec\n+      @Nonnull final PartitionsSpec partitionsSpec\n   ) throws IOException\n   {\n     final ObjectMapper jsonMapper = toolbox.getJsonMapper();\n-    final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n-    final IndexIOConfig ioConfig = ingestionSchema.getIOConfig();\n \n     final GranularitySpec granularitySpec = ingestionSchema.getDataSchema().getGranularitySpec();\n \n     // Must determine intervals if unknown, since we acquire all locks before processing any data.\n     final boolean determineIntervals = !granularitySpec.bucketIntervals().isPresent();\n \n     // Must determine partitions if rollup is guaranteed and the user didn't provide a specific value.\n-    final boolean determineNumPartitions = nonNullPartitionsSpec.needsDeterminePartitions(false);\n+    final boolean determineNumPartitions = partitionsSpec.needsDeterminePartitions(false);\n \n     // if we were given number of shards per interval and the intervals, we don't need to scan the data\n     if (!determineNumPartitions && !determineIntervals) {\n       log.info(\"Skipping determine partition scan\");\n-      return createShardSpecWithoutInputScan(\n-          granularitySpec,\n-          ioConfig,\n-          tuningConfig,\n-          nonNullPartitionsSpec\n-      );\n+      if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+        return PartialHashSegmentGenerateTask.createHashPartitionAnalysisFromPartitionsSpec(\n+            granularitySpec,\n+            (HashedPartitionsSpec) partitionsSpec\n+        );\n+      } else if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+        return createLinearPartitionAnalysis(granularitySpec, (DynamicPartitionsSpec) partitionsSpec);\n+      } else {\n+        throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+      }", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk5Mw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924993", "bodyText": "I think it's a good idea. Unfortunately, CompletePartitionAnalysis needs TaskToolbox which is in the indexing-service module. This prevents partition analysis classes from moving to the core module.\nHowever, I think I can remove TaskToolbox from CompletePartitionAnalysis in my next PR. I'll do it later.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODIxNw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODk2OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372148968", "bodyText": "What do you think about adding a method to the partition spec interface so that future addition of partition specs do not potentially require modification to this code?", "author": "ccaominh", "createdAt": "2020-01-29T01:31:28Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -659,50 +688,49 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n         inputSource,\n         tmpDir,\n         granularitySpec,\n-        nonNullPartitionsSpec,\n+        partitionsSpec,\n         determineIntervals\n     );\n-\n-    final Map<Interval, Pair<ShardSpecFactory, Integer>> allocateSpecs = new HashMap<>();\n+    final PartitionAnalysis<Integer, ?> partitionAnalysis;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      partitionAnalysis = new LinearPartitionAnalysis((DynamicPartitionsSpec) partitionsSpec);\n+    } else if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+      partitionAnalysis = new HashPartitionAnalysis((HashedPartitionsSpec) partitionsSpec);\n+    } else {\n+      throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+    }", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0OTY5OQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372149699", "bodyText": "May be useful add some unit tests to IndexTaskTest to cover the new code you've added", "author": "ccaominh", "createdAt": "2020-01-29T01:34:47Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -264,6 +271,13 @@ public String getType()\n   @Override\n   public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   {\n+    final IndexTuningConfig tuningConfig = getIngestionSchema().getTuningConfig();", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTAxNA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925014", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0OTY5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\nindex 9f796a9a06..3091581b42 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\n\n@@ -275,7 +275,7 @@ public class IndexTask extends AbstractBatchIndexTask implements ChatHandler\n     if (tuningConfig != null && tuningConfig.getPartitionsSpec() != null) {\n       if (tuningConfig.getPartitionsSpec().getType() != SecondaryPartitionType.LINEAR\n           && tuningConfig.getPartitionsSpec().getType() != SecondaryPartitionType.HASH) {\n-        throw new IAE(\"partitionsSpec[%s] is not supported\", tuningConfig.getPartitionsSpec().getClass().getName());\n+        throw new UOE(\"partitionsSpec[%s] is not supported\", tuningConfig.getPartitionsSpec().getClass().getName());\n       }\n     }\n     return determineLockGranularityAndTryLock(taskActionClient, ingestionSchema.dataSchema.getGranularitySpec());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjE1NA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372152154", "bodyText": "Is it worth adding unit test for this class now?", "author": "ccaominh", "createdAt": "2020-01-29T01:44:59Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwriteShardSpecFactory;\n+import org.apache.druid.timeline.partition.NumberedShardSpecFactory;\n+import org.apache.druid.timeline.partition.ShardSpecFactory;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTAyOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925028", "bodyText": "Hmm, I'll add some in a follow-up PR.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjE1NA=="}], "type": "inlineReview", "revised_code": {"commit": "bf54438f363d097f685744463e63f663327053f0", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java\nindex 9c4768033d..a16dcdab9e 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java\n\n@@ -33,9 +33,9 @@ import org.apache.druid.segment.indexing.DataSchema;\n import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n-import org.apache.druid.timeline.partition.NumberedOverwriteShardSpecFactory;\n-import org.apache.druid.timeline.partition.NumberedShardSpecFactory;\n-import org.apache.druid.timeline.partition.ShardSpecFactory;\n+import org.apache.druid.timeline.partition.NumberedOverwriteShardSpecBuilder;\n+import org.apache.druid.timeline.partition.NumberedShardSpecBuilder;\n+import org.apache.druid.timeline.partition.ShardSpecBuilder;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjgzNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372152836", "bodyText": "Do you want to add unit tests for this class?", "author": "ccaominh", "createdAt": "2020-01-29T01:47:56Z", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTA0MQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925041", "bodyText": "This is a class for easy testing. Does it need unit tests?", "author": "jihoonson", "createdAt": "2020-02-03T05:16:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjgzNg=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClientForTest.java\nsimilarity index 95%\nrename from indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java\nrename to indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClientForTest.java\nindex 783e23cd53..63380e84fd 100644\n--- a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java\n+++ b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClientForTest.java\n\n@@ -30,13 +30,13 @@ import org.apache.druid.indexing.overlord.TaskStorage;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.atomic.AtomicInteger;\n \n-public class CountingLocalTaskActionClient implements TaskActionClient\n+public class CountingLocalTaskActionClientForTest implements TaskActionClient\n {\n   private final ConcurrentHashMap<Class<? extends TaskAction>, AtomicInteger> actionCountMap =\n       new ConcurrentHashMap<>();\n   private final LocalTaskActionClient delegate;\n \n-  public CountingLocalTaskActionClient(\n+  public CountingLocalTaskActionClientForTest(\n       Task task,\n       TaskStorage storage,\n       TaskActionToolbox toolbox\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MzYxNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r372153616", "bodyText": "Thanks for the additional helpful comments!", "author": "ccaominh", "createdAt": "2020-01-29T01:51:16Z", "path": "server/src/main/java/org/apache/druid/segment/realtime/appenderator/SegmentAllocator.java", "diffHunk": "@@ -21,25 +21,32 @@\n \n import org.apache.druid.data.input.InputRow;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n \n public interface SegmentAllocator\n {\n   /**\n-   * Allocates a new segment for a given timestamp.\n+   * Allocates a new segment for a given timestamp. Even though its name is \"allocate\", this method is actually", "originalCommit": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzY2NA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793664", "bodyText": "Maybe revise the javadoc wording to match the method rename better (similar comment for the method below)", "author": "ccaominh", "createdAt": "2020-02-01T18:11:53Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java", "diffHunk": "@@ -20,34 +20,37 @@\n package org.apache.druid.timeline.partition;\n \n import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n import com.fasterxml.jackson.annotation.JsonTypeInfo;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n \n /**\n- * Factory to be used to allocate segments remotely in the overlord.\n+ * Class to contain all information of a {@link ShardSpec} except for the partition ID.\n+ * This class is mainly used by the indexing tasks to allocate new segments using the Overlord.\n  */\n @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"type\")\n @JsonSubTypes({\n-    @JsonSubTypes.Type(name = \"numbered\", value = NumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"hashed\", value = HashBasedNumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"numbered_overwrite\", value = NumberedOverwritingShardSpecFactory.class),\n+    @Type(name = \"numbered\", value = NumberedPartialShardSpec.class),\n+    @Type(name = \"hashed\", value = HashBasedNumberedPartialShardSpec.class),\n+    @Type(name = \"single_dim\", value = SingleDimensionPartialShardSpec.class),\n+    @Type(name = \"numbered_overwrite\", value = NumberedOverwritePartialShardSpec.class),\n })\n-public interface ShardSpecFactory\n+public interface PartialShardSpec\n {\n   /**\n    * Create a new shardSpec based on {@code specOfPreviousMaxPartitionId}. If it's null, it assumes that this is the\n    * first call for the timeChunk where the new segment is created.\n    * Note that {@code specOfPreviousMaxPartitionId} can also be null for {@link OverwriteShardSpec} if all segments\n    * in the timeChunk are first-generation segments.\n    */\n-  ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);\n+  ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTA4NQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925085", "bodyText": "This method will be changed in my next PR. I'll update the javadoc in it.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzY2NA=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java b/core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java\nindex 2b09cc4720..a1cba82383 100644\n--- a/core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java\n+++ b/core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java\n\n@@ -19,6 +19,7 @@\n \n package org.apache.druid.timeline.partition;\n \n+import com.fasterxml.jackson.annotation.JsonIgnore;\n import com.fasterxml.jackson.annotation.JsonSubTypes;\n import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n import com.fasterxml.jackson.annotation.JsonTypeInfo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzcyOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793728", "bodyText": "Do you want to add a serde unit test?", "author": "ccaominh", "createdAt": "2020-02-01T18:13:27Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTA5NQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925095", "bodyText": "\ud83d\udc4d added.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzcyOA=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java b/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java\nindex 9d9719e681..22ca97d3fe 100644\n--- a/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java\n+++ b/core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java\n\n@@ -24,6 +24,7 @@ import com.fasterxml.jackson.annotation.JsonProperty;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n+import java.util.Objects;\n \n public class SingleDimensionPartialShardSpec implements PartialShardSpec\n {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5Mzg4MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793880", "bodyText": "This method name can be updated to match the rename to \"PartialShardSpec\"", "author": "ccaominh", "createdAt": "2020-02-01T18:15:44Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwritePartialShardSpec;\n+import org.apache.druid.timeline.partition.NumberedPartialShardSpec;\n+import org.apache.druid.timeline.partition.PartialShardSpec;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator\n+{\n+  private final ActionBasedSegmentAllocator internalAllocator;\n+\n+  OverlordCoordinatingSegmentAllocator(\n+      final TaskToolbox toolbox,\n+      final @Nullable SupervisorTaskAccess supervisorTaskAccess,\n+      final DataSchema dataSchema,\n+      final TaskLockHelper taskLockHelper,\n+      final boolean appendToExisting,\n+      final PartitionsSpec partitionsSpec\n+  )\n+  {\n+    this.internalAllocator = new ActionBasedSegmentAllocator(\n+        toolbox.getTaskActionClient(),\n+        dataSchema,\n+        (schema, row, sequenceName, previousSegmentId, skipSegmentLineageCheck) -> {\n+          final GranularitySpec granularitySpec = schema.getGranularitySpec();\n+          final Interval interval = granularitySpec\n+              .bucketInterval(row.getTimestamp())\n+              .or(granularitySpec.getSegmentGranularity().bucket(row.getTimestamp()));\n+          final PartialShardSpec partialShardSpec = createShardSpecFactory(\n+              appendToExisting,\n+              partitionsSpec,\n+              taskLockHelper,\n+              interval\n+          );\n+          if (supervisorTaskAccess != null) {\n+            return new SurrogateAction<>(\n+                supervisorTaskAccess.getSupervisorTaskId(),\n+                new SegmentAllocateAction(\n+                    schema.getDataSource(),\n+                    row.getTimestamp(),\n+                    schema.getGranularitySpec().getQueryGranularity(),\n+                    schema.getGranularitySpec().getSegmentGranularity(),\n+                    sequenceName,\n+                    previousSegmentId,\n+                    skipSegmentLineageCheck,\n+                    partialShardSpec,\n+                    taskLockHelper.getLockGranularityToUse()\n+                )\n+            );\n+          } else {\n+            return new SegmentAllocateAction(\n+                schema.getDataSource(),\n+                row.getTimestamp(),\n+                schema.getGranularitySpec().getQueryGranularity(),\n+                schema.getGranularitySpec().getSegmentGranularity(),\n+                sequenceName,\n+                previousSegmentId,\n+                skipSegmentLineageCheck,\n+                partialShardSpec,\n+                taskLockHelper.getLockGranularityToUse()\n+            );\n+          }\n+        }\n+    );\n+  }\n+\n+  @Nullable\n+  @Override\n+  public SegmentIdWithShardSpec allocate(\n+      InputRow row,\n+      String sequenceName,\n+      String previousSegmentId,\n+      boolean skipSegmentLineageCheck\n+  ) throws IOException\n+  {\n+    return internalAllocator.allocate(row, sequenceName, previousSegmentId, skipSegmentLineageCheck);\n+  }\n+\n+  private static PartialShardSpec createShardSpecFactory(", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEwNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925106", "bodyText": "Renamed.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5Mzg4MA=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java\nindex 45c3f93b9b..1598dee0c3 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java\n\n@@ -65,7 +65,7 @@ public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator\n           final Interval interval = granularitySpec\n               .bucketInterval(row.getTimestamp())\n               .or(granularitySpec.getSegmentGranularity().bucket(row.getTimestamp()));\n-          final PartialShardSpec partialShardSpec = createShardSpecFactory(\n+          final PartialShardSpec partialShardSpec = createPartialShardSpec(\n               appendToExisting,\n               partitionsSpec,\n               taskLockHelper,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIxMA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794210", "bodyText": "Is it worth adding a unit test for this method now?", "author": "ccaominh", "createdAt": "2020-02-01T18:21:57Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -125,14 +127,18 @@ public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTExMw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925113", "bodyText": "Do you mean for createSegmentAllocator()? Is it covered by HashPartitionMultiPhaseParallelIndexingTest? BTW, the return type of this method will also be changed to SegmentAllocator in my follow-up PR.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIxMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIzNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794236", "bodyText": "Is it worth adding a unit test for this method now?", "author": "ccaominh", "createdAt": "2020-02-01T18:22:51Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -158,17 +164,24 @@ private HashPartitionStat createPartitionStat(TaskToolbox toolbox, DataSegment s\n     );\n   }\n \n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> createShardSpecs()\n+  /**\n+   * Creates shard specs based on the given configurations. The return value is a map between intervals created\n+   * based on the segment granularity and the shard specs to be created.\n+   * Note that the shard specs to be created is a pair of {@link PartialShardSpec} and number of segments per interval\n+   * and filled only when {@link #isGuaranteedRollup} = true. Otherwise, the return value contains only the set of\n+   * intervals generated based on the segment granularity.\n+   */\n+  public static HashPartitionAnalysis createHashPartitionAnalysisFromPartitionsSpec(", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEyMw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925123", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIzNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDI1MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794250", "bodyText": "Is it worth adding a unit test for this method now?", "author": "ccaominh", "createdAt": "2020-02-01T18:23:06Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialRangeSegmentGenerateTask.java", "diffHunk": "@@ -149,15 +150,19 @@ public boolean isReady(TaskActionClient taskActionClient)\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEyOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925128", "bodyText": "Is it covered by RangePartitionMultiPhaseParallelIndexingTest?", "author": "jihoonson", "createdAt": "2020-02-03T05:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDI1MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDU0NA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794544", "bodyText": "Is it worth adding a unit test for this method?", "author": "ccaominh", "createdAt": "2020-02-01T18:29:10Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Maps;\n+import org.apache.druid.indexer.partitions.HashedPartitionsSpec;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.HashBasedNumberedShardSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+public class HashPartitionAnalysis implements CompletePartitionAnalysis<Integer, HashedPartitionsSpec>\n+{\n+  /**\n+   * Key is the time ranges for the primary partitioning.\n+   * Value is the number of partitions per time range for the secondary partitioning\n+   */\n+  private final Map<Interval, Integer> intervalToNumBuckets = new HashMap<>();\n+  private final HashedPartitionsSpec partitionsSpec;\n+\n+  public HashPartitionAnalysis(HashedPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public HashedPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, Integer bucketAnalysis)\n+  {\n+    intervalToNumBuckets.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public Integer getBucketAnalysis(Interval interval)\n+  {\n+    return Preconditions.checkNotNull(\n+        intervalToNumBuckets.get(interval),\n+        \"Missing numBuckets for interval[%s]\",\n+        interval\n+    );\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToNumBuckets.keySet());\n+  }\n+\n+  @Override\n+  public int numTimePartitions()\n+  {\n+    return intervalToNumBuckets.size();\n+  }\n+\n+  public void forEach(BiConsumer<Interval, Integer> consumer)\n+  {\n+    intervalToNumBuckets.forEach(consumer);\n+  }\n+\n+  @Override\n+  public Map<Interval, List<SegmentIdWithShardSpec>> convertToIntervalToSegmentIds(", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEzNA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925134", "bodyText": "This method will be removed in my follow-up PR.", "author": "jihoonson", "createdAt": "2020-02-03T05:16:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDU0NA=="}], "type": "inlineReview", "revised_code": {"commit": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java\nindex b1ac1342d4..a4b3a86a1b 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java\n\n@@ -19,10 +19,10 @@\n \n package org.apache.druid.indexing.common.task.batch.partition;\n \n-import com.google.common.base.Preconditions;\n import com.google.common.collect.Maps;\n import org.apache.druid.indexer.partitions.HashedPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.java.util.common.IAE;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n import org.apache.druid.timeline.partition.HashBasedNumberedShardSpec;\n import org.joda.time.Interval;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794708", "bodyText": "Do you want to add javadocs (especially for these methods)", "author": "ccaominh", "createdAt": "2020-02-01T18:32:08Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Set;\n+\n+/**\n+ * Analysis of the partitions to create. The implementation is mutable and updated by the indexing\n+ * {@link org.apache.druid.indexing.common.task.Task}.\n+ *\n+ * This interface provides all time chunks for the primary partitioning and the bucket information per time chunk\n+ * for the secondary partitioning.\n+ */\n+public interface PartitionAnalysis<T, P extends PartitionsSpec>\n+{\n+  P getPartitionsSpec();\n+\n+  void updateBucket(Interval interval, T bucketAnalysis);\n+\n+  T getBucketAnalysis(Interval interval);", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDc0Mw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794743", "bodyText": "I assume getBucketAnalysis is used by a follow up PR?", "author": "ccaominh", "createdAt": "2020-02-01T18:32:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE0Mg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925142", "bodyText": "Yes, it will be used in the follow-up PR. Added a simple javadoc and will add more details in the next PR because it will be more clear in it.", "author": "jihoonson", "createdAt": "2020-02-03T05:17:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java\nindex 563f13a3a1..f30fb7c84a 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java\n\n@@ -37,6 +37,9 @@ public interface PartitionAnalysis<T, P extends PartitionsSpec>\n \n   void updateBucket(Interval interval, T bucketAnalysis);\n \n+  /**\n+   * Returns the analysis of the secondary bucket for the given time chunk.\n+   */\n   T getBucketAnalysis(Interval interval);\n \n   Set<Interval> getAllIntervalsToIndex();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTAwOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795008", "bodyText": "Can this be private?", "author": "ccaominh", "createdAt": "2020-02-01T18:38:18Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToPartitionBoundaries.keySet());\n+  }\n+\n+  public void forEach(BiConsumer<Interval, PartitionBoundaries> consumer)", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE1Mg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925152", "bodyText": "Fixed.", "author": "jihoonson", "createdAt": "2020-02-03T05:17:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTAwOA=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java\nindex 8b4d1c0ed5..65ddb51eaa 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java\n\n@@ -73,7 +73,7 @@ public class RangePartitionAnalysis\n     return Collections.unmodifiableSet(intervalToPartitionBoundaries.keySet());\n   }\n \n-  public void forEach(BiConsumer<Interval, PartitionBoundaries> consumer)\n+  private void forEach(BiConsumer<Interval, PartitionBoundaries> consumer)\n   {\n     intervalToPartitionBoundaries.forEach(consumer);\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTI0OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795248", "bodyText": "Is this only needed for tests? If so, maybe add @VisibleForTesting", "author": "ccaominh", "createdAt": "2020-02-01T18:42:32Z", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient\n+{\n+  private final ConcurrentHashMap<Class<? extends TaskAction>, AtomicInteger> actionCountMap =\n+      new ConcurrentHashMap<>();\n+  private final LocalTaskActionClient delegate;\n+\n+  public CountingLocalTaskActionClient(\n+      Task task,\n+      TaskStorage storage,\n+      TaskActionToolbox toolbox\n+  )\n+  {\n+    delegate = new LocalTaskActionClient(task, storage, toolbox, new TaskAuditLogConfig(false));\n+  }\n+\n+  @Override\n+  public <RetType> RetType submit(TaskAction<RetType> taskAction)\n+  {\n+    final RetType result = delegate.submit(taskAction);\n+    final TaskAction actionKey;\n+    if (taskAction instanceof SurrogateAction) {\n+      actionKey = ((SurrogateAction) taskAction).getTaskAction();\n+    } else {\n+      actionKey = taskAction;\n+    }\n+    actionCountMap.computeIfAbsent(actionKey.getClass(), k -> new AtomicInteger()).incrementAndGet();\n+    return result;\n+  }\n+\n+  public int getActionCount(Class<? extends TaskAction> actionClass)", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE1OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925158", "bodyText": "This class is defined in a test package. Renamed to CountingLocalTaskActionClientForTest for clarity.", "author": "jihoonson", "createdAt": "2020-02-03T05:17:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTI0OA=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClientForTest.java\nsimilarity index 95%\nrename from indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java\nrename to indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClientForTest.java\nindex 783e23cd53..63380e84fd 100644\n--- a/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java\n+++ b/indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClientForTest.java\n\n@@ -30,13 +30,13 @@ import org.apache.druid.indexing.overlord.TaskStorage;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.atomic.AtomicInteger;\n \n-public class CountingLocalTaskActionClient implements TaskActionClient\n+public class CountingLocalTaskActionClientForTest implements TaskActionClient\n {\n   private final ConcurrentHashMap<Class<? extends TaskAction>, AtomicInteger> actionCountMap =\n       new ConcurrentHashMap<>();\n   private final LocalTaskActionClient delegate;\n \n-  public CountingLocalTaskActionClient(\n+  public CountingLocalTaskActionClientForTest(\n       Task task,\n       TaskStorage storage,\n       TaskActionToolbox toolbox\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTQ0Mw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795443", "bodyText": "Do you want to update the parameter description to match the rename?", "author": "ccaominh", "createdAt": "2020-02-01T18:46:23Z", "path": "server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java", "diffHunk": "@@ -157,7 +157,7 @@\n    * @param previousSegmentId       previous segment in the series; may be null or empty, meaning this is the first\n    *                                segment\n    * @param interval                interval for which to allocate a segment\n-   * @param shardSpecFactory        shardSpecFactory containing all necessary information to create a shardSpec for the\n+   * @param partialShardSpec        shardSpecFactory containing all necessary information to create a shardSpec for the", "originalCommit": "58998ac74be63ce92e375d8d605daf35e69da637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE2Ng==", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925166", "bodyText": "Thanks, updated.", "author": "jihoonson", "createdAt": "2020-02-03T05:17:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTQ0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "chunk": "diff --git a/server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java b/server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java\nindex 7e08109e1e..fdbdb7a944 100644\n--- a/server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java\n+++ b/server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java\n\n@@ -157,7 +157,7 @@ public interface IndexerMetadataStorageCoordinator\n    * @param previousSegmentId       previous segment in the series; may be null or empty, meaning this is the first\n    *                                segment\n    * @param interval                interval for which to allocate a segment\n-   * @param partialShardSpec        shardSpecFactory containing all necessary information to create a shardSpec for the\n+   * @param partialShardSpec        partialShardSpec containing all necessary information to create a shardSpec for the\n    *                                new segmentId\n    * @param maxVersion              use this version if we have no better version to use. The returned segment\n    *                                identifier may have a version lower than this one, but will not have one higher.\n"}}, {"oid": "09f1776133ef6f437bb809a15e75b7bf0449aaef", "url": "https://github.com/apache/druid/commit/09f1776133ef6f437bb809a15e75b7bf0449aaef", "message": "fix comment; add unit tests for partitionBoundaries", "committedDate": "2020-02-03T04:03:48Z", "type": "commit"}, {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936", "url": "https://github.com/apache/druid/commit/b8962a37f884f3ca3cad3abb20eb801b13783936", "message": "add more tests and fix javadoc", "committedDate": "2020-02-03T05:15:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNDU3NQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374204575", "bodyText": "javadocs please - what is this used for?", "author": "suneet-s", "createdAt": "2020-02-03T16:30:00Z", "path": "core/src/main/java/org/apache/druid/indexer/partitions/PartitionsSpec.java", "diffHunk": "@@ -41,6 +41,9 @@\n   String MAX_ROWS_PER_SEGMENT = \"maxRowsPerSegment\";\n   int HISTORICAL_NULL = -1;\n \n+  @JsonIgnore\n+  SecondaryPartitionType getType();", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTE4Nw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439187", "bodyText": "This was originally to easily get some characteristics of the secondary partitioning type but turns out they are not that useful. But, I still find it useful especially when I need to do something based on the secondary partition type. I can use switch instead of multiple if statements. But maybe this will be unnecessary once I address #9274 (comment) in the follow-up PR. I'll remove this method or add javadoc later.", "author": "jihoonson", "createdAt": "2020-02-04T01:57:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNDU3NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNjE4Nw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374206187", "bodyText": "Is there a test that fails if we change the property name here?\nIf there isn't, let's at least leave a comment here saying numPartitions is for backward compatibility.", "author": "suneet-s", "createdAt": "2020-02-03T16:32:43Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java", "diffHunk": "@@ -27,20 +27,20 @@\n import java.util.List;\n import java.util.Objects;\n \n-public class HashBasedNumberedShardSpecFactory implements ShardSpecFactory\n+public class HashBasedNumberedPartialShardSpec implements PartialShardSpec\n {\n   @Nullable\n   private final List<String> partitionDimensions;\n-  private final int numPartitions;\n+  private final int numBuckets;\n \n   @JsonCreator\n-  public HashBasedNumberedShardSpecFactory(\n+  public HashBasedNumberedPartialShardSpec(\n       @JsonProperty(\"partitionDimensions\") @Nullable List<String> partitionDimensions,\n-      @JsonProperty(\"numPartitions\") int numPartitions\n+      @JsonProperty(\"numPartitions\") int numBuckets", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTIwMw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439203", "bodyText": "\ud83d\udc4d added a test.", "author": "jihoonson", "createdAt": "2020-02-04T01:57:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNjE4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "chunk": "diff --git a/core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java b/core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java\nindex a52ea69091..495a85284b 100644\n--- a/core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java\n+++ b/core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java\n\n@@ -29,6 +29,8 @@ import java.util.Objects;\n \n public class HashBasedNumberedPartialShardSpec implements PartialShardSpec\n {\n+  public static final String TYPE = \"hashed\";\n+\n   @Nullable\n   private final List<String> partitionDimensions;\n   private final int numBuckets;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMzUzMg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374223532", "bodyText": "do we need a unit test for this?", "author": "suneet-s", "createdAt": "2020-02-03T17:03:19Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTIxOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439218", "bodyText": "This logic will be changed in the follow-up PR.", "author": "jihoonson", "createdAt": "2020-02-04T01:57:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMzUzMg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNDU1NQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374224555", "bodyText": "Why is this cast needed?", "author": "suneet-s", "createdAt": "2020-02-03T17:05:15Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTIzMw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439233", "bodyText": "It doesn't necessary for now, but will be in the follow-up PR.", "author": "jihoonson", "createdAt": "2020-02-04T01:57:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNDU1NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNjM0Ng==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374226346", "bodyText": "why public?", "author": "suneet-s", "createdAt": "2020-02-03T17:08:52Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -41,11 +45,8 @@\n \n /**\n  * Allocates all necessary segments locally at the beginning and reuses them.\n- *\n- * @see HashPartitionCachingLocalSegmentAllocator\n- * @see RangePartitionCachingLocalSegmentAllocator\n  */\n-class CachingLocalSegmentAllocatorHelper implements IndexTaskSegmentAllocator\n+public class CachingLocalSegmentAllocator implements CachingSegmentAllocator", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTI0Mw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439243", "bodyText": "It can be package default, but will be removed in the follow-up pr.", "author": "jihoonson", "createdAt": "2020-02-04T01:57:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNjM0Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzIwOQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374227209", "bodyText": "I don't see a unit test class for this. Do we want to write a test that makes sure we set the action correctly based on the passed in supervisorTaskAccess", "author": "suneet-s", "createdAt": "2020-02-03T17:10:47Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -59,30 +60,46 @@\n      *\n      * @return Information for segment preallocation\n      */\n-    Map<Interval, List<SegmentIdWithShardSpec>> create(Function<Interval, String> versionFinder);\n+    Map<Interval, List<SegmentIdWithShardSpec>> create(\n+        TaskToolbox toolbox,\n+        String dataSource,\n+        Function<Interval, String> versionFinder\n+    );\n   }\n \n-  CachingLocalSegmentAllocatorHelper(\n+  CachingLocalSegmentAllocator(\n       TaskToolbox toolbox,\n+      String dataSource,\n       String taskId,\n-      String supervisorTaskId,\n+      @Nullable SupervisorTaskAccess supervisorTaskAccess,\n       IntervalToSegmentIdsCreator intervalToSegmentIdsCreator\n   ) throws IOException\n   {\n     this.taskId = taskId;\n     this.sequenceNameToSegmentId = new HashMap<>();\n \n+    final TaskAction<List<TaskLock>> action;\n+    if (supervisorTaskAccess == null) {\n+      action = new LockListAction();\n+    } else {\n+      action = new SurrogateAction<>(supervisorTaskAccess.getSupervisorTaskId(), new LockListAction());\n+    }", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTI2MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439260", "bodyText": "Same, this class will be removed.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzIwOQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzk4MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374227980", "bodyText": "Why must this be NotNull? The javadocs say this function is nullable", "author": "suneet-s", "createdAt": "2020-02-03T17:12:11Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -115,14 +132,11 @@ public SegmentIdWithShardSpec allocate(\n       boolean skipSegmentLineageCheck\n   )\n   {\n-    return sequenceNameToSegmentId.get(sequenceName);\n-  }\n-\n-  @Override\n-  public String getSequenceName(Interval interval, InputRow inputRow)\n-  {\n-    // Sequence name is based solely on the shardSpec, and there will only be one segment per sequence.\n-    return getSequenceName(interval, shardSpecs.getShardSpec(interval, inputRow));\n+    return Preconditions.checkNotNull(", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTI3NQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439275", "bodyText": "The CachingLocalSegmentAllocator allocates all necessary segment IDs upfront and returns a proper segment ID corresponding to the sequenceName. It's a bug if there's a missing segment ID for a sequence.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzk4MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMjEyMQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374232121", "bodyText": "I think it's better to be explicit here about which types we expect to be non linear and throw a UOE exception if there another type is added. This forces the dev who adds a new type to think about which category it should fall in to.", "author": "suneet-s", "createdAt": "2020-02-03T17:20:09Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -875,14 +876,36 @@ private TaskStatus generateAndPublishSegments(\n       toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n     }\n \n+    final PartitionsSpec partitionsSpec = partitionAnalysis.getPartitionsSpec();\n     final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(\n-        toolbox,\n-        dataSchema,\n-        allocateSpec\n-    );\n+    final SegmentAllocator segmentAllocator;\n+    final SequenceNameFunction sequenceNameFunction;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      segmentAllocator = SegmentAllocators.forLinearPartitioning(\n+          toolbox,\n+          null,\n+          dataSchema,\n+          getTaskLockHelper(),\n+          ingestionSchema.getIOConfig().isAppendToExisting(),\n+          partitionAnalysis.getPartitionsSpec()\n+      );\n+      sequenceNameFunction = new LinearlyPartitionedSequenceNameFunction(getId());\n+    } else {", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTMwOQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439309", "bodyText": "Done.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMjEyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\nindex 3091581b42..e4bb8dec67 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\n\n@@ -882,29 +882,35 @@ public class IndexTask extends AbstractBatchIndexTask implements ChatHandler\n \n     final SegmentAllocator segmentAllocator;\n     final SequenceNameFunction sequenceNameFunction;\n-    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n-      segmentAllocator = SegmentAllocators.forLinearPartitioning(\n-          toolbox,\n-          null,\n-          dataSchema,\n-          getTaskLockHelper(),\n-          ingestionSchema.getIOConfig().isAppendToExisting(),\n-          partitionAnalysis.getPartitionsSpec()\n-      );\n-      sequenceNameFunction = new LinearlyPartitionedSequenceNameFunction(getId());\n-    } else {\n-      final CachingSegmentAllocator localSegmentAllocator = SegmentAllocators.forNonLinearPartitioning(\n-          toolbox,\n-          getDataSource(),\n-          getId(),\n-          null,\n-          (CompletePartitionAnalysis) partitionAnalysis\n-      );\n-      sequenceNameFunction = new NonLinearlyPartitionedSequenceNameFunction(\n-          getId(),\n-          localSegmentAllocator.getShardSpecs()\n-      );\n-      segmentAllocator = localSegmentAllocator;\n+    switch (partitionsSpec.getType()) {\n+      case HASH:\n+      case RANGE:\n+        final CachingSegmentAllocator localSegmentAllocator = SegmentAllocators.forNonLinearPartitioning(\n+            toolbox,\n+            getDataSource(),\n+            getId(),\n+            null,\n+            (CompletePartitionAnalysis) partitionAnalysis\n+        );\n+        sequenceNameFunction = new NonLinearlyPartitionedSequenceNameFunction(\n+            getId(),\n+            localSegmentAllocator.getShardSpecs()\n+        );\n+        segmentAllocator = localSegmentAllocator;\n+        break;\n+      case LINEAR:\n+        segmentAllocator = SegmentAllocators.forLinearPartitioning(\n+            toolbox,\n+            null,\n+            dataSchema,\n+            getTaskLockHelper(),\n+            ingestionSchema.getIOConfig().isAppendToExisting(),\n+            partitionAnalysis.getPartitionsSpec()\n+        );\n+        sequenceNameFunction = new LinearlyPartitionedSequenceNameFunction(getId());\n+        break;\n+      default:\n+        throw new UOE(\"[%s] secondary partition type is not supported\", partitionsSpec.getType());\n     }\n \n     final TransactionalSegmentPublisher publisher = (segmentsToBeOverwritten, segmentsToPublish, commitMetadata) ->\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMzc3MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374233770", "bodyText": "Does this need to be public", "author": "suneet-s", "createdAt": "2020-02-03T17:23:25Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LinearlyPartitionedSequenceNameFunction.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.joda.time.Interval;\n+\n+/**\n+ * This sequence name function should be used for the linear partitioning. Since the segments are created as needed,\n+ * this function uses a single sequence name.\n+ *\n+ * @see org.apache.druid.indexer.partitions.SecondaryPartitionType\n+ */\n+public class LinearlyPartitionedSequenceNameFunction implements SequenceNameFunction", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTMyOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439328", "bodyText": "It may need to be public in the follow-up PR. I'll clean up in it.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMzc3MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDA0Ng==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374234046", "bodyText": "does this need to be public?", "author": "suneet-s", "createdAt": "2020-02-03T17:23:58Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -32,32 +34,27 @@\n import org.joda.time.DateTime;\n import org.joda.time.Interval;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n-import java.util.HashMap;\n import java.util.Map;\n import java.util.Map.Entry;\n-import java.util.concurrent.atomic.AtomicInteger;\n import java.util.stream.Collectors;\n \n /**\n  * Segment allocator which allocates new segments locally per request.\n  */\n-class LocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class LocalSegmentAllocator implements SegmentAllocator", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTM1Mg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439352", "bodyText": "Removed.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDA0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java\nindex 377791b917..ead0f63559 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java\n\n@@ -43,7 +43,7 @@ import java.util.stream.Collectors;\n /**\n  * Segment allocator which allocates new segments locally per request.\n  */\n-public class LocalSegmentAllocator implements SegmentAllocator\n+class LocalSegmentAllocator implements SegmentAllocator\n {\n   private final SegmentAllocator internalAllocator;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDk4NQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374234985", "bodyText": "For my understanding - why did we need to change this to MutableInt", "author": "suneet-s", "createdAt": "2020-02-03T17:25:54Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -67,30 +64,25 @@\n       }\n \n       final Interval interval = maybeInterval.get();\n-      final String version = intervalToVersion.entrySet().stream()\n-                                              .filter(entry -> entry.getKey().contains(interval))\n-                                              .map(Entry::getValue)\n-                                              .findFirst()\n-                                              .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n+      final String version = intervalToVersion\n+          .entrySet()\n+          .stream()\n+          .filter(entry -> entry.getKey().contains(interval))\n+          .map(Entry::getValue)\n+          .findFirst()\n+          .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n \n-      final int partitionNum = counters.computeIfAbsent(interval, x -> new AtomicInteger()).getAndIncrement();\n+      final int partitionId = counters.computeIfAbsent(interval, x -> new MutableInt()).getAndIncrement();", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTM3OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439378", "bodyText": "It doesn't have to be an AtomicInteger since there's no concurrent update.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDk4NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MDYxMQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374240611", "bodyText": "Why is this always NonLinearlyPartitionedSequenceNameFunction shouldn't we check the partitionsSpec type to determine the  sequenceNameFunction here?\nIf it is, I think we should , make the constructors package private and expose the function name creation through a factory that accepts a PartitionsSpec", "author": "suneet-s", "createdAt": "2020-02-03T17:37:09Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialSegmentGenerateTask.java", "diffHunk": "@@ -164,7 +171,11 @@ abstract T createGeneratedPartitionsReport(\n     final PartitionsSpec partitionsSpec = tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox);\n+    final CachingSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SequenceNameFunction sequenceNameFunction = new NonLinearlyPartitionedSequenceNameFunction(", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTM5Mw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439393", "bodyText": "PartialSegmentGenerateTask is used when shuffling intermediate segment is required. The hash or range partitionings need the shuffle, but for the linear partitioning, I think it would never need it.\nHmm, well actually I think I can make SequenceNameFunction to be more general so that it can create the proper sequence name based on the partialShardSpec. I will do it in the follow-up pr.", "author": "jihoonson", "createdAt": "2020-02-04T01:58:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MDYxMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MjIzNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374242236", "bodyText": "This should look at partitionsSpec.getType() otherwise if that implementation changes to return a non linear type this will break", "author": "suneet-s", "createdAt": "2020-02-03T17:40:39Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java", "diffHunk": "@@ -410,7 +313,14 @@ private SegmentAllocator createSegmentAllocator()\n     final DynamicPartitionsSpec partitionsSpec = (DynamicPartitionsSpec) tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n     final boolean explicitIntervals = granularitySpec.bucketIntervals().isPresent();\n-    final SegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SegmentAllocator segmentAllocator = SegmentAllocators.forLinearPartitioning(", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTUwMw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439503", "bodyText": "This task type is supposed to be used with only linear partitioning.", "author": "jihoonson", "createdAt": "2020-02-04T01:59:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MjIzNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NTExOQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374245119", "bodyText": "Other implementations of ParitionAnalysis throw an exception if the interval is not found. This returns null. I think we should consolidate the behavior and document it in the interface to make it easy for consumers of the interface to interact with this function", "author": "suneet-s", "createdAt": "2020-02-03T17:46:22Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTUyMw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439523", "bodyText": "Good catch! I fixed the code and updated the javadoc. I want to add unit tests for this but think it would be easier to do in the follow-up PR.", "author": "jihoonson", "createdAt": "2020-02-04T01:59:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NTExOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java\nindex 65ddb51eaa..b2753931ba 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java\n\n@@ -22,6 +22,7 @@ package org.apache.druid.indexing.common.task.batch.partition;\n import com.google.common.collect.Maps;\n import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.java.util.common.IAE;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NjQxNg==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374246416", "bodyText": "shardSpecFactory -> partialShardSpec. Lombok would be nice and hide all of this away :)", "author": "suneet-s", "createdAt": "2020-02-03T17:48:58Z", "path": "indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java", "diffHunk": "@@ -187,7 +187,7 @@ public String toString()\n            \", groupId='\" + groupId + '\\'' +\n            \", dataSource='\" + dataSource + '\\'' +\n            \", interval=\" + interval +\n-           \", shardSpecFactory=\" + shardSpecFactory +\n+           \", shardSpecFactory=\" + partialShardSpec +", "originalCommit": "b8962a37f884f3ca3cad3abb20eb801b13783936", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTUzNA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439534", "bodyText": "Thanks, fixed.", "author": "jihoonson", "createdAt": "2020-02-04T01:59:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NjQxNg=="}], "type": "inlineReview", "revised_code": {"commit": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "chunk": "diff --git a/indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java b/indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java\nindex e194f252aa..2171d6b386 100644\n--- a/indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java\n+++ b/indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java\n\n@@ -187,7 +187,7 @@ public class LockRequestForNewSegment implements LockRequest\n            \", groupId='\" + groupId + '\\'' +\n            \", dataSource='\" + dataSource + '\\'' +\n            \", interval=\" + interval +\n-           \", shardSpecFactory=\" + partialShardSpec +\n+           \", partialShardSpec=\" + partialShardSpec +\n            \", priority=\" + priority +\n            \", sequenceName='\" + sequenceName + '\\'' +\n            \", previsousSegmentId='\" + previsousSegmentId + '\\'' +\n"}}, {"oid": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "url": "https://github.com/apache/druid/commit/7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "message": "fix toString(); add serde tests for HashBasedNumberedPartialShardSpec and SegmentAllocateAction", "committedDate": "2020-02-04T01:57:31Z", "type": "commit"}, {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c", "url": "https://github.com/apache/druid/commit/02bea97c3c04911d6b71a788ed743b7bbdd4530c", "message": "fix test", "committedDate": "2020-02-04T05:22:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NDQ3OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r375544478", "bodyText": "Was there an issue with using TestHelper?", "author": "ccaominh", "createdAt": "2020-02-05T22:29:33Z", "path": "core/src/test/java/org/apache/druid/timeline/partition/PartitionBoundariesTest.java", "diffHunk": "@@ -75,8 +76,23 @@ public void handlesRepeatedValue()\n   }\n \n   @Test\n-  public void serializesDeserializes()\n+  public void serializesDeserializes() throws JsonProcessingException\n   {\n-    TestHelper.testSerializesDeserializes(TestHelper.JSON_MAPPER, target);\n+    final ObjectMapper objectMapper = new ObjectMapper();", "originalCommit": "02bea97c3c04911d6b71a788ed743b7bbdd4530c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY0MQ==", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632641", "bodyText": "TestHelper is in druid-processing while this class is in druid-core.", "author": "jihoonson", "createdAt": "2020-02-07T22:14:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NDQ3OA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NzkzOA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r375547938", "bodyText": "May be useful to add an EqualsVerifier test for this.", "author": "ccaominh", "createdAt": "2020-02-05T22:38:34Z", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -94,14 +125,17 @@ public boolean equals(Object o)\n     if (o == null || getClass() != o.getClass()) {\n       return false;\n     }\n-    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n-    return Objects.equals(partitionDimension, that.partitionDimension) &&\n-           Objects.equals(partitionBoundaries, that.partitionBoundaries);\n+    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;", "originalCommit": "02bea97c3c04911d6b71a788ed743b7bbdd4530c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY1Nw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632657", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-07T22:14:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NzkzOA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0ODU3MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r375548570", "bodyText": "How about adding an EqualsVerifier test to this class?", "author": "ccaominh", "createdAt": "2020-02-05T22:40:11Z", "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public class HashBasedNumberedPartialShardSpecTest\n+{\n+  private static final ObjectMapper MAPPER = new ObjectMapper();\n+\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    final HashBasedNumberedPartialShardSpec fromJson = (HashBasedNumberedPartialShardSpec) MAPPER.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+\n+  @Test\n+  public void testJsonPropertyNames() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    //noinspection unchecked\n+    final Map<String, Object> map = MAPPER.readValue(json, Map.class);\n+    Assert.assertEquals(3, map.size());\n+    Assert.assertEquals(HashBasedNumberedPartialShardSpec.TYPE, map.get(\"type\"));\n+    Assert.assertEquals(expected.getPartitionDimensions(), map.get(\"partitionDimensions\"));\n+    Assert.assertEquals(expected.getNumBuckets(), map.get(\"numPartitions\"));\n+  }\n+}", "originalCommit": "02bea97c3c04911d6b71a788ed743b7bbdd4530c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY3OA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632678", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-07T22:14:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0ODU3MA=="}], "type": "inlineReview", "revised_code": {"commit": "e7c9cecd63922226d4399313874c6971e7e55938", "chunk": "diff --git a/core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java b/core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java\nindex b5aa9a8bd2..9b2c664679 100644\n--- a/core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java\n+++ b/core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java\n\n@@ -21,6 +21,7 @@ package org.apache.druid.timeline.partition;\n \n import com.fasterxml.jackson.databind.ObjectMapper;\n import com.google.common.collect.ImmutableList;\n+import nl.jqno.equalsverifier.EqualsVerifier;\n import org.junit.Assert;\n import org.junit.Test;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0OTU0MA==", "url": "https://github.com/apache/druid/pull/9274#discussion_r375549540", "bodyText": "May be useful to add an EqualsVerifier test to this class.", "author": "ccaominh", "createdAt": "2020-02-05T22:42:40Z", "path": "core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+public class SingleDimensionPartialShardSpecTest\n+{\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final SingleDimensionPartialShardSpec expected = new SingleDimensionPartialShardSpec(\n+        \"partitionKey\",\n+        3,\n+        \"start\",\n+        \"end\",\n+        10\n+    );\n+    final ObjectMapper mapper = new ObjectMapper();\n+    final byte[] json = mapper.writeValueAsBytes(expected);\n+    final SingleDimensionPartialShardSpec fromJson = (SingleDimensionPartialShardSpec) mapper.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+}", "originalCommit": "02bea97c3c04911d6b71a788ed743b7bbdd4530c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY5Nw==", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632697", "bodyText": "Added.", "author": "jihoonson", "createdAt": "2020-02-07T22:14:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0OTU0MA=="}], "type": "inlineReview", "revised_code": {"commit": "e7c9cecd63922226d4399313874c6971e7e55938", "chunk": "diff --git a/core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java b/core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java\nindex 80b91111bd..4b2e52aa6d 100644\n--- a/core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java\n+++ b/core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java\n\n@@ -20,6 +20,7 @@\n package org.apache.druid.timeline.partition;\n \n import com.fasterxml.jackson.databind.ObjectMapper;\n+import nl.jqno.equalsverifier.EqualsVerifier;\n import org.junit.Assert;\n import org.junit.Test;\n \n"}}, {"oid": "e7c9cecd63922226d4399313874c6971e7e55938", "url": "https://github.com/apache/druid/commit/e7c9cecd63922226d4399313874c6971e7e55938", "message": "add equality test for hash and range partial shard specs", "committedDate": "2020-02-07T22:14:28Z", "type": "commit"}]}