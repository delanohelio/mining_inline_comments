{"pr_number": 6242, "pr_title": "6713 implement domain discovery", "pr_createdAt": "2020-09-08T14:21:14Z", "pr_url": "https://github.com/sleuthkit/autopsy/pull/6242", "timeline": [{"oid": "62c97436d1cefe0cc2d2501fcbee72284780341c", "url": "https://github.com/sleuthkit/autopsy/commit/62c97436d1cefe0cc2d2501fcbee72284780341c", "message": "Implemented Domain Discovery functionality", "committedDate": "2020-09-08T14:06:18Z", "type": "commit"}, {"oid": "bcce8133d94dfaedfd562962dd2578ee08e097bf", "url": "https://github.com/sleuthkit/autopsy/commit/bcce8133d94dfaedfd562962dd2578ee08e097bf", "message": "Clean up from diff review, added in PageWorker and SearchWorker changes", "committedDate": "2020-09-08T14:18:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTU2ODczNw==", "url": "https://github.com/sleuthkit/autopsy/pull/6242#discussion_r485568737", "bodyText": "access level of constructor and some methods do not match class access level, it looks like they should all be private I think", "author": "wschaeferB", "createdAt": "2020-09-09T12:24:22Z", "path": "Core/src/org/sleuthkit/autopsy/discovery/search/DomainSearchCacheLoader.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Autopsy Forensic Browser\n+ *\n+ * Copyright 2020 Basis Technology Corp.\n+ * Contact: carrier <at> sleuthkit <dot> org\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.sleuthkit.autopsy.discovery.search;\n+\n+import com.google.common.cache.CacheLoader;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.time.Instant;\n+import java.time.temporal.ChronoUnit;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.StringJoiner;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.sleuthkit.autopsy.discovery.search.DiscoveryAttributes.AttributeType;\n+import org.sleuthkit.autopsy.discovery.search.DiscoveryAttributes.DataSourceAttribute;\n+import org.sleuthkit.autopsy.discovery.search.DiscoveryKeyUtils.GroupKey;\n+import org.sleuthkit.autopsy.discovery.search.DiscoveryKeyUtils.SearchKey;\n+import org.sleuthkit.autopsy.discovery.search.SearchFiltering.ArtifactDateRangeFilter;\n+import org.sleuthkit.autopsy.discovery.search.SearchFiltering.ArtifactTypeFilter;\n+import org.sleuthkit.autopsy.discovery.search.SearchFiltering.DataSourceFilter;\n+import static org.sleuthkit.datamodel.BlackboardArtifact.ARTIFACT_TYPE.TSK_WEB_DOWNLOAD;\n+import static org.sleuthkit.datamodel.BlackboardArtifact.ARTIFACT_TYPE.TSK_WEB_HISTORY;\n+import static org.sleuthkit.datamodel.BlackboardAttribute.ATTRIBUTE_TYPE.TSK_DOMAIN;\n+import org.sleuthkit.datamodel.CaseDbAccessManager;\n+import org.sleuthkit.datamodel.CaseDbAccessManager.CaseDbAccessQueryCallback;\n+import org.sleuthkit.datamodel.Content;\n+import org.sleuthkit.datamodel.SleuthkitCase;\n+import org.sleuthkit.datamodel.TskCoreException;\n+\n+/**\n+ * Loads domain search results for cache misses. This loader is a Guava cache loader,\n+ * which will be used in tandem with the DomainSearchCache, which is backed by a \n+ * Guava LoadingCache.\n+ */\n+class DomainSearchCacheLoader extends CacheLoader<SearchKey, Map<GroupKey, List<Result>>> {\n+        \n+    @Override\n+    public Map<GroupKey, List<Result>> load(SearchKey key) throws DiscoveryException, SQLException, TskCoreException {\n+\n+        List<Result> domainResults = getResultDomainsFromDatabase(key);\n+        \n+        // Apply secondary in memory filters\n+        for (AbstractFilter filter : key.getFilters()) {\n+            if (filter.useAlternateFilter()) {\n+                domainResults = filter.applyAlternateFilter(domainResults, key.getSleuthkitCase(), key.getCentralRepository());\n+            }\n+        }\n+\n+        // Sort the ResultDomains by the requested criteria.\n+        final SearchResults searchResults = new SearchResults(\n+                key.getGroupSortingType(),\n+                key.getGroupAttributeType(),\n+                key.getFileSortingMethod());\n+        searchResults.add(domainResults);\n+        return searchResults.toLinkedHashMap();\n+    }\n+\n+    /**\n+     * Queries for domain names from the case database.\n+     * \n+     * @param key The SearchKey passed to the cache.\n+     * @return A list of results corresponding to the domains found in the\n+     *         case database.\n+     */\n+    List<Result> getResultDomainsFromDatabase(SearchKey key) throws TskCoreException, SQLException, DiscoveryException {\n+        \n+        // Filters chosen in the UI are aggregated into SQL statements to be used in \n+        // the queries that follow.\n+        final Pair<String, String> filterClauses = createWhereAndHavingClause(key.getFilters());\n+        final String whereClause = filterClauses.getLeft();\n+        final String havingClause = filterClauses.getRight();\n+        \n+        // You may think of each row of this result as a TSK_DOMAIN attribute, where the parent\n+        // artifact type is within the (optional) filter and the parent artifact\n+        // had a date time attribute that was within the (optional) filter. With this\n+        // table in hand, we can simply group by domain and apply aggregate functions\n+        // to get, for example, # of downloads, # of visits in last 60, etc.\n+        final String domainsTable = \n+                \"SELECT MAX(value_text)  AS domain,\" +\n+                \"       MAX(value_int64) AS date,\" + \n+                \"       artifact_id AS parent_artifact_id,\" +\n+                \"       MAX(artifact_type_id) AS parent_artifact_type_id \" +\n+                \n+                \"FROM   blackboard_attributes \" + \n+                \"WHERE  \" + whereClause + \" \" +\n+                \n+                \"GROUP BY artifact_id \" +\n+                \"HAVING \" + havingClause;\n+        \n+        // Needed to populate the visitsInLast60 data.\n+        final Instant currentTime = Instant.now();\n+        final Instant sixtyDaysAgo = currentTime.minus(60, ChronoUnit.DAYS);\n+        \n+        // Check the group attribute, if by data source then the GROUP BY clause\n+        // should group by data source id before grouping by domain.\n+        final AttributeType groupAttribute = key.getGroupAttributeType();   \n+        final String groupByClause = (groupAttribute instanceof DataSourceAttribute) ?\n+                \"data_source_obj_id, domain\" : \"domain\";\n+        \n+        final Optional<AbstractFilter> dataSourceFilter = key.getFilters().stream()\n+                .filter(filter -> filter instanceof DataSourceFilter)\n+                .findFirst();\n+        \n+        String dataSourceWhereClause = null;\n+        if (dataSourceFilter.isPresent()) {\n+            dataSourceWhereClause = dataSourceFilter.get().getWhereClause();\n+        }\n+        \n+        // This query just processes the domains table, performing additional \n+        // groupings and applying aggregate functions to calculate discovery data.\n+        final String domainsQuery = \n+               /*SELECT */\" domain,\" + \n+                \"           MIN(date) AS activity_start,\" + \n+                \"           MAX(date) AS activity_end,\" + \n+                \"           SUM(CASE \" +\n+                \"                 WHEN artifact_type_id = \" + TSK_WEB_DOWNLOAD.getTypeID() + \" THEN 1 \" +\n+                \"                 ELSE 0 \" +\n+                \"               END) AS fileDownloads,\" + \n+                \"           SUM(CASE \" +\n+                \"                 WHEN artifact_type_id = \" + TSK_WEB_HISTORY.getTypeID() + \" AND\" +\n+                \"                      date BETWEEN \" + sixtyDaysAgo.getEpochSecond() + \" AND \" + currentTime.getEpochSecond() + \" THEN 1 \" +\n+                \"                 ELSE 0 \" +\n+                \"               END) AS last60,\" + \n+                \"           data_source_obj_id AS dataSource \" + \n+                \n+                \"FROM blackboard_artifacts\" +\n+                \"     JOIN (\" + domainsTable + \") AS domains_table\" + \n+                \"       ON artifact_id = parent_artifact_id \" + \n+                \n+                // Add the data source where clause here if present.\n+                ((dataSourceWhereClause != null) ? \"WHERE \" + dataSourceWhereClause + \" \" : \"\") +\n+                \n+                \"GROUP BY \" + groupByClause;\n+        \n+        final SleuthkitCase caseDb = key.getSleuthkitCase();\n+        final CaseDbAccessManager dbManager = caseDb.getCaseDbAccessManager();   \n+        \n+        final DomainCallback domainCallback = new DomainCallback(caseDb);\n+        dbManager.select(domainsQuery, domainCallback);\n+        \n+        if (domainCallback.getSQLException() != null) {\n+            throw domainCallback.getSQLException();\n+        }\n+        \n+        if (domainCallback.getTskCoreException() != null) {\n+            throw domainCallback.getTskCoreException();\n+        }\n+\n+        return domainCallback.getResultDomains();\n+    }\n+\n+    /**\n+     * A utility method to transform filters into the necessary SQL statements\n+     * for the domainsTable query. The complexity of that query requires this\n+     * transformation process to be conditional. The date time filter is a good\n+     * example of the type of conditional handling that follows in the method\n+     * below. If no dateTime filter is supplied, then in order for the query to\n+     * be correct, an additional clause needs to be added in.\n+     *\n+     * @return The whereClause and havingClause as a pair. These methods are one\n+     * to stress that these clauses are tightly coupled.\n+     */\n+    Pair<String, String> createWhereAndHavingClause(List<AbstractFilter> filters) {        \n+        final StringJoiner whereClause = new StringJoiner(\" OR \");\n+        final StringJoiner havingClause = new StringJoiner(\" AND \"); \n+        \n+        String artifactTypeFilter = null;\n+        boolean hasDateTimeFilter = false;\n+        \n+        for (AbstractFilter filter : filters) {       \n+            if (filter instanceof ArtifactTypeFilter) {\n+                artifactTypeFilter = filter.getWhereClause();\n+            } else if (!(filter instanceof DataSourceFilter) && !filter.useAlternateFilter()) {\n+                if (filter instanceof ArtifactDateRangeFilter) {\n+                    hasDateTimeFilter = true;\n+                }\n+                \n+                whereClause.add(\"(\" + filter.getWhereClause() + \")\");\n+                havingClause.add(\"SUM(CASE WHEN \" + filter.getWhereClause() + \" THEN 1 ELSE 0 END) > 0\");\n+            }\n+        }\n+        \n+        if (!hasDateTimeFilter) {\n+            whereClause.add(ArtifactDateRangeFilter.createAttributeTypeClause());\n+        }\n+        \n+        String domainAttributeFilter = \"attribute_type_id = \" + TSK_DOMAIN.getTypeID() +\n+                \" AND value_text <> ''\";\n+        \n+        whereClause.add(\"(\" + domainAttributeFilter + \")\");\n+        havingClause.add(\"SUM(CASE WHEN \" + domainAttributeFilter + \" THEN 1 ELSE 0 END) > 0\");\n+        \n+        return Pair.of(\n+                whereClause.toString() + ((artifactTypeFilter != null) ? \" AND (\" + artifactTypeFilter + \")\" : \"\"),\n+                havingClause.toString()\n+        );\n+    }\n+    \n+    /**\n+     * Callback to handle the result set of the domain query. This callback\n+     * is responsible for mapping result set rows into ResultDomain objects\n+     * for display.\n+     */\n+    private class DomainCallback implements CaseDbAccessQueryCallback {", "originalCommit": "bcce8133d94dfaedfd562962dd2578ee08e097bf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "637e0572b6783fa8f13719acd9b492d1ac2e6380", "chunk": "diff --git a/Core/src/org/sleuthkit/autopsy/discovery/search/DomainSearchCacheLoader.java b/Core/src/org/sleuthkit/autopsy/discovery/search/DomainSearchCacheLoader.java\nindex 59c47429c4..9bc6e1f417 100755\n--- a/Core/src/org/sleuthkit/autopsy/discovery/search/DomainSearchCacheLoader.java\n+++ b/Core/src/org/sleuthkit/autopsy/discovery/search/DomainSearchCacheLoader.java\n\n@@ -95,7 +95,7 @@\n         // table in hand, we can simply group by domain and apply aggregate functions\n         // to get, for example, # of downloads, # of visits in last 60, etc.\n         final String domainsTable = \n-                \"SELECT MAX(value_text)  AS domain,\" +\n+                \"SELECT LOWER(MAX(value_text))  AS domain,\" +\n                 \"       MAX(value_int64) AS date,\" + \n                 \"       artifact_id AS parent_artifact_id,\" +\n                 \"       MAX(artifact_type_id) AS parent_artifact_type_id \" +\n"}}, {"oid": "637e0572b6783fa8f13719acd9b492d1ac2e6380", "url": "https://github.com/sleuthkit/autopsy/commit/637e0572b6783fa8f13719acd9b492d1ac2e6380", "message": "Bug fixes and performance fixes", "committedDate": "2020-09-10T18:19:34Z", "type": "commit"}, {"oid": "e36e32fd6d20dbc6f3cb655b20be8124e1a05c28", "url": "https://github.com/sleuthkit/autopsy/commit/e36e32fd6d20dbc6f3cb655b20be8124e1a05c28", "message": "Added tests, removed some logic added for data source domains table", "committedDate": "2020-09-11T14:02:25Z", "type": "commit"}, {"oid": "9cbc432aaea57db21d44e3b577b4a4238e343019", "url": "https://github.com/sleuthkit/autopsy/commit/9cbc432aaea57db21d44e3b577b4a4238e343019", "message": "Merged in develop", "committedDate": "2020-09-11T19:48:12Z", "type": "commit"}, {"oid": "c2e2f1fea86d21ff9d4c5704a7ad2c0809c83956", "url": "https://github.com/sleuthkit/autopsy/commit/c2e2f1fea86d21ff9d4c5704a7ad2c0809c83956", "message": "Fixed tests", "committedDate": "2020-09-11T19:49:10Z", "type": "commit"}, {"oid": "9188c299f47639aff1fd2ebc681fb8d2242d323d", "url": "https://github.com/sleuthkit/autopsy/commit/9188c299f47639aff1fd2ebc681fb8d2242d323d", "message": "Removed my local path from the project files", "committedDate": "2020-09-11T19:51:26Z", "type": "commit"}]}