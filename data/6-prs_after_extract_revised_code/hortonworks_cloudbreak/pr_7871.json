{"pr_number": 7871, "pr_title": "CB-5741 Support For Retrieving VM Size Information", "pr_createdAt": "2020-04-22T14:01:46Z", "pr_url": "https://github.com/hortonworks/cloudbreak/pull/7871", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ0NDkzNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413444937", "bodyText": "This is nice. Had forgotten that eventually the instanceType doesn't matter. What we need is the memory assigned for containers on the node. Have the CMCommunicator in place will help with https://jira.cloudera.com/browse/DISTX-410, https://jira.cloudera.com/browse/OPSAPS-54750", "author": "sidseth", "createdAt": "2020-04-23T01:34:35Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -37,21 +37,28 @@\n \n     private static final String DEFAULT_UPSCALE_RESOURCE_TYPE = \"memory-mb\";\n \n+    private static final Integer DEFAULT_CLOUD_VM_NUM_CORES = 8;\n+\n+    private static final Long DEFAULT_CLOUD_VM_MEMORY_MB = 32000L;\n+\n     @Inject\n     private TlsSecurityService tlsSecurityService;\n \n     @Inject\n     private ClusterProxyConfigurationService clusterProxyConfigurationService;\n \n     @Inject\n-    private CloudInstanceTypeService cloudInstanceTypeService;\n+    private ClouderaManagerCommunicator clouderaManagerCommunicator;", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\nindex 79913894d9..25eeb2a124 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\n\n@@ -37,31 +36,24 @@ public class YarnMetricsClient {\n \n     private static final String DEFAULT_UPSCALE_RESOURCE_TYPE = \"memory-mb\";\n \n-    private static final Integer DEFAULT_CLOUD_VM_NUM_CORES = 8;\n-\n-    private static final Long DEFAULT_CLOUD_VM_MEMORY_MB = 32000L;\n-\n     @Inject\n     private TlsSecurityService tlsSecurityService;\n \n     @Inject\n     private ClusterProxyConfigurationService clusterProxyConfigurationService;\n \n-    @Inject\n-    private ClouderaManagerCommunicator clouderaManagerCommunicator;\n-\n     @Inject\n     private RequestLogging requestLogging;\n \n-    private CloudInstanceType defaultCloudInstanceType = new CloudInstanceType(\n-            \"DefaultInstanceType\", DEFAULT_CLOUD_VM_NUM_CORES, DEFAULT_CLOUD_VM_MEMORY_MB);\n+    @Inject\n+    private YarnServiceConfigClient yarnServiceConfigClient;\n \n-    public YarnScalingServiceV1Response getYarnMetricsForCluster(Cluster cluster,\n-            String hostGroup,\n-            Set<String> hostGroupFqdns) throws Exception {\n+    public YarnScalingServiceV1Response getYarnMetricsForCluster(Cluster cluster, StackV4Response stackV4Response,\n+            String hostGroup) throws Exception {\n \n         TlsConfiguration tlsConfig = tlsSecurityService.getTls(cluster.getId());\n         Optional<String> clusterProxyUrl = clusterProxyConfigurationService.getClusterProxyUrl();\n+\n         if (!clusterProxyUrl.isPresent() || !cluster.getTunnel().useClusterProxy()) {\n             String msg = String.format(\"ClusterProxy Not Configured for Cluster {}, cannot query YARN Metrics.\", cluster.getStackCrn());\n             throw new RuntimeException(msg);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ0NTY1NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413445655", "bodyText": "If the number of nodes in 'compute' is 0 - will end up using 32GB? That I think is a big problem. Maybe the CM jiras mentioned above help with this. I don't think we can ship with (if 0) assume 32GB though.", "author": "sidseth", "createdAt": "2020-04-23T01:36:45Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -66,13 +73,17 @@ public YarnScalingServiceV1Response getYarnMetricsForCluster(Cluster cluster,\n         String yarnApiUrl = String.format(YARN_API_URL, clusterProxyUrl.get(), cluster.getStackCrn());\n         YarnScalingServiceV1Request yarnScalingServiceV1Request = new YarnScalingServiceV1Request();\n \n-        CloudInstanceType cloudInstanceType = cloudInstanceTypeService.getCloudVMInstanceType(cloudPlatform, hostGroupInstanceType)\n-                .orElseThrow(() -> new RuntimeException(String.format(\"CloudVmType not found for CloudPlatform %s, \" +\n-                        \" InstanceType %s, Cluster %s \", cloudPlatform, hostGroupInstanceType, cluster.getStackCrn())));\n+        CloudInstanceType cloudInstanceType = hostGroupFqdns.size() == 0 ? defaultCloudInstanceType : clouderaManagerCommunicator", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzcyMDE3OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413720179", "bodyText": "The yarnScalingAPI uses the instance vm information we give as a shirt size to give recommended nodeCount and don't think it is used to configure 32GB internally that would be based on the actual node added to the cluster.\nAlso once one node is added to hostGroup the scaling service autocorrects itself. So next scaleUpEvent corrects the node size and count if a non-default standard size is used in the template.\nThe 32 gb default is the standard size used in DE templates corresponding to m5.2xlarge and Standard_D8_v3.\nSo these are the only options I see for this.\n\nUse default DE Template Host Size and let the service auto correct itself as implemented above.\nAbove changes plus enforce minHostNodeCount to \"1\" in LoadAlertConfiguration whenever hostGroup needs to be auto-scaled. In autoscale run if nodeCount is 0, trigger scale to change it to \"1\".\nRevert back to the earlier implementation where in all the cloud platform vms were defined.\nCan retrieve the  yarn_nodemanager_resource_cpu_vcores and yarn_nodemanager_resource_memory_mb from backend CM api, but values seems to be differ by around 12 GB Memory. Dont know much about yarn internal but does this seem to be fine ? As you mentioned there is no easy way to retrieve roleName for this.\n\nI don't see any other possible implementation for this. Let me know what you think.", "author": "smaniraju", "createdAt": "2020-04-23T11:00:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ0NTY1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\nindex 79913894d9..25eeb2a124 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\n\n@@ -69,24 +61,15 @@ public class YarnMetricsClient {\n \n         Client restClient = RestClientUtil.createClient(tlsConfig.getServerCert(),\n                 tlsConfig.getClientCert(), tlsConfig.getClientKey(), true);\n-\n         String yarnApiUrl = String.format(YARN_API_URL, clusterProxyUrl.get(), cluster.getStackCrn());\n-        YarnScalingServiceV1Request yarnScalingServiceV1Request = new YarnScalingServiceV1Request();\n-\n-        CloudInstanceType cloudInstanceType = hostGroupFqdns.size() == 0 ? defaultCloudInstanceType : clouderaManagerCommunicator\n-                .getCloudVMDetailsForHostGroup(cluster, hostGroup, hostGroupFqdns)\n-                .orElseGet(() -> {\n-                    LOGGER.debug(\"CloudVmSize could not be determined from CM for Cluster '{}', HostGroup '{}', HostGroupFqdnSize '{}'.\",\n-                            cluster.getStackCrn(), hostGroup, hostGroupFqdns.size());\n-                    return defaultCloudInstanceType;\n-                });\n \n+        InstanceConfig instanceConfig = yarnServiceConfigClient.getInstanceConfigFromCM(cluster, stackV4Response, hostGroup);\n+        YarnScalingServiceV1Request yarnScalingServiceV1Request = new YarnScalingServiceV1Request();\n         yarnScalingServiceV1Request.setInstanceTypes(List.of(\n-                new HostGroupInstanceType(cloudInstanceType.getInstanceName(),\n-                        cloudInstanceType.getMemoryInMB().intValue(), cloudInstanceType.getCoreCPU())));\n+                new HostGroupInstanceType(instanceConfig.getInstanceName(),\n+                        instanceConfig.getMemoryInMb().intValue(), instanceConfig.getCoreCPU())));\n \n         String clusterCreatorCrn = cluster.getClusterPertain().getUserCrn();\n-\n         YarnScalingServiceV1Response yarnResponse = requestLogging.logResponseTime(() -> {\n             return restClient.target(yarnApiUrl)\n                     .queryParam(PARAM_UPSCALE_FACTOR_NODE_RESOURCE_TYPE, DEFAULT_UPSCALE_RESOURCE_TYPE)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ0NzE2Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413447167", "bodyText": "Likewise for the fallback in case of a CM failure.", "author": "sidseth", "createdAt": "2020-04-23T01:41:21Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -66,13 +73,17 @@ public YarnScalingServiceV1Response getYarnMetricsForCluster(Cluster cluster,\n         String yarnApiUrl = String.format(YARN_API_URL, clusterProxyUrl.get(), cluster.getStackCrn());\n         YarnScalingServiceV1Request yarnScalingServiceV1Request = new YarnScalingServiceV1Request();\n \n-        CloudInstanceType cloudInstanceType = cloudInstanceTypeService.getCloudVMInstanceType(cloudPlatform, hostGroupInstanceType)\n-                .orElseThrow(() -> new RuntimeException(String.format(\"CloudVmType not found for CloudPlatform %s, \" +\n-                        \" InstanceType %s, Cluster %s \", cloudPlatform, hostGroupInstanceType, cluster.getStackCrn())));\n+        CloudInstanceType cloudInstanceType = hostGroupFqdns.size() == 0 ? defaultCloudInstanceType : clouderaManagerCommunicator\n+                .getCloudVMDetailsForHostGroup(cluster, hostGroup, hostGroupFqdns)\n+                .orElseGet(() -> {", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzcyMDM5Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413720393", "bodyText": "same as above.", "author": "smaniraju", "createdAt": "2020-04-23T11:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ0NzE2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\nindex 79913894d9..25eeb2a124 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java\n\n@@ -69,24 +61,15 @@ public class YarnMetricsClient {\n \n         Client restClient = RestClientUtil.createClient(tlsConfig.getServerCert(),\n                 tlsConfig.getClientCert(), tlsConfig.getClientKey(), true);\n-\n         String yarnApiUrl = String.format(YARN_API_URL, clusterProxyUrl.get(), cluster.getStackCrn());\n-        YarnScalingServiceV1Request yarnScalingServiceV1Request = new YarnScalingServiceV1Request();\n-\n-        CloudInstanceType cloudInstanceType = hostGroupFqdns.size() == 0 ? defaultCloudInstanceType : clouderaManagerCommunicator\n-                .getCloudVMDetailsForHostGroup(cluster, hostGroup, hostGroupFqdns)\n-                .orElseGet(() -> {\n-                    LOGGER.debug(\"CloudVmSize could not be determined from CM for Cluster '{}', HostGroup '{}', HostGroupFqdnSize '{}'.\",\n-                            cluster.getStackCrn(), hostGroup, hostGroupFqdns.size());\n-                    return defaultCloudInstanceType;\n-                });\n \n+        InstanceConfig instanceConfig = yarnServiceConfigClient.getInstanceConfigFromCM(cluster, stackV4Response, hostGroup);\n+        YarnScalingServiceV1Request yarnScalingServiceV1Request = new YarnScalingServiceV1Request();\n         yarnScalingServiceV1Request.setInstanceTypes(List.of(\n-                new HostGroupInstanceType(cloudInstanceType.getInstanceName(),\n-                        cloudInstanceType.getMemoryInMB().intValue(), cloudInstanceType.getCoreCPU())));\n+                new HostGroupInstanceType(instanceConfig.getInstanceName(),\n+                        instanceConfig.getMemoryInMb().intValue(), instanceConfig.getCoreCPU())));\n \n         String clusterCreatorCrn = cluster.getClusterPertain().getUserCrn();\n-\n         YarnScalingServiceV1Response yarnResponse = requestLogging.logResponseTime(() -> {\n             return restClient.target(yarnApiUrl)\n                     .queryParam(PARAM_UPSCALE_FACTOR_NODE_RESOURCE_TYPE, DEFAULT_UPSCALE_RESOURCE_TYPE)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ1MDQ2Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413450463", "bodyText": "Should this just be a log line instead of an Exception? Does YARN never return an empty ScaleUpCandidateList", "author": "sidseth", "createdAt": "2020-04-23T01:51:07Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -109,55 +115,50 @@ protected void execute() {\n     }\n \n     protected void pollYarnMetricsAndScaleCluster() throws Exception {\n-\n         StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n-\n-        String hostGroupInstanceType =\n-                stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+        Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n \n         YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n-                .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+                .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n \n-        Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n-                .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n         yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n-                scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                scaleUpCandidates -> handleScaleUp(scaleUpCandidates, hostFqdnsToInstanceId.size()),\n                 () -> {\n-                    yarnResponse.getScaleDownCandidates().ifPresent(\n-                            scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    handleScaleDown(yarnResponse.getScaleDownCandidates().orElse(List.of()), hostFqdnsToInstanceId);\n                 });\n     }\n \n-    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+    protected void handleScaleUp(NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n         Integer yarnRecommendedHostGroupCount =\n                 newNMCandidates.getCandidates().stream()\n-                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n                         .findFirst()\n                         .map(NewNodeManagerCandidates.Candidate::getCount)\n                         .orElseThrow(() -> new RuntimeException(String.format(", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzcyMDc3MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413720771", "bodyText": "ok removed exception.", "author": "smaniraju", "createdAt": "2020-04-23T11:01:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ1MDQ2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2a9ea3e18ce0504385806badc1535bd3e7c29e0c", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\nindex aeccd01639..50e9c5bb61 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n\n@@ -117,75 +116,57 @@ public class YarnLoadEvaluator extends EvaluatorExecutor {\n     protected void pollYarnMetricsAndScaleCluster() throws Exception {\n         StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n         Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n+        Set<String> hostGroupFqdns = hostFqdnsToInstanceId.keySet();\n \n         YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n                 .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n \n-        yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n-                scaleUpCandidates -> handleScaleUp(scaleUpCandidates, hostFqdnsToInstanceId.size()),\n-                () -> {\n-                    handleScaleDown(yarnResponse.getScaleDownCandidates().orElse(List.of()), hostFqdnsToInstanceId);\n-                });\n-    }\n-\n-    protected void handleScaleUp(NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n-        Integer yarnRecommendedHostGroupCount =\n-                newNMCandidates.getCandidates().stream()\n-                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n-                        .findFirst()\n-                        .map(NewNodeManagerCandidates.Candidate::getCount)\n-                        .orElseThrow(() -> new RuntimeException(String.format(\n-                                \"Yarn Scaling API Response does not contain recommended node count \" +\n-                                        \" for hostGroupInstanceType '%s' in Cluster '%s', Yarn Response '%s'\",\n-                                policyHostGroup, cluster.getStackCrn(), newNMCandidates)));\n-\n+        Integer existingHostGroupSize = hostFqdnsToInstanceId.size();\n         Integer maxAllowedScaleUp = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-        Integer scaleUpCount = IntStream.of(yarnRecommendedHostGroupCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE, maxAllowedScaleUp)\n-                .min()\n-                .getAsInt();\n-\n-        LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\", scaleUpCount,\n-                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n-\n-        if (scaleUpCount != 0) {\n-            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(scaleUpCount));\n-            eventPublisher.publishEvent(scalingEvent);\n-        }\n-    }\n-\n-    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n-        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n-        Integer existingHostGroupSize = hostGroupFqdns.size();\n-        int maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n-\n-        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+        Integer maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n+\n+        Integer yarnRecommendedUpscaleCount = yarnResponse.getScaleUpCandidates()\n+                .map(NewNodeManagerCandidates::getCandidates).orElse(List.of()).stream()\n+                .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n+                .findFirst()\n+                .map(NewNodeManagerCandidates.Candidate::getCount)\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE))\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, maxAllowedScaleUp))\n+                .orElse(0);\n+\n+        List<String> yarnRecommendedDecommissionHosts = yarnResponse.getScaleDownCandidates().orElse(List.of()).stream()\n                 .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n                 .map(DecommissionCandidate::getNodeId)\n                 .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n                 .filter(s -> hostGroupFqdns.contains(s))\n                 .limit(maxAllowedScaleDown)\n-                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .map(nodeFqdn -> hostFqdnsToInstanceId.get(nodeFqdn))\n                 .collect(Collectors.toList());\n \n+        if (yarnRecommendedUpscaleCount > 0 && yarnRecommendedUpscaleCount <= maxAllowedScaleUp) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n+            scalingEvent.setScalingNodeCount(Optional.of(yarnRecommendedUpscaleCount));\n+            eventPublisher.publishEvent(scalingEvent);\n \n-        ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-        if (!decommissionHostGroupNodeIds.isEmpty()) {\n-            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n-                    decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), policyHostGroup,\n-                    decommissionHostGroupNodeIds);\n-\n-            scalingEvent.setDecommissionNodeIds(decommissionHostGroupNodeIds);\n+            LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    yarnRecommendedUpscaleCount, cluster.getStackCrn(), policyHostGroup);\n+        } else if (maxAllowedScaleDown > 0 && !yarnRecommendedDecommissionHosts.isEmpty()) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setDecommissionNodeIds(yarnRecommendedDecommissionHosts);\n             eventPublisher.publishEvent(scalingEvent);\n-        } else if (existingHostGroupSize > loadAlertConfiguration.getMaxResourceValue()) {\n-            //Forced downscale to match policy max limit.\n-            Integer scaleDownCount = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n-                    scaleDownCount, cluster.getStackCrn(), policyHostGroup);\n+\n+            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n+                    yarnRecommendedDecommissionHosts.size(), cluster.getStackCrn(), policyHostGroup,\n+                    yarnRecommendedDecommissionHosts);\n+        } else if (maxAllowedScaleUp < 0) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n             scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(scaleDownCount));\n+            scalingEvent.setScalingNodeCount(Optional.of(maxAllowedScaleUp));\n             eventPublisher.publishEvent(scalingEvent);\n+\n+            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    maxAllowedScaleUp, cluster.getStackCrn(), policyHostGroup);\n         }\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ1MzUwMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413453502", "bodyText": "Shouldn't the check for whether to scale based on config.min / config.max happen before checking what YARN has to say. That decides on whether this will be a scale up or a scale down.\nclusterSize=10, max=8, YARN has pending containers. The scale up event will end up asking for \"-2\" containers from what I can tell. Even if negative values are handled, it's better to get these decommission candidates from YARN itself.", "author": "sidseth", "createdAt": "2020-04-23T01:59:50Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -109,55 +115,50 @@ protected void execute() {\n     }\n \n     protected void pollYarnMetricsAndScaleCluster() throws Exception {\n-\n         StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n-\n-        String hostGroupInstanceType =\n-                stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+        Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n \n         YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n-                .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+                .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n \n-        Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n-                .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n         yarnResponse.getScaleUpCandidates().ifPresentOrElse(", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzcyNDE0OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413724149", "bodyText": "Logically Yarn should either give a ScaleUp Count or Decommission Node because both are mutually exclusive. So if scaleUp is asked, decommission nodes should be empty but since cluster size is already above max, scale up event \"-2\" forces it down. But one corner case is scaleUp count is given and decommission nodes contains unhealthy nodes, in this case decommissionUnhealthy nodes was given lower priority.\nNow I have updated patch to make limit check more explicit for all the conditions.\nAlso forced scaleDown is done only after yarnResponse so that we can collect any available yarn decommissionCandidates.", "author": "smaniraju", "createdAt": "2020-04-23T11:07:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ1MzUwMg=="}], "type": "inlineReview", "revised_code": {"commit": "2a9ea3e18ce0504385806badc1535bd3e7c29e0c", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\nindex aeccd01639..50e9c5bb61 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n\n@@ -117,75 +116,57 @@ public class YarnLoadEvaluator extends EvaluatorExecutor {\n     protected void pollYarnMetricsAndScaleCluster() throws Exception {\n         StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n         Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n+        Set<String> hostGroupFqdns = hostFqdnsToInstanceId.keySet();\n \n         YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n                 .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n \n-        yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n-                scaleUpCandidates -> handleScaleUp(scaleUpCandidates, hostFqdnsToInstanceId.size()),\n-                () -> {\n-                    handleScaleDown(yarnResponse.getScaleDownCandidates().orElse(List.of()), hostFqdnsToInstanceId);\n-                });\n-    }\n-\n-    protected void handleScaleUp(NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n-        Integer yarnRecommendedHostGroupCount =\n-                newNMCandidates.getCandidates().stream()\n-                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n-                        .findFirst()\n-                        .map(NewNodeManagerCandidates.Candidate::getCount)\n-                        .orElseThrow(() -> new RuntimeException(String.format(\n-                                \"Yarn Scaling API Response does not contain recommended node count \" +\n-                                        \" for hostGroupInstanceType '%s' in Cluster '%s', Yarn Response '%s'\",\n-                                policyHostGroup, cluster.getStackCrn(), newNMCandidates)));\n-\n+        Integer existingHostGroupSize = hostFqdnsToInstanceId.size();\n         Integer maxAllowedScaleUp = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-        Integer scaleUpCount = IntStream.of(yarnRecommendedHostGroupCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE, maxAllowedScaleUp)\n-                .min()\n-                .getAsInt();\n-\n-        LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\", scaleUpCount,\n-                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n-\n-        if (scaleUpCount != 0) {\n-            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(scaleUpCount));\n-            eventPublisher.publishEvent(scalingEvent);\n-        }\n-    }\n-\n-    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n-        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n-        Integer existingHostGroupSize = hostGroupFqdns.size();\n-        int maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n-\n-        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+        Integer maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n+\n+        Integer yarnRecommendedUpscaleCount = yarnResponse.getScaleUpCandidates()\n+                .map(NewNodeManagerCandidates::getCandidates).orElse(List.of()).stream()\n+                .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n+                .findFirst()\n+                .map(NewNodeManagerCandidates.Candidate::getCount)\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE))\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, maxAllowedScaleUp))\n+                .orElse(0);\n+\n+        List<String> yarnRecommendedDecommissionHosts = yarnResponse.getScaleDownCandidates().orElse(List.of()).stream()\n                 .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n                 .map(DecommissionCandidate::getNodeId)\n                 .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n                 .filter(s -> hostGroupFqdns.contains(s))\n                 .limit(maxAllowedScaleDown)\n-                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .map(nodeFqdn -> hostFqdnsToInstanceId.get(nodeFqdn))\n                 .collect(Collectors.toList());\n \n+        if (yarnRecommendedUpscaleCount > 0 && yarnRecommendedUpscaleCount <= maxAllowedScaleUp) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n+            scalingEvent.setScalingNodeCount(Optional.of(yarnRecommendedUpscaleCount));\n+            eventPublisher.publishEvent(scalingEvent);\n \n-        ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-        if (!decommissionHostGroupNodeIds.isEmpty()) {\n-            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n-                    decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), policyHostGroup,\n-                    decommissionHostGroupNodeIds);\n-\n-            scalingEvent.setDecommissionNodeIds(decommissionHostGroupNodeIds);\n+            LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    yarnRecommendedUpscaleCount, cluster.getStackCrn(), policyHostGroup);\n+        } else if (maxAllowedScaleDown > 0 && !yarnRecommendedDecommissionHosts.isEmpty()) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setDecommissionNodeIds(yarnRecommendedDecommissionHosts);\n             eventPublisher.publishEvent(scalingEvent);\n-        } else if (existingHostGroupSize > loadAlertConfiguration.getMaxResourceValue()) {\n-            //Forced downscale to match policy max limit.\n-            Integer scaleDownCount = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n-                    scaleDownCount, cluster.getStackCrn(), policyHostGroup);\n+\n+            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n+                    yarnRecommendedDecommissionHosts.size(), cluster.getStackCrn(), policyHostGroup,\n+                    yarnRecommendedDecommissionHosts);\n+        } else if (maxAllowedScaleUp < 0) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n             scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(scaleDownCount));\n+            scalingEvent.setScalingNodeCount(Optional.of(maxAllowedScaleUp));\n             eventPublisher.publishEvent(scalingEvent);\n+\n+            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    maxAllowedScaleUp, cluster.getStackCrn(), policyHostGroup);\n         }\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ1Mzc1NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413453755", "bodyText": "Similarly here. This check before the actual scale down. Actually the combined check likely needs to happen before processing results from YARN.", "author": "sidseth", "createdAt": "2020-04-23T02:00:35Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -168,14 +169,23 @@ protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidate\n                 .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n                 .collect(Collectors.toList());\n \n-        LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n-                decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup(),\n-                decommissionHostGroupNodeIds);\n \n         ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n         if (!decommissionHostGroupNodeIds.isEmpty()) {\n+            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n+                    decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), policyHostGroup,\n+                    decommissionHostGroupNodeIds);\n+\n             scalingEvent.setDecommissionNodeIds(decommissionHostGroupNodeIds);\n             eventPublisher.publishEvent(scalingEvent);\n+        } else if (existingHostGroupSize > loadAlertConfiguration.getMaxResourceValue()) {", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzc2NzMzMQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413767331", "bodyText": "commented above.", "author": "smaniraju", "createdAt": "2020-04-23T12:19:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ1Mzc1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "2a9ea3e18ce0504385806badc1535bd3e7c29e0c", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\nindex aeccd01639..50e9c5bb61 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n\n@@ -117,75 +116,57 @@ public class YarnLoadEvaluator extends EvaluatorExecutor {\n     protected void pollYarnMetricsAndScaleCluster() throws Exception {\n         StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n         Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n+        Set<String> hostGroupFqdns = hostFqdnsToInstanceId.keySet();\n \n         YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n                 .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n \n-        yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n-                scaleUpCandidates -> handleScaleUp(scaleUpCandidates, hostFqdnsToInstanceId.size()),\n-                () -> {\n-                    handleScaleDown(yarnResponse.getScaleDownCandidates().orElse(List.of()), hostFqdnsToInstanceId);\n-                });\n-    }\n-\n-    protected void handleScaleUp(NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n-        Integer yarnRecommendedHostGroupCount =\n-                newNMCandidates.getCandidates().stream()\n-                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n-                        .findFirst()\n-                        .map(NewNodeManagerCandidates.Candidate::getCount)\n-                        .orElseThrow(() -> new RuntimeException(String.format(\n-                                \"Yarn Scaling API Response does not contain recommended node count \" +\n-                                        \" for hostGroupInstanceType '%s' in Cluster '%s', Yarn Response '%s'\",\n-                                policyHostGroup, cluster.getStackCrn(), newNMCandidates)));\n-\n+        Integer existingHostGroupSize = hostFqdnsToInstanceId.size();\n         Integer maxAllowedScaleUp = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-        Integer scaleUpCount = IntStream.of(yarnRecommendedHostGroupCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE, maxAllowedScaleUp)\n-                .min()\n-                .getAsInt();\n-\n-        LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\", scaleUpCount,\n-                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n-\n-        if (scaleUpCount != 0) {\n-            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(scaleUpCount));\n-            eventPublisher.publishEvent(scalingEvent);\n-        }\n-    }\n-\n-    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n-        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n-        Integer existingHostGroupSize = hostGroupFqdns.size();\n-        int maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n-\n-        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+        Integer maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n+\n+        Integer yarnRecommendedUpscaleCount = yarnResponse.getScaleUpCandidates()\n+                .map(NewNodeManagerCandidates::getCandidates).orElse(List.of()).stream()\n+                .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n+                .findFirst()\n+                .map(NewNodeManagerCandidates.Candidate::getCount)\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE))\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, maxAllowedScaleUp))\n+                .orElse(0);\n+\n+        List<String> yarnRecommendedDecommissionHosts = yarnResponse.getScaleDownCandidates().orElse(List.of()).stream()\n                 .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n                 .map(DecommissionCandidate::getNodeId)\n                 .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n                 .filter(s -> hostGroupFqdns.contains(s))\n                 .limit(maxAllowedScaleDown)\n-                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .map(nodeFqdn -> hostFqdnsToInstanceId.get(nodeFqdn))\n                 .collect(Collectors.toList());\n \n+        if (yarnRecommendedUpscaleCount > 0 && yarnRecommendedUpscaleCount <= maxAllowedScaleUp) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n+            scalingEvent.setScalingNodeCount(Optional.of(yarnRecommendedUpscaleCount));\n+            eventPublisher.publishEvent(scalingEvent);\n \n-        ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-        if (!decommissionHostGroupNodeIds.isEmpty()) {\n-            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n-                    decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), policyHostGroup,\n-                    decommissionHostGroupNodeIds);\n-\n-            scalingEvent.setDecommissionNodeIds(decommissionHostGroupNodeIds);\n+            LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    yarnRecommendedUpscaleCount, cluster.getStackCrn(), policyHostGroup);\n+        } else if (maxAllowedScaleDown > 0 && !yarnRecommendedDecommissionHosts.isEmpty()) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setDecommissionNodeIds(yarnRecommendedDecommissionHosts);\n             eventPublisher.publishEvent(scalingEvent);\n-        } else if (existingHostGroupSize > loadAlertConfiguration.getMaxResourceValue()) {\n-            //Forced downscale to match policy max limit.\n-            Integer scaleDownCount = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n-                    scaleDownCount, cluster.getStackCrn(), policyHostGroup);\n+\n+            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n+                    yarnRecommendedDecommissionHosts.size(), cluster.getStackCrn(), policyHostGroup,\n+                    yarnRecommendedDecommissionHosts);\n+        } else if (maxAllowedScaleUp < 0) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n             scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(scaleDownCount));\n+            scalingEvent.setScalingNodeCount(Optional.of(maxAllowedScaleUp));\n             eventPublisher.publishEvent(scalingEvent);\n+\n+            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    maxAllowedScaleUp, cluster.getStackCrn(), policyHostGroup);\n         }\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ2NjQwNA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413466404", "bodyText": "Not really related to this patch\nDug through the CM API after looking at this usage.\nhttps://sseth-hf34092-master0.sseth-en.xcu2-8y8x.dev.cldr.work/api/v32/clusters/sseth-hf34092/services/yarn/roleConfigGroups/yarn-NODEMANAGER-WORKER/config - may provide the actual value allocated.\nThe problem here may be the roleConfigGroup name. Highly doubt that CB stores that in its database. Even if it does, or we could get access to the template to figure this out - determining the roleName may not be trivial.", "author": "sidseth", "createdAt": "2020-04-23T02:39:40Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ClouderaManagerCommunicator.java", "diffHunk": "@@ -0,0 +1,72 @@\n+package com.sequenceiq.periscope.monitor.handler;\n+\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.cache.annotation.Cacheable;\n+import org.springframework.stereotype.Service;\n+\n+import com.cloudera.api.swagger.HostsResourceApi;\n+import com.cloudera.api.swagger.client.ApiClient;\n+import com.sequenceiq.cloudbreak.client.HttpClientConfig;\n+import com.sequenceiq.cloudbreak.cm.DataView;\n+import com.sequenceiq.cloudbreak.cm.client.ClouderaManagerApiClientProvider;\n+import com.sequenceiq.cloudbreak.cm.client.retry.ClouderaManagerApiFactory;\n+import com.sequenceiq.cloudbreak.service.secret.service.SecretService;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.ClusterManager;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.service.security.TlsHttpClientConfigurationService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+\n+@Service\n+public class ClouderaManagerCommunicator {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(ClouderaManagerCommunicator.class);\n+\n+    @Inject\n+    private TlsHttpClientConfigurationService tlsHttpClientConfigurationService;\n+\n+    @Inject\n+    private SecretService secretService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private ClouderaManagerApiClientProvider clouderaManagerApiClientProvider;\n+\n+    @Inject\n+    private ClouderaManagerApiFactory clouderaManagerApiFactory;\n+\n+    @Cacheable(cacheNames = \"cloudVMTypeCache\", unless = \"#result == null\", key = \"#cluster.id + #hostGroup\")\n+    public Optional<CloudInstanceType> getCloudVMDetailsForHostGroup(Cluster cluster, String hostGroup, Set<String> hostGroupFqdns) {\n+        try {\n+            LOGGER.debug(\"Retrieving CloudVMType for cluster '{}', hostGroup '{}'\", cluster.getStackCrn(), hostGroupFqdns);\n+            HttpClientConfig httpClientConfig = tlsHttpClientConfigurationService.buildTLSClientConfig(cluster.getStackCrn(),\n+                    cluster.getClusterManager().getHost(), cluster.getTunnel());\n+            ClusterManager cm = cluster.getClusterManager();\n+            String user = secretService.get(cm.getUser());\n+            String pass = secretService.get(cm.getPass());\n+            ApiClient client = clouderaManagerApiClientProvider.getClient(Integer.valueOf(cm.getPort()), user, pass, httpClientConfig);\n+            HostsResourceApi hostsResourceApi = clouderaManagerApiFactory.getHostsResourceApi(client);", "originalCommit": "a2492e94502bd73f1e5c0528fe18e1c37cdfdefd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzc2NTgzNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413765837", "bodyText": "I am able to retrieve the yarn_nodemanager_resource_cpu_vcores and yarn_nodemanager_resource_memory_mb from backend CM api but i am seeing huge difference, yarn_nodemanager_resource_memory_mb is 19975mb where as \"m5.2xlarge\" is 32 gb. I used yarn-NODEMANAGER-\"hostgroup\" but that is not reliable as was discussed in call, so not implementing this mechanism to retrieve MB until a utility is provided.\nhttps://jira.cloudera.com/browse/OPSAPS-54928", "author": "smaniraju", "createdAt": "2020-04-23T12:17:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ2NjQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDEwNTczNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r414105737", "bodyText": "Sounds good. Which API did you end up using to look up the nodemanager memory. IThink you had mentioned a 'hosts' api.", "author": "sidseth", "createdAt": "2020-04-23T20:35:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzQ2NjQwNA=="}], "type": "inlineReview", "revised_code": {"commit": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ClouderaManagerCommunicator.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ClouderaManagerCommunicator.java\nindex 144b14d259..ebe0f287af 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ClouderaManagerCommunicator.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ClouderaManagerCommunicator.java\n\n@@ -1,28 +1,27 @@\n package com.sequenceiq.periscope.monitor.handler;\n \n-import java.util.Optional;\n+import java.util.Map;\n import java.util.Set;\n+import java.util.stream.Collectors;\n \n import javax.inject.Inject;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import org.springframework.cache.annotation.Cacheable;\n import org.springframework.stereotype.Service;\n \n-import com.cloudera.api.swagger.HostsResourceApi;\n+import com.cloudera.api.swagger.RoleConfigGroupsResourceApi;\n import com.cloudera.api.swagger.client.ApiClient;\n+import com.cloudera.api.swagger.model.ApiConfig;\n import com.sequenceiq.cloudbreak.client.HttpClientConfig;\n import com.sequenceiq.cloudbreak.cm.DataView;\n import com.sequenceiq.cloudbreak.cm.client.ClouderaManagerApiClientProvider;\n-import com.sequenceiq.cloudbreak.cm.client.retry.ClouderaManagerApiFactory;\n import com.sequenceiq.cloudbreak.service.secret.service.SecretService;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n import com.sequenceiq.periscope.domain.Cluster;\n import com.sequenceiq.periscope.domain.ClusterManager;\n-import com.sequenceiq.periscope.model.CloudInstanceType;\n import com.sequenceiq.periscope.service.ClusterService;\n import com.sequenceiq.periscope.service.security.TlsHttpClientConfigurationService;\n-import com.sequenceiq.periscope.utils.ClusterUtils;\n \n @Service\n public class ClouderaManagerCommunicator {\n"}}, {"oid": "2a9ea3e18ce0504385806badc1535bd3e7c29e0c", "url": "https://github.com/hortonworks/cloudbreak/commit/2a9ea3e18ce0504385806badc1535bd3e7c29e0c", "message": "CB-5741SupportForRetrievingVMSize", "committedDate": "2020-04-23T10:48:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzczNzQyOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7871#discussion_r413737429", "bodyText": "The number of nodes to be scaled down can be greater than the decommissionCandidates size but that will be forcibly downscaled in the next evaluator run since CB does not support forced downscaling and decommissioning certain node ids simultaneously.", "author": "smaniraju", "createdAt": "2020-04-23T11:30:25Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -109,73 +114,59 @@ protected void execute() {\n     }\n \n     protected void pollYarnMetricsAndScaleCluster() throws Exception {\n-\n         StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n-\n-        String hostGroupInstanceType =\n-                stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+        Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n+        Set<String> hostGroupFqdns = hostFqdnsToInstanceId.keySet();\n \n         YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n-                .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n-\n-        Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n-                .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n-        yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n-                scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n-                () -> {\n-                    yarnResponse.getScaleDownCandidates().ifPresent(\n-                            scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n-                });\n-    }\n-\n-    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n-        Integer yarnRecommendedHostGroupCount =\n-                newNMCandidates.getCandidates().stream()\n-                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n-                        .findFirst()\n-                        .map(NewNodeManagerCandidates.Candidate::getCount)\n-                        .orElseThrow(() -> new RuntimeException(String.format(\n-                                \"Yarn Scaling API Response does not contain recommended node count \" +\n-                                        \" for hostGroupInstanceType '%s' in Cluster '%s', Yarn Response '%s'\",\n-                                hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n-\n-        Integer maxAllowedScaleUp = Math.max(0, loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize);\n-        Integer scaleUpCount = IntStream.of(yarnRecommendedHostGroupCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE, maxAllowedScaleUp)\n-                .min()\n-                .getAsInt();\n-\n-        LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\", scaleUpCount,\n-                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n-\n-        if (scaleUpCount > 0) {\n-            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScaleUpNodeCount(Optional.of(scaleUpCount));\n-            eventPublisher.publishEvent(scalingEvent);\n-        }\n-    }\n-\n-    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n-        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n-        int maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue());\n-\n-        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n+\n+        Integer existingHostGroupSize = hostFqdnsToInstanceId.size();\n+        Integer maxAllowedScaleUp = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n+        Integer maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n+\n+        Integer yarnRecommendedUpscaleCount = yarnResponse.getScaleUpCandidates()\n+                .map(NewNodeManagerCandidates::getCandidates).orElse(List.of()).stream()\n+                .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n+                .findFirst()\n+                .map(NewNodeManagerCandidates.Candidate::getCount)\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE))\n+                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, maxAllowedScaleUp))\n+                .orElse(0);\n+\n+        List<String> yarnRecommendedDecommissionHosts = yarnResponse.getScaleDownCandidates().orElse(List.of()).stream()\n                 .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n                 .map(DecommissionCandidate::getNodeId)\n                 .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n                 .filter(s -> hostGroupFqdns.contains(s))\n                 .limit(maxAllowedScaleDown)\n-                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .map(nodeFqdn -> hostFqdnsToInstanceId.get(nodeFqdn))\n                 .collect(Collectors.toList());\n \n-        LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n-                decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup(),\n-                decommissionHostGroupNodeIds);\n+        if (yarnRecommendedUpscaleCount > 0 && yarnRecommendedUpscaleCount <= maxAllowedScaleUp) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n+            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n+            scalingEvent.setScalingNodeCount(Optional.of(yarnRecommendedUpscaleCount));\n+            eventPublisher.publishEvent(scalingEvent);\n+\n+            LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n+                    yarnRecommendedUpscaleCount, cluster.getStackCrn(), policyHostGroup);\n+        } else if (maxAllowedScaleDown > 0 && !yarnRecommendedDecommissionHosts.isEmpty()) {\n+            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);", "originalCommit": "2a9ea3e18ce0504385806badc1535bd3e7c29e0c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "chunk": "diff --git a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\nindex 50e9c5bb61..65d76eeba8 100644\n--- a/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n+++ b/autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java\n\n@@ -118,55 +119,54 @@ public class YarnLoadEvaluator extends EvaluatorExecutor {\n         Map<String, String> hostFqdnsToInstanceId = stackResponseUtils.getCloudInstanceIdsForHostGroup(stackV4Response, policyHostGroup);\n         Set<String> hostGroupFqdns = hostFqdnsToInstanceId.keySet();\n \n-        YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n-                .getYarnMetricsForCluster(cluster, policyHostGroup, hostFqdnsToInstanceId.keySet());\n+        YarnScalingServiceV1Response yarnResponse = yarnMetricsClient.getYarnMetricsForCluster(cluster, stackV4Response, policyHostGroup);\n+        int existingHostGroupSize = hostFqdnsToInstanceId.size();\n \n-        Integer existingHostGroupSize = hostFqdnsToInstanceId.size();\n-        Integer maxAllowedScaleUp = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n-        Integer maxAllowedScaleDown = Math.max(0, hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue());\n+        int configMaxNodeCount = loadAlertConfiguration.getMaxResourceValue() - existingHostGroupSize;\n+        int configMinNodeCount = hostGroupFqdns.size() - loadAlertConfiguration.getMinResourceValue();\n \n-        Integer yarnRecommendedUpscaleCount = yarnResponse.getScaleUpCandidates()\n+        int allowedUpScale = configMaxNodeCount < 0 ? 0 : configMaxNodeCount;\n+        int yarnRecommendedScaleUpCount = yarnResponse.getScaleUpCandidates()\n                 .map(NewNodeManagerCandidates::getCandidates).orElse(List.of()).stream()\n                 .filter(candidate -> candidate.getModelName().equalsIgnoreCase(policyHostGroup))\n                 .findFirst()\n                 .map(NewNodeManagerCandidates.Candidate::getCount)\n-                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE))\n-                .map(scaleUpNodeCount -> Math.min(scaleUpNodeCount, maxAllowedScaleUp))\n+                .map(scaleUpCount -> IntStream.of(scaleUpCount, allowedUpScale, DEFAULT_MAX_SCALE_UP_STEP_SIZE).min().getAsInt())\n                 .orElse(0);\n \n-        List<String> yarnRecommendedDecommissionHosts = yarnResponse.getScaleDownCandidates().orElse(List.of()).stream()\n+        int allowedDownScale = configMinNodeCount > 0 ? configMinNodeCount : 0;\n+        List<String> yarnDecommissionHosts = yarnResponse.getScaleDownCandidates().orElse(List.of()).stream()\n                 .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n                 .map(DecommissionCandidate::getNodeId)\n                 .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n                 .filter(s -> hostGroupFqdns.contains(s))\n-                .limit(maxAllowedScaleDown)\n                 .map(nodeFqdn -> hostFqdnsToInstanceId.get(nodeFqdn))\n+                .limit(allowedDownScale)\n                 .collect(Collectors.toList());\n \n-        if (yarnRecommendedUpscaleCount > 0 && yarnRecommendedUpscaleCount <= maxAllowedScaleUp) {\n-            ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(yarnRecommendedUpscaleCount));\n-            eventPublisher.publishEvent(scalingEvent);\n+        int targetScaleUpCount = configMinNodeCount < 0 ? Math.max(-1 * configMinNodeCount, yarnRecommendedScaleUpCount) : yarnRecommendedScaleUpCount;\n+        int targetScaleDownCount = configMaxNodeCount < 0 ? Math.max(-1 * configMaxNodeCount, yarnDecommissionHosts.size()) : yarnDecommissionHosts.size();\n+\n+        if (targetScaleUpCount > 0) {\n \n-            LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n-                    yarnRecommendedUpscaleCount, cluster.getStackCrn(), policyHostGroup);\n-        } else if (maxAllowedScaleDown > 0 && !yarnRecommendedDecommissionHosts.isEmpty()) {\n             ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n-            scalingEvent.setDecommissionNodeIds(yarnRecommendedDecommissionHosts);\n+            scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n+            scalingEvent.setScalingNodeCount(Optional.of(targetScaleUpCount));\n             eventPublisher.publishEvent(scalingEvent);\n+            LOGGER.info(\"ScaleUp NodeCount '{}' for Cluster '{}', HostGroup '{}'\", targetScaleUpCount, cluster.getStackCrn(), policyHostGroup);\n+        } else if (targetScaleDownCount > 0) {\n \n-            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\",\n-                    yarnRecommendedDecommissionHosts.size(), cluster.getStackCrn(), policyHostGroup,\n-                    yarnRecommendedDecommissionHosts);\n-        } else if (maxAllowedScaleUp < 0) {\n             ScalingEvent scalingEvent = new ScalingEvent(loadAlert);\n             scalingEvent.setHostGroupNodeCount(Optional.of(existingHostGroupSize));\n-            scalingEvent.setScalingNodeCount(Optional.of(maxAllowedScaleUp));\n+            targetScaleDownCount = -1 * targetScaleDownCount;\n+            if (!yarnDecommissionHosts.isEmpty()) {\n+                scalingEvent.setDecommissionNodeIds(yarnDecommissionHosts);\n+            } else {\n+                scalingEvent.setScalingNodeCount(Optional.of(targetScaleDownCount));\n+            }\n             eventPublisher.publishEvent(scalingEvent);\n-\n-            LOGGER.info(\"Forced ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}'\",\n-                    maxAllowedScaleUp, cluster.getStackCrn(), policyHostGroup);\n+            LOGGER.info(\"ScaleDown NodeCount '{}' for Cluster '{}', HostGroup '{}', NodeIds '{}'\", targetScaleDownCount,\n+                    cluster.getStackCrn(), policyHostGroup, yarnDecommissionHosts);\n         }\n     }\n-}\n+}\n\\ No newline at end of file\n"}}, {"oid": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "url": "https://github.com/hortonworks/cloudbreak/commit/1a0017330a5208245f4e3cb24a10994a09c1d71f", "message": "CB-5741SupportForRetrievingVMSize", "committedDate": "2020-04-25T13:47:16Z", "type": "commit"}, {"oid": "1a0017330a5208245f4e3cb24a10994a09c1d71f", "url": "https://github.com/hortonworks/cloudbreak/commit/1a0017330a5208245f4e3cb24a10994a09c1d71f", "message": "CB-5741SupportForRetrievingVMSize", "committedDate": "2020-04-25T13:47:16Z", "type": "forcePushed"}]}