{"pr_number": 8194, "pr_title": "CB-7212: Add datalake service changes to perform database backup/restore.", "pr_createdAt": "2020-06-02T13:39:21Z", "pr_url": "https://github.com/hortonworks/cloudbreak/pull/8194", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg4NjAxOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r433886018", "bodyText": "nitpick: This should be DATABASE.\nThe same is true for all the following enums, and for the related @Bean(name = \"\") annotations in the action class.", "author": "brycederriso", "createdAt": "2020-06-02T13:44:38Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import com.sequenceiq.flow.core.FlowState;\n+import com.sequenceiq.flow.core.RestartAction;\n+import com.sequenceiq.flow.core.restart.DefaultRestartAction;\n+\n+public enum DatalakeDatabaseDrState implements FlowState {\n+\n+    INIT_STATE,\n+    DATALAKE_DATABSE_BACKUP_START_STATE,", "originalCommit": "eeb0ac24348ecbbc4850b91fd35da885067a3cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5b53f6a124117c9d051c0bc95aa76a71d4c6f3b7", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java\nindex f517917546..e31d5c09d7 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java\n\n@@ -7,14 +7,16 @@ import com.sequenceiq.flow.core.restart.DefaultRestartAction;\n public enum DatalakeDatabaseDrState implements FlowState {\n \n     INIT_STATE,\n-    DATALAKE_DATABSE_BACKUP_START_STATE,\n-    DATALAKE_DATABSE_BACKUP_IN_PROGRESS_STATE,\n-    DATALAKE_DATABSE_BACKUP_FAILED_STATE,\n-    DATALAKE_DATABSE_BACKUP_FINISHED_STATE,\n-    DATALAKE_DATABSE_RESTORE_START_STATE,\n-    DATALAKE_DATABSE_RESTORE_IN_PROGRESS_STATE,\n-    DATALAKE_DATABSE_RESTORE_FAILED_STATE,\n-    DATALAKE_DATABSE_RESTORE_FINISHED_STATE,\n+    DATALAKE_DATABASE_BACKUP_START_STATE,\n+    DATALAKE_DATABASE_BACKUP_COULD_NOT_START_STATE,\n+    DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE,\n+    DATALAKE_DATABASE_BACKUP_FAILED_STATE,\n+    DATALAKE_DATABASE_BACKUP_FINISHED_STATE,\n+    DATALAKE_DATABASE_RESTORE_START_STATE,\n+    DATALAKE_DATABASE_RESTORE_COULD_NOT_START_STATE,\n+    DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE,\n+    DATALAKE_DATABASE_RESTORE_FAILED_STATE,\n+    DATALAKE_DATABASE_RESTORE_FINISHED_STATE,\n     FINAL_STATE;\n \n     private Class<? extends DefaultRestartAction> restartAction = DefaultRestartAction.class;\n"}}, {"oid": "5b53f6a124117c9d051c0bc95aa76a71d4c6f3b7", "url": "https://github.com/hortonworks/cloudbreak/commit/5b53f6a124117c9d051c0bc95aa76a71d4c6f3b7", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-11T04:10:41Z", "type": "forcePushed"}, {"oid": "193405603e46ccc9be38527729240556706c3fe6", "url": "https://github.com/hortonworks/cloudbreak/commit/193405603e46ccc9be38527729240556706c3fe6", "message": "CB-7212: Add datalake service changes to perform database backup/restore.\n\nAdded changes to accept the backup-id and pass it to CB.", "committedDate": "2020-06-15T12:32:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDMzMjcxNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r440332715", "bodyText": "Capitalization and grammer: \"Performs a backup of the database to a provided location\"", "author": "hreeve-cloudera", "createdAt": "2020-06-15T17:27:02Z", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/doc/OperationDescriptions.java", "diffHunk": "@@ -44,6 +44,8 @@\n         public static final String CHECK_STACK_UPGRADE = \"Checks for upgrade options by name\";\n         public static final String STACK_UPGRADE = \"Upgrades a cluster to the latest CM or CDH version\";\n         public static final String LIST_RETRYABLE_FLOWS = \"List retryable failed flows\";\n+        public static final String DATABASE_BACKUP = \"performs a backup of database to a provided location\";", "originalCommit": "193405603e46ccc9be38527729240556706c3fe6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0d0152ccd99c44623234b376e8701f5ef0328a1b", "chunk": "diff --git a/core-api/src/main/java/com/sequenceiq/cloudbreak/doc/OperationDescriptions.java b/core-api/src/main/java/com/sequenceiq/cloudbreak/doc/OperationDescriptions.java\nindex 78e6678756..e35d1a1259 100644\n--- a/core-api/src/main/java/com/sequenceiq/cloudbreak/doc/OperationDescriptions.java\n+++ b/core-api/src/main/java/com/sequenceiq/cloudbreak/doc/OperationDescriptions.java\n\n@@ -44,8 +45,8 @@ public class OperationDescriptions {\n         public static final String CHECK_STACK_UPGRADE = \"Checks for upgrade options by name\";\n         public static final String STACK_UPGRADE = \"Upgrades a cluster to the latest CM or CDH version\";\n         public static final String LIST_RETRYABLE_FLOWS = \"List retryable failed flows\";\n-        public static final String DATABASE_BACKUP = \"performs a backup of database to a provided location\";\n-        public static final String DATABASE_RESTORE = \"performs a restore of database from a provided location\";\n+        public static final String DATABASE_BACKUP = \"Performs a backup of database to a provided location\";\n+        public static final String DATABASE_RESTORE = \"Performs a restore of database from a provided location\";\n     }\n \n     public static class ClusterOpDescription {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDM1MDc2OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r440350769", "bodyText": "This is a general comment for the review about how the status works on the cloudbreak side. It might or might not have any affect on what you do with status in your code. But on the cloudbreak side, there is no separate states of requested/started and in-progress. By the time the flow advances to the point where it's updating the stack status, the operation is already in progress. So in my version of these status messages, I had:\nBACKUP_IN_PROGRESS(StatusKind.PROGRESS), BACKUP_FINISHED(StatusKind.FINAL), BACKUP_FAILED(StatusKind.FINAL), RESTORE_IN_PROGRESS(StatusKind.PROGRESS), RESTORE_FINISHED(StatusKind.FINAL), RESTORE_FAILED(StatusKind.FINAL);\nI see you have multiple places where you have a separate start state, and an in-progress state. For the datalake service I think that makes sense, since you can mark it as started as soon as you get the request, and in-progress when you get the flow identifier back from cloudbreak. I just wanted to give you a heads up that cloudbreak won't be using the REQUESTED stattus.", "author": "hreeve-cloudera", "createdAt": "2020-06-15T18:00:08Z", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java", "diffHunk": "@@ -12,7 +12,13 @@\n     AVAILABLE(StatusKind.FINAL),\n     UPDATE_IN_PROGRESS(StatusKind.PROGRESS),\n     UPDATE_REQUESTED(StatusKind.PROGRESS),\n+    BACKUP_REQUESTED(StatusKind.PROGRESS),", "originalCommit": "193405603e46ccc9be38527729240556706c3fe6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQyNjY3Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r440426673", "bodyText": "I just followed the states defined for UPDATE. UPDATE has UPDATE_REQUESTED and UPDATE_IN_PROGRESS etc.\nI can update the patch accordingly.", "author": "kkalvagadda1", "createdAt": "2020-06-15T20:25:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDM1MDc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQyODgxNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r440428815", "bodyText": "I just followed the states defined for UPDATE. It has UPDATE_REQUESTED and UPDATE_IN_PROGRESS etc.\nIf your patch is not going to have the REQUESTED state, I will remove it.", "author": "kkalvagadda1", "createdAt": "2020-06-15T20:30:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDM1MDc2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "0d0152ccd99c44623234b376e8701f5ef0328a1b", "chunk": "diff --git a/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java b/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java\nindex 12691515ee..c30db0670b 100644\n--- a/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java\n+++ b/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/common/Status.java\n\n@@ -12,9 +12,7 @@ public enum Status {\n     AVAILABLE(StatusKind.FINAL),\n     UPDATE_IN_PROGRESS(StatusKind.PROGRESS),\n     UPDATE_REQUESTED(StatusKind.PROGRESS),\n-    BACKUP_REQUESTED(StatusKind.PROGRESS),\n     BACKUP_IN_PROGRESS(StatusKind.PROGRESS),\n-    RESTORE_REQUESTED(StatusKind.PROGRESS),\n     RESTORE_IN_PROGRESS(StatusKind.PROGRESS),\n     UPDATE_FAILED(StatusKind.FINAL),\n     BACKUP_FAILED(StatusKind.FINAL),\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQwODYwNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r440408605", "bodyText": "To match REST conventions and StackV4Endpoint naming conventions:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @POST\n          \n          \n            \n                @POST\n          \n          \n            \n                @Path(\"{name}/database_backup\")\n          \n          \n            \n                @Produces(MediaType.APPLICATION_JSON)\n          \n          \n            \n                @ApiOperation(value = DATABASE_BACKUP, nickname = \"databaseBackup\")\n          \n          \n            \n                BackupV4Response backupDatabaseByName(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name,\n          \n          \n            \n                        @QueryParam(\"location\") String location, @QueryParam(\"backupId\") String backupId);\n          \n          \n            \n            \n          \n          \n            \n                @POST\n          \n          \n            \n                @Path(\"{name}/database_restore\")\n          \n          \n            \n                @Produces(MediaType.APPLICATION_JSON)\n          \n          \n            \n                @ApiOperation(value = DATABASE_RESTORE, nickname = \"databaseRestore\")\n          \n          \n            \n                RestoreV4Response restoreDatabaseByName(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name,\n          \n          \n            \n                        @QueryParam(\"location\") String location, @QueryParam(\"backupId\") String backupId);", "author": "hreeve-cloudera", "createdAt": "2020-06-15T19:49:35Z", "path": "core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java", "diffHunk": "@@ -269,4 +273,17 @@ FlowIdentifier setClusterMaintenanceMode(@PathParam(\"workspaceId\") Long workspac\n     @ApiOperation(value = UPDATE_SALT, nickname = \"updateSaltByName\")\n     FlowIdentifier updateSaltByName(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name);\n \n+    @POST", "originalCommit": "193405603e46ccc9be38527729240556706c3fe6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQyOTg4OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r440429888", "bodyText": "Basically the suggestion is to accepted location and backup-id as query parameters, right.", "author": "kkalvagadda1", "createdAt": "2020-06-15T20:32:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQwODYwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "0d0152ccd99c44623234b376e8701f5ef0328a1b", "chunk": "diff --git a/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java b/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java\nindex 84c7df330c..d42b4682ff 100644\n--- a/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java\n+++ b/core-api/src/main/java/com/sequenceiq/cloudbreak/api/endpoint/v4/stacks/StackV4Endpoint.java\n\n@@ -277,13 +277,23 @@ public interface StackV4Endpoint {\n     @Path(\"{name}/database_backup\")\n     @Produces(MediaType.APPLICATION_JSON)\n     @ApiOperation(value = DATABASE_BACKUP, nickname = \"databaseBackup\")\n+<<<<<<< HEAD\n+    BackupV4Response backupDatabaseByName(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name,\n+            @QueryParam(\"backupLocation\") String backupLocation, @QueryParam(\"backupId\") String backupId);\n+=======\n     BackupV4Response backupDatabase(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name,\n             String backupLocation, String backupId);\n+>>>>>>> CB-7212: Add datalake service changes to perform database backup/restore.\n \n     @POST\n     @Path(\"{name}/database_restore\")\n     @Produces(MediaType.APPLICATION_JSON)\n     @ApiOperation(value = DATABASE_RESTORE, nickname = \"databaseRestore\")\n+<<<<<<< HEAD\n+    RestoreV4Response restoreDatabaseByName(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name,\n+            @QueryParam(\"backupLocation\") String backupLocation, @QueryParam(\"backupId\") String backupId);\n+=======\n     RestoreV4Response restoreDatabase(@PathParam(\"workspaceId\") Long workspaceId, @PathParam(\"name\") String name,\n             String backupLocation, String backupId);\n+>>>>>>> CB-7212: Add datalake service changes to perform database backup/restore.\n }\n"}}, {"oid": "0d0152ccd99c44623234b376e8701f5ef0328a1b", "url": "https://github.com/hortonworks/cloudbreak/commit/0d0152ccd99c44623234b376e8701f5ef0328a1b", "message": "CB-7212: Add datalake service changes to perform database backup/restore.\n\nAdded changes to accept the backup-id and pass it to CB.", "committedDate": "2020-06-17T12:14:26Z", "type": "forcePushed"}, {"oid": "4f2d9c115f912bb9ba9bc34022900a36c862928b", "url": "https://github.com/hortonworks/cloudbreak/commit/4f2d9c115f912bb9ba9bc34022900a36c862928b", "message": "CB-7212: Add datalake service changes to perform database backup/restore.\n\nAdded changes to accept the backup-id and pass it to CB.", "committedDate": "2020-06-17T15:11:03Z", "type": "forcePushed"}, {"oid": "878a27e569cf3d3847035d1e04140228710f8881", "url": "https://github.com/hortonworks/cloudbreak/commit/878a27e569cf3d3847035d1e04140228710f8881", "message": "CB-7212: Add datalake service changes to perform database backup/restore.\n\nAdded changes to accept the backup-id and pass it to CB.", "committedDate": "2020-06-17T15:50:16Z", "type": "forcePushed"}, {"oid": "c2b01428e259a1a1565101b57a98c9371b5fd157", "url": "https://github.com/hortonworks/cloudbreak/commit/c2b01428e259a1a1565101b57a98c9371b5fd157", "message": "fixed a flaky test(CloudStorageValidatorTest).", "committedDate": "2020-06-18T14:51:29Z", "type": "forcePushed"}, {"oid": "cc6825762f7475cf94b1e98379c24a3f7b5cd2c8", "url": "https://github.com/hortonworks/cloudbreak/commit/cc6825762f7475cf94b1e98379c24a3f7b5cd2c8", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-18T14:55:50Z", "type": "forcePushed"}, {"oid": "e2cf07a07d0db9bd403a8fc69fdb8a98e71270dc", "url": "https://github.com/hortonworks/cloudbreak/commit/e2cf07a07d0db9bd403a8fc69fdb8a98e71270dc", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-18T14:58:38Z", "type": "forcePushed"}, {"oid": "22ed8587748ab6331641c647bad02daf3f52df0d", "url": "https://github.com/hortonworks/cloudbreak/commit/22ed8587748ab6331641c647bad02daf3f52df0d", "message": "Unit test fix", "committedDate": "2020-06-19T11:18:07Z", "type": "forcePushed"}, {"oid": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "url": "https://github.com/hortonworks/cloudbreak/commit/52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-22T03:24:35Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3MzQ2Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444073463", "bodyText": "this should be getBackupDatabaseStatusByName instead", "author": "pdarvasi", "createdAt": "2020-06-23T09:02:13Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java", "diffHunk": "@@ -246,24 +250,31 @@ public FlowIdentifier stopByCrn(@ResourceCrn String crn) {\n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.BACKUP_DATALAKE)\n     public SdxDatabaseBackupResponse backupDatabaseByName(@ResourceName String name, String backupId, String backupLocation) {\n-        return null;\n+        String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n+        SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n+        return sdxDrService.triggerDatabaseBackup(sdxCluster, backupId, backupLocation);\n     }\n \n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.RESTORE_DATALAKE)\n     public SdxDatabaseRestoreResponse restoreDatabaseByName(@ResourceName String name, String backupId, String backupLocation) {\n-        return null;\n+        String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n+        SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n+        return sdxDrService.triggerDatabaseRestore(sdxCluster, backupId, backupLocation);\n     }\n \n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.BACKUP_DATALAKE)\n     public SdxDatabaseBackupStatusResponse backupDatabaseStatusByName(@ResourceName String name, String operationId) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIzMTQyOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444231429", "bodyText": "will fix.", "author": "kkalvagadda1", "createdAt": "2020-06-23T13:39:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3MzQ2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java b/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java\nindex 57a082d2ed..37266a5bb3 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java\n\n@@ -252,7 +252,7 @@ public class SdxController implements SdxEndpoint {\n     public SdxDatabaseBackupResponse backupDatabaseByName(@ResourceName String name, String backupId, String backupLocation) {\n         String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n         SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n-        return sdxDrService.triggerDatabaseBackup(sdxCluster, backupId, backupLocation);\n+        return sdxDatabaseDrService.triggerDatabaseBackup(sdxCluster, backupId, backupLocation);\n     }\n \n     @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3Mzc4MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444073780", "bodyText": "this should be getRestoreDatabaseStatusByName instead", "author": "pdarvasi", "createdAt": "2020-06-23T09:02:42Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java", "diffHunk": "@@ -246,24 +250,31 @@ public FlowIdentifier stopByCrn(@ResourceCrn String crn) {\n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.BACKUP_DATALAKE)\n     public SdxDatabaseBackupResponse backupDatabaseByName(@ResourceName String name, String backupId, String backupLocation) {\n-        return null;\n+        String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n+        SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n+        return sdxDrService.triggerDatabaseBackup(sdxCluster, backupId, backupLocation);\n     }\n \n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.RESTORE_DATALAKE)\n     public SdxDatabaseRestoreResponse restoreDatabaseByName(@ResourceName String name, String backupId, String backupLocation) {\n-        return null;\n+        String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n+        SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n+        return sdxDrService.triggerDatabaseRestore(sdxCluster, backupId, backupLocation);\n     }\n \n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.BACKUP_DATALAKE)\n     public SdxDatabaseBackupStatusResponse backupDatabaseStatusByName(@ResourceName String name, String operationId) {\n-        return null;\n+        String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n+        SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n+        return sdxDrService.getDatabaseBackupStatus(sdxCluster, operationId);\n     }\n \n     @Override\n     @CheckPermissionByAccount(action = AuthorizationResourceAction.RESTORE_DATALAKE)\n     public SdxDatabaseRestoreStatusResponse restoreDatabaseStatusByName(@ResourceName String name, String operationId) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIzMTQ4MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444231481", "bodyText": "will fix.", "author": "kkalvagadda1", "createdAt": "2020-06-23T13:39:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3Mzc4MA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java b/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java\nindex 57a082d2ed..37266a5bb3 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/controller/sdx/SdxController.java\n\n@@ -252,7 +252,7 @@ public class SdxController implements SdxEndpoint {\n     public SdxDatabaseBackupResponse backupDatabaseByName(@ResourceName String name, String backupId, String backupLocation) {\n         String userCrn = ThreadBasedUserCrnProvider.getUserCrn();\n         SdxCluster sdxCluster = sdxService.getSdxByNameInAccount(userCrn, name);\n-        return sdxDrService.triggerDatabaseBackup(sdxCluster, backupId, backupLocation);\n+        return sdxDatabaseDrService.triggerDatabaseBackup(sdxCluster, backupId, backupLocation);\n     }\n \n     @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NjcyMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444076722", "bodyText": "FlowIdentifier should be returned here, the operationId, should be passed as parameter so that notify() can be used instead of notifyDatabaseDrEvent()", "author": "pdarvasi", "createdAt": "2020-06-23T09:07:41Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java", "diffHunk": "@@ -104,6 +109,18 @@ public FlowIdentifier triggerSdxStopFlow(SdxCluster cluster) {\n         return notify(selector, new SdxStartStopEvent(selector, cluster.getId(), userId));\n     }\n \n+    public String triggerDatalakeDatabaseBackupFlow(Long sdxId, String backupId, String backupLocation) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIzMjk0MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444232940", "bodyText": "Why should FlowIdentifier return when it is not used? API invoking triggerDatalakeDatabaseBackupFlow uses operationId instead of flowIdentifier.\nI can make changes to avoid the need for notifyDatabaseDrEvent. Does that address your concern?", "author": "kkalvagadda1", "createdAt": "2020-06-23T13:41:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NjcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4NDEwNA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444484104", "bodyText": "I have removed method \"notifyDatabaseDrEvent\" and re-used \"notify\".", "author": "kkalvagadda1", "createdAt": "2020-06-23T20:21:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NjcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3OTA2OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444979069", "bodyText": "will update.", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:25:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NjcyMg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\nindex 732f24296b..96284d85ce 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\n\n@@ -109,16 +108,14 @@ public class SdxReactorFlowManager {\n         return notify(selector, new SdxStartStopEvent(selector, cluster.getId(), userId));\n     }\n \n-    public String triggerDatalakeDatabaseBackupFlow(Long sdxId, String backupId, String backupLocation) {\n+    public FlowIdentifier triggerDatalakeDatabaseBackupFlow(DatalakeDatabaseBackupStartEvent startEvent) {\n         String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n-        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n-        return notifyDatabaseDrEvent(selector, new DatalakeDatabaseBackupStartEvent(selector, sdxId, userId, backupId, backupLocation));\n+        return notify(selector, startEvent);\n     }\n \n-    public String triggerDatalakeDatabaseRestoreFlow(Long sdxId, String backupId, String backupLocation) {\n+    public FlowIdentifier triggerDatalakeDatabaseRestoreFlow(DatalakeDatabaseRestoreStartEvent startEvent) {\n         String selector = DATALAKE_DATABASE_RESTORE_EVENT.event();\n-        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n-        return notifyDatabaseDrEvent(selector, new DatalakeDatabaseRestoreStartEvent(selector, sdxId, userId, backupId, backupLocation));\n+        return notify(selector, startEvent);\n     }\n \n     private FlowIdentifier notify(String selector, SdxEvent acceptable) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NjgxMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444076812", "bodyText": "FlowIdentifier should be returned here, the operationId, should be passed as parameter so that notify() can be used instead of notifyDatabaseDrEvent()", "author": "pdarvasi", "createdAt": "2020-06-23T09:07:53Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java", "diffHunk": "@@ -104,6 +109,18 @@ public FlowIdentifier triggerSdxStopFlow(SdxCluster cluster) {\n         return notify(selector, new SdxStartStopEvent(selector, cluster.getId(), userId));\n     }\n \n+    public String triggerDatalakeDatabaseBackupFlow(Long sdxId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        return notifyDatabaseDrEvent(selector, new DatalakeDatabaseBackupStartEvent(selector, sdxId, userId, backupId, backupLocation));\n+    }\n+\n+    public String triggerDatalakeDatabaseRestoreFlow(Long sdxId, String backupId, String backupLocation) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3ODk4NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444978985", "bodyText": "will update.", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NjgxMg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\nindex 732f24296b..96284d85ce 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\n\n@@ -109,16 +108,14 @@ public class SdxReactorFlowManager {\n         return notify(selector, new SdxStartStopEvent(selector, cluster.getId(), userId));\n     }\n \n-    public String triggerDatalakeDatabaseBackupFlow(Long sdxId, String backupId, String backupLocation) {\n+    public FlowIdentifier triggerDatalakeDatabaseBackupFlow(DatalakeDatabaseBackupStartEvent startEvent) {\n         String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n-        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n-        return notifyDatabaseDrEvent(selector, new DatalakeDatabaseBackupStartEvent(selector, sdxId, userId, backupId, backupLocation));\n+        return notify(selector, startEvent);\n     }\n \n-    public String triggerDatalakeDatabaseRestoreFlow(Long sdxId, String backupId, String backupLocation) {\n+    public FlowIdentifier triggerDatalakeDatabaseRestoreFlow(DatalakeDatabaseRestoreStartEvent startEvent) {\n         String selector = DATALAKE_DATABASE_RESTORE_EVENT.event();\n-        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n-        return notifyDatabaseDrEvent(selector, new DatalakeDatabaseRestoreStartEvent(selector, sdxId, userId, backupId, backupLocation));\n+        return notify(selector, startEvent);\n     }\n \n     private FlowIdentifier notify(String selector, SdxEvent acceptable) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NzA0Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444077043", "bodyText": "this is not needed if operationId is passed as parameter", "author": "pdarvasi", "createdAt": "2020-06-23T09:08:19Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java", "diffHunk": "@@ -132,4 +149,30 @@ private FlowIdentifier notify(String selector, SdxEvent acceptable) {\n         }\n \n     }\n+\n+    String notifyDatabaseDrEvent(String selector,  DatalakeDatabaseDrStartBaseEvent acceptable) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4NDM1MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444484351", "bodyText": "will remove the method.", "author": "kkalvagadda1", "createdAt": "2020-06-23T20:22:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA3NzA0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\nindex 732f24296b..96284d85ce 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/SdxReactorFlowManager.java\n\n@@ -149,30 +146,4 @@ public class SdxReactorFlowManager {\n         }\n \n     }\n-\n-    String notifyDatabaseDrEvent(String selector,  DatalakeDatabaseDrStartBaseEvent acceptable) {\n-        Map<String, Object> flowTriggerUserCrnHeader = Map.of(FlowConstants.FLOW_TRIGGER_USERCRN, acceptable.getUserId());\n-        Event<Acceptable> event = eventFactory.createEventWithErrHandler(flowTriggerUserCrnHeader, acceptable);\n-\n-        reactor.notify(selector, event);\n-        try {\n-            FlowAcceptResult accepted = (FlowAcceptResult) event.getData().accepted().await(WAIT_FOR_ACCEPT, TimeUnit.SECONDS);\n-            if (accepted == null) {\n-                throw new FlowNotAcceptedException(String.format(\"Timeout happened when trying to start the flow for sdx cluster %s.\",\n-                        event.getData().getResourceId()));\n-            } else {\n-                switch (accepted.getResultType()) {\n-                    case ALREADY_EXISTING_FLOW:\n-                        throw new FlowsAlreadyRunningException(String.format(\"Sdx cluster %s has flows under operation, request not allowed.\",\n-                                event.getData().getResourceId()));\n-                    case RUNNING_IN_FLOW:\n-                        return acceptable.getDrStatus().getOperationId();\n-                    default:\n-                        throw new IllegalStateException(\"Unsupported accept result type: \" + accepted.getClass());\n-                }\n-            }\n-        } catch (InterruptedException e) {\n-            throw new CloudbreakApiException(e.getMessage());\n-        }\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4NTE0Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444085147", "bodyText": "shouldn't we set the status (sdxDrService.updateDatabaseStatusEntry() to INPROGRESS here?", "author": "pdarvasi", "createdAt": "2020-06-23T09:21:46Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,173 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseBackupActions {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseBackupActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_START_STATE\")\n+    public Action<?, ?> datalakeBackup() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Datalake database backup has been started for {}\", payload.getResourceId());\n+                sdxDrService.databaseBackup(payload.getDrStatus(),\n+                        payload.getResourceId(),\n+                        payload.getBackupId(),\n+                        payload.getBackupLocation());\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupCouldNotStartEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE\")\n+    public Action<?, ?> datalakebackupInProgress() {\n+        return new AbstractSdxAction<>(SdxEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext, SdxEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, SdxEvent payload, Map<Object, Object> variables) {\n+                LOGGER.info(\"Datalake database backup is in progress for {} \", payload.getResourceId());", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDIzNzA3Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444237072", "bodyText": "yes, you are right. I will fix it.", "author": "kkalvagadda1", "createdAt": "2020-06-23T13:47:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4NTE0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\nindex 58873bdb64..4111a61d71 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n\n@@ -16,7 +16,7 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTYzMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444089630", "bodyText": "this doExecute() is the same as the backupCouldNotStart() one, could you pls. extract it to a common method?", "author": "pdarvasi", "createdAt": "2020-06-23T09:29:00Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,173 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseBackupActions {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseBackupActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_START_STATE\")\n+    public Action<?, ?> datalakeBackup() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Datalake database backup has been started for {}\", payload.getResourceId());\n+                sdxDrService.databaseBackup(payload.getDrStatus(),\n+                        payload.getResourceId(),\n+                        payload.getBackupId(),\n+                        payload.getBackupLocation());\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupCouldNotStartEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE\")\n+    public Action<?, ?> datalakebackupInProgress() {\n+        return new AbstractSdxAction<>(SdxEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext, SdxEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, SdxEvent payload, Map<Object, Object> variables) {\n+                LOGGER.info(\"Datalake database backup is in progress for {} \", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sendEvent(context, DatalakeDatabaseBackupWaitRequest.from(context, operationId));\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(SdxEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupFailedEvent.from(payload, ex);\n+\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_COULD_NOT_START_STATE\")\n+    public Action<?, ?> backupCouldNotStart() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupCouldNotStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupCouldNotStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupCouldNotStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database backup could not be started for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, payload.getException().getMessage());\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupCouldNotStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_FINISHED_STATE\")\n+    public Action<?, ?> finishedBackupAction() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupSuccessEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupSuccessEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupSuccessEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Sdx database backup is finalized with sdx id: {}\", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.SUCCEEDED, null);\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupSuccessEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_FAILED_STATE\")\n+    public Action<?, ?> backupFailed() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupFailedEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupFailedEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupFailedEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4ODgwNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444488805", "bodyText": "I understand that the code is duplicate. In fact, I tried to do it before but there is an issue.\nThis code uses \"sentEvent\" which is an implementation in \"AbstractAction\". It is available in a private API in DatalakeDatabaseBackupActions.", "author": "kkalvagadda1", "createdAt": "2020-06-23T20:31:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTYzMA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\nindex 58873bdb64..4111a61d71 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n\n@@ -16,7 +16,7 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTgzNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444089836", "bodyText": "Not DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT instead?", "author": "pdarvasi", "createdAt": "2020-06-23T09:29:24Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,173 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseBackupActions {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseBackupActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_START_STATE\")\n+    public Action<?, ?> datalakeBackup() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Datalake database backup has been started for {}\", payload.getResourceId());\n+                sdxDrService.databaseBackup(payload.getDrStatus(),\n+                        payload.getResourceId(),\n+                        payload.getBackupId(),\n+                        payload.getBackupLocation());\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupCouldNotStartEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE\")\n+    public Action<?, ?> datalakebackupInProgress() {\n+        return new AbstractSdxAction<>(SdxEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext, SdxEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, SdxEvent payload, Map<Object, Object> variables) {\n+                LOGGER.info(\"Datalake database backup is in progress for {} \", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sendEvent(context, DatalakeDatabaseBackupWaitRequest.from(context, operationId));\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(SdxEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupFailedEvent.from(payload, ex);\n+\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_COULD_NOT_START_STATE\")\n+    public Action<?, ?> backupCouldNotStart() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupCouldNotStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupCouldNotStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupCouldNotStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database backup could not be started for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, payload.getException().getMessage());\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupCouldNotStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_FINISHED_STATE\")\n+    public Action<?, ?> finishedBackupAction() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupSuccessEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupSuccessEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupSuccessEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Sdx database backup is finalized with sdx id: {}\", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.SUCCEEDED, null);\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseBackupSuccessEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseBackupFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_FAILED_STATE\")\n+    public Action<?, ?> backupFailed() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupFailedEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupFailedEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupFailedEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database backup failed for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, exception.getLocalizedMessage());\n+                sendEvent(context, DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT.event(), payload);", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI0Mzc5Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444243793", "bodyText": "Just for understanding sake, Is \"DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT\" used only in success cases?", "author": "kkalvagadda1", "createdAt": "2020-06-23T13:56:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTgzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDkwMDk0Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444900942", "bodyText": "Yes, we use it like that", "author": "pdarvasi", "createdAt": "2020-06-24T13:40:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA4OTgzNg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\nindex 58873bdb64..4111a61d71 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n\n@@ -16,7 +16,7 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5MjczMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444092730", "bodyText": "Not DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT instead?", "author": "pdarvasi", "createdAt": "2020-06-23T09:34:23Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupFlowConfig.java", "diffHunk": "@@ -0,0 +1,98 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FAILED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_BACKUP_COULD_NOT_START_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_BACKUP_FAILED_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_BACKUP_FINISHED_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_BACKUP_START_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.FINAL_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.INIT_STATE;\n+\n+import java.util.List;\n+\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.flow.core.config.AbstractFlowConfiguration;\n+import com.sequenceiq.flow.core.config.RetryableFlowConfiguration;\n+\n+@Component\n+public class DatalakeDatabaseBackupFlowConfig extends AbstractFlowConfiguration<DatalakeDatabaseDrState, DatalakeDatabaseDrEvent>\n+        implements RetryableFlowConfiguration<DatalakeDatabaseDrEvent> {\n+\n+    private static final List<Transition<DatalakeDatabaseDrState, DatalakeDatabaseDrEvent>> TRANSITIONS =\n+            new Transition.Builder<DatalakeDatabaseDrState, DatalakeDatabaseDrEvent>()\n+                    .defaultFailureEvent(DATALAKE_DATABASE_BACKUP_FAILED_EVENT)\n+\n+                    .from(INIT_STATE)\n+                    .to(DATALAKE_DATABASE_BACKUP_START_STATE)\n+                    .event(DATALAKE_DATABASE_BACKUP_EVENT).noFailureEvent()\n+\n+                    .from(DATALAKE_DATABASE_BACKUP_START_STATE)\n+                    .to(DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE)\n+                    .event(DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT)\n+                    .failureState(DATALAKE_DATABASE_BACKUP_COULD_NOT_START_STATE)\n+                    .failureEvent(DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT)\n+\n+                    .from(DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE)\n+                    .to(DATALAKE_DATABASE_BACKUP_FINISHED_STATE)\n+                    .event(DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT)\n+                    .failureState(DATALAKE_DATABASE_BACKUP_FAILED_STATE)\n+                    .failureEvent(DATALAKE_DATABASE_BACKUP_FAILED_EVENT)\n+\n+                    .from(DATALAKE_DATABASE_BACKUP_FINISHED_STATE)\n+                    .to(FINAL_STATE)\n+                    .event(DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT).defaultFailureEvent()\n+\n+                    .from(DATALAKE_DATABASE_BACKUP_FAILED_STATE)\n+                    .to(FINAL_STATE)\n+                    .event(DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT).defaultFailureEvent()", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupFlowConfig.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupFlowConfig.java\nindex 7ee4c88cfd..95367f48fd 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupFlowConfig.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupFlowConfig.java\n\n@@ -53,7 +53,7 @@ public class DatalakeDatabaseBackupFlowConfig extends AbstractFlowConfiguration<\n \n                     .from(DATALAKE_DATABASE_BACKUP_FAILED_STATE)\n                     .to(FINAL_STATE)\n-                    .event(DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT).defaultFailureEvent()\n+                    .event(DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT).defaultFailureEvent()\n \n                     .build();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NTYwMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444095600", "bodyText": "Shouldn't we upgrade to INPROGRESS here also with updateDatabaseStatusEntry?", "author": "pdarvasi", "createdAt": "2020-06-23T09:39:10Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,170 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseRestoreActions {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseRestoreActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_START_STATE\")\n+    public Action<?, ?> datalakeRestore() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseRestoreStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Datalake database restore has been started for {}\", payload.getResourceId());\n+                sdxDrService.databaseRestore(payload.getDrStatus(),\n+                        payload.getResourceId(),\n+                        payload.getBackupId(),\n+                        payload.getBackupLocation());\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreCouldNotStartEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE\")\n+    public Action<?, ?> datalakeRestoreInProgress() {\n+        return new AbstractSdxAction<>(SdxEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext, SdxEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, SdxEvent payload, Map<Object, Object> variables) {\n+                LOGGER.info(\"Datalake database restore is in progress for {} \", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sendEvent(context, DatalakeDatabaseRestoreWaitRequest.from(context, operationId));", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI0NDA4NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444244084", "bodyText": "yes, you are right. I will fix it.", "author": "kkalvagadda1", "createdAt": "2020-06-23T13:56:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NTYwMA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\nindex 3c9c5098f5..d0f0c42e43 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\n\n@@ -16,16 +16,16 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n-import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n import com.sequenceiq.datalake.service.AbstractSdxAction;\n-import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDatabaseDrService;\n import com.sequenceiq.flow.core.FlowEvent;\n import com.sequenceiq.flow.core.FlowParameters;\n import com.sequenceiq.flow.core.FlowState;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NjkxMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444096913", "bodyText": "How about setting the SDX status here to failed as well with sdxStatusService.setStatusForDatalakeAndNotify()?", "author": "pdarvasi", "createdAt": "2020-06-23T09:41:29Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,170 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseRestoreActions {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseRestoreActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_START_STATE\")\n+    public Action<?, ?> datalakeRestore() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseRestoreStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Datalake database restore has been started for {}\", payload.getResourceId());\n+                sdxDrService.databaseRestore(payload.getDrStatus(),\n+                        payload.getResourceId(),\n+                        payload.getBackupId(),\n+                        payload.getBackupLocation());\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreCouldNotStartEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE\")\n+    public Action<?, ?> datalakeRestoreInProgress() {\n+        return new AbstractSdxAction<>(SdxEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext, SdxEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, SdxEvent payload, Map<Object, Object> variables) {\n+                LOGGER.info(\"Datalake database restore is in progress for {} \", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sendEvent(context, DatalakeDatabaseRestoreWaitRequest.from(context, operationId));\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(SdxEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_COULD_NOT_START_STATE\")\n+    public Action<?, ?> restoreCouldNotStart() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreCouldNotStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreCouldNotStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreCouldNotStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database restore could not be started for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, exception.getLocalizedMessage());\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreCouldNotStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> finishedRestoreAction() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreSuccessEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreSuccessEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreSuccessEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Sdx database restore is finalized with sdx id: {}\", payload.getResourceId());\n+                sdxDrService.updateDatabaseStatusEntry(payload.getOperationId(), SdxDatabaseDrStatus.Status.SUCCEEDED, null);\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreSuccessEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_FAILED_STATE\")\n+    public Action<?, ?> restoreFailed() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreFailedEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreFailedEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreFailedEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database restore could not be started for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, exception.getLocalizedMessage());", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI0NzczMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444247730", "bodyText": "database backup/restore is one part of the datalake backup restore. There will be a separate patch to update the datalake status using SdxStatusService which will be invoked by datalakedr service which orchestrates the datalake backup and restore.", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:01:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5NjkxMw=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\nindex 3c9c5098f5..d0f0c42e43 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\n\n@@ -16,16 +16,16 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n-import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n import com.sequenceiq.datalake.service.AbstractSdxAction;\n-import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDatabaseDrService;\n import com.sequenceiq.flow.core.FlowEvent;\n import com.sequenceiq.flow.core.FlowParameters;\n import com.sequenceiq.flow.core.FlowState;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5ODAzNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444098036", "bodyText": "this should be FAILED_HANDLED_EVENT instead", "author": "pdarvasi", "createdAt": "2020-06-23T09:43:26Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java", "diffHunk": "@@ -0,0 +1,170 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseRestoreActions {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseRestoreActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_START_STATE\")\n+    public Action<?, ?> datalakeRestore() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseRestoreStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Datalake database restore has been started for {}\", payload.getResourceId());\n+                sdxDrService.databaseRestore(payload.getDrStatus(),\n+                        payload.getResourceId(),\n+                        payload.getBackupId(),\n+                        payload.getBackupLocation());\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreCouldNotStartEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE\")\n+    public Action<?, ?> datalakeRestoreInProgress() {\n+        return new AbstractSdxAction<>(SdxEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext, SdxEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, SdxEvent payload, Map<Object, Object> variables) {\n+                LOGGER.info(\"Datalake database restore is in progress for {} \", payload.getResourceId());\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sendEvent(context, DatalakeDatabaseRestoreWaitRequest.from(context, operationId));\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(SdxEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_COULD_NOT_START_STATE\")\n+    public Action<?, ?> restoreCouldNotStart() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreCouldNotStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreCouldNotStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreCouldNotStartEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database restore could not be started for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, exception.getLocalizedMessage());\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreCouldNotStartEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_FINISHED_STATE\")\n+    public Action<?, ?> finishedRestoreAction() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreSuccessEvent.class) {\n+\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreSuccessEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreSuccessEvent payload, Map<Object, Object> variables) throws Exception {\n+                LOGGER.info(\"Sdx database restore is finalized with sdx id: {}\", payload.getResourceId());\n+                sdxDrService.updateDatabaseStatusEntry(payload.getOperationId(), SdxDatabaseDrStatus.Status.SUCCEEDED, null);\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT.event(), payload);\n+            }\n+\n+            @Override\n+            protected Object getFailurePayload(DatalakeDatabaseRestoreSuccessEvent payload, Optional<SdxContext> flowContext, Exception ex) {\n+                return DatalakeDatabaseRestoreFailedEvent.from(payload, ex);\n+            }\n+        };\n+    }\n+\n+    @Bean(name = \"DATALAKE_DATABASE_RESTORE_FAILED_STATE\")\n+    public Action<?, ?> restoreFailed() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseRestoreFailedEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseRestoreFailedEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseRestoreFailedEvent payload, Map<Object, Object> variables) throws Exception {\n+                Exception exception = payload.getException();\n+                LOGGER.error(\"Datalake database restore could not be started for datalake with id: {}\", payload.getResourceId(), exception);\n+                String operationId = (String) variables.get(OPERATION_ID);\n+                sdxDrService.updateDatabaseStatusEntry(operationId, SdxDatabaseDrStatus.Status.FAILED, exception.getLocalizedMessage());\n+                sendEvent(context, DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT.event(), payload);", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\nindex 3c9c5098f5..d0f0c42e43 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreActions.java\n\n@@ -16,16 +16,16 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n-import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n import com.sequenceiq.datalake.service.AbstractSdxAction;\n-import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDatabaseDrService;\n import com.sequenceiq.flow.core.FlowEvent;\n import com.sequenceiq.flow.core.FlowParameters;\n import com.sequenceiq.flow.core.FlowState;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDA5ODE4OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444098188", "bodyText": "this should be FAILED_HANDLED_EVENT instead", "author": "pdarvasi", "createdAt": "2020-06-23T09:43:42Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreFlowConfig.java", "diffHunk": "@@ -0,0 +1,98 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FAILED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_RESTORE_COULD_NOT_START_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_RESTORE_FAILED_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_RESTORE_FINISHED_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.DATALAKE_DATABASE_RESTORE_START_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.FINAL_STATE;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrState.INIT_STATE;\n+\n+import java.util.List;\n+\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.flow.core.config.AbstractFlowConfiguration;\n+import com.sequenceiq.flow.core.config.RetryableFlowConfiguration;\n+\n+@Component\n+public class DatalakeDatabaseRestoreFlowConfig extends AbstractFlowConfiguration<DatalakeDatabaseDrState, DatalakeDatabaseDrEvent>\n+        implements RetryableFlowConfiguration<DatalakeDatabaseDrEvent> {\n+\n+    private static final List<Transition<DatalakeDatabaseDrState, DatalakeDatabaseDrEvent>> TRANSITIONS =\n+            new Transition.Builder<DatalakeDatabaseDrState, DatalakeDatabaseDrEvent>()\n+                    .defaultFailureEvent(DATALAKE_DATABASE_RESTORE_FAILED_EVENT)\n+\n+                    .from(INIT_STATE)\n+                    .to(DATALAKE_DATABASE_RESTORE_START_STATE)\n+                    .event(DATALAKE_DATABASE_RESTORE_EVENT).noFailureEvent()\n+\n+                    .from(DATALAKE_DATABASE_RESTORE_START_STATE)\n+                    .to(DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE)\n+                    .event(DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT)\n+                    .failureState(DATALAKE_DATABASE_RESTORE_COULD_NOT_START_STATE)\n+                    .failureEvent(DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT)\n+\n+                    .from(DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE)\n+                    .to(DATALAKE_DATABASE_RESTORE_FINISHED_STATE)\n+                    .event(DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT)\n+                    .failureState(DATALAKE_DATABASE_RESTORE_FAILED_STATE)\n+                    .failureEvent(DATALAKE_DATABASE_RESTORE_FAILED_EVENT)\n+\n+                    .from(DATALAKE_DATABASE_RESTORE_FINISHED_STATE)\n+                    .to(FINAL_STATE)\n+                    .event(DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT).defaultFailureEvent()\n+\n+                    .from(DATALAKE_DATABASE_RESTORE_FAILED_STATE)\n+                    .to(FINAL_STATE)\n+                    .event(DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT).defaultFailureEvent()", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreFlowConfig.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreFlowConfig.java\nindex 827d3931a7..991a996482 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreFlowConfig.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseRestoreFlowConfig.java\n\n@@ -53,7 +53,7 @@ public class DatalakeDatabaseRestoreFlowConfig extends AbstractFlowConfiguration\n \n                     .from(DATALAKE_DATABASE_RESTORE_FAILED_STATE)\n                     .to(FINAL_STATE)\n-                    .event(DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT).defaultFailureEvent()\n+                    .event(DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT).defaultFailureEvent()\n \n                     .build();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMjMxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444102319", "bodyText": "We should include the FlowIdentifier in SdxDatabaseBackupResponse, too", "author": "pdarvasi", "createdAt": "2020-06-23T09:50:43Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3ODY4MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444978681", "bodyText": "will update.", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:25:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMjMxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMjQzNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444102436", "bodyText": "We should include the FlowIdentifier in SdxDatabaseRestoreResponse, too", "author": "pdarvasi", "createdAt": "2020-06-23T09:50:58Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3ODY0OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444978648", "bodyText": "will update.", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:25:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMjQzNg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMzM5MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444103390", "bodyText": "should return FlowIdentifier", "author": "pdarvasi", "createdAt": "2020-06-23T09:52:32Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwMzUwNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444103507", "bodyText": "should return FlowIdentifier", "author": "pdarvasi", "createdAt": "2020-06-23T09:52:43Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwNTYyNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444105625", "bodyText": "We might want to set SDX status to something to indicate the restore with sdxStatusService.setStatusForDatalakeAndNotify(), too", "author": "pdarvasi", "createdAt": "2020-06-23T09:56:13Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI1MDUxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444250519", "bodyText": "database backup/restore is one part of the datalake backup restore. There will be a separate patch to update the datalake status using SdxStatusService which will be invoked by datalakedr service which orchestrates the datalake backup and restore.", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwNTYyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwNjIyMQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444106221", "bodyText": "these 3 lines have multiple occurrences pls extract to a separate method.", "author": "pdarvasi", "createdAt": "2020-06-23T09:57:17Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI2MTI1OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444261259", "bodyText": "will do.", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:20:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwNjIyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwODY5NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444108694", "bodyText": "typo: successful + doe -> for", "author": "pdarvasi", "createdAt": "2020-06-23T10:01:29Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id %d not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in inmemory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (stackAndClusterAvailable(stackV4Response, cluster)) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else {\n+            if (Status.BACKUP_FAILED.equals(stackV4Response.getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getStatus())) {\n+                LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+            } else if (Status.BACKUP_FAILED.equals(stackV4Response.getCluster().getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getCluster().getStatus())) {\n+                LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                        stackV4Response.getCluster().getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+            } else {\n+                if (FINISHED.equals(flowState)) {\n+                    LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+                    return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+                } else {\n+                    return AttemptResults.justContinue();\n+                }\n+            }\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrFailed(SdxCluster sdxCluster, String statusReason, String pollingMessage) {\n+        LOGGER.info(\"{} failed, statusReason: {}\", pollingMessage, statusReason);\n+        return AttemptResults.breakFor(\"SDX \" + pollingMessage + \" failed '\" + sdxCluster.getClusterName() + \"', \" + statusReason);\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrSucceeded(StackV4Response stackV4Response) {\n+        LOGGER.info(\"Database DR operation doe SDX cluster {} is successfull\", stackV4Response.getCluster().getName());", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI2MTU2Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444261562", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:20:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEwODY5NA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExMDUzNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444110536", "bodyText": "we might log this as it should not happen", "author": "pdarvasi", "createdAt": "2020-06-23T10:04:46Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id %d not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in inmemory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (stackAndClusterAvailable(stackV4Response, cluster)) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else {\n+            if (Status.BACKUP_FAILED.equals(stackV4Response.getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getStatus())) {\n+                LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+            } else if (Status.BACKUP_FAILED.equals(stackV4Response.getCluster().getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getCluster().getStatus())) {\n+                LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                        stackV4Response.getCluster().getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+            } else {\n+                if (FINISHED.equals(flowState)) {\n+                    LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+                    return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+                } else {\n+                    return AttemptResults.justContinue();\n+                }\n+            }\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrFailed(SdxCluster sdxCluster, String statusReason, String pollingMessage) {\n+        LOGGER.info(\"{} failed, statusReason: {}\", pollingMessage, statusReason);\n+        return AttemptResults.breakFor(\"SDX \" + pollingMessage + \" failed '\" + sdxCluster.getClusterName() + \"', \" + statusReason);\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrSucceeded(StackV4Response stackV4Response) {\n+        LOGGER.info(\"Database DR operation doe SDX cluster {} is successfull\", stackV4Response.getCluster().getName());\n+        return AttemptResults.finishWith(stackV4Response);\n+    }\n+\n+    private boolean stackAndClusterAvailable(StackV4Response stackV4Response, ClusterV4Response cluster) {\n+        return stackV4Response.getStatus().isAvailable()\n+                && cluster != null\n+                && cluster.getStatus() != null\n+                && cluster.getStatus().isAvailable();\n+    }\n+\n+    /**\n+     * Updates the status of the database backup/restore operation.\n+     * @param operationId Operation Id\n+     * @param status Status of the operation\n+     * @param failedReason Failure reason, if any.\n+     */\n+    public void updateDatabaseStatusEntry(String operationId, SdxDatabaseDrStatus.Status status, String failedReason) {\n+        if (Strings.isNullOrEmpty(operationId)) {\n+            return;", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI2MjcyMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444262720", "bodyText": "will do.", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:21:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExMDUzNg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExMjg3Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444112873", "bodyText": "the first 6 lines of getDatabaseBackupStatus and getDatabaseRestoreStatus are almost the same -> should be extracted to a common method with SdxDatabaseDrStatusTypeEnum as parameter", "author": "pdarvasi", "createdAt": "2020-06-23T10:09:02Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id %d not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in inmemory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (stackAndClusterAvailable(stackV4Response, cluster)) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else {\n+            if (Status.BACKUP_FAILED.equals(stackV4Response.getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getStatus())) {\n+                LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+            } else if (Status.BACKUP_FAILED.equals(stackV4Response.getCluster().getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getCluster().getStatus())) {\n+                LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                        stackV4Response.getCluster().getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+            } else {\n+                if (FINISHED.equals(flowState)) {\n+                    LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+                    return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+                } else {\n+                    return AttemptResults.justContinue();\n+                }\n+            }\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrFailed(SdxCluster sdxCluster, String statusReason, String pollingMessage) {\n+        LOGGER.info(\"{} failed, statusReason: {}\", pollingMessage, statusReason);\n+        return AttemptResults.breakFor(\"SDX \" + pollingMessage + \" failed '\" + sdxCluster.getClusterName() + \"', \" + statusReason);\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrSucceeded(StackV4Response stackV4Response) {\n+        LOGGER.info(\"Database DR operation doe SDX cluster {} is successfull\", stackV4Response.getCluster().getName());\n+        return AttemptResults.finishWith(stackV4Response);\n+    }\n+\n+    private boolean stackAndClusterAvailable(StackV4Response stackV4Response, ClusterV4Response cluster) {\n+        return stackV4Response.getStatus().isAvailable()\n+                && cluster != null\n+                && cluster.getStatus() != null\n+                && cluster.getStatus().isAvailable();\n+    }\n+\n+    /**\n+     * Updates the status of the database backup/restore operation.\n+     * @param operationId Operation Id\n+     * @param status Status of the operation\n+     * @param failedReason Failure reason, if any.\n+     */\n+    public void updateDatabaseStatusEntry(String operationId, SdxDatabaseDrStatus.Status status, String failedReason) {\n+        if (Strings.isNullOrEmpty(operationId)) {\n+            return;\n+        }\n+        SdxDatabaseDrStatus drStatus = sdxDatabaseDrStatusRepository.findSdxDatabaseDrStatusByOperationId(operationId);\n+        drStatus.setStatus(status);\n+        if (!Strings.isNullOrEmpty(failedReason)) {\n+            drStatus.setStatusReason(failedReason);\n+        }\n+        sdxDatabaseDrStatusRepository.save(drStatus);\n+    }\n+\n+    /**\n+     * Gets the status of the database backup operation.\n+     * @param sdxCluster Sdx cluster on which the backup operation is performed.\n+     * @param operationId Operation Id\n+     * @return Backup status\n+     */\n+    public SdxDatabaseBackupStatusResponse getDatabaseBackupStatus(SdxCluster sdxCluster, String operationId) {\n+        SdxDatabaseDrStatus drStatus = sdxDatabaseDrStatusRepository.findSdxDatabaseDrStatusByOperationId(operationId);", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI2NTM4NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444265385", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:25:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExMjg3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExNjI1Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444116256", "bodyText": "you shouldn't specify the name here", "author": "lacikaaa", "createdAt": "2020-06-23T10:15:04Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package com.sequenceiq.datalake.entity;\n+\n+import java.util.UUID;\n+\n+import javax.persistence.Entity;\n+import javax.persistence.EnumType;\n+import javax.persistence.Enumerated;\n+import javax.persistence.GeneratedValue;\n+import javax.persistence.GenerationType;\n+import javax.persistence.Id;\n+import javax.persistence.SequenceGenerator;\n+import javax.persistence.Table;\n+import javax.persistence.UniqueConstraint;\n+import javax.validation.constraints.NotNull;\n+\n+@Entity\n+@Table(name = \"sdxDatabaseDrstatus\", uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI2NzI2Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444267263", "bodyText": "This patch also has the sql file to create table \"sdxDatabaseDrstatus\". Without having the name here, can I assume that the entity would using the table with the name \"sdxDatabaseDrstatus\"?", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:27:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExNjI1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3NDEzNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444974137", "bodyText": "will do.", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:19:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExNjI1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\nindex 311d79cd98..800dded8b4 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n\n@@ -2,9 +2,8 @@ package com.sequenceiq.datalake.entity;\n \n import java.util.UUID;\n \n+import javax.persistence.Convert;\n import javax.persistence.Entity;\n-import javax.persistence.EnumType;\n-import javax.persistence.Enumerated;\n import javax.persistence.GeneratedValue;\n import javax.persistence.GenerationType;\n import javax.persistence.Id;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExNzk3OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444117979", "bodyText": "please move them out from the entity", "author": "lacikaaa", "createdAt": "2020-06-23T10:18:09Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package com.sequenceiq.datalake.entity;\n+\n+import java.util.UUID;\n+\n+import javax.persistence.Entity;\n+import javax.persistence.EnumType;\n+import javax.persistence.Enumerated;\n+import javax.persistence.GeneratedValue;\n+import javax.persistence.GenerationType;\n+import javax.persistence.Id;\n+import javax.persistence.SequenceGenerator;\n+import javax.persistence.Table;\n+import javax.persistence.UniqueConstraint;\n+import javax.validation.constraints.NotNull;\n+\n+@Entity\n+@Table(name = \"sdxDatabaseDrstatus\", uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))\n+public class SdxDatabaseDrStatus {\n+    public enum SdxDatabaseDrStatusTypeEnum {\n+        BACKUP,\n+        RESTORE\n+    }\n+\n+    public enum Status {\n+        INIT,\n+        TRIGGERRED,\n+        INPROGRESS,\n+        SUCCEEDED,\n+        FAILED\n+    }", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3NDAxNA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444374014", "bodyText": "will do.", "author": "kkalvagadda1", "createdAt": "2020-06-23T17:01:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDExNzk3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\nindex 311d79cd98..800dded8b4 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n\n@@ -2,9 +2,8 @@ package com.sequenceiq.datalake.entity;\n \n import java.util.UUID;\n \n+import javax.persistence.Convert;\n import javax.persistence.Entity;\n-import javax.persistence.EnumType;\n-import javax.persistence.Enumerated;\n import javax.persistence.GeneratedValue;\n import javax.persistence.GenerationType;\n import javax.persistence.Id;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyMDI1OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444120259", "bodyText": "please use converter", "author": "lacikaaa", "createdAt": "2020-06-23T10:22:20Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package com.sequenceiq.datalake.entity;\n+\n+import java.util.UUID;\n+\n+import javax.persistence.Entity;\n+import javax.persistence.EnumType;\n+import javax.persistence.Enumerated;\n+import javax.persistence.GeneratedValue;\n+import javax.persistence.GenerationType;\n+import javax.persistence.Id;\n+import javax.persistence.SequenceGenerator;\n+import javax.persistence.Table;\n+import javax.persistence.UniqueConstraint;\n+import javax.validation.constraints.NotNull;\n+\n+@Entity\n+@Table(name = \"sdxDatabaseDrstatus\", uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))\n+public class SdxDatabaseDrStatus {\n+    public enum SdxDatabaseDrStatusTypeEnum {\n+        BACKUP,\n+        RESTORE\n+    }\n+\n+    public enum Status {\n+        INIT,\n+        TRIGGERRED,\n+        INPROGRESS,\n+        SUCCEEDED,\n+        FAILED\n+    }\n+\n+    @Id\n+    @GeneratedValue(strategy = GenerationType.AUTO, generator = \"sdx_status_generator\")\n+    @SequenceGenerator(name = \"sdx_status_generator\", sequenceName = \"sdxstatus_id_seq\", allocationSize = 1)\n+    private Long id;\n+\n+    @NotNull\n+    @Enumerated(EnumType.STRING)", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI2ODg2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444268866", "bodyText": "Can you elaborate?", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:29:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyMDI1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4MDk3Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444380977", "bodyText": "Figured it out. will do.", "author": "kkalvagadda1", "createdAt": "2020-06-23T17:13:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyMDI1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\nindex 311d79cd98..800dded8b4 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n\n@@ -2,9 +2,8 @@ package com.sequenceiq.datalake.entity;\n \n import java.util.UUID;\n \n+import javax.persistence.Convert;\n import javax.persistence.Entity;\n-import javax.persistence.EnumType;\n-import javax.persistence.Enumerated;\n import javax.persistence.GeneratedValue;\n import javax.persistence.GenerationType;\n import javax.persistence.Id;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyMDMwOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444120309", "bodyText": "here too", "author": "lacikaaa", "createdAt": "2020-06-23T10:22:27Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package com.sequenceiq.datalake.entity;\n+\n+import java.util.UUID;\n+\n+import javax.persistence.Entity;\n+import javax.persistence.EnumType;\n+import javax.persistence.Enumerated;\n+import javax.persistence.GeneratedValue;\n+import javax.persistence.GenerationType;\n+import javax.persistence.Id;\n+import javax.persistence.SequenceGenerator;\n+import javax.persistence.Table;\n+import javax.persistence.UniqueConstraint;\n+import javax.validation.constraints.NotNull;\n+\n+@Entity\n+@Table(name = \"sdxDatabaseDrstatus\", uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))\n+public class SdxDatabaseDrStatus {\n+    public enum SdxDatabaseDrStatusTypeEnum {\n+        BACKUP,\n+        RESTORE\n+    }\n+\n+    public enum Status {\n+        INIT,\n+        TRIGGERRED,\n+        INPROGRESS,\n+        SUCCEEDED,\n+        FAILED\n+    }\n+\n+    @Id\n+    @GeneratedValue(strategy = GenerationType.AUTO, generator = \"sdx_status_generator\")\n+    @SequenceGenerator(name = \"sdx_status_generator\", sequenceName = \"sdxstatus_id_seq\", allocationSize = 1)\n+    private Long id;\n+\n+    @NotNull\n+    @Enumerated(EnumType.STRING)\n+    private SdxDatabaseDrStatusTypeEnum operationType;\n+\n+    @NotNull\n+    private Long sdxClusterId;\n+\n+    private String operationId;\n+\n+    private String statusReason;\n+\n+    @NotNull\n+    @Enumerated(EnumType.STRING)", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\nindex 311d79cd98..800dded8b4 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n\n@@ -2,9 +2,8 @@ package com.sequenceiq.datalake.entity;\n \n import java.util.UUID;\n \n+import javax.persistence.Convert;\n import javax.persistence.Entity;\n-import javax.persistence.EnumType;\n-import javax.persistence.Enumerated;\n import javax.persistence.GeneratedValue;\n import javax.persistence.GenerationType;\n import javax.persistence.Id;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyNjk4OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444126989", "bodyText": "throws Exception is not necessary. same for all the doExecute", "author": "lacikaaa", "createdAt": "2020-06-23T10:35:25Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java", "diffHunk": "@@ -0,0 +1,173 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Bean;\n+import org.springframework.context.annotation.Configuration;\n+import org.springframework.statemachine.StateContext;\n+import org.springframework.statemachine.action.Action;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxContext;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupWaitRequest;\n+import com.sequenceiq.datalake.service.AbstractSdxAction;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDrService;\n+import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.core.FlowParameters;\n+import com.sequenceiq.flow.core.FlowState;\n+\n+@Configuration\n+public class DatalakeDatabaseBackupActions {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseBackupActions.class);\n+\n+    private static final String OPERATION_ID = \"OPERATION-ID\";\n+\n+    @Inject\n+    private SdxDrService sdxDrService;\n+\n+    @Bean(name = \"DATALAKE_DATABASE_BACKUP_START_STATE\")\n+    public Action<?, ?> datalakeBackup() {\n+        return new AbstractSdxAction<>(DatalakeDatabaseBackupStartEvent.class) {\n+            @Override\n+            protected SdxContext createFlowContext(FlowParameters flowParameters, StateContext<FlowState, FlowEvent> stateContext,\n+                    DatalakeDatabaseBackupStartEvent payload) {\n+                return SdxContext.from(flowParameters, payload);\n+            }\n+\n+            @Override\n+            protected void prepareExecution(DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) {\n+                super.prepareExecution(payload, variables);\n+                variables.put(OPERATION_ID, payload.getDrStatus().getOperationId());\n+            }\n+\n+            @Override\n+            protected void doExecute(SdxContext context, DatalakeDatabaseBackupStartEvent payload, Map<Object, Object> variables) throws Exception {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI3MDIzOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444270239", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:31:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyNjk4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\nindex 58873bdb64..4111a61d71 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseBackupActions.java\n\n@@ -16,7 +16,7 @@ import org.springframework.context.annotation.Configuration;\n import org.springframework.statemachine.StateContext;\n import org.springframework.statemachine.action.Action;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n import com.sequenceiq.datalake.flow.SdxContext;\n import com.sequenceiq.datalake.flow.SdxEvent;\n import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyOTA0NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444129044", "bodyText": "I won't go through all of your request, but please check them all.\nThe parent class already has defined this with EventSelectorUtil so you should depend on that instead of overriding it with the same", "author": "lacikaaa", "createdAt": "2020-06-23T10:39:17Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupCouldNotStartEvent.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package com.sequenceiq.datalake.flow.dr.event;\n+\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+\n+public class DatalakeDatabaseBackupCouldNotStartEvent extends SdxEvent {\n+    private final Exception exception;\n+\n+    public DatalakeDatabaseBackupCouldNotStartEvent(Long sdxId, String userId, Exception exception) {\n+        super(sdxId, userId);\n+        this.exception = exception;\n+    }\n+\n+    public static DatalakeDatabaseBackupCouldNotStartEvent from(SdxEvent event, Exception exception) {\n+        return new DatalakeDatabaseBackupCouldNotStartEvent(event.getResourceId(), event.getUserId(), exception);\n+    }\n+\n+    @Override\n+    public String selector() {\n+        return \"DatalakeDatabaseBackupCouldNotStartEvent\";", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI3MzYzOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444273638", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-23T14:35:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyOTA0NA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupCouldNotStartEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupCouldNotStartEvent.java\nindex 017a2fe587..fb3ccbc9ad 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupCouldNotStartEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupCouldNotStartEvent.java\n\n@@ -14,20 +14,14 @@ public class DatalakeDatabaseBackupCouldNotStartEvent extends SdxEvent {\n         return new DatalakeDatabaseBackupCouldNotStartEvent(event.getResourceId(), event.getUserId(), exception);\n     }\n \n-    @Override\n-    public String selector() {\n-        return \"DatalakeDatabaseBackupCouldNotStartEvent\";\n-    }\n-\n     public Exception getException() {\n         return exception;\n     }\n \n     @Override\n     public String toString() {\n-        final StringBuffer sb = new StringBuffer(\"DatalakeDatabaseBackupCouldNotStartEvent{\");\n-        sb.append(\"exception=\").append(exception);\n-        sb.append('}');\n-        return sb.toString();\n+        return \"DatalakeDatabaseBackupCouldNotStartEvent{\" +\n+                \"exception= \" + exception.toString() +\n+                '}';\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyOTk2OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444129969", "bodyText": "please check my comment on one of your event, and use there and here also EventSelectorUtil instead of duplicating string everywhere", "author": "lacikaaa", "createdAt": "2020-06-23T10:41:03Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrEvent.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import com.sequenceiq.flow.core.FlowEvent;\n+\n+public enum DatalakeDatabaseDrEvent implements FlowEvent {\n+\n+    DATALAKE_DATABASE_BACKUP_EVENT(\"DATALAKE_DATABASE_BACKUP_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT(\"DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT(\"DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT(\"DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_FAILED_EVENT(\"DATALAKE_DATABASE_BACKUP_FAILED_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT(\"DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT(\"DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_EVENT(\"DATALAKE_DATABASE_RESTORE_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT(\"DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT(\"DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT(\"DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_FAILED_EVENT(\"DATALAKE_DATABASE_RESTORE_FAILED_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT(\"DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT(\"DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT\");", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMzNDIyNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444334227", "bodyText": "I do not have classes defined for all the events. For the events for which classes are defined, i will make changes following your suggestion.", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:58:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyOTk2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc0MzA1Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444743052", "bodyText": "you don't have to create classes for all events. I didn't want to go through all of them to tag which should be replaced. Leaving those untouched which don't have class is fine", "author": "lacikaaa", "createdAt": "2020-06-24T08:50:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEyOTk2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrEvent.java\nindex 73ad703707..f77f6e0111 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrEvent.java\n\n@@ -1,21 +1,30 @@\n package com.sequenceiq.datalake.flow.dr;\n \n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreCouldNotStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n import com.sequenceiq.flow.core.FlowEvent;\n+import com.sequenceiq.flow.event.EventSelectorUtil;\n \n public enum DatalakeDatabaseDrEvent implements FlowEvent {\n \n-    DATALAKE_DATABASE_BACKUP_EVENT(\"DATALAKE_DATABASE_BACKUP_EVENT\"),\n-    DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT(\"DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_EVENT(EventSelectorUtil.selector(DatalakeDatabaseBackupStartEvent.class)),\n+    DATALAKE_DATABASE_BACKUP_COULD_NOT_START_EVENT(EventSelectorUtil.selector(DatalakeDatabaseBackupCouldNotStartEvent.class)),\n     DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT(\"DATALAKE_DATABASE_BACKUP_IN_PROGRESS_EVENT\"),\n-    DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT(\"DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT\"),\n-    DATALAKE_DATABASE_BACKUP_FAILED_EVENT(\"DATALAKE_DATABASE_BACKUP_FAILED_EVENT\"),\n+    DATALAKE_DATABASE_BACKUP_SUCCESS_EVENT(EventSelectorUtil.selector(DatalakeDatabaseBackupSuccessEvent.class)),\n+    DATALAKE_DATABASE_BACKUP_FAILED_EVENT(EventSelectorUtil.selector(DatalakeDatabaseBackupFailedEvent.class)),\n     DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT(\"DATALAKE_DATABASE_BACKUP_FINALIZED_EVENT\"),\n     DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT(\"DATALAKE_DATABASE_BACKUP_FAILURE_HANDLED_EVENT\"),\n-    DATALAKE_DATABASE_RESTORE_EVENT(\"DATALAKE_DATABASE_RESTORE_EVENT\"),\n-    DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT(\"DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_EVENT(EventSelectorUtil.selector(DatalakeDatabaseRestoreStartEvent.class)),\n+    DATALAKE_DATABASE_RESTORE_COULD_NOT_START_EVENT(EventSelectorUtil.selector(DatalakeDatabaseRestoreCouldNotStartEvent.class)),\n     DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT(\"DATALAKE_DATABASE_RESTORE_IN_PROGRESS_EVENT\"),\n-    DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT(\"DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT\"),\n-    DATALAKE_DATABASE_RESTORE_FAILED_EVENT(\"DATALAKE_DATABASE_RESTORE_FAILED_EVENT\"),\n+    DATALAKE_DATABASE_RESTORE_SUCCESS_EVENT(EventSelectorUtil.selector(DatalakeDatabaseRestoreSuccessEvent.class)),\n+    DATALAKE_DATABASE_RESTORE_FAILED_EVENT(EventSelectorUtil.selector(DatalakeDatabaseRestoreFailedEvent.class)),\n     DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT(\"DATALAKE_DATABASE_RESTORE_FINALIZED_EVENT\"),\n     DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT(\"DATALAKE_DATABASE_RESTORE_FAILURE_HANDLED_EVENT\");\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMTU4OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444131588", "bodyText": "you should use either plain String with concatenation or StringBuilder.\nalso final is unnecessary", "author": "lacikaaa", "createdAt": "2020-06-23T10:44:19Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreCouldNotStartEvent.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package com.sequenceiq.datalake.flow.dr.event;\n+\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+\n+public class DatalakeDatabaseRestoreCouldNotStartEvent extends SdxEvent {\n+    private final Exception exception;\n+\n+    public DatalakeDatabaseRestoreCouldNotStartEvent(Long sdxId, String userId, Exception exception) {\n+        super(\"DatalakeDatabaseRestoreCouldNotStartEvent\", sdxId, userId);\n+        this.exception = exception;\n+    }\n+\n+    public static DatalakeDatabaseRestoreCouldNotStartEvent from(SdxEvent event, Exception exception) {\n+        return new DatalakeDatabaseRestoreCouldNotStartEvent(event.getResourceId(), event.getUserId(), exception);\n+    }\n+\n+    @Override\n+    public String selector() {\n+        return \"DatalakeDatabaseRestoreCouldNotStartEvent\";\n+    }\n+\n+    public Exception getException() {\n+        return exception;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        final StringBuffer sb = new StringBuffer(\"DatalakeDatabaseRestoreCouldNotStartEvent{\");", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMzMzU5Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444333592", "bodyText": "I will remove the final.\nStringBuilder is not thread-safe by StringBuffer is. That is why I used StringBuffer.\nIs there a specific reason to use StringBuilder?", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:57:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMTU4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDc0MTkwNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444741905", "bodyText": "why would you need thread-safe solution here? it has a performance drawback\nalso simple string concatenation would do, I usually use that for toString", "author": "lacikaaa", "createdAt": "2020-06-24T08:48:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMTU4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3ODMwMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444978303", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:24:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMTU4OA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreCouldNotStartEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreCouldNotStartEvent.java\nindex 9f04430678..6f51e7a355 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreCouldNotStartEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreCouldNotStartEvent.java\n\n@@ -14,20 +14,14 @@ public class DatalakeDatabaseRestoreCouldNotStartEvent extends SdxEvent {\n         return new DatalakeDatabaseRestoreCouldNotStartEvent(event.getResourceId(), event.getUserId(), exception);\n     }\n \n-    @Override\n-    public String selector() {\n-        return \"DatalakeDatabaseRestoreCouldNotStartEvent\";\n-    }\n-\n     public Exception getException() {\n         return exception;\n     }\n \n     @Override\n     public String toString() {\n-        final StringBuffer sb = new StringBuffer(\"DatalakeDatabaseRestoreCouldNotStartEvent{\");\n-        sb.append(\"exception=\").append(exception);\n-        sb.append('}');\n-        return sb.toString();\n+        return \"DatalakeDatabaseRestoreCouldNotStartEvent{\" +\n+                \"exception= \" + exception.toString() +\n+                '}';\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzQxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444133419", "bodyText": "this class needs some identation fix, idea fixed 8 lines for me", "author": "lacikaaa", "createdAt": "2020-06-23T10:47:45Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNTQxMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444135413", "bodyText": "I think this class should be broken into 3\n\nbackup\nrestore\ncommon part\nwhat do you think?", "author": "lacikaaa", "createdAt": "2020-06-23T10:51:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMwMTk4Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444301983", "bodyText": "Fixed the indentation. What is the rationale to split the service into multiple parts?", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:13:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDczODc3NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444738774", "bodyText": "ideally one class does one thing, see: single-responsibility principle\nalso it would be easier to read as there would be less code in that class. so if you are looking for backup related stuff, you don't have to go through the restore part", "author": "lacikaaa", "createdAt": "2020-06-24T08:43:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk4ODYyOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444988628", "bodyText": "Will create a sperate patch for it.", "author": "kkalvagadda1", "createdAt": "2020-06-24T15:39:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzQxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzYyNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444133626", "bodyText": "if service is the name I think the annotation should be service", "author": "lacikaaa", "createdAt": "2020-06-23T10:48:09Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMwMjA3Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444302073", "bodyText": "will update", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:13:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzYyNg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzkxMQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444133911", "bodyText": "if we need this comment then the name of the class is wrong", "author": "lacikaaa", "createdAt": "2020-06-23T10:48:35Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMwMzEzOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444303139", "bodyText": "Will rename the class to SdxDatabaseDrService.", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:14:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzMzkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNDE0NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444134145", "bodyText": "unused", "author": "lacikaaa", "createdAt": "2020-06-23T10:49:05Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNDIwMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444134202", "bodyText": "unused", "author": "lacikaaa", "createdAt": "2020-06-23T10:49:12Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMwMzM3NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444303374", "bodyText": "will update.", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:15:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNDIwMg=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNjA3NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444136074", "bodyText": "this condition is a bit hard to read and also almost the same as in getDatabaseRestoreStatus\nit would worth to refactor them into a method", "author": "lacikaaa", "createdAt": "2020-06-23T10:53:05Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id %d not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in inmemory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (stackAndClusterAvailable(stackV4Response, cluster)) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else {\n+            if (Status.BACKUP_FAILED.equals(stackV4Response.getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getStatus())) {\n+                LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+            } else if (Status.BACKUP_FAILED.equals(stackV4Response.getCluster().getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getCluster().getStatus())) {\n+                LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                        stackV4Response.getCluster().getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+            } else {\n+                if (FINISHED.equals(flowState)) {\n+                    LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+                    return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+                } else {\n+                    return AttemptResults.justContinue();\n+                }\n+            }\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrFailed(SdxCluster sdxCluster, String statusReason, String pollingMessage) {\n+        LOGGER.info(\"{} failed, statusReason: {}\", pollingMessage, statusReason);\n+        return AttemptResults.breakFor(\"SDX \" + pollingMessage + \" failed '\" + sdxCluster.getClusterName() + \"', \" + statusReason);\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrSucceeded(StackV4Response stackV4Response) {\n+        LOGGER.info(\"Database DR operation doe SDX cluster {} is successfull\", stackV4Response.getCluster().getName());\n+        return AttemptResults.finishWith(stackV4Response);\n+    }\n+\n+    private boolean stackAndClusterAvailable(StackV4Response stackV4Response, ClusterV4Response cluster) {\n+        return stackV4Response.getStatus().isAvailable()\n+                && cluster != null\n+                && cluster.getStatus() != null\n+                && cluster.getStatus().isAvailable();\n+    }\n+\n+    /**\n+     * Updates the status of the database backup/restore operation.\n+     * @param operationId Operation Id\n+     * @param status Status of the operation\n+     * @param failedReason Failure reason, if any.\n+     */\n+    public void updateDatabaseStatusEntry(String operationId, SdxDatabaseDrStatus.Status status, String failedReason) {\n+        if (Strings.isNullOrEmpty(operationId)) {\n+            return;\n+        }\n+        SdxDatabaseDrStatus drStatus = sdxDatabaseDrStatusRepository.findSdxDatabaseDrStatusByOperationId(operationId);\n+        drStatus.setStatus(status);\n+        if (!Strings.isNullOrEmpty(failedReason)) {\n+            drStatus.setStatusReason(failedReason);\n+        }\n+        sdxDatabaseDrStatusRepository.save(drStatus);\n+    }\n+\n+    /**\n+     * Gets the status of the database backup operation.\n+     * @param sdxCluster Sdx cluster on which the backup operation is performed.\n+     * @param operationId Operation Id\n+     * @return Backup status\n+     */\n+    public SdxDatabaseBackupStatusResponse getDatabaseBackupStatus(SdxCluster sdxCluster, String operationId) {\n+        SdxDatabaseDrStatus drStatus = sdxDatabaseDrStatusRepository.findSdxDatabaseDrStatusByOperationId(operationId);\n+        if ((drStatus == null) || (!drStatus.getSdxClusterId().equals(sdxCluster.getId()))\n+                || (!drStatus.getOperationType().equals(SdxDatabaseDrStatus.SdxDatabaseDrStatusTypeEnum.BACKUP))) {", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI5MzYxMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444293613", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:01:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNjA3NA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNzQ1NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444137454", "bodyText": "this if-else thing got out of hand. please refactor parts of into separate method with meaningful names so it would be easier to follow what happens", "author": "lacikaaa", "createdAt": "2020-06-23T10:55:53Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id %d not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in inmemory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (stackAndClusterAvailable(stackV4Response, cluster)) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else {\n+            if (Status.BACKUP_FAILED.equals(stackV4Response.getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getStatus())) {\n+                LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+            } else if (Status.BACKUP_FAILED.equals(stackV4Response.getCluster().getStatus()) ||\n+                    Status.RESTORE_FAILED.equals(stackV4Response.getCluster().getStatus())) {\n+                LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                        stackV4Response.getCluster().getStatus());\n+                return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+            } else {\n+                if (FINISHED.equals(flowState)) {\n+                    LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+                    return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+                } else {\n+                    return AttemptResults.justContinue();\n+                }\n+            }\n+        }", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMyNzQ4Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444327486", "bodyText": "will refactor it.", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:49:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNzQ1NA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNzkyMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444137920", "bodyText": "you might want to use WebApplicationExceptionMessageExtractor here", "author": "lacikaaa", "createdAt": "2020-06-23T10:56:55Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java", "diffHunk": "@@ -0,0 +1,273 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.status.SdxStatusService;\n+import com.sequenceiq.redbeams.api.endpoint.v4.databaseserver.DatabaseServerV4Endpoint;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Component\n+public class SdxDrService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private SdxStatusService sdxStatusService;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private DatabaseServerV4Endpoint databaseServerV4Endpoint;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        String operationId = triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseBackupResponse(operationId);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        String operationId = triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+        return new SdxDatabaseRestoreResponse(operationId);\n+\n+    }\n+\n+    private String triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    private String triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        return sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(clusterId, backupId, backupLocation);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, backupV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                cloudbreakFlowService.saveLastCloudbreakFlowChainId(sdxCluster, restoreV4Response.getFlowIdentifier());\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.TRIGGERRED, null);\n+            }, () -> {\n+                updateDatabaseStatusEntry(drStatus.getOperationId(), SdxDatabaseDrStatus.Status.FAILED,\n+                        String.format(\"SDX cluster with Id %d not found\", clusterId));\n+                throw notFound(\"SDX cluster\", clusterId).get();\n+            });\n+        } catch (WebApplicationException e) {\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, e.getMessage());\n+            throw new CloudbreakApiException(message);\n+        }", "originalCommit": "52d0c5ba63baf481f6bd70ccb9ab3d5bc616f511", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDMyOTU0Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r444329543", "bodyText": "Will use it", "author": "kkalvagadda1", "createdAt": "2020-06-23T15:52:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDEzNzkyMA=="}], "type": "inlineReview", "revised_code": {"commit": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nsimilarity index 59%\nrename from datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex d2b2f0d28a..d7bbbbd221 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,6 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"oid": "7bff4f9ec8d26fb09462b89b93099f341d595cef", "url": "https://github.com/hortonworks/cloudbreak/commit/7bff4f9ec8d26fb09462b89b93099f341d595cef", "message": "addressed review comments.", "committedDate": "2020-06-24T15:37:00Z", "type": "forcePushed"}, {"oid": "5f09eca14c5c14a0d91249d689024d88c8163506", "url": "https://github.com/hortonworks/cloudbreak/commit/5f09eca14c5c14a0d91249d689024d88c8163506", "message": "fixed issues observed in e2e testing.", "committedDate": "2020-06-25T12:06:49Z", "type": "forcePushed"}, {"oid": "5675e74f382ccd9d117a2c32c7a69a8ba9401d04", "url": "https://github.com/hortonworks/cloudbreak/commit/5675e74f382ccd9d117a2c32c7a69a8ba9401d04", "message": "fixed failure observed in e2e testing.", "committedDate": "2020-06-25T16:50:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTUxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446139519", "bodyText": "why would you skip check in case of finished state?\nalso it looks like is changed in the other PR too", "author": "lacikaaa", "createdAt": "2020-06-26T11:58:04Z", "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -142,8 +142,10 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n                 Status.BACKUP_FAILED,\n+                Status.BACKUP_FINISHED,\n                 Status.RESTORE_IN_PROGRESS,\n-                Status.RESTORE_FAILED\n+                Status.RESTORE_FAILED,\n+                Status.RESTORE_FINISHED", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0Nzc0Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446247746", "bodyText": "will move the finished states to synchable states", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:17:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTUxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java b/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\nindex 2f9ad2a07d..5ad7a83e6e 100644\n--- a/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\n+++ b/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\n\n@@ -142,10 +142,8 @@ public class StackStatusCheckerJob extends StatusCheckerJob {\n                 Status.EXTERNAL_DATABASE_CREATION_IN_PROGRESS,\n                 Status.BACKUP_IN_PROGRESS,\n                 Status.BACKUP_FAILED,\n-                Status.BACKUP_FINISHED,\n                 Status.RESTORE_IN_PROGRESS,\n-                Status.RESTORE_FAILED,\n-                Status.RESTORE_FINISHED\n+                Status.RESTORE_FAILED\n         );\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1MTg3Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446151872", "bodyText": "after having another glimpse at your pr, I'm confused why would you need this altogether.\nI mean we have flowid, with that you should be able to create a status on the fly, as this is also generated from the state of the flow.\nSo I think you should drop all the operationid stuff, return with the flowid, and the query endpoint should expect flowid instead of operationid. (right now your response also have flowid in it)\nI know in freeipa we have this, but back then we didn't have this for flow, and also usersync doesn't run in flow. But if we would like to go this way, then we should move from returning flowid on all endpoint and make operation general, but I'm not sure this would worth it right now", "author": "lacikaaa", "createdAt": "2020-06-26T12:25:44Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java", "diffHunk": "@@ -0,0 +1,92 @@\n+package com.sequenceiq.datalake.entity;\n+\n+import java.util.UUID;\n+\n+import javax.persistence.Convert;\n+import javax.persistence.Entity;\n+import javax.persistence.GeneratedValue;\n+import javax.persistence.GenerationType;\n+import javax.persistence.Id;\n+import javax.persistence.SequenceGenerator;\n+import javax.persistence.Table;\n+import javax.persistence.UniqueConstraint;\n+import javax.validation.constraints.NotNull;\n+\n+import com.sequenceiq.datalake.converter.SdxDatabaseDrOperationTypeEnumConverter;\n+import com.sequenceiq.datalake.converter.SdxDatabaseDrStatusTypeEnumConverter;\n+\n+@Entity\n+@Table(uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))\n+public class SdxDatabaseDrStatus {", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjIzMDQ2MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446230461", "bodyText": "As per our conversation, I will generalize the classes and move them to a new package,", "author": "kkalvagadda1", "createdAt": "2020-06-26T14:48:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1MTg3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java\nsimilarity index 69%\nrename from datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java\nindex 800dded8b4..3651181b99 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/SdxDatabaseDrStatus.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java\n\n@@ -1,4 +1,4 @@\n-package com.sequenceiq.datalake.entity;\n+package com.sequenceiq.datalake.entity.operation;\n \n import java.util.UUID;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1NzA2Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446157067", "bodyText": "before the return line you should build the MDCContext using MdcBuilder", "author": "lacikaaa", "createdAt": "2020-06-26T12:36:59Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Service;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.auth.ThreadBasedUserCrnProvider;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.exception.WebApplicationExceptionMessageExtractor;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Service\n+public class SdxDatabaseDrService {\n+\n+    private static final int MAX_SIZE_OF_FAILURE_REASON = 254;\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDatabaseDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private WebApplicationExceptionMessageExtractor webApplicationExceptionMessageExtractor;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        return triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        return triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjIzMDY1Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446230656", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-26T14:48:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1NzA2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex 7eaa625de0..5d4d47a675 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,8 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.backup.DatalakeDatabaseBackupEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.restore.DatalakeDatabaseRestoreEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2MzEzNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446163135", "bodyText": "as backup and restore 2 separate flow, it should have 2 separate state and event enum", "author": "lacikaaa", "createdAt": "2020-06-26T12:49:14Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java", "diffHunk": "@@ -0,0 +1,35 @@\n+package com.sequenceiq.datalake.flow.dr;\n+\n+import com.sequenceiq.flow.core.FlowState;\n+import com.sequenceiq.flow.core.RestartAction;\n+import com.sequenceiq.flow.core.restart.DefaultRestartAction;\n+\n+public enum DatalakeDatabaseDrState implements FlowState {", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0MjU2Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446242567", "bodyText": "will do.", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:08:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2MzEzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/DatalakeDatabaseRestoreState.java\nsimilarity index 60%\nrename from datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/DatalakeDatabaseRestoreState.java\nindex e31d5c09d7..0fd05009f6 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/DatalakeDatabaseDrState.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/DatalakeDatabaseRestoreState.java\n\n@@ -1,17 +1,12 @@\n-package com.sequenceiq.datalake.flow.dr;\n+package com.sequenceiq.datalake.flow.dr.restore;\n \n import com.sequenceiq.flow.core.FlowState;\n import com.sequenceiq.flow.core.RestartAction;\n import com.sequenceiq.flow.core.restart.DefaultRestartAction;\n \n-public enum DatalakeDatabaseDrState implements FlowState {\n+public enum DatalakeDatabaseRestoreState implements FlowState {\n \n     INIT_STATE,\n-    DATALAKE_DATABASE_BACKUP_START_STATE,\n-    DATALAKE_DATABASE_BACKUP_COULD_NOT_START_STATE,\n-    DATALAKE_DATABASE_BACKUP_IN_PROGRESS_STATE,\n-    DATALAKE_DATABASE_BACKUP_FAILED_STATE,\n-    DATALAKE_DATABASE_BACKUP_FINISHED_STATE,\n     DATALAKE_DATABASE_RESTORE_START_STATE,\n     DATALAKE_DATABASE_RESTORE_COULD_NOT_START_STATE,\n     DATALAKE_DATABASE_RESTORE_IN_PROGRESS_STATE,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NDk5NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446164994", "bodyText": "could be final", "author": "lacikaaa", "createdAt": "2020-06-26T12:53:07Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupStartEvent.java", "diffHunk": "@@ -0,0 +1,25 @@\n+package com.sequenceiq.datalake.flow.dr.event;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+\n+public class DatalakeDatabaseBackupStartEvent extends DatalakeDatabaseDrStartBaseEvent {\n+\n+    private String backupId;\n+\n+    private String backupLocation;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0MzM4NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446243384", "bodyText": "will fix", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:10:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NDk5NA=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupStartEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/event/DatalakeDatabaseBackupStartEvent.java\nsimilarity index 58%\nrename from datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupStartEvent.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/event/DatalakeDatabaseBackupStartEvent.java\nindex ecbc9f5b94..a9fd287402 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupStartEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/event/DatalakeDatabaseBackupStartEvent.java\n\n@@ -1,16 +1,17 @@\n-package com.sequenceiq.datalake.flow.dr.event;\n+package com.sequenceiq.datalake.flow.dr.backup.event;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.operation.SdxOperationTypeEnum;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseDrStartBaseEvent;\n \n public class DatalakeDatabaseBackupStartEvent extends DatalakeDatabaseDrStartBaseEvent {\n \n-    private String backupId;\n+    private final String backupId;\n \n-    private String backupLocation;\n+    private final String backupLocation;\n \n     public DatalakeDatabaseBackupStartEvent(String selector, Long sdxId, String userId,\n             String backupId, String backupLocation) {\n-        super(selector, sdxId, userId, SdxDatabaseDrOperationTypeEnum.BACKUP);\n+        super(selector, sdxId, userId, SdxOperationTypeEnum.BACKUP);\n         this.backupId = backupId;\n         this.backupLocation = backupLocation;\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTExOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446165118", "bodyText": "could be final", "author": "lacikaaa", "createdAt": "2020-06-26T12:53:21Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupSuccessEvent.java", "diffHunk": "@@ -0,0 +1,17 @@\n+package com.sequenceiq.datalake.flow.dr.event;\n+\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+\n+public class DatalakeDatabaseBackupSuccessEvent extends SdxEvent {\n+    private String operationId;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0MzQ2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446243466", "bodyText": "will fix", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:10:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTExOA=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupSuccessEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/event/DatalakeDatabaseBackupSuccessEvent.java\nsimilarity index 79%\nrename from datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupSuccessEvent.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/event/DatalakeDatabaseBackupSuccessEvent.java\nindex 145c57e567..e16df58d64 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseBackupSuccessEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/event/DatalakeDatabaseBackupSuccessEvent.java\n\n@@ -1,9 +1,9 @@\n-package com.sequenceiq.datalake.flow.dr.event;\n+package com.sequenceiq.datalake.flow.dr.backup.event;\n \n import com.sequenceiq.datalake.flow.SdxEvent;\n \n public class DatalakeDatabaseBackupSuccessEvent extends SdxEvent {\n-    private String operationId;\n+    private final String operationId;\n \n     public DatalakeDatabaseBackupSuccessEvent(Long sdxId, String userId, String operationId) {\n         super(sdxId, userId);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTM5NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446165395", "bodyText": "coudl be final", "author": "lacikaaa", "createdAt": "2020-06-26T12:53:58Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseDrStartBaseEvent.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package com.sequenceiq.datalake.flow.dr.event;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.flow.SdxEvent;\n+\n+public class DatalakeDatabaseDrStartBaseEvent extends SdxEvent  {\n+    private SdxDatabaseDrStatus drStatus;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0MzUwNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446243506", "bodyText": "will fix", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:10:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTM5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseDrStartBaseEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseDrStartBaseEvent.java\nindex 99bf8fc199..6dd217a640 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseDrStartBaseEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseDrStartBaseEvent.java\n\n@@ -1,19 +1,19 @@\n package com.sequenceiq.datalake.flow.dr.event;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n-import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.operation.SdxOperationStatus;\n+import com.sequenceiq.datalake.entity.operation.SdxOperationTypeEnum;\n import com.sequenceiq.datalake.flow.SdxEvent;\n \n public class DatalakeDatabaseDrStartBaseEvent extends SdxEvent  {\n-    private SdxDatabaseDrStatus drStatus;\n+    private SdxOperationStatus drStatus;\n \n     public DatalakeDatabaseDrStartBaseEvent(String selector, Long sdxId, String userId,\n-            SdxDatabaseDrOperationTypeEnum operationType) {\n+            SdxOperationTypeEnum operationType) {\n         super(selector, sdxId, userId);\n-        drStatus = new SdxDatabaseDrStatus(operationType, sdxId);\n+        drStatus = new SdxOperationStatus(operationType, sdxId);\n     }\n \n-    public SdxDatabaseDrStatus getDrStatus() {\n+    public SdxOperationStatus getDrStatus() {\n         return drStatus;\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTYwMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446165600", "bodyText": "final", "author": "lacikaaa", "createdAt": "2020-06-26T12:54:23Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreStartEvent.java", "diffHunk": "@@ -0,0 +1,25 @@\n+package com.sequenceiq.datalake.flow.dr.event;\n+\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+\n+public class DatalakeDatabaseRestoreStartEvent extends DatalakeDatabaseDrStartBaseEvent {\n+    private String backupId;\n+\n+    private String backupLocation;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0MzU1NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446243555", "bodyText": "will fix", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTYwMA=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreStartEvent.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/event/DatalakeDatabaseRestoreStartEvent.java\nsimilarity index 58%\nrename from datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreStartEvent.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/event/DatalakeDatabaseRestoreStartEvent.java\nindex 67b7616d03..bf414d71b4 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/event/DatalakeDatabaseRestoreStartEvent.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/event/DatalakeDatabaseRestoreStartEvent.java\n\n@@ -1,15 +1,16 @@\n-package com.sequenceiq.datalake.flow.dr.event;\n+package com.sequenceiq.datalake.flow.dr.restore.event;\n \n-import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.operation.SdxOperationTypeEnum;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseDrStartBaseEvent;\n \n public class DatalakeDatabaseRestoreStartEvent extends DatalakeDatabaseDrStartBaseEvent {\n-    private String backupId;\n+    private final String backupId;\n \n-    private String backupLocation;\n+    private final String backupLocation;\n \n     public DatalakeDatabaseRestoreStartEvent(String selector, Long sdxId, String userId,\n             String backupId, String backupLocation) {\n-        super(selector, sdxId, userId, SdxDatabaseDrOperationTypeEnum.RESTORE);\n+        super(selector, sdxId, userId, SdxOperationTypeEnum.RESTORE);\n         this.backupId = backupId;\n         this.backupLocation = backupLocation;\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTk1Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446165952", "bodyText": "should be configurable", "author": "lacikaaa", "createdAt": "2020-06-26T12:55:02Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseBackupWaitHandler.java", "diffHunk": "@@ -0,0 +1,69 @@\n+package com.sequenceiq.datalake.flow.dr.handler;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.exception.PollerException;\n+import com.dyngr.exception.PollerStoppedException;\n+import com.dyngr.exception.UserBreakException;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupWaitRequest;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDatabaseDrService;\n+import com.sequenceiq.flow.event.EventSelectorUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+\n+@Component\n+public class DatalakeDatabaseBackupWaitHandler extends ExceptionCatcherEventHandler<DatalakeDatabaseBackupWaitRequest> {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDatabaseBackupWaitHandler.class);\n+\n+    private static final int SLEEP_TIME_IN_SEC = 20;\n+\n+    private static final int DURATION_IN_MINUTES = 90;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0NDg5NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446244894", "bodyText": "I did find a place where these values are configurable. Can you provide a reference?", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:12:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTk1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI2MDQzMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446260432", "bodyText": "look for @Value anywhere in the code", "author": "lacikaaa", "createdAt": "2020-06-26T15:40:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NTk1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseBackupWaitHandler.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/handler/DatalakeDatabaseBackupWaitHandler.java\nsimilarity index 90%\nrename from datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseBackupWaitHandler.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/handler/DatalakeDatabaseBackupWaitHandler.java\nindex bce2ca90b0..57d5e55e8c 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseBackupWaitHandler.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/backup/handler/DatalakeDatabaseBackupWaitHandler.java\n\n@@ -1,4 +1,4 @@\n-package com.sequenceiq.datalake.flow.dr.handler;\n+package com.sequenceiq.datalake.flow.dr.backup.handler;\n \n import java.util.concurrent.TimeUnit;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NzM1Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446167352", "bodyText": "the 2 wait handler is almost the same, might be worth to refactor them into one", "author": "lacikaaa", "createdAt": "2020-06-26T12:57:41Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseRestoreWaitHandler.java", "diffHunk": "@@ -0,0 +1,69 @@\n+package com.sequenceiq.datalake.flow.dr.handler;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.dyngr.exception.PollerException;\n+import com.dyngr.exception.PollerStoppedException;\n+import com.dyngr.exception.UserBreakException;\n+import com.sequenceiq.cloudbreak.common.event.Selectable;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreFailedEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreSuccessEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreWaitRequest;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.datalake.service.sdx.dr.SdxDatabaseDrService;\n+import com.sequenceiq.flow.event.EventSelectorUtil;\n+import com.sequenceiq.flow.reactor.api.handler.ExceptionCatcherEventHandler;\n+\n+@Component\n+public class DatalakeDatabaseRestoreWaitHandler extends ExceptionCatcherEventHandler<DatalakeDatabaseRestoreWaitRequest> {", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0NTYxOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446245618", "bodyText": "They send different events on success and failure scenarios. I think it will be clean to have them separate.", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:14:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2NzM1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseRestoreWaitHandler.java b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/handler/DatalakeDatabaseRestoreWaitHandler.java\nsimilarity index 90%\nrename from datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseRestoreWaitHandler.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/handler/DatalakeDatabaseRestoreWaitHandler.java\nindex 441bc78c0f..438096f1fb 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/handler/DatalakeDatabaseRestoreWaitHandler.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/flow/dr/restore/handler/DatalakeDatabaseRestoreWaitHandler.java\n\n@@ -1,4 +1,4 @@\n-package com.sequenceiq.datalake.flow.dr.handler;\n+package com.sequenceiq.datalake.flow.dr.restore.handler;\n \n import java.util.concurrent.TimeUnit;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2OTYxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446169619", "bodyText": "return Status.BACKUP_FINISHED.equals(status) ||\n                Status.RESTORE_FINISHED.equals(status);", "author": "lacikaaa", "createdAt": "2020-06-26T13:01:59Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Service;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.auth.ThreadBasedUserCrnProvider;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.exception.WebApplicationExceptionMessageExtractor;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Service\n+public class SdxDatabaseDrService {\n+\n+    private static final int MAX_SIZE_OF_FAILURE_REASON = 254;\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDatabaseDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private WebApplicationExceptionMessageExtractor webApplicationExceptionMessageExtractor;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        return triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        return triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    private SdxDatabaseBackupResponse triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseBackupStartEvent startEvent = new DatalakeDatabaseBackupStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(startEvent);\n+        return new SdxDatabaseBackupResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    private SdxDatabaseRestoreResponse triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_RESTORE_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseRestoreStartEvent startEvent = new DatalakeDatabaseRestoreStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(startEvent);\n+        return new SdxDatabaseRestoreResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, backupV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, restoreV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in in-memory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (isStackOrClusterDrStatusComplete(stackV4Response.getStatus()) && isStackOrClusterDrStatusComplete(cluster.getStatus())) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getStatus())) {\n+            LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getCluster().getStatus())) {\n+            LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                    stackV4Response.getCluster().getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+        } else if (FINISHED.equals(flowState)) {\n+            LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+            return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+        } else {\n+            LOGGER.info(\"Flow is unknown state\");\n+            return sdxDrFailed(sdxCluster, \"Flow is unknown state\", pollingMessage);\n+        }\n+    }\n+\n+    /**\n+     * Checks the status if the backup/restore operation failed.\n+     * @param status It could be stack/cluster status\n+     * @return true if status is failed, false otherwise.\n+     */\n+    private boolean isStackOrClusterStatusFailed(Status status) {\n+        return (Status.BACKUP_FAILED.equals(status) ||\n+                Status.RESTORE_FAILED.equals(status)) ? true : false;\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrFailed(SdxCluster sdxCluster, String statusReason, String pollingMessage) {\n+        LOGGER.info(\"{} failed, statusReason: {}\", pollingMessage, statusReason);\n+        return AttemptResults.breakFor(\"SDX \" + pollingMessage + \" failed '\" + sdxCluster.getClusterName() + \"', \" + statusReason);\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrSucceeded(StackV4Response stackV4Response) {\n+        LOGGER.info(\"Database DR operation does SDX cluster {} is successful\", stackV4Response.getCluster().getName());\n+        return AttemptResults.finishWith(stackV4Response);\n+    }\n+\n+    /**\n+     * Checks the status if the backup/restore operation is successful.\n+     * @param status It could be stack/cluster status\n+     * @return true if status is successful, false otherwise.\n+     */\n+    private boolean isStackOrClusterDrStatusComplete(Status status) {\n+        return (Status.BACKUP_FINISHED.equals(status) ||\n+                Status.RESTORE_FINISHED.equals(status)) ? true : false;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0NjMwNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446246306", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:15:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE2OTYxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex 7eaa625de0..5d4d47a675 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,8 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.backup.DatalakeDatabaseBackupEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.restore.DatalakeDatabaseRestoreEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3MDA2Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446170062", "bodyText": "return Status.BACKUP_FAILED.equals(status) ||\n                Status.RESTORE_FAILED.equals(status);", "author": "lacikaaa", "createdAt": "2020-06-26T13:02:57Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Service;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.auth.ThreadBasedUserCrnProvider;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.exception.WebApplicationExceptionMessageExtractor;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Service\n+public class SdxDatabaseDrService {\n+\n+    private static final int MAX_SIZE_OF_FAILURE_REASON = 254;\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDatabaseDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private WebApplicationExceptionMessageExtractor webApplicationExceptionMessageExtractor;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        return triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        return triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    private SdxDatabaseBackupResponse triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseBackupStartEvent startEvent = new DatalakeDatabaseBackupStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(startEvent);\n+        return new SdxDatabaseBackupResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    private SdxDatabaseRestoreResponse triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_RESTORE_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseRestoreStartEvent startEvent = new DatalakeDatabaseRestoreStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(startEvent);\n+        return new SdxDatabaseRestoreResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, backupV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, restoreV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in in-memory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (isStackOrClusterDrStatusComplete(stackV4Response.getStatus()) && isStackOrClusterDrStatusComplete(cluster.getStatus())) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getStatus())) {\n+            LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getCluster().getStatus())) {\n+            LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                    stackV4Response.getCluster().getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+        } else if (FINISHED.equals(flowState)) {\n+            LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+            return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+        } else {\n+            LOGGER.info(\"Flow is unknown state\");\n+            return sdxDrFailed(sdxCluster, \"Flow is unknown state\", pollingMessage);\n+        }\n+    }\n+\n+    /**\n+     * Checks the status if the backup/restore operation failed.\n+     * @param status It could be stack/cluster status\n+     * @return true if status is failed, false otherwise.\n+     */\n+    private boolean isStackOrClusterStatusFailed(Status status) {\n+        return (Status.BACKUP_FAILED.equals(status) ||\n+                Status.RESTORE_FAILED.equals(status)) ? true : false;", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0NjM2OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446246369", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:15:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3MDA2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex 7eaa625de0..5d4d47a675 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,8 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.backup.DatalakeDatabaseBackupEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.restore.DatalakeDatabaseRestoreEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3MDM4Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446170387", "bodyText": "drop the comment, method name is self explaining", "author": "lacikaaa", "createdAt": "2020-06-26T13:03:39Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Service;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.auth.ThreadBasedUserCrnProvider;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.exception.WebApplicationExceptionMessageExtractor;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Service\n+public class SdxDatabaseDrService {\n+\n+    private static final int MAX_SIZE_OF_FAILURE_REASON = 254;\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDatabaseDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private WebApplicationExceptionMessageExtractor webApplicationExceptionMessageExtractor;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        return triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        return triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    private SdxDatabaseBackupResponse triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseBackupStartEvent startEvent = new DatalakeDatabaseBackupStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(startEvent);\n+        return new SdxDatabaseBackupResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    private SdxDatabaseRestoreResponse triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_RESTORE_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseRestoreStartEvent startEvent = new DatalakeDatabaseRestoreStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(startEvent);\n+        return new SdxDatabaseRestoreResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, backupV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, restoreV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in in-memory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (isStackOrClusterDrStatusComplete(stackV4Response.getStatus()) && isStackOrClusterDrStatusComplete(cluster.getStatus())) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getStatus())) {\n+            LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getCluster().getStatus())) {\n+            LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                    stackV4Response.getCluster().getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+        } else if (FINISHED.equals(flowState)) {\n+            LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+            return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+        } else {\n+            LOGGER.info(\"Flow is unknown state\");\n+            return sdxDrFailed(sdxCluster, \"Flow is unknown state\", pollingMessage);\n+        }\n+    }\n+\n+    /**\n+     * Checks the status if the backup/restore operation failed.\n+     * @param status It could be stack/cluster status\n+     * @return true if status is failed, false otherwise.\n+     */\n+    private boolean isStackOrClusterStatusFailed(Status status) {\n+        return (Status.BACKUP_FAILED.equals(status) ||\n+                Status.RESTORE_FAILED.equals(status)) ? true : false;\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrFailed(SdxCluster sdxCluster, String statusReason, String pollingMessage) {\n+        LOGGER.info(\"{} failed, statusReason: {}\", pollingMessage, statusReason);\n+        return AttemptResults.breakFor(\"SDX \" + pollingMessage + \" failed '\" + sdxCluster.getClusterName() + \"', \" + statusReason);\n+    }\n+\n+    private AttemptResult<StackV4Response> sdxDrSucceeded(StackV4Response stackV4Response) {\n+        LOGGER.info(\"Database DR operation does SDX cluster {} is successful\", stackV4Response.getCluster().getName());\n+        return AttemptResults.finishWith(stackV4Response);\n+    }\n+\n+    /**\n+     * Checks the status if the backup/restore operation is successful.\n+     * @param status It could be stack/cluster status\n+     * @return true if status is successful, false otherwise.\n+     */", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0NjgyMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446246823", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:16:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3MDM4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex 7eaa625de0..5d4d47a675 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,8 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.backup.DatalakeDatabaseBackupEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.restore.DatalakeDatabaseRestoreEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3MDQ0Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446170446", "bodyText": "drop the comment", "author": "lacikaaa", "createdAt": "2020-06-26T13:03:47Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java", "diffHunk": "@@ -0,0 +1,309 @@\n+package com.sequenceiq.datalake.service.sdx.dr;\n+\n+import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n+import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n+\n+import java.util.Collections;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.WebApplicationException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Service;\n+\n+import com.dyngr.Polling;\n+import com.dyngr.core.AttemptResult;\n+import com.dyngr.core.AttemptResults;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.common.base.Strings;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.StackV4Endpoint;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.cluster.ClusterV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.BackupV4Response;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.dr.RestoreV4Response;\n+import com.sequenceiq.cloudbreak.auth.ThreadBasedUserCrnProvider;\n+import com.sequenceiq.cloudbreak.cloud.scheduler.PollGroup;\n+import com.sequenceiq.cloudbreak.common.exception.WebApplicationExceptionMessageExtractor;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.exception.CloudbreakApiException;\n+import com.sequenceiq.datalake.entity.SdxCluster;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrOperationTypeEnum;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatus;\n+import com.sequenceiq.datalake.entity.SdxDatabaseDrStatusTypeEnum;\n+import com.sequenceiq.datalake.flow.SdxReactorFlowManager;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseBackupStartEvent;\n+import com.sequenceiq.datalake.flow.dr.event.DatalakeDatabaseRestoreStartEvent;\n+import com.sequenceiq.datalake.flow.statestore.DatalakeInMemoryStateStore;\n+import com.sequenceiq.datalake.repository.SDxDatabaseDrStatusRepository;\n+import com.sequenceiq.datalake.repository.SdxClusterRepository;\n+import com.sequenceiq.datalake.service.sdx.CloudbreakFlowService;\n+import com.sequenceiq.datalake.service.sdx.PollingConfig;\n+import com.sequenceiq.flow.api.model.FlowIdentifier;\n+import com.sequenceiq.sdx.api.model.DatalakeDatabaseDrStatus;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseBackupStatusResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreResponse;\n+import com.sequenceiq.sdx.api.model.SdxDatabaseRestoreStatusResponse;\n+\n+/**\n+ * Service to perform backup/restore of the database backing SDX.\n+ */\n+@Service\n+public class SdxDatabaseDrService {\n+\n+    private static final int MAX_SIZE_OF_FAILURE_REASON = 254;\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(SdxDatabaseDrService.class);\n+\n+    @Inject\n+    private SdxReactorFlowManager sdxReactorFlowManager;\n+\n+    @Inject\n+    private StackV4Endpoint stackV4Endpoint;\n+\n+    @Inject\n+    private WebApplicationExceptionMessageExtractor webApplicationExceptionMessageExtractor;\n+\n+    @Inject\n+    private CloudbreakFlowService cloudbreakFlowService;\n+\n+    @Inject\n+    private SdxClusterRepository sdxClusterRepository;\n+\n+    @Inject\n+    private SDxDatabaseDrStatusRepository sdxDatabaseDrStatusRepository;\n+\n+    public SdxDatabaseBackupResponse triggerDatabaseBackup(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+\n+        return triggerDatalakeDatabaseBackupFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    public SdxDatabaseRestoreResponse triggerDatabaseRestore(SdxCluster sdxCluster, String backupId, String backupLocation) {\n+        return triggerDatalakeDatabaseRestoreFlow(sdxCluster.getId(), backupId, backupLocation);\n+    }\n+\n+    private SdxDatabaseBackupResponse triggerDatalakeDatabaseBackupFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_BACKUP_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseBackupStartEvent startEvent = new DatalakeDatabaseBackupStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseBackupFlow(startEvent);\n+        return new SdxDatabaseBackupResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    private SdxDatabaseRestoreResponse triggerDatalakeDatabaseRestoreFlow(Long clusterId, String backupId, String backupLocation) {\n+        String selector = DATALAKE_DATABASE_RESTORE_EVENT.event();\n+        String userId = ThreadBasedUserCrnProvider.getUserCrn();\n+        DatalakeDatabaseRestoreStartEvent startEvent = new DatalakeDatabaseRestoreStartEvent(selector, clusterId, userId, backupId, backupLocation);\n+        FlowIdentifier flowIdentifier = sdxReactorFlowManager.triggerDatalakeDatabaseRestoreFlow(startEvent);\n+        return new SdxDatabaseRestoreResponse(startEvent.getDrStatus().getOperationId(), flowIdentifier);\n+    }\n+\n+    public void databaseBackup(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                BackupV4Response backupV4Response = stackV4Endpoint.backupDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, backupV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database backup failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void databaseRestore(SdxDatabaseDrStatus drStatus, Long clusterId, String backupId, String backupLocation) {\n+        try {\n+            sdxDatabaseDrStatusRepository.save(drStatus);\n+            sdxClusterRepository.findById(clusterId).ifPresentOrElse(sdxCluster -> {\n+                RestoreV4Response restoreV4Response = stackV4Endpoint.restoreDatabaseByName(0L, sdxCluster.getClusterName(),\n+                        backupLocation, backupId);\n+                updateSuccessStatus(drStatus.getOperationId(), sdxCluster, restoreV4Response.getFlowIdentifier(),\n+                        SdxDatabaseDrStatusTypeEnum.TRIGGERRED);\n+            }, () -> {\n+                updateFailureStatus(drStatus.getOperationId(), clusterId, String.format(\"SDX cluster with Id [%d] not found\", clusterId));\n+            });\n+        } catch (WebApplicationException e) {\n+            String errorMessage = webApplicationExceptionMessageExtractor.getErrorMessage(e);\n+            String message = String.format(\"Database restore failed for datalake-id: [%d]. Message: [%s]\", clusterId, errorMessage);\n+            throw new CloudbreakApiException(message);\n+        }\n+    }\n+\n+    public void waitCloudbreakFlow(Long id, PollingConfig pollingConfig, String pollingMessage) {\n+        SdxCluster sdxCluster = sdxClusterRepository.findById(id).orElseThrow(notFound(\"SDX cluster\", id));\n+        Polling.waitPeriodly(pollingConfig.getSleepTime(), pollingConfig.getSleepTimeUnit())\n+                .stopIfException(pollingConfig.getStopPollingIfExceptionOccured())\n+                .stopAfterDelay(pollingConfig.getDuration(), pollingConfig.getDurationTimeUnit())\n+                .run(() -> checkDatabaseDrStatus(sdxCluster, pollingMessage));\n+    }\n+\n+    private AttemptResult<StackV4Response> checkDatabaseDrStatus(SdxCluster sdxCluster, String pollingMessage) throws JsonProcessingException {\n+        LOGGER.info(\"{} polling cloudbreak for stack status: '{}' in '{}' env\", pollingMessage, sdxCluster.getClusterName(), sdxCluster.getEnvName());\n+        try {\n+            if (PollGroup.CANCELLED.equals(DatalakeInMemoryStateStore.get(sdxCluster.getId()))) {\n+                LOGGER.info(\"{} polling cancelled in in-memory store, id: {}\", pollingMessage, sdxCluster.getId());\n+                return AttemptResults.breakFor(pollingMessage + \" polling cancelled in inmemory store, id: \" + sdxCluster.getId());\n+            } else {\n+                CloudbreakFlowService.FlowState flowState = cloudbreakFlowService.getLastKnownFlowState(sdxCluster);\n+                if (RUNNING.equals(flowState)) {\n+                    LOGGER.info(\"{} polling will continue, cluster has an active flow in Cloudbreak, id: {}\", pollingMessage, sdxCluster.getId());\n+                    return AttemptResults.justContinue();\n+                } else {\n+                    return getStackResponseAttemptResult(sdxCluster, pollingMessage, flowState);\n+                }\n+            }\n+        } catch (javax.ws.rs.NotFoundException e) {\n+            LOGGER.debug(\"Stack not found on CB side \" + sdxCluster.getClusterName(), e);\n+            return AttemptResults.breakFor(\"Stack not found on CB side \" + sdxCluster.getClusterName());\n+        }\n+    }\n+\n+    private AttemptResult<StackV4Response> getStackResponseAttemptResult(SdxCluster sdxCluster, String pollingMessage, CloudbreakFlowService.FlowState flowState)\n+            throws JsonProcessingException {\n+        StackV4Response stackV4Response = stackV4Endpoint.get(0L, sdxCluster.getClusterName(), Collections.emptySet());\n+        LOGGER.info(\"Response from cloudbreak: {}\", JsonUtil.writeValueAsString(stackV4Response));\n+        ClusterV4Response cluster = stackV4Response.getCluster();\n+        if (isStackOrClusterDrStatusComplete(stackV4Response.getStatus()) && isStackOrClusterDrStatusComplete(cluster.getStatus())) {\n+            return sdxDrSucceeded(stackV4Response);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getStatus())) {\n+            LOGGER.info(\"{} failed for Stack {} with status {}\", pollingMessage, stackV4Response.getName(), stackV4Response.getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getStatusReason(), pollingMessage);\n+        } else if (isStackOrClusterStatusFailed(stackV4Response.getCluster().getStatus())) {\n+            LOGGER.info(\"{} failed for Cluster {} status {}\", pollingMessage, stackV4Response.getCluster().getName(),\n+                    stackV4Response.getCluster().getStatus());\n+            return sdxDrFailed(sdxCluster, stackV4Response.getCluster().getStatusReason(), pollingMessage);\n+        } else if (FINISHED.equals(flowState)) {\n+            LOGGER.info(\"Flow finished, but Backup/Restore is not complete: {}\", sdxCluster.getClusterName());\n+            return sdxDrFailed(sdxCluster, \"stack is in improper state\", pollingMessage);\n+        } else {\n+            LOGGER.info(\"Flow is unknown state\");\n+            return sdxDrFailed(sdxCluster, \"Flow is unknown state\", pollingMessage);\n+        }\n+    }\n+\n+    /**\n+     * Checks the status if the backup/restore operation failed.\n+     * @param status It could be stack/cluster status\n+     * @return true if status is failed, false otherwise.\n+     */", "originalCommit": "84c0a31f4e95900fb13de42d1db56c55e1c6bd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI0Njg5Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446246897", "bodyText": "will do", "author": "kkalvagadda1", "createdAt": "2020-06-26T15:16:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE3MDQ0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\nindex 7eaa625de0..5d4d47a675 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/service/sdx/dr/SdxDatabaseDrService.java\n\n@@ -1,8 +1,8 @@\n package com.sequenceiq.datalake.service.sdx.dr;\n \n import static com.sequenceiq.cloudbreak.exception.NotFoundException.notFound;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n-import static com.sequenceiq.datalake.flow.dr.DatalakeDatabaseDrEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.backup.DatalakeDatabaseBackupEvent.DATALAKE_DATABASE_BACKUP_EVENT;\n+import static com.sequenceiq.datalake.flow.dr.restore.DatalakeDatabaseRestoreEvent.DATALAKE_DATABASE_RESTORE_EVENT;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.FINISHED;\n import static com.sequenceiq.datalake.service.sdx.CloudbreakFlowService.FlowState.RUNNING;\n \n"}}, {"oid": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "url": "https://github.com/hortonworks/cloudbreak/commit/4592edaca637c73aebd18e9c87b2e62a1143aa11", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-26T15:25:43Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5NTA4Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446895086", "bodyText": "I think this class should be renamed also", "author": "lacikaaa", "createdAt": "2020-06-29T11:22:47Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/converter/SdxDatabaseDrStatusTypeEnumConverter.java", "diffHunk": "@@ -0,0 +1,12 @@\n+package com.sequenceiq.datalake.converter;\n+\n+import com.sequenceiq.cloudbreak.converter.DefaultEnumConverter;\n+import com.sequenceiq.datalake.entity.operation.SdxOperationStatusTypeEnum;\n+\n+public class SdxDatabaseDrStatusTypeEnumConverter extends DefaultEnumConverter<SdxOperationStatusTypeEnum> {", "originalCommit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk5MjQ5Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446992493", "bodyText": "ok", "author": "kkalvagadda1", "createdAt": "2020-06-29T13:58:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5NTA4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "cb474bc68b698a1fe3a72cafece971a6000dfa05", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/converter/SdxDatabaseDrStatusTypeEnumConverter.java b/datalake/src/main/java/com/sequenceiq/datalake/converter/SdxDatabaseDrStatusTypeEnumConverter.java\ndeleted file mode 100644\nindex 22535b74ab..0000000000\n--- a/datalake/src/main/java/com/sequenceiq/datalake/converter/SdxDatabaseDrStatusTypeEnumConverter.java\n+++ /dev/null\n\n@@ -1,12 +0,0 @@\n-package com.sequenceiq.datalake.converter;\n-\n-import com.sequenceiq.cloudbreak.converter.DefaultEnumConverter;\n-import com.sequenceiq.datalake.entity.operation.SdxOperationStatusTypeEnum;\n-\n-public class SdxDatabaseDrStatusTypeEnumConverter extends DefaultEnumConverter<SdxOperationStatusTypeEnum> {\n-\n-    @Override\n-    public SdxOperationStatusTypeEnum getDefault() {\n-        return SdxOperationStatusTypeEnum.INIT;\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5NjY3MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446896670", "bodyText": "I think SdxOperation would fit better, there is too much status around this class", "author": "lacikaaa", "createdAt": "2020-06-29T11:25:54Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java", "diffHunk": "@@ -0,0 +1,92 @@\n+package com.sequenceiq.datalake.entity.operation;\n+\n+import java.util.UUID;\n+\n+import javax.persistence.Convert;\n+import javax.persistence.Entity;\n+import javax.persistence.GeneratedValue;\n+import javax.persistence.GenerationType;\n+import javax.persistence.Id;\n+import javax.persistence.SequenceGenerator;\n+import javax.persistence.Table;\n+import javax.persistence.UniqueConstraint;\n+import javax.validation.constraints.NotNull;\n+\n+import com.sequenceiq.datalake.converter.SdxOperationTypeEnumConverter;\n+import com.sequenceiq.datalake.converter.SdxDatabaseDrStatusTypeEnumConverter;\n+\n+@Entity\n+@Table(uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))\n+public class SdxOperationStatus {", "originalCommit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cb474bc68b698a1fe3a72cafece971a6000dfa05", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java\nindex 3651181b99..8131d34768 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatus.java\n\n@@ -1,92 +1,19 @@\n package com.sequenceiq.datalake.entity.operation;\n \n-import java.util.UUID;\n+public enum SdxOperationStatus {\n+    INIT(\"INIT\"),\n+    TRIGGERRED(\"TRIGGERRED\"),\n+    INPROGRESS(\"INPROGRESS\"),\n+    SUCCEEDED(\"SUCCEEDED\"),\n+    FAILED(\"FAILED\");\n \n-import javax.persistence.Convert;\n-import javax.persistence.Entity;\n-import javax.persistence.GeneratedValue;\n-import javax.persistence.GenerationType;\n-import javax.persistence.Id;\n-import javax.persistence.SequenceGenerator;\n-import javax.persistence.Table;\n-import javax.persistence.UniqueConstraint;\n-import javax.validation.constraints.NotNull;\n+    private String name;\n \n-import com.sequenceiq.datalake.converter.SdxOperationTypeEnumConverter;\n-import com.sequenceiq.datalake.converter.SdxDatabaseDrStatusTypeEnumConverter;\n-\n-@Entity\n-@Table(uniqueConstraints = @UniqueConstraint(columnNames = {\"operationId\"}))\n-public class SdxOperationStatus {\n-\n-    @Id\n-    @GeneratedValue(strategy = GenerationType.AUTO, generator = \"sdx_status_generator\")\n-    @SequenceGenerator(name = \"sdx_status_generator\", sequenceName = \"sdxstatus_id_seq\", allocationSize = 1)\n-    private Long id;\n-\n-    @NotNull\n-    @Convert(converter = SdxOperationTypeEnumConverter.class)\n-    private SdxOperationTypeEnum operationType;\n-\n-    @NotNull\n-    private Long sdxClusterId;\n-\n-    private String operationId;\n-\n-    private String statusReason;\n-\n-    @NotNull\n-    @Convert(converter = SdxDatabaseDrStatusTypeEnumConverter.class)\n-    private SdxOperationStatusTypeEnum status;\n-\n-    public SdxOperationStatus() {\n+    SdxOperationStatus(String name) {\n+        this.name = name;\n     }\n \n-    public SdxOperationStatus(SdxOperationTypeEnum operationType, long sdxClusterId) {\n-        this.operationId = UUID.randomUUID().toString();\n-        this.operationType = operationType;\n-        this.sdxClusterId = sdxClusterId;\n-        this.status = SdxOperationStatusTypeEnum.INIT;\n+    public String getName() {\n+        return name;\n     }\n-\n-    public String getOperationId() {\n-        return operationId;\n-    }\n-\n-    public void setOperationId(String operationId) {\n-        this.operationId = operationId;\n-    }\n-\n-    public Long getSdxClusterId() {\n-        return sdxClusterId;\n-    }\n-\n-    public SdxOperationTypeEnum getOperationType() {\n-        return operationType;\n-    }\n-\n-    public void setOperationType(SdxOperationTypeEnum operationType) {\n-        this.operationType = operationType;\n-    }\n-\n-    public String getStatusReason() {\n-        return statusReason;\n-    }\n-\n-    public void setStatusReason(String statusReason) {\n-        this.statusReason = statusReason;\n-    }\n-\n-    public SdxOperationStatusTypeEnum getStatus() {\n-        return status;\n-    }\n-\n-    public void setSdxClusterId(Long sdxClusterId) {\n-        this.sdxClusterId = sdxClusterId;\n-    }\n-\n-    public void setStatus(SdxOperationStatusTypeEnum status) {\n-        this.status = status;\n-    }\n-\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5NzUzOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446897539", "bodyText": "rename to SdxOperationStatus", "author": "lacikaaa", "createdAt": "2020-06-29T11:27:31Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatusTypeEnum.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package com.sequenceiq.datalake.entity.operation;\n+\n+public enum SdxOperationStatusTypeEnum {", "originalCommit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cb474bc68b698a1fe3a72cafece971a6000dfa05", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatusTypeEnum.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatusTypeEnum.java\ndeleted file mode 100644\nindex 8015ed6843..0000000000\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationStatusTypeEnum.java\n+++ /dev/null\n\n@@ -1,19 +0,0 @@\n-package com.sequenceiq.datalake.entity.operation;\n-\n-public enum SdxOperationStatusTypeEnum {\n-    INIT(\"INIT\"),\n-    TRIGGERRED(\"TRIGGERRED\"),\n-    INPROGRESS(\"INPROGRESS\"),\n-    SUCCEEDED(\"SUCCEEDED\"),\n-    FAILED(\"FAILED\");\n-\n-    private String name;\n-\n-    SdxOperationStatusTypeEnum(String name) {\n-        this.name = name;\n-    }\n-\n-    public String getName() {\n-        return name;\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njg5ODIzNA==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446898234", "bodyText": "drop the Enum from the end", "author": "lacikaaa", "createdAt": "2020-06-29T11:28:57Z", "path": "datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationTypeEnum.java", "diffHunk": "@@ -0,0 +1,17 @@\n+package com.sequenceiq.datalake.entity.operation;\n+\n+public enum SdxOperationTypeEnum {", "originalCommit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "cb474bc68b698a1fe3a72cafece971a6000dfa05", "chunk": "diff --git a/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationTypeEnum.java b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationType.java\nsimilarity index 75%\nrename from datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationTypeEnum.java\nrename to datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationType.java\nindex 82cad59047..695a777615 100644\n--- a/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationTypeEnum.java\n+++ b/datalake/src/main/java/com/sequenceiq/datalake/entity/operation/SdxOperationType.java\n\n@@ -1,13 +1,13 @@\n package com.sequenceiq.datalake.entity.operation;\n \n-public enum SdxOperationTypeEnum {\n+public enum SdxOperationType {\n     NONE(\"NONE\"),\n     BACKUP(\"BACKUP\"),\n     RESTORE(\"RESTORE\");\n \n     private String name;\n \n-    SdxOperationTypeEnum(String name) {\n+    SdxOperationType(String name) {\n         this.name = name;\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMTI5MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446901291", "bodyText": "I don't know which pr will contain the final setting for this, but the 2 FAILED statuses should be here also.\ncc @hreeve-cloudera", "author": "lacikaaa", "createdAt": "2020-06-29T11:34:49Z", "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -156,7 +156,9 @@ protected void executeInternal(JobExecutionContext context) throws JobExecutionE\n                 Status.START_FAILED,\n                 Status.STOPPED,\n                 Status.STOP_FAILED,\n-                Status.AMBIGUOUS\n+                Status.AMBIGUOUS,\n+                Status.BACKUP_FINISHED,\n+                Status.RESTORE_FINISHED", "originalCommit": "4592edaca637c73aebd18e9c87b2e62a1143aa11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Njk5ODM2Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/8194#discussion_r446998362", "bodyText": "will take care of it.", "author": "kkalvagadda1", "createdAt": "2020-06-29T14:06:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMTI5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "b1a94bc7942abdb0d7e5ea324ba2eddcdba0c80c", "chunk": "diff --git a/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java b/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\nindex 5ad7a83e6e..ed05d13224 100644\n--- a/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\n+++ b/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\n\n@@ -157,6 +155,8 @@ public class StackStatusCheckerJob extends StatusCheckerJob {\n                 Status.STOPPED,\n                 Status.STOP_FAILED,\n                 Status.AMBIGUOUS,\n+                Status.RESTORE_FAILED,\n+                Status.BACKUP_FAILED,\n                 Status.BACKUP_FINISHED,\n                 Status.RESTORE_FINISHED\n         );\n"}}, {"oid": "f36e483bae35f9e39f0c958d3b73e7002981153a", "url": "https://github.com/hortonworks/cloudbreak/commit/f36e483bae35f9e39f0c958d3b73e7002981153a", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-29T13:32:05Z", "type": "forcePushed"}, {"oid": "cb474bc68b698a1fe3a72cafece971a6000dfa05", "url": "https://github.com/hortonworks/cloudbreak/commit/cb474bc68b698a1fe3a72cafece971a6000dfa05", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-29T14:31:49Z", "type": "forcePushed"}, {"oid": "b1a94bc7942abdb0d7e5ea324ba2eddcdba0c80c", "url": "https://github.com/hortonworks/cloudbreak/commit/b1a94bc7942abdb0d7e5ea324ba2eddcdba0c80c", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-29T14:47:13Z", "type": "forcePushed"}, {"oid": "87ffbcb7be03687ef4eae15f750eb4889195a22f", "url": "https://github.com/hortonworks/cloudbreak/commit/87ffbcb7be03687ef4eae15f750eb4889195a22f", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-29T15:25:28Z", "type": "commit"}, {"oid": "87ffbcb7be03687ef4eae15f750eb4889195a22f", "url": "https://github.com/hortonworks/cloudbreak/commit/87ffbcb7be03687ef4eae15f750eb4889195a22f", "message": "CB-7212: Add datalake service changes to perform database backup/restore.", "committedDate": "2020-06-29T15:25:28Z", "type": "forcePushed"}]}