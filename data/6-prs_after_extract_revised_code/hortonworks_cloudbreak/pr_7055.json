{"pr_number": 7055, "pr_title": "CB-4613 Apply syncer to CB for cluster syncs", "pr_createdAt": "2020-01-13T12:06:45Z", "pr_url": "https://github.com/hortonworks/cloudbreak/pull/7055", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTgxOTIyOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7055#discussion_r365819229", "bodyText": "has this the same logic as getAllFailedInstanceMetadata?", "author": "horadla23", "createdAt": "2020-01-13T14:03:02Z", "path": "core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java", "diffHunk": "@@ -0,0 +1,229 @@\n+package com.sequenceiq.cloudbreak.job;\n+\n+import static com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.base.InstanceStatus.SERVICES_UNHEALTHY;\n+import static com.sequenceiq.cloudbreak.cloud.model.AvailabilityZone.availabilityZone;\n+import static com.sequenceiq.cloudbreak.cloud.model.HostName.hostName;\n+import static com.sequenceiq.cloudbreak.cloud.model.Location.location;\n+import static com.sequenceiq.cloudbreak.cloud.model.Region.region;\n+import static java.util.stream.Collectors.toSet;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.inject.Inject;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.quartz.JobExecutionContext;\n+import org.quartz.JobExecutionException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.gs.collections.impl.factory.Sets;\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.Status;\n+import com.sequenceiq.cloudbreak.cloud.context.CloudContext;\n+import com.sequenceiq.cloudbreak.cloud.handler.InstanceStateQuery;\n+import com.sequenceiq.cloudbreak.cloud.model.CloudCredential;\n+import com.sequenceiq.cloudbreak.cloud.model.CloudInstance;\n+import com.sequenceiq.cloudbreak.cloud.model.CloudVmInstanceStatus;\n+import com.sequenceiq.cloudbreak.cloud.model.HostName;\n+import com.sequenceiq.cloudbreak.cloud.model.InstanceStatus;\n+import com.sequenceiq.cloudbreak.cloud.model.Location;\n+import com.sequenceiq.cloudbreak.cluster.api.ClusterApi;\n+import com.sequenceiq.cloudbreak.cluster.status.ClusterStatus;\n+import com.sequenceiq.cloudbreak.cluster.status.ClusterStatusResult;\n+import com.sequenceiq.cloudbreak.common.type.ClusterManagerState;\n+import com.sequenceiq.cloudbreak.converter.spi.CredentialToCloudCredentialConverter;\n+import com.sequenceiq.cloudbreak.converter.spi.InstanceMetaDataToCloudInstanceConverter;\n+import com.sequenceiq.cloudbreak.domain.stack.Stack;\n+import com.sequenceiq.cloudbreak.domain.stack.cluster.Cluster;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceGroup;\n+import com.sequenceiq.cloudbreak.domain.stack.instance.InstanceMetaData;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterApiConnectors;\n+import com.sequenceiq.cloudbreak.service.cluster.ClusterService;\n+import com.sequenceiq.cloudbreak.service.environment.credential.CredentialConverter;\n+import com.sequenceiq.cloudbreak.service.stack.StackService;\n+import com.sequenceiq.cloudbreak.service.stack.flow.InstanceSyncState;\n+import com.sequenceiq.cloudbreak.service.stack.flow.StackSyncService;\n+import com.sequenceiq.environment.client.EnvironmentInternalCrnClient;\n+import com.sequenceiq.flow.core.FlowLogService;\n+import com.sequenceiq.statuschecker.job.StatusCheckerJob;\n+\n+@Component\n+public class StackStatusCheckerJob extends StatusCheckerJob {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(StackStatusCheckerJob.class);\n+\n+    @Inject\n+    private StackService stackService;\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private ClusterApiConnectors clusterApiConnectors;\n+\n+    @Inject\n+    private InstanceMetaDataToCloudInstanceConverter cloudInstanceConverter;\n+\n+    @Inject\n+    private InstanceStateQuery instanceStateQuery;\n+\n+    @Inject\n+    private EnvironmentInternalCrnClient environmentInternalCrnClient;\n+\n+    @Inject\n+    private CredentialConverter credentialConverter;\n+\n+    @Inject\n+    private CredentialToCloudCredentialConverter cloudCredentialConverter;\n+\n+    @Inject\n+    private StackSyncService syncService;\n+\n+    @Inject\n+    private FlowLogService flowLogService;\n+\n+    @Override\n+    protected void executeInternal(JobExecutionContext context) throws JobExecutionException {\n+        if (flowLogService.isOtherFlowRunning(getStackId())) {\n+            LOGGER.debug(\"StackStatusCheckerJob cannot run, because flow is running for stack: {}\", getStackId());\n+            return;\n+        }\n+        try {\n+            Stack stack = stackService.getByIdWithListsInTransaction(getStackId());\n+            if (stack.isStackInDeletionOrFailedPhase()) {\n+                LOGGER.debug(\"StackStatusCheckerJob cannot run, stack is being terminated: {}\", getStackId());\n+                return;\n+            }\n+            ClusterApi connector = clusterApiConnectors.getConnector(stack);\n+            try {\n+                if (isClusterManagerRunning(stack, connector)) {\n+                    Map<HostName, ClusterManagerState> hostStatuses = connector.clusterStatusService().getExtendedHostStatuses();\n+                    LOGGER.debug(\"Cluster '{}' state check, cm running, hoststates: {}\", stack.getId(), hostStatuses);\n+                    reportHealthAndSyncInstances(stack, getFailedInstancesInstanceMetadata(stack, hostStatuses),\n+                            getNewHealthyHostNames(stack, hostStatuses), InstanceSyncState.RUNNING);\n+                } else {\n+                    syncInstances(stack, getAllRunningInstanceMetadata(stack), InstanceSyncState.DELETED_ON_PROVIDER_SIDE);\n+                }\n+            } catch (RuntimeException e) {\n+                syncInstances(stack, getAllRunningInstanceMetadata(stack), InstanceSyncState.DELETED_ON_PROVIDER_SIDE);\n+            }\n+        } catch (Exception e) {\n+            LOGGER.info(\"Exception during cluster state check.\", e);\n+        }\n+    }\n+\n+    private void reportHealthAndSyncInstances(Stack stack, Collection<InstanceMetaData> failedInstances,\n+            Set<String> newHealtyHostNames, InstanceSyncState defaultState) {\n+        Set<String> failedNodeNames = failedInstances.stream()\n+                .map(InstanceMetaData::getDiscoveryFQDN)\n+                .collect(toSet());\n+        clusterService.reportHealthChange(stack.getResourceCrn(), failedNodeNames, newHealtyHostNames);\n+        if (failedNodeNames.size() > 0) {\n+            clusterService.updateClusterStatusByStackId(stack.getId(), Status.AMBIGUOUS);\n+        } else if (stack.getCluster().getStatus() == Status.AMBIGUOUS) {\n+            clusterService.updateClusterStatusByStackId(stack.getId(), Status.AVAILABLE);\n+        }\n+        syncInstances(stack, failedInstances, InstanceSyncState.RUNNING);\n+    }\n+\n+    private boolean isClusterManagerRunning(Stack stack, ClusterApi connector) {\n+        return !stack.isStopped() && !queryClusterStatus(connector).getClusterStatus().equals(ClusterStatus.AMBARISERVER_NOT_RUNNING);\n+    }\n+\n+    private void syncInstances(Stack stack, Collection<InstanceMetaData> instanceMetaData, InstanceSyncState defaultState) {\n+        List<CloudVmInstanceStatus> instanceStatuses = queryInstanceStatuses(stack, instanceMetaData);\n+        LOGGER.debug(\"Cluster '{}' state check on provider, instances: {}\", stack.getId(), instanceStatuses);\n+        syncService.autoSync(stack, instanceStatuses, true, defaultState);\n+    }\n+\n+    private ClusterStatusResult queryClusterStatus(ClusterApi connector) {\n+        Optional<Cluster> cluster = clusterService.retrieveClusterByStackIdWithoutAuth(getStackId());\n+        String blueprintName = cluster.isPresent() ? cluster.get().getBlueprint().getStackName() : null;\n+        return connector.clusterStatusService().getStatus(StringUtils.isNotBlank(blueprintName));\n+    }\n+\n+    private Set<String> getNewHealthyHostNames(Stack stack, Map<HostName, ClusterManagerState> hostStatuses) {\n+        Set<String> healthyHosts = hostStatuses.entrySet().stream()\n+                .filter(e -> e.getValue().getClusterManagerStatus() == ClusterManagerState.ClusterManagerStatus.HEALTHY)\n+                .map(Map.Entry::getKey)\n+                .map(HostName::value)\n+                .collect(Collectors.toSet());\n+        Set<String> unhealthyStoredHosts = getAllRunningInstanceMetadata(stack).stream()\n+                .filter(i -> i.getInstanceStatus() == SERVICES_UNHEALTHY)\n+                .map(InstanceMetaData::getDiscoveryFQDN)\n+                .collect(Collectors.toSet());\n+        return Sets.intersect(healthyHosts, unhealthyStoredHosts);\n+    }\n+\n+    private Set<InstanceMetaData> getFailedInstancesInstanceMetadata(Stack stack, Map<HostName, ClusterManagerState> hostStatuses) {\n+        Set<String> failedHosts = hostStatuses.entrySet().stream()\n+                .filter(e -> e.getValue().getClusterManagerStatus() == ClusterManagerState.ClusterManagerStatus.UNHEALTHY)\n+                .map(Map.Entry::getKey)\n+                .map(HostName::value)\n+                .collect(Collectors.toSet());\n+        Set<String> noReportHosts = getAllRunningInstanceMetadata(stack).stream()\n+                .filter(i -> hostStatuses.get(hostName(i.getDiscoveryFQDN())) == null)\n+                .map(InstanceMetaData::getDiscoveryFQDN)\n+                .collect(Collectors.toSet());\n+        return stack.getInstanceMetaDataAsList().stream()\n+                .filter(i -> failedHosts.contains(i.getDiscoveryFQDN()) || noReportHosts.contains(i.getDiscoveryFQDN()))\n+                .collect(Collectors.toSet());\n+    }\n+\n+    private List<InstanceMetaData> getAllRunningInstanceMetadata(Stack stack) {", "originalCommit": "ce97670a169638f2731a9b3726a197356527dc2e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3d209e8b94c5bc43e8ab3628562043845646e605", "chunk": "diff --git a/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java b/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\nindex 0e4c8e2cbb..6ade7f913a 100644\n--- a/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\n+++ b/core/src/main/java/com/sequenceiq/cloudbreak/job/StackStatusCheckerJob.java\n\n@@ -184,13 +184,6 @@ public class StackStatusCheckerJob extends StatusCheckerJob {\n                 .collect(Collectors.toList());\n     }\n \n-    private List<InstanceMetaData> getAllFailedInstanceMetadata(Stack stack) {\n-        return stack.getInstanceGroups().stream()\n-                .map(InstanceGroup::getNotDeletedInstanceMetaDataSet)\n-                .flatMap(Set::stream)\n-                .collect(Collectors.toList());\n-    }\n-\n     private Long getStackId() {\n         return Long.valueOf(getLocalId());\n     }\n"}}, {"oid": "3d209e8b94c5bc43e8ab3628562043845646e605", "url": "https://github.com/hortonworks/cloudbreak/commit/3d209e8b94c5bc43e8ab3628562043845646e605", "message": "CB-4613 Apply syncer to CB for cluster syncs", "committedDate": "2020-01-13T14:12:07Z", "type": "forcePushed"}, {"oid": "6983f1ba7bc2679f2c64a4b2e2fd8c0048218aaa", "url": "https://github.com/hortonworks/cloudbreak/commit/6983f1ba7bc2679f2c64a4b2e2fd8c0048218aaa", "message": "CB-4613 Apply syncer to CB for cluster syncs", "committedDate": "2020-01-14T09:01:16Z", "type": "commit"}, {"oid": "6983f1ba7bc2679f2c64a4b2e2fd8c0048218aaa", "url": "https://github.com/hortonworks/cloudbreak/commit/6983f1ba7bc2679f2c64a4b2e2fd8c0048218aaa", "message": "CB-4613 Apply syncer to CB for cluster syncs", "committedDate": "2020-01-14T09:01:16Z", "type": "forcePushed"}]}