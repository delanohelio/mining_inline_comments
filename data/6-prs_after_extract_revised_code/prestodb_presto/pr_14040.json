{"pr_number": 14040, "pr_title": "Move Hive filter pushdown logic out of PickTableLayout", "pr_createdAt": "2020-02-01T01:51:08Z", "pr_url": "https://github.com/prestodb/presto/pull/14040", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc1Njc1MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r373756750", "bodyText": "this should be injected into HiveConnector. No need to open an interface.", "author": "highker", "createdAt": "2020-02-01T04:20:55Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -2593,6 +2593,11 @@ public void revokeTablePrivileges(ConnectorSession session, SchemaTableName sche\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n+    public FunctionMetadataManager getFunctionMetadataManager()", "originalCommit": "d74e26c2e63460610484c75369ad925154f7397a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDAwNTU3Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384005577", "bodyText": "@sachdevs +1. Is there any particular reason to introduce this method?", "author": "mbasmanova", "createdAt": "2020-02-25T17:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc1Njc1MA=="}], "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\nindex ac677f968b..e4ffb835e2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n\n@@ -2593,11 +2463,6 @@ public class HiveMetadata\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n-    public FunctionMetadataManager getFunctionMetadataManager()\n-    {\n-        return functionMetadataManager;\n-    }\n-\n     private List<GrantInfo> buildGrants(SchemaTableName tableName, PrestoPrincipal principal)\n     {\n         ImmutableList.Builder<GrantInfo> result = ImmutableList.builder();\n"}}, {"oid": "d3049bc52bee892f804ee2edb95d7f31cc526f8a", "url": "https://github.com/prestodb/presto/commit/d3049bc52bee892f804ee2edb95d7f31cc526f8a", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-03T18:34:33Z", "type": "forcePushed"}, {"oid": "5c5de97bcbf70f260298abb74cbe6b7f44084edc", "url": "https://github.com/prestodb/presto/commit/5c5de97bcbf70f260298abb74cbe6b7f44084edc", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-03T20:56:33Z", "type": "forcePushed"}, {"oid": "6db4a0a05338e05cf74d12276af8ea812bfd06b2", "url": "https://github.com/prestodb/presto/commit/6db4a0a05338e05cf74d12276af8ea812bfd06b2", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-04T01:30:36Z", "type": "forcePushed"}, {"oid": "a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "url": "https://github.com/prestodb/presto/commit/a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-05T20:58:28Z", "type": "forcePushed"}, {"oid": "cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "url": "https://github.com/prestodb/presto/commit/cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-05T21:43:44Z", "type": "forcePushed"}, {"oid": "155a2a17645fc737d90477f444576a1cb8b44f81", "url": "https://github.com/prestodb/presto/commit/155a2a17645fc737d90477f444576a1cb8b44f81", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-07T22:12:55Z", "type": "forcePushed"}, {"oid": "6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "url": "https://github.com/prestodb/presto/commit/6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-07T22:23:19Z", "type": "forcePushed"}, {"oid": "7453811611d6a1364f2ec185556170654630ad8f", "url": "https://github.com/prestodb/presto/commit/7453811611d6a1364f2ec185556170654630ad8f", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-08T00:02:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTI5NA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r376759294", "bodyText": "We should combine all these visitors into one. No need to separate them apart.", "author": "highker", "createdAt": "2020-02-09T06:38:56Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java", "diffHunk": "@@ -0,0 +1,527 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorPushdownFilterResult;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveFilterPushdownLogicalOptimizer\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdownLogicalOptimizer(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        PlanNode newPlan = maxSubplan.accept(new FilterVisitor(session, idAllocator, transactionManager), null);\n+        return newPlan.accept(new TableScanVisitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdownLogicalOptimizer::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    private abstract class Visitor", "originalCommit": "7453811611d6a1364f2ec185556170654630ad8f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI2MjQ0Mw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377262443", "bodyText": "I'll check if that is doable. Using multiple visitors as the original code had multiple optimizer rules executed one after another. If both rules are executed mutually exclusively then this is possible. I'll check if it works.", "author": "sachdevs", "createdAt": "2020-02-10T19:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTI5NA=="}], "type": "inlineReview", "revised_code": {"commit": "78504d28d98fbf4946ae4a228364d7a5cc6daa08", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java\nindex e4112a7fd9..0ac726a949 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java\n\n@@ -285,7 +285,8 @@ public class HiveFilterPushdownLogicalOptimizer\n         public PlanNode visitFilter(FilterNode filter, Void context)\n         {\n             if (!(filter.getSource() instanceof TableScanNode)) {\n-                return filter;\n+//                return filter;\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n             }\n \n             TableScanNode tableScan = (TableScanNode) filter.getSource();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTMxNw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r376759317", "bodyText": "This doesn't seem right. It should be return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());. Otherwise, the visitor will stop exploring for such case.", "author": "highker", "createdAt": "2020-02-09T06:39:45Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java", "diffHunk": "@@ -0,0 +1,527 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorPushdownFilterResult;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveFilterPushdownLogicalOptimizer\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdownLogicalOptimizer(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        PlanNode newPlan = maxSubplan.accept(new FilterVisitor(session, idAllocator, transactionManager), null);\n+        return newPlan.accept(new TableScanVisitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdownLogicalOptimizer::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    private abstract class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        protected final ConnectorSession session;\n+        protected final PlanNodeIdAllocator idAllocator;\n+        protected final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+    }\n+\n+    private class FilterVisitor\n+            extends Visitor\n+    {\n+        FilterVisitor(ConnectorSession session, PlanNodeIdAllocator idAllocator, HiveTransactionManager transactionManager)\n+        {\n+            super(session, idAllocator, transactionManager);\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return filter;", "originalCommit": "7453811611d6a1364f2ec185556170654630ad8f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI2MjU2Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377262567", "bodyText": "Nice catch :)", "author": "sachdevs", "createdAt": "2020-02-10T19:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTMxNw=="}], "type": "inlineReview", "revised_code": {"commit": "78504d28d98fbf4946ae4a228364d7a5cc6daa08", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java\nindex e4112a7fd9..0ac726a949 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java\n\n@@ -285,7 +285,8 @@ public class HiveFilterPushdownLogicalOptimizer\n         public PlanNode visitFilter(FilterNode filter, Void context)\n         {\n             if (!(filter.getSource() instanceof TableScanNode)) {\n-                return filter;\n+//                return filter;\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n             }\n \n             TableScanNode tableScan = (TableScanNode) filter.getSource();\n"}}, {"oid": "78504d28d98fbf4946ae4a228364d7a5cc6daa08", "url": "https://github.com/prestodb/presto/commit/78504d28d98fbf4946ae4a228364d7a5cc6daa08", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-10T18:54:04Z", "type": "forcePushed"}, {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "url": "https://github.com/prestodb/presto/commit/8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-10T23:37:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Mjg5Mw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377382893", "bodyText": "This part of the test verification can no longer occur in this way as we cannot explicitly call metadata.pushdownFilter", "author": "sachdevs", "createdAt": "2020-02-10T23:42:21Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2052,15 +2050,15 @@ private void doTestBucketedTableEvolution(HiveStorageFormat storageFormat, Schem\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-\n-                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-            }\n-            else {\n-                layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-            }\n+//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n+//\n+//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n+//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//            }\n+//            else {\n+            layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n+//            }", "originalCommit": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex ed555046b1..65a1909066 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -2050,15 +2026,7 @@ public abstract class AbstractTestHiveClient\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-//\n-//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-//            }\n-//            else {\n             layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-//            }\n \n             result = readTable(\n                     transaction,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Mjk1MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377382950", "bodyText": "ditto.", "author": "sachdevs", "createdAt": "2020-02-10T23:42:32Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2373,12 +2371,12 @@ public void testPartitionSchemaNonCanonical()\n \n     private static ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorMetadata metadata, ConnectorTableHandle tableHandle, Constraint<ColumnHandle> constraint)\n     {\n-        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-            assertTrue(constraint.getSummary().isAll());\n-\n-            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n-            return pushdownFilterResult.getLayout();\n-        }\n+//        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//            assertTrue(constraint.getSummary().isAll());\n+//\n+//            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n+//            return pushdownFilterResult.getLayout();\n+//        }\n ", "originalCommit": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex ed555046b1..47ac668b22 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -2369,14 +2394,23 @@ public abstract class AbstractTestHiveClient\n         }\n     }\n \n-    private static ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorMetadata metadata, ConnectorTableHandle tableHandle, Constraint<ColumnHandle> constraint)\n+    private ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorMetadata metadata, ConnectorTableHandle tableHandle, Constraint<ColumnHandle> constraint, Transaction transaction)\n     {\n-//        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-//            assertTrue(constraint.getSummary().isAll());\n-//\n-//            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n-//            return pushdownFilterResult.getLayout();\n-//        }\n+        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+            assertTrue(constraint.getSummary().isAll());\n+\n+            return pushdownFilter(\n+                    session,\n+                    metadata,\n+                    transaction.getMetastore(\"\"), // function does not use param in all implementations?\n+                    ROW_EXPRESSION_SERVICE,\n+                    FUNCTION_RESOLUTION,\n+                    hivePartitionManager,\n+                    METADATA.getFunctionManager(),\n+                    tableHandle,\n+                    TRUE_CONSTANT,\n+                    Optional.empty()).getLayout();\n+        }\n \n         List<ConnectorTableLayoutResult> tableLayoutResults = metadata.getTableLayouts(session, tableHandle, constraint, Optional.empty());\n         return getOnlyElement(tableLayoutResults).getTableLayout();\n"}}, {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "url": "https://github.com/prestodb/presto/commit/a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-11T19:48:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NDc3Mg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378444772", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-12T18:50:40Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 036509d9c1..39949a4ff9 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -131,7 +131,7 @@ public class HiveFilterPushdown\n     @Override\n     public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n     {\n-        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n     }\n \n     protected ConnectorPushdownFilterResult pushdownFilter(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NTI1NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378445255", "bodyText": "nit node", "author": "highker", "createdAt": "2020-02-12T18:51:33Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 036509d9c1..39949a4ff9 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -131,7 +131,7 @@ public class HiveFilterPushdown\n     @Override\n     public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n     {\n-        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n     }\n \n     protected ConnectorPushdownFilterResult pushdownFilter(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0OTY1OQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378449659", "bodyText": "static", "author": "highker", "createdAt": "2020-02-12T18:59:31Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), ret, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return ret;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            return new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    pushdownFilterResult.getLayout().getPredicate(),\n+                    TupleDomain.all());\n+        }\n+    }\n+\n+    private static class ConstraintEvaluator\n+    {\n+        private final Map<String, ColumnHandle> assignments;\n+        private final RowExpressionService evaluator;\n+        private final ConnectorSession session;\n+        private final RowExpression expression;\n+        private final Set<ColumnHandle> arguments;\n+\n+        public ConstraintEvaluator(RowExpressionService evaluator, ConnectorSession session, Map<String, ColumnHandle> assignments, RowExpression expression)\n+        {\n+            this.assignments = assignments;\n+            this.evaluator = evaluator;\n+            this.session = session;\n+            this.expression = expression;\n+\n+            arguments = ImmutableSet.copyOf(extractAll(expression)).stream()\n+                    .map(VariableReferenceExpression::getName)\n+                    .map(assignments::get)\n+                    .collect(toImmutableSet());\n+        }\n+\n+        private boolean isCandidate(Map<ColumnHandle, NullableValue> bindings)\n+        {\n+            if (intersection(bindings.keySet(), arguments).isEmpty()) {\n+                return true;\n+            }\n+\n+            Function<VariableReferenceExpression, Object> variableResolver = variable -> {\n+                ColumnHandle column = assignments.get(variable.getName());\n+                checkArgument(column != null, \"Missing column assignment for %s\", variable);\n+\n+                if (!bindings.containsKey(column)) {\n+                    return variable;\n+                }\n+\n+                return bindings.get(column).getValue();\n+            };\n+\n+            // Skip pruning if evaluation fails in a recoverable way. Failing here can cause\n+            // spurious query failures for partitions that would otherwise be filtered out.\n+            Object optimized = null;\n+            try {\n+                optimized = evaluator.getExpressionOptimizer().optimize(expression, OPTIMIZED, session, variableResolver);\n+            }\n+            catch (PrestoException e) {\n+                propagateIfUnhandled(e);\n+            }\n+\n+            // If any conjuncts evaluate to FALSE or null, then the whole predicate will never be true and so the partition should be pruned\n+            return !Boolean.FALSE.equals(optimized) && optimized != null && (!(optimized instanceof ConstantExpression) || !((ConstantExpression) optimized).isNull());\n+        }\n+\n+        private static void propagateIfUnhandled(PrestoException e)\n+                throws PrestoException\n+        {\n+            int errorCode = e.getErrorCode().getCode();\n+            if (errorCode == DIVISION_BY_ZERO.toErrorCode().getCode()\n+                    || errorCode == INVALID_CAST_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == INVALID_FUNCTION_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == NUMERIC_VALUE_OUT_OF_RANGE.toErrorCode().getCode()) {\n+                return;\n+            }\n+\n+            throw e;\n+        }\n+    }\n+\n+    private HiveMetadata getMetadata(TableHandle tableHandle)\n+    {\n+        ConnectorMetadata metadata = transactionManager.get(tableHandle.getTransaction());\n+        checkState(metadata instanceof HiveMetadata, \"metadata must be HiveMetadata\");\n+        return (HiveMetadata) metadata;\n+    }\n+\n+    private String getColumnName(ConnectorSession session, HiveMetadata metadata, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n+    {\n+        return metadata.getColumnMetadata(session, tableHandle, columnHandle).getName();\n+    }\n+\n+    private boolean isPushdownFilterSupported(ConnectorSession session, TableHandle tableHandle)\n+    {\n+        checkArgument(tableHandle.getConnectorHandle() instanceof HiveTableHandle, \"pushdownFilter is never supported on a non-hive TableHandle\");\n+        if (((HiveTableHandle) tableHandle.getConnectorHandle()).getAnalyzePartitionValues().isPresent()) {\n+            return false;\n+        }\n+\n+        boolean pushdownFilterEnabled = HiveSessionProperties.isPushdownFilterEnabled(session);\n+        if (pushdownFilterEnabled) {\n+            HiveStorageFormat hiveStorageFormat = getHiveStorageFormat(getMetadata(tableHandle).getTableMetadata(session, tableHandle.getConnectorHandle()).getProperties());\n+            if (hiveStorageFormat == HiveStorageFormat.ORC || hiveStorageFormat == HiveStorageFormat.DWRF) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private DomainTranslator.ExtractionResult intersectExtractionResult(DomainTranslator.ExtractionResult left, DomainTranslator.ExtractionResult right)", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 036509d9c1..39949a4ff9 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -131,7 +131,7 @@ public class HiveFilterPushdown\n     @Override\n     public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n     {\n-        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n     }\n \n     protected ConnectorPushdownFilterResult pushdownFilter(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0OTc4NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378449785", "bodyText": "static, same for other helpers", "author": "highker", "createdAt": "2020-02-12T18:59:48Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), ret, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return ret;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            return new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    pushdownFilterResult.getLayout().getPredicate(),\n+                    TupleDomain.all());\n+        }\n+    }\n+\n+    private static class ConstraintEvaluator\n+    {\n+        private final Map<String, ColumnHandle> assignments;\n+        private final RowExpressionService evaluator;\n+        private final ConnectorSession session;\n+        private final RowExpression expression;\n+        private final Set<ColumnHandle> arguments;\n+\n+        public ConstraintEvaluator(RowExpressionService evaluator, ConnectorSession session, Map<String, ColumnHandle> assignments, RowExpression expression)\n+        {\n+            this.assignments = assignments;\n+            this.evaluator = evaluator;\n+            this.session = session;\n+            this.expression = expression;\n+\n+            arguments = ImmutableSet.copyOf(extractAll(expression)).stream()\n+                    .map(VariableReferenceExpression::getName)\n+                    .map(assignments::get)\n+                    .collect(toImmutableSet());\n+        }\n+\n+        private boolean isCandidate(Map<ColumnHandle, NullableValue> bindings)\n+        {\n+            if (intersection(bindings.keySet(), arguments).isEmpty()) {\n+                return true;\n+            }\n+\n+            Function<VariableReferenceExpression, Object> variableResolver = variable -> {\n+                ColumnHandle column = assignments.get(variable.getName());\n+                checkArgument(column != null, \"Missing column assignment for %s\", variable);\n+\n+                if (!bindings.containsKey(column)) {\n+                    return variable;\n+                }\n+\n+                return bindings.get(column).getValue();\n+            };\n+\n+            // Skip pruning if evaluation fails in a recoverable way. Failing here can cause\n+            // spurious query failures for partitions that would otherwise be filtered out.\n+            Object optimized = null;\n+            try {\n+                optimized = evaluator.getExpressionOptimizer().optimize(expression, OPTIMIZED, session, variableResolver);\n+            }\n+            catch (PrestoException e) {\n+                propagateIfUnhandled(e);\n+            }\n+\n+            // If any conjuncts evaluate to FALSE or null, then the whole predicate will never be true and so the partition should be pruned\n+            return !Boolean.FALSE.equals(optimized) && optimized != null && (!(optimized instanceof ConstantExpression) || !((ConstantExpression) optimized).isNull());\n+        }\n+\n+        private static void propagateIfUnhandled(PrestoException e)\n+                throws PrestoException\n+        {\n+            int errorCode = e.getErrorCode().getCode();\n+            if (errorCode == DIVISION_BY_ZERO.toErrorCode().getCode()\n+                    || errorCode == INVALID_CAST_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == INVALID_FUNCTION_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == NUMERIC_VALUE_OUT_OF_RANGE.toErrorCode().getCode()) {\n+                return;\n+            }\n+\n+            throw e;\n+        }\n+    }\n+\n+    private HiveMetadata getMetadata(TableHandle tableHandle)\n+    {\n+        ConnectorMetadata metadata = transactionManager.get(tableHandle.getTransaction());\n+        checkState(metadata instanceof HiveMetadata, \"metadata must be HiveMetadata\");\n+        return (HiveMetadata) metadata;\n+    }\n+\n+    private String getColumnName(ConnectorSession session, HiveMetadata metadata, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n+    {\n+        return metadata.getColumnMetadata(session, tableHandle, columnHandle).getName();\n+    }\n+\n+    private boolean isPushdownFilterSupported(ConnectorSession session, TableHandle tableHandle)\n+    {\n+        checkArgument(tableHandle.getConnectorHandle() instanceof HiveTableHandle, \"pushdownFilter is never supported on a non-hive TableHandle\");\n+        if (((HiveTableHandle) tableHandle.getConnectorHandle()).getAnalyzePartitionValues().isPresent()) {\n+            return false;\n+        }\n+\n+        boolean pushdownFilterEnabled = HiveSessionProperties.isPushdownFilterEnabled(session);\n+        if (pushdownFilterEnabled) {\n+            HiveStorageFormat hiveStorageFormat = getHiveStorageFormat(getMetadata(tableHandle).getTableMetadata(session, tableHandle.getConnectorHandle()).getProperties());\n+            if (hiveStorageFormat == HiveStorageFormat.ORC || hiveStorageFormat == HiveStorageFormat.DWRF) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private DomainTranslator.ExtractionResult intersectExtractionResult(DomainTranslator.ExtractionResult left, DomainTranslator.ExtractionResult right)\n+    {\n+        RowExpression newRemainingExpression;\n+        if (right.getRemainingExpression().equals(TRUE_CONSTANT)) {\n+            newRemainingExpression = left.getRemainingExpression();\n+        }\n+        else if (left.getRemainingExpression().equals(TRUE_CONSTANT)) {\n+            newRemainingExpression = right.getRemainingExpression();\n+        }\n+        else {\n+            newRemainingExpression = and(left.getRemainingExpression(), right.getRemainingExpression());\n+        }\n+        return new DomainTranslator.ExtractionResult(left.getTupleDomain().intersect(right.getTupleDomain()), newRemainingExpression);\n+    }\n+\n+    private boolean isEntireColumn(Subfield subfield)", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 036509d9c1..39949a4ff9 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -131,7 +131,7 @@ public class HiveFilterPushdown\n     @Override\n     public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n     {\n-        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n     }\n \n     protected ConnectorPushdownFilterResult pushdownFilter(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MTE1OA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378451158", "bodyText": "Explain more how to use ConnectorPlanOptimizer as the way to pushdown compute.", "author": "highker", "createdAt": "2020-02-12T19:02:26Z", "path": "presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java", "diffHunk": "@@ -100,18 +99,11 @@\n     TableHandle getAlternativeTableHandle(Session session, TableHandle tableHandle, PartitioningHandle partitioningHandle);\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getLayout.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    boolean isPushdownFilterSupported(Session session, TableHandle tableHandle);\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU2ODgxMQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378568811", "bodyText": "Let me know if the description I added is sufficient.", "author": "sachdevs", "createdAt": "2020-02-12T23:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MTE1OA=="}], "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java b/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java\nindex 4fa90ef0d1..ac67e7c549 100644\n--- a/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java\n+++ b/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java\n\n@@ -101,6 +101,8 @@ public interface Metadata\n     /**\n      * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n      * This function remains to ensure backwards compatibility, it needs to be removed.\n+     * If filter pushdown is required, use a ConnectorPlanOptimizer in the respective connector in order\n+     * to push compute into it's TableScan.\n      */\n     @Deprecated\n     boolean isPredicatePushdownEnabled(Session session, TableHandle tableHandle);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MzIzOQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453239", "bodyText": "Add a comment to explain \"new filters can be created and we need to merge them together\" something like that", "author": "highker", "createdAt": "2020-02-12T19:06:27Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,53 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n \n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\nindex 9708952a96..b42cf2e583 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\n\n@@ -60,6 +60,7 @@ public class HivePlanOptimizerProvider\n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n+        // New filters may be created in between logical optimization and physical optimization. Push those newly created filters as well.\n         return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MzgwMA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453800", "bodyText": "Just remove. They don't hold anymore", "author": "highker", "createdAt": "2020-02-12T19:07:36Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,29 +1371,29 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-\n-                // Read all columns with a filter\n-                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-\n-                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-\n-                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-\n-                // Read all columns except the ones used in the filter\n-                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-\n-                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-                        .collect(toList());\n-\n-                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-                assertEquals(resultCount, expectedRows.size());\n-            }\n+//            int filterCount = afterFilters.size();\n+//            for (int i = 0; i < filterCount; i++) {\n+//                RowExpression predicate = afterFilters.get(i);\n+//                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//\n+//                // Read all columns with a filter\n+//                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n+//\n+//                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n+//                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n+//\n+//                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n+//\n+//                // Read all columns except the ones used in the filter\n+//                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n+//\n+//                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n+//                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n+//                        .collect(toList());\n+//\n+//                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n+//                assertEquals(resultCount, expectedRows.size());\n+//            }", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex ed555046b1..65a1909066 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -1371,30 +1371,6 @@ public abstract class AbstractTestHiveClient\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-//            int filterCount = afterFilters.size();\n-//            for (int i = 0; i < filterCount; i++) {\n-//                RowExpression predicate = afterFilters.get(i);\n-//                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-//\n-//                // Read all columns with a filter\n-//                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-//\n-//                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-//                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-//\n-//                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-//\n-//                // Read all columns except the ones used in the filter\n-//                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-//\n-//                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-//                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-//                        .collect(toList());\n-//\n-//                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-//                assertEquals(resultCount, expectedRows.size());\n-//            }\n-\n             transaction.commit();\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1Mzg5MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453890", "bodyText": "same", "author": "highker", "createdAt": "2020-02-12T19:07:46Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2052,15 +2050,15 @@ private void doTestBucketedTableEvolution(HiveStorageFormat storageFormat, Schem\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-\n-                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-            }\n-            else {\n-                layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-            }\n+//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n+//\n+//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n+//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//            }\n+//            else {\n+            layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n+//            }", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex ed555046b1..65a1909066 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -2050,15 +2026,7 @@ public abstract class AbstractTestHiveClient\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-//\n-//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-//            }\n-//            else {\n             layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-//            }\n \n             result = readTable(\n                     transaction,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378462068", "bodyText": "@sachdevs Why is this code commented out?", "author": "mbasmanova", "createdAt": "2020-02-12T19:23:02Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,29 +1371,29 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-\n-                // Read all columns with a filter\n-                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-\n-                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-\n-                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-\n-                // Read all columns except the ones used in the filter\n-                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-\n-                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-                        .collect(toList());\n-\n-                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-                assertEquals(resultCount, expectedRows.size());\n-            }\n+//            int filterCount = afterFilters.size();", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU2NDI3MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378564270", "bodyText": "We can no longer test by calling metadata.pushdownFilter in our tests. These commented out blocks (see above comments in the PR) were left in just so that it is clear that it is clear that they are obsolete (and to draw attention to it for the reviewers :) ).\nIt is no longer possible to get the connector table layout handle without invoking the entire plan optimizer and maybe doing an assertPlan(...). I am removing these now.\nI'm unsure if there's another way to rewrite this logic or the tests that inherit from AbstractTestHiveClient that depend on this logic. Let me know if you have any alternative ideas.", "author": "sachdevs", "createdAt": "2020-02-12T23:04:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODYzMzYyOA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378633628", "bodyText": "@sachdevs These tests are providing coverage for important scenarios, e.g. schema evolution. I don't believe we have that coverage anywhere else. Simply removing this coverage is undesirable. We need to figure out a replacement.\nCC: @bhhari @yingsu00 @oerling", "author": "mbasmanova", "createdAt": "2020-02-13T03:25:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODY3OTA3Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378679077", "bodyText": "@sachdevs @mbasmanova, a quick workaround is to keep the original pushdownFilter for HiveMetadata (i.e., moving pushdownFilter from HiveFilterPushdown to HiveMetadata). Then in the test, we downcast ConnectorMetadata to HiveMetadata to still call pushdownFilter. WDYT?", "author": "highker", "createdAt": "2020-02-13T06:53:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODY5NTY2OQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378695669", "bodyText": "It tests function pushdownFilter, isn't it?", "author": "highker", "createdAt": "2020-02-13T07:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODY5Nzg1Ng==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378697856", "bodyText": "I can try that out - just need to verify that has no impact on Prism (but should be fine). @mbasmanova ?", "author": "sachdevs", "createdAt": "2020-02-13T07:52:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA1MzkyMg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379053922", "bodyText": "It tests function pushdownFilter, isn't it?\n\nYeah, I misunderstood your comment earlier.", "author": "sachdevs", "createdAt": "2020-02-13T18:53:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}], "type": "inlineReview", "revised_code": {"commit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex ed555046b1..65a1909066 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -1371,30 +1371,6 @@ public abstract class AbstractTestHiveClient\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-//            int filterCount = afterFilters.size();\n-//            for (int i = 0; i < filterCount; i++) {\n-//                RowExpression predicate = afterFilters.get(i);\n-//                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-//\n-//                // Read all columns with a filter\n-//                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-//\n-//                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-//                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-//\n-//                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-//\n-//                // Read all columns except the ones used in the filter\n-//                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-//\n-//                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-//                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-//                        .collect(toList());\n-//\n-//                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-//                assertEquals(resultCount, expectedRows.size());\n-//            }\n-\n             transaction.commit();\n         }\n \n"}}, {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "url": "https://github.com/prestodb/presto/commit/37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-12T23:19:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMDUzNg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379310536", "bodyText": "Consider editing for brevity and clarity:\n/**\n * Runs during both logical and physical phases of connector-aided plan optimization.\n * In most cases filter pushdown will occur during logical phase. However, in cases \n * when new filter is added between logical and physical phases, e.g. a filter on a join \n * key from one side of a join is added to the other side, the new filter will get\n * merged with the one already pushed down.\n */", "author": "mbasmanova", "createdAt": "2020-02-14T08:49:50Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 39949a4ff9..6168612b0e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -28,6 +28,7 @@ import com.facebook.presto.hive.HiveTableLayoutHandle;\n import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.hive.SubfieldExtractor;\n import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n import com.facebook.presto.spi.ColumnHandle;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.ConnectorSession;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTIyOQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311229", "bodyText": "perhaps, drop Connector prefix here: PushdownFilterResult\nmake private", "author": "mbasmanova", "createdAt": "2020-02-14T08:51:25Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4Nzc5Ng==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379687796", "bodyText": "See the corresponding PR in prism. These functions need to be protected. Let me know if there's a cleaner way that doesnt cause confusion in open source.", "author": "sachdevs", "createdAt": "2020-02-14T23:26:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTIyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 39949a4ff9..6168612b0e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -28,6 +28,7 @@ import com.facebook.presto.hive.HiveTableLayoutHandle;\n import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.hive.SubfieldExtractor;\n import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n import com.facebook.presto.spi.ColumnHandle;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.ConnectorSession;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTQzNQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311435", "bodyText": "make this private", "author": "mbasmanova", "createdAt": "2020-02-14T08:51:51Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4NzgzNQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379687835", "bodyText": "same", "author": "sachdevs", "createdAt": "2020-02-14T23:26:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTQzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 39949a4ff9..6168612b0e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -28,6 +28,7 @@ import com.facebook.presto.hive.HiveTableLayoutHandle;\n import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.hive.SubfieldExtractor;\n import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n import com.facebook.presto.spi.ColumnHandle;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.ConnectorSession;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTcwMg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311702", "bodyText": "nit: put arguments on a single line: Visitor(ConnectorSession session, PlanNodeIdAllocator idAllocator)", "author": "mbasmanova", "createdAt": "2020-02-14T08:52:28Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 39949a4ff9..6168612b0e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -28,6 +28,7 @@ import com.facebook.presto.hive.HiveTableLayoutHandle;\n import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.hive.SubfieldExtractor;\n import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n import com.facebook.presto.spi.ColumnHandle;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.ConnectorSession;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMzA5Mg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379313092", "bodyText": "no need to create new object if source didn't change; perhaps, just call visitPlan: return visitPlan(filter, context);", "author": "mbasmanova", "createdAt": "2020-02-14T08:55:38Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4Nzg4Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379687887", "bodyText": "nice", "author": "sachdevs", "createdAt": "2020-02-14T23:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMzA5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 39949a4ff9..6168612b0e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -28,6 +28,7 @@ import com.facebook.presto.hive.HiveTableLayoutHandle;\n import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.hive.SubfieldExtractor;\n import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n import com.facebook.presto.spi.ColumnHandle;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.ConnectorSession;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNDQ4OQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379314489", "bodyText": "move this variable up and re-use", "author": "mbasmanova", "createdAt": "2020-02-14T08:58:52Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode node = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), node, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return node;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 39949a4ff9..6168612b0e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -28,6 +28,7 @@ import com.facebook.presto.hive.HiveTableLayoutHandle;\n import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.hive.SubfieldExtractor;\n import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n import com.facebook.presto.spi.ColumnHandle;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.ConnectorSession;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNTU0NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379315545", "bodyText": "any reason to make a new HiveFilterPushdown object here? Can the same object be re-used in logical and physical phases?", "author": "mbasmanova", "createdAt": "2020-02-14T09:01:14Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,54 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n \n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        // New filters may be created in between logical optimization and physical optimization. Push those newly created filters as well.\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkwMzM0MQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380903341", "bodyText": "It can - good catch.", "author": "sachdevs", "createdAt": "2020-02-18T20:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNTU0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\nindex b42cf2e583..634f88b41e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\n\n@@ -30,11 +30,7 @@ import static java.util.Objects.requireNonNull;\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n-    private final HiveTransactionManager transactionManager;\n-    private final RowExpressionService rowExpressionService;\n-    private final StandardFunctionResolution functionResolution;\n-    private final HivePartitionManager partitionManager;\n-    private final FunctionMetadataManager functionMetadataManager;\n+    private final HiveFilterPushdown filterPushdownOptimizer;\n \n     @Inject\n     public HivePlanOptimizerProvider(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNzYxOA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379317618", "bodyText": "Based on the description, I'd rename this method to isLegacyGetLayoutSupported. What kind of backwards compatibility is needed here?", "author": "mbasmanova", "createdAt": "2020-02-14T09:06:09Z", "path": "presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java", "diffHunk": "@@ -100,18 +99,13 @@\n     TableHandle getAlternativeTableHandle(Session session, TableHandle tableHandle, PartitioningHandle partitioningHandle);\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getLayout.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    boolean isPushdownFilterSupported(Session session, TableHandle tableHandle);\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.\n+     * If filter pushdown is required, use a ConnectorPlanOptimizer in the respective connector in order\n+     * to push compute into it's TableScan.\n      */\n-    PushdownFilterResult pushdownFilter(Session session, TableHandle tableHandle, RowExpression filter);\n+    @Deprecated\n+    boolean isPredicatePushdownEnabled(Session session, TableHandle tableHandle);", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkxMDk2Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380910967", "bodyText": "Essentially PickTableLayout needs to know that it should not invoke getLayout for queries in which predicatePushdown is enabled. PickTableLayout logic is currently mutually exclusive with pushdownFilter logic. This is the \"backwards compatibility\" that needs to be supported.\nI do think calling this function \"isLegacyGetLayoutSupported\" is an apt name. However, when reading PickTableLayout pushPredicateIntoTableScan is only called when ! isPredicatePushdownEnabled. Hence in that context, isPredicatePushdownEnabled may make more sense.\nLet me know if you still think that the name may be misleading or if we can come up with a better a comment to represent what it actually does.", "author": "sachdevs", "createdAt": "2020-02-18T20:15:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNzYxOA=="}], "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java b/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java\nindex ac67e7c549..e1196930bf 100644\n--- a/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java\n+++ b/presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java\n\n@@ -100,12 +100,11 @@ public interface Metadata\n \n     /**\n      * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n-     * This function remains to ensure backwards compatibility, it needs to be removed.\n      * If filter pushdown is required, use a ConnectorPlanOptimizer in the respective connector in order\n      * to push compute into it's TableScan.\n      */\n     @Deprecated\n-    boolean isPredicatePushdownEnabled(Session session, TableHandle tableHandle);\n+    boolean isLegacyGetLayoutSupported(Session session, TableHandle tableHandle);\n \n     /**\n      * Return a partitioning handle which the connector can transparently convert both {@code left} and {@code right} into.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxOTMxNA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379319314", "bodyText": "perhaps, make com.facebook.presto.hive.rule.HiveFilterPushdown#pushdownFilter @VisibleForTesting and use here?", "author": "mbasmanova", "createdAt": "2020-02-14T09:10:12Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,30 +1371,6 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NTMyNA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380965324", "bodyText": "Okay I refactored a ton to make this static and testable - take a look and see if it makes sense.", "author": "sachdevs", "createdAt": "2020-02-18T22:09:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxOTMxNA=="}], "type": "inlineReview", "revised_code": {"commit": "11344ed62d98905bf429f35f8328988606319f8b", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex 65a1909066..47ac668b22 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -1371,6 +1376,40 @@ public abstract class AbstractTestHiveClient\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n+            int filterCount = afterFilters.size();\n+            for (int i = 0; i < filterCount; i++) {\n+                RowExpression predicate = afterFilters.get(i);\n+                ConnectorTableLayoutHandle layoutHandle = pushdownFilter(\n+                        session,\n+                        metadata,\n+                        transaction.getMetastore(\"\"), // function does not use param in all implementations?\n+                        ROW_EXPRESSION_SERVICE,\n+                        FUNCTION_RESOLUTION,\n+                        hivePartitionManager,\n+                        METADATA.getFunctionManager(),\n+                        tableHandle,\n+                        predicate,\n+                        Optional.empty()).getLayout().getHandle();\n+\n+                // Read all columns with a filter\n+                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n+\n+                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n+                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n+\n+                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n+\n+                // Read all columns except the ones used in the filter\n+                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n+\n+                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n+                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n+                        .collect(toList());\n+\n+                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n+                assertEquals(resultCount, expectedRows.size());\n+            }\n+\n             transaction.commit();\n         }\n \n"}}, {"oid": "11344ed62d98905bf429f35f8328988606319f8b", "url": "https://github.com/prestodb/presto/commit/11344ed62d98905bf429f35f8328988606319f8b", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-18T22:07:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NjY2Mw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380966663", "bodyText": "I dont think we intended this Transaction interface to have a param for getMetastore - I dont see it being used anywhere (even in the internal codebase) am I missing something?", "author": "sachdevs", "createdAt": "2020-02-18T22:12:15Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1376,7 +1379,17 @@ protected void doTestMismatchSchemaTable(\n             int filterCount = afterFilters.size();\n             for (int i = 0; i < filterCount; i++) {\n                 RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+                ConnectorTableLayoutHandle layoutHandle = pushdownFilter(\n+                        session,\n+                        metadata,\n+                        transaction.getMetastore(\"\"), // function does not use param in all implementations?", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxODY2MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384818660", "bodyText": "@sachdevs Let's remove the parameter then. Just check prism connector first.", "author": "mbasmanova", "createdAt": "2020-02-26T22:57:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NjY2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\nindex 47ac668b22..981a1bfc9a 100644\n--- a/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n+++ b/presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java\n\n@@ -1382,7 +1383,7 @@ public abstract class AbstractTestHiveClient\n                 ConnectorTableLayoutHandle layoutHandle = pushdownFilter(\n                         session,\n                         metadata,\n-                        transaction.getMetastore(\"\"), // function does not use param in all implementations?\n+                        transaction.getMetastore(),\n                         ROW_EXPRESSION_SERVICE,\n                         FUNCTION_RESOLUTION,\n                         hivePartitionManager,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNjY0NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384816645", "bodyText": "Please, remove this method.", "author": "mbasmanova", "createdAt": "2020-02-26T22:52:37Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -2675,6 +2460,11 @@ public void revokeTablePrivileges(ConnectorSession session, SchemaTableName sche\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n+    public FunctionMetadataManager getFunctionMetadataManager()", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\nindex f65253c72e..e4ffb835e2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n\n@@ -2460,11 +2463,6 @@ public class HiveMetadata\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n-    public FunctionMetadataManager getFunctionMetadataManager()\n-    {\n-        return functionMetadataManager;\n-    }\n-\n     private List<GrantInfo> buildGrants(SchemaTableName tableName, PrestoPrincipal principal)\n     {\n         ImmutableList.Builder<GrantInfo> result = ImmutableList.builder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNzE0Mg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384817142", "bodyText": "let's rename to isLegacyGetLayoutSupported; that name would match the description and the actual meaning more closely", "author": "mbasmanova", "createdAt": "2020-02-26T22:53:52Z", "path": "presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java", "diffHunk": "@@ -127,25 +125,14 @@ default ConnectorTableLayoutHandle getAlternativeLayoutHandle(ConnectorSession s\n     }\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getTableLayouts.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    @Experimental\n-    default boolean isPushdownFilterSupported(ConnectorSession session, ConnectorTableHandle tableHandle)\n-    {\n-        return false;\n-    }\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.\n      */\n+    @Deprecated\n     @Experimental\n-    default ConnectorPushdownFilterResult pushdownFilter(ConnectorSession session, ConnectorTableHandle tableHandle, RowExpression filter, Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    default boolean isPredicatePushdownEnabled(ConnectorSession session, ConnectorTableHandle tableHandle)", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java b/presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java\nindex 7997a357c6..a11e97d359 100644\n--- a/presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java\n+++ b/presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java\n\n@@ -126,11 +126,10 @@ public interface ConnectorMetadata\n \n     /**\n      * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n-     * This function remains to ensure backwards compatibility, it needs to be removed.\n      */\n     @Deprecated\n     @Experimental\n-    default boolean isPredicatePushdownEnabled(ConnectorSession session, ConnectorTableHandle tableHandle)\n+    default boolean isLegacyGetLayoutSupported(ConnectorSession session, ConnectorTableHandle tableHandle)\n     {\n         return true;\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNzgyNA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384817824", "bodyText": "Please, move this variable up and reuse in the following places:\nHiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n...tableScan.getTable().getConnectorHandle()", "author": "mbasmanova", "createdAt": "2020-02-26T22:55:32Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,578 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Runs during both logical and physical phases of connector-aided plan optimization.\n+ * In most cases filter pushdown will occur during logical phase. However, in cases\n+ * when new filter is added between logical and physical phases, e.g. a filter on a join\n+ * key from one side of a join is added to the other side, the new filter will get\n+ * merged with the one already pushed down.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    protected final RowExpressionService rowExpressionService;\n+    protected final StandardFunctionResolution functionResolution;\n+    protected final HivePartitionManager partitionManager;\n+    protected final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        return pushdownFilter(\n+                session,\n+                metadata,\n+                metadata.getMetastore(),\n+                rowExpressionService,\n+                functionResolution,\n+                partitionManager,\n+                functionMetadataManager,\n+                tableHandle,\n+                filter,\n+                currentLayoutHandle);\n+    }\n+\n+    @VisibleForTesting\n+    public static ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            ConnectorMetadata metadata,\n+            SemiTransactionalHiveMetastore metastore,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metastore, tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(\n+                                        session,\n+                                        rowExpressionService,\n+                                        tableName,\n+                                        hivePartitionResult.getBucketHandle(),\n+                                        hivePartitionResult.getBucketFilter(),\n+                                        decomposedFilter.getRemainingExpression(),\n+                                        domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    @VisibleForTesting\n+    public static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return visitPlan(filter, context);\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            TableHandle handle = tableScan.getTable();\n+            HiveMetadata hiveMetadata = getMetadata(handle);\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, handle.getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(\n+                    session,\n+                    hiveMetadata,\n+                    handle.getConnectorHandle(),\n+                    replacedExpression,\n+                    handle.getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableScanNode node = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), node, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return node;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(\n+                    session,\n+                    hiveMetadata,\n+                    tableScan.getTable().getConnectorHandle(),\n+                    TRUE_CONSTANT,\n+                    tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\nindex 6168612b0e..97802a4688 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java\n\n@@ -113,7 +113,7 @@ public class HiveFilterPushdown\n             Optional.empty(),\n             emptyList());\n \n-    private final HiveTransactionManager transactionManager;\n+    protected final HiveTransactionManager transactionManager;\n     protected final RowExpressionService rowExpressionService;\n     protected final StandardFunctionResolution functionResolution;\n     protected final HivePartitionManager partitionManager;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxODAzMg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384818032", "bodyText": "no need to make new set object every time; change the variable type to Set", "author": "mbasmanova", "createdAt": "2020-02-26T22:56:01Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,51 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveFilterPushdown filterPushdownOptimizer;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        requireNonNull(transactionManager, \"transactionManager is null\");\n+        requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        requireNonNull(functionResolution, \"functionResolution is null\");\n+        requireNonNull(partitionManager, \"partitionManager is null\");\n+        requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+        this.filterPushdownOptimizer = new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager);\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(filterPushdownOptimizer);", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\nindex 634f88b41e..0b3fd2c3cf 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java\n\n@@ -30,7 +30,7 @@ import static java.util.Objects.requireNonNull;\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n-    private final HiveFilterPushdown filterPushdownOptimizer;\n+    private final Set<ConnectorPlanOptimizer> planOptimizers;\n \n     @Inject\n     public HivePlanOptimizerProvider(\n"}}, {"oid": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "url": "https://github.com/prestodb/presto/commit/889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-03-04T00:24:46Z", "type": "forcePushed"}, {"oid": "abf05811d635dc6c4df778ba1e872efded23a5db", "url": "https://github.com/prestodb/presto/commit/abf05811d635dc6c4df778ba1e872efded23a5db", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-03-04T20:24:55Z", "type": "commit"}, {"oid": "abf05811d635dc6c4df778ba1e872efded23a5db", "url": "https://github.com/prestodb/presto/commit/abf05811d635dc6c4df778ba1e872efded23a5db", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-03-04T20:24:55Z", "type": "forcePushed"}]}