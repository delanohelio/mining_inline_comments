{"pr_number": 15325, "pr_title": "Disable listFiles call to underlying storage", "pr_createdAt": "2020-10-16T23:50:33Z", "pr_url": "https://github.com/prestodb/presto/pull/15325", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzAyMjc2MQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r507022761", "bodyText": "we don't need this. It can be obtained from MAX_SPLIT_SIZE session property.", "author": "highker", "createdAt": "2020-10-18T06:12:04Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -103,6 +112,7 @@\n         implements HiveSplitLoader\n {\n     private static final ListenableFuture<?> COMPLETED_FUTURE = immediateFuture(null);\n+    private static final DataSize TARGET_BLOCK_SIZE = new DataSize(72, MEGABYTE);", "originalCommit": "449bcc9ed83ac4aff6dcf2f450522c7c5bc33a25", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6a0d8aa5e1b1670a5c9f919b97078ed829b7940b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\nindex 861b602a61..adf901b30d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n\n@@ -112,7 +101,6 @@ public class BackgroundHiveSplitLoader\n         implements HiveSplitLoader\n {\n     private static final ListenableFuture<?> COMPLETED_FUTURE = immediateFuture(null);\n-    private static final DataSize TARGET_BLOCK_SIZE = new DataSize(72, MEGABYTE);\n \n     private final Table table;\n     private final Optional<Domain> pathDomain;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzAyMzYyNw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r507023627", "bodyText": "This will still call the underlying remote FS. I think locations only works for colocated HDFS. It should be empty.", "author": "highker", "createdAt": "2020-10-18T06:22:58Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -452,13 +462,63 @@ private static boolean shouldUseFileSplitsFromInputFormat(InputFormat<?, ?> inpu\n         }\n \n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n+\n+        if (HiveSessionProperties.isListFilesDisabled(session) && partition.isPresent()) {\n+            Map<String, String> parameters = partition.get().getParameters();\n+            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {\n+                List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n+                List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+\n+                // Verify that the count of fileNames and fileSizes are same\n+                verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+                ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+                for (int i = 0; i < fileNames.size(); i++) {\n+                    Path filePath = new Path(path, fileNames.get(i));\n+                    FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, TARGET_BLOCK_SIZE.toBytes(), 0, filePath);\n+                    try {\n+                        BlockLocation[] locations = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());", "originalCommit": "449bcc9ed83ac4aff6dcf2f450522c7c5bc33a25", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6a0d8aa5e1b1670a5c9f919b97078ed829b7940b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\nindex 861b602a61..adf901b30d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n\n@@ -463,36 +409,6 @@ public class BackgroundHiveSplitLoader\n \n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n \n-        if (HiveSessionProperties.isListFilesDisabled(session) && partition.isPresent()) {\n-            Map<String, String> parameters = partition.get().getParameters();\n-            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {\n-                List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n-                List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n-\n-                // Verify that the count of fileNames and fileSizes are same\n-                verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n-\n-                ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n-                for (int i = 0; i < fileNames.size(); i++) {\n-                    Path filePath = new Path(path, fileNames.get(i));\n-                    FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, TARGET_BLOCK_SIZE.toBytes(), 0, filePath);\n-                    try {\n-                        BlockLocation[] locations = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());\n-                        fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n-                    }\n-                    catch (IOException e) {\n-                        throw new UncheckedIOException(e);\n-                    }\n-                }\n-\n-                return fileListBuilder.build().stream()\n-                        .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n-                        .filter(Optional::isPresent)\n-                        .map(Optional::get)\n-                        .iterator();\n-            }\n-        }\n-\n         return stream(directoryLister.list(fileSystem, table, path, namenodeStats, pathFilter, hiveDirectoryContext))\n                 .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n                 .filter(Optional::isPresent)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzAyMzY4Mg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r507023682", "bodyText": "We need to double check if extraFileContext is empty will cause downstream failure. Because downstream could assume it's always non-empty if we turn the config on. Either we need to add a comment here to indicate it's safe or fix the downstream. cc: @shixuan-fan", "author": "highker", "createdAt": "2020-10-18T06:23:47Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -452,13 +462,63 @@ private static boolean shouldUseFileSplitsFromInputFormat(InputFormat<?, ?> inpu\n         }\n \n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n+\n+        if (HiveSessionProperties.isListFilesDisabled(session) && partition.isPresent()) {\n+            Map<String, String> parameters = partition.get().getParameters();\n+            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {\n+                List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n+                List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+\n+                // Verify that the count of fileNames and fileSizes are same\n+                verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+                ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+                for (int i = 0; i < fileNames.size(); i++) {\n+                    Path filePath = new Path(path, fileNames.get(i));\n+                    FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, TARGET_BLOCK_SIZE.toBytes(), 0, filePath);\n+                    try {\n+                        BlockLocation[] locations = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());\n+                        fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));", "originalCommit": "449bcc9ed83ac4aff6dcf2f450522c7c5bc33a25", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA5MjQzNw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r527092437", "bodyText": "Yes its safe to set extraFileContext as Optional.empty() because the downstream always checks if its present before proceeding. So added a comment saying it's safe and okay to set it empty().", "author": "NikhilCollooru", "createdAt": "2020-11-19T18:05:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzAyMzY4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "6a0d8aa5e1b1670a5c9f919b97078ed829b7940b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\nindex 861b602a61..adf901b30d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n\n@@ -463,36 +409,6 @@ public class BackgroundHiveSplitLoader\n \n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n \n-        if (HiveSessionProperties.isListFilesDisabled(session) && partition.isPresent()) {\n-            Map<String, String> parameters = partition.get().getParameters();\n-            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {\n-                List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n-                List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n-\n-                // Verify that the count of fileNames and fileSizes are same\n-                verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n-\n-                ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n-                for (int i = 0; i < fileNames.size(); i++) {\n-                    Path filePath = new Path(path, fileNames.get(i));\n-                    FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, TARGET_BLOCK_SIZE.toBytes(), 0, filePath);\n-                    try {\n-                        BlockLocation[] locations = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());\n-                        fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n-                    }\n-                    catch (IOException e) {\n-                        throw new UncheckedIOException(e);\n-                    }\n-                }\n-\n-                return fileListBuilder.build().stream()\n-                        .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n-                        .filter(Optional::isPresent)\n-                        .map(Optional::get)\n-                        .iterator();\n-            }\n-        }\n-\n         return stream(directoryLister.list(fileSystem, table, path, namenodeStats, pathFilter, hiveDirectoryContext))\n                 .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n                 .filter(Optional::isPresent)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzAyNDM0Ng==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r507024346", "bodyText": "what about non-partitioned tables?\nwhat if a table is mixed with file paths in some partitions and some not?", "author": "highker", "createdAt": "2020-10-18T06:30:39Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -452,13 +462,63 @@ private static boolean shouldUseFileSplitsFromInputFormat(InputFormat<?, ?> inpu\n         }\n \n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n+\n+        if (HiveSessionProperties.isListFilesDisabled(session) && partition.isPresent()) {", "originalCommit": "449bcc9ed83ac4aff6dcf2f450522c7c5bc33a25", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "6a0d8aa5e1b1670a5c9f919b97078ed829b7940b", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\nindex 861b602a61..adf901b30d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n\n@@ -463,36 +409,6 @@ public class BackgroundHiveSplitLoader\n \n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n \n-        if (HiveSessionProperties.isListFilesDisabled(session) && partition.isPresent()) {\n-            Map<String, String> parameters = partition.get().getParameters();\n-            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {\n-                List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n-                List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n-\n-                // Verify that the count of fileNames and fileSizes are same\n-                verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n-\n-                ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n-                for (int i = 0; i < fileNames.size(); i++) {\n-                    Path filePath = new Path(path, fileNames.get(i));\n-                    FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, TARGET_BLOCK_SIZE.toBytes(), 0, filePath);\n-                    try {\n-                        BlockLocation[] locations = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());\n-                        fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n-                    }\n-                    catch (IOException e) {\n-                        throw new UncheckedIOException(e);\n-                    }\n-                }\n-\n-                return fileListBuilder.build().stream()\n-                        .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n-                        .filter(Optional::isPresent)\n-                        .map(Optional::get)\n-                        .iterator();\n-            }\n-        }\n-\n         return stream(directoryLister.list(fileSystem, table, path, namenodeStats, pathFilter, hiveDirectoryContext))\n                 .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n                 .filter(Optional::isPresent)\n"}}, {"oid": "6a0d8aa5e1b1670a5c9f919b97078ed829b7940b", "url": "https://github.com/prestodb/presto/commit/6a0d8aa5e1b1670a5c9f919b97078ed829b7940b", "message": "Add DelegatingHiveSplitLoader\n\nManifestHiveSplitLoader has the logic to read filenamse,size from\npartition object and add splits to splitSource. But not all partitions\nmight contain the list of filenames and sizes.Hence we need\nDelegatingHiveSplitLoader to create both HiveSplitLoader\nand ManifestHiveSplitLaoder.", "committedDate": "2020-11-13T00:31:13Z", "type": "forcePushed"}, {"oid": "aa8f0099b951a7da3ac2ed3ac0c226f1d3005ef0", "url": "https://github.com/prestodb/presto/commit/aa8f0099b951a7da3ac2ed3ac0c226f1d3005ef0", "message": "Add DelegatingHiveSplitLoader\n\nManifestHiveSplitLoader has the logic to read filenamse,size from\npartition object and add splits to splitSource. But not all partitions\nmight contain the list of filenames and sizes.Hence we need\nDelegatingHiveSplitLoader to create both HiveSplitLoader\nand ManifestHiveSplitLaoder.", "committedDate": "2020-11-13T03:29:01Z", "type": "forcePushed"}, {"oid": "5807b874a75a9e8de04363179f3673de9a764b94", "url": "https://github.com/prestodb/presto/commit/5807b874a75a9e8de04363179f3673de9a764b94", "message": "Add PartitionLoader to load partitions\n\nAdd DelegatingPartitionLoader to delegate the partion\nloading to ManifestPartitionLoader when Partition retrieved\nfrom Metastore has list of fileNames, sizes in it.", "committedDate": "2020-11-16T00:17:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkwODg0MQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523908841", "bodyText": "hive.prefer_manifests_to_list_files", "author": "highker", "createdAt": "2020-11-16T05:39:13Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1524,4 +1525,17 @@ public boolean isFileRenamingEnabled()\n     {\n         return this.fileRenamingEnabled;\n     }\n+\n+    @Config(\"hive.list-files-disabled\")", "originalCommit": "f05f2812e010c828d968aaf814fe5d7ed48a22cb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\nindex f1300df22d..bd4406497f 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\n\n@@ -1526,16 +1527,29 @@ public class HiveClientConfig\n         return this.fileRenamingEnabled;\n     }\n \n-    @Config(\"hive.list-files-disabled\")\n-    @ConfigDescription(\"Disable list files call to underlying storage\")\n-    public HiveClientConfig setListFilesDisabled(boolean listFilesDisabled)\n+    @Config(\"hive.prefer-manifests-to-list-files\")\n+    @ConfigDescription(\"Prefer to fetch the list of filenames, sizes from manifests rather than storage\")\n+    public HiveClientConfig setManifestsToListFilesPreferred(boolean preferManifestToListFiles)\n     {\n-        this.listFilesDisabled = listFilesDisabled;\n+        this.preferManifestToListFiles = preferManifestToListFiles;\n         return this;\n     }\n \n-    public boolean isListFilesDisabled()\n+    public boolean isManifestsToListFilesPreferred()\n     {\n-        return this.listFilesDisabled;\n+        return this.preferManifestToListFiles;\n+    }\n+\n+    @Config(\"hive.manifest-verification-enabled\")\n+    @ConfigDescription(\"Enable verification of file names and sizes in manifest / partition parameters\")\n+    public HiveClientConfig setManifestVerificationEnabled(boolean manifestVerificationEnabled)\n+    {\n+        this.manifestVerificationEnabled = manifestVerificationEnabled;\n+        return this;\n+    }\n+\n+    public boolean isManifestVerificationEnabled()\n+    {\n+        return this.manifestVerificationEnabled;\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkwOTAwOQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523909009", "bodyText": "prefer_manifests_to_list_files", "author": "highker", "createdAt": "2020-11-16T05:39:50Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java", "diffHunk": "@@ -111,6 +111,7 @@\n     public static final String PARTIAL_AGGREGATION_PUSHDOWN_ENABLED = \"partial_aggregation_pushdown_enabled\";\n     public static final String PARTIAL_AGGREGATION_PUSHDOWN_FOR_VARIABLE_LENGTH_DATATYPES_ENABLED = \"partial_aggregation_pushdown_for_variable_length_datatypes_enabled\";\n     public static final String FILE_RENAMING_ENABLED = \"file_renaming_enabled\";\n+    public static final String LIST_FILES_DISABLED = \"list_files_disabled\";", "originalCommit": "f05f2812e010c828d968aaf814fe5d7ed48a22cb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java\nindex a63ca61960..863a21a6c0 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveSessionProperties.java\n\n@@ -111,7 +111,8 @@ public final class HiveSessionProperties\n     public static final String PARTIAL_AGGREGATION_PUSHDOWN_ENABLED = \"partial_aggregation_pushdown_enabled\";\n     public static final String PARTIAL_AGGREGATION_PUSHDOWN_FOR_VARIABLE_LENGTH_DATATYPES_ENABLED = \"partial_aggregation_pushdown_for_variable_length_datatypes_enabled\";\n     public static final String FILE_RENAMING_ENABLED = \"file_renaming_enabled\";\n-    public static final String LIST_FILES_DISABLED = \"list_files_disabled\";\n+    public static final String PREFER_MANIFESTS_TO_LIST_FILES = \"prefer_manifests_to_list_files\";\n+    public static final String MANIFEST_VERIFICATION_ENABLED = \"manifest_verification_enabled\";\n \n     private final List<PropertyMetadata<?>> sessionProperties;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkwOTgwOA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523909808", "bodyText": "Let's have two interfaces for this. Otherwise, we will have regression for https://github.com/prestodb/presto/pull/10760/files", "author": "highker", "createdAt": "2020-11-16T05:43:31Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/OrcFileWriter.java", "diffHunk": "@@ -123,7 +123,7 @@ public OrcFileWriter(\n     @Override\n     public long getWrittenBytes()\n     {\n-        return orcWriter.getWrittenBytes() + orcWriter.getBufferedBytes();\n+        return orcWriter.getWrittenBytes();\n     }", "originalCommit": "3ac00c6e9cc1aa8c588fc44939f96d0ca8ce66e7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/OrcFileWriter.java b/presto-hive/src/main/java/com/facebook/presto/hive/OrcFileWriter.java\nindex 7c029feaae..290a05909b 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/OrcFileWriter.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/OrcFileWriter.java\n\n@@ -122,6 +122,12 @@ public class OrcFileWriter\n \n     @Override\n     public long getWrittenBytes()\n+    {\n+        return orcWriter.getWrittenBytes() + orcWriter.getBufferedBytes();\n+    }\n+\n+    @Override\n+    public long getFileSize()\n     {\n         return orcWriter.getWrittenBytes();\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkxMzQzMw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523913433", "bodyText": "both these two functions can be static. Shall we put them into HiveManifestUtils?", "author": "highker", "createdAt": "2020-11-16T05:58:54Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -1970,6 +1981,55 @@ else if (partitionUpdate.getUpdateMode() == NEW || partitionUpdate.getUpdateMode\n                         .collect(Collectors.toList())));\n     }\n \n+    private Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)", "originalCommit": "bb1bd7832b741a39725bc2411c58fc611b7fe8bc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\nindex e8266ad921..9bf971802d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n\n@@ -1981,55 +1979,6 @@ public class HiveMetadata\n                         .collect(Collectors.toList())));\n     }\n \n-    private Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n-    {\n-        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n-        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n-\n-        // Sort the file infos based on fileName\n-        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n-\n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n-\n-        // Join the file sizes\n-        String fileSizes = fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(joining(\",\"));\n-\n-        partitionMetadata.put(FILE_NAMES, fileNames);\n-        partitionMetadata.put(FILE_SIZES, fileSizes);\n-        partitionMetadata.putAll(metadata);\n-\n-        return partitionMetadata.build();\n-    }\n-\n-    private String joinFileNames(List<String> fileNames)\n-    {\n-        if (fileNames.size() == 1) {\n-            return fileNames.get(0);\n-        }\n-\n-        boolean isContinuousSequence = true;\n-        int start = 0;\n-        for (String name : fileNames) {\n-            if (start != Integer.valueOf(name)) {\n-                isContinuousSequence = false;\n-                break;\n-            }\n-            start++;\n-        }\n-\n-        if (isContinuousSequence) {\n-            return fileNames.get(0) + \",\" + fileNames.get(fileNames.size() - 1);\n-        }\n-\n-        return Joiner.on(COMMA).join(fileNames);\n-    }\n-\n     private static boolean isTempPathRequired(ConnectorSession session, Optional<HiveBucketProperty> bucketProperty, List<SortingColumn> preferredOrderingColumns)\n     {\n         boolean hasSortedWrite = bucketProperty.map(property -> !property.getSortedBy().isEmpty()).orElse(false) || !preferredOrderingColumns.isEmpty();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkxMzU4Nw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523913587", "bodyText": "This should use COMMA", "author": "highker", "createdAt": "2020-11-16T05:59:27Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -1970,6 +1981,55 @@ else if (partitionUpdate.getUpdateMode() == NEW || partitionUpdate.getUpdateMode\n                         .collect(Collectors.toList())));\n     }\n \n+    private Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = fileWriteInfos.stream()\n+                .map(FileWriteInfo::getFileSize)\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .map(String::valueOf)\n+                .collect(joining(\",\"));", "originalCommit": "bb1bd7832b741a39725bc2411c58fc611b7fe8bc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\nindex e8266ad921..9bf971802d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n\n@@ -1981,55 +1979,6 @@ public class HiveMetadata\n                         .collect(Collectors.toList())));\n     }\n \n-    private Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n-    {\n-        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n-        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n-\n-        // Sort the file infos based on fileName\n-        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n-\n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n-\n-        // Join the file sizes\n-        String fileSizes = fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(joining(\",\"));\n-\n-        partitionMetadata.put(FILE_NAMES, fileNames);\n-        partitionMetadata.put(FILE_SIZES, fileSizes);\n-        partitionMetadata.putAll(metadata);\n-\n-        return partitionMetadata.build();\n-    }\n-\n-    private String joinFileNames(List<String> fileNames)\n-    {\n-        if (fileNames.size() == 1) {\n-            return fileNames.get(0);\n-        }\n-\n-        boolean isContinuousSequence = true;\n-        int start = 0;\n-        for (String name : fileNames) {\n-            if (start != Integer.valueOf(name)) {\n-                isContinuousSequence = false;\n-                break;\n-            }\n-            start++;\n-        }\n-\n-        if (isContinuousSequence) {\n-            return fileNames.get(0) + \",\" + fileNames.get(fileNames.size() - 1);\n-        }\n-\n-        return Joiner.on(COMMA).join(fileNames);\n-    }\n-\n     private static boolean isTempPathRequired(ConnectorSession session, Optional<HiveBucketProperty> bucketProperty, List<SortingColumn> preferredOrderingColumns)\n     {\n         boolean hasSortedWrite = bucketProperty.map(property -> !property.getSortedBy().isEmpty()).orElse(false) || !preferredOrderingColumns.isEmpty();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkxMzg3Ng==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523913876", "bodyText": "parseInt", "author": "highker", "createdAt": "2020-11-16T06:00:28Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -1970,6 +1981,55 @@ else if (partitionUpdate.getUpdateMode() == NEW || partitionUpdate.getUpdateMode\n                         .collect(Collectors.toList())));\n     }\n \n+    private Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = fileWriteInfos.stream()\n+                .map(FileWriteInfo::getFileSize)\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .map(String::valueOf)\n+                .collect(joining(\",\"));\n+\n+        partitionMetadata.put(FILE_NAMES, fileNames);\n+        partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.putAll(metadata);\n+\n+        return partitionMetadata.build();\n+    }\n+\n+    private String joinFileNames(List<String> fileNames)\n+    {\n+        if (fileNames.size() == 1) {\n+            return fileNames.get(0);\n+        }\n+\n+        boolean isContinuousSequence = true;\n+        int start = 0;\n+        for (String name : fileNames) {\n+            if (start != Integer.valueOf(name)) {", "originalCommit": "bb1bd7832b741a39725bc2411c58fc611b7fe8bc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\nindex e8266ad921..9bf971802d 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n\n@@ -1981,55 +1979,6 @@ public class HiveMetadata\n                         .collect(Collectors.toList())));\n     }\n \n-    private Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n-    {\n-        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n-        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n-\n-        // Sort the file infos based on fileName\n-        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n-\n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n-\n-        // Join the file sizes\n-        String fileSizes = fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(joining(\",\"));\n-\n-        partitionMetadata.put(FILE_NAMES, fileNames);\n-        partitionMetadata.put(FILE_SIZES, fileSizes);\n-        partitionMetadata.putAll(metadata);\n-\n-        return partitionMetadata.build();\n-    }\n-\n-    private String joinFileNames(List<String> fileNames)\n-    {\n-        if (fileNames.size() == 1) {\n-            return fileNames.get(0);\n-        }\n-\n-        boolean isContinuousSequence = true;\n-        int start = 0;\n-        for (String name : fileNames) {\n-            if (start != Integer.valueOf(name)) {\n-                isContinuousSequence = false;\n-                break;\n-            }\n-            start++;\n-        }\n-\n-        if (isContinuousSequence) {\n-            return fileNames.get(0) + \",\" + fileNames.get(fileNames.size() - 1);\n-        }\n-\n-        return Joiner.on(COMMA).join(fileNames);\n-    }\n-\n     private static boolean isTempPathRequired(ConnectorSession session, Optional<HiveBucketProperty> bucketProperty, List<SortingColumn> preferredOrderingColumns)\n     {\n         boolean hasSortedWrite = bucketProperty.map(property -> !property.getSortedBy().isEmpty()).orElse(false) || !preferredOrderingColumns.isEmpty();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkyMTU2Mw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523921563", "bodyText": "keep it private and duplicate it to the classes where it is needed.", "author": "highker", "createdAt": "2020-11-16T06:30:49Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -14,112 +14,38 @@\n package com.facebook.presto.hive;\n \n import com.facebook.presto.common.predicate.Domain;\n-import com.facebook.presto.hive.HiveBucketing.HiveBucketFilter;\n-import com.facebook.presto.hive.HiveSplit.BucketConversion;\n-import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n-import com.facebook.presto.hive.metastore.Column;\n-import com.facebook.presto.hive.metastore.Partition;\n-import com.facebook.presto.hive.metastore.Storage;\n import com.facebook.presto.hive.metastore.Table;\n-import com.facebook.presto.hive.util.HiveFileIterator.NestedDirectoryNotAllowedException;\n-import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n import com.facebook.presto.hive.util.ResumableTask;\n import com.facebook.presto.hive.util.ResumableTasks;\n import com.facebook.presto.spi.ConnectorSession;\n import com.facebook.presto.spi.PrestoException;\n-import com.facebook.presto.spi.SchemaTableName;\n-import com.google.common.base.Suppliers;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.Iterators;\n-import com.google.common.io.CharStreams;\n import com.google.common.util.concurrent.ListenableFuture;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.PathFilter;\n-import org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat;\n-import org.apache.hadoop.mapred.FileInputFormat;\n-import org.apache.hadoop.mapred.FileSplit;\n-import org.apache.hadoop.mapred.InputFormat;\n-import org.apache.hadoop.mapred.InputSplit;\n-import org.apache.hadoop.mapred.JobConf;\n-import org.apache.hadoop.mapred.TextInputFormat;\n-import org.apache.hudi.hadoop.HoodieParquetInputFormat;\n-import org.apache.hudi.hadoop.HoodieROTablePathFilter;\n-import org.apache.hudi.hadoop.realtime.HoodieParquetRealtimeInputFormat;\n \n-import java.io.BufferedReader;\n import java.io.IOException;\n-import java.io.InputStreamReader;\n-import java.lang.annotation.Annotation;\n-import java.nio.charset.StandardCharsets;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n import java.util.Deque;\n import java.util.Iterator;\n-import java.util.List;\n import java.util.Optional;\n-import java.util.Properties;\n import java.util.concurrent.ConcurrentLinkedDeque;\n import java.util.concurrent.Executor;\n import java.util.concurrent.locks.ReentrantReadWriteLock;\n-import java.util.function.IntPredicate;\n-import java.util.function.Supplier;\n \n-import static com.facebook.presto.hive.HiveBucketing.getVirtualBucketNumber;\n-import static com.facebook.presto.hive.HiveColumnHandle.pathColumnHandle;\n-import static com.facebook.presto.hive.HiveErrorCode.HIVE_BAD_DATA;\n import static com.facebook.presto.hive.HiveErrorCode.HIVE_FILESYSTEM_ERROR;\n-import static com.facebook.presto.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n-import static com.facebook.presto.hive.HiveErrorCode.HIVE_INVALID_METADATA;\n-import static com.facebook.presto.hive.HiveErrorCode.HIVE_INVALID_PARTITION_VALUE;\n import static com.facebook.presto.hive.HiveErrorCode.HIVE_UNKNOWN_ERROR;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n-import static com.facebook.presto.hive.HiveSessionProperties.isUseListDirectoryCache;\n-import static com.facebook.presto.hive.HiveUtil.getFooterCount;\n-import static com.facebook.presto.hive.HiveUtil.getHeaderCount;\n-import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.FAIL;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n-import static com.facebook.presto.hive.S3SelectPushdown.shouldEnablePushdownForTable;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.checkCondition;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getHiveSchema;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n-import static com.facebook.presto.hive.util.ConfigurationUtils.toJobConf;\n-import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n import static com.google.common.base.Preconditions.checkArgument;\n import static com.google.common.base.Preconditions.checkState;\n-import static com.google.common.collect.ImmutableList.toImmutableList;\n-import static com.google.common.collect.Streams.stream;\n import static com.google.common.util.concurrent.Futures.immediateFuture;\n-import static java.lang.Math.max;\n-import static java.lang.String.format;\n import static java.util.Objects.requireNonNull;\n-import static org.apache.hadoop.hive.common.FileUtils.HIDDEN_FILES_PATH_FILTER;\n \n public class BackgroundHiveSplitLoader\n         implements HiveSplitLoader\n {\n-    private static final ListenableFuture<?> COMPLETED_FUTURE = immediateFuture(null);\n+    public static final ListenableFuture<?> COMPLETED_FUTURE = immediateFuture(null);", "originalCommit": "5807b874a75a9e8de04363179f3673de9a764b94", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\nindex 5f5060634a..26e38de752 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n\n@@ -14,6 +14,7 @@\n package com.facebook.presto.hive;\n \n import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.StoragePartitionLoader.BucketSplitInfo;\n import com.facebook.presto.hive.metastore.Table;\n import com.facebook.presto.hive.util.ResumableTask;\n import com.facebook.presto.hive.util.ResumableTasks;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkyMjA0OQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523922049", "bodyText": "looks like an accidental change", "author": "highker", "createdAt": "2020-11-16T06:32:40Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java", "diffHunk": "@@ -145,7 +71,7 @@ public BackgroundHiveSplitLoader(\n             Table table,\n             Iterable<HivePartitionMetadata> partitions,\n             Optional<Domain> pathDomain,\n-            Optional<BucketSplitInfo> tableBucketInfo,\n+            Optional<StoragePartitionLoader.BucketSplitInfo> tableBucketInfo,", "originalCommit": "5807b874a75a9e8de04363179f3673de9a764b94", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\nindex 5f5060634a..26e38de752 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/BackgroundHiveSplitLoader.java\n\n@@ -71,7 +72,7 @@ public class BackgroundHiveSplitLoader\n             Table table,\n             Iterable<HivePartitionMetadata> partitions,\n             Optional<Domain> pathDomain,\n-            Optional<StoragePartitionLoader.BucketSplitInfo> tableBucketInfo,\n+            Optional<BucketSplitInfo> tableBucketInfo,\n             ConnectorSession session,\n             HdfsEnvironment hdfsEnvironment,\n             NamenodeStats namenodeStats,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkyNDgwOA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523924808", "bodyText": "This is a no-op right? I thought we need to call HiveSplitSource.addToQueue?", "author": "highker", "createdAt": "2020-11-16T06:42:33Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.BackgroundHiveSplitLoader.COMPLETED_FUTURE;\n+import static com.facebook.presto.hive.HiveMetadata.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveMetadata.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final Deque<Iterator<InternalHiveSplit>> fileIterators;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            Deque<Iterator<InternalHiveSplit>> fileIterators,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.fileIterators = requireNonNull(fileIterators, \"fileIterators is null\");\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+\n+        // Verify that the count of fileNames and fileSizes are same\n+        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+        for (int i = 0; i < fileNames.size(); i++) {\n+            Path filePath = new Path(path, fileNames.get(i));\n+            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n+            try {\n+                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};\n+                fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n+            }\n+            catch (IOException e) {\n+                throw new UncheckedIOException(e);\n+            }\n+        }\n+\n+        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n+\n+        fileIterators.addLast(fileListBuilder.build().stream()\n+                .map(status -> splitFactory.createInternalHiveSplit(status, true))\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .iterator());", "originalCommit": "5807b874a75a9e8de04363179f3673de9a764b94", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex ff4c31604e..0a4bfe25b5 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -20,6 +20,7 @@ import com.facebook.presto.hive.metastore.Storage;\n import com.facebook.presto.hive.metastore.Table;\n import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n import com.google.common.collect.ImmutableList;\n import com.google.common.util.concurrent.ListenableFuture;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzkyNTgyMA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r523925820", "bodyText": "Let's add a new session property to call directoryLister.list here to do verification on the file names in manifests are the same as the ones listed.", "author": "highker", "createdAt": "2020-11-16T06:46:14Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.BackgroundHiveSplitLoader.COMPLETED_FUTURE;\n+import static com.facebook.presto.hive.HiveMetadata.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveMetadata.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final Deque<Iterator<InternalHiveSplit>> fileIterators;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            Deque<Iterator<InternalHiveSplit>> fileIterators,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.fileIterators = requireNonNull(fileIterators, \"fileIterators is null\");\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+\n+        // Verify that the count of fileNames and fileSizes are same\n+        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+        for (int i = 0; i < fileNames.size(); i++) {\n+            Path filePath = new Path(path, fileNames.get(i));\n+            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n+            try {\n+                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};\n+                fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n+            }\n+            catch (IOException e) {\n+                throw new UncheckedIOException(e);\n+            }\n+        }\n+\n+        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n+\n+        fileIterators.addLast(fileListBuilder.build().stream()\n+                .map(status -> splitFactory.createInternalHiveSplit(status, true))\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .iterator());\n+", "originalCommit": "5807b874a75a9e8de04363179f3673de9a764b94", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "4019f8cb5cf583526da9558b97ce935d007bae37", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex ff4c31604e..0a4bfe25b5 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -20,6 +20,7 @@ import com.facebook.presto.hive.metastore.Storage;\n import com.facebook.presto.hive.metastore.Table;\n import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n import com.google.common.collect.ImmutableList;\n import com.google.common.util.concurrent.ListenableFuture;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"oid": "4019f8cb5cf583526da9558b97ce935d007bae37", "url": "https://github.com/prestodb/presto/commit/4019f8cb5cf583526da9558b97ce935d007bae37", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-17T01:20:50Z", "type": "forcePushed"}, {"oid": "2ad53812561e93767216d8dd910c145fcba83bbf", "url": "https://github.com/prestodb/presto/commit/2ad53812561e93767216d8dd910c145fcba83bbf", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-17T03:00:34Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ0ODAyMQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525448021", "bodyText": "Let use the consistent names for this:\n\nvariable: preferManifestsToListFiles\nconfig: hive.prefer-manifests-to-list-files\ngetter/setter: isPreferManifestsToListFiles()/setPreferManifestsToListFiles()\nsession property: prefer_manifests_to_list_files", "author": "highker", "createdAt": "2020-11-17T19:46:00Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -182,6 +182,7 @@\n     private boolean isPartialAggregationPushdownForVariableLengthDatatypesEnabled;\n \n     private boolean fileRenamingEnabled;\n+    private boolean preferManifestToListFiles;", "originalCommit": "d2067ff424532edd84d556d92962e4594b8dac00", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\nindex b805d8ebeb..e6fd16f09c 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\n\n@@ -183,6 +183,7 @@ public class HiveClientConfig\n \n     private boolean fileRenamingEnabled;\n     private boolean preferManifestToListFiles;\n+    private boolean manifestVerificationEnabled;\n \n     public int getMaxInitialSplits()\n     {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ1OTk3MQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525459971", "bodyText": "Usually we wanna avoid default interface. Let's have this in each writer impl.", "author": "highker", "createdAt": "2020-11-17T19:55:46Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java", "diffHunk": "@@ -36,4 +36,9 @@\n     {\n         return Optional.empty();\n     }\n+\n+    default long getFileSize()\n+    {\n+        return getWrittenBytes();\n+    }", "originalCommit": "320d24d15e16c75ac64050f215182995f4e8aa00", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java\nindex 2a43206627..321f019f58 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java\n\n@@ -37,8 +37,5 @@ public interface HiveFileWriter\n         return Optional.empty();\n     }\n \n-    default long getFileSize()\n-    {\n-        return getWrittenBytes();\n-    }\n+    long getFileSizeInBytes();\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ2MDUxNA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525460514", "bodyText": "getFileSizeInBytes()", "author": "highker", "createdAt": "2020-11-17T19:56:11Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java", "diffHunk": "@@ -36,4 +36,9 @@\n     {\n         return Optional.empty();\n     }\n+\n+    default long getFileSize()", "originalCommit": "320d24d15e16c75ac64050f215182995f4e8aa00", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java\nindex 2a43206627..321f019f58 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveFileWriter.java\n\n@@ -37,8 +37,5 @@ public interface HiveFileWriter\n         return Optional.empty();\n     }\n \n-    default long getFileSize()\n-    {\n-        return getWrittenBytes();\n-    }\n+    long getFileSizeInBytes();\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNzU0NA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525527544", "bodyText": "Let's move this above public constants closer to private ones.", "author": "highker", "createdAt": "2020-11-17T21:12:29Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -33,6 +40,13 @@\n     private static final int FILE_SIZE_CHANNEL = 0;\n     private static final int ROW_COUNT_CHANNEL = 1;\n \n+    public static final String FILE_NAMES = \"FILE_NAMES\";\n+    public static final String FILE_SIZES = \"FILE_SIZES\";\n+\n+    // Comma is not a reserved keyword with or without quote\n+    // See https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Keywords,Non-reservedKeywordsandReservedKeywords\n+    private static final char COMMA = ',';", "originalCommit": "fe4ce8f43b9546408285179914e15aece614fd45", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex e3e0688f0c..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -39,13 +46,13 @@ public class HiveManifestUtils\n {\n     private static final int FILE_SIZE_CHANNEL = 0;\n     private static final int ROW_COUNT_CHANNEL = 1;\n+    private static final int COMPRESSION_LEVEL = 7; // default level\n+    private static final String COMMA = \",\";\n \n     public static final String FILE_NAMES = \"FILE_NAMES\";\n     public static final String FILE_SIZES = \"FILE_SIZES\";\n-\n-    // Comma is not a reserved keyword with or without quote\n-    // See https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Keywords,Non-reservedKeywordsandReservedKeywords\n-    private static final char COMMA = ',';\n+    public static final String MANIFEST_VERSION = \"MANIFEST_VERSION\";\n+    public static final String VERSION_1 = \"V1\";\n \n     private HiveManifestUtils()\n     {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyODY0Ng==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525528646", "bodyText": "\"filenames, sizes\" -> file names and sizes", "author": "highker", "createdAt": "2020-11-17T21:14:32Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -1524,4 +1525,17 @@ public boolean isFileRenamingEnabled()\n     {\n         return this.fileRenamingEnabled;\n     }\n+\n+    @Config(\"hive.prefer-manifests-to-list-files\")\n+    @ConfigDescription(\"Prefer to fetch the list of filenames, sizes from manifests rather than storage\")", "originalCommit": "d2067ff424532edd84d556d92962e4594b8dac00", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\nindex b805d8ebeb..e6fd16f09c 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java\n\n@@ -1527,15 +1528,28 @@ public class HiveClientConfig\n     }\n \n     @Config(\"hive.prefer-manifests-to-list-files\")\n-    @ConfigDescription(\"Prefer to fetch the list of filenames, sizes from manifests rather than storage\")\n-    public HiveClientConfig setManifestsToListFilesPreferred(boolean preferManifestToListFiles)\n+    @ConfigDescription(\"Prefer to fetch the list of file names and sizes from manifests rather than storage\")\n+    public HiveClientConfig setPreferManifestsToListFiles(boolean preferManifestToListFiles)\n     {\n         this.preferManifestToListFiles = preferManifestToListFiles;\n         return this;\n     }\n \n-    public boolean isManifestsToListFilesPreferred()\n+    public boolean isPreferManifestsToListFiles()\n     {\n         return this.preferManifestToListFiles;\n     }\n+\n+    @Config(\"hive.manifest-verification-enabled\")\n+    @ConfigDescription(\"Enable verification of file names and sizes in manifest / partition parameters\")\n+    public HiveClientConfig setManifestVerificationEnabled(boolean manifestVerificationEnabled)\n+    {\n+        this.manifestVerificationEnabled = manifestVerificationEnabled;\n+        return this;\n+    }\n+\n+    public boolean isManifestVerificationEnabled()\n+    {\n+        return this.manifestVerificationEnabled;\n+    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzMjcwOA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525532708", "bodyText": "When will we have optional sizes? Will this cause inconsistency between file names and sizes?\nSuggest using delta encoding. Or more easily, build the string and zstd it.", "author": "highker", "createdAt": "2020-11-17T21:22:16Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -85,4 +99,53 @@ public static long getFileSize(Page statisticsPage, int position)\n         }\n         return Optional.of(manifestBuilder.build());\n     }\n+\n+    public static Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n+                .map(FileWriteInfo::getFileSize)\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)", "originalCommit": "fe4ce8f43b9546408285179914e15aece614fd45", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex e3e0688f0c..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -108,25 +115,21 @@ public class HiveManifestUtils\n         // Sort the file infos based on fileName\n         fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n \n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+        // Compress the file names into a consolidated string\n+        String fileNames = compressFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n \n-        // Join the file sizes\n-        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(toImmutableList()));\n+        // Compress the file sizes\n+        String fileSizes = compressFileSizes(fileWriteInfos.stream().map(FileWriteInfo::getFileSize).map(Optional::get).collect(toImmutableList()));\n \n         partitionMetadata.put(FILE_NAMES, fileNames);\n         partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.put(MANIFEST_VERSION, VERSION_1);\n         partitionMetadata.putAll(metadata);\n \n         return partitionMetadata.build();\n     }\n \n-    public static String joinFileNames(List<String> fileNames)\n+    static String compressFileNames(List<String> fileNames)\n     {\n         if (fileNames.size() == 1) {\n             return fileNames.get(0);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUzNTY2Mg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525535662", "bodyText": "private\ncompressFileNames", "author": "highker", "createdAt": "2020-11-17T21:27:34Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -85,4 +99,53 @@ public static long getFileSize(Page statisticsPage, int position)\n         }\n         return Optional.of(manifestBuilder.build());\n     }\n+\n+    public static Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n+                .map(FileWriteInfo::getFileSize)\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .map(String::valueOf)\n+                .collect(toImmutableList()));\n+\n+        partitionMetadata.put(FILE_NAMES, fileNames);\n+        partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.putAll(metadata);\n+\n+        return partitionMetadata.build();\n+    }\n+\n+    public static String joinFileNames(List<String> fileNames)", "originalCommit": "fe4ce8f43b9546408285179914e15aece614fd45", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex e3e0688f0c..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -108,25 +115,21 @@ public class HiveManifestUtils\n         // Sort the file infos based on fileName\n         fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n \n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+        // Compress the file names into a consolidated string\n+        String fileNames = compressFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n \n-        // Join the file sizes\n-        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(toImmutableList()));\n+        // Compress the file sizes\n+        String fileSizes = compressFileSizes(fileWriteInfos.stream().map(FileWriteInfo::getFileSize).map(Optional::get).collect(toImmutableList()));\n \n         partitionMetadata.put(FILE_NAMES, fileNames);\n         partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.put(MANIFEST_VERSION, VERSION_1);\n         partitionMetadata.putAll(metadata);\n \n         return partitionMetadata.build();\n     }\n \n-    public static String joinFileNames(List<String> fileNames)\n+    static String compressFileNames(List<String> fileNames)\n     {\n         if (fileNames.size() == 1) {\n             return fileNames.get(0);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0MDkzNg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525540936", "bodyText": "Leaning towards having a version (e.g., \"V1\", \"V2\", ...) for the file names/sizes format. This can be helpful in the future to use different serde. Once we have that, we can put joinFileNames and Joiner on sizes into for example a V1 class for serde processing. We may introduce V2 sometime in the future.", "author": "highker", "createdAt": "2020-11-17T21:37:26Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -85,4 +99,53 @@ public static long getFileSize(Page statisticsPage, int position)\n         }\n         return Optional.of(manifestBuilder.build());\n     }\n+\n+    public static Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n+                .map(FileWriteInfo::getFileSize)\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .map(String::valueOf)\n+                .collect(toImmutableList()));\n+\n+        partitionMetadata.put(FILE_NAMES, fileNames);\n+        partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.putAll(metadata);", "originalCommit": "fe4ce8f43b9546408285179914e15aece614fd45", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex e3e0688f0c..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -108,25 +115,21 @@ public class HiveManifestUtils\n         // Sort the file infos based on fileName\n         fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n \n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+        // Compress the file names into a consolidated string\n+        String fileNames = compressFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n \n-        // Join the file sizes\n-        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(toImmutableList()));\n+        // Compress the file sizes\n+        String fileSizes = compressFileSizes(fileWriteInfos.stream().map(FileWriteInfo::getFileSize).map(Optional::get).collect(toImmutableList()));\n \n         partitionMetadata.put(FILE_NAMES, fileNames);\n         partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.put(MANIFEST_VERSION, VERSION_1);\n         partitionMetadata.putAll(metadata);\n \n         return partitionMetadata.build();\n     }\n \n-    public static String joinFileNames(List<String> fileNames)\n+    static String compressFileNames(List<String> fileNames)\n     {\n         if (fileNames.size() == 1) {\n             return fileNames.get(0);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0NjMyNg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525546326", "bodyText": "create a similar helper like joinFileNames.", "author": "highker", "createdAt": "2020-11-17T21:47:28Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -85,4 +99,53 @@ public static long getFileSize(Page statisticsPage, int position)\n         }\n         return Optional.of(manifestBuilder.build());\n     }\n+\n+    public static Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()", "originalCommit": "fe4ce8f43b9546408285179914e15aece614fd45", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex e3e0688f0c..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -108,25 +115,21 @@ public class HiveManifestUtils\n         // Sort the file infos based on fileName\n         fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n \n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+        // Compress the file names into a consolidated string\n+        String fileNames = compressFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n \n-        // Join the file sizes\n-        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(toImmutableList()));\n+        // Compress the file sizes\n+        String fileSizes = compressFileSizes(fileWriteInfos.stream().map(FileWriteInfo::getFileSize).map(Optional::get).collect(toImmutableList()));\n \n         partitionMetadata.put(FILE_NAMES, fileNames);\n         partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.put(MANIFEST_VERSION, VERSION_1);\n         partitionMetadata.putAll(metadata);\n \n         return partitionMetadata.build();\n     }\n \n-    public static String joinFileNames(List<String> fileNames)\n+    static String compressFileNames(List<String> fileNames)\n     {\n         if (fileNames.size() == 1) {\n             return fileNames.get(0);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU0NjY2NA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525546664", "bodyText": "Recommend to use roaring bitmap (https://roaringbitmap.org/) for this. It will provide good compression ratio.", "author": "highker", "createdAt": "2020-11-17T21:48:08Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -85,4 +99,53 @@ public static long getFileSize(Page statisticsPage, int position)\n         }\n         return Optional.of(manifestBuilder.build());\n     }\n+\n+    public static Map<String, String> updatePartitionMetadataWithFileNamesAndSizes(PartitionUpdate partitionUpdate, Map<String, String> metadata)\n+    {\n+        ImmutableMap.Builder<String, String> partitionMetadata = ImmutableMap.builder();\n+        List<FileWriteInfo> fileWriteInfos = new ArrayList<>(partitionUpdate.getFileWriteInfos());\n+\n+        // Sort the file infos based on fileName\n+        fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n+\n+        // Join the file names into a consolidated string\n+        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+\n+        // Join the file sizes\n+        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n+                .map(FileWriteInfo::getFileSize)\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .map(String::valueOf)\n+                .collect(toImmutableList()));\n+\n+        partitionMetadata.put(FILE_NAMES, fileNames);\n+        partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.putAll(metadata);\n+\n+        return partitionMetadata.build();\n+    }\n+\n+    public static String joinFileNames(List<String> fileNames)\n+    {\n+        if (fileNames.size() == 1) {\n+            return fileNames.get(0);\n+        }\n+\n+        boolean isContinuousSequence = true;\n+        int start = 0;\n+        for (String name : fileNames) {\n+            if (start != Integer.parseInt(name)) {\n+                isContinuousSequence = false;\n+                break;\n+            }\n+            start++;\n+        }\n+\n+        if (isContinuousSequence) {\n+            return fileNames.get(fileNames.size() - 1);\n+        }\n+\n+        return Joiner.on(COMMA).join(fileNames);", "originalCommit": "fe4ce8f43b9546408285179914e15aece614fd45", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex e3e0688f0c..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -108,25 +115,21 @@ public class HiveManifestUtils\n         // Sort the file infos based on fileName\n         fileWriteInfos.sort(Comparator.comparing(info -> Integer.valueOf(info.getWriteFileName())));\n \n-        // Join the file names into a consolidated string\n-        String fileNames = joinFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n+        // Compress the file names into a consolidated string\n+        String fileNames = compressFileNames(fileWriteInfos.stream().map(FileWriteInfo::getWriteFileName).collect(toImmutableList()));\n \n-        // Join the file sizes\n-        String fileSizes = Joiner.on(COMMA).join(fileWriteInfos.stream()\n-                .map(FileWriteInfo::getFileSize)\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .map(String::valueOf)\n-                .collect(toImmutableList()));\n+        // Compress the file sizes\n+        String fileSizes = compressFileSizes(fileWriteInfos.stream().map(FileWriteInfo::getFileSize).map(Optional::get).collect(toImmutableList()));\n \n         partitionMetadata.put(FILE_NAMES, fileNames);\n         partitionMetadata.put(FILE_SIZES, fileSizes);\n+        partitionMetadata.put(MANIFEST_VERSION, VERSION_1);\n         partitionMetadata.putAll(metadata);\n \n         return partitionMetadata.build();\n     }\n \n-    public static String joinFileNames(List<String> fileNames)\n+    static String compressFileNames(List<String> fileNames)\n     {\n         if (fileNames.size() == 1) {\n             return fileNames.get(0);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NDExNA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525554114", "bodyText": "Use versioning flag to decide maybe", "author": "highker", "createdAt": "2020-11-17T22:02:15Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.StoragePartitionLoader.BucketSplitInfo;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import java.io.IOException;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DelegatingPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final ConnectorSession session;\n+    private final PartitionLoader storagePartitionLoader;\n+    private final PartitionLoader manifestPartitionLoader;\n+\n+    public DelegatingPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            Optional<BucketSplitInfo> tableBucketInfo,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            NamenodeStats namenodeStats,\n+            DirectoryLister directoryLister,\n+            Deque<Iterator<InternalHiveSplit>> fileIterators,\n+            boolean recursiveDirWalkerEnabled,\n+            boolean schedulerUsesHostAddresses,\n+            boolean partialAggregationsPushedDown)\n+    {\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.storagePartitionLoader = new StoragePartitionLoader(table, pathDomain, tableBucketInfo, session, hdfsEnvironment, namenodeStats, directoryLister, fileIterators, recursiveDirWalkerEnabled, schedulerUsesHostAddresses, partialAggregationsPushedDown);\n+        this.manifestPartitionLoader = new ManifestPartitionLoader(table, pathDomain, session, hdfsEnvironment, schedulerUsesHostAddresses);\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        if (isListFilesLoadedPartition(session, partition.getPartition())) {\n+            // Partition has list of filenames, sizes. We can avoid the listFiles() call to underlying storage.\n+            return manifestPartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n+        }\n+\n+        return storagePartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n+    }\n+\n+    public static boolean isListFilesLoadedPartition(ConnectorSession session, Optional<Partition> partition)\n+    {\n+        if (partition.isPresent() && HiveSessionProperties.isManifestsToListFilesPreferred(session)) {\n+            Map<String, String> parameters = partition.get().getParameters();\n+            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {", "originalCommit": "f2bf68f4a0e48a2b4c5a53391f7a2b90a7f3f831", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\nindex cdebe7aec0..f9f5e0a95e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\n\n@@ -26,8 +26,7 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Optional;\n \n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.MANIFEST_VERSION;\n import static java.util.Objects.requireNonNull;\n \n public class DelegatingPartitionLoader\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NDIzMw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525554233", "bodyText": "No need to have if, directly return the condition within if.", "author": "highker", "createdAt": "2020-11-17T22:02:30Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.StoragePartitionLoader.BucketSplitInfo;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import java.io.IOException;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DelegatingPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final ConnectorSession session;\n+    private final PartitionLoader storagePartitionLoader;\n+    private final PartitionLoader manifestPartitionLoader;\n+\n+    public DelegatingPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            Optional<BucketSplitInfo> tableBucketInfo,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            NamenodeStats namenodeStats,\n+            DirectoryLister directoryLister,\n+            Deque<Iterator<InternalHiveSplit>> fileIterators,\n+            boolean recursiveDirWalkerEnabled,\n+            boolean schedulerUsesHostAddresses,\n+            boolean partialAggregationsPushedDown)\n+    {\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.storagePartitionLoader = new StoragePartitionLoader(table, pathDomain, tableBucketInfo, session, hdfsEnvironment, namenodeStats, directoryLister, fileIterators, recursiveDirWalkerEnabled, schedulerUsesHostAddresses, partialAggregationsPushedDown);\n+        this.manifestPartitionLoader = new ManifestPartitionLoader(table, pathDomain, session, hdfsEnvironment, schedulerUsesHostAddresses);\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        if (isListFilesLoadedPartition(session, partition.getPartition())) {\n+            // Partition has list of filenames, sizes. We can avoid the listFiles() call to underlying storage.\n+            return manifestPartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n+        }\n+\n+        return storagePartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n+    }\n+\n+    public static boolean isListFilesLoadedPartition(ConnectorSession session, Optional<Partition> partition)\n+    {\n+        if (partition.isPresent() && HiveSessionProperties.isManifestsToListFilesPreferred(session)) {\n+            Map<String, String> parameters = partition.get().getParameters();\n+            if (parameters.containsKey(FILE_NAMES) && parameters.containsKey(FILE_SIZES)) {\n+                return true;", "originalCommit": "f2bf68f4a0e48a2b4c5a53391f7a2b90a7f3f831", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\nindex cdebe7aec0..f9f5e0a95e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\n\n@@ -26,8 +26,7 @@ import java.util.Iterator;\n import java.util.Map;\n import java.util.Optional;\n \n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.MANIFEST_VERSION;\n import static java.util.Objects.requireNonNull;\n \n public class DelegatingPartitionLoader\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NDk5MA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525554990", "bodyText": "Didn't look deep into this class. Assume it's all about moving code around. Anything specific I should be aware of?", "author": "highker", "createdAt": "2020-11-17T22:04:06Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/StoragePartitionLoader.java", "diffHunk": "@@ -0,0 +1,495 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.HiveFileIterator;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.google.common.base.Suppliers;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterators;\n+import com.google.common.io.CharStreams;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.PathFilter;\n+import org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat;\n+import org.apache.hadoop.mapred.FileInputFormat;\n+import org.apache.hadoop.mapred.FileSplit;\n+import org.apache.hadoop.mapred.InputFormat;\n+import org.apache.hadoop.mapred.InputSplit;\n+import org.apache.hadoop.mapred.JobConf;\n+import org.apache.hadoop.mapred.TextInputFormat;\n+import org.apache.hudi.hadoop.HoodieParquetInputFormat;\n+import org.apache.hudi.hadoop.HoodieROTablePathFilter;\n+import org.apache.hudi.hadoop.realtime.HoodieParquetRealtimeInputFormat;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.lang.annotation.Annotation;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.function.IntPredicate;\n+import java.util.function.Supplier;\n+\n+import static com.facebook.presto.hive.HiveBucketing.getVirtualBucketNumber;\n+import static com.facebook.presto.hive.HiveColumnHandle.pathColumnHandle;\n+import static com.facebook.presto.hive.HiveErrorCode.HIVE_BAD_DATA;\n+import static com.facebook.presto.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveSessionProperties.isUseListDirectoryCache;\n+import static com.facebook.presto.hive.HiveUtil.getFooterCount;\n+import static com.facebook.presto.hive.HiveUtil.getHeaderCount;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.FAIL;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n+import static com.facebook.presto.hive.S3SelectPushdown.shouldEnablePushdownForTable;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getHiveSchema;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.facebook.presto.hive.util.ConfigurationUtils.toJobConf;\n+import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.util.concurrent.Futures.immediateFuture;\n+import static java.lang.Math.max;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.hadoop.hive.common.FileUtils.HIDDEN_FILES_PATH_FILTER;\n+\n+public class StoragePartitionLoader", "originalCommit": "f2bf68f4a0e48a2b4c5a53391f7a2b90a7f3f831", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzA3NzE5Mg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r527077192", "bodyText": "Correct. It's just moved code. No changes to be aware of.", "author": "NikhilCollooru", "createdAt": "2020-11-19T17:41:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NDk5MA=="}], "type": "inlineReview", "revised_code": {"commit": "16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/StoragePartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/StoragePartitionLoader.java\ndeleted file mode 100644\nindex e96fef7015..0000000000\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/StoragePartitionLoader.java\n+++ /dev/null\n\n@@ -1,495 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.facebook.presto.hive;\n-\n-import com.facebook.presto.common.predicate.Domain;\n-import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n-import com.facebook.presto.hive.metastore.Partition;\n-import com.facebook.presto.hive.metastore.Storage;\n-import com.facebook.presto.hive.metastore.Table;\n-import com.facebook.presto.hive.util.HiveFileIterator;\n-import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n-import com.facebook.presto.spi.ConnectorSession;\n-import com.facebook.presto.spi.PrestoException;\n-import com.facebook.presto.spi.SchemaTableName;\n-import com.google.common.base.Suppliers;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.Iterators;\n-import com.google.common.io.CharStreams;\n-import com.google.common.util.concurrent.ListenableFuture;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.PathFilter;\n-import org.apache.hadoop.hive.ql.io.SymlinkTextInputFormat;\n-import org.apache.hadoop.mapred.FileInputFormat;\n-import org.apache.hadoop.mapred.FileSplit;\n-import org.apache.hadoop.mapred.InputFormat;\n-import org.apache.hadoop.mapred.InputSplit;\n-import org.apache.hadoop.mapred.JobConf;\n-import org.apache.hadoop.mapred.TextInputFormat;\n-import org.apache.hudi.hadoop.HoodieParquetInputFormat;\n-import org.apache.hudi.hadoop.HoodieROTablePathFilter;\n-import org.apache.hudi.hadoop.realtime.HoodieParquetRealtimeInputFormat;\n-\n-import java.io.BufferedReader;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n-import java.lang.annotation.Annotation;\n-import java.nio.charset.StandardCharsets;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Deque;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Optional;\n-import java.util.Properties;\n-import java.util.function.IntPredicate;\n-import java.util.function.Supplier;\n-\n-import static com.facebook.presto.hive.HiveBucketing.getVirtualBucketNumber;\n-import static com.facebook.presto.hive.HiveColumnHandle.pathColumnHandle;\n-import static com.facebook.presto.hive.HiveErrorCode.HIVE_BAD_DATA;\n-import static com.facebook.presto.hive.HiveErrorCode.HIVE_INVALID_BUCKET_FILES;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n-import static com.facebook.presto.hive.HiveSessionProperties.isUseListDirectoryCache;\n-import static com.facebook.presto.hive.HiveUtil.getFooterCount;\n-import static com.facebook.presto.hive.HiveUtil.getHeaderCount;\n-import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.FAIL;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n-import static com.facebook.presto.hive.S3SelectPushdown.shouldEnablePushdownForTable;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getHiveSchema;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n-import static com.facebook.presto.hive.util.ConfigurationUtils.toJobConf;\n-import static com.facebook.presto.spi.StandardErrorCode.NOT_SUPPORTED;\n-import static com.google.common.base.Preconditions.checkArgument;\n-import static com.google.common.base.Preconditions.checkState;\n-import static com.google.common.collect.ImmutableList.toImmutableList;\n-import static com.google.common.collect.Streams.stream;\n-import static com.google.common.util.concurrent.Futures.immediateFuture;\n-import static java.lang.Math.max;\n-import static java.lang.String.format;\n-import static java.util.Objects.requireNonNull;\n-import static org.apache.hadoop.hive.common.FileUtils.HIDDEN_FILES_PATH_FILTER;\n-\n-public class StoragePartitionLoader\n-        extends PartitionLoader\n-{\n-    private static final ListenableFuture<?> COMPLETED_FUTURE = immediateFuture(null);\n-\n-    private final Table table;\n-    private final Optional<Domain> pathDomain;\n-    private final Optional<BucketSplitInfo> tableBucketInfo;\n-    private final HdfsEnvironment hdfsEnvironment;\n-    private final HdfsContext hdfsContext;\n-    private final NamenodeStats namenodeStats;\n-    private final DirectoryLister directoryLister;\n-    private final boolean recursiveDirWalkerEnabled;\n-    private final ConnectorSession session;\n-    private final Deque<Iterator<InternalHiveSplit>> fileIterators;\n-    private final boolean schedulerUsesHostAddresses;\n-    private final Supplier<HoodieROTablePathFilter> hoodiePathFilterSupplier;\n-    private final boolean partialAggregationsPushedDown;\n-\n-    public StoragePartitionLoader(\n-            Table table,\n-            Optional<Domain> pathDomain,\n-            Optional<BucketSplitInfo> tableBucketInfo,\n-            ConnectorSession session,\n-            HdfsEnvironment hdfsEnvironment,\n-            NamenodeStats namenodeStats,\n-            DirectoryLister directoryLister,\n-            Deque<Iterator<InternalHiveSplit>> fileIterators,\n-            boolean recursiveDirWalkerEnabled,\n-            boolean schedulerUsesHostAddresses,\n-            boolean partialAggregationsPushedDown)\n-    {\n-        this.table = requireNonNull(table, \"table is null\");\n-        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n-        this.tableBucketInfo = requireNonNull(tableBucketInfo, \"tableBucketInfo is null\");\n-        this.session = requireNonNull(session, \"session is null\");\n-        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n-        this.namenodeStats = requireNonNull(namenodeStats, \"namenodeStats is null\");\n-        this.directoryLister = requireNonNull(directoryLister, \"directoryLister is null\");\n-        this.recursiveDirWalkerEnabled = recursiveDirWalkerEnabled;\n-        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n-        this.fileIterators = requireNonNull(fileIterators, \"fileIterators is null\");\n-        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n-        this.hoodiePathFilterSupplier = Suppliers.memoize(HoodieROTablePathFilter::new)::get;\n-        this.partialAggregationsPushedDown = partialAggregationsPushedDown;\n-    }\n-\n-    @Override\n-    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n-            throws IOException\n-    {\n-        String partitionName = partition.getHivePartition().getPartitionId();\n-        Storage storage = partition.getPartition().map(Partition::getStorage).orElse(table.getStorage());\n-        String inputFormatName = storage.getStorageFormat().getInputFormat();\n-        int partitionDataColumnCount = partition.getPartition()\n-                .map(p -> p.getColumns().size())\n-                .orElse(table.getDataColumns().size());\n-        List<HivePartitionKey> partitionKeys = getPartitionKeys(table, partition.getPartition());\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Configuration configuration = hdfsEnvironment.getConfiguration(hdfsContext, path);\n-        InputFormat<?, ?> inputFormat = getInputFormat(configuration, inputFormatName, false);\n-        ExtendedFileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);\n-        boolean s3SelectPushdownEnabled = shouldEnablePushdownForTable(session, table, path.toString(), partition.getPartition());\n-\n-        if (inputFormat instanceof SymlinkTextInputFormat) {\n-            if (tableBucketInfo.isPresent()) {\n-                throw new PrestoException(NOT_SUPPORTED, \"Bucketed table in SymlinkTextInputFormat is not yet supported\");\n-            }\n-\n-            // TODO: This should use an iterator like the HiveFileIterator\n-            ListenableFuture<?> lastResult = COMPLETED_FUTURE;\n-            for (Path targetPath : getTargetPathsFromSymlink(fs, path)) {\n-                // The input should be in TextInputFormat.\n-                TextInputFormat targetInputFormat = new TextInputFormat();\n-                // the splits must be generated using the file system for the target path\n-                // get the configuration for the target path -- it may be a different hdfs instance\n-                ExtendedFileSystem targetFilesystem = hdfsEnvironment.getFileSystem(hdfsContext, targetPath);\n-                JobConf targetJob = toJobConf(targetFilesystem.getConf());\n-                targetJob.setInputFormat(TextInputFormat.class);\n-                targetInputFormat.configure(targetJob);\n-                FileInputFormat.setInputPaths(targetJob, targetPath);\n-                InputSplit[] targetSplits = targetInputFormat.getSplits(targetJob, 0);\n-\n-                InternalHiveSplitFactory splitFactory = new InternalHiveSplitFactory(\n-                        targetFilesystem,\n-                        inputFormat,\n-                        pathDomain,\n-                        getNodeSelectionStrategy(session),\n-                        getMaxInitialSplitSize(session),\n-                        s3SelectPushdownEnabled,\n-                        new HiveSplitPartitionInfo(storage, path.toUri(), partitionKeys, partitionName, partitionDataColumnCount, partition.getPartitionSchemaDifference(), Optional.empty()),\n-                        schedulerUsesHostAddresses,\n-                        partition.getEncryptionInformation());\n-                lastResult = addSplitsToSource(targetSplits, splitFactory, hiveSplitSource, stopped);\n-                if (stopped) {\n-                    return COMPLETED_FUTURE;\n-                }\n-            }\n-            return lastResult;\n-        }\n-\n-        Optional<HiveSplit.BucketConversion> bucketConversion = Optional.empty();\n-        boolean bucketConversionRequiresWorkerParticipation = false;\n-        if (partition.getPartition().isPresent()) {\n-            Optional<HiveBucketProperty> partitionBucketProperty = partition.getPartition().get().getStorage().getBucketProperty();\n-            if (tableBucketInfo.isPresent() && partitionBucketProperty.isPresent()) {\n-                int tableBucketCount = tableBucketInfo.get().getTableBucketCount();\n-                int partitionBucketCount = partitionBucketProperty.get().getBucketCount();\n-                // Validation was done in HiveSplitManager#getPartitionMetadata.\n-                // Here, it's just trying to see if its needs the BucketConversion.\n-                if (tableBucketCount != partitionBucketCount) {\n-                    bucketConversion = Optional.of(new HiveSplit.BucketConversion(tableBucketCount, partitionBucketCount, tableBucketInfo.get().getBucketColumns()));\n-                    if (tableBucketCount > partitionBucketCount) {\n-                        bucketConversionRequiresWorkerParticipation = true;\n-                    }\n-                }\n-            }\n-        }\n-        InternalHiveSplitFactory splitFactory = new InternalHiveSplitFactory(\n-                fs,\n-                inputFormat,\n-                pathDomain,\n-                getNodeSelectionStrategy(session),\n-                getMaxInitialSplitSize(session),\n-                s3SelectPushdownEnabled,\n-                new HiveSplitPartitionInfo(\n-                        storage,\n-                        path.toUri(),\n-                        partitionKeys,\n-                        partitionName,\n-                        partitionDataColumnCount,\n-                        partition.getPartitionSchemaDifference(),\n-                        bucketConversionRequiresWorkerParticipation ? bucketConversion : Optional.empty()),\n-                schedulerUsesHostAddresses,\n-                partition.getEncryptionInformation());\n-\n-        if (!isHudiParquetInputFormat(inputFormat) && shouldUseFileSplitsFromInputFormat(inputFormat)) {\n-            if (tableBucketInfo.isPresent()) {\n-                throw new PrestoException(NOT_SUPPORTED, \"Presto cannot read bucketed partition in an input format with UseFileSplitsFromInputFormat annotation: \" + inputFormat.getClass().getSimpleName());\n-            }\n-            JobConf jobConf = toJobConf(configuration);\n-            FileInputFormat.setInputPaths(jobConf, path);\n-            InputSplit[] splits = inputFormat.getSplits(jobConf, 0);\n-\n-            return addSplitsToSource(splits, splitFactory, hiveSplitSource, stopped);\n-        }\n-        PathFilter pathFilter = isHudiParquetInputFormat(inputFormat) ? hoodiePathFilterSupplier.get() : path1 -> true;\n-        // S3 Select pushdown works at the granularity of individual S3 objects,\n-        // Partial aggregation pushdown works at the granularity of individual files\n-        // therefore we must not split files when either is enabled.\n-        Properties schema = getHiveSchema(storage.getSerdeParameters(), table.getParameters());\n-        // Skip header / footer lines are not splittable except for a special case when skip.header.line.count=1\n-        boolean splittable = !s3SelectPushdownEnabled && !partialAggregationsPushedDown && getFooterCount(schema) == 0 && getHeaderCount(schema) <= 1;\n-\n-        // Bucketed partitions are fully loaded immediately since all files must be loaded to determine the file to bucket mapping\n-        if (tableBucketInfo.isPresent()) {\n-            if (tableBucketInfo.get().isVirtuallyBucketed()) {\n-                // For virtual bucket, bucket conversion must not be present because there is no physical partition bucket count\n-                checkState(!bucketConversion.isPresent(), \"Virtually bucketed table must not have partitions that are physically bucketed\");\n-                checkState(\n-                        tableBucketInfo.get().getTableBucketCount() == tableBucketInfo.get().getReadBucketCount(),\n-                        \"Table and read bucket count should be the same for virtual bucket\");\n-                return hiveSplitSource.addToQueue(getVirtuallyBucketedSplits(path, fs, splitFactory, tableBucketInfo.get().getReadBucketCount(), splittable, pathFilter));\n-            }\n-            return hiveSplitSource.addToQueue(getBucketedSplits(path, fs, splitFactory, tableBucketInfo.get(), bucketConversion, partitionName, splittable, pathFilter));\n-        }\n-\n-        fileIterators.addLast(createInternalHiveSplitIterator(path, fs, splitFactory, splittable, pathFilter, partition.getPartition()));\n-        return COMPLETED_FUTURE;\n-    }\n-\n-    private ListenableFuture<?> addSplitsToSource(InputSplit[] targetSplits, InternalHiveSplitFactory splitFactory, HiveSplitSource hiveSplitSource, boolean stopped)\n-            throws IOException\n-    {\n-        ListenableFuture<?> lastResult = COMPLETED_FUTURE;\n-        for (InputSplit inputSplit : targetSplits) {\n-            Optional<InternalHiveSplit> internalHiveSplit = splitFactory.createInternalHiveSplit((FileSplit) inputSplit);\n-            if (internalHiveSplit.isPresent()) {\n-                lastResult = hiveSplitSource.addToQueue(internalHiveSplit.get());\n-            }\n-            if (stopped) {\n-                return COMPLETED_FUTURE;\n-            }\n-        }\n-        return lastResult;\n-    }\n-\n-    private static boolean isHudiParquetInputFormat(InputFormat<?, ?> inputFormat)\n-    {\n-        if (inputFormat instanceof HoodieParquetRealtimeInputFormat) {\n-            return false;\n-        }\n-        return inputFormat instanceof HoodieParquetInputFormat;\n-    }\n-\n-    private static boolean shouldUseFileSplitsFromInputFormat(InputFormat<?, ?> inputFormat)\n-    {\n-        return Arrays.stream(inputFormat.getClass().getAnnotations())\n-                .map(Annotation::annotationType)\n-                .map(Class::getSimpleName)\n-                .anyMatch(name -> name.equals(\"UseFileSplitsFromInputFormat\"));\n-    }\n-\n-    private Iterator<InternalHiveSplit> createInternalHiveSplitIterator(Path path, ExtendedFileSystem fileSystem, InternalHiveSplitFactory splitFactory, boolean splittable, PathFilter pathFilter, Optional<Partition> partition)\n-    {\n-        boolean cacheable = isUseListDirectoryCache(session);\n-        if (partition.isPresent()) {\n-            // Use cache only for sealed partitions\n-            cacheable &= partition.get().isSealedPartition();\n-        }\n-\n-        HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, cacheable);\n-        return stream(directoryLister.list(fileSystem, table, path, namenodeStats, pathFilter, hiveDirectoryContext))\n-                .map(status -> splitFactory.createInternalHiveSplit(status, splittable))\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .iterator();\n-    }\n-\n-    private List<InternalHiveSplit> getBucketedSplits(\n-            Path path,\n-            ExtendedFileSystem fileSystem,\n-            InternalHiveSplitFactory splitFactory,\n-            BucketSplitInfo bucketSplitInfo,\n-            Optional<HiveSplit.BucketConversion> bucketConversion,\n-            String partitionName,\n-            boolean splittable,\n-            PathFilter pathFilter)\n-    {\n-        int readBucketCount = bucketSplitInfo.getReadBucketCount();\n-        int tableBucketCount = bucketSplitInfo.getTableBucketCount();\n-        int partitionBucketCount = bucketConversion.map(HiveSplit.BucketConversion::getPartitionBucketCount).orElse(tableBucketCount);\n-\n-        checkState(readBucketCount <= tableBucketCount, \"readBucketCount(%s) should be less than or equal to tableBucketCount(%s)\", readBucketCount, tableBucketCount);\n-\n-        // list all files in the partition\n-        List<HiveFileInfo> fileInfos = new ArrayList<>(partitionBucketCount);\n-        try {\n-            Iterators.addAll(fileInfos, directoryLister.list(fileSystem, table, path, namenodeStats, pathFilter, new HiveDirectoryContext(FAIL, isUseListDirectoryCache(session))));\n-        }\n-        catch (HiveFileIterator.NestedDirectoryNotAllowedException e) {\n-            // Fail here to be on the safe side. This seems to be the same as what Hive does\n-            throw new PrestoException(\n-                    HIVE_INVALID_BUCKET_FILES,\n-                    format(\"Hive table '%s' is corrupt. Found sub-directory in bucket directory for partition: %s\",\n-                            new SchemaTableName(table.getDatabaseName(), table.getTableName()),\n-                            partitionName));\n-        }\n-\n-        // verify we found one file per bucket\n-        if (fileInfos.size() != partitionBucketCount) {\n-            throw new PrestoException(\n-                    HIVE_INVALID_BUCKET_FILES,\n-                    format(\"Hive table '%s' is corrupt. The number of files in the directory (%s) does not match the declared bucket count (%s) for partition: %s\",\n-                            new SchemaTableName(table.getDatabaseName(), table.getTableName()),\n-                            fileInfos.size(),\n-                            partitionBucketCount,\n-                            partitionName));\n-        }\n-\n-        // Sort FileStatus objects (instead of, e.g., fileStatus.getPath().toString). This matches org.apache.hadoop.hive.ql.metadata.Table.getSortedPaths\n-        fileInfos.sort(null);\n-\n-        // convert files internal splits\n-        List<InternalHiveSplit> splitList = new ArrayList<>();\n-        for (int bucketNumber = 0; bucketNumber < max(readBucketCount, partitionBucketCount); bucketNumber++) {\n-            // Physical bucket #. This determine file name. It also determines the order of splits in the result.\n-            int partitionBucketNumber = bucketNumber % partitionBucketCount;\n-            // Logical bucket #. Each logical bucket corresponds to a \"bucket\" from engine's perspective.\n-            int readBucketNumber = bucketNumber % readBucketCount;\n-\n-            boolean containsIneligibleTableBucket = false;\n-            List<Integer> eligibleTableBucketNumbers = new ArrayList<>();\n-            for (int tableBucketNumber = bucketNumber % tableBucketCount; tableBucketNumber < tableBucketCount; tableBucketNumber += max(readBucketCount, partitionBucketCount)) {\n-                // table bucket number: this is used for evaluating \"$bucket\" filters.\n-                if (bucketSplitInfo.isTableBucketEnabled(tableBucketNumber)) {\n-                    eligibleTableBucketNumbers.add(tableBucketNumber);\n-                }\n-                else {\n-                    containsIneligibleTableBucket = true;\n-                }\n-            }\n-\n-            if (!eligibleTableBucketNumbers.isEmpty() && containsIneligibleTableBucket) {\n-                throw new PrestoException(\n-                        NOT_SUPPORTED,\n-                        \"The bucket filter cannot be satisfied. There are restrictions on the bucket filter when all the following is true: \" +\n-                                \"1. a table has a different buckets count as at least one of its partitions that is read in this query; \" +\n-                                \"2. the table has a different but compatible bucket number with another table in the query; \" +\n-                                \"3. some buckets of the table is filtered out from the query, most likely using a filter on \\\"$bucket\\\". \" +\n-                                \"(table name: \" + table.getTableName() + \", table bucket count: \" + tableBucketCount + \", \" +\n-                                \"partition bucket count: \" + partitionBucketCount + \", effective reading bucket count: \" + readBucketCount + \")\");\n-            }\n-            if (!eligibleTableBucketNumbers.isEmpty()) {\n-                HiveFileInfo fileInfo = fileInfos.get(partitionBucketNumber);\n-                eligibleTableBucketNumbers.stream()\n-                        .map(tableBucketNumber -> splitFactory.createInternalHiveSplit(fileInfo, readBucketNumber, tableBucketNumber, splittable))\n-                        .forEach(optionalSplit -> optionalSplit.ifPresent(splitList::add));\n-            }\n-        }\n-        return splitList;\n-    }\n-\n-    private List<InternalHiveSplit> getVirtuallyBucketedSplits(Path path, ExtendedFileSystem fileSystem, InternalHiveSplitFactory splitFactory, int bucketCount, boolean splittable, PathFilter pathFilter)\n-    {\n-        // List all files recursively in the partition and assign virtual bucket number to each of them\n-        HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, isUseListDirectoryCache(session));\n-        return stream(directoryLister.list(fileSystem, table, path, namenodeStats, pathFilter, hiveDirectoryContext))\n-                .map(fileInfo -> {\n-                    int virtualBucketNumber = getVirtualBucketNumber(bucketCount, fileInfo.getPath());\n-                    return splitFactory.createInternalHiveSplit(fileInfo, virtualBucketNumber, virtualBucketNumber, splittable);\n-                })\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .collect(toImmutableList());\n-    }\n-\n-    private static List<Path> getTargetPathsFromSymlink(ExtendedFileSystem fileSystem, Path symlinkDir)\n-    {\n-        try {\n-            FileStatus[] symlinks = fileSystem.listStatus(symlinkDir, HIDDEN_FILES_PATH_FILTER);\n-            List<Path> targets = new ArrayList<>();\n-\n-            for (FileStatus symlink : symlinks) {\n-                try (BufferedReader reader = new BufferedReader(new InputStreamReader(fileSystem.open(symlink.getPath()), StandardCharsets.UTF_8))) {\n-                    CharStreams.readLines(reader).stream()\n-                            .map(Path::new)\n-                            .forEach(targets::add);\n-                }\n-            }\n-            return targets;\n-        }\n-        catch (IOException e) {\n-            throw new PrestoException(HIVE_BAD_DATA, \"Error parsing symlinks from: \" + symlinkDir, e);\n-        }\n-    }\n-\n-    public static class BucketSplitInfo\n-    {\n-        private final List<HiveColumnHandle> bucketColumns;\n-        private final int tableBucketCount;\n-        private final int readBucketCount;\n-        private final IntPredicate bucketFilter;\n-\n-        public static Optional<BucketSplitInfo> createBucketSplitInfo(Optional<HiveBucketHandle> bucketHandle, Optional<HiveBucketing.HiveBucketFilter> bucketFilter)\n-        {\n-            requireNonNull(bucketHandle, \"bucketHandle is null\");\n-            requireNonNull(bucketFilter, \"buckets is null\");\n-\n-            if (!bucketHandle.isPresent()) {\n-                checkArgument(!bucketFilter.isPresent(), \"bucketHandle must be present if bucketFilter is present\");\n-                return Optional.empty();\n-            }\n-\n-            int tableBucketCount = bucketHandle.get().getTableBucketCount();\n-            int readBucketCount = bucketHandle.get().getReadBucketCount();\n-\n-            List<HiveColumnHandle> bucketColumns = bucketHandle.get().getColumns();\n-            IntPredicate predicate = bucketFilter\n-                    .<IntPredicate>map(filter -> filter.getBucketsToKeep()::contains)\n-                    .orElse(bucket -> true);\n-            return Optional.of(new BucketSplitInfo(bucketColumns, tableBucketCount, readBucketCount, predicate));\n-        }\n-\n-        private BucketSplitInfo(List<HiveColumnHandle> bucketColumns, int tableBucketCount, int readBucketCount, IntPredicate bucketFilter)\n-        {\n-            this.bucketColumns = ImmutableList.copyOf(requireNonNull(bucketColumns, \"bucketColumns is null\"));\n-            this.tableBucketCount = tableBucketCount;\n-            this.readBucketCount = readBucketCount;\n-            this.bucketFilter = requireNonNull(bucketFilter, \"bucketFilter is null\");\n-        }\n-\n-        public List<HiveColumnHandle> getBucketColumns()\n-        {\n-            return bucketColumns;\n-        }\n-\n-        public int getTableBucketCount()\n-        {\n-            return tableBucketCount;\n-        }\n-\n-        public int getReadBucketCount()\n-        {\n-            return readBucketCount;\n-        }\n-\n-        public boolean isVirtuallyBucketed()\n-        {\n-            return bucketColumns.size() == 1 && bucketColumns.get(0).equals(pathColumnHandle());\n-        }\n-\n-        /**\n-         * Evaluates whether the provided table bucket number passes the bucket predicate.\n-         * A bucket predicate can be present in two cases:\n-         * <ul>\n-         * <li>Filter on \"$bucket\" column. e.g. {@code \"$bucket\" between 0 and 100}\n-         * <li>Single-value equality filter on all bucket columns. e.g. for a table with two bucketing columns,\n-         * {@code bucketCol1 = 'a' AND bucketCol2 = 123}\n-         * </ul>\n-         */\n-        public boolean isTableBucketEnabled(int tableBucketNumber)\n-        {\n-            return bucketFilter.test(tableBucketNumber);\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NjAyOA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525556028", "bodyText": "Reuse the COMMA constant in the util class", "author": "highker", "createdAt": "2020-11-17T22:05:54Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.getFileNames;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());", "originalCommit": "f2bf68f4a0e48a2b4c5a53391f7a2b90a7f3f831", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex b3723abe6a..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -20,6 +20,7 @@ import com.facebook.presto.hive.metastore.Storage;\n import com.facebook.presto.hive.metastore.Table;\n import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n import com.google.common.collect.ImmutableList;\n import com.google.common.util.concurrent.ListenableFuture;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NjM0MQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525556341", "bodyText": "Same comment for the one with roaring bitmap or delta encoding.", "author": "highker", "createdAt": "2020-11-17T22:06:31Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java", "diffHunk": "@@ -148,4 +146,22 @@ public static String joinFileNames(List<String> fileNames)\n \n         return Joiner.on(COMMA).join(fileNames);\n     }\n+\n+    public static List<String> getFileNames(String names)", "originalCommit": "f2bf68f4a0e48a2b4c5a53391f7a2b90a7f3f831", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\nindex d8f8c87261..e591fd7dc2 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveManifestUtils.java\n\n@@ -144,24 +149,69 @@ public class HiveManifestUtils\n             return fileNames.get(fileNames.size() - 1);\n         }\n \n-        return Joiner.on(COMMA).join(fileNames);\n+        return compressFileNamesUsingRoaringBitmap(fileNames);\n     }\n \n-    public static List<String> getFileNames(String names)\n+    static List<String> decompressFileNames(String compressedFileNames)\n     {\n-        ImmutableList.Builder<String> result = ImmutableList.builder();\n-        String[] fileNames = names.split(COMMA);\n+        // Check if the compressed fileNames string is a number\n+        if (compressedFileNames.matches(\"\\\\d+\")) {\n+            long end = Long.parseLong(compressedFileNames);\n \n-        if (fileNames.length == 1) {\n-            int end = Integer.valueOf(fileNames[0]);\n-\n-            if (end > 0) {\n-                for (int i = 0; i <= end; i++) {\n-                    result.add(String.valueOf(i));\n-                }\n-                return result.build();\n+            if (end == 0) {\n+                return ImmutableList.of(\"0\");\n             }\n+\n+            return LongStream.range(0, end + 1).mapToObj(String::valueOf).collect(toImmutableList());\n+        }\n+\n+        try {\n+            RoaringBitmap roaringBitmap = new RoaringBitmap();\n+            ByteBuffer byteBuffer = ByteBuffer.wrap(compressedFileNames.getBytes(StandardCharsets.ISO_8859_1));\n+            roaringBitmap.deserialize(byteBuffer);\n+            return Arrays.stream(roaringBitmap.toArray()).mapToObj(Integer::toString).collect(toImmutableList());\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS, \"Failed de-compressing the file names in manifest\");\n+        }\n+    }\n+\n+    private static String compressFileNamesUsingRoaringBitmap(List<String> fileNames)\n+    {\n+        RoaringBitmap roaringBitmap = new RoaringBitmap();\n+\n+        // Add file names to roaring bitmap\n+        fileNames.forEach(name -> roaringBitmap.add(Integer.parseInt(name)));\n+\n+        // Serialize the compressed data into ByteBuffer\n+        ByteBuffer byteBuffer = ByteBuffer.allocate(roaringBitmap.serializedSizeInBytes());\n+        roaringBitmap.serialize(byteBuffer);\n+        byteBuffer.flip();\n+\n+        return new String(byteBuffer.array(), StandardCharsets.ISO_8859_1);\n+    }\n+\n+    public static String compressFileSizes(List<Long> fileSizes)\n+    {\n+        String fileSizesString = Joiner.on(COMMA).join(fileSizes.stream().map(String::valueOf).collect(toImmutableList()));\n+        try {\n+            return new String(Zstd.compress(fileSizesString.getBytes(StandardCharsets.ISO_8859_1), COMPRESSION_LEVEL), StandardCharsets.ISO_8859_1);\n+        }\n+        catch (RuntimeException e) {\n+            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS, \"Failed compressing the file sizes for manifest\");\n+        }\n+    }\n+\n+    public static List<Long> decompressFileSizes(String compressedFileSizes)\n+    {\n+        try {\n+            byte[] compressedBytes = compressedFileSizes.getBytes(StandardCharsets.ISO_8859_1);\n+            long decompressedSize = Zstd.decompressedSize(compressedBytes);\n+            String decompressedFileSizes = new String(Zstd.decompress(compressedBytes, (int) decompressedSize), StandardCharsets.ISO_8859_1);\n+            return Arrays.stream(decompressedFileSizes.split(COMMA)).map(Long::valueOf).collect(toImmutableList());\n+        }\n+        catch (RuntimeException e) {\n+            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS, \"Failed de-compressing the file sizes in manifest\");\n         }\n-        return ImmutableList.copyOf(fileNames);\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NzIwOA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525557208", "bodyText": "Do we really need this? This could be an empty array right?", "author": "highker", "createdAt": "2020-11-17T22:08:11Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.getFileNames;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+\n+        // Verify that the count of fileNames and fileSizes are same\n+        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+        for (int i = 0; i < fileNames.size(); i++) {\n+            Path filePath = new Path(path, fileNames.get(i));\n+            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n+            try {\n+                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};", "originalCommit": "f2bf68f4a0e48a2b4c5a53391f7a2b90a7f3f831", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTg0ODIxMA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525848210", "bodyText": "If its empty, its failing because of the check in InternalHiveSplitFactory.java\n\n  \n    \n      presto/presto-hive/src/main/java/com/facebook/presto/hive/util/InternalHiveSplitFactory.java\n    \n    \n         Line 181\n      in\n      6970b6d\n    \n    \n    \n    \n\n        \n          \n           checkBlocks(blocks, start, length);", "author": "NikhilCollooru", "createdAt": "2020-11-18T06:45:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1NzIwOA=="}], "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex b3723abe6a..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -20,6 +20,7 @@ import com.facebook.presto.hive.metastore.Storage;\n import com.facebook.presto.hive.metastore.Table;\n import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n import com.google.common.collect.ImmutableList;\n import com.google.common.util.concurrent.ListenableFuture;\n import org.apache.hadoop.conf.Configuration;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1OTc5Mg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525559792", "bodyText": "Move MALFORMED_HIVE_FILE_STATISTICS to its own line", "author": "highker", "createdAt": "2020-11-17T22:13:20Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -80,10 +96,17 @@ public ManifestPartitionLoader(\n         Map<String, String> parameters = partition.getPartition().get().getParameters();\n         List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n         List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n \n         // Verify that the count of fileNames and fileSizes are same\n         verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n \n+        // Verify that the file names, sizes in manifest are the same as listed by directory lister\n+        if (isManifestVerificationEnabled(session) && isManifestCorrupted(fileNames, fileSizes, path)) {\n+            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS,", "originalCommit": "2ad53812561e93767216d8dd910c145fcba83bbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex 0a4bfe25b5..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -94,17 +94,15 @@ public class ManifestPartitionLoader\n     {\n         Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n         Map<String, String> parameters = partition.getPartition().get().getParameters();\n-        List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n-        List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n-        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n+        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n \n         // Verify that the count of fileNames and fileSizes are same\n         verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n \n-        // Verify that the file names, sizes in manifest are the same as listed by directory lister\n-        if (isManifestVerificationEnabled(session) && isManifestCorrupted(fileNames, fileSizes, path)) {\n-            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS,\n-                    format(\"FileNames, sizes stored in the partition parameters are not equal to those returned by listFiles() call to storage. Partition = %s, TableName = %s\", partition.getHivePartition().getPartitionId(), table.getTableName()));\n+        if (isManifestVerificationEnabled(session)) {\n+            // Verify that the file names and sizes in manifest are the same as listed by directory lister\n+            validateManifest(partition, path, fileNames, fileSizes);\n         }\n \n         ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1OTg5Nw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525559897", "bodyText": "break lines for params inside format", "author": "highker", "createdAt": "2020-11-17T22:13:30Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -80,10 +96,17 @@ public ManifestPartitionLoader(\n         Map<String, String> parameters = partition.getPartition().get().getParameters();\n         List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n         List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n+        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n \n         // Verify that the count of fileNames and fileSizes are same\n         verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n \n+        // Verify that the file names, sizes in manifest are the same as listed by directory lister\n+        if (isManifestVerificationEnabled(session) && isManifestCorrupted(fileNames, fileSizes, path)) {\n+            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS,\n+                    format(\"FileNames, sizes stored in the partition parameters are not equal to those returned by listFiles() call to storage. Partition = %s, TableName = %s\", partition.getHivePartition().getPartitionId(), table.getTableName()));", "originalCommit": "2ad53812561e93767216d8dd910c145fcba83bbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex 0a4bfe25b5..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -94,17 +94,15 @@ public class ManifestPartitionLoader\n     {\n         Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n         Map<String, String> parameters = partition.getPartition().get().getParameters();\n-        List<String> fileNames = getFileNames(parameters.get(FILE_NAMES));\n-        List<Long> fileSizes = Arrays.stream(parameters.get(FILE_SIZES).split(\",\")).map(Long::valueOf).collect(toImmutableList());\n-        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n+        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n \n         // Verify that the count of fileNames and fileSizes are same\n         verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n \n-        // Verify that the file names, sizes in manifest are the same as listed by directory lister\n-        if (isManifestVerificationEnabled(session) && isManifestCorrupted(fileNames, fileSizes, path)) {\n-            throw new PrestoException(MALFORMED_HIVE_FILE_STATISTICS,\n-                    format(\"FileNames, sizes stored in the partition parameters are not equal to those returned by listFiles() call to storage. Partition = %s, TableName = %s\", partition.getHivePartition().getPartitionId(), table.getTableName()));\n+        if (isManifestVerificationEnabled(session)) {\n+            // Verify that the file names and sizes in manifest are the same as listed by directory lister\n+            validateManifest(partition, path, fileNames, fileSizes);\n         }\n \n         ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MDI5Mg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525560292", "bodyText": "Does this change belong to this commit (i.e., the last commit)?", "author": "highker", "createdAt": "2020-11-17T22:14:20Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -97,8 +120,6 @@ public ManifestPartitionLoader(\n             }\n         }\n \n-        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n-", "originalCommit": "2ad53812561e93767216d8dd910c145fcba83bbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex 0a4bfe25b5..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -120,6 +118,8 @@ public class ManifestPartitionLoader\n             }\n         }\n \n+        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n+\n         return hiveSplitSource.addToQueue(fileListBuilder.build().stream()\n                 .map(status -> splitFactory.createInternalHiveSplit(status, true))\n                 .filter(Optional::isPresent)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MDUyNg==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525560526", "bodyText": "s/fs/fileSystem", "author": "highker", "createdAt": "2020-11-17T22:14:46Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -146,4 +167,34 @@ public InternalHiveSplitFactory createInternalHiveSplitFactory(\n                 schedulerUsesHostAddresses,\n                 partition.getEncryptionInformation());\n     }\n+\n+    private boolean isManifestCorrupted(List<String> manifestFileNames, List<Long> manifestFileSizes, Path path)\n+            throws IOException\n+    {\n+        ExtendedFileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);", "originalCommit": "2ad53812561e93767216d8dd910c145fcba83bbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex 0a4bfe25b5..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -168,33 +168,49 @@ public class ManifestPartitionLoader\n                 partition.getEncryptionInformation());\n     }\n \n-    private boolean isManifestCorrupted(List<String> manifestFileNames, List<Long> manifestFileSizes, Path path)\n+    private void validateManifest(HivePartitionMetadata partition, Path path, List<String> manifestFileNames, List<Long> manifestFileSizes)\n             throws IOException\n     {\n-        ExtendedFileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);\n+        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n \n-        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fs, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n+        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fileSystem, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n         int fileCount = 0;\n         while (fileInfoIterator.hasNext()) {\n             HiveFileInfo fileInfo = fileInfoIterator.next();\n             String fileName = fileInfo.getPath().getName();\n             if (!manifestFileNames.contains(fileName)) {\n-                return true;\n+                throw new PrestoException(\n+                        MALFORMED_HIVE_FILE_STATISTICS,\n+                        format(\"Filename = %s not stored in manifest. Partition = %s, TableName = %s\",\n+                                fileName,\n+                                partition.getHivePartition().getPartitionId(),\n+                                table.getTableName()));\n             }\n \n             int index = manifestFileNames.indexOf(fileName);\n             if (!manifestFileSizes.get(index).equals(fileInfo.getLength())) {\n-                return true;\n+                throw new PrestoException(\n+                        MALFORMED_HIVE_FILE_STATISTICS,\n+                        format(\"FilesizeFromManifest = %s is not equal to FilesizeFromStorage = %s. File = %s, Partition = %s, TableName = %s\",\n+                                manifestFileSizes.get(index),\n+                                fileInfo.getLength(),\n+                                fileName,\n+                                partition.getHivePartition().getPartitionId(),\n+                                table.getTableName()));\n             }\n \n             fileCount++;\n         }\n \n         if (fileCount != manifestFileNames.size()) {\n-            return true;\n+            throw new PrestoException(\n+                    MALFORMED_HIVE_FILE_STATISTICS,\n+                    format(\"Number of files in Manifest = %s is not equal to Number of files in storage = %s. Partition = %s, TableName = %s\",\n+                            manifestFileNames.size(),\n+                            fileCount,\n+                            partition.getHivePartition().getPartitionId(),\n+                            table.getTableName()));\n         }\n-\n-        return false;\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MTIyNQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525561225", "bodyText": "Maybe just make this a void function and call it validateManifest", "author": "highker", "createdAt": "2020-11-17T22:16:08Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -146,4 +167,34 @@ public InternalHiveSplitFactory createInternalHiveSplitFactory(\n                 schedulerUsesHostAddresses,\n                 partition.getEncryptionInformation());\n     }\n+\n+    private boolean isManifestCorrupted(List<String> manifestFileNames, List<Long> manifestFileSizes, Path path)", "originalCommit": "2ad53812561e93767216d8dd910c145fcba83bbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex 0a4bfe25b5..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -168,33 +168,49 @@ public class ManifestPartitionLoader\n                 partition.getEncryptionInformation());\n     }\n \n-    private boolean isManifestCorrupted(List<String> manifestFileNames, List<Long> manifestFileSizes, Path path)\n+    private void validateManifest(HivePartitionMetadata partition, Path path, List<String> manifestFileNames, List<Long> manifestFileSizes)\n             throws IOException\n     {\n-        ExtendedFileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);\n+        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n \n-        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fs, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n+        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fileSystem, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n         int fileCount = 0;\n         while (fileInfoIterator.hasNext()) {\n             HiveFileInfo fileInfo = fileInfoIterator.next();\n             String fileName = fileInfo.getPath().getName();\n             if (!manifestFileNames.contains(fileName)) {\n-                return true;\n+                throw new PrestoException(\n+                        MALFORMED_HIVE_FILE_STATISTICS,\n+                        format(\"Filename = %s not stored in manifest. Partition = %s, TableName = %s\",\n+                                fileName,\n+                                partition.getHivePartition().getPartitionId(),\n+                                table.getTableName()));\n             }\n \n             int index = manifestFileNames.indexOf(fileName);\n             if (!manifestFileSizes.get(index).equals(fileInfo.getLength())) {\n-                return true;\n+                throw new PrestoException(\n+                        MALFORMED_HIVE_FILE_STATISTICS,\n+                        format(\"FilesizeFromManifest = %s is not equal to FilesizeFromStorage = %s. File = %s, Partition = %s, TableName = %s\",\n+                                manifestFileSizes.get(index),\n+                                fileInfo.getLength(),\n+                                fileName,\n+                                partition.getHivePartition().getPartitionId(),\n+                                table.getTableName()));\n             }\n \n             fileCount++;\n         }\n \n         if (fileCount != manifestFileNames.size()) {\n-            return true;\n+            throw new PrestoException(\n+                    MALFORMED_HIVE_FILE_STATISTICS,\n+                    format(\"Number of files in Manifest = %s is not equal to Number of files in storage = %s. Partition = %s, TableName = %s\",\n+                            manifestFileNames.size(),\n+                            fileCount,\n+                            partition.getHivePartition().getPartitionId(),\n+                            table.getTableName()));\n         }\n-\n-        return false;\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU2MTM0NA==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r525561344", "bodyText": "directly throw; so we can have precise error message.", "author": "highker", "createdAt": "2020-11-17T22:16:24Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -146,4 +167,34 @@ public InternalHiveSplitFactory createInternalHiveSplitFactory(\n                 schedulerUsesHostAddresses,\n                 partition.getEncryptionInformation());\n     }\n+\n+    private boolean isManifestCorrupted(List<String> manifestFileNames, List<Long> manifestFileSizes, Path path)\n+            throws IOException\n+    {\n+        ExtendedFileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);\n+        HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n+\n+        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fs, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n+        int fileCount = 0;\n+        while (fileInfoIterator.hasNext()) {\n+            HiveFileInfo fileInfo = fileInfoIterator.next();\n+            String fileName = fileInfo.getPath().getName();\n+            if (!manifestFileNames.contains(fileName)) {\n+                return true;", "originalCommit": "2ad53812561e93767216d8dd910c145fcba83bbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2b83a785eca28d5eb38d6848778ccc46014f2483", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\nindex 0a4bfe25b5..8378747acc 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n\n@@ -168,33 +168,49 @@ public class ManifestPartitionLoader\n                 partition.getEncryptionInformation());\n     }\n \n-    private boolean isManifestCorrupted(List<String> manifestFileNames, List<Long> manifestFileSizes, Path path)\n+    private void validateManifest(HivePartitionMetadata partition, Path path, List<String> manifestFileNames, List<Long> manifestFileSizes)\n             throws IOException\n     {\n-        ExtendedFileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);\n+        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n         HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n \n-        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fs, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n+        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fileSystem, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n         int fileCount = 0;\n         while (fileInfoIterator.hasNext()) {\n             HiveFileInfo fileInfo = fileInfoIterator.next();\n             String fileName = fileInfo.getPath().getName();\n             if (!manifestFileNames.contains(fileName)) {\n-                return true;\n+                throw new PrestoException(\n+                        MALFORMED_HIVE_FILE_STATISTICS,\n+                        format(\"Filename = %s not stored in manifest. Partition = %s, TableName = %s\",\n+                                fileName,\n+                                partition.getHivePartition().getPartitionId(),\n+                                table.getTableName()));\n             }\n \n             int index = manifestFileNames.indexOf(fileName);\n             if (!manifestFileSizes.get(index).equals(fileInfo.getLength())) {\n-                return true;\n+                throw new PrestoException(\n+                        MALFORMED_HIVE_FILE_STATISTICS,\n+                        format(\"FilesizeFromManifest = %s is not equal to FilesizeFromStorage = %s. File = %s, Partition = %s, TableName = %s\",\n+                                manifestFileSizes.get(index),\n+                                fileInfo.getLength(),\n+                                fileName,\n+                                partition.getHivePartition().getPartitionId(),\n+                                table.getTableName()));\n             }\n \n             fileCount++;\n         }\n \n         if (fileCount != manifestFileNames.size()) {\n-            return true;\n+            throw new PrestoException(\n+                    MALFORMED_HIVE_FILE_STATISTICS,\n+                    format(\"Number of files in Manifest = %s is not equal to Number of files in storage = %s. Partition = %s, TableName = %s\",\n+                            manifestFileNames.size(),\n+                            fileCount,\n+                            partition.getHivePartition().getPartitionId(),\n+                            table.getTableName()));\n         }\n-\n-        return false;\n     }\n }\n"}}, {"oid": "2b83a785eca28d5eb38d6848778ccc46014f2483", "url": "https://github.com/prestodb/presto/commit/2b83a785eca28d5eb38d6848778ccc46014f2483", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-19T17:39:35Z", "type": "forcePushed"}, {"oid": "909a2b52777ee012fa42ab84b7fce76213bd3763", "url": "https://github.com/prestodb/presto/commit/909a2b52777ee012fa42ab84b7fce76213bd3763", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-19T18:02:58Z", "type": "forcePushed"}, {"oid": "747a81a7e71a66572e7316f79758e8ef54707554", "url": "https://github.com/prestodb/presto/commit/747a81a7e71a66572e7316f79758e8ef54707554", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-19T19:35:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM5ODU3Ng==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r527398576", "bodyText": "static import isPreferManifestsToListFiles", "author": "highker", "createdAt": "2020-11-20T05:00:45Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.StoragePartitionLoader.BucketSplitInfo;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import java.io.IOException;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveManifestUtils.MANIFEST_VERSION;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DelegatingPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final ConnectorSession session;\n+    private final PartitionLoader storagePartitionLoader;\n+    private final PartitionLoader manifestPartitionLoader;\n+\n+    public DelegatingPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            Optional<BucketSplitInfo> tableBucketInfo,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            NamenodeStats namenodeStats,\n+            DirectoryLister directoryLister,\n+            Deque<Iterator<InternalHiveSplit>> fileIterators,\n+            boolean recursiveDirWalkerEnabled,\n+            boolean schedulerUsesHostAddresses,\n+            boolean partialAggregationsPushedDown)\n+    {\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.storagePartitionLoader = new StoragePartitionLoader(table, pathDomain, tableBucketInfo, session, hdfsEnvironment, namenodeStats, directoryLister, fileIterators, recursiveDirWalkerEnabled, schedulerUsesHostAddresses, partialAggregationsPushedDown);\n+        this.manifestPartitionLoader = new ManifestPartitionLoader(table, pathDomain, session, hdfsEnvironment, schedulerUsesHostAddresses);\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        if (isListFilesLoadedPartition(session, partition.getPartition())) {\n+            // Partition has list of file names and sizes. We can avoid the listFiles() call to underlying storage.\n+            return manifestPartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n+        }\n+\n+        return storagePartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n+    }\n+\n+    private static boolean isListFilesLoadedPartition(ConnectorSession session, Optional<Partition> partition)\n+    {\n+        if (partition.isPresent() && HiveSessionProperties.isPreferManifestsToListFiles(session)) {", "originalCommit": "a45b81593c8095c07020a6e0c034ae796c1fb667", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\ndeleted file mode 100644\nindex 68378f3c37..0000000000\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/DelegatingPartitionLoader.java\n+++ /dev/null\n\n@@ -1,78 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.facebook.presto.hive;\n-\n-import com.facebook.presto.common.predicate.Domain;\n-import com.facebook.presto.hive.StoragePartitionLoader.BucketSplitInfo;\n-import com.facebook.presto.hive.metastore.Partition;\n-import com.facebook.presto.hive.metastore.Table;\n-import com.facebook.presto.spi.ConnectorSession;\n-import com.google.common.util.concurrent.ListenableFuture;\n-\n-import java.io.IOException;\n-import java.util.Deque;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.Optional;\n-\n-import static com.facebook.presto.hive.HiveManifestUtils.MANIFEST_VERSION;\n-import static java.util.Objects.requireNonNull;\n-\n-public class DelegatingPartitionLoader\n-        extends PartitionLoader\n-{\n-    private final ConnectorSession session;\n-    private final PartitionLoader storagePartitionLoader;\n-    private final PartitionLoader manifestPartitionLoader;\n-\n-    public DelegatingPartitionLoader(\n-            Table table,\n-            Optional<Domain> pathDomain,\n-            Optional<BucketSplitInfo> tableBucketInfo,\n-            ConnectorSession session,\n-            HdfsEnvironment hdfsEnvironment,\n-            NamenodeStats namenodeStats,\n-            DirectoryLister directoryLister,\n-            Deque<Iterator<InternalHiveSplit>> fileIterators,\n-            boolean recursiveDirWalkerEnabled,\n-            boolean schedulerUsesHostAddresses,\n-            boolean partialAggregationsPushedDown)\n-    {\n-        this.session = requireNonNull(session, \"session is null\");\n-        this.storagePartitionLoader = new StoragePartitionLoader(table, pathDomain, tableBucketInfo, session, hdfsEnvironment, namenodeStats, directoryLister, fileIterators, recursiveDirWalkerEnabled, schedulerUsesHostAddresses, partialAggregationsPushedDown);\n-        this.manifestPartitionLoader = new ManifestPartitionLoader(table, pathDomain, session, hdfsEnvironment, schedulerUsesHostAddresses);\n-    }\n-\n-    @Override\n-    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n-            throws IOException\n-    {\n-        if (isListFilesLoadedPartition(session, partition.getPartition())) {\n-            // Partition has list of file names and sizes. We can avoid the listFiles() call to underlying storage.\n-            return manifestPartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n-        }\n-\n-        return storagePartitionLoader.loadPartition(partition, hiveSplitSource, stopped);\n-    }\n-\n-    private static boolean isListFilesLoadedPartition(ConnectorSession session, Optional<Partition> partition)\n-    {\n-        if (partition.isPresent() && HiveSessionProperties.isPreferManifestsToListFiles(session)) {\n-            Map<String, String> parameters = partition.get().getParameters();\n-            return parameters.containsKey(MANIFEST_VERSION);\n-        }\n-\n-        return false;\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzQwMTc0MQ==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r527401741", "bodyText": "Make new String[] {\"localhost:50010\"} and new String[] {\"localhost\"} constants. Add comment to these constants to refer to FileSystem.getFileBlockLocations method from Hadoop", "author": "highker", "createdAt": "2020-11-20T05:12:44Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.decompressFileNames;\n+import static com.facebook.presto.hive.HiveManifestUtils.decompressFileSizes;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n+\n+        // Verify that the count of fileNames and fileSizes are same\n+        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+        for (int i = 0; i < fileNames.size(); i++) {\n+            Path filePath = new Path(path, fileNames.get(i));\n+            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n+            try {\n+                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};", "originalCommit": "a45b81593c8095c07020a6e0c034ae796c1fb667", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\ndeleted file mode 100644\nindex 68afa4aaff..0000000000\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ /dev/null\n\n@@ -1,151 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.facebook.presto.hive;\n-\n-import com.facebook.presto.common.predicate.Domain;\n-import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n-import com.facebook.presto.hive.metastore.Partition;\n-import com.facebook.presto.hive.metastore.Storage;\n-import com.facebook.presto.hive.metastore.Table;\n-import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n-import com.facebook.presto.spi.ConnectorSession;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.util.concurrent.ListenableFuture;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.fs.BlockLocation;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.LocatedFileStatus;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.mapred.InputFormat;\n-\n-import java.io.IOException;\n-import java.io.UncheckedIOException;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n-import static com.facebook.presto.hive.HiveManifestUtils.decompressFileNames;\n-import static com.facebook.presto.hive.HiveManifestUtils.decompressFileSizes;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n-import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n-import static com.google.common.base.Verify.verify;\n-import static com.google.common.collect.ImmutableList.toImmutableList;\n-import static java.util.Objects.requireNonNull;\n-\n-public class ManifestPartitionLoader\n-        extends PartitionLoader\n-{\n-    private final Table table;\n-    private final Optional<Domain> pathDomain;\n-    private final ConnectorSession session;\n-    private final HdfsEnvironment hdfsEnvironment;\n-    private final HdfsContext hdfsContext;\n-    private final boolean schedulerUsesHostAddresses;\n-\n-    public ManifestPartitionLoader(\n-            Table table,\n-            Optional<Domain> pathDomain,\n-            ConnectorSession session,\n-            HdfsEnvironment hdfsEnvironment,\n-            boolean schedulerUsesHostAddresses)\n-    {\n-        this.table = requireNonNull(table, \"table is null\");\n-        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n-        this.session = requireNonNull(session, \"session is null\");\n-        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n-        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n-        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n-    }\n-\n-    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n-            throws IOException\n-    {\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Map<String, String> parameters = partition.getPartition().get().getParameters();\n-        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n-        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n-\n-        // Verify that the count of fileNames and fileSizes are same\n-        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n-\n-        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n-        for (int i = 0; i < fileNames.size(); i++) {\n-            Path filePath = new Path(path, fileNames.get(i));\n-            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n-            try {\n-                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};\n-\n-                // It is safe to set extraFileContext as empty because downstream code always checks if its present before proceeding.\n-                fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n-            }\n-            catch (IOException e) {\n-                throw new UncheckedIOException(e);\n-            }\n-        }\n-\n-        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n-\n-        return hiveSplitSource.addToQueue(fileListBuilder.build().stream()\n-                .map(status -> splitFactory.createInternalHiveSplit(status, true))\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .collect(toImmutableList()));\n-    }\n-\n-    private InternalHiveSplitFactory createInternalHiveSplitFactory(\n-            Table table,\n-            HivePartitionMetadata partition,\n-            ConnectorSession session,\n-            Optional<Domain> pathDomain,\n-            HdfsEnvironment hdfsEnvironment,\n-            HdfsContext hdfsContext,\n-            boolean schedulerUsesHostAddresses)\n-            throws IOException\n-    {\n-        String partitionName = partition.getHivePartition().getPartitionId();\n-        Storage storage = partition.getPartition().map(Partition::getStorage).orElse(table.getStorage());\n-        String inputFormatName = storage.getStorageFormat().getInputFormat();\n-        int partitionDataColumnCount = partition.getPartition()\n-                .map(p -> p.getColumns().size())\n-                .orElse(table.getDataColumns().size());\n-        List<HivePartitionKey> partitionKeys = getPartitionKeys(table, partition.getPartition());\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Configuration configuration = hdfsEnvironment.getConfiguration(hdfsContext, path);\n-        InputFormat<?, ?> inputFormat = getInputFormat(configuration, inputFormatName, false);\n-        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n-\n-        return new InternalHiveSplitFactory(\n-                fileSystem,\n-                inputFormat,\n-                pathDomain,\n-                getNodeSelectionStrategy(session),\n-                getMaxInitialSplitSize(session),\n-                false,\n-                new HiveSplitPartitionInfo(\n-                        storage,\n-                        path.toUri(),\n-                        partitionKeys,\n-                        partitionName,\n-                        partitionDataColumnCount,\n-                        partition.getPartitionSchemaDifference(),\n-                        Optional.empty()),\n-                schedulerUsesHostAddresses,\n-                partition.getEncryptionInformation());\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzQwMjA3Mw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r527402073", "bodyText": "s/path1/ignore", "author": "highker", "createdAt": "2020-11-20T05:14:16Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveErrorCode.MALFORMED_HIVE_FILE_STATISTICS;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.decompressFileNames;\n+import static com.facebook.presto.hive.HiveManifestUtils.decompressFileSizes;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveSessionProperties.isManifestVerificationEnabled;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final NamenodeStats namenodeStats;\n+    private final DirectoryLister directoryLister;\n+    private final boolean recursiveDirWalkerEnabled;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            NamenodeStats namenodeStats,\n+            DirectoryLister directoryLister,\n+            boolean recursiveDirWalkerEnabled,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.namenodeStats = requireNonNull(namenodeStats, \"namenodeStats is null\");\n+        this.directoryLister = requireNonNull(directoryLister, \"directoryLister is null\");\n+        this.recursiveDirWalkerEnabled = recursiveDirWalkerEnabled;\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n+        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n+\n+        // Verify that the count of fileNames and fileSizes are same\n+        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n+\n+        if (isManifestVerificationEnabled(session)) {\n+            // Verify that the file names and sizes in manifest are the same as listed by directory lister\n+            validateManifest(partition, path, fileNames, fileSizes);\n+        }\n+\n+        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n+        for (int i = 0; i < fileNames.size(); i++) {\n+            Path filePath = new Path(path, fileNames.get(i));\n+            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n+            try {\n+                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};\n+\n+                // It is safe to set extraFileContext as empty because downstream code always checks if its present before proceeding.\n+                fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n+            }\n+            catch (IOException e) {\n+                throw new UncheckedIOException(e);\n+            }\n+        }\n+\n+        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n+\n+        return hiveSplitSource.addToQueue(fileListBuilder.build().stream()\n+                .map(status -> splitFactory.createInternalHiveSplit(status, true))\n+                .filter(Optional::isPresent)\n+                .map(Optional::get)\n+                .collect(toImmutableList()));\n+    }\n+\n+    private InternalHiveSplitFactory createInternalHiveSplitFactory(\n+            Table table,\n+            HivePartitionMetadata partition,\n+            ConnectorSession session,\n+            Optional<Domain> pathDomain,\n+            HdfsEnvironment hdfsEnvironment,\n+            HdfsContext hdfsContext,\n+            boolean schedulerUsesHostAddresses)\n+            throws IOException\n+    {\n+        String partitionName = partition.getHivePartition().getPartitionId();\n+        Storage storage = partition.getPartition().map(Partition::getStorage).orElse(table.getStorage());\n+        String inputFormatName = storage.getStorageFormat().getInputFormat();\n+        int partitionDataColumnCount = partition.getPartition()\n+                .map(p -> p.getColumns().size())\n+                .orElse(table.getDataColumns().size());\n+        List<HivePartitionKey> partitionKeys = getPartitionKeys(table, partition.getPartition());\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Configuration configuration = hdfsEnvironment.getConfiguration(hdfsContext, path);\n+        InputFormat<?, ?> inputFormat = getInputFormat(configuration, inputFormatName, false);\n+        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n+\n+        return new InternalHiveSplitFactory(\n+                fileSystem,\n+                inputFormat,\n+                pathDomain,\n+                getNodeSelectionStrategy(session),\n+                getMaxInitialSplitSize(session),\n+                false,\n+                new HiveSplitPartitionInfo(\n+                        storage,\n+                        path.toUri(),\n+                        partitionKeys,\n+                        partitionName,\n+                        partitionDataColumnCount,\n+                        partition.getPartitionSchemaDifference(),\n+                        Optional.empty()),\n+                schedulerUsesHostAddresses,\n+                partition.getEncryptionInformation());\n+    }\n+\n+    private void validateManifest(HivePartitionMetadata partition, Path path, List<String> manifestFileNames, List<Long> manifestFileSizes)\n+            throws IOException\n+    {\n+        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n+        HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n+\n+        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fileSystem, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);", "originalCommit": "747a81a7e71a66572e7316f79758e8ef54707554", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\ndeleted file mode 100644\nindex 6ee2e7f137..0000000000\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ /dev/null\n\n@@ -1,218 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.facebook.presto.hive;\n-\n-import com.facebook.presto.common.predicate.Domain;\n-import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n-import com.facebook.presto.hive.metastore.Partition;\n-import com.facebook.presto.hive.metastore.Storage;\n-import com.facebook.presto.hive.metastore.Table;\n-import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n-import com.facebook.presto.spi.ConnectorSession;\n-import com.facebook.presto.spi.PrestoException;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.util.concurrent.ListenableFuture;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.fs.BlockLocation;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.LocatedFileStatus;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.mapred.InputFormat;\n-\n-import java.io.IOException;\n-import java.io.UncheckedIOException;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-\n-import static com.facebook.presto.hive.HiveErrorCode.MALFORMED_HIVE_FILE_STATISTICS;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n-import static com.facebook.presto.hive.HiveManifestUtils.decompressFileNames;\n-import static com.facebook.presto.hive.HiveManifestUtils.decompressFileSizes;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n-import static com.facebook.presto.hive.HiveSessionProperties.isManifestVerificationEnabled;\n-import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n-import static com.google.common.base.Verify.verify;\n-import static com.google.common.collect.ImmutableList.toImmutableList;\n-import static java.lang.String.format;\n-import static java.util.Objects.requireNonNull;\n-\n-public class ManifestPartitionLoader\n-        extends PartitionLoader\n-{\n-    private final Table table;\n-    private final Optional<Domain> pathDomain;\n-    private final ConnectorSession session;\n-    private final HdfsEnvironment hdfsEnvironment;\n-    private final HdfsContext hdfsContext;\n-    private final NamenodeStats namenodeStats;\n-    private final DirectoryLister directoryLister;\n-    private final boolean recursiveDirWalkerEnabled;\n-    private final boolean schedulerUsesHostAddresses;\n-\n-    public ManifestPartitionLoader(\n-            Table table,\n-            Optional<Domain> pathDomain,\n-            ConnectorSession session,\n-            HdfsEnvironment hdfsEnvironment,\n-            NamenodeStats namenodeStats,\n-            DirectoryLister directoryLister,\n-            boolean recursiveDirWalkerEnabled,\n-            boolean schedulerUsesHostAddresses)\n-    {\n-        this.table = requireNonNull(table, \"table is null\");\n-        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n-        this.session = requireNonNull(session, \"session is null\");\n-        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n-        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n-        this.namenodeStats = requireNonNull(namenodeStats, \"namenodeStats is null\");\n-        this.directoryLister = requireNonNull(directoryLister, \"directoryLister is null\");\n-        this.recursiveDirWalkerEnabled = recursiveDirWalkerEnabled;\n-        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n-    }\n-\n-    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n-            throws IOException\n-    {\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Map<String, String> parameters = partition.getPartition().get().getParameters();\n-        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n-        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n-\n-        // Verify that the count of fileNames and fileSizes are same\n-        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n-\n-        if (isManifestVerificationEnabled(session)) {\n-            // Verify that the file names and sizes in manifest are the same as listed by directory lister\n-            validateManifest(partition, path, fileNames, fileSizes);\n-        }\n-\n-        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n-        for (int i = 0; i < fileNames.size(); i++) {\n-            Path filePath = new Path(path, fileNames.get(i));\n-            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n-            try {\n-                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};\n-\n-                // It is safe to set extraFileContext as empty because downstream code always checks if its present before proceeding.\n-                fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n-            }\n-            catch (IOException e) {\n-                throw new UncheckedIOException(e);\n-            }\n-        }\n-\n-        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n-\n-        return hiveSplitSource.addToQueue(fileListBuilder.build().stream()\n-                .map(status -> splitFactory.createInternalHiveSplit(status, true))\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .collect(toImmutableList()));\n-    }\n-\n-    private InternalHiveSplitFactory createInternalHiveSplitFactory(\n-            Table table,\n-            HivePartitionMetadata partition,\n-            ConnectorSession session,\n-            Optional<Domain> pathDomain,\n-            HdfsEnvironment hdfsEnvironment,\n-            HdfsContext hdfsContext,\n-            boolean schedulerUsesHostAddresses)\n-            throws IOException\n-    {\n-        String partitionName = partition.getHivePartition().getPartitionId();\n-        Storage storage = partition.getPartition().map(Partition::getStorage).orElse(table.getStorage());\n-        String inputFormatName = storage.getStorageFormat().getInputFormat();\n-        int partitionDataColumnCount = partition.getPartition()\n-                .map(p -> p.getColumns().size())\n-                .orElse(table.getDataColumns().size());\n-        List<HivePartitionKey> partitionKeys = getPartitionKeys(table, partition.getPartition());\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Configuration configuration = hdfsEnvironment.getConfiguration(hdfsContext, path);\n-        InputFormat<?, ?> inputFormat = getInputFormat(configuration, inputFormatName, false);\n-        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n-\n-        return new InternalHiveSplitFactory(\n-                fileSystem,\n-                inputFormat,\n-                pathDomain,\n-                getNodeSelectionStrategy(session),\n-                getMaxInitialSplitSize(session),\n-                false,\n-                new HiveSplitPartitionInfo(\n-                        storage,\n-                        path.toUri(),\n-                        partitionKeys,\n-                        partitionName,\n-                        partitionDataColumnCount,\n-                        partition.getPartitionSchemaDifference(),\n-                        Optional.empty()),\n-                schedulerUsesHostAddresses,\n-                partition.getEncryptionInformation());\n-    }\n-\n-    private void validateManifest(HivePartitionMetadata partition, Path path, List<String> manifestFileNames, List<Long> manifestFileSizes)\n-            throws IOException\n-    {\n-        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n-        HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n-\n-        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fileSystem, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n-        int fileCount = 0;\n-        while (fileInfoIterator.hasNext()) {\n-            HiveFileInfo fileInfo = fileInfoIterator.next();\n-            String fileName = fileInfo.getPath().getName();\n-            if (!manifestFileNames.contains(fileName)) {\n-                throw new PrestoException(\n-                        MALFORMED_HIVE_FILE_STATISTICS,\n-                        format(\"Filename = %s not stored in manifest. Partition = %s, TableName = %s\",\n-                                fileName,\n-                                partition.getHivePartition().getPartitionId(),\n-                                table.getTableName()));\n-            }\n-\n-            int index = manifestFileNames.indexOf(fileName);\n-            if (!manifestFileSizes.get(index).equals(fileInfo.getLength())) {\n-                throw new PrestoException(\n-                        MALFORMED_HIVE_FILE_STATISTICS,\n-                        format(\"FilesizeFromManifest = %s is not equal to FilesizeFromStorage = %s. File = %s, Partition = %s, TableName = %s\",\n-                                manifestFileSizes.get(index),\n-                                fileInfo.getLength(),\n-                                fileName,\n-                                partition.getHivePartition().getPartitionId(),\n-                                table.getTableName()));\n-            }\n-\n-            fileCount++;\n-        }\n-\n-        if (fileCount != manifestFileNames.size()) {\n-            throw new PrestoException(\n-                    MALFORMED_HIVE_FILE_STATISTICS,\n-                    format(\"Number of files in Manifest = %s is not equal to Number of files in storage = %s. Partition = %s, TableName = %s\",\n-                            manifestFileNames.size(),\n-                            fileCount,\n-                            partition.getHivePartition().getPartitionId(),\n-                            table.getTableName()));\n-        }\n-    }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzQwMjUzMw==", "url": "https://github.com/prestodb/presto/pull/15325#discussion_r527402533", "bodyText": "Also get manifest version and validate it's \"V1\"\nAdd a TODO to make versioning available in the future", "author": "highker", "createdAt": "2020-11-20T05:15:38Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive;\n+\n+import com.facebook.presto.common.predicate.Domain;\n+import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n+import com.facebook.presto.hive.metastore.Partition;\n+import com.facebook.presto.hive.metastore.Storage;\n+import com.facebook.presto.hive.metastore.Table;\n+import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.PrestoException;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.BlockLocation;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.LocatedFileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.mapred.InputFormat;\n+\n+import java.io.IOException;\n+import java.io.UncheckedIOException;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.hive.HiveErrorCode.MALFORMED_HIVE_FILE_STATISTICS;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n+import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n+import static com.facebook.presto.hive.HiveManifestUtils.decompressFileNames;\n+import static com.facebook.presto.hive.HiveManifestUtils.decompressFileSizes;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n+import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n+import static com.facebook.presto.hive.HiveSessionProperties.isManifestVerificationEnabled;\n+import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n+import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n+import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n+import static com.google.common.base.Verify.verify;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ManifestPartitionLoader\n+        extends PartitionLoader\n+{\n+    private final Table table;\n+    private final Optional<Domain> pathDomain;\n+    private final ConnectorSession session;\n+    private final HdfsEnvironment hdfsEnvironment;\n+    private final HdfsContext hdfsContext;\n+    private final NamenodeStats namenodeStats;\n+    private final DirectoryLister directoryLister;\n+    private final boolean recursiveDirWalkerEnabled;\n+    private final boolean schedulerUsesHostAddresses;\n+\n+    public ManifestPartitionLoader(\n+            Table table,\n+            Optional<Domain> pathDomain,\n+            ConnectorSession session,\n+            HdfsEnvironment hdfsEnvironment,\n+            NamenodeStats namenodeStats,\n+            DirectoryLister directoryLister,\n+            boolean recursiveDirWalkerEnabled,\n+            boolean schedulerUsesHostAddresses)\n+    {\n+        this.table = requireNonNull(table, \"table is null\");\n+        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n+        this.session = requireNonNull(session, \"session is null\");\n+        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n+        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n+        this.namenodeStats = requireNonNull(namenodeStats, \"namenodeStats is null\");\n+        this.directoryLister = requireNonNull(directoryLister, \"directoryLister is null\");\n+        this.recursiveDirWalkerEnabled = recursiveDirWalkerEnabled;\n+        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n+    }\n+\n+    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n+            throws IOException\n+    {\n+        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n+        Map<String, String> parameters = partition.getPartition().get().getParameters();\n+        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));", "originalCommit": "747a81a7e71a66572e7316f79758e8ef54707554", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java b/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\ndeleted file mode 100644\nindex 6ee2e7f137..0000000000\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/ManifestPartitionLoader.java\n+++ /dev/null\n\n@@ -1,218 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package com.facebook.presto.hive;\n-\n-import com.facebook.presto.common.predicate.Domain;\n-import com.facebook.presto.hive.filesystem.ExtendedFileSystem;\n-import com.facebook.presto.hive.metastore.Partition;\n-import com.facebook.presto.hive.metastore.Storage;\n-import com.facebook.presto.hive.metastore.Table;\n-import com.facebook.presto.hive.util.InternalHiveSplitFactory;\n-import com.facebook.presto.spi.ConnectorSession;\n-import com.facebook.presto.spi.PrestoException;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.util.concurrent.ListenableFuture;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.hadoop.fs.BlockLocation;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.LocatedFileStatus;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.mapred.InputFormat;\n-\n-import java.io.IOException;\n-import java.io.UncheckedIOException;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Optional;\n-\n-import static com.facebook.presto.hive.HiveErrorCode.MALFORMED_HIVE_FILE_STATISTICS;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_NAMES;\n-import static com.facebook.presto.hive.HiveManifestUtils.FILE_SIZES;\n-import static com.facebook.presto.hive.HiveManifestUtils.decompressFileNames;\n-import static com.facebook.presto.hive.HiveManifestUtils.decompressFileSizes;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxInitialSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getMaxSplitSize;\n-import static com.facebook.presto.hive.HiveSessionProperties.getNodeSelectionStrategy;\n-import static com.facebook.presto.hive.HiveSessionProperties.isManifestVerificationEnabled;\n-import static com.facebook.presto.hive.HiveUtil.getInputFormat;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.IGNORED;\n-import static com.facebook.presto.hive.NestedDirectoryPolicy.RECURSE;\n-import static com.facebook.presto.hive.metastore.MetastoreUtil.getPartitionLocation;\n-import static com.google.common.base.Verify.verify;\n-import static com.google.common.collect.ImmutableList.toImmutableList;\n-import static java.lang.String.format;\n-import static java.util.Objects.requireNonNull;\n-\n-public class ManifestPartitionLoader\n-        extends PartitionLoader\n-{\n-    private final Table table;\n-    private final Optional<Domain> pathDomain;\n-    private final ConnectorSession session;\n-    private final HdfsEnvironment hdfsEnvironment;\n-    private final HdfsContext hdfsContext;\n-    private final NamenodeStats namenodeStats;\n-    private final DirectoryLister directoryLister;\n-    private final boolean recursiveDirWalkerEnabled;\n-    private final boolean schedulerUsesHostAddresses;\n-\n-    public ManifestPartitionLoader(\n-            Table table,\n-            Optional<Domain> pathDomain,\n-            ConnectorSession session,\n-            HdfsEnvironment hdfsEnvironment,\n-            NamenodeStats namenodeStats,\n-            DirectoryLister directoryLister,\n-            boolean recursiveDirWalkerEnabled,\n-            boolean schedulerUsesHostAddresses)\n-    {\n-        this.table = requireNonNull(table, \"table is null\");\n-        this.pathDomain = requireNonNull(pathDomain, \"pathDomain is null\");\n-        this.session = requireNonNull(session, \"session is null\");\n-        this.hdfsEnvironment = requireNonNull(hdfsEnvironment, \"hdfsEnvironment is null\");\n-        this.hdfsContext = new HdfsContext(session, table.getDatabaseName(), table.getTableName());\n-        this.namenodeStats = requireNonNull(namenodeStats, \"namenodeStats is null\");\n-        this.directoryLister = requireNonNull(directoryLister, \"directoryLister is null\");\n-        this.recursiveDirWalkerEnabled = recursiveDirWalkerEnabled;\n-        this.schedulerUsesHostAddresses = schedulerUsesHostAddresses;\n-    }\n-\n-    public ListenableFuture<?> loadPartition(HivePartitionMetadata partition, HiveSplitSource hiveSplitSource, boolean stopped)\n-            throws IOException\n-    {\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Map<String, String> parameters = partition.getPartition().get().getParameters();\n-        List<String> fileNames = decompressFileNames(parameters.get(FILE_NAMES));\n-        List<Long> fileSizes = decompressFileSizes(parameters.get(FILE_SIZES));\n-\n-        // Verify that the count of fileNames and fileSizes are same\n-        verify(fileNames.size() == fileSizes.size(), \"List of fileNames and fileSizes differ in length\");\n-\n-        if (isManifestVerificationEnabled(session)) {\n-            // Verify that the file names and sizes in manifest are the same as listed by directory lister\n-            validateManifest(partition, path, fileNames, fileSizes);\n-        }\n-\n-        ImmutableList.Builder<HiveFileInfo> fileListBuilder = ImmutableList.builder();\n-        for (int i = 0; i < fileNames.size(); i++) {\n-            Path filePath = new Path(path, fileNames.get(i));\n-            FileStatus fileStatus = new FileStatus(fileSizes.get(i), false, 1, getMaxSplitSize(session).toBytes(), 0, filePath);\n-            try {\n-                BlockLocation[] locations = new BlockLocation[] {new BlockLocation(new String[] {\"localhost:50010\"}, new String[] {\"localhost\"}, 0, fileSizes.get(i))};\n-\n-                // It is safe to set extraFileContext as empty because downstream code always checks if its present before proceeding.\n-                fileListBuilder.add(HiveFileInfo.createHiveFileInfo(new LocatedFileStatus(fileStatus, locations), Optional.empty()));\n-            }\n-            catch (IOException e) {\n-                throw new UncheckedIOException(e);\n-            }\n-        }\n-\n-        InternalHiveSplitFactory splitFactory = createInternalHiveSplitFactory(table, partition, session, pathDomain, hdfsEnvironment, hdfsContext, schedulerUsesHostAddresses);\n-\n-        return hiveSplitSource.addToQueue(fileListBuilder.build().stream()\n-                .map(status -> splitFactory.createInternalHiveSplit(status, true))\n-                .filter(Optional::isPresent)\n-                .map(Optional::get)\n-                .collect(toImmutableList()));\n-    }\n-\n-    private InternalHiveSplitFactory createInternalHiveSplitFactory(\n-            Table table,\n-            HivePartitionMetadata partition,\n-            ConnectorSession session,\n-            Optional<Domain> pathDomain,\n-            HdfsEnvironment hdfsEnvironment,\n-            HdfsContext hdfsContext,\n-            boolean schedulerUsesHostAddresses)\n-            throws IOException\n-    {\n-        String partitionName = partition.getHivePartition().getPartitionId();\n-        Storage storage = partition.getPartition().map(Partition::getStorage).orElse(table.getStorage());\n-        String inputFormatName = storage.getStorageFormat().getInputFormat();\n-        int partitionDataColumnCount = partition.getPartition()\n-                .map(p -> p.getColumns().size())\n-                .orElse(table.getDataColumns().size());\n-        List<HivePartitionKey> partitionKeys = getPartitionKeys(table, partition.getPartition());\n-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));\n-        Configuration configuration = hdfsEnvironment.getConfiguration(hdfsContext, path);\n-        InputFormat<?, ?> inputFormat = getInputFormat(configuration, inputFormatName, false);\n-        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n-\n-        return new InternalHiveSplitFactory(\n-                fileSystem,\n-                inputFormat,\n-                pathDomain,\n-                getNodeSelectionStrategy(session),\n-                getMaxInitialSplitSize(session),\n-                false,\n-                new HiveSplitPartitionInfo(\n-                        storage,\n-                        path.toUri(),\n-                        partitionKeys,\n-                        partitionName,\n-                        partitionDataColumnCount,\n-                        partition.getPartitionSchemaDifference(),\n-                        Optional.empty()),\n-                schedulerUsesHostAddresses,\n-                partition.getEncryptionInformation());\n-    }\n-\n-    private void validateManifest(HivePartitionMetadata partition, Path path, List<String> manifestFileNames, List<Long> manifestFileSizes)\n-            throws IOException\n-    {\n-        ExtendedFileSystem fileSystem = hdfsEnvironment.getFileSystem(hdfsContext, path);\n-        HiveDirectoryContext hiveDirectoryContext = new HiveDirectoryContext(recursiveDirWalkerEnabled ? RECURSE : IGNORED, false);\n-\n-        Iterator<HiveFileInfo> fileInfoIterator = directoryLister.list(fileSystem, table, path, namenodeStats, path1 -> true, hiveDirectoryContext);\n-        int fileCount = 0;\n-        while (fileInfoIterator.hasNext()) {\n-            HiveFileInfo fileInfo = fileInfoIterator.next();\n-            String fileName = fileInfo.getPath().getName();\n-            if (!manifestFileNames.contains(fileName)) {\n-                throw new PrestoException(\n-                        MALFORMED_HIVE_FILE_STATISTICS,\n-                        format(\"Filename = %s not stored in manifest. Partition = %s, TableName = %s\",\n-                                fileName,\n-                                partition.getHivePartition().getPartitionId(),\n-                                table.getTableName()));\n-            }\n-\n-            int index = manifestFileNames.indexOf(fileName);\n-            if (!manifestFileSizes.get(index).equals(fileInfo.getLength())) {\n-                throw new PrestoException(\n-                        MALFORMED_HIVE_FILE_STATISTICS,\n-                        format(\"FilesizeFromManifest = %s is not equal to FilesizeFromStorage = %s. File = %s, Partition = %s, TableName = %s\",\n-                                manifestFileSizes.get(index),\n-                                fileInfo.getLength(),\n-                                fileName,\n-                                partition.getHivePartition().getPartitionId(),\n-                                table.getTableName()));\n-            }\n-\n-            fileCount++;\n-        }\n-\n-        if (fileCount != manifestFileNames.size()) {\n-            throw new PrestoException(\n-                    MALFORMED_HIVE_FILE_STATISTICS,\n-                    format(\"Number of files in Manifest = %s is not equal to Number of files in storage = %s. Partition = %s, TableName = %s\",\n-                            manifestFileNames.size(),\n-                            fileCount,\n-                            partition.getHivePartition().getPartitionId(),\n-                            table.getTableName()));\n-        }\n-    }\n-}\n"}}, {"oid": "16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "url": "https://github.com/prestodb/presto/commit/16a740bb4eac27acdaaa85c8696c9d16c8d7a0ee", "message": "Add new session property prefer_manifests_to_list_files\n\nWhen this property is enabled, we try to get the list of\nfilenames, sizes from the Metastore partition and thereby avoid\nlistFiles call to underlying storage.", "committedDate": "2020-11-20T05:59:01Z", "type": "commit"}, {"oid": "7bb7f3f8f9e9a20fa2770f4052595c7bc20ccb12", "url": "https://github.com/prestodb/presto/commit/7bb7f3f8f9e9a20fa2770f4052595c7bc20ccb12", "message": "Add PartitionLoader to load partitions\n\nAdd DelegatingPartitionLoader to delegate the partion\nloading to ManifestPartitionLoader when Partition retrieved\nfrom Metastore has list of fileNames, sizes in it.", "committedDate": "2020-11-20T05:59:01Z", "type": "commit"}, {"oid": "c898bb9747bb06470fe9def2d615ee452a653f72", "url": "https://github.com/prestodb/presto/commit/c898bb9747bb06470fe9def2d615ee452a653f72", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-20T05:59:01Z", "type": "commit"}, {"oid": "c898bb9747bb06470fe9def2d615ee452a653f72", "url": "https://github.com/prestodb/presto/commit/c898bb9747bb06470fe9def2d615ee452a653f72", "message": "Add session property manifest_verification_enabled\n\nWhen this property is enabled, the file names & sizes\nstored in manifest/partition parameters will be verified\nagainst the output of listFiles() call.", "committedDate": "2020-11-20T05:59:01Z", "type": "forcePushed"}]}