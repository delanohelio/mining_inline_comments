{"pr_number": 14675, "pr_title": "Initial Support of Adaptive Optimization with Presto Unlimited", "pr_createdAt": "2020-06-18T20:37:12Z", "pr_url": "https://github.com/prestodb/presto/pull/14675", "timeline": [{"oid": "a5947a880087c2525e457fe55630f76aac585764", "url": "https://github.com/prestodb/presto/commit/a5947a880087c2525e457fe55630f76aac585764", "message": "Make CBO invokable from SqlQueryScheduler. Create the join swapping rule based on probe and build side statistics.", "committedDate": "2020-06-19T01:41:11Z", "type": "forcePushed"}, {"oid": "1d5edc73b5f1ab77f1d7c04ded6b913c6b90c30f", "url": "https://github.com/prestodb/presto/commit/1d5edc73b5f1ab77f1d7c04ded6b913c6b90c30f", "message": "Make CBO invokable from SqlQueryScheduler. Create the join swapping rule based on probe and build side statistics.", "committedDate": "2020-06-19T17:04:42Z", "type": "forcePushed"}, {"oid": "0e4d41e4991938c985389c3a9aa7da108a88e2f3", "url": "https://github.com/prestodb/presto/commit/0e4d41e4991938c985389c3a9aa7da108a88e2f3", "message": "Add a session property for runtime optimizer.", "committedDate": "2020-06-23T15:29:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ3ODk1OA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444478958", "bodyText": "nit: comment isn't necessary", "author": "rschlussel", "createdAt": "2020-06-23T20:11:41Z", "path": "presto-main/src/main/java/com/facebook/presto/cost/StatsUtil.java", "diffHunk": "@@ -77,11 +78,15 @@ private static boolean convertibleToDoubleWithCast(Type type)\n                 || BooleanType.BOOLEAN.equals(type);\n     }\n \n-    public static VariableStatsEstimate toVariableStatsEstimate(TableStatistics tableStatistics, ColumnStatistics columnStatistics)\n+    public static VariableStatsEstimate toVariableStatsEstimate(TableStatistics tableStatistics, ColumnStatistics columnStatistics, Type columnType)\n     {\n         double nullsFraction = columnStatistics.getNullsFraction().getValue();\n         double nonNullRowsCount = tableStatistics.getRowCount().getValue() * (1.0 - nullsFraction);\n         double averageRowSize = nonNullRowsCount == 0 ? 0 : columnStatistics.getDataSize().getValue() / nonNullRowsCount;\n+        // Fixed width type column statistics all have DataSize NaN.", "originalCommit": "e6738ea00cef9ac2bccdf54f0f291835f2b8d54b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1f309db277ff8c222a942f85e458370af70bfe0a", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/cost/StatsUtil.java b/presto-main/src/main/java/com/facebook/presto/cost/StatsUtil.java\nindex 4b301ca3df..d8a1290d9b 100644\n--- a/presto-main/src/main/java/com/facebook/presto/cost/StatsUtil.java\n+++ b/presto-main/src/main/java/com/facebook/presto/cost/StatsUtil.java\n\n@@ -83,7 +83,6 @@ final class StatsUtil\n         double nullsFraction = columnStatistics.getNullsFraction().getValue();\n         double nonNullRowsCount = tableStatistics.getRowCount().getValue() * (1.0 - nullsFraction);\n         double averageRowSize = nonNullRowsCount == 0 ? 0 : columnStatistics.getDataSize().getValue() / nonNullRowsCount;\n-        // Fixed width type column statistics all have DataSize NaN.\n         if (Double.isNaN(averageRowSize) && columnType instanceof FixedWidthType) {\n             averageRowSize = ((FixedWidthType) columnType).getFixedSize();\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4MzEwNg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444483106", "bodyText": "ideally all this logic to filter relevant plans should go into the optimizer rule", "author": "rschlussel", "createdAt": "2020-06-23T20:19:54Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -458,10 +517,244 @@ else if (!result.getBlocked().isDone()) {\n         return stream(forTree(StreamingPlanSection::getChildren).depthFirstPreOrder(sectionedPlan))\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n+                /* .map(this::fetchTemporaryTableStatistics) */\n+                .map(this::tryCostBasedOptimize)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                // filter leaf stages\n+                .filter(plan -> plan.getChildren().isEmpty())", "originalCommit": "6093bb2272e5406e7e1c6c0333ba6a93c411e501", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUwMzAxMw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444503013", "bodyText": "Yeah, I thought about moving all the filtering logic inside the rule, but my concern is it seems not possible to easily tell from the iterative optimizer output if the returned plan is actually changed or not. If we are not able to tell, then for each ready section, we will waste time rebuilding the whole section and stageExecution/scheduler etc. even the optimizer rule is not fired at all.", "author": "pguofb", "createdAt": "2020-06-23T20:55:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4MzEwNg=="}], "type": "inlineReview", "revised_code": {"commit": "1f309db277ff8c222a942f85e458370af70bfe0a", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 3e4aec7bae..88439ce7c1 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -530,7 +531,7 @@ public class LegacySqlQueryScheduler\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (section.getChildren().isEmpty()) {\n+        if (!SystemSessionProperties.isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4NTIwNA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444485204", "bodyText": "@arhimondr can you check this logic?", "author": "rschlussel", "createdAt": "2020-06-23T20:23:52Z", "path": "presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java", "diffHunk": "@@ -91,6 +91,12 @@ public static HiveBasicStatistics reduce(HiveBasicStatistics first, HiveBasicSta\n \n     public static Map<String, HiveColumnStatistics> merge(Map<String, HiveColumnStatistics> first, Map<String, HiveColumnStatistics> second)\n     {\n+        // To correctly merge statistics during temporary table finish insertion. When ``first'' have exactly the same columns as ``second'' but all empty statistics,\n+        // then the ``first'' is the placeholder empty statistics left at temporary table creation and safe to directly return second.\n+        if (first.values().stream().allMatch(statistics -> statistics.equals(HiveColumnStatistics.empty()))", "originalCommit": "8b97369082357d8ca46aa9c048fce12ff8d0036c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwNTkyMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444605920", "bodyText": "How about instead of adding this logic we set all statistics to 0 when creating a temporary table?", "author": "arhimondr", "createdAt": "2020-06-24T02:14:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4NTIwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwNzk4Ng==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444607986", "bodyText": "You can use this helper method: https://github.com/prestodb/presto/blob/master/presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java#L244", "author": "arhimondr", "createdAt": "2020-06-24T02:22:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4NTIwNA=="}], "type": "inlineReview", "revised_code": {"commit": "1f309db277ff8c222a942f85e458370af70bfe0a", "chunk": "diff --git a/presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java b/presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java\nindex 7116cb5229..640e0edee9 100644\n--- a/presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java\n+++ b/presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java\n\n@@ -94,7 +94,7 @@ public final class Statistics\n         // To correctly merge statistics during temporary table finish insertion. When ``first'' have exactly the same columns as ``second'' but all empty statistics,\n         // then the ``first'' is the placeholder empty statistics left at temporary table creation and safe to directly return second.\n         if (first.values().stream().allMatch(statistics -> statistics.equals(HiveColumnStatistics.empty()))\n-                && first.values().containsAll(second.values()) && second.values().containsAll(first.values())) {\n+                && first.keySet().containsAll(second.keySet()) && second.keySet().containsAll(first.keySet())) {\n             return second;\n         }\n         // only keep columns that have statistics for both sides\n"}}, {"oid": "1f309db277ff8c222a942f85e458370af70bfe0a", "url": "https://github.com/prestodb/presto/commit/1f309db277ff8c222a942f85e458370af70bfe0a", "message": "Add a session property for runtime optimizer.", "committedDate": "2020-06-24T01:26:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwNDg4Ng==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444604886", "bodyText": "In what case the stats are missing? Why didn't we need this special case before?", "author": "arhimondr", "createdAt": "2020-06-24T02:11:02Z", "path": "presto-main/src/main/java/com/facebook/presto/cost/ConnectorFilterStatsCalculatorService.java", "diffHunk": "@@ -111,7 +111,8 @@ private static ColumnStatistics toColumnStatistics(VariableStatsEstimate variabl\n             builder.setDistinctValuesCount(Estimate.of(variableStatsEstimate.getDistinctValuesCount()));\n         }\n \n-        if (!Double.isNaN(variableStatsEstimate.getAverageRowSize())) {\n+        // for (synthesized) bucket columns, averageRowSize is not null (4, derived from columnType int) and nullFraction is NULL.\n+        if (!Double.isNaN(variableStatsEstimate.getAverageRowSize()) && !Double.isNaN(nonNullRowsCount)) {", "originalCommit": "962c24d3df0ab633c8c89405d8121feddae26f61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDkyMTk2NA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444921964", "bodyText": "Before, it is assumed (not strictly guaranteed) that averageRowSize and nonNullRowCount are either all NaN, or all have meaningful values. And it is not solid anyway.\nFor our case, as we derive the averageRowSize from the columnType already, it becomes much more likely that averageRowSize is not NaN, but nullRowCount is still NaN. And this is why we need to add this additional condition.", "author": "pguofb", "createdAt": "2020-06-24T14:10:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwNDg4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA5NzY3OA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r445097678", "bodyText": "Could you please elaborate a little bit more on what was the issue and it what cases it manifests?", "author": "arhimondr", "createdAt": "2020-06-24T18:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwNDg4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2ODIzMQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r445168231", "bodyText": "Sorry, i commented on the wrong line", "author": "arhimondr", "createdAt": "2020-06-24T20:58:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwNDg4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2d8982dd71765408439c704fef14f70f0b8f589b", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/cost/ConnectorFilterStatsCalculatorService.java b/presto-main/src/main/java/com/facebook/presto/cost/ConnectorFilterStatsCalculatorService.java\nindex d9b28b7007..9983320aa7 100644\n--- a/presto-main/src/main/java/com/facebook/presto/cost/ConnectorFilterStatsCalculatorService.java\n+++ b/presto-main/src/main/java/com/facebook/presto/cost/ConnectorFilterStatsCalculatorService.java\n\n@@ -111,8 +111,7 @@ public class ConnectorFilterStatsCalculatorService\n             builder.setDistinctValuesCount(Estimate.of(variableStatsEstimate.getDistinctValuesCount()));\n         }\n \n-        // for (synthesized) bucket columns, averageRowSize is not null (4, derived from columnType int) and nullFraction is NULL.\n-        if (!Double.isNaN(variableStatsEstimate.getAverageRowSize()) && !Double.isNaN(nonNullRowsCount)) {\n+        if (!Double.isNaN(variableStatsEstimate.getAverageRowSize())) {\n             builder.setDataSize(Estimate.of(variableStatsEstimate.getAverageRowSize() * nonNullRowsCount));\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYwODEwMQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444608101", "bodyText": "You can use https://github.com/prestodb/presto/blob/master/presto-hive-metastore/src/main/java/com/facebook/presto/hive/metastore/Statistics.java#L244 to create empty statistics.", "author": "arhimondr", "createdAt": "2020-06-24T02:22:46Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -923,7 +924,7 @@ public ConnectorTableHandle createTemporaryTable(ConnectorSession session, List<\n                 buildInitialPrivilegeSet(table.getOwner()),\n                 Optional.empty(),\n                 false,\n-                new PartitionStatistics(createEmptyStatistics(), ImmutableMap.of()));\n+                new PartitionStatistics(createZeroStatistics(), columnHandles.stream().collect(toImmutableMap(HiveColumnHandle::getName, x -> empty()))));", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\nindex 424d868b0b..79df74114e 100644\n--- a/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n+++ b/presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java\n\n@@ -918,13 +917,25 @@ public class HiveMetadata\n                         .setLocation(\"\"))\n                 .build();\n \n+        List<String> partitionColumnNames = table.getPartitionColumns().stream()\n+                .map(Column::getName)\n+                .collect(toImmutableList());\n+        List<HiveColumnHandle> hiveColumnHandles = hiveColumnHandles(table);\n+        Map<String, Type> columnTypes = hiveColumnHandles.stream()\n+                .filter(columnHandle -> !columnHandle.isHidden())\n+                .collect(toImmutableMap(HiveColumnHandle::getName, column -> column.getHiveType().getType(typeManager)));\n+        Map<String, Set<ColumnStatisticType>> columnStatisticTypes = hiveColumnHandles.stream()\n+                .filter(columnHandle -> !partitionColumnNames.contains(columnHandle.getName()))\n+                .filter(column -> !column.isHidden())\n+                .collect(toImmutableMap(HiveColumnHandle::getName, column -> ImmutableSet.copyOf(metastore.getSupportedColumnStatistics(typeManager.getType(column.getTypeSignature())))));\n+\n         metastore.createTable(\n                 session,\n                 table,\n                 buildInitialPrivilegeSet(table.getOwner()),\n                 Optional.empty(),\n                 false,\n-                new PartitionStatistics(createZeroStatistics(), columnHandles.stream().collect(toImmutableMap(HiveColumnHandle::getName, x -> empty()))));\n+                createEmptyPartitionStatistics(columnTypes, columnStatisticTypes));\n \n         return new HiveTableHandle(schemaName, tableName);\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxMTkwMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444611900", "bodyText": "@rongrong Do we still need to use SymbolReference in the planner?", "author": "arhimondr", "createdAt": "2020-06-24T02:37:34Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java", "diffHunk": "@@ -110,26 +110,49 @@ public TableStatisticAggregation createStatisticsAggregation(TableStatisticsMeta\n         return new TableStatisticAggregation(aggregation, descriptor.build());\n     }\n \n-    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input)\n+    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean afterTranslateExpressions)\n     {\n-        SymbolReference symbolReference = new SymbolReference(input.getName());\n-        switch (statisticType) {\n-            case MIN_VALUE:\n-                return createAggregation(\"min\", symbolReference, input.getType(), input.getType());\n-            case MAX_VALUE:\n-                return createAggregation(\"max\", symbolReference, input.getType(), input.getType());\n-            case NUMBER_OF_DISTINCT_VALUES:\n-                return createAggregation(\"approx_distinct\", symbolReference, input.getType(), BIGINT);\n-            case NUMBER_OF_NON_NULL_VALUES:\n-                return createAggregation(\"count\", symbolReference, input.getType(), BIGINT);\n-            case NUMBER_OF_TRUE_VALUES:\n-                return createAggregation(\"count_if\", symbolReference, BOOLEAN, BIGINT);\n-            case TOTAL_SIZE_IN_BYTES:\n-                return createAggregation(SumDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-            case MAX_VALUE_SIZE_IN_BYTES:\n-                return createAggregation(MaxDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-            default:\n-                throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n+        if (!afterTranslateExpressions) {\n+            SymbolReference symbolReference = new SymbolReference(input.getName());", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\nindex 42d23f439a..4a36db5d72 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\n\n@@ -110,73 +111,31 @@ public class StatisticsAggregationPlanner\n         return new TableStatisticAggregation(aggregation, descriptor.build());\n     }\n \n-    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean afterTranslateExpressions)\n+    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean useOriginalExpression)\n     {\n-        if (!afterTranslateExpressions) {\n-            SymbolReference symbolReference = new SymbolReference(input.getName());\n-            switch (statisticType) {\n-                case MIN_VALUE:\n-                    return createAggregation(\"min\", symbolReference, input.getType(), input.getType());\n-                case MAX_VALUE:\n-                    return createAggregation(\"max\", symbolReference, input.getType(), input.getType());\n-                case NUMBER_OF_DISTINCT_VALUES:\n-                    return createAggregation(\"approx_distinct\", symbolReference, input.getType(), BIGINT);\n-                case NUMBER_OF_NON_NULL_VALUES:\n-                    return createAggregation(\"count\", symbolReference, input.getType(), BIGINT);\n-                case NUMBER_OF_TRUE_VALUES:\n-                    return createAggregation(\"count_if\", symbolReference, BOOLEAN, BIGINT);\n-                case TOTAL_SIZE_IN_BYTES:\n-                    return createAggregation(SumDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-                case MAX_VALUE_SIZE_IN_BYTES:\n-                    return createAggregation(MaxDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-                default:\n-                    throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n-            }\n-        }\n-        else {\n-            // Example call site: PlanFragmenter when creating temporary table for materialized exchange.\n-            switch (statisticType) {\n-                case MIN_VALUE:\n-                    return createAggregationWithVariableReferenceExpression(\"min\", input, input.getType(), input.getType());\n-                case MAX_VALUE:\n-                    return createAggregationWithVariableReferenceExpression(\"max\", input, input.getType(), input.getType());\n-                case NUMBER_OF_DISTINCT_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"approx_distinct\", input, input.getType(), BIGINT);\n-                case NUMBER_OF_NON_NULL_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"count\", input, input.getType(), BIGINT);\n-                case NUMBER_OF_TRUE_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"count_if\", input, BOOLEAN, BIGINT);\n-                case TOTAL_SIZE_IN_BYTES:\n-                    return createAggregationWithVariableReferenceExpression(SumDataSizeForStats.NAME, input, input.getType(), BIGINT);\n-                case MAX_VALUE_SIZE_IN_BYTES:\n-                    return createAggregationWithVariableReferenceExpression(MaxDataSizeForStats.NAME, input, input.getType(), BIGINT);\n-                default:\n-                    throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n-            }\n+        // This is transitional. Will migrate to only using VariableReferenceExpression when supported by all the planner rules.\n+        RowExpression inputExpression = useOriginalExpression ? castToRowExpression(new SymbolReference(input.getName())) : input;\n+        switch (statisticType) {\n+            case MIN_VALUE:\n+                return createAggregation(\"min\", inputExpression, input.getType(), input.getType());\n+            case MAX_VALUE:\n+                return createAggregation(\"max\", inputExpression, input.getType(), input.getType());\n+            case NUMBER_OF_DISTINCT_VALUES:\n+                return createAggregation(\"approx_distinct\", inputExpression, input.getType(), BIGINT);\n+            case NUMBER_OF_NON_NULL_VALUES:\n+                return createAggregation(\"count\", inputExpression, input.getType(), BIGINT);\n+            case NUMBER_OF_TRUE_VALUES:\n+                return createAggregation(\"count_if\", inputExpression, BOOLEAN, BIGINT);\n+            case TOTAL_SIZE_IN_BYTES:\n+                return createAggregation(SumDataSizeForStats.NAME, inputExpression, input.getType(), BIGINT);\n+            case MAX_VALUE_SIZE_IN_BYTES:\n+                return createAggregation(MaxDataSizeForStats.NAME, inputExpression, input.getType(), BIGINT);\n+            default:\n+                throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n         }\n     }\n \n-    private ColumnStatisticsAggregation createAggregation(String functionName, SymbolReference input, Type inputType, Type outputType)\n-    {\n-        FunctionManager functionManager = metadata.getFunctionManager();\n-        FunctionHandle functionHandle = functionManager.lookupFunction(functionName, TypeSignatureProvider.fromTypes(ImmutableList.of(inputType)));\n-        Type resolvedType = metadata.getType(getOnlyElement(functionManager.getFunctionMetadata(functionHandle).getArgumentTypes()));\n-        verify(resolvedType.equals(inputType), \"resolved function input type does not match the input type: %s != %s\", resolvedType, inputType);\n-        return new ColumnStatisticsAggregation(\n-                new AggregationNode.Aggregation(\n-                        new CallExpression(\n-                                functionName,\n-                                functionHandle,\n-                                outputType,\n-                                ImmutableList.of(castToRowExpression(input))),\n-                        Optional.empty(),\n-                        Optional.empty(),\n-                        false,\n-                        Optional.empty()),\n-                outputType);\n-    }\n-\n-    private ColumnStatisticsAggregation createAggregationWithVariableReferenceExpression(String functionName, VariableReferenceExpression input, Type inputType, Type outputType)\n+    private ColumnStatisticsAggregation createAggregation(String functionName, RowExpression input, Type inputType, Type outputType)\n     {\n         FunctionManager functionManager = metadata.getFunctionManager();\n         FunctionHandle functionHandle = functionManager.lookupFunction(functionName, TypeSignatureProvider.fromTypes(ImmutableList.of(inputType)));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxMjA1NA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444612054", "bodyText": "I tried to use the VariableReferenceExpression directly, and it seems like there are test failures.", "author": "arhimondr", "createdAt": "2020-06-24T02:38:14Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java", "diffHunk": "@@ -110,26 +110,49 @@ public TableStatisticAggregation createStatisticsAggregation(TableStatisticsMeta\n         return new TableStatisticAggregation(aggregation, descriptor.build());\n     }\n \n-    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input)\n+    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean afterTranslateExpressions)\n     {\n-        SymbolReference symbolReference = new SymbolReference(input.getName());\n-        switch (statisticType) {\n-            case MIN_VALUE:\n-                return createAggregation(\"min\", symbolReference, input.getType(), input.getType());\n-            case MAX_VALUE:\n-                return createAggregation(\"max\", symbolReference, input.getType(), input.getType());\n-            case NUMBER_OF_DISTINCT_VALUES:\n-                return createAggregation(\"approx_distinct\", symbolReference, input.getType(), BIGINT);\n-            case NUMBER_OF_NON_NULL_VALUES:\n-                return createAggregation(\"count\", symbolReference, input.getType(), BIGINT);\n-            case NUMBER_OF_TRUE_VALUES:\n-                return createAggregation(\"count_if\", symbolReference, BOOLEAN, BIGINT);\n-            case TOTAL_SIZE_IN_BYTES:\n-                return createAggregation(SumDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-            case MAX_VALUE_SIZE_IN_BYTES:\n-                return createAggregation(MaxDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-            default:\n-                throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n+        if (!afterTranslateExpressions) {\n+            SymbolReference symbolReference = new SymbolReference(input.getName());", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\nindex 42d23f439a..4a36db5d72 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\n\n@@ -110,73 +111,31 @@ public class StatisticsAggregationPlanner\n         return new TableStatisticAggregation(aggregation, descriptor.build());\n     }\n \n-    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean afterTranslateExpressions)\n+    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean useOriginalExpression)\n     {\n-        if (!afterTranslateExpressions) {\n-            SymbolReference symbolReference = new SymbolReference(input.getName());\n-            switch (statisticType) {\n-                case MIN_VALUE:\n-                    return createAggregation(\"min\", symbolReference, input.getType(), input.getType());\n-                case MAX_VALUE:\n-                    return createAggregation(\"max\", symbolReference, input.getType(), input.getType());\n-                case NUMBER_OF_DISTINCT_VALUES:\n-                    return createAggregation(\"approx_distinct\", symbolReference, input.getType(), BIGINT);\n-                case NUMBER_OF_NON_NULL_VALUES:\n-                    return createAggregation(\"count\", symbolReference, input.getType(), BIGINT);\n-                case NUMBER_OF_TRUE_VALUES:\n-                    return createAggregation(\"count_if\", symbolReference, BOOLEAN, BIGINT);\n-                case TOTAL_SIZE_IN_BYTES:\n-                    return createAggregation(SumDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-                case MAX_VALUE_SIZE_IN_BYTES:\n-                    return createAggregation(MaxDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-                default:\n-                    throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n-            }\n-        }\n-        else {\n-            // Example call site: PlanFragmenter when creating temporary table for materialized exchange.\n-            switch (statisticType) {\n-                case MIN_VALUE:\n-                    return createAggregationWithVariableReferenceExpression(\"min\", input, input.getType(), input.getType());\n-                case MAX_VALUE:\n-                    return createAggregationWithVariableReferenceExpression(\"max\", input, input.getType(), input.getType());\n-                case NUMBER_OF_DISTINCT_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"approx_distinct\", input, input.getType(), BIGINT);\n-                case NUMBER_OF_NON_NULL_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"count\", input, input.getType(), BIGINT);\n-                case NUMBER_OF_TRUE_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"count_if\", input, BOOLEAN, BIGINT);\n-                case TOTAL_SIZE_IN_BYTES:\n-                    return createAggregationWithVariableReferenceExpression(SumDataSizeForStats.NAME, input, input.getType(), BIGINT);\n-                case MAX_VALUE_SIZE_IN_BYTES:\n-                    return createAggregationWithVariableReferenceExpression(MaxDataSizeForStats.NAME, input, input.getType(), BIGINT);\n-                default:\n-                    throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n-            }\n+        // This is transitional. Will migrate to only using VariableReferenceExpression when supported by all the planner rules.\n+        RowExpression inputExpression = useOriginalExpression ? castToRowExpression(new SymbolReference(input.getName())) : input;\n+        switch (statisticType) {\n+            case MIN_VALUE:\n+                return createAggregation(\"min\", inputExpression, input.getType(), input.getType());\n+            case MAX_VALUE:\n+                return createAggregation(\"max\", inputExpression, input.getType(), input.getType());\n+            case NUMBER_OF_DISTINCT_VALUES:\n+                return createAggregation(\"approx_distinct\", inputExpression, input.getType(), BIGINT);\n+            case NUMBER_OF_NON_NULL_VALUES:\n+                return createAggregation(\"count\", inputExpression, input.getType(), BIGINT);\n+            case NUMBER_OF_TRUE_VALUES:\n+                return createAggregation(\"count_if\", inputExpression, BOOLEAN, BIGINT);\n+            case TOTAL_SIZE_IN_BYTES:\n+                return createAggregation(SumDataSizeForStats.NAME, inputExpression, input.getType(), BIGINT);\n+            case MAX_VALUE_SIZE_IN_BYTES:\n+                return createAggregation(MaxDataSizeForStats.NAME, inputExpression, input.getType(), BIGINT);\n+            default:\n+                throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n         }\n     }\n \n-    private ColumnStatisticsAggregation createAggregation(String functionName, SymbolReference input, Type inputType, Type outputType)\n-    {\n-        FunctionManager functionManager = metadata.getFunctionManager();\n-        FunctionHandle functionHandle = functionManager.lookupFunction(functionName, TypeSignatureProvider.fromTypes(ImmutableList.of(inputType)));\n-        Type resolvedType = metadata.getType(getOnlyElement(functionManager.getFunctionMetadata(functionHandle).getArgumentTypes()));\n-        verify(resolvedType.equals(inputType), \"resolved function input type does not match the input type: %s != %s\", resolvedType, inputType);\n-        return new ColumnStatisticsAggregation(\n-                new AggregationNode.Aggregation(\n-                        new CallExpression(\n-                                functionName,\n-                                functionHandle,\n-                                outputType,\n-                                ImmutableList.of(castToRowExpression(input))),\n-                        Optional.empty(),\n-                        Optional.empty(),\n-                        false,\n-                        Optional.empty()),\n-                outputType);\n-    }\n-\n-    private ColumnStatisticsAggregation createAggregationWithVariableReferenceExpression(String functionName, VariableReferenceExpression input, Type inputType, Type outputType)\n+    private ColumnStatisticsAggregation createAggregation(String functionName, RowExpression input, Type inputType, Type outputType)\n     {\n         FunctionManager functionManager = metadata.getFunctionManager();\n         FunctionHandle functionHandle = functionManager.lookupFunction(functionName, TypeSignatureProvider.fromTypes(ImmutableList.of(inputType)));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxMzUwMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444613500", "bodyText": "@pguofb Please try to rewrite this code to avoid code duplication.\nLet's keep only a single version of the createColumnAggregation and the createAggregation. Let's change the type of the input to RowExpression  for both and let's pass either VariableReferenceExpression or OriginalExpression based on the flag from the createStatisticsAggregation. Also let's change the flag name to something like useOriginalExpression and set it to true in the LogicalPlanner. Also please add a comment that this is transitional, and must be migrated to RowExpression after these are fully supported by all the planner rules.", "author": "arhimondr", "createdAt": "2020-06-24T02:43:49Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java", "diffHunk": "@@ -110,26 +110,49 @@ public TableStatisticAggregation createStatisticsAggregation(TableStatisticsMeta\n         return new TableStatisticAggregation(aggregation, descriptor.build());\n     }\n \n-    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input)\n+    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean afterTranslateExpressions)\n     {\n-        SymbolReference symbolReference = new SymbolReference(input.getName());\n-        switch (statisticType) {\n-            case MIN_VALUE:\n-                return createAggregation(\"min\", symbolReference, input.getType(), input.getType());\n-            case MAX_VALUE:\n-                return createAggregation(\"max\", symbolReference, input.getType(), input.getType());\n-            case NUMBER_OF_DISTINCT_VALUES:\n-                return createAggregation(\"approx_distinct\", symbolReference, input.getType(), BIGINT);\n-            case NUMBER_OF_NON_NULL_VALUES:\n-                return createAggregation(\"count\", symbolReference, input.getType(), BIGINT);\n-            case NUMBER_OF_TRUE_VALUES:\n-                return createAggregation(\"count_if\", symbolReference, BOOLEAN, BIGINT);\n-            case TOTAL_SIZE_IN_BYTES:\n-                return createAggregation(SumDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-            case MAX_VALUE_SIZE_IN_BYTES:\n-                return createAggregation(MaxDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-            default:\n-                throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n+        if (!afterTranslateExpressions) {\n+            SymbolReference symbolReference = new SymbolReference(input.getName());", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\nindex 42d23f439a..4a36db5d72 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/StatisticsAggregationPlanner.java\n\n@@ -110,73 +111,31 @@ public class StatisticsAggregationPlanner\n         return new TableStatisticAggregation(aggregation, descriptor.build());\n     }\n \n-    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean afterTranslateExpressions)\n+    private ColumnStatisticsAggregation createColumnAggregation(ColumnStatisticType statisticType, VariableReferenceExpression input, boolean useOriginalExpression)\n     {\n-        if (!afterTranslateExpressions) {\n-            SymbolReference symbolReference = new SymbolReference(input.getName());\n-            switch (statisticType) {\n-                case MIN_VALUE:\n-                    return createAggregation(\"min\", symbolReference, input.getType(), input.getType());\n-                case MAX_VALUE:\n-                    return createAggregation(\"max\", symbolReference, input.getType(), input.getType());\n-                case NUMBER_OF_DISTINCT_VALUES:\n-                    return createAggregation(\"approx_distinct\", symbolReference, input.getType(), BIGINT);\n-                case NUMBER_OF_NON_NULL_VALUES:\n-                    return createAggregation(\"count\", symbolReference, input.getType(), BIGINT);\n-                case NUMBER_OF_TRUE_VALUES:\n-                    return createAggregation(\"count_if\", symbolReference, BOOLEAN, BIGINT);\n-                case TOTAL_SIZE_IN_BYTES:\n-                    return createAggregation(SumDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-                case MAX_VALUE_SIZE_IN_BYTES:\n-                    return createAggregation(MaxDataSizeForStats.NAME, symbolReference, input.getType(), BIGINT);\n-                default:\n-                    throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n-            }\n-        }\n-        else {\n-            // Example call site: PlanFragmenter when creating temporary table for materialized exchange.\n-            switch (statisticType) {\n-                case MIN_VALUE:\n-                    return createAggregationWithVariableReferenceExpression(\"min\", input, input.getType(), input.getType());\n-                case MAX_VALUE:\n-                    return createAggregationWithVariableReferenceExpression(\"max\", input, input.getType(), input.getType());\n-                case NUMBER_OF_DISTINCT_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"approx_distinct\", input, input.getType(), BIGINT);\n-                case NUMBER_OF_NON_NULL_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"count\", input, input.getType(), BIGINT);\n-                case NUMBER_OF_TRUE_VALUES:\n-                    return createAggregationWithVariableReferenceExpression(\"count_if\", input, BOOLEAN, BIGINT);\n-                case TOTAL_SIZE_IN_BYTES:\n-                    return createAggregationWithVariableReferenceExpression(SumDataSizeForStats.NAME, input, input.getType(), BIGINT);\n-                case MAX_VALUE_SIZE_IN_BYTES:\n-                    return createAggregationWithVariableReferenceExpression(MaxDataSizeForStats.NAME, input, input.getType(), BIGINT);\n-                default:\n-                    throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n-            }\n+        // This is transitional. Will migrate to only using VariableReferenceExpression when supported by all the planner rules.\n+        RowExpression inputExpression = useOriginalExpression ? castToRowExpression(new SymbolReference(input.getName())) : input;\n+        switch (statisticType) {\n+            case MIN_VALUE:\n+                return createAggregation(\"min\", inputExpression, input.getType(), input.getType());\n+            case MAX_VALUE:\n+                return createAggregation(\"max\", inputExpression, input.getType(), input.getType());\n+            case NUMBER_OF_DISTINCT_VALUES:\n+                return createAggregation(\"approx_distinct\", inputExpression, input.getType(), BIGINT);\n+            case NUMBER_OF_NON_NULL_VALUES:\n+                return createAggregation(\"count\", inputExpression, input.getType(), BIGINT);\n+            case NUMBER_OF_TRUE_VALUES:\n+                return createAggregation(\"count_if\", inputExpression, BOOLEAN, BIGINT);\n+            case TOTAL_SIZE_IN_BYTES:\n+                return createAggregation(SumDataSizeForStats.NAME, inputExpression, input.getType(), BIGINT);\n+            case MAX_VALUE_SIZE_IN_BYTES:\n+                return createAggregation(MaxDataSizeForStats.NAME, inputExpression, input.getType(), BIGINT);\n+            default:\n+                throw new IllegalArgumentException(\"Unsupported statistic type: \" + statisticType);\n         }\n     }\n \n-    private ColumnStatisticsAggregation createAggregation(String functionName, SymbolReference input, Type inputType, Type outputType)\n-    {\n-        FunctionManager functionManager = metadata.getFunctionManager();\n-        FunctionHandle functionHandle = functionManager.lookupFunction(functionName, TypeSignatureProvider.fromTypes(ImmutableList.of(inputType)));\n-        Type resolvedType = metadata.getType(getOnlyElement(functionManager.getFunctionMetadata(functionHandle).getArgumentTypes()));\n-        verify(resolvedType.equals(inputType), \"resolved function input type does not match the input type: %s != %s\", resolvedType, inputType);\n-        return new ColumnStatisticsAggregation(\n-                new AggregationNode.Aggregation(\n-                        new CallExpression(\n-                                functionName,\n-                                functionHandle,\n-                                outputType,\n-                                ImmutableList.of(castToRowExpression(input))),\n-                        Optional.empty(),\n-                        Optional.empty(),\n-                        false,\n-                        Optional.empty()),\n-                outputType);\n-    }\n-\n-    private ColumnStatisticsAggregation createAggregationWithVariableReferenceExpression(String functionName, VariableReferenceExpression input, Type inputType, Type outputType)\n+    private ColumnStatisticsAggregation createAggregation(String functionName, RowExpression input, Type inputType, Type outputType)\n     {\n         FunctionManager functionManager = metadata.getFunctionManager();\n         FunctionHandle functionHandle = functionManager.lookupFunction(functionName, TypeSignatureProvider.fromTypes(ImmutableList.of(inputType)));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxMzk0Nw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444613947", "bodyText": "let's inline this", "author": "arhimondr", "createdAt": "2020-06-24T02:45:37Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java", "diffHunk": "@@ -756,21 +761,28 @@ private TableFinishNode createTemporaryTableWrite(\n                         partitioningScheme);\n             }\n \n-            TableWriterNode tableWriter = new TableWriterNode(\n-                    idAllocator.getNextId(),\n-                    writerSource,\n-                    Optional.of(insertReference),\n-                    variableAllocator.newVariable(\"partialrows\", BIGINT),\n-                    variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n-                    variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n-                    outputs,\n-                    outputColumnNames,\n-                    Optional.of(partitioningScheme),\n-                    Optional.empty(),\n-                    Optional.empty());\n+            String catalogName = tableHandle.getConnectorId().getCatalogName();\n+            TableMetadata tableMetadata = metadata.getTableMetadata(session, tableHandle);\n+            TableStatisticsMetadata statisticsMetadata = metadata.getStatisticsCollectionMetadataForWrite(session, catalogName, tableMetadata.getMetadata());\n+            StatisticsAggregationPlanner.TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, true);\n+            StatisticAggregations.Parts aggregations = statisticsResult.getAggregations().splitIntoPartialAndFinal(variableAllocator, metadata.getFunctionManager());\n+            PlanNode tableWriterMerge;\n \n-            PlanNode tableWriterMerge = tableWriter;\n             if (isTableWriterMergeOperatorEnabled(session)) {\n+                StatisticAggregations.Parts localAggregations = aggregations.getPartialAggregation().splitIntoPartialAndIntermediate(variableAllocator, metadata.getFunctionManager());\n+                TableWriterNode tableWriter = new TableWriterNode(", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\nindex bbce8da20a..766ad91f49 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n\n@@ -764,35 +794,36 @@ public class PlanFragmenter\n             String catalogName = tableHandle.getConnectorId().getCatalogName();\n             TableMetadata tableMetadata = metadata.getTableMetadata(session, tableHandle);\n             TableStatisticsMetadata statisticsMetadata = metadata.getStatisticsCollectionMetadataForWrite(session, catalogName, tableMetadata.getMetadata());\n-            StatisticsAggregationPlanner.TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, true);\n+            TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, false);\n             StatisticAggregations.Parts aggregations = statisticsResult.getAggregations().splitIntoPartialAndFinal(variableAllocator, metadata.getFunctionManager());\n             PlanNode tableWriterMerge;\n \n+            // Disabled by default. Enable when the column statistics are essential for future runtime adaptive plan optimizations\n+            boolean enableStatsCollectionForTemporaryTable = SystemSessionProperties.isEnableStatsCollectionForTemporaryTable(session);\n+\n             if (isTableWriterMergeOperatorEnabled(session)) {\n                 StatisticAggregations.Parts localAggregations = aggregations.getPartialAggregation().splitIntoPartialAndIntermediate(variableAllocator, metadata.getFunctionManager());\n-                TableWriterNode tableWriter = new TableWriterNode(\n-                        idAllocator.getNextId(),\n-                        writerSource,\n-                        Optional.of(insertReference),\n-                        variableAllocator.newVariable(\"partialrows\", BIGINT),\n-                        variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n-                        variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n-                        outputs,\n-                        outputColumnNames,\n-                        Optional.of(partitioningScheme),\n-                        Optional.empty(),\n-                        Optional.of(localAggregations.getPartialAggregation()));\n-\n                 tableWriterMerge = new TableWriterMergeNode(\n                         idAllocator.getNextId(),\n                         gatheringExchange(\n                                 idAllocator.getNextId(),\n                                 LOCAL,\n-                                tableWriter),\n+                                new TableWriterNode(\n+                                        idAllocator.getNextId(),\n+                                        writerSource,\n+                                        Optional.of(insertReference),\n+                                        variableAllocator.newVariable(\"partialrows\", BIGINT),\n+                                        variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n+                                        variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n+                                        outputs,\n+                                        outputColumnNames,\n+                                        Optional.of(partitioningScheme),\n+                                        Optional.empty(),\n+                                        enableStatsCollectionForTemporaryTable ? Optional.of(localAggregations.getPartialAggregation()) : Optional.empty())),\n                         variableAllocator.newVariable(\"intermediaterows\", BIGINT),\n                         variableAllocator.newVariable(\"intermediatefragments\", VARBINARY),\n                         variableAllocator.newVariable(\"intermediatetablecommitcontext\", VARBINARY),\n-                        Optional.of(localAggregations.getIntermediateAggregation()));\n+                        enableStatsCollectionForTemporaryTable ? Optional.of(localAggregations.getIntermediateAggregation()) : Optional.empty());\n             }\n             else {\n                 tableWriterMerge = new TableWriterNode(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxNDAzMw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444614033", "bodyText": "nit: static import TableStatisticAggregation", "author": "arhimondr", "createdAt": "2020-06-24T02:45:57Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java", "diffHunk": "@@ -756,21 +761,28 @@ private TableFinishNode createTemporaryTableWrite(\n                         partitioningScheme);\n             }\n \n-            TableWriterNode tableWriter = new TableWriterNode(\n-                    idAllocator.getNextId(),\n-                    writerSource,\n-                    Optional.of(insertReference),\n-                    variableAllocator.newVariable(\"partialrows\", BIGINT),\n-                    variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n-                    variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n-                    outputs,\n-                    outputColumnNames,\n-                    Optional.of(partitioningScheme),\n-                    Optional.empty(),\n-                    Optional.empty());\n+            String catalogName = tableHandle.getConnectorId().getCatalogName();\n+            TableMetadata tableMetadata = metadata.getTableMetadata(session, tableHandle);\n+            TableStatisticsMetadata statisticsMetadata = metadata.getStatisticsCollectionMetadataForWrite(session, catalogName, tableMetadata.getMetadata());\n+            StatisticsAggregationPlanner.TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, true);", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\nindex bbce8da20a..766ad91f49 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n\n@@ -764,35 +794,36 @@ public class PlanFragmenter\n             String catalogName = tableHandle.getConnectorId().getCatalogName();\n             TableMetadata tableMetadata = metadata.getTableMetadata(session, tableHandle);\n             TableStatisticsMetadata statisticsMetadata = metadata.getStatisticsCollectionMetadataForWrite(session, catalogName, tableMetadata.getMetadata());\n-            StatisticsAggregationPlanner.TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, true);\n+            TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, false);\n             StatisticAggregations.Parts aggregations = statisticsResult.getAggregations().splitIntoPartialAndFinal(variableAllocator, metadata.getFunctionManager());\n             PlanNode tableWriterMerge;\n \n+            // Disabled by default. Enable when the column statistics are essential for future runtime adaptive plan optimizations\n+            boolean enableStatsCollectionForTemporaryTable = SystemSessionProperties.isEnableStatsCollectionForTemporaryTable(session);\n+\n             if (isTableWriterMergeOperatorEnabled(session)) {\n                 StatisticAggregations.Parts localAggregations = aggregations.getPartialAggregation().splitIntoPartialAndIntermediate(variableAllocator, metadata.getFunctionManager());\n-                TableWriterNode tableWriter = new TableWriterNode(\n-                        idAllocator.getNextId(),\n-                        writerSource,\n-                        Optional.of(insertReference),\n-                        variableAllocator.newVariable(\"partialrows\", BIGINT),\n-                        variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n-                        variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n-                        outputs,\n-                        outputColumnNames,\n-                        Optional.of(partitioningScheme),\n-                        Optional.empty(),\n-                        Optional.of(localAggregations.getPartialAggregation()));\n-\n                 tableWriterMerge = new TableWriterMergeNode(\n                         idAllocator.getNextId(),\n                         gatheringExchange(\n                                 idAllocator.getNextId(),\n                                 LOCAL,\n-                                tableWriter),\n+                                new TableWriterNode(\n+                                        idAllocator.getNextId(),\n+                                        writerSource,\n+                                        Optional.of(insertReference),\n+                                        variableAllocator.newVariable(\"partialrows\", BIGINT),\n+                                        variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n+                                        variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n+                                        outputs,\n+                                        outputColumnNames,\n+                                        Optional.of(partitioningScheme),\n+                                        Optional.empty(),\n+                                        enableStatsCollectionForTemporaryTable ? Optional.of(localAggregations.getPartialAggregation()) : Optional.empty())),\n                         variableAllocator.newVariable(\"intermediaterows\", BIGINT),\n                         variableAllocator.newVariable(\"intermediatefragments\", VARBINARY),\n                         variableAllocator.newVariable(\"intermediatetablecommitcontext\", VARBINARY),\n-                        Optional.of(localAggregations.getIntermediateAggregation()));\n+                        enableStatsCollectionForTemporaryTable ? Optional.of(localAggregations.getIntermediateAggregation()) : Optional.empty());\n             }\n             else {\n                 tableWriterMerge = new TableWriterNode(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDYxNDM4NA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r444614384", "bodyText": "Statistic aggregation has a non trivial cost. Please guard it with a feature flag and disable it by default.", "author": "arhimondr", "createdAt": "2020-06-24T02:47:16Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java", "diffHunk": "@@ -756,21 +761,28 @@ private TableFinishNode createTemporaryTableWrite(\n                         partitioningScheme);\n             }\n \n-            TableWriterNode tableWriter = new TableWriterNode(\n-                    idAllocator.getNextId(),\n-                    writerSource,\n-                    Optional.of(insertReference),\n-                    variableAllocator.newVariable(\"partialrows\", BIGINT),\n-                    variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n-                    variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n-                    outputs,\n-                    outputColumnNames,\n-                    Optional.of(partitioningScheme),\n-                    Optional.empty(),\n-                    Optional.empty());\n+            String catalogName = tableHandle.getConnectorId().getCatalogName();\n+            TableMetadata tableMetadata = metadata.getTableMetadata(session, tableHandle);\n+            TableStatisticsMetadata statisticsMetadata = metadata.getStatisticsCollectionMetadataForWrite(session, catalogName, tableMetadata.getMetadata());\n+            StatisticsAggregationPlanner.TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, true);", "originalCommit": "48f6a850b544c06c216136ca470a18104f3656c8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\nindex bbce8da20a..766ad91f49 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n\n@@ -764,35 +794,36 @@ public class PlanFragmenter\n             String catalogName = tableHandle.getConnectorId().getCatalogName();\n             TableMetadata tableMetadata = metadata.getTableMetadata(session, tableHandle);\n             TableStatisticsMetadata statisticsMetadata = metadata.getStatisticsCollectionMetadataForWrite(session, catalogName, tableMetadata.getMetadata());\n-            StatisticsAggregationPlanner.TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, true);\n+            TableStatisticAggregation statisticsResult = statisticsAggregationPlanner.createStatisticsAggregation(statisticsMetadata, columnNameToVariable, false);\n             StatisticAggregations.Parts aggregations = statisticsResult.getAggregations().splitIntoPartialAndFinal(variableAllocator, metadata.getFunctionManager());\n             PlanNode tableWriterMerge;\n \n+            // Disabled by default. Enable when the column statistics are essential for future runtime adaptive plan optimizations\n+            boolean enableStatsCollectionForTemporaryTable = SystemSessionProperties.isEnableStatsCollectionForTemporaryTable(session);\n+\n             if (isTableWriterMergeOperatorEnabled(session)) {\n                 StatisticAggregations.Parts localAggregations = aggregations.getPartialAggregation().splitIntoPartialAndIntermediate(variableAllocator, metadata.getFunctionManager());\n-                TableWriterNode tableWriter = new TableWriterNode(\n-                        idAllocator.getNextId(),\n-                        writerSource,\n-                        Optional.of(insertReference),\n-                        variableAllocator.newVariable(\"partialrows\", BIGINT),\n-                        variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n-                        variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n-                        outputs,\n-                        outputColumnNames,\n-                        Optional.of(partitioningScheme),\n-                        Optional.empty(),\n-                        Optional.of(localAggregations.getPartialAggregation()));\n-\n                 tableWriterMerge = new TableWriterMergeNode(\n                         idAllocator.getNextId(),\n                         gatheringExchange(\n                                 idAllocator.getNextId(),\n                                 LOCAL,\n-                                tableWriter),\n+                                new TableWriterNode(\n+                                        idAllocator.getNextId(),\n+                                        writerSource,\n+                                        Optional.of(insertReference),\n+                                        variableAllocator.newVariable(\"partialrows\", BIGINT),\n+                                        variableAllocator.newVariable(\"partialfragments\", VARBINARY),\n+                                        variableAllocator.newVariable(\"partialtablecommitcontext\", VARBINARY),\n+                                        outputs,\n+                                        outputColumnNames,\n+                                        Optional.of(partitioningScheme),\n+                                        Optional.empty(),\n+                                        enableStatsCollectionForTemporaryTable ? Optional.of(localAggregations.getPartialAggregation()) : Optional.empty())),\n                         variableAllocator.newVariable(\"intermediaterows\", BIGINT),\n                         variableAllocator.newVariable(\"intermediatefragments\", VARBINARY),\n                         variableAllocator.newVariable(\"intermediatetablecommitcontext\", VARBINARY),\n-                        Optional.of(localAggregations.getIntermediateAggregation()));\n+                        enableStatsCollectionForTemporaryTable ? Optional.of(localAggregations.getIntermediateAggregation()) : Optional.empty());\n             }\n             else {\n                 tableWriterMerge = new TableWriterNode(\n"}}, {"oid": "8e946bf8b79a9554e4531d06666d407b2f75fc68", "url": "https://github.com/prestodb/presto/commit/8e946bf8b79a9554e4531d06666d407b2f75fc68", "message": "Add a session property for runtime optimizer.", "committedDate": "2020-06-24T18:02:58Z", "type": "forcePushed"}, {"oid": "2d8982dd71765408439c704fef14f70f0b8f589b", "url": "https://github.com/prestodb/presto/commit/2d8982dd71765408439c704fef14f70f0b8f589b", "message": "Add a session property for runtime optimizer.", "committedDate": "2020-06-24T21:16:17Z", "type": "forcePushed"}, {"oid": "71d73873638956a242b64c4b52c886d81006fa2d", "url": "https://github.com/prestodb/presto/commit/71d73873638956a242b64c4b52c886d81006fa2d", "message": "Add test case for RuntimeReorderJoinSides rule.", "committedDate": "2020-06-25T14:17:38Z", "type": "forcePushed"}, {"oid": "369b6dddb2234c3c2948904bc8d66d4e017bf67a", "url": "https://github.com/prestodb/presto/commit/369b6dddb2234c3c2948904bc8d66d4e017bf67a", "message": "Add test case for RuntimeReorderJoinSides rule.", "committedDate": "2020-06-25T19:45:21Z", "type": "forcePushed"}, {"oid": "5d972ab7b85f0736d7b4bdb26569eeedf4bc93cc", "url": "https://github.com/prestodb/presto/commit/5d972ab7b85f0736d7b4bdb26569eeedf4bc93cc", "message": "Add test case for RuntimeReorderJoinSides rule.", "committedDate": "2020-06-26T15:14:53Z", "type": "forcePushed"}, {"oid": "b42a58cf861d8adaa9dcac54ec08c28858a55e0c", "url": "https://github.com/prestodb/presto/commit/b42a58cf861d8adaa9dcac54ec08c28858a55e0c", "message": "Add test case for RuntimeReorderJoinSides rule.", "committedDate": "2020-06-26T15:32:51Z", "type": "forcePushed"}, {"oid": "3c33361849cf0bf3e8df7b42bb31fef53c6995df", "url": "https://github.com/prestodb/presto/commit/3c33361849cf0bf3e8df7b42bb31fef53c6995df", "message": "Add test case for RuntimeReorderJoinSides rule.", "committedDate": "2020-06-27T04:15:17Z", "type": "forcePushed"}, {"oid": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "url": "https://github.com/prestodb/presto/commit/7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "message": "Add CBO invocation logic also in SqlQueryScheduler", "committedDate": "2020-06-30T03:45:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMzMTE5Mg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r446331192", "bodyText": "change this to something like getPlanningTimeOptimizers() (and the variable as well)", "author": "rschlussel", "createdAt": "2020-06-26T17:59:40Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/PlanOptimizers.java", "diffHunk": "@@ -557,10 +559,25 @@ public PlanOptimizers(\n         // TODO: consider adding a formal final plan sanitization optimizer that prepares the plan for transmission/execution/logging\n         // TODO: figure out how to improve the set flattening optimizer so that it can run at any point\n         this.optimizers = builder.build();\n+\n+        // Add runtime cost-based optimizers\n+        ImmutableList.Builder<PlanOptimizer> runtimeBuilder = ImmutableList.builder();\n+        runtimeBuilder.add(new IterativeOptimizer(\n+                ruleStats,\n+                statsCalculator,\n+                costCalculator,\n+                ImmutableList.of(),\n+                ImmutableSet.of(new RuntimeReorderJoinSides())));\n+        this.runtimeOptimizers = runtimeBuilder.build();\n     }\n \n     public List<PlanOptimizer> get()", "originalCommit": "6a36a2c6c2add96f4d1ef049cc32821c03c9971b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanOptimizers.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanOptimizers.java\nindex d8a79fb391..aad7cd8315 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanOptimizers.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanOptimizers.java\n\n@@ -558,7 +558,7 @@ public class PlanOptimizers\n \n         // TODO: consider adding a formal final plan sanitization optimizer that prepares the plan for transmission/execution/logging\n         // TODO: figure out how to improve the set flattening optimizer so that it can run at any point\n-        this.optimizers = builder.build();\n+        this.planningTimeOptimizers = builder.build();\n \n         // Add runtime cost-based optimizers\n         ImmutableList.Builder<PlanOptimizer> runtimeBuilder = ImmutableList.builder();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwMzU2Ng==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448303566", "bodyText": "nit: comment should be about outputSizeInBytes", "author": "rschlussel", "createdAt": "2020-07-01T11:38:22Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwODE3Mg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448308172", "bodyText": "I don't love the implicit dependency here with AddLocalExchanges because if something changes there, nobody is going to know to update this. Maybe it would be better if we just removed the local exchanges and then ran AddLocalExchanges again after this.", "author": "rschlussel", "createdAt": "2020-07-01T11:47:56Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.\n+            if (!Double.isNaN(leftOutputSizeInBytes) && !Double.isNaN(rightOutputSizeInBytes) && rightOutputSizeInBytes > leftOutputSizeInBytes) {\n+                JoinNode swapped = joinNode.flipChildren();\n+\n+                PlanNode newLeft = swapped.getLeft();\n+                PlanNode resolvedNewLeft = context.getLookup().resolve(newLeft);\n+                // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NTA5MA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448375090", "bodyText": "Discussed offline.\nAddLocalExchanges will transform all Unions into LocalExchanges, and this is why it is not viable just remove all local exchanges and add them back later on by running this AddLocalExchanges optimizer.\nInstead, we decide to let it be here, and add a sanity checker to report an error if AddLocalExchanges logic later on evolves to be different from our adjustments of the localExchanges here.", "author": "pguofb", "createdAt": "2020-07-01T13:47:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwODE3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwOTAyMg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448309022", "bodyText": "what kind of exceptions are you expecting?  I'd rather throw a Presto internal error if there were any issues, since that is likely a bug in Presto.", "author": "rschlussel", "createdAt": "2020-07-01T11:49:50Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.\n+            if (!Double.isNaN(leftOutputSizeInBytes) && !Double.isNaN(rightOutputSizeInBytes) && rightOutputSizeInBytes > leftOutputSizeInBytes) {\n+                JoinNode swapped = joinNode.flipChildren();\n+\n+                PlanNode newLeft = swapped.getLeft();\n+                PlanNode resolvedNewLeft = context.getLookup().resolve(newLeft);\n+                // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node\n+                // is a localExchange, there are two cases: an Exchange introduced by the current probe side (previous build side); or it is a UnionNode.\n+                // If the exchangeNode has more than 1 sources, it corresponds to the second case, otherwise it corresponds to the first case and safe to remove\n+                Optional<VariableReferenceExpression> leftHashVariable = swapped.getLeftHashVariable();\n+                if (resolvedNewLeft instanceof ExchangeNode && resolvedNewLeft.getSources().size() == 1) {\n+                    newLeft = resolvedNewLeft.getSources().get(0);\n+                    // The HashGenerationOptimizer will generate hashVariables and append to the output layout of the nodes following the same order. Therefore,\n+                    // we use the index of the old hashVariable in the ExchangeNode output layout to retrieve the hashVariable from the new left node, and feed\n+                    // it as the leftHashVariable of the swapped join node.\n+                    if (swapped.getLeftHashVariable().isPresent()) {\n+                        int hashVariableIndex = ((ExchangeNode) resolvedNewLeft).getPartitioningScheme().getOutputLayout().indexOf(swapped.getLeftHashVariable().get());\n+                        leftHashVariable = Optional.of(resolvedNewLeft.getSources().get(0).getOutputVariables().get(hashVariableIndex));\n+                    }\n+                }\n+\n+                // Add additional localExchange if the new build side does not satisfy the partitioning conditions.\n+                List<VariableReferenceExpression> buildJoinVariables = swapped.getCriteria().stream()\n+                        .map(JoinNode.EquiJoinClause::getRight)\n+                        .collect(toImmutableList());\n+                PlanNode newRight = swapped.getRight();\n+                if (needLocalExchange(swapped.getRight(), Optional.of(ImmutableSet.copyOf(buildJoinVariables)), context)) {\n+                    if (getTaskConcurrency(context.getSession()) > 1) {\n+                        newRight = systemPartitionedExchange(\n+                                context.getIdAllocator().getNextId(),\n+                                LOCAL,\n+                                swapped.getRight(),\n+                                buildJoinVariables,\n+                                Optional.empty());\n+                    }\n+                    else {\n+                        newRight = gatheringExchange(context.getIdAllocator().getNextId(), LOCAL, swapped.getRight());\n+                    }\n+                }\n+\n+                JoinNode newJoinNode = new JoinNode(\n+                        swapped.getId(),\n+                        swapped.getType(),\n+                        newLeft,\n+                        newRight,\n+                        swapped.getCriteria(),\n+                        swapped.getOutputVariables(),\n+                        swapped.getFilter(),\n+                        leftHashVariable,\n+                        swapped.getRightHashVariable(),\n+                        swapped.getDistributionType());\n+\n+                log.info(\"Probe size: \" + leftOutputSizeInBytes + \" is smaller than Build size: \" + rightOutputSizeInBytes + \" => invoke join swapping.\");\n+                return Result.ofPlanNode(newJoinNode);\n+            }\n+            else {\n+                return Result.empty();\n+            }\n+        }\n+        catch (Exception e) {", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwODUxMg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448708512", "bodyText": "+1", "author": "arhimondr", "createdAt": "2020-07-02T02:08:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwOTAyMg=="}], "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMxMDA0OQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448310049", "bodyText": "nit: this is a general purpose utility function (it just happens to be that right now there is only one plan optimizer)", "author": "rschlussel", "createdAt": "2020-07-01T11:52:00Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +505,182 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 1acdae1b67..bbab68ae5c 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -510,41 +508,21 @@ public class LegacySqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n-        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    // The partitioningScheme should stay the same\n-                    // even if the root's outputVariables are changed.\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMxMDgwOQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448310809", "bodyText": "I wonder if the runtime plan optimizers should operate on the whole fragment rather than just the plan. That would be so that in the future we can add optimizers that change the partitioning.  We can save that though for when we have any such optimizers.", "author": "rschlussel", "createdAt": "2020-07-01T11:53:34Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +505,182 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .map(StreamingSubPlan::getFragment)\n+                .forEach(fragment -> {\n+                    PlanNode newRoot = fragment.getRoot();\n+                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+                    }\n+                    // The partitioningScheme should stay the same\n+                    // even if the root's outputVariables are changed.", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 1acdae1b67..bbab68ae5c 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -510,41 +508,21 @@ public class LegacySqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n-        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    // The partitioningScheme should stay the same\n-                    // even if the root's outputVariables are changed.\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY0NzkyMQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448647921", "bodyText": "nit: RUNTIME_OPTIMIZER_ENABLED", "author": "arhimondr", "createdAt": "2020-07-01T22:27:00Z", "path": "presto-main/src/main/java/com/facebook/presto/SystemSessionProperties.java", "diffHunk": "@@ -119,6 +119,7 @@\n     public static final String LEGACY_MAP_SUBSCRIPT = \"do_not_use_legacy_map_subscript\";\n     public static final String ITERATIVE_OPTIMIZER = \"iterative_optimizer_enabled\";\n     public static final String ITERATIVE_OPTIMIZER_TIMEOUT = \"iterative_optimizer_timeout\";\n+    public static final String RUNTIME_OPTIMIZER = \"runtime_optimizer_enabled\";", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/SystemSessionProperties.java b/presto-main/src/main/java/com/facebook/presto/SystemSessionProperties.java\nindex e115769b65..6e7f45bf84 100644\n--- a/presto-main/src/main/java/com/facebook/presto/SystemSessionProperties.java\n+++ b/presto-main/src/main/java/com/facebook/presto/SystemSessionProperties.java\n\n@@ -119,7 +119,7 @@ public final class SystemSessionProperties\n     public static final String LEGACY_MAP_SUBSCRIPT = \"do_not_use_legacy_map_subscript\";\n     public static final String ITERATIVE_OPTIMIZER = \"iterative_optimizer_enabled\";\n     public static final String ITERATIVE_OPTIMIZER_TIMEOUT = \"iterative_optimizer_timeout\";\n-    public static final String RUNTIME_OPTIMIZER = \"runtime_optimizer_enabled\";\n+    public static final String RUNTIME_OPTIMIZER_ENABLED = \"runtime_optimizer_enabled\";\n     public static final String EXCHANGE_COMPRESSION = \"exchange_compression\";\n     public static final String LEGACY_TIMESTAMP = \"legacy_timestamp\";\n     public static final String ENABLE_INTERMEDIATE_AGGREGATIONS = \"enable_intermediate_aggregations\";\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY0ODE1MQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448648151", "bodyText": "let's keep it off by default", "author": "arhimondr", "createdAt": "2020-07-01T22:27:44Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/analyzer/FeaturesConfig.java", "diffHunk": "@@ -116,6 +116,7 @@\n     private int spillerThreads = 4;\n     private double spillMaxUsedSpaceThreshold = 0.9;\n     private boolean iterativeOptimizerEnabled = true;\n+    private boolean runtimeOptimizerEnabled = true;", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/analyzer/FeaturesConfig.java b/presto-main/src/main/java/com/facebook/presto/sql/analyzer/FeaturesConfig.java\nindex 8122814fa6..5acb166b09 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/analyzer/FeaturesConfig.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/analyzer/FeaturesConfig.java\n\n@@ -116,7 +116,7 @@ public class FeaturesConfig\n     private int spillerThreads = 4;\n     private double spillMaxUsedSpaceThreshold = 0.9;\n     private boolean iterativeOptimizerEnabled = true;\n-    private boolean runtimeOptimizerEnabled = true;\n+    private boolean runtimeOptimizerEnabled;\n     private boolean enableStatsCalculator = true;\n     private boolean enableStatsCollectionForTemporaryTable;\n     private boolean ignoreStatsCalculatorFailures = true;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwNjk1Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448706953", "bodyText": "This code looks a little bit weird. How about instead of returning SubPlanAndVariableAllocator you pass the PlanVariableAllocator (similar to the PlanNodeIdAllocator)", "author": "arhimondr", "createdAt": "2020-07-02T02:01:15Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java", "diffHunk": "@@ -162,6 +162,12 @@ public PlanFragmenter(Metadata metadata, NodePartitioningManager nodePartitionin\n \n     public SubPlan createSubPlans(Session session, Plan plan, boolean forceSingleNode, PlanNodeIdAllocator idAllocator, WarningCollector warningCollector)\n     {\n+        return createSubPlansAndVariableAllocator(session, plan, forceSingleNode, idAllocator, warningCollector).getPlan();\n+    }\n+\n+    public SubPlanAndVariableAllocator createSubPlansAndVariableAllocator(Session session, Plan plan, boolean forceSingleNode, PlanNodeIdAllocator idAllocator, WarningCollector warningCollector)", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\nindex 766ad91f49..8f5cdeff0b 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanFragmenter.java\n\n@@ -162,12 +162,12 @@ public class PlanFragmenter\n \n     public SubPlan createSubPlans(Session session, Plan plan, boolean forceSingleNode, PlanNodeIdAllocator idAllocator, WarningCollector warningCollector)\n     {\n-        return createSubPlansAndVariableAllocator(session, plan, forceSingleNode, idAllocator, warningCollector).getPlan();\n+        PlanVariableAllocator variableAllocator = new PlanVariableAllocator(plan.getTypes().allVariables());\n+        return createSubPlans(session, plan, forceSingleNode, idAllocator, variableAllocator, warningCollector);\n     }\n \n-    public SubPlanAndVariableAllocator createSubPlansAndVariableAllocator(Session session, Plan plan, boolean forceSingleNode, PlanNodeIdAllocator idAllocator, WarningCollector warningCollector)\n+    public SubPlan createSubPlans(Session session, Plan plan, boolean forceSingleNode, PlanNodeIdAllocator idAllocator, PlanVariableAllocator variableAllocator, WarningCollector warningCollector)\n     {\n-        PlanVariableAllocator variableAllocator = new PlanVariableAllocator(plan.getTypes().allVariables());\n         Fragmenter fragmenter = new Fragmenter(\n                 session,\n                 metadata,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwNzM0Nw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448707347", "bodyText": "Why is this change needed? Why wasn't it needed before? If this is an independent optimization it feels like it is worth to extract it into a separate commit.", "author": "arhimondr", "createdAt": "2020-07-02T02:02:58Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/IterativeOptimizer.java", "diffHunk": "@@ -92,8 +92,10 @@ public PlanNode optimize(PlanNode plan, Session session, TypeProvider types, Pla\n \n         Duration timeout = SystemSessionProperties.getOptimizerTimeout(session);\n         Context context = new Context(memo, lookup, idAllocator, variableAllocator, System.nanoTime(), timeout.toMillis(), session, warningCollector);\n-        exploreGroup(memo.getRootGroup(), context, matcher);\n-\n+        boolean planChanged = exploreGroup(memo.getRootGroup(), context, matcher);", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcyODA1OQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448728059", "bodyText": "I'm not sure if there are hidden reasons, but I suppose the reason that this is not needed previously is that the logicalPlanner does not care if a plan is actually rewritten or not by a specific rule, as long as the plan pass all the rules and finally become stable.\nNow, for runtime optimization, we do care about whether the plan is actually rewritten or not. Because If not, we won't bother re-generating all the involved stageExecutionAndSchedulers, etc. Therefore, we make this change here so that if the plan is not actually rewritten, the original reference is returned, instead of a new identical plan. Doing so, we can easily tell (outside of iterativeOptimizer) if the returnedPlan is the unchanged by simply comparing the references.", "author": "pguofb", "createdAt": "2020-07-02T03:29:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwNzM0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "76f74999c411b559acc712f29fe4b89c08d7b119", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/IterativeOptimizer.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/IterativeOptimizer.java\nindex f17de5e324..aeda50f8de 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/IterativeOptimizer.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/IterativeOptimizer.java\n\n@@ -92,10 +92,8 @@ public class IterativeOptimizer\n \n         Duration timeout = SystemSessionProperties.getOptimizerTimeout(session);\n         Context context = new Context(memo, lookup, idAllocator, variableAllocator, System.nanoTime(), timeout.toMillis(), session, warningCollector);\n-        boolean planChanged = exploreGroup(memo.getRootGroup(), context, matcher);\n-        if (!planChanged) {\n-            return plan;\n-        }\n+        exploreGroup(memo.getRootGroup(), context, matcher);\n+\n         return memo.extract();\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcwNzY2OQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448707669", "bodyText": "Should we exist when at least one of the join inputs is not a table scan?", "author": "arhimondr", "createdAt": "2020-07-02T02:04:31Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMDU2Nw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448710567", "bodyText": "We should provide a hash column here if one is present", "author": "arhimondr", "createdAt": "2020-07-02T02:16:23Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.\n+            if (!Double.isNaN(leftOutputSizeInBytes) && !Double.isNaN(rightOutputSizeInBytes) && rightOutputSizeInBytes > leftOutputSizeInBytes) {\n+                JoinNode swapped = joinNode.flipChildren();\n+\n+                PlanNode newLeft = swapped.getLeft();\n+                PlanNode resolvedNewLeft = context.getLookup().resolve(newLeft);\n+                // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node\n+                // is a localExchange, there are two cases: an Exchange introduced by the current probe side (previous build side); or it is a UnionNode.\n+                // If the exchangeNode has more than 1 sources, it corresponds to the second case, otherwise it corresponds to the first case and safe to remove\n+                Optional<VariableReferenceExpression> leftHashVariable = swapped.getLeftHashVariable();\n+                if (resolvedNewLeft instanceof ExchangeNode && resolvedNewLeft.getSources().size() == 1) {\n+                    newLeft = resolvedNewLeft.getSources().get(0);\n+                    // The HashGenerationOptimizer will generate hashVariables and append to the output layout of the nodes following the same order. Therefore,\n+                    // we use the index of the old hashVariable in the ExchangeNode output layout to retrieve the hashVariable from the new left node, and feed\n+                    // it as the leftHashVariable of the swapped join node.\n+                    if (swapped.getLeftHashVariable().isPresent()) {\n+                        int hashVariableIndex = ((ExchangeNode) resolvedNewLeft).getPartitioningScheme().getOutputLayout().indexOf(swapped.getLeftHashVariable().get());\n+                        leftHashVariable = Optional.of(resolvedNewLeft.getSources().get(0).getOutputVariables().get(hashVariableIndex));\n+                    }\n+                }\n+\n+                // Add additional localExchange if the new build side does not satisfy the partitioning conditions.\n+                List<VariableReferenceExpression> buildJoinVariables = swapped.getCriteria().stream()\n+                        .map(JoinNode.EquiJoinClause::getRight)\n+                        .collect(toImmutableList());\n+                PlanNode newRight = swapped.getRight();\n+                if (needLocalExchange(swapped.getRight(), Optional.of(ImmutableSet.copyOf(buildJoinVariables)), context)) {\n+                    if (getTaskConcurrency(context.getSession()) > 1) {\n+                        newRight = systemPartitionedExchange(\n+                                context.getIdAllocator().getNextId(),\n+                                LOCAL,\n+                                swapped.getRight(),\n+                                buildJoinVariables,\n+                                Optional.empty());", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMDY4MA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448710680", "bodyText": "debug", "author": "arhimondr", "createdAt": "2020-07-02T02:16:47Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.\n+            if (!Double.isNaN(leftOutputSizeInBytes) && !Double.isNaN(rightOutputSizeInBytes) && rightOutputSizeInBytes > leftOutputSizeInBytes) {\n+                JoinNode swapped = joinNode.flipChildren();\n+\n+                PlanNode newLeft = swapped.getLeft();\n+                PlanNode resolvedNewLeft = context.getLookup().resolve(newLeft);\n+                // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node\n+                // is a localExchange, there are two cases: an Exchange introduced by the current probe side (previous build side); or it is a UnionNode.\n+                // If the exchangeNode has more than 1 sources, it corresponds to the second case, otherwise it corresponds to the first case and safe to remove\n+                Optional<VariableReferenceExpression> leftHashVariable = swapped.getLeftHashVariable();\n+                if (resolvedNewLeft instanceof ExchangeNode && resolvedNewLeft.getSources().size() == 1) {\n+                    newLeft = resolvedNewLeft.getSources().get(0);\n+                    // The HashGenerationOptimizer will generate hashVariables and append to the output layout of the nodes following the same order. Therefore,\n+                    // we use the index of the old hashVariable in the ExchangeNode output layout to retrieve the hashVariable from the new left node, and feed\n+                    // it as the leftHashVariable of the swapped join node.\n+                    if (swapped.getLeftHashVariable().isPresent()) {\n+                        int hashVariableIndex = ((ExchangeNode) resolvedNewLeft).getPartitioningScheme().getOutputLayout().indexOf(swapped.getLeftHashVariable().get());\n+                        leftHashVariable = Optional.of(resolvedNewLeft.getSources().get(0).getOutputVariables().get(hashVariableIndex));\n+                    }\n+                }\n+\n+                // Add additional localExchange if the new build side does not satisfy the partitioning conditions.\n+                List<VariableReferenceExpression> buildJoinVariables = swapped.getCriteria().stream()\n+                        .map(JoinNode.EquiJoinClause::getRight)\n+                        .collect(toImmutableList());\n+                PlanNode newRight = swapped.getRight();\n+                if (needLocalExchange(swapped.getRight(), Optional.of(ImmutableSet.copyOf(buildJoinVariables)), context)) {\n+                    if (getTaskConcurrency(context.getSession()) > 1) {\n+                        newRight = systemPartitionedExchange(\n+                                context.getIdAllocator().getNextId(),\n+                                LOCAL,\n+                                swapped.getRight(),\n+                                buildJoinVariables,\n+                                Optional.empty());\n+                    }\n+                    else {\n+                        newRight = gatheringExchange(context.getIdAllocator().getNextId(), LOCAL, swapped.getRight());\n+                    }\n+                }\n+\n+                JoinNode newJoinNode = new JoinNode(\n+                        swapped.getId(),\n+                        swapped.getType(),\n+                        newLeft,\n+                        newRight,\n+                        swapped.getCriteria(),\n+                        swapped.getOutputVariables(),\n+                        swapped.getFilter(),\n+                        leftHashVariable,\n+                        swapped.getRightHashVariable(),\n+                        swapped.getDistributionType());\n+\n+                log.info(\"Probe size: \" + leftOutputSizeInBytes + \" is smaller than Build size: \" + rightOutputSizeInBytes + \" => invoke join swapping.\");", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMTA2NA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448711064", "bodyText": "To avoid this nesting i would rewrite it to something like this\nif(Double.isNaN(leftOutputSizeInBytes) || Double.isNaN(rightOutputSizeInBytes)){\nreturn empty\n}\nif(leftOutputSizeInBytes > rightOutputSizeInBytes){\nreturn empty\n}\n...", "author": "arhimondr", "createdAt": "2020-07-02T02:18:28Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.\n+            if (!Double.isNaN(leftOutputSizeInBytes) && !Double.isNaN(rightOutputSizeInBytes) && rightOutputSizeInBytes > leftOutputSizeInBytes) {\n+                JoinNode swapped = joinNode.flipChildren();\n+\n+                PlanNode newLeft = swapped.getLeft();\n+                PlanNode resolvedNewLeft = context.getLookup().resolve(newLeft);\n+                // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node\n+                // is a localExchange, there are two cases: an Exchange introduced by the current probe side (previous build side); or it is a UnionNode.\n+                // If the exchangeNode has more than 1 sources, it corresponds to the second case, otherwise it corresponds to the first case and safe to remove\n+                Optional<VariableReferenceExpression> leftHashVariable = swapped.getLeftHashVariable();\n+                if (resolvedNewLeft instanceof ExchangeNode && resolvedNewLeft.getSources().size() == 1) {\n+                    newLeft = resolvedNewLeft.getSources().get(0);\n+                    // The HashGenerationOptimizer will generate hashVariables and append to the output layout of the nodes following the same order. Therefore,\n+                    // we use the index of the old hashVariable in the ExchangeNode output layout to retrieve the hashVariable from the new left node, and feed\n+                    // it as the leftHashVariable of the swapped join node.\n+                    if (swapped.getLeftHashVariable().isPresent()) {\n+                        int hashVariableIndex = ((ExchangeNode) resolvedNewLeft).getPartitioningScheme().getOutputLayout().indexOf(swapped.getLeftHashVariable().get());\n+                        leftHashVariable = Optional.of(resolvedNewLeft.getSources().get(0).getOutputVariables().get(hashVariableIndex));\n+                    }\n+                }\n+\n+                // Add additional localExchange if the new build side does not satisfy the partitioning conditions.\n+                List<VariableReferenceExpression> buildJoinVariables = swapped.getCriteria().stream()\n+                        .map(JoinNode.EquiJoinClause::getRight)\n+                        .collect(toImmutableList());\n+                PlanNode newRight = swapped.getRight();\n+                if (needLocalExchange(swapped.getRight(), Optional.of(ImmutableSet.copyOf(buildJoinVariables)), context)) {\n+                    if (getTaskConcurrency(context.getSession()) > 1) {\n+                        newRight = systemPartitionedExchange(\n+                                context.getIdAllocator().getNextId(),\n+                                LOCAL,\n+                                swapped.getRight(),\n+                                buildJoinVariables,\n+                                Optional.empty());\n+                    }\n+                    else {\n+                        newRight = gatheringExchange(context.getIdAllocator().getNextId(), LOCAL, swapped.getRight());\n+                    }\n+                }\n+\n+                JoinNode newJoinNode = new JoinNode(\n+                        swapped.getId(),\n+                        swapped.getType(),\n+                        newLeft,\n+                        newRight,\n+                        swapped.getCriteria(),\n+                        swapped.getOutputVariables(),\n+                        swapped.getFilter(),\n+                        leftHashVariable,\n+                        swapped.getRightHashVariable(),\n+                        swapped.getDistributionType());\n+\n+                log.info(\"Probe size: \" + leftOutputSizeInBytes + \" is smaller than Build size: \" + rightOutputSizeInBytes + \" => invoke join swapping.\");\n+                return Result.ofPlanNode(newJoinNode);\n+            }\n+            else {\n+                return Result.empty();", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjEwMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448712100", "bodyText": "I simplified this part. And it become\nreturn partitioningColumns.isPresent() || ((ExchangeNode) actual).getType() != ExchangeNode.Type.GATHER;\n\nShouldn't it be partitioningColumns.isPresent() && ((ExchangeNode) actual).getType() != ExchangeNode.Type.GATHER;?", "author": "arhimondr", "createdAt": "2020-07-02T02:23:03Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.PrestoWarning;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.spi.StandardWarningCode.PERFORMANCE_WARNING;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.Streams.stream;\n+import static com.google.common.graph.Traverser.forTree;\n+import static java.lang.String.format;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        try {\n+            // Early exit if the leaves of the joinNode subtree do not include table scan.\n+            if (stream(forTree(node -> context.getLookup().resolve((PlanNode) node).getSources()).depthFirstPreOrder(joinNode))\n+                    .noneMatch(child -> context.getLookup().resolve((PlanNode) child) instanceof TableScanNode)) {\n+                return Result.empty();\n+            }\n+            StatsProvider statsProvider = context.getStatsProvider();\n+            double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+            double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+\n+            // Only swap join sides when outputRowCount is available for both sides.\n+            if (!Double.isNaN(leftOutputSizeInBytes) && !Double.isNaN(rightOutputSizeInBytes) && rightOutputSizeInBytes > leftOutputSizeInBytes) {\n+                JoinNode swapped = joinNode.flipChildren();\n+\n+                PlanNode newLeft = swapped.getLeft();\n+                PlanNode resolvedNewLeft = context.getLookup().resolve(newLeft);\n+                // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node\n+                // is a localExchange, there are two cases: an Exchange introduced by the current probe side (previous build side); or it is a UnionNode.\n+                // If the exchangeNode has more than 1 sources, it corresponds to the second case, otherwise it corresponds to the first case and safe to remove\n+                Optional<VariableReferenceExpression> leftHashVariable = swapped.getLeftHashVariable();\n+                if (resolvedNewLeft instanceof ExchangeNode && resolvedNewLeft.getSources().size() == 1) {\n+                    newLeft = resolvedNewLeft.getSources().get(0);\n+                    // The HashGenerationOptimizer will generate hashVariables and append to the output layout of the nodes following the same order. Therefore,\n+                    // we use the index of the old hashVariable in the ExchangeNode output layout to retrieve the hashVariable from the new left node, and feed\n+                    // it as the leftHashVariable of the swapped join node.\n+                    if (swapped.getLeftHashVariable().isPresent()) {\n+                        int hashVariableIndex = ((ExchangeNode) resolvedNewLeft).getPartitioningScheme().getOutputLayout().indexOf(swapped.getLeftHashVariable().get());\n+                        leftHashVariable = Optional.of(resolvedNewLeft.getSources().get(0).getOutputVariables().get(hashVariableIndex));\n+                    }\n+                }\n+\n+                // Add additional localExchange if the new build side does not satisfy the partitioning conditions.\n+                List<VariableReferenceExpression> buildJoinVariables = swapped.getCriteria().stream()\n+                        .map(JoinNode.EquiJoinClause::getRight)\n+                        .collect(toImmutableList());\n+                PlanNode newRight = swapped.getRight();\n+                if (needLocalExchange(swapped.getRight(), Optional.of(ImmutableSet.copyOf(buildJoinVariables)), context)) {\n+                    if (getTaskConcurrency(context.getSession()) > 1) {\n+                        newRight = systemPartitionedExchange(\n+                                context.getIdAllocator().getNextId(),\n+                                LOCAL,\n+                                swapped.getRight(),\n+                                buildJoinVariables,\n+                                Optional.empty());\n+                    }\n+                    else {\n+                        newRight = gatheringExchange(context.getIdAllocator().getNextId(), LOCAL, swapped.getRight());\n+                    }\n+                }\n+\n+                JoinNode newJoinNode = new JoinNode(\n+                        swapped.getId(),\n+                        swapped.getType(),\n+                        newLeft,\n+                        newRight,\n+                        swapped.getCriteria(),\n+                        swapped.getOutputVariables(),\n+                        swapped.getFilter(),\n+                        leftHashVariable,\n+                        swapped.getRightHashVariable(),\n+                        swapped.getDistributionType());\n+\n+                log.info(\"Probe size: \" + leftOutputSizeInBytes + \" is smaller than Build size: \" + rightOutputSizeInBytes + \" => invoke join swapping.\");\n+                return Result.ofPlanNode(newJoinNode);\n+            }\n+            else {\n+                return Result.empty();\n+            }\n+        }\n+        catch (Exception e) {\n+            log.error(format(\"Runtime join reordering of joinNode (%s) failed, due to (%s).\", joinNode.getId(), e.getMessage()));\n+            context.getWarningCollector().add(new PrestoWarning(PERFORMANCE_WARNING,\n+                    format(\"Runtime join reordering of joinNode (%s) failed, due to (%s).\", joinNode.getId(), e.getMessage())));\n+            return Result.empty();\n+        }\n+    }\n+\n+    private boolean needLocalExchange(PlanNode root, Optional<Set<VariableReferenceExpression>> partitioningColumns, Context context)\n+    {\n+        PlanNode actual = context.getLookup().resolve(root);\n+        if (actual instanceof ExchangeNode) {\n+            if (partitioningColumns.isPresent() && ((ExchangeNode) actual).getPartitioningScheme().getPartitioning().getVariableReferences().containsAll(partitioningColumns.get())) {\n+                return false;\n+            }\n+            // when taskParallelism equals to 1\n+            else if (!partitioningColumns.isPresent() && ((ExchangeNode) actual).getType() == ExchangeNode.Type.GATHER) {", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTAzNDQyOQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r449034429", "bodyText": "If this line is reached and there are partitioningColumns required by parent, it basically means the current exchange node's partitioning does not match the requirement from the parent join. And so, no matter if the current one is GATHER or partitioned, we will need to add an exchange. So, I think || makes more sense.", "author": "pguofb", "createdAt": "2020-07-02T14:16:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTEyMjk2OA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r449122968", "bodyText": "But if the current is gather, why do we need to repartition it? If the planner decided that the gather exchange is required?", "author": "arhimondr", "createdAt": "2020-07-02T16:07:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE0MDM3Ng==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r449140376", "bodyText": "A made-up example: Suppose Join's build-side op chain is ... -> [GATHER] -> Sort -> Join. In this case, the join would like partitioned parallel streams for build side (per the TaskParallelism config), but the data is single stream after Sort[/or some other ops requiring single stream]?", "author": "pguofb", "createdAt": "2020-07-02T16:37:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE2MzY2Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r449163663", "bodyText": "I don't think it is possible in practice.\n@rschlussel what do you think?", "author": "arhimondr", "createdAt": "2020-07-02T17:19:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE2ODUxMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r449168510", "bodyText": "Ok, if it is not possible to see Ops needing repartition from a single stream (namely single stream ops will always sit around the root of a stage), then I agree using && makes more sense.", "author": "pguofb", "createdAt": "2020-07-02T17:29:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjEwMA=="}], "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 3161e6ee4f..959708fff6 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -18,7 +18,6 @@ import com.facebook.airlift.log.Logger;\n import com.facebook.presto.cost.StatsProvider;\n import com.facebook.presto.matching.Captures;\n import com.facebook.presto.matching.Pattern;\n-import com.facebook.presto.spi.PrestoWarning;\n import com.facebook.presto.spi.plan.PlanNode;\n import com.facebook.presto.spi.plan.TableScanNode;\n import com.facebook.presto.spi.relation.VariableReferenceExpression;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjI2OA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448712268", "bodyText": "please nullify the remaining fields.", "author": "arhimondr", "createdAt": "2020-07-02T02:23:54Z", "path": "presto-main/src/test/java/com/facebook/presto/sql/planner/iterative/rule/TestRuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.presto.common.predicate.TupleDomain;\n+import com.facebook.presto.cost.PlanNodeStatsEstimate;\n+import com.facebook.presto.cost.VariableStatsEstimate;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorId;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.rule.test.RuleAssert;\n+import com.facebook.presto.sql.planner.iterative.rule.test.RuleTester;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.facebook.presto.testing.TestingTransactionHandle;\n+import com.facebook.presto.tpch.TpchColumnHandle;\n+import com.facebook.presto.tpch.TpchTableHandle;\n+import com.facebook.presto.tpch.TpchTableLayoutHandle;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.common.type.BigintType.BIGINT;\n+import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.equiJoinClause;\n+import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.exchange;\n+import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.join;\n+import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.tableScan;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.Type.INNER;\n+\n+@Test(singleThreaded = true)\n+public class TestRuntimeReorderJoinSides\n+{\n+    private static final int NODES_COUNT = 4;\n+    private RuleTester tester;\n+    private TableHandle nationTableHandle;\n+    private TableHandle supplierTableHandle;\n+    private ColumnHandle nationColumnHandle;\n+    private ColumnHandle suppColumnHandle;\n+    private ConnectorId connectorId;\n+\n+    @BeforeClass\n+    public void setUp()\n+    {\n+        tester = new RuleTester(ImmutableList.of(), ImmutableMap.of(), Optional.of(NODES_COUNT));\n+        connectorId = tester.getCurrentConnectorId();\n+\n+        TpchTableHandle nationTpchTableHandle = new TpchTableHandle(\"nation\", 1.0);\n+        TpchTableHandle supplierTpchTableHandle = new TpchTableHandle(\"supplier\", 1.0);\n+\n+        nationTableHandle = new TableHandle(\n+                connectorId,\n+                nationTpchTableHandle,\n+                TestingTransactionHandle.create(),\n+                Optional.of(new TpchTableLayoutHandle(nationTpchTableHandle, TupleDomain.all())));\n+        supplierTableHandle = new TableHandle(\n+                connectorId,\n+                supplierTpchTableHandle,\n+                TestingTransactionHandle.create(),\n+                Optional.of(new TpchTableLayoutHandle(supplierTpchTableHandle, TupleDomain.all())));\n+\n+        nationColumnHandle = new TpchColumnHandle(\"nationkey\", BIGINT);\n+        suppColumnHandle = new TpchColumnHandle(\"suppkey\", BIGINT);\n+    }\n+\n+    @AfterClass(alwaysRun = true)\n+    public void tearDown()\n+    {\n+        tester.close();\n+        tester = null;", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/test/java/com/facebook/presto/sql/planner/iterative/rule/TestRuntimeReorderJoinSides.java b/presto-main/src/test/java/com/facebook/presto/sql/planner/iterative/rule/TestRuntimeReorderJoinSides.java\nindex d1332c3af8..65a1dc2bb1 100644\n--- a/presto-main/src/test/java/com/facebook/presto/sql/planner/iterative/rule/TestRuntimeReorderJoinSides.java\n+++ b/presto-main/src/test/java/com/facebook/presto/sql/planner/iterative/rule/TestRuntimeReorderJoinSides.java\n\n@@ -45,7 +45,10 @@ import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.equiJo\n import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.exchange;\n import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.join;\n import static com.facebook.presto.sql.planner.assertions.PlanMatchPattern.tableScan;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.DistributionType.PARTITIONED;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.DistributionType.REPLICATED;\n import static com.facebook.presto.sql.planner.plan.JoinNode.Type.INNER;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.Type.LEFT;\n \n @Test(singleThreaded = true)\n public class TestRuntimeReorderJoinSides\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjYwMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448712600", "bodyText": "nit: let's group both, the PlanNodeIdAllocator  and the PlanVariableAllocator together", "author": "arhimondr", "createdAt": "2020-07-02T02:25:05Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -130,7 +148,11 @@ public static SqlQueryScheduler createSqlQueryScheduler(\n             Session session,\n             QueryStateMachine queryStateMachine,\n             SubPlan plan,\n-            boolean summarizeTaskInfo)\n+            boolean summarizeTaskInfo,\n+            List<PlanOptimizer> runtimePlanOptimizers,\n+            PlanNodeIdAllocator idAllocator,", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..2648611177 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -150,8 +148,8 @@ public class SqlQueryScheduler\n             SubPlan plan,\n             boolean summarizeTaskInfo,\n             List<PlanOptimizer> runtimePlanOptimizers,\n-            PlanNodeIdAllocator idAllocator,\n             WarningCollector warningCollector,\n+            PlanNodeIdAllocator idAllocator,\n             PlanVariableAllocator variableAllocator)\n     {\n         SqlQueryScheduler sqlQueryScheduler = new SqlQueryScheduler(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMjk1Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448712953", "bodyText": "I wonder if it makes much sense to support the LegacySqlQueryScheduler since we are going to retire it?", "author": "arhimondr", "createdAt": "2020-07-02T02:26:25Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -14,6 +14,7 @@\n package com.facebook.presto.execution.scheduler;\n \n import com.facebook.airlift.concurrent.SetThreadName;\n+import com.facebook.airlift.log.Logger;", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "76f74999c411b559acc712f29fe4b89c08d7b119", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 1acdae1b67..ceacc02d7e 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -14,7 +14,6 @@\n package com.facebook.presto.execution.scheduler;\n \n import com.facebook.airlift.concurrent.SetThreadName;\n-import com.facebook.airlift.log.Logger;\n import com.facebook.airlift.stats.TimeStat;\n import com.facebook.presto.Session;\n import com.facebook.presto.execution.BasicStageExecutionStats;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMzY0Nw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448713647", "bodyText": "Making this mutable is likely to break the statistics on the UI / CLI", "author": "arhimondr", "createdAt": "2020-07-02T02:29:12Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -173,7 +203,11 @@ private SqlQueryScheduler(\n         this.nodeManager = requireNonNull(nodeManager, \"nodeManager is null\");\n         this.session = requireNonNull(session, \"session is null\");\n         this.queryStateMachine = requireNonNull(queryStateMachine, \"queryStateMachine is null\");\n-        this.plan = requireNonNull(plan, \"plan is null\");\n+        this.runtimePlanOptimizers = requireNonNull(runtimePlanOptimizers, \"runtimePlanOptimizers is null\");\n+        this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        this.warningCollector = requireNonNull(warningCollector, \"warningCollector is null\");\n+        this.variableAllocator = requireNonNull(variableAllocator, \"variableAllocator is null\");\n+        this.plan.compareAndSet(null, requireNonNull(plan, \"plan is null\"));", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..2648611177 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -204,8 +202,8 @@ public class SqlQueryScheduler\n         this.session = requireNonNull(session, \"session is null\");\n         this.queryStateMachine = requireNonNull(queryStateMachine, \"queryStateMachine is null\");\n         this.runtimePlanOptimizers = requireNonNull(runtimePlanOptimizers, \"runtimePlanOptimizers is null\");\n-        this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n         this.warningCollector = requireNonNull(warningCollector, \"warningCollector is null\");\n+        this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n         this.variableAllocator = requireNonNull(variableAllocator, \"variableAllocator is null\");\n         this.plan.compareAndSet(null, requireNonNull(plan, \"plan is null\"));\n         this.sectionedPlan = extractStreamingSections(plan);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxMzg1OA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448713858", "bodyText": "Let's put .map(this::tryCostBasedOptimize) and .collect(toImmutableList())) on the new line each", "author": "arhimondr", "createdAt": "2020-07-02T02:30:02Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -235,7 +269,8 @@ private void schedule()\n                     break;\n                 }\n \n-                List<SectionExecution> sectionExecutions = createStageExecutions(sectionsReadyForExecution);\n+                // Apply runtime CBO on the ready sections before creating SectionExecutions.\n+                List<SectionExecution> sectionExecutions = createStageExecutions(sectionsReadyForExecution.stream().map(this::tryCostBasedOptimize).collect(toImmutableList()));", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..2648611177 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -270,7 +268,9 @@ public class SqlQueryScheduler\n                 }\n \n                 // Apply runtime CBO on the ready sections before creating SectionExecutions.\n-                List<SectionExecution> sectionExecutions = createStageExecutions(sectionsReadyForExecution.stream().map(this::tryCostBasedOptimize).collect(toImmutableList()));\n+                List<SectionExecution> sectionExecutions = createStageExecutions(sectionsReadyForExecution.stream()\n+                        .map(this::tryCostBasedOptimize)\n+                        .collect(toImmutableList()));\n                 if (queryStateMachine.isDone()) {\n                     sectionExecutions.forEach(SectionExecution::abort);\n                 }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxNDA2Mg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448714062", "bodyText": "debug", "author": "arhimondr", "createdAt": "2020-07-02T02:30:50Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -361,6 +396,86 @@ else if (!result.getBlocked().isDone()) {\n         }\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .map(StreamingSubPlan::getFragment)\n+                .forEach(fragment -> {\n+                    PlanNode newRoot = fragment.getRoot();\n+                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+                    }\n+                    if (newRoot != fragment.getRoot()) {\n+                        oldToNewFragment.put(fragment, new PlanFragment(\n+                                fragment.getId(),\n+                                newRoot,\n+                                fragment.getVariables(),\n+                                fragment.getPartitioning(),\n+                                scheduleOrder(newRoot),\n+                                fragment.getPartitioningScheme(),\n+                                fragment.getStageExecutionDescriptor(),\n+                                fragment.isOutputTableWriterFragment(),\n+                                fragment.getStatsAndCosts(),\n+                                fragment.getJsonRepresentation()));\n+                    }\n+                });\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        log.info(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream().map(PlanFragment::getId).map(PlanFragmentId::toString).collect(Collectors.joining(\", \")));", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..2648611177 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -397,39 +397,21 @@ public class SqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n         // Apply runtime optimization on each StreamingSubPlan's fragment\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxNDIyMw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448714223", "bodyText": "ImmutableList.builder()", "author": "arhimondr", "createdAt": "2020-07-02T02:31:24Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -361,6 +396,86 @@ else if (!result.getBlocked().isDone()) {\n         }\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .map(StreamingSubPlan::getFragment)\n+                .forEach(fragment -> {\n+                    PlanNode newRoot = fragment.getRoot();\n+                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+                    }\n+                    if (newRoot != fragment.getRoot()) {\n+                        oldToNewFragment.put(fragment, new PlanFragment(\n+                                fragment.getId(),\n+                                newRoot,\n+                                fragment.getVariables(),\n+                                fragment.getPartitioning(),\n+                                scheduleOrder(newRoot),\n+                                fragment.getPartitioningScheme(),\n+                                fragment.getStageExecutionDescriptor(),\n+                                fragment.isOutputTableWriterFragment(),\n+                                fragment.getStatsAndCosts(),\n+                                fragment.getJsonRepresentation()));\n+                    }\n+                });\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        log.info(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream().map(PlanFragment::getId).map(PlanFragmentId::toString).collect(Collectors.joining(\", \")));\n+        return new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());\n+    }\n+\n+    private void updatePlan(Map<PlanFragment, PlanFragment> oldToNewFragments)\n+    {\n+        plan.getAndUpdate(value -> rewritePlan(value, oldToNewFragments));\n+    }\n+\n+    private SubPlan rewritePlan(SubPlan root, Map<PlanFragment, PlanFragment> oldToNewFragments)\n+    {\n+        List<SubPlan> children = new ArrayList<>();", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..2648611177 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -397,39 +397,21 @@ public class SqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n         // Apply runtime optimization on each StreamingSubPlan's fragment\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxNDI2Nw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448714267", "bodyText": "ImmutableList.builder", "author": "arhimondr", "createdAt": "2020-07-02T02:31:37Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -361,6 +396,86 @@ else if (!result.getBlocked().isDone()) {\n         }\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .map(StreamingSubPlan::getFragment)\n+                .forEach(fragment -> {\n+                    PlanNode newRoot = fragment.getRoot();\n+                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+                    }\n+                    if (newRoot != fragment.getRoot()) {\n+                        oldToNewFragment.put(fragment, new PlanFragment(\n+                                fragment.getId(),\n+                                newRoot,\n+                                fragment.getVariables(),\n+                                fragment.getPartitioning(),\n+                                scheduleOrder(newRoot),\n+                                fragment.getPartitioningScheme(),\n+                                fragment.getStageExecutionDescriptor(),\n+                                fragment.isOutputTableWriterFragment(),\n+                                fragment.getStatsAndCosts(),\n+                                fragment.getJsonRepresentation()));\n+                    }\n+                });\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        log.info(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream().map(PlanFragment::getId).map(PlanFragmentId::toString).collect(Collectors.joining(\", \")));\n+        return new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());\n+    }\n+\n+    private void updatePlan(Map<PlanFragment, PlanFragment> oldToNewFragments)\n+    {\n+        plan.getAndUpdate(value -> rewritePlan(value, oldToNewFragments));\n+    }\n+\n+    private SubPlan rewritePlan(SubPlan root, Map<PlanFragment, PlanFragment> oldToNewFragments)\n+    {\n+        List<SubPlan> children = new ArrayList<>();\n+        for (SubPlan child : root.getChildren()) {\n+            children.add(rewritePlan(child, oldToNewFragments));\n+        }\n+        if (oldToNewFragments.containsKey(root.getFragment())) {\n+            return new SubPlan(oldToNewFragments.get(root.getFragment()), children);\n+        }\n+        else {\n+            return new SubPlan(root.getFragment(), children);\n+        }\n+    }\n+\n+    private StreamingSubPlan rewriteStreamingSubPlan(StreamingSubPlan root, Map<PlanFragment, PlanFragment> oldToNewFragment)\n+    {\n+        List<StreamingSubPlan> childrenPlans = new ArrayList<>();", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..2648611177 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -397,39 +397,21 @@ public class SqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n         // Apply runtime optimization on each StreamingSubPlan's fragment\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxNDM3NA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r448714374", "bodyText": "This is likely to break statistics\nCC: @rschlussel", "author": "arhimondr", "createdAt": "2020-07-02T02:32:00Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java", "diffHunk": "@@ -591,7 +706,7 @@ public BasicStageExecutionStats getBasicStageStats()\n     public StageInfo getStageInfo()\n     {\n         ListMultimap<StageId, SqlStageExecution> stageExecutions = getStageExecutions();\n-        return buildStageInfo(plan, stageExecutions);\n+        return buildStageInfo(plan.get(), stageExecutions);", "originalCommit": "7154ef6c0d2e0a0ed2bc0f231d3ab20bb5db625f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjMyMjMxMQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r452322311", "bodyText": "@pguofb is looking at that next. Right now the info in the live plan will be incorrect, but the final plan in the querycompletedevent and the stage info will be correct.", "author": "rschlussel", "createdAt": "2020-07-09T15:56:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODcxNDM3NA=="}], "type": "inlineReview", "revised_code": {"commit": "76f74999c411b559acc712f29fe4b89c08d7b119", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\nindex 68b432102d..d29259d2e5 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java\n\n@@ -706,7 +591,7 @@ public class SqlQueryScheduler\n     public StageInfo getStageInfo()\n     {\n         ListMultimap<StageId, SqlStageExecution> stageExecutions = getStageExecutions();\n-        return buildStageInfo(plan.get(), stageExecutions);\n+        return buildStageInfo(plan, stageExecutions);\n     }\n \n     private StageInfo buildStageInfo(SubPlan subPlan, ListMultimap<StageId, SqlStageExecution> stageExecutions)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAwNzg2NA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450007864", "bodyText": "Two questions:\n\nIs the ordering of depth-first required? -- Or DFS is just to make all the plan fragment in this section get traversed? (and the actual ordering of fragments being visited doesn't matter)\nSince this lambda is a bit long, I would suggest to refactor into a static private method, e.g. performRuntimeOptimization", "author": "wenleix", "createdAt": "2020-07-06T06:28:14Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +505,182 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .map(StreamingSubPlan::getFragment)\n+                .forEach(fragment -> {", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDIwNzQzMA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450207430", "bodyText": "The ordering is not required, it is just to make all fragments in a section traversed.\n\n\nSounds good!", "author": "pguofb", "createdAt": "2020-07-06T13:07:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAwNzg2NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 1acdae1b67..bbab68ae5c 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -510,41 +508,21 @@ public class LegacySqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n-        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    // The partitioningScheme should stay the same\n-                    // even if the root's outputVariables are changed.\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAwOTA3Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450009073", "bodyText": "nit:  reformat the code:\n        log.info(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream()\n                .map(PlanFragment::getId)\n                .map(PlanFragmentId::toString)\n                .collect(Collectors.joining(\", \")));", "author": "wenleix", "createdAt": "2020-07-06T06:31:43Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +505,182 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .map(StreamingSubPlan::getFragment)\n+                .forEach(fragment -> {\n+                    PlanNode newRoot = fragment.getRoot();\n+                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+                    }\n+                    // The partitioningScheme should stay the same\n+                    // even if the root's outputVariables are changed.\n+                    if (newRoot != fragment.getRoot()) {\n+                        oldToNewFragment.put(fragment, new PlanFragment(\n+                                fragment.getId(),\n+                                newRoot,\n+                                fragment.getVariables(),\n+                                fragment.getPartitioning(),\n+                                scheduleOrder(newRoot),\n+                                fragment.getPartitioningScheme(),\n+                                fragment.getStageExecutionDescriptor(),\n+                                fragment.isOutputTableWriterFragment(),\n+                                fragment.getStatsAndCosts(),\n+                                fragment.getJsonRepresentation()));\n+                    }\n+                });\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        // Rebuild and update entries of the stageExecutions map.\n+        updateStageExecutions(section, oldToNewFragment);\n+        log.info(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream().map(PlanFragment::getId).map(PlanFragmentId::toString).collect(Collectors.joining(\", \")));", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 1acdae1b67..bbab68ae5c 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -510,41 +508,21 @@ public class LegacySqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n-        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    // The partitioningScheme should stay the same\n-                    // even if the root's outputVariables are changed.\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAxMTIwOA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450011208", "bodyText": "I am wondering  the conditiongetExchangeMaterializationStrategy(session) != ALL is necessary? -- What we really want is tryCostBasedOptimize only get called for non-root sections right? In that case we probably just want to sure tryCostBasedOptimize doesn't get called in getSectionsReadyForExecution for non-root section? :)", "author": "wenleix", "createdAt": "2020-07-06T06:37:41Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +505,182 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {", "originalCommit": "178a17e1ca5702b2f87a576b13b807cb0daa44e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDIxNjc3Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450216773", "bodyText": "I guess you mean non-leaf section right? Yeah, when materialization is not enabled, there will be only one section, which has no children, and so will not trigger tryCostBasedOptimize", "author": "pguofb", "createdAt": "2020-07-06T13:23:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAxMTIwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMxMDAxOA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450310018", "bodyText": "@pguofb : Right, non-leaf section :)", "author": "wenleix", "createdAt": "2020-07-06T15:40:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAxMTIwOA=="}], "type": "inlineReview", "revised_code": {"commit": "e3b6cd8537d747b266787373e045cc8c3e283330", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 1acdae1b67..bbab68ae5c 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -510,41 +508,21 @@ public class LegacySqlQueryScheduler\n     }\n \n     /**\n-     * Utility function to invoke runtime cost-based optimizer, which determines if the probe and build side of a JoinNode should be swapped,\n-     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections.\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n      */\n     private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n     {\n         // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n-        if (!isRuntimeOptimizerEnabled(session) || getExchangeMaterializationStrategy(session) != ALL || section.getChildren().isEmpty()) {\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n             return section;\n         }\n \n-        // Apply runtime optimization on each StreamingSubPlan's fragment\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .map(StreamingSubPlan::getFragment)\n-                .forEach(fragment -> {\n-                    PlanNode newRoot = fragment.getRoot();\n-                    for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n-                        newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n-                    }\n-                    // The partitioningScheme should stay the same\n-                    // even if the root's outputVariables are changed.\n-                    if (newRoot != fragment.getRoot()) {\n-                        oldToNewFragment.put(fragment, new PlanFragment(\n-                                fragment.getId(),\n-                                newRoot,\n-                                fragment.getVariables(),\n-                                fragment.getPartitioning(),\n-                                scheduleOrder(newRoot),\n-                                fragment.getPartitioningScheme(),\n-                                fragment.getStageExecutionDescriptor(),\n-                                fragment.isOutputTableWriterFragment(),\n-                                fragment.getStatsAndCosts(),\n-                                fragment.getJsonRepresentation()));\n-                    }\n-                });\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"oid": "e3b6cd8537d747b266787373e045cc8c3e283330", "url": "https://github.com/prestodb/presto/commit/e3b6cd8537d747b266787373e045cc8c3e283330", "message": "Add tests for RuntimeReorderJoinSides rule", "committedDate": "2020-07-06T13:48:25Z", "type": "forcePushed"}, {"oid": "d03265a465252aec4fd4c334b6267e01793420d6", "url": "https://github.com/prestodb/presto/commit/d03265a465252aec4fd4c334b6267e01793420d6", "message": "Add tests for RuntimeReorderJoinSides rule", "committedDate": "2020-07-06T15:05:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMyMDU5Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450320593", "bodyText": "nit: Can we add a blank line, and add a comment stating the following fields are required by adaptive optimization in runtime?\nThe reason is it's a lot of these class are clearly not required by normal static execution. So ideally we want to split from what is required by static schedule and what is required by adaptive execution.\nOne common pattern is to refactor them into a separate class (e.g. AdatpiveOptimizer). But we can leave that refactor as future work.", "author": "wenleix", "createdAt": "2020-07-06T15:56:42Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -89,13 +104,22 @@\n     private final SplitSchedulerStats schedulerStats;\n \n     private final QueryStateMachine queryStateMachine;\n-    private final SubPlan plan;\n+    private final AtomicReference<SubPlan> plan = new AtomicReference<>();\n     private final StreamingPlanSection sectionedPlan;\n     private final StageId rootStageId;\n     private final boolean summarizeTaskInfo;\n     private final int maxConcurrentMaterializations;\n-\n-    private final Map<StageId, StageExecutionAndScheduler> stageExecutions;\n+    private final Session session;", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex bbab68ae5c..5ba4882601 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -109,6 +109,8 @@ public class LegacySqlQueryScheduler\n     private final StageId rootStageId;\n     private final boolean summarizeTaskInfo;\n     private final int maxConcurrentMaterializations;\n+\n+    // The following fields are required by adaptive optimization in runtime.\n     private final Session session;\n     private final List<PlanOptimizer> runtimePlanOptimizers;\n     private final WarningCollector warningCollector;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMyODcwMg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450328702", "bodyText": "Hmm. Now performRuntimeOptimizations updates oldToNewFragment. Ideally we want the input/output of methods to be more clear (e.g. pass in the current plan, returns the new optimized plan)\nWhat about the following:\n\nMake performRuntimeOptimizations to return Optional<PlanFragment> as follows:\n\n    private Optional<PlanFragment> getRuntimeOptimizedPlan(StreamingSubPlan subPlan)\n    {\n        PlanFragment fragment = subPlan.getFragment();\n        PlanNode newRoot = fragment.getRoot();\n        for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n            newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n        }\n        // The partitioningScheme should stay the same\n        // even if the root's outputVariable layout is changed.\n        if (newRoot != fragment.getRoot()) {\n            return Optional.of(\n                    new PlanFragment(\n                            fragment.getId(),\n                            newRoot,\n                            fragment.getVariables(),\n                            fragment.getPartitioning(),\n                            scheduleOrder(newRoot),\n                            fragment.getPartitioningScheme(),\n                            fragment.getStageExecutionDescriptor(),\n                            fragment.isOutputTableWriterFragment(),\n                            fragment.getStatsAndCosts(),\n                            fragment.getJsonRepresentation())));\n        }\n    }\n\nRewrite this line to\n\n        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n                .forEach(currentPlan -> {\n                    Optional<PlanFragment> newPlan = getRuntimeOptimizedPlan(currentPlan);\n                    if (newPlan.isPresent()) {\n                        oldToNewFragment.put(currentPlan.getFragment(), newPlan.get());\n                    }\n                });\nThis will still contain a multi-line anonymous lambda, but it should be easier to follow than the original one :)", "author": "wenleix", "createdAt": "2020-07-06T16:10:04Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +503,189 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex bbab68ae5c..5ba4882601 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -522,7 +524,12 @@ public class LegacySqlQueryScheduler\n         // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+                .forEach(currentSubPlan -> {\n+                    Optional<PlanFragment> newPlanFragment = performRuntimeOptimizations(currentSubPlan);\n+                    if (newPlanFragment.isPresent()) {\n+                        oldToNewFragment.put(currentSubPlan.getFragment(), newPlanFragment.get());\n+                    }\n+                });\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMTE5NQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450331195", "bodyText": "@rschlussel : Is SectionExecutionFactory introduced for the new sql query scheduler? So essentially we are calling something in the new scheduler from the legacy scheduler? ;)", "author": "wenleix", "createdAt": "2020-07-06T16:14:11Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +503,189 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        // Rebuild and update entries of the stageExecutions map.\n+        updateStageExecutions(section, oldToNewFragment);\n+        log.debug(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream()\n+                .map(PlanFragment::getId)\n+                .map(PlanFragmentId::toString)\n+                .collect(Collectors.joining(\", \")));\n+        return section;\n+    }\n+\n+    private void performRuntimeOptimizations(StreamingSubPlan subPlan, Map<PlanFragment, PlanFragment> oldToNewFragmentMapping)\n+    {\n+        PlanFragment fragment = subPlan.getFragment();\n+        PlanNode newRoot = fragment.getRoot();\n+        for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+            newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+        }\n+        // The partitioningScheme should stay the same\n+        // even if the root's outputVariable layout is changed.\n+        if (newRoot != fragment.getRoot()) {\n+            oldToNewFragmentMapping.put(fragment, new PlanFragment(\n+                    fragment.getId(),\n+                    newRoot,\n+                    fragment.getVariables(),\n+                    fragment.getPartitioning(),\n+                    scheduleOrder(newRoot),\n+                    fragment.getPartitioningScheme(),\n+                    fragment.getStageExecutionDescriptor(),\n+                    fragment.isOutputTableWriterFragment(),\n+                    fragment.getStatsAndCosts(),\n+                    fragment.getJsonRepresentation()));\n+        }\n+    }\n+\n+    /**\n+     * Utility function that rebuild a StreamingPlanSection, re-create stageExecutionAndScheduler for each of its stage, and finally update the stageExecutions map.\n+     */\n+    private void updateStageExecutions(StreamingPlanSection section, Map<PlanFragment, PlanFragment> oldToNewFragment)\n+    {\n+        StreamingPlanSection newSection = new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());\n+        PlanFragment sectionRootFragment = newSection.getPlan().getFragment();\n+        Optional<int[]> bucketToPartition;\n+        OutputBuffers outputBuffers;\n+        ExchangeLocationsConsumer locationsConsumer;\n+        if (isRootFragment(sectionRootFragment)) {\n+            bucketToPartition = Optional.of(new int[1]);\n+            outputBuffers = createInitialEmptyOutputBuffers(sectionRootFragment.getPartitioningScheme().getPartitioning().getHandle())\n+                    .withBuffer(new OutputBufferId(0), BROADCAST_PARTITION_ID)\n+                    .withNoMoreBufferIds();\n+            OutputBufferId rootBufferId = getOnlyElement(outputBuffers.getBuffers().keySet());\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) ->\n+                    updateQueryOutputLocations(queryStateMachine, rootBufferId, tasks, noMoreExchangeLocations);\n+        }\n+        else {\n+            bucketToPartition = Optional.empty();\n+            outputBuffers = createDiscardingOutputBuffers();\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) -> {};\n+        }\n+        SectionExecution sectionExecution = sectionExecutionFactory.createSectionExecutions(", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjMyMDcxNA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r452320714", "bodyText": "sectionexecutionfactory is already used in the legacySqlQueryScheduler (and the logic was originally extracted from there)", "author": "rschlussel", "createdAt": "2020-07-09T15:53:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMTE5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex bbab68ae5c..5ba4882601 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -522,7 +524,12 @@ public class LegacySqlQueryScheduler\n         // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+                .forEach(currentSubPlan -> {\n+                    Optional<PlanFragment> newPlanFragment = performRuntimeOptimizations(currentSubPlan);\n+                    if (newPlanFragment.isPresent()) {\n+                        oldToNewFragment.put(currentSubPlan.getFragment(), newPlanFragment.get());\n+                    }\n+                });\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMTg0Mw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450331843", "bodyText": "do we need to remove the state change listeners for old sections?", "author": "wenleix", "createdAt": "2020-07-06T16:15:07Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +503,189 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        // Rebuild and update entries of the stageExecutions map.\n+        updateStageExecutions(section, oldToNewFragment);\n+        log.debug(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream()\n+                .map(PlanFragment::getId)\n+                .map(PlanFragmentId::toString)\n+                .collect(Collectors.joining(\", \")));\n+        return section;\n+    }\n+\n+    private void performRuntimeOptimizations(StreamingSubPlan subPlan, Map<PlanFragment, PlanFragment> oldToNewFragmentMapping)\n+    {\n+        PlanFragment fragment = subPlan.getFragment();\n+        PlanNode newRoot = fragment.getRoot();\n+        for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+            newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+        }\n+        // The partitioningScheme should stay the same\n+        // even if the root's outputVariable layout is changed.\n+        if (newRoot != fragment.getRoot()) {\n+            oldToNewFragmentMapping.put(fragment, new PlanFragment(\n+                    fragment.getId(),\n+                    newRoot,\n+                    fragment.getVariables(),\n+                    fragment.getPartitioning(),\n+                    scheduleOrder(newRoot),\n+                    fragment.getPartitioningScheme(),\n+                    fragment.getStageExecutionDescriptor(),\n+                    fragment.isOutputTableWriterFragment(),\n+                    fragment.getStatsAndCosts(),\n+                    fragment.getJsonRepresentation()));\n+        }\n+    }\n+\n+    /**\n+     * Utility function that rebuild a StreamingPlanSection, re-create stageExecutionAndScheduler for each of its stage, and finally update the stageExecutions map.\n+     */\n+    private void updateStageExecutions(StreamingPlanSection section, Map<PlanFragment, PlanFragment> oldToNewFragment)\n+    {\n+        StreamingPlanSection newSection = new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());\n+        PlanFragment sectionRootFragment = newSection.getPlan().getFragment();\n+        Optional<int[]> bucketToPartition;\n+        OutputBuffers outputBuffers;\n+        ExchangeLocationsConsumer locationsConsumer;\n+        if (isRootFragment(sectionRootFragment)) {\n+            bucketToPartition = Optional.of(new int[1]);\n+            outputBuffers = createInitialEmptyOutputBuffers(sectionRootFragment.getPartitioningScheme().getPartitioning().getHandle())\n+                    .withBuffer(new OutputBufferId(0), BROADCAST_PARTITION_ID)\n+                    .withNoMoreBufferIds();\n+            OutputBufferId rootBufferId = getOnlyElement(outputBuffers.getBuffers().keySet());\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) ->\n+                    updateQueryOutputLocations(queryStateMachine, rootBufferId, tasks, noMoreExchangeLocations);\n+        }\n+        else {\n+            bucketToPartition = Optional.empty();\n+            outputBuffers = createDiscardingOutputBuffers();\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) -> {};\n+        }\n+        SectionExecution sectionExecution = sectionExecutionFactory.createSectionExecutions(\n+                session,\n+                newSection,\n+                locationsConsumer,\n+                bucketToPartition,\n+                outputBuffers,\n+                summarizeTaskInfo,\n+                remoteTaskFactory,\n+                splitSourceFactory,\n+                0);\n+        addStateChangeListeners(sectionExecution);", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM2NDc4Mg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450364782", "bodyText": "Yeah, I thought about this. When we created new stageExecutions and replace the old ones in this.stageExecutions, these old stageExecutions will have nothing referencing to them and will be garbage collected eventually without getting triggered. Therefore, I'm not too worried about explicitly removing listeners. Besides, stateMachine class also does not provide methods to explicitly remove listeners, so I think it is ok to trust on the GC to do its own job :)", "author": "pguofb", "createdAt": "2020-07-06T17:10:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMTg0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex bbab68ae5c..5ba4882601 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -522,7 +524,12 @@ public class LegacySqlQueryScheduler\n         // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+                .forEach(currentSubPlan -> {\n+                    Optional<PlanFragment> newPlanFragment = performRuntimeOptimizations(currentSubPlan);\n+                    if (newPlanFragment.isPresent()) {\n+                        oldToNewFragment.put(currentSubPlan.getFragment(), newPlanFragment.get());\n+                    }\n+                });\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMjI4NQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450332285", "bodyText": "ditto: do we need to remove old stage executions from stageExecutions ?", "author": "wenleix", "createdAt": "2020-07-06T16:15:43Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +503,189 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        // Rebuild and update entries of the stageExecutions map.\n+        updateStageExecutions(section, oldToNewFragment);\n+        log.debug(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream()\n+                .map(PlanFragment::getId)\n+                .map(PlanFragmentId::toString)\n+                .collect(Collectors.joining(\", \")));\n+        return section;\n+    }\n+\n+    private void performRuntimeOptimizations(StreamingSubPlan subPlan, Map<PlanFragment, PlanFragment> oldToNewFragmentMapping)\n+    {\n+        PlanFragment fragment = subPlan.getFragment();\n+        PlanNode newRoot = fragment.getRoot();\n+        for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+            newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+        }\n+        // The partitioningScheme should stay the same\n+        // even if the root's outputVariable layout is changed.\n+        if (newRoot != fragment.getRoot()) {\n+            oldToNewFragmentMapping.put(fragment, new PlanFragment(\n+                    fragment.getId(),\n+                    newRoot,\n+                    fragment.getVariables(),\n+                    fragment.getPartitioning(),\n+                    scheduleOrder(newRoot),\n+                    fragment.getPartitioningScheme(),\n+                    fragment.getStageExecutionDescriptor(),\n+                    fragment.isOutputTableWriterFragment(),\n+                    fragment.getStatsAndCosts(),\n+                    fragment.getJsonRepresentation()));\n+        }\n+    }\n+\n+    /**\n+     * Utility function that rebuild a StreamingPlanSection, re-create stageExecutionAndScheduler for each of its stage, and finally update the stageExecutions map.\n+     */\n+    private void updateStageExecutions(StreamingPlanSection section, Map<PlanFragment, PlanFragment> oldToNewFragment)\n+    {\n+        StreamingPlanSection newSection = new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());\n+        PlanFragment sectionRootFragment = newSection.getPlan().getFragment();\n+        Optional<int[]> bucketToPartition;\n+        OutputBuffers outputBuffers;\n+        ExchangeLocationsConsumer locationsConsumer;\n+        if (isRootFragment(sectionRootFragment)) {\n+            bucketToPartition = Optional.of(new int[1]);\n+            outputBuffers = createInitialEmptyOutputBuffers(sectionRootFragment.getPartitioningScheme().getPartitioning().getHandle())\n+                    .withBuffer(new OutputBufferId(0), BROADCAST_PARTITION_ID)\n+                    .withNoMoreBufferIds();\n+            OutputBufferId rootBufferId = getOnlyElement(outputBuffers.getBuffers().keySet());\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) ->\n+                    updateQueryOutputLocations(queryStateMachine, rootBufferId, tasks, noMoreExchangeLocations);\n+        }\n+        else {\n+            bucketToPartition = Optional.empty();\n+            outputBuffers = createDiscardingOutputBuffers();\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) -> {};\n+        }\n+        SectionExecution sectionExecution = sectionExecutionFactory.createSectionExecutions(\n+                session,\n+                newSection,\n+                locationsConsumer,\n+                bucketToPartition,\n+                outputBuffers,\n+                summarizeTaskInfo,\n+                remoteTaskFactory,\n+                splitSourceFactory,\n+                0);\n+        addStateChangeListeners(sectionExecution);\n+        Map<StageId, StageExecutionAndScheduler> updatedStageExecutions = sectionExecution.getSectionStages().stream()\n+                .collect(toImmutableMap(execution -> execution.getStageExecution().getStageExecutionId().getStageId(), identity()));\n+        synchronized (this) {\n+            stageExecutions.putAll(updatedStageExecutions);", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM2NjgzNA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450366834", "bodyText": "Samewise, stageExecutions is a map from StageId -> StageExecutionAndScheduler. The rewritten stages have the same id from the old one (a bit different from retry because we optimize them right before we schedule & execute them), and so we actually replace the old ones, not simply inserting a batch of new ones.", "author": "pguofb", "createdAt": "2020-07-06T17:14:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMjI4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex bbab68ae5c..5ba4882601 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -522,7 +524,12 @@ public class LegacySqlQueryScheduler\n         // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+                .forEach(currentSubPlan -> {\n+                    Optional<PlanFragment> newPlanFragment = performRuntimeOptimizations(currentSubPlan);\n+                    if (newPlanFragment.isPresent()) {\n+                        oldToNewFragment.put(currentSubPlan.getFragment(), newPlanFragment.get());\n+                    }\n+                });\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDMzMzM4OQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450333389", "bodyText": "Add a comment that it's only used by adaptive optimization.", "author": "wenleix", "createdAt": "2020-07-06T16:17:35Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -459,9 +503,189 @@ else if (!result.getBlocked().isDone()) {\n                 // get all sections ready for execution\n                 .filter(this::isReadyForExecution)\n                 .limit(maxConcurrentMaterializations - runningPlanSections)\n+                .map(this::tryCostBasedOptimize)\n                 .collect(toImmutableList());\n     }\n \n+    /**\n+     * A general purpose utility function to invoke runtime cost-based optimizer.\n+     * (right now there is only one plan optimizer which determines if the probe and build side of a JoinNode should be swapped\n+     * based on the statistics of the temporary table holding materialized exchange outputs from finished children sections)\n+     */\n+    private StreamingPlanSection tryCostBasedOptimize(StreamingPlanSection section)\n+    {\n+        // no need to do runtime optimization if no materialized exchange data is utilized by the section.\n+        if (!isRuntimeOptimizerEnabled(session) || section.getChildren().isEmpty()) {\n+            return section;\n+        }\n+\n+        // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n+        Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n+        stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n+                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+\n+        // Early exit when no stage's fragment is changed\n+        if (oldToNewFragment.isEmpty()) {\n+            return section;\n+        }\n+\n+        // Update SubPlan so that getStageInfo will reflect the latest optimized plan when query is finished.\n+        updatePlan(oldToNewFragment);\n+\n+        // Rebuild and update entries of the stageExecutions map.\n+        updateStageExecutions(section, oldToNewFragment);\n+        log.debug(\"Invoked CBO during runtime, optimized stage IDs: \" + oldToNewFragment.keySet().stream()\n+                .map(PlanFragment::getId)\n+                .map(PlanFragmentId::toString)\n+                .collect(Collectors.joining(\", \")));\n+        return section;\n+    }\n+\n+    private void performRuntimeOptimizations(StreamingSubPlan subPlan, Map<PlanFragment, PlanFragment> oldToNewFragmentMapping)\n+    {\n+        PlanFragment fragment = subPlan.getFragment();\n+        PlanNode newRoot = fragment.getRoot();\n+        for (PlanOptimizer optimizer : runtimePlanOptimizers) {\n+            newRoot = optimizer.optimize(newRoot, session, variableAllocator.getTypes(), variableAllocator, idAllocator, warningCollector);\n+        }\n+        // The partitioningScheme should stay the same\n+        // even if the root's outputVariable layout is changed.\n+        if (newRoot != fragment.getRoot()) {\n+            oldToNewFragmentMapping.put(fragment, new PlanFragment(\n+                    fragment.getId(),\n+                    newRoot,\n+                    fragment.getVariables(),\n+                    fragment.getPartitioning(),\n+                    scheduleOrder(newRoot),\n+                    fragment.getPartitioningScheme(),\n+                    fragment.getStageExecutionDescriptor(),\n+                    fragment.isOutputTableWriterFragment(),\n+                    fragment.getStatsAndCosts(),\n+                    fragment.getJsonRepresentation()));\n+        }\n+    }\n+\n+    /**\n+     * Utility function that rebuild a StreamingPlanSection, re-create stageExecutionAndScheduler for each of its stage, and finally update the stageExecutions map.\n+     */\n+    private void updateStageExecutions(StreamingPlanSection section, Map<PlanFragment, PlanFragment> oldToNewFragment)\n+    {\n+        StreamingPlanSection newSection = new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());\n+        PlanFragment sectionRootFragment = newSection.getPlan().getFragment();\n+        Optional<int[]> bucketToPartition;\n+        OutputBuffers outputBuffers;\n+        ExchangeLocationsConsumer locationsConsumer;\n+        if (isRootFragment(sectionRootFragment)) {\n+            bucketToPartition = Optional.of(new int[1]);\n+            outputBuffers = createInitialEmptyOutputBuffers(sectionRootFragment.getPartitioningScheme().getPartitioning().getHandle())\n+                    .withBuffer(new OutputBufferId(0), BROADCAST_PARTITION_ID)\n+                    .withNoMoreBufferIds();\n+            OutputBufferId rootBufferId = getOnlyElement(outputBuffers.getBuffers().keySet());\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) ->\n+                    updateQueryOutputLocations(queryStateMachine, rootBufferId, tasks, noMoreExchangeLocations);\n+        }\n+        else {\n+            bucketToPartition = Optional.empty();\n+            outputBuffers = createDiscardingOutputBuffers();\n+            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) -> {};\n+        }\n+        SectionExecution sectionExecution = sectionExecutionFactory.createSectionExecutions(\n+                session,\n+                newSection,\n+                locationsConsumer,\n+                bucketToPartition,\n+                outputBuffers,\n+                summarizeTaskInfo,\n+                remoteTaskFactory,\n+                splitSourceFactory,\n+                0);\n+        addStateChangeListeners(sectionExecution);\n+        Map<StageId, StageExecutionAndScheduler> updatedStageExecutions = sectionExecution.getSectionStages().stream()\n+                .collect(toImmutableMap(execution -> execution.getStageExecution().getStageExecutionId().getStageId(), identity()));\n+        synchronized (this) {\n+            stageExecutions.putAll(updatedStageExecutions);\n+        }\n+    }\n+\n+    private void updatePlan(Map<PlanFragment, PlanFragment> oldToNewFragments)\n+    {\n+        plan.getAndUpdate(value -> rewritePlan(value, oldToNewFragments));\n+    }\n+\n+    private SubPlan rewritePlan(SubPlan root, Map<PlanFragment, PlanFragment> oldToNewFragments)\n+    {\n+        ImmutableList.Builder<SubPlan> children = ImmutableList.builder();\n+        for (SubPlan child : root.getChildren()) {\n+            children.add(rewritePlan(child, oldToNewFragments));\n+        }\n+        if (oldToNewFragments.containsKey(root.getFragment())) {\n+            return new SubPlan(oldToNewFragments.get(root.getFragment()), children.build());\n+        }\n+        else {\n+            return new SubPlan(root.getFragment(), children.build());\n+        }\n+    }\n+\n+    private void addStateChangeListeners(SectionExecution sectionExecution)", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex bbab68ae5c..5ba4882601 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -522,7 +524,12 @@ public class LegacySqlQueryScheduler\n         // Apply runtime optimization on each StreamingSubPlan and generate optimized new fragments\n         Map<PlanFragment, PlanFragment> oldToNewFragment = new HashMap<>();\n         stream(forTree(StreamingSubPlan::getChildren).depthFirstPreOrder(section.getPlan()))\n-                .forEach(subPlan -> performRuntimeOptimizations(subPlan, oldToNewFragment));\n+                .forEach(currentSubPlan -> {\n+                    Optional<PlanFragment> newPlanFragment = performRuntimeOptimizations(currentSubPlan);\n+                    if (newPlanFragment.isPresent()) {\n+                        oldToNewFragment.put(currentSubPlan.getFragment(), newPlanFragment.get());\n+                    }\n+                });\n \n         // Early exit when no stage's fragment is changed\n         if (oldToNewFragment.isEmpty()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM0ODMwNA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r450348304", "bodyText": "This probably already raised discussions . But it looks weird to have variableAllocator in PlanRoot.\nI see PlanRoot#getVariableAllocator is called when creating SqlQueryScheduler. Is it possible to create the variableAllocator  by using the plan? (i.e. new PlanVariableAllocator(plan.getTypes().allVariables())", "author": "wenleix", "createdAt": "2020-07-06T16:41:33Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java", "diffHunk": "@@ -384,13 +388,15 @@ private PlanRoot doAnalyzeQuery()\n         stateMachine.setOutput(output);\n \n         // fragment the plan\n-        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, stateMachine.getWarningCollector());\n+        // the variableAllocator is finally passed to SqlQueryScheduler for runtime cost-based optimizations\n+        PlanVariableAllocator variableAllocator = new PlanVariableAllocator(plan.getTypes().allVariables());\n+        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, variableAllocator, stateMachine.getWarningCollector());\n \n         // record analysis time\n         stateMachine.endAnalysis();\n \n         boolean explainAnalyze = analysis.getStatement() instanceof Explain && ((Explain) analysis.getStatement()).isAnalyze();\n-        return new PlanRoot(fragmentedPlan, !explainAnalyze, extractConnectors(analysis));\n+        return new PlanRoot(fragmentedPlan, !explainAnalyze, extractConnectors(analysis), variableAllocator);", "originalCommit": "aba601e685ed363edbf12e06bb6ac8c491e88d7f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fab8a61955854722c8e349a9c435b303b12b2ec5", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java b/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java\nindex 3bd4ce277c..ff1d1ca2a5 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java\n\n@@ -389,14 +390,14 @@ public class SqlQueryExecution\n \n         // fragment the plan\n         // the variableAllocator is finally passed to SqlQueryScheduler for runtime cost-based optimizations\n-        PlanVariableAllocator variableAllocator = new PlanVariableAllocator(plan.getTypes().allVariables());\n-        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, variableAllocator, stateMachine.getWarningCollector());\n+        variableAllocator.set(new PlanVariableAllocator(plan.getTypes().allVariables()));\n+        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, variableAllocator.get(), stateMachine.getWarningCollector());\n \n         // record analysis time\n         stateMachine.endAnalysis();\n \n         boolean explainAnalyze = analysis.getStatement() instanceof Explain && ((Explain) analysis.getStatement()).isAnalyze();\n-        return new PlanRoot(fragmentedPlan, !explainAnalyze, extractConnectors(analysis), variableAllocator);\n+        return new PlanRoot(fragmentedPlan, !explainAnalyze, extractConnectors(analysis));\n     }\n \n     private static Set<ConnectorId> extractConnectors(Analysis analysis)\n"}}, {"oid": "fab8a61955854722c8e349a9c435b303b12b2ec5", "url": "https://github.com/prestodb/presto/commit/fab8a61955854722c8e349a9c435b303b12b2ec5", "message": "Add tests for RuntimeReorderJoinSides rule", "committedDate": "2020-07-06T18:13:12Z", "type": "forcePushed"}, {"oid": "3dc8803256ed6c061debe2ea9ac97947f4bef45b", "url": "https://github.com/prestodb/presto/commit/3dc8803256ed6c061debe2ea9ac97947f4bef45b", "message": "Fix broken LivePlan statistics\n\nThe Live Plan graph shown in the web UI is generated from parsing the\njsonRepresentation of each PlanFragment, not actually tracing the plan\nnode dependency graph. Therefore, when generating the new PlanFragment\nafter runtime optimizations, the jsonRepresentation of the fragment\nneeds to be updated.", "committedDate": "2020-07-10T13:01:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkxNTgxNA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r452915814", "bodyText": "nit: just get the functionmanager from the metadata since that's all you need (and same below)", "author": "rschlussel", "createdAt": "2020-07-10T15:29:23Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -190,6 +196,7 @@ private LegacySqlQueryScheduler(\n         this.queryStateMachine = requireNonNull(queryStateMachine, \"queryStateMachine is null\");\n         this.plan.compareAndSet(null, requireNonNull(plan, \"plan is null\"));\n         this.session = requireNonNull(session, \"session is null\");\n+        this.metadata = requireNonNull(metadata, \"metadata is null\");", "originalCommit": "3dc8803256ed6c061debe2ea9ac97947f4bef45b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8e7d5f04a7cf3d2dce05adcf9340ab6873da9073", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 70b031ae40..5c2025038b 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -196,7 +196,7 @@ public class LegacySqlQueryScheduler\n         this.queryStateMachine = requireNonNull(queryStateMachine, \"queryStateMachine is null\");\n         this.plan.compareAndSet(null, requireNonNull(plan, \"plan is null\"));\n         this.session = requireNonNull(session, \"session is null\");\n-        this.metadata = requireNonNull(metadata, \"metadata is null\");\n+        this.functionManager = requireNonNull(functionManager, \"functionManager is null\");\n         this.runtimePlanOptimizers = requireNonNull(runtimePlanOptimizers, \"runtimePlanOptimizers is null\");\n         this.warningCollector = requireNonNull(warningCollector, \"warningCollector is null\");\n         this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n"}}, {"oid": "8e7d5f04a7cf3d2dce05adcf9340ab6873da9073", "url": "https://github.com/prestodb/presto/commit/8e7d5f04a7cf3d2dce05adcf9340ab6873da9073", "message": "Fix broken LivePlan statistics\n\nThe Live Plan graph shown in the web UI is generated from parsing the\njsonRepresentation of each PlanFragment, not actually tracing the plan\nnode dependency graph. Therefore, when generating the new PlanFragment\nafter runtime optimizations, the jsonRepresentation of the fragment\nneeds to be updated.", "committedDate": "2020-07-10T15:51:39Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NzEzOA==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r453997138", "bodyText": "nit: Usually we define log as a very first field in the class and separate it from the other fields", "author": "arhimondr", "createdAt": "2020-07-13T23:07:34Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java", "diffHunk": "@@ -89,13 +106,25 @@\n     private final SplitSchedulerStats schedulerStats;\n \n     private final QueryStateMachine queryStateMachine;\n-    private final SubPlan plan;\n+    private final AtomicReference<SubPlan> plan = new AtomicReference<>();\n     private final StreamingPlanSection sectionedPlan;\n     private final StageId rootStageId;\n     private final boolean summarizeTaskInfo;\n     private final int maxConcurrentMaterializations;\n \n-    private final Map<StageId, StageExecutionAndScheduler> stageExecutions;\n+    // The following fields are required by adaptive optimization in runtime.\n+    private final Session session;\n+    private final FunctionManager functionManager;\n+    private final List<PlanOptimizer> runtimePlanOptimizers;\n+    private final WarningCollector warningCollector;\n+    private final PlanNodeIdAllocator idAllocator;\n+    private final PlanVariableAllocator variableAllocator;\n+    private final SectionExecutionFactory sectionExecutionFactory;\n+    private final RemoteTaskFactory remoteTaskFactory;\n+    private final SplitSourceFactory splitSourceFactory;\n+    private static final Logger log = Logger.get(LegacySqlQueryScheduler.class);", "originalCommit": "8e7d5f04a7cf3d2dce05adcf9340ab6873da9073", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "455d053e5458eb49cfb20d210d5628532367d94e", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\nindex 5c2025038b..96e0d2ab21 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/scheduler/LegacySqlQueryScheduler.java\n\n@@ -100,6 +100,8 @@ import static java.util.function.Function.identity;\n public class LegacySqlQueryScheduler\n         implements SqlQuerySchedulerInterface\n {\n+    private static final Logger log = Logger.get(LegacySqlQueryScheduler.class);\n+\n     private final LocationFactory locationFactory;\n     private final ExecutionPolicy executionPolicy;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Nzc1Nw==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r453997757", "bodyText": "private static final", "author": "arhimondr", "createdAt": "2020-07-13T23:09:35Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.DistributionType.PARTITIONED;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.DistributionType.REPLICATED;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.Type.LEFT;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.Type.RIGHT;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);", "originalCommit": "8e7d5f04a7cf3d2dce05adcf9340ab6873da9073", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "455d053e5458eb49cfb20d210d5628532367d94e", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 959708fff6..03008a9c89 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -41,11 +41,12 @@ import static com.facebook.presto.sql.planner.plan.JoinNode.Type.LEFT;\n import static com.facebook.presto.sql.planner.plan.JoinNode.Type.RIGHT;\n import static com.facebook.presto.sql.planner.plan.Patterns.join;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.String.format;\n \n public class RuntimeReorderJoinSides\n         implements Rule<JoinNode>\n {\n-    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+    private static final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n \n     private static final Pattern<JoinNode> PATTERN = join();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Nzk2Mg==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r453997962", "bodyText": "Use pattern Probe size: %s is smaller than build size: %s => ...", "author": "arhimondr", "createdAt": "2020-07-13T23:10:08Z", "path": "presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.facebook.presto.sql.planner.iterative.rule;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.cost.StatsProvider;\n+import com.facebook.presto.matching.Captures;\n+import com.facebook.presto.matching.Pattern;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.facebook.presto.sql.planner.iterative.Rule;\n+import com.facebook.presto.sql.planner.plan.ExchangeNode;\n+import com.facebook.presto.sql.planner.plan.JoinNode;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+\n+import static com.facebook.presto.SystemSessionProperties.getTaskConcurrency;\n+import static com.facebook.presto.sql.planner.optimizations.PlanNodeSearcher.searchFrom;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.Scope.LOCAL;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.gatheringExchange;\n+import static com.facebook.presto.sql.planner.plan.ExchangeNode.systemPartitionedExchange;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.DistributionType.PARTITIONED;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.DistributionType.REPLICATED;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.Type.LEFT;\n+import static com.facebook.presto.sql.planner.plan.JoinNode.Type.RIGHT;\n+import static com.facebook.presto.sql.planner.plan.Patterns.join;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+\n+public class RuntimeReorderJoinSides\n+        implements Rule<JoinNode>\n+{\n+    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+\n+    private static final Pattern<JoinNode> PATTERN = join();\n+\n+    @Override\n+    public Pattern<JoinNode> getPattern()\n+    {\n+        return PATTERN;\n+    }\n+\n+    @Override\n+    public Result apply(JoinNode joinNode, Captures captures, Context context)\n+    {\n+        // Early exit if the leaves of the joinNode subtree include non tableScan nodes.\n+        if (searchFrom(joinNode, context.getLookup())\n+                .where(node -> node.getSources().isEmpty() && !(node instanceof TableScanNode))\n+                .matches()) {\n+            return Result.empty();\n+        }\n+\n+        StatsProvider statsProvider = context.getStatsProvider();\n+        double leftOutputSizeInBytes = statsProvider.getStats(joinNode.getLeft()).getOutputSizeInBytes(joinNode.getLeft().getOutputVariables());\n+        double rightOutputSizeInBytes = statsProvider.getStats(joinNode.getRight()).getOutputSizeInBytes(joinNode.getRight().getOutputVariables());\n+        if (Double.isNaN(leftOutputSizeInBytes) || Double.isNaN(rightOutputSizeInBytes)) {\n+            return Result.empty();\n+        }\n+        if (rightOutputSizeInBytes <= leftOutputSizeInBytes) {\n+            return Result.empty();\n+        }\n+\n+        // Check if the swapped join is valid.\n+        if (!isSwappedJoinValid(joinNode)) {\n+            return Result.empty();\n+        }\n+        JoinNode swapped = joinNode.flipChildren();\n+\n+        PlanNode newLeft = swapped.getLeft();\n+        PlanNode resolvedSwappedLeft = context.getLookup().resolve(newLeft);\n+        // Remove unnecessary LocalExchange in the current probe side. If the immediate left child (new probe side) of the join node\n+        // is a localExchange, there are two cases: an Exchange introduced by the current probe side (previous build side); or it is a UnionNode.\n+        // If the exchangeNode has more than 1 sources, it corresponds to the second case, otherwise it corresponds to the first case and safe to remove\n+        Optional<VariableReferenceExpression> leftHashVariable = swapped.getLeftHashVariable();\n+        if (resolvedSwappedLeft instanceof ExchangeNode && resolvedSwappedLeft.getSources().size() == 1) {\n+            newLeft = resolvedSwappedLeft.getSources().get(0);\n+            // The HashGenerationOptimizer will generate hashVariables and append to the output layout of the nodes following the same order. Therefore,\n+            // we use the index of the old hashVariable in the ExchangeNode output layout to retrieve the hashVariable from the new left node, and feed\n+            // it as the leftHashVariable of the swapped join node.\n+            if (swapped.getLeftHashVariable().isPresent()) {\n+                int hashVariableIndex = resolvedSwappedLeft.getOutputVariables().indexOf(swapped.getLeftHashVariable().get());\n+                leftHashVariable = Optional.of(resolvedSwappedLeft.getSources().get(0).getOutputVariables().get(hashVariableIndex));\n+            }\n+        }\n+\n+        // Add additional localExchange if the new build side does not satisfy the partitioning conditions.\n+        List<VariableReferenceExpression> buildJoinVariables = swapped.getCriteria().stream()\n+                .map(JoinNode.EquiJoinClause::getRight)\n+                .collect(toImmutableList());\n+        PlanNode newRight = swapped.getRight();\n+        if (needLocalExchange(swapped.getRight(), ImmutableSet.copyOf(buildJoinVariables), context)) {\n+            if (getTaskConcurrency(context.getSession()) > 1) {\n+                newRight = systemPartitionedExchange(\n+                        context.getIdAllocator().getNextId(),\n+                        LOCAL,\n+                        swapped.getRight(),\n+                        buildJoinVariables,\n+                        swapped.getRightHashVariable());\n+            }\n+            else {\n+                newRight = gatheringExchange(context.getIdAllocator().getNextId(), LOCAL, swapped.getRight());\n+            }\n+        }\n+\n+        JoinNode newJoinNode = new JoinNode(\n+                swapped.getId(),\n+                swapped.getType(),\n+                newLeft,\n+                newRight,\n+                swapped.getCriteria(),\n+                swapped.getOutputVariables(),\n+                swapped.getFilter(),\n+                leftHashVariable,\n+                swapped.getRightHashVariable(),\n+                swapped.getDistributionType());\n+\n+        log.debug(\"Probe size: \" + leftOutputSizeInBytes + \" is smaller than Build size: \" + rightOutputSizeInBytes + \" => invoke runtime join swapping on JoinNode ID: \" + newJoinNode.getId());", "originalCommit": "8e7d5f04a7cf3d2dce05adcf9340ab6873da9073", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "455d053e5458eb49cfb20d210d5628532367d94e", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\nindex 959708fff6..03008a9c89 100644\n--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/iterative/rule/RuntimeReorderJoinSides.java\n\n@@ -41,11 +41,12 @@ import static com.facebook.presto.sql.planner.plan.JoinNode.Type.LEFT;\n import static com.facebook.presto.sql.planner.plan.JoinNode.Type.RIGHT;\n import static com.facebook.presto.sql.planner.plan.Patterns.join;\n import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.String.format;\n \n public class RuntimeReorderJoinSides\n         implements Rule<JoinNode>\n {\n-    private final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n+    private static final Logger log = Logger.get(RuntimeReorderJoinSides.class);\n \n     private static final Pattern<JoinNode> PATTERN = join();\n \n"}}, {"oid": "455d053e5458eb49cfb20d210d5628532367d94e", "url": "https://github.com/prestodb/presto/commit/455d053e5458eb49cfb20d210d5628532367d94e", "message": "Fix broken LivePlan statistics\n\nThe Live Plan graph shown in the web UI is generated from parsing the\njsonRepresentation of each PlanFragment, not actually tracing the plan\nnode dependency graph. Therefore, when generating the new PlanFragment\nafter runtime optimizations, the jsonRepresentation of the fragment\nneeds to be updated.", "committedDate": "2020-07-14T01:31:48Z", "type": "forcePushed"}, {"oid": "45f9a57a5330668ecb3f1c5636b2fef7f668bd19", "url": "https://github.com/prestodb/presto/commit/45f9a57a5330668ecb3f1c5636b2fef7f668bd19", "message": "Fix broken LivePlan statistics\n\nThe Live Plan graph shown in the web UI is generated from parsing the\njsonRepresentation of each PlanFragment, not actually tracing the plan\nnode dependency graph. Therefore, when generating the new PlanFragment\nafter runtime optimizations, the jsonRepresentation of the fragment\nneeds to be updated.", "committedDate": "2020-07-14T14:01:32Z", "type": "forcePushed"}, {"oid": "8752111f3386f38b842ef968eac720a0e92bbbe5", "url": "https://github.com/prestodb/presto/commit/8752111f3386f38b842ef968eac720a0e92bbbe5", "message": "Skip runtime swapping for nested inner join", "committedDate": "2020-07-15T14:34:16Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ1MTQyNQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r454451425", "bodyText": "No need to pass the variableAllocator here - createSubPlans creates a variableallocator in the exact same way.", "author": "rschlussel", "createdAt": "2020-07-14T15:39:20Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java", "diffHunk": "@@ -384,7 +389,9 @@ private PlanRoot doAnalyzeQuery()\n         stateMachine.setOutput(output);\n \n         // fragment the plan\n-        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, stateMachine.getWarningCollector());\n+        // the variableAllocator is finally passed to SqlQueryScheduler for runtime cost-based optimizations\n+        variableAllocator.set(new PlanVariableAllocator(plan.getTypes().allVariables()));\n+        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, variableAllocator.get(), stateMachine.getWarningCollector());", "originalCommit": "8fe1d5e5126daa5f33073bfd73ce3f4ce7e380dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTE0MjA5NQ==", "url": "https://github.com/prestodb/presto/pull/14675#discussion_r455142095", "bodyText": "Yes, createSubPlans internally create a variableAllocator this way, but we want this variableAllocator to be exposed after creating the subplans, and then use it for runtime optimizers. Therefore, we moved the creation outside here, pass it in as an argument, and later on can feed it in SqlQueryScheduler.", "author": "pguofb", "createdAt": "2020-07-15T15:29:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQ1MTQyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "76f74999c411b559acc712f29fe4b89c08d7b119", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java b/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java\nindex 6d2be5b938..276b3109a8 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/SqlQueryExecution.java\n\n@@ -389,9 +388,7 @@ public class SqlQueryExecution\n         stateMachine.setOutput(output);\n \n         // fragment the plan\n-        // the variableAllocator is finally passed to SqlQueryScheduler for runtime cost-based optimizations\n-        variableAllocator.set(new PlanVariableAllocator(plan.getTypes().allVariables()));\n-        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, variableAllocator.get(), stateMachine.getWarningCollector());\n+        SubPlan fragmentedPlan = planFragmenter.createSubPlans(stateMachine.getSession(), plan, false, idAllocator, stateMachine.getWarningCollector());\n \n         // record analysis time\n         stateMachine.endAnalysis();\n"}}, {"oid": "cad2c36d9fddfcea8f716f01929ee06a7bf10b03", "url": "https://github.com/prestodb/presto/commit/cad2c36d9fddfcea8f716f01929ee06a7bf10b03", "message": "Invoke CBO at SqlQueryScheduler for Join Swapping\n\n- Pass in CBO and make it invokable at [Legacy/]SqlQueryScheduler\nduring runtime.\n- Rename get() method of PlanOptimizers to\ngetPlanningTimeOptimizers() to distinguish getRuntimeOptimizers()\n- Adjust IterativeOptimizer optimize() function to return the original\nplan when the plan is not changed, instead of always calling\nmemo.extract() to rebuild a new one.\n- Create a join swapping rule (RuntimeReorderJoinSides) based on\nthe probe and build side statistics, and adjust the local exchange\nwhen necessary (add at build side, remove at probe side).\n- Rebuild the section, re-generate stageExecutionAndSchedulers of the\nsection, and adjust the overall subplan when the join is swapped to\nreflect correct statistics to web UI and QueryCompletionEvent.", "committedDate": "2020-07-15T15:19:29Z", "type": "forcePushed"}, {"oid": "e60d5a370e73a2e5efd80ac31620b7f86cfe5d52", "url": "https://github.com/prestodb/presto/commit/e60d5a370e73a2e5efd80ac31620b7f86cfe5d52", "message": "Invoke CBO at SqlQueryScheduler for Join Swapping\n\n- Pass in CBO and make it invokable at [Legacy/]SqlQueryScheduler\nduring runtime.\n- Rename get() method of PlanOptimizers to\ngetPlanningTimeOptimizers() to distinguish getRuntimeOptimizers()\n- Adjust IterativeOptimizer optimize() function to return the original\nplan when the plan is not changed, instead of always calling\nmemo.extract() to rebuild a new one.\n- Create a join swapping rule (RuntimeReorderJoinSides) based on\nthe probe and build side statistics, and adjust the local exchange\nwhen necessary (add at build side, remove at probe side).\n- Rebuild the section, re-generate stageExecutionAndSchedulers of the\nsection, and adjust the overall subplan when the join is swapped to\nreflect the correct statistics to web UI and QueryCompletionEvent.", "committedDate": "2020-07-15T15:33:12Z", "type": "forcePushed"}, {"oid": "76f74999c411b559acc712f29fe4b89c08d7b119", "url": "https://github.com/prestodb/presto/commit/76f74999c411b559acc712f29fe4b89c08d7b119", "message": "Add a session property for runtime optimizer", "committedDate": "2020-07-15T17:42:59Z", "type": "commit"}, {"oid": "054d36a0def54fed3e385b70b607c9f918fc8376", "url": "https://github.com/prestodb/presto/commit/054d36a0def54fed3e385b70b607c9f918fc8376", "message": "Invoke CBO at SqlQueryScheduler for Join Swapping\n\n- Pass in CBO and make it invokable at [Legacy/]SqlQueryScheduler\nduring runtime.\n- Rename get() method of PlanOptimizers to\ngetPlanningTimeOptimizers() to distinguish getRuntimeOptimizers()\n- Adjust IterativeOptimizer optimize() function to return the original\nplan when the plan is not changed, instead of always calling\nmemo.extract() to rebuild a new one.\n- Create a join swapping rule (RuntimeReorderJoinSides) based on\nthe probe and build side statistics, and adjust the local exchange\nwhen necessary (add at build side, remove at probe side).\n- Rebuild the section, re-generate stageExecutionAndSchedulers of the\nsection, and adjust the overall subplan when the join is swapped to\nreflect the correct statistics to web UI and QueryCompletionEvent.", "committedDate": "2020-07-15T17:46:19Z", "type": "commit"}, {"oid": "054d36a0def54fed3e385b70b607c9f918fc8376", "url": "https://github.com/prestodb/presto/commit/054d36a0def54fed3e385b70b607c9f918fc8376", "message": "Invoke CBO at SqlQueryScheduler for Join Swapping\n\n- Pass in CBO and make it invokable at [Legacy/]SqlQueryScheduler\nduring runtime.\n- Rename get() method of PlanOptimizers to\ngetPlanningTimeOptimizers() to distinguish getRuntimeOptimizers()\n- Adjust IterativeOptimizer optimize() function to return the original\nplan when the plan is not changed, instead of always calling\nmemo.extract() to rebuild a new one.\n- Create a join swapping rule (RuntimeReorderJoinSides) based on\nthe probe and build side statistics, and adjust the local exchange\nwhen necessary (add at build side, remove at probe side).\n- Rebuild the section, re-generate stageExecutionAndSchedulers of the\nsection, and adjust the overall subplan when the join is swapped to\nreflect the correct statistics to web UI and QueryCompletionEvent.", "committedDate": "2020-07-15T17:46:19Z", "type": "forcePushed"}]}