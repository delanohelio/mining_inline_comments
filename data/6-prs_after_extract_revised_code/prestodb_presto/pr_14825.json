{"pr_number": 14825, "pr_title": "Presto spark query info", "pr_createdAt": "2020-07-10T17:17:10Z", "pr_url": "https://github.com/prestodb/presto/pull/14825", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA2NzIxMQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453067211", "bodyText": "I think it's right to use TaskInfo instead of TaskStats. Just curious why previous TaskStats is chosen?", "author": "wenleix", "createdAt": "2020-07-10T20:40:51Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkModule.java", "diffHunk": "@@ -206,7 +206,7 @@ protected void setup(Binder binder)\n \n         // json codecs\n         jsonCodecBinder(binder).bindJsonCodec(ViewDefinition.class);\n-        jsonCodecBinder(binder).bindJsonCodec(TaskStats.class);\n+        jsonCodecBinder(binder).bindJsonCodec(TaskInfo.class);", "originalCommit": "239e5b3f42fbbab413c86809826e44fe3ebde84e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc5MjUwMA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453792500", "bodyText": "Just curious why previous TaskStats is chosen?\n\nJust some premature coding. I was trying to prototype something, and hadn't finish =)", "author": "arhimondr", "createdAt": "2020-07-13T16:55:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA2NzIxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkModule.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkModule.java\nindex 862da05cd9..9f89b3c7b2 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkModule.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkModule.java\n\n@@ -214,6 +215,7 @@ public class PrestoSparkModule\n         jsonCodecBinder(binder).bindJsonCodec(ExecutionFailureInfo.class);\n         jsonCodecBinder(binder).bindJsonCodec(StageInfo.class);\n         jsonCodecBinder(binder).bindJsonCodec(OperatorStats.class);\n+        jsonCodecBinder(binder).bindJsonCodec(QueryInfo.class);\n \n         // index manager\n         binder.bind(IndexManager.class).in(Scopes.SINGLETON);\n"}}, {"oid": "572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "url": "https://github.com/prestodb/presto/commit/572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "message": "Allow query info to be stored in a file upon query finish\n\nThis will allow to retrieve query id, stack trace and potentially\nother debug information upon query completition", "committedDate": "2020-07-13T16:56:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MjA1Ng==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453882056", "bodyText": "nit: looks like only \"ROW\" and \"PAGE\" can be valid input to this String, what about make it to be an enum?\nI am asking this because I originally thought it's a Presto type (e..g  BIGINT, ARRAY(VARCHAR) )", "author": "wenleix", "createdAt": "2020-07-13T19:30:14Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java", "diffHunk": "@@ -33,8 +35,12 @@\n     @GuardedBy(\"monitor\")\n     private boolean finished;\n \n-    public PrestoSparkOutputBuffer(OutputBufferMemoryManager memoryManager)\n+    private final AtomicLong totalRowsProcessed = new AtomicLong();\n+    private final AtomicLong totalPagesProcessed = new AtomicLong();\n+\n+    public PrestoSparkOutputBuffer(String type, OutputBufferMemoryManager memoryManager)", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMTE2Nw==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454021167", "bodyText": "Technically it can accept anything that implements PrestoSparkBufferedResult. What do you think about renaming type to something like description?", "author": "arhimondr", "createdAt": "2020-07-14T00:15:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MjA1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDQwNjkwMw==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454406903", "bodyText": "Actually I removed this fields from the PrestoSparkOutputBuffer class and added private enum OutputBufferType in the PrestoSparkTaskExecutorFactory", "author": "arhimondr", "createdAt": "2020-07-14T14:39:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg4MjA1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java\nindex cddeac0ff5..44e0547c60 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java\n\n@@ -35,12 +33,8 @@ public class PrestoSparkOutputBuffer<T extends PrestoSparkBufferedResult>\n     @GuardedBy(\"monitor\")\n     private boolean finished;\n \n-    private final AtomicLong totalRowsProcessed = new AtomicLong();\n-    private final AtomicLong totalPagesProcessed = new AtomicLong();\n-\n-    public PrestoSparkOutputBuffer(String type, OutputBufferMemoryManager memoryManager)\n+    public PrestoSparkOutputBuffer(OutputBufferMemoryManager memoryManager)\n     {\n-        this.type = requireNonNull(type, \"type is null\");\n         this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5NTYzNA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453895634", "bodyText": "is this for debug?", "author": "wenleix", "createdAt": "2020-07-13T19:56:18Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskInfo.java", "diffHunk": "@@ -20,15 +20,25 @@\n public class SerializedTaskInfo\n         implements Serializable\n {\n+    private final int fragmentId;\n+    private final int taskId;\n     private final byte[] bytes;\n \n-    public SerializedTaskInfo(byte[] bytes)\n+    public SerializedTaskInfo(int fragmentId, int taskId, byte[] bytes)\n     {\n+        this.fragmentId = fragmentId;\n+        this.taskId = taskId;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return fragmentId + \".\" + taskId;", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMDE5NA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454020194", "bodyText": "This is to avoid byte[] being displayed on the Spark UI", "author": "arhimondr", "createdAt": "2020-07-14T00:11:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg5NTYzNA=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskInfo.java b/presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskStats.java\nsimilarity index 73%\nrename from presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskInfo.java\nrename to presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskStats.java\nindex c346733428..4f532cd487 100644\n--- a/presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskInfo.java\n+++ b/presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/SerializedTaskStats.java\n\n@@ -17,17 +17,13 @@ import java.io.Serializable;\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedTaskInfo\n+public class SerializedTaskStats\n         implements Serializable\n {\n-    private final int fragmentId;\n-    private final int taskId;\n     private final byte[] bytes;\n \n-    public SerializedTaskInfo(int fragmentId, int taskId, byte[] bytes)\n+    public SerializedTaskStats(byte[] bytes)\n     {\n-        this.fragmentId = fragmentId;\n-        this.taskId = taskId;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NDE0Nw==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453964147", "bodyText": "curious: how do we avoid byte[] being displayed on Spark UI?", "author": "wenleix", "createdAt": "2020-07-13T22:03:25Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -478,14 +496,17 @@ public boolean hasNext()\n                 return output;\n             }\n \n-            //  TODO: Implement task stats collection\n-            //  TaskStats taskStats = taskContext.getTaskStats();\n-            //  byte[] taskStatsSerialized = taskInfoJsonCodec.toJsonBytes(taskStats);\n-            //  taskStatsCollector.add(new SerializedTaskStats(taskStatsSerialized));\n-\n             // task finished\n             TaskState taskState = taskStateMachine.getState();\n             checkState(taskState.isDone(), \"task is expected to be done\");\n+\n+            TaskInfo taskInfo = createTaskInfo(taskContext, taskStateMachine, taskInstanceId, outputBuffer);\n+            SerializedTaskInfo serializedTaskInfo = new SerializedTaskInfo(\n+                    taskInfo.getTaskId().getStageExecutionId().getStageId().getId(),\n+                    taskInfo.getTaskId().getId(),\n+                    compress(taskInfoJsonCodec.toJsonBytes(taskInfo)));\n+            taskInfoCollector.add(serializedTaskInfo);", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMDI0MA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454020240", "bodyText": "Answered in the previous comment", "author": "arhimondr", "createdAt": "2020-07-14T00:12:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NDE0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java\nindex 897e64e591..aa38be7c76 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java\n\n@@ -496,17 +478,14 @@ public class PrestoSparkTaskExecutorFactory\n                 return output;\n             }\n \n+            //  TODO: Implement task stats collection\n+            //  TaskStats taskStats = taskContext.getTaskStats();\n+            //  byte[] taskStatsSerialized = taskStatsJsonCodec.toJsonBytes(taskStats);\n+            //  taskStatsCollector.add(new SerializedTaskStats(taskStatsSerialized));\n+\n             // task finished\n             TaskState taskState = taskStateMachine.getState();\n             checkState(taskState.isDone(), \"task is expected to be done\");\n-\n-            TaskInfo taskInfo = createTaskInfo(taskContext, taskStateMachine, taskInstanceId, outputBuffer);\n-            SerializedTaskInfo serializedTaskInfo = new SerializedTaskInfo(\n-                    taskInfo.getTaskId().getStageExecutionId().getStageId().getId(),\n-                    taskInfo.getTaskId().getId(),\n-                    compress(taskInfoJsonCodec.toJsonBytes(taskInfo)));\n-            taskInfoCollector.add(serializedTaskInfo);\n-\n             LinkedBlockingQueue<Throwable> failures = taskStateMachine.getFailureCauses();\n             if (failures.isEmpty()) {\n                 return null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk2NjM0OQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453966349", "bodyText": "Assume it's copied from QueryStateMachine#getQueryStats.", "author": "wenleix", "createdAt": "2020-07-13T22:06:37Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java", "diffHunk": "@@ -240,6 +246,207 @@ public QueryStats(\n         this.operatorSummaries = ImmutableList.copyOf(requireNonNull(operatorSummaries, \"operatorSummaries is null\"));\n     }\n \n+    public static QueryStats create(", "originalCommit": "27d88f04c6454b8aa63b36d0eec9e86049d6e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java b/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java\nindex 8ed650c9f5..84f7a509a4 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java\n\n@@ -246,207 +240,6 @@ public class QueryStats\n         this.operatorSummaries = ImmutableList.copyOf(requireNonNull(operatorSummaries, \"operatorSummaries is null\"));\n     }\n \n-    public static QueryStats create(\n-            QueryStateTimer queryStateTimer,\n-            Optional<StageInfo> rootStage,\n-            int peakRunningTasks,\n-            DataSize peakUserMemoryReservation,\n-            DataSize peakTotalMemoryReservation,\n-            DataSize peakTaskUserMemory,\n-            DataSize peakTaskTotalMemory)\n-    {\n-        int totalTasks = 0;\n-        int runningTasks = 0;\n-        int completedTasks = 0;\n-\n-        int totalDrivers = 0;\n-        int queuedDrivers = 0;\n-        int runningDrivers = 0;\n-        int blockedDrivers = 0;\n-        int completedDrivers = 0;\n-\n-        long cumulativeUserMemory = 0;\n-        long userMemoryReservation = 0;\n-        long totalMemoryReservation = 0;\n-\n-        long totalScheduledTime = 0;\n-        long totalCpuTime = 0;\n-        long retriedCpuTime = 0;\n-        long totalBlockedTime = 0;\n-\n-        long totalAllocation = 0;\n-\n-        long rawInputDataSize = 0;\n-        long rawInputPositions = 0;\n-\n-        long processedInputDataSize = 0;\n-        long processedInputPositions = 0;\n-\n-        long outputDataSize = 0;\n-        long outputPositions = 0;\n-\n-        long writtenOutputPositions = 0;\n-        long writtenOutputLogicalDataSize = 0;\n-        long writtenOutputPhysicalDataSize = 0;\n-\n-        long writtenIntermediatePhysicalDataSize = 0;\n-\n-        ImmutableList.Builder<StageGcStatistics> stageGcStatistics = ImmutableList.builder();\n-\n-        boolean fullyBlocked = rootStage.isPresent();\n-        Set<BlockedReason> blockedReasons = new HashSet<>();\n-\n-        ImmutableList.Builder<OperatorStats> operatorStatsSummary = ImmutableList.builder();\n-        boolean completeInfo = true;\n-        for (StageInfo stageInfo : getAllStages(rootStage)) {\n-            StageExecutionStats stageExecutionStats = stageInfo.getLatestAttemptExecutionInfo().getStats();\n-            totalTasks += stageExecutionStats.getTotalTasks();\n-            runningTasks += stageExecutionStats.getRunningTasks();\n-            completedTasks += stageExecutionStats.getCompletedTasks();\n-\n-            totalDrivers += stageExecutionStats.getTotalDrivers();\n-            queuedDrivers += stageExecutionStats.getQueuedDrivers();\n-            runningDrivers += stageExecutionStats.getRunningDrivers();\n-            blockedDrivers += stageExecutionStats.getBlockedDrivers();\n-            completedDrivers += stageExecutionStats.getCompletedDrivers();\n-\n-            cumulativeUserMemory += stageExecutionStats.getCumulativeUserMemory();\n-            userMemoryReservation += stageExecutionStats.getUserMemoryReservation().toBytes();\n-            totalMemoryReservation += stageExecutionStats.getTotalMemoryReservation().toBytes();\n-            totalScheduledTime += stageExecutionStats.getTotalScheduledTime().roundTo(MILLISECONDS);\n-            totalCpuTime += stageExecutionStats.getTotalCpuTime().roundTo(MILLISECONDS);\n-            retriedCpuTime += computeRetriedCpuTime(stageInfo);\n-            totalBlockedTime += stageExecutionStats.getTotalBlockedTime().roundTo(MILLISECONDS);\n-            if (!stageInfo.getLatestAttemptExecutionInfo().getState().isDone()) {\n-                fullyBlocked &= stageExecutionStats.isFullyBlocked();\n-                blockedReasons.addAll(stageExecutionStats.getBlockedReasons());\n-            }\n-\n-            totalAllocation += stageExecutionStats.getTotalAllocation().toBytes();\n-\n-            if (stageInfo.getPlan().isPresent()) {\n-                PlanFragment plan = stageInfo.getPlan().get();\n-                if (!plan.getTableScanSchedulingOrder().isEmpty()) {\n-                    rawInputDataSize += stageExecutionStats.getRawInputDataSize().toBytes();\n-                    rawInputPositions += stageExecutionStats.getRawInputPositions();\n-\n-                    processedInputDataSize += stageExecutionStats.getProcessedInputDataSize().toBytes();\n-                    processedInputPositions += stageExecutionStats.getProcessedInputPositions();\n-                }\n-\n-                if (plan.isOutputTableWriterFragment()) {\n-                    writtenOutputPositions += stageExecutionStats.getOperatorSummaries().stream()\n-                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n-                            .mapToLong(OperatorStats::getInputPositions)\n-                            .sum();\n-                    writtenOutputLogicalDataSize += stageExecutionStats.getOperatorSummaries().stream()\n-                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n-                            .mapToLong(stats -> stats.getInputDataSize().toBytes())\n-                            .sum();\n-                    writtenOutputPhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n-                }\n-                else {\n-                    writtenIntermediatePhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n-                }\n-            }\n-\n-            stageGcStatistics.add(stageExecutionStats.getGcInfo());\n-\n-            completeInfo = completeInfo && stageInfo.isFinalStageInfo();\n-            operatorStatsSummary.addAll(stageExecutionStats.getOperatorSummaries());\n-        }\n-\n-        if (rootStage.isPresent()) {\n-            StageExecutionStats outputStageStats = rootStage.get().getLatestAttemptExecutionInfo().getStats();\n-            outputDataSize += outputStageStats.getOutputDataSize().toBytes();\n-            outputPositions += outputStageStats.getOutputPositions();\n-        }\n-\n-        boolean isScheduled = isScheduled(rootStage);\n-\n-        return new QueryStats(\n-                queryStateTimer.getCreateTime(),\n-                queryStateTimer.getExecutionStartTime().orElse(null),\n-                queryStateTimer.getLastHeartbeat(),\n-                queryStateTimer.getEndTime().orElse(null),\n-\n-                queryStateTimer.getElapsedTime(),\n-                queryStateTimer.getQueuedTime(),\n-                queryStateTimer.getResourceWaitingTime(),\n-                queryStateTimer.getDispatchingTime(),\n-                queryStateTimer.getExecutionTime(),\n-                queryStateTimer.getAnalysisTime(),\n-                queryStateTimer.getPlanningTime(),\n-                queryStateTimer.getFinishingTime(),\n-\n-                totalTasks,\n-                runningTasks,\n-                peakRunningTasks,\n-                completedTasks,\n-\n-                totalDrivers,\n-                queuedDrivers,\n-                runningDrivers,\n-                blockedDrivers,\n-                completedDrivers,\n-\n-                cumulativeUserMemory,\n-                succinctBytes(userMemoryReservation),\n-                succinctBytes(totalMemoryReservation),\n-                peakUserMemoryReservation,\n-                peakTotalMemoryReservation,\n-                peakTaskUserMemory,\n-                peakTaskTotalMemory,\n-\n-                isScheduled,\n-\n-                succinctDuration(totalScheduledTime, MILLISECONDS),\n-                succinctDuration(totalCpuTime, MILLISECONDS),\n-                succinctDuration(retriedCpuTime, MILLISECONDS),\n-                succinctDuration(totalBlockedTime, MILLISECONDS),\n-                fullyBlocked,\n-                blockedReasons,\n-\n-                succinctBytes(totalAllocation),\n-\n-                succinctBytes(rawInputDataSize),\n-                rawInputPositions,\n-                succinctBytes(processedInputDataSize),\n-                processedInputPositions,\n-                succinctBytes(outputDataSize),\n-                outputPositions,\n-\n-                writtenOutputPositions,\n-                succinctBytes(writtenOutputLogicalDataSize),\n-                succinctBytes(writtenOutputPhysicalDataSize),\n-\n-                succinctBytes(writtenIntermediatePhysicalDataSize),\n-\n-                stageGcStatistics.build(),\n-\n-                operatorStatsSummary.build());\n-    }\n-\n-    private static boolean isScheduled(Optional<StageInfo> rootStage)\n-    {\n-        if (!rootStage.isPresent()) {\n-            return false;\n-        }\n-        return getAllStages(rootStage).stream()\n-                .map(StageInfo::getLatestAttemptExecutionInfo)\n-                .map(StageExecutionInfo::getState)\n-                .allMatch(state -> (state == StageExecutionState.RUNNING) || state.isDone());\n-    }\n-\n-    private static long computeRetriedCpuTime(StageInfo stageInfo)\n-    {\n-        long stageRetriedCpuTime = stageInfo.getPreviousAttemptsExecutionInfos().stream()\n-                .mapToLong(executionInfo -> executionInfo.getStats().getTotalCpuTime().roundTo(MILLISECONDS))\n-                .sum();\n-        long taskRetriedCpuTime = stageInfo.getLatestAttemptExecutionInfo().getStats().getRetriedCpuTime().roundTo(MILLISECONDS);\n-        return stageRetriedCpuTime + taskRetriedCpuTime;\n-    }\n-\n     public static QueryStats immediateFailureQueryStats()\n     {\n         DateTime now = DateTime.now();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njk3Mg==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453976972", "bodyText": "I personally don't prefer to have Optional<Collection<>> as configuration, as the semantic difference between \"not present\" and \"presented but empty\" can be very tricky. Can we enforce eventListenerProperties always have to present? (EVENT_LISTENER_PROPERTY_NAME can be set to a special value such as \"NO_EVENT_LISTENER\")  ?", "author": "wenleix", "createdAt": "2020-07-13T22:22:29Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkInjectorFactory.java", "diffHunk": "@@ -46,29 +46,33 @@\n     private final SparkProcessType sparkProcessType;\n     private final Map<String, String> configProperties;\n     private final Map<String, Map<String, String>> catalogProperties;\n+    private final Optional<Map<String, String>> eventListenerProperties;", "originalCommit": "2cd44517170115bd7d9deb0a0cebfcc87d3d4694", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMTYxNg==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454021616", "bodyText": "I would rather prefer it to be explicitly. One can read it as event listener is not configured - eventListenerProperties = Optional.empty(). Or event listener is configured - the the Optional contains configuration properties for event listener.", "author": "arhimondr", "createdAt": "2020-07-14T00:16:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3Njk3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkInjectorFactory.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkInjectorFactory.java\nindex df2241ab69..b610f7fee1 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkInjectorFactory.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkInjectorFactory.java\n\n@@ -46,7 +46,6 @@ public class PrestoSparkInjectorFactory\n     private final SparkProcessType sparkProcessType;\n     private final Map<String, String> configProperties;\n     private final Map<String, Map<String, String>> catalogProperties;\n-    private final Optional<Map<String, String>> eventListenerProperties;\n     private final List<Module> additionalModules;\n     private final Optional<Module> accessControlModuleOverride;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MjY1MQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453982651", "bodyText": "nit: one line per parameter.", "author": "wenleix", "createdAt": "2020-07-13T22:31:18Z", "path": "presto-spark-launcher/src/main/java/com/facebook/presto/spark/launcher/PrestoSparkLauncherCommand.java", "diffHunk": "@@ -62,7 +62,7 @@ public void run()\n         String query = readFileUtf8(checkFile(new File(clientOptions.file)));\n \n         try (PrestoSparkRunner runner = new PrestoSparkRunner(distribution)) {\n-            runner.run(clientOptions.catalog, clientOptions.schema, query, ImmutableMap.of(), ImmutableMap.of());\n+            runner.run(clientOptions.catalog, clientOptions.schema, query, ImmutableMap.of(), ImmutableMap.of(), Optional.empty());", "originalCommit": "572b05208f9c684b6ce5a0ac15b9ca491b41c09d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-launcher/src/main/java/com/facebook/presto/spark/launcher/PrestoSparkLauncherCommand.java b/presto-spark-launcher/src/main/java/com/facebook/presto/spark/launcher/PrestoSparkLauncherCommand.java\nindex 182b922c18..63aefd9c8b 100644\n--- a/presto-spark-launcher/src/main/java/com/facebook/presto/spark/launcher/PrestoSparkLauncherCommand.java\n+++ b/presto-spark-launcher/src/main/java/com/facebook/presto/spark/launcher/PrestoSparkLauncherCommand.java\n\n@@ -56,13 +55,12 @@ public class PrestoSparkLauncherCommand\n                 sparkContext,\n                 packageSupplier,\n                 loadProperties(checkFile(new File(clientOptions.config))),\n-                loadCatalogProperties(new File(clientOptions.catalogs)),\n-                Optional.empty());\n+                loadCatalogProperties(new File(clientOptions.catalogs)));\n \n         String query = readFileUtf8(checkFile(new File(clientOptions.file)));\n \n         try (PrestoSparkRunner runner = new PrestoSparkRunner(distribution)) {\n-            runner.run(clientOptions.catalog, clientOptions.schema, query, ImmutableMap.of(), ImmutableMap.of(), Optional.empty());\n+            runner.run(clientOptions.catalog, clientOptions.schema, query, ImmutableMap.of(), ImmutableMap.of());\n         }\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MTc5OQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453981799", "bodyText": "Is it possible for rowBatch to be Type PrestoSparkBufferedSerializedPage,  then we can just call it batch.", "author": "viczhang861", "createdAt": "2020-07-13T22:30:11Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java", "diffHunk": "@@ -79,6 +85,25 @@ public T get()\n                 memoryManager.updateMemoryUsage(-rowBatch.getRetainedSizeInBytes());\n             }\n         }\n+        if (rowBatch != null) {", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAyMTg0NA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454021844", "bodyText": "PrestoSparkBufferedSerializedPage is technically still a batch of rows, just encoded in a columnar fashion", "author": "arhimondr", "createdAt": "2020-07-14T00:17:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MTc5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java\nindex cddeac0ff5..44e0547c60 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputBuffer.java\n\n@@ -85,25 +79,6 @@ public class PrestoSparkOutputBuffer<T extends PrestoSparkBufferedResult>\n                 memoryManager.updateMemoryUsage(-rowBatch.getRetainedSizeInBytes());\n             }\n         }\n-        if (rowBatch != null) {\n-            totalPagesProcessed.incrementAndGet();\n-            totalRowsProcessed.addAndGet(rowBatch.getPositionCount());\n-        }\n         return rowBatch;\n     }\n-\n-    public String getType()\n-    {\n-        return type;\n-    }\n-\n-    public long getTotalRowsProcessed()\n-    {\n-        return totalRowsProcessed.get();\n-    }\n-\n-    public long getTotalPagesProcessed()\n-    {\n-        return totalPagesProcessed.get();\n-    }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTU1NA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r453991554", "bodyText": "There is a constant in TaskStatus to use STARTING_VERSION", "author": "viczhang861", "createdAt": "2020-07-13T22:50:58Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java", "diffHunk": "@@ -497,6 +518,60 @@ public boolean hasNext()\n             propagateIfPossible(failure, InterruptedException.class);\n             throw new RuntimeException(failure);\n         }\n+\n+        private static TaskInfo createTaskInfo(\n+                TaskContext taskContext,\n+                TaskStateMachine taskStateMachine,\n+                UUID taskInstanceId,\n+                PrestoSparkOutputBuffer<?> outputBuffer)\n+        {\n+            TaskId taskId = taskContext.getTaskId();\n+            TaskState taskState = taskContext.getState();\n+            TaskStats taskStats = taskContext.getTaskStats();\n+\n+            List<ExecutionFailureInfo> failures = ImmutableList.of();\n+            if (taskState == FAILED) {\n+                failures = toFailures(taskStateMachine.getFailureCauses());\n+            }\n+\n+            TaskStatus taskStatus = new TaskStatus(\n+                    taskInstanceId.getLeastSignificantBits(),\n+                    taskInstanceId.getMostSignificantBits(),\n+                    1,", "originalCommit": "5542710ee5adc1fe0eefc4b1f435b669914e433c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java\nindex 897e64e591..aa38be7c76 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkTaskExecutorFactory.java\n\n@@ -518,60 +497,6 @@ public class PrestoSparkTaskExecutorFactory\n             propagateIfPossible(failure, InterruptedException.class);\n             throw new RuntimeException(failure);\n         }\n-\n-        private static TaskInfo createTaskInfo(\n-                TaskContext taskContext,\n-                TaskStateMachine taskStateMachine,\n-                UUID taskInstanceId,\n-                PrestoSparkOutputBuffer<?> outputBuffer)\n-        {\n-            TaskId taskId = taskContext.getTaskId();\n-            TaskState taskState = taskContext.getState();\n-            TaskStats taskStats = taskContext.getTaskStats();\n-\n-            List<ExecutionFailureInfo> failures = ImmutableList.of();\n-            if (taskState == FAILED) {\n-                failures = toFailures(taskStateMachine.getFailureCauses());\n-            }\n-\n-            TaskStatus taskStatus = new TaskStatus(\n-                    taskInstanceId.getLeastSignificantBits(),\n-                    taskInstanceId.getMostSignificantBits(),\n-                    1,\n-                    taskState,\n-                    URI.create(\"http://fake.invalid/task/\" + taskId),\n-                    taskContext.getCompletedDriverGroups(),\n-                    failures,\n-                    taskStats.getQueuedPartitionedDrivers(),\n-                    taskStats.getRunningPartitionedDrivers(),\n-                    0,\n-                    false,\n-                    taskStats.getPhysicalWrittenDataSize().toBytes(),\n-                    taskStats.getUserMemoryReservation().toBytes(),\n-                    taskStats.getSystemMemoryReservation().toBytes(),\n-                    taskStats.getFullGcCount(),\n-                    taskStats.getFullGcTime().toMillis());\n-\n-            OutputBufferInfo outputBufferInfo = new OutputBufferInfo(\n-                    \"SPARK-\" + outputBuffer.getType(),\n-                    FINISHED,\n-                    false,\n-                    false,\n-                    0,\n-                    0,\n-                    outputBuffer.getTotalRowsProcessed(),\n-                    outputBuffer.getTotalPagesProcessed(),\n-                    ImmutableList.of());\n-\n-            return new TaskInfo(\n-                    taskId,\n-                    taskStatus,\n-                    DateTime.now(),\n-                    outputBufferInfo,\n-                    ImmutableSet.of(),\n-                    taskStats,\n-                    false);\n-        }\n     }\n \n     private static class Output<T extends PrestoSparkTaskOutput>\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAzMjUxNQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454032515", "bodyText": "nit, this can be inlined", "author": "viczhang861", "createdAt": "2020-07-14T00:51:18Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java", "diffHunk": "@@ -240,6 +246,207 @@ public QueryStats(\n         this.operatorSummaries = ImmutableList.copyOf(requireNonNull(operatorSummaries, \"operatorSummaries is null\"));\n     }\n \n+    public static QueryStats create(\n+            QueryStateTimer queryStateTimer,\n+            Optional<StageInfo> rootStage,\n+            int peakRunningTasks,\n+            DataSize peakUserMemoryReservation,\n+            DataSize peakTotalMemoryReservation,\n+            DataSize peakTaskUserMemory,\n+            DataSize peakTaskTotalMemory)\n+    {\n+        int totalTasks = 0;\n+        int runningTasks = 0;\n+        int completedTasks = 0;\n+\n+        int totalDrivers = 0;\n+        int queuedDrivers = 0;\n+        int runningDrivers = 0;\n+        int blockedDrivers = 0;\n+        int completedDrivers = 0;\n+\n+        long cumulativeUserMemory = 0;\n+        long userMemoryReservation = 0;\n+        long totalMemoryReservation = 0;\n+\n+        long totalScheduledTime = 0;\n+        long totalCpuTime = 0;\n+        long retriedCpuTime = 0;\n+        long totalBlockedTime = 0;\n+\n+        long totalAllocation = 0;\n+\n+        long rawInputDataSize = 0;\n+        long rawInputPositions = 0;\n+\n+        long processedInputDataSize = 0;\n+        long processedInputPositions = 0;\n+\n+        long outputDataSize = 0;\n+        long outputPositions = 0;\n+\n+        long writtenOutputPositions = 0;\n+        long writtenOutputLogicalDataSize = 0;\n+        long writtenOutputPhysicalDataSize = 0;\n+\n+        long writtenIntermediatePhysicalDataSize = 0;\n+\n+        ImmutableList.Builder<StageGcStatistics> stageGcStatistics = ImmutableList.builder();\n+\n+        boolean fullyBlocked = rootStage.isPresent();\n+        Set<BlockedReason> blockedReasons = new HashSet<>();\n+\n+        ImmutableList.Builder<OperatorStats> operatorStatsSummary = ImmutableList.builder();\n+        boolean completeInfo = true;\n+        for (StageInfo stageInfo : getAllStages(rootStage)) {\n+            StageExecutionStats stageExecutionStats = stageInfo.getLatestAttemptExecutionInfo().getStats();\n+            totalTasks += stageExecutionStats.getTotalTasks();\n+            runningTasks += stageExecutionStats.getRunningTasks();\n+            completedTasks += stageExecutionStats.getCompletedTasks();\n+\n+            totalDrivers += stageExecutionStats.getTotalDrivers();\n+            queuedDrivers += stageExecutionStats.getQueuedDrivers();\n+            runningDrivers += stageExecutionStats.getRunningDrivers();\n+            blockedDrivers += stageExecutionStats.getBlockedDrivers();\n+            completedDrivers += stageExecutionStats.getCompletedDrivers();\n+\n+            cumulativeUserMemory += stageExecutionStats.getCumulativeUserMemory();\n+            userMemoryReservation += stageExecutionStats.getUserMemoryReservation().toBytes();\n+            totalMemoryReservation += stageExecutionStats.getTotalMemoryReservation().toBytes();\n+            totalScheduledTime += stageExecutionStats.getTotalScheduledTime().roundTo(MILLISECONDS);\n+            totalCpuTime += stageExecutionStats.getTotalCpuTime().roundTo(MILLISECONDS);\n+            retriedCpuTime += computeRetriedCpuTime(stageInfo);\n+            totalBlockedTime += stageExecutionStats.getTotalBlockedTime().roundTo(MILLISECONDS);\n+            if (!stageInfo.getLatestAttemptExecutionInfo().getState().isDone()) {\n+                fullyBlocked &= stageExecutionStats.isFullyBlocked();\n+                blockedReasons.addAll(stageExecutionStats.getBlockedReasons());\n+            }\n+\n+            totalAllocation += stageExecutionStats.getTotalAllocation().toBytes();\n+\n+            if (stageInfo.getPlan().isPresent()) {\n+                PlanFragment plan = stageInfo.getPlan().get();\n+                if (!plan.getTableScanSchedulingOrder().isEmpty()) {\n+                    rawInputDataSize += stageExecutionStats.getRawInputDataSize().toBytes();\n+                    rawInputPositions += stageExecutionStats.getRawInputPositions();\n+\n+                    processedInputDataSize += stageExecutionStats.getProcessedInputDataSize().toBytes();\n+                    processedInputPositions += stageExecutionStats.getProcessedInputPositions();\n+                }\n+\n+                if (plan.isOutputTableWriterFragment()) {\n+                    writtenOutputPositions += stageExecutionStats.getOperatorSummaries().stream()\n+                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n+                            .mapToLong(OperatorStats::getInputPositions)\n+                            .sum();\n+                    writtenOutputLogicalDataSize += stageExecutionStats.getOperatorSummaries().stream()\n+                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n+                            .mapToLong(stats -> stats.getInputDataSize().toBytes())\n+                            .sum();\n+                    writtenOutputPhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n+                }\n+                else {\n+                    writtenIntermediatePhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n+                }\n+            }\n+\n+            stageGcStatistics.add(stageExecutionStats.getGcInfo());\n+\n+            completeInfo = completeInfo && stageInfo.isFinalStageInfo();\n+            operatorStatsSummary.addAll(stageExecutionStats.getOperatorSummaries());\n+        }\n+\n+        if (rootStage.isPresent()) {\n+            StageExecutionStats outputStageStats = rootStage.get().getLatestAttemptExecutionInfo().getStats();\n+            outputDataSize += outputStageStats.getOutputDataSize().toBytes();\n+            outputPositions += outputStageStats.getOutputPositions();\n+        }\n+\n+        boolean isScheduled = isScheduled(rootStage);", "originalCommit": "27d88f04c6454b8aa63b36d0eec9e86049d6e86f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java b/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java\nindex 8ed650c9f5..84f7a509a4 100644\n--- a/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java\n+++ b/presto-main/src/main/java/com/facebook/presto/execution/QueryStats.java\n\n@@ -246,207 +240,6 @@ public class QueryStats\n         this.operatorSummaries = ImmutableList.copyOf(requireNonNull(operatorSummaries, \"operatorSummaries is null\"));\n     }\n \n-    public static QueryStats create(\n-            QueryStateTimer queryStateTimer,\n-            Optional<StageInfo> rootStage,\n-            int peakRunningTasks,\n-            DataSize peakUserMemoryReservation,\n-            DataSize peakTotalMemoryReservation,\n-            DataSize peakTaskUserMemory,\n-            DataSize peakTaskTotalMemory)\n-    {\n-        int totalTasks = 0;\n-        int runningTasks = 0;\n-        int completedTasks = 0;\n-\n-        int totalDrivers = 0;\n-        int queuedDrivers = 0;\n-        int runningDrivers = 0;\n-        int blockedDrivers = 0;\n-        int completedDrivers = 0;\n-\n-        long cumulativeUserMemory = 0;\n-        long userMemoryReservation = 0;\n-        long totalMemoryReservation = 0;\n-\n-        long totalScheduledTime = 0;\n-        long totalCpuTime = 0;\n-        long retriedCpuTime = 0;\n-        long totalBlockedTime = 0;\n-\n-        long totalAllocation = 0;\n-\n-        long rawInputDataSize = 0;\n-        long rawInputPositions = 0;\n-\n-        long processedInputDataSize = 0;\n-        long processedInputPositions = 0;\n-\n-        long outputDataSize = 0;\n-        long outputPositions = 0;\n-\n-        long writtenOutputPositions = 0;\n-        long writtenOutputLogicalDataSize = 0;\n-        long writtenOutputPhysicalDataSize = 0;\n-\n-        long writtenIntermediatePhysicalDataSize = 0;\n-\n-        ImmutableList.Builder<StageGcStatistics> stageGcStatistics = ImmutableList.builder();\n-\n-        boolean fullyBlocked = rootStage.isPresent();\n-        Set<BlockedReason> blockedReasons = new HashSet<>();\n-\n-        ImmutableList.Builder<OperatorStats> operatorStatsSummary = ImmutableList.builder();\n-        boolean completeInfo = true;\n-        for (StageInfo stageInfo : getAllStages(rootStage)) {\n-            StageExecutionStats stageExecutionStats = stageInfo.getLatestAttemptExecutionInfo().getStats();\n-            totalTasks += stageExecutionStats.getTotalTasks();\n-            runningTasks += stageExecutionStats.getRunningTasks();\n-            completedTasks += stageExecutionStats.getCompletedTasks();\n-\n-            totalDrivers += stageExecutionStats.getTotalDrivers();\n-            queuedDrivers += stageExecutionStats.getQueuedDrivers();\n-            runningDrivers += stageExecutionStats.getRunningDrivers();\n-            blockedDrivers += stageExecutionStats.getBlockedDrivers();\n-            completedDrivers += stageExecutionStats.getCompletedDrivers();\n-\n-            cumulativeUserMemory += stageExecutionStats.getCumulativeUserMemory();\n-            userMemoryReservation += stageExecutionStats.getUserMemoryReservation().toBytes();\n-            totalMemoryReservation += stageExecutionStats.getTotalMemoryReservation().toBytes();\n-            totalScheduledTime += stageExecutionStats.getTotalScheduledTime().roundTo(MILLISECONDS);\n-            totalCpuTime += stageExecutionStats.getTotalCpuTime().roundTo(MILLISECONDS);\n-            retriedCpuTime += computeRetriedCpuTime(stageInfo);\n-            totalBlockedTime += stageExecutionStats.getTotalBlockedTime().roundTo(MILLISECONDS);\n-            if (!stageInfo.getLatestAttemptExecutionInfo().getState().isDone()) {\n-                fullyBlocked &= stageExecutionStats.isFullyBlocked();\n-                blockedReasons.addAll(stageExecutionStats.getBlockedReasons());\n-            }\n-\n-            totalAllocation += stageExecutionStats.getTotalAllocation().toBytes();\n-\n-            if (stageInfo.getPlan().isPresent()) {\n-                PlanFragment plan = stageInfo.getPlan().get();\n-                if (!plan.getTableScanSchedulingOrder().isEmpty()) {\n-                    rawInputDataSize += stageExecutionStats.getRawInputDataSize().toBytes();\n-                    rawInputPositions += stageExecutionStats.getRawInputPositions();\n-\n-                    processedInputDataSize += stageExecutionStats.getProcessedInputDataSize().toBytes();\n-                    processedInputPositions += stageExecutionStats.getProcessedInputPositions();\n-                }\n-\n-                if (plan.isOutputTableWriterFragment()) {\n-                    writtenOutputPositions += stageExecutionStats.getOperatorSummaries().stream()\n-                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n-                            .mapToLong(OperatorStats::getInputPositions)\n-                            .sum();\n-                    writtenOutputLogicalDataSize += stageExecutionStats.getOperatorSummaries().stream()\n-                            .filter(stats -> stats.getOperatorType().equals(TableWriterOperator.class.getSimpleName()))\n-                            .mapToLong(stats -> stats.getInputDataSize().toBytes())\n-                            .sum();\n-                    writtenOutputPhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n-                }\n-                else {\n-                    writtenIntermediatePhysicalDataSize += stageExecutionStats.getPhysicalWrittenDataSize().toBytes();\n-                }\n-            }\n-\n-            stageGcStatistics.add(stageExecutionStats.getGcInfo());\n-\n-            completeInfo = completeInfo && stageInfo.isFinalStageInfo();\n-            operatorStatsSummary.addAll(stageExecutionStats.getOperatorSummaries());\n-        }\n-\n-        if (rootStage.isPresent()) {\n-            StageExecutionStats outputStageStats = rootStage.get().getLatestAttemptExecutionInfo().getStats();\n-            outputDataSize += outputStageStats.getOutputDataSize().toBytes();\n-            outputPositions += outputStageStats.getOutputPositions();\n-        }\n-\n-        boolean isScheduled = isScheduled(rootStage);\n-\n-        return new QueryStats(\n-                queryStateTimer.getCreateTime(),\n-                queryStateTimer.getExecutionStartTime().orElse(null),\n-                queryStateTimer.getLastHeartbeat(),\n-                queryStateTimer.getEndTime().orElse(null),\n-\n-                queryStateTimer.getElapsedTime(),\n-                queryStateTimer.getQueuedTime(),\n-                queryStateTimer.getResourceWaitingTime(),\n-                queryStateTimer.getDispatchingTime(),\n-                queryStateTimer.getExecutionTime(),\n-                queryStateTimer.getAnalysisTime(),\n-                queryStateTimer.getPlanningTime(),\n-                queryStateTimer.getFinishingTime(),\n-\n-                totalTasks,\n-                runningTasks,\n-                peakRunningTasks,\n-                completedTasks,\n-\n-                totalDrivers,\n-                queuedDrivers,\n-                runningDrivers,\n-                blockedDrivers,\n-                completedDrivers,\n-\n-                cumulativeUserMemory,\n-                succinctBytes(userMemoryReservation),\n-                succinctBytes(totalMemoryReservation),\n-                peakUserMemoryReservation,\n-                peakTotalMemoryReservation,\n-                peakTaskUserMemory,\n-                peakTaskTotalMemory,\n-\n-                isScheduled,\n-\n-                succinctDuration(totalScheduledTime, MILLISECONDS),\n-                succinctDuration(totalCpuTime, MILLISECONDS),\n-                succinctDuration(retriedCpuTime, MILLISECONDS),\n-                succinctDuration(totalBlockedTime, MILLISECONDS),\n-                fullyBlocked,\n-                blockedReasons,\n-\n-                succinctBytes(totalAllocation),\n-\n-                succinctBytes(rawInputDataSize),\n-                rawInputPositions,\n-                succinctBytes(processedInputDataSize),\n-                processedInputPositions,\n-                succinctBytes(outputDataSize),\n-                outputPositions,\n-\n-                writtenOutputPositions,\n-                succinctBytes(writtenOutputLogicalDataSize),\n-                succinctBytes(writtenOutputPhysicalDataSize),\n-\n-                succinctBytes(writtenIntermediatePhysicalDataSize),\n-\n-                stageGcStatistics.build(),\n-\n-                operatorStatsSummary.build());\n-    }\n-\n-    private static boolean isScheduled(Optional<StageInfo> rootStage)\n-    {\n-        if (!rootStage.isPresent()) {\n-            return false;\n-        }\n-        return getAllStages(rootStage).stream()\n-                .map(StageInfo::getLatestAttemptExecutionInfo)\n-                .map(StageExecutionInfo::getState)\n-                .allMatch(state -> (state == StageExecutionState.RUNNING) || state.isDone());\n-    }\n-\n-    private static long computeRetriedCpuTime(StageInfo stageInfo)\n-    {\n-        long stageRetriedCpuTime = stageInfo.getPreviousAttemptsExecutionInfos().stream()\n-                .mapToLong(executionInfo -> executionInfo.getStats().getTotalCpuTime().roundTo(MILLISECONDS))\n-                .sum();\n-        long taskRetriedCpuTime = stageInfo.getLatestAttemptExecutionInfo().getStats().getRetriedCpuTime().roundTo(MILLISECONDS);\n-        return stageRetriedCpuTime + taskRetriedCpuTime;\n-    }\n-\n     public static QueryStats immediateFailureQueryStats()\n     {\n         DateTime now = DateTime.now();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1NDI1OA==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454054258", "bodyText": "flatMap", "author": "viczhang861", "createdAt": "2020-07-14T02:06:44Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -310,6 +369,122 @@ private static TransactionInfo getTransactionInfo(Session session, TransactionMa\n         return transaction.get();\n     }\n \n+    private static QueryInfo createQueryInfo(\n+            Session session,\n+            String query,\n+            QueryState queryState,\n+            Optional<PlanAndMore> planAndMore,\n+            Optional<ExecutionFailureInfo> failureInfo,\n+            QueryStateTimer queryStateTimer,\n+            Optional<StageInfo> rootStage,\n+            WarningCollector warningCollector)\n+    {\n+        checkArgument(failureInfo.isPresent() || queryState != FAILED, \"unexpected query state: %s\", queryState);\n+\n+        int peakRunningTasks = 0;\n+        long peakUserMemoryReservationInBytes = 0;\n+        long peakTotalMemoryReservationInBytes = 0;\n+        long peakTaskUserMemoryInBytes = 0;\n+        long peakTaskTotalMemoryInBytes = 0;\n+\n+        for (StageInfo stageInfo : getAllStages(rootStage)) {\n+            StageExecutionInfo stageExecutionInfo = stageInfo.getLatestAttemptExecutionInfo();\n+            for (TaskInfo taskInfo : stageExecutionInfo.getTasks()) {\n+                // there's no way to know how many tasks were running in parallel in Spark\n+                // for now let's assume that all the tasks were running in parallel\n+                peakRunningTasks++;\n+                long taskPeakUserMemoryInBytes = taskInfo.getStats().getUserMemoryReservation().toBytes();\n+                long taskPeakTotalMemoryInBytes = taskInfo.getStats().getPeakTotalMemoryInBytes();\n+                peakUserMemoryReservationInBytes += taskPeakUserMemoryInBytes;\n+                peakTotalMemoryReservationInBytes += taskPeakTotalMemoryInBytes;\n+                peakTaskUserMemoryInBytes = max(peakTaskUserMemoryInBytes, taskPeakUserMemoryInBytes);\n+                peakTaskTotalMemoryInBytes = max(peakTaskTotalMemoryInBytes, taskPeakTotalMemoryInBytes);\n+            }\n+        }\n+\n+        QueryStats queryStats = QueryStats.create(\n+                queryStateTimer,\n+                rootStage,\n+                peakRunningTasks,\n+                succinctBytes(peakUserMemoryReservationInBytes),\n+                succinctBytes(peakTotalMemoryReservationInBytes),\n+                succinctBytes(peakTaskUserMemoryInBytes),\n+                succinctBytes(peakTaskTotalMemoryInBytes));\n+\n+        return new QueryInfo(\n+                session.getQueryId(),\n+                session.toSessionRepresentation(),\n+                queryState,\n+                new MemoryPoolId(\"spark-memory-pool\"),\n+                queryStats.isScheduled(),\n+                URI.create(\"http://fake.invalid/query/\" + session.getQueryId()),\n+                planAndMore.map(PlanAndMore::getFieldNames).orElse(ImmutableList.of()),\n+                query,\n+                queryStats,\n+                Optional.empty(),\n+                Optional.empty(),\n+                ImmutableMap.of(),\n+                ImmutableSet.of(),\n+                ImmutableMap.of(),\n+                ImmutableMap.of(),\n+                ImmutableSet.of(),\n+                Optional.empty(),\n+                false,\n+                planAndMore.flatMap(PlanAndMore::getUpdateType).orElse(null),\n+                rootStage,\n+                failureInfo.orElse(null),\n+                failureInfo.map(ExecutionFailureInfo::getErrorCode).orElse(null),", "originalCommit": "27d88f04c6454b8aa63b36d0eec9e86049d6e86f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA2ODI0OQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454068249", "bodyText": "Nevermind, ErrorCode is nullable in ExecutionFailureInfo", "author": "viczhang861", "createdAt": "2020-07-14T02:55:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1NDI1OA=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java b/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java\nindex 1b3f13c2d8..843d43c7ef 100644\n--- a/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java\n+++ b/presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java\n\n@@ -369,139 +310,20 @@ public class PrestoSparkQueryExecutionFactory\n         return transaction.get();\n     }\n \n-    private static QueryInfo createQueryInfo(\n-            Session session,\n-            String query,\n-            QueryState queryState,\n-            Optional<PlanAndMore> planAndMore,\n-            Optional<ExecutionFailureInfo> failureInfo,\n-            QueryStateTimer queryStateTimer,\n-            Optional<StageInfo> rootStage,\n-            WarningCollector warningCollector)\n-    {\n-        checkArgument(failureInfo.isPresent() || queryState != FAILED, \"unexpected query state: %s\", queryState);\n-\n-        int peakRunningTasks = 0;\n-        long peakUserMemoryReservationInBytes = 0;\n-        long peakTotalMemoryReservationInBytes = 0;\n-        long peakTaskUserMemoryInBytes = 0;\n-        long peakTaskTotalMemoryInBytes = 0;\n-\n-        for (StageInfo stageInfo : getAllStages(rootStage)) {\n-            StageExecutionInfo stageExecutionInfo = stageInfo.getLatestAttemptExecutionInfo();\n-            for (TaskInfo taskInfo : stageExecutionInfo.getTasks()) {\n-                // there's no way to know how many tasks were running in parallel in Spark\n-                // for now let's assume that all the tasks were running in parallel\n-                peakRunningTasks++;\n-                long taskPeakUserMemoryInBytes = taskInfo.getStats().getUserMemoryReservation().toBytes();\n-                long taskPeakTotalMemoryInBytes = taskInfo.getStats().getPeakTotalMemoryInBytes();\n-                peakUserMemoryReservationInBytes += taskPeakUserMemoryInBytes;\n-                peakTotalMemoryReservationInBytes += taskPeakTotalMemoryInBytes;\n-                peakTaskUserMemoryInBytes = max(peakTaskUserMemoryInBytes, taskPeakUserMemoryInBytes);\n-                peakTaskTotalMemoryInBytes = max(peakTaskTotalMemoryInBytes, taskPeakTotalMemoryInBytes);\n-            }\n-        }\n-\n-        QueryStats queryStats = QueryStats.create(\n-                queryStateTimer,\n-                rootStage,\n-                peakRunningTasks,\n-                succinctBytes(peakUserMemoryReservationInBytes),\n-                succinctBytes(peakTotalMemoryReservationInBytes),\n-                succinctBytes(peakTaskUserMemoryInBytes),\n-                succinctBytes(peakTaskTotalMemoryInBytes));\n-\n-        return new QueryInfo(\n-                session.getQueryId(),\n-                session.toSessionRepresentation(),\n-                queryState,\n-                new MemoryPoolId(\"spark-memory-pool\"),\n-                queryStats.isScheduled(),\n-                URI.create(\"http://fake.invalid/query/\" + session.getQueryId()),\n-                planAndMore.map(PlanAndMore::getFieldNames).orElse(ImmutableList.of()),\n-                query,\n-                queryStats,\n-                Optional.empty(),\n-                Optional.empty(),\n-                ImmutableMap.of(),\n-                ImmutableSet.of(),\n-                ImmutableMap.of(),\n-                ImmutableMap.of(),\n-                ImmutableSet.of(),\n-                Optional.empty(),\n-                false,\n-                planAndMore.flatMap(PlanAndMore::getUpdateType).orElse(null),\n-                rootStage,\n-                failureInfo.orElse(null),\n-                failureInfo.map(ExecutionFailureInfo::getErrorCode).orElse(null),\n-                warningCollector.getWarnings(),\n-                planAndMore.map(PlanAndMore::getInputs).orElse(ImmutableSet.of()),\n-                planAndMore.flatMap(PlanAndMore::getOutput),\n-                true,\n-                Optional.empty(),\n-                planAndMore.flatMap(PlanAndMore::getQueryType),\n-                Optional.empty());\n-    }\n-\n-    private static StageInfo createStageInfo(QueryId queryId, SubPlan plan, List<TaskInfo> taskInfos)\n-    {\n-        ListMultimap<PlanFragmentId, TaskInfo> taskInfoMap = ArrayListMultimap.create();\n-        for (TaskInfo taskInfo : taskInfos) {\n-            PlanFragmentId fragmentId = new PlanFragmentId(taskInfo.getTaskId().getStageExecutionId().getStageId().getId());\n-            taskInfoMap.put(fragmentId, taskInfo);\n-        }\n-        return createStageInfo(queryId, plan, taskInfoMap);\n-    }\n-\n-    private static StageInfo createStageInfo(QueryId queryId, SubPlan plan, ListMultimap<PlanFragmentId, TaskInfo> taskInfoMap)\n-    {\n-        PlanFragmentId planFragmentId = plan.getFragment().getId();\n-        StageId stageId = new StageId(queryId, planFragmentId.getId());\n-        List<TaskInfo> taskInfos = taskInfoMap.get(planFragmentId);\n-        long peakUserMemoryReservationInBytes = 0;\n-        for (TaskInfo taskInfo : taskInfos) {\n-            long taskPeakUserMemoryInBytes = taskInfo.getStats().getUserMemoryReservation().toBytes();\n-            peakUserMemoryReservationInBytes += taskPeakUserMemoryInBytes;\n-        }\n-        StageExecutionInfo stageExecutionInfo = StageExecutionInfo.create(\n-                new StageExecutionId(stageId, 0),\n-                // TODO: figure out a way to know what exactly stage has caused a failure\n-                StageExecutionState.FINISHED,\n-                Optional.empty(),\n-                taskInfos,\n-                DateTime.now(),\n-                new Distribution().snapshot(),\n-                succinctBytes(peakUserMemoryReservationInBytes),\n-                1,\n-                1);\n-        return new StageInfo(\n-                stageId,\n-                URI.create(\"http://fake.invalid/stage/\" + stageId),\n-                Optional.of(plan.getFragment()),\n-                stageExecutionInfo,\n-                ImmutableList.of(),\n-                plan.getChildren().stream()\n-                        .map(child -> createStageInfo(queryId, child, taskInfoMap))\n-                        .collect(toImmutableList()));\n-    }\n-\n     public static class PrestoSparkQueryExecution\n             implements IPrestoSparkQueryExecution\n     {\n         private final JavaSparkContext sparkContext;\n         private final Session session;\n         private final QueryMonitor queryMonitor;\n-        private final CollectionAccumulator<SerializedTaskInfo> taskInfoCollector;\n+        private final CollectionAccumulator<SerializedTaskStats> taskStatsCollector;\n         // used to create tasks on the Driver\n         private final PrestoSparkTaskExecutorFactory taskExecutorFactory;\n         // used to create tasks on executor, serializable\n         private final PrestoSparkTaskExecutorFactoryProvider taskExecutorFactoryProvider;\n-        private final QueryStateTimer queryStateTimer;\n-        private final WarningCollector warningCollector;\n-        private final String query;\n-        private final PlanAndMore planAndMore;\n-        private final SubPlan fragmentedPlan;\n-        private final JsonCodec<TaskInfo> taskInfoJsonCodec;\n+        private final SubPlan plan;\n+        private final Optional<String> updateType;\n+        private final JsonCodec<TaskStats> taskStatsJsonCodec;\n         private final JsonCodec<PrestoSparkTaskDescriptor> sparkTaskDescriptorJsonCodec;\n         private final PrestoSparkRddFactory rddFactory;\n         private final TableWriteInfo tableWriteInfo;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1ODM3NQ==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454058375", "bodyText": "Why not simply get(EVENT_LISTENER_PROPERTY_NAME) ?", "author": "viczhang861", "createdAt": "2020-07-14T02:21:30Z", "path": "presto-main/src/main/java/com/facebook/presto/eventlistener/EventListenerManager.java", "diffHunk": "@@ -59,16 +59,24 @@ public void loadConfiguredEventListener()\n             throws Exception\n     {\n         if (EVENT_LISTENER_CONFIGURATION.exists()) {\n-            Map<String, String> properties = new HashMap<>(loadProperties(EVENT_LISTENER_CONFIGURATION));\n-\n-            String eventListenerName = properties.remove(EVENT_LISTENER_PROPERTY_NAME);\n-            checkArgument(!isNullOrEmpty(eventListenerName),\n-                    \"Access control configuration %s does not contain %s\", EVENT_LISTENER_CONFIGURATION.getAbsoluteFile(), EVENT_LISTENER_PROPERTY_NAME);\n-\n-            setConfiguredEventListener(eventListenerName, properties);\n+            Map<String, String> properties = loadProperties(EVENT_LISTENER_CONFIGURATION);\n+            checkArgument(\n+                    !isNullOrEmpty(properties.get(EVENT_LISTENER_PROPERTY_NAME)),\n+                    \"Access control configuration %s does not contain %s\",\n+                    EVENT_LISTENER_CONFIGURATION.getAbsoluteFile(),\n+                    EVENT_LISTENER_PROPERTY_NAME);\n+            loadConfiguredEventListener(properties);\n         }\n     }\n \n+    public void loadConfiguredEventListener(Map<String, String> properties)\n+    {\n+        properties = new HashMap<>(properties);\n+        String eventListenerName = properties.remove(EVENT_LISTENER_PROPERTY_NAME);", "originalCommit": "2cd44517170115bd7d9deb0a0cebfcc87d3d4694", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM4MjgyNg==", "url": "https://github.com/prestodb/presto/pull/14825#discussion_r454382826", "bodyText": "This is per convention. One of the properties defines what event listener provider to use, the other properties is the actual configuration that must be passed to the provider. The property that defines what provider to use must be removed, as the provider itself doesn't understand it.", "author": "arhimondr", "createdAt": "2020-07-14T14:07:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA1ODM3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "3499cc4fb973864178239f0a92a95e8e21feaa45", "chunk": "diff --git a/presto-main/src/main/java/com/facebook/presto/eventlistener/EventListenerManager.java b/presto-main/src/main/java/com/facebook/presto/eventlistener/EventListenerManager.java\nindex 190652e11f..a2e4e799c5 100644\n--- a/presto-main/src/main/java/com/facebook/presto/eventlistener/EventListenerManager.java\n+++ b/presto-main/src/main/java/com/facebook/presto/eventlistener/EventListenerManager.java\n\n@@ -59,22 +59,14 @@ public class EventListenerManager\n             throws Exception\n     {\n         if (EVENT_LISTENER_CONFIGURATION.exists()) {\n-            Map<String, String> properties = loadProperties(EVENT_LISTENER_CONFIGURATION);\n-            checkArgument(\n-                    !isNullOrEmpty(properties.get(EVENT_LISTENER_PROPERTY_NAME)),\n-                    \"Access control configuration %s does not contain %s\",\n-                    EVENT_LISTENER_CONFIGURATION.getAbsoluteFile(),\n-                    EVENT_LISTENER_PROPERTY_NAME);\n-            loadConfiguredEventListener(properties);\n-        }\n-    }\n+            Map<String, String> properties = new HashMap<>(loadProperties(EVENT_LISTENER_CONFIGURATION));\n \n-    public void loadConfiguredEventListener(Map<String, String> properties)\n-    {\n-        properties = new HashMap<>(properties);\n-        String eventListenerName = properties.remove(EVENT_LISTENER_PROPERTY_NAME);\n-        checkArgument(!isNullOrEmpty(eventListenerName), \"event-listener.name property must be present\");\n-        setConfiguredEventListener(eventListenerName, properties);\n+            String eventListenerName = properties.remove(EVENT_LISTENER_PROPERTY_NAME);\n+            checkArgument(!isNullOrEmpty(eventListenerName),\n+                    \"Access control configuration %s does not contain %s\", EVENT_LISTENER_CONFIGURATION.getAbsoluteFile(), EVENT_LISTENER_PROPERTY_NAME);\n+\n+            setConfiguredEventListener(eventListenerName, properties);\n+        }\n     }\n \n     @VisibleForTesting\n"}}, {"oid": "3499cc4fb973864178239f0a92a95e8e21feaa45", "url": "https://github.com/prestodb/presto/commit/3499cc4fb973864178239f0a92a95e8e21feaa45", "message": "Apply compression to Presto on Spark splits", "committedDate": "2020-07-14T14:08:19Z", "type": "commit"}, {"oid": "d8d6015c302902f7ff89692c860c85df3b1adf97", "url": "https://github.com/prestodb/presto/commit/d8d6015c302902f7ff89692c860c85df3b1adf97", "message": "Prepare to collect TaskInfo from Presto on Spark tasks", "committedDate": "2020-07-14T14:08:19Z", "type": "commit"}, {"oid": "764bb7728fddd1d57fe46b4801ca6100d49b27ca", "url": "https://github.com/prestodb/presto/commit/764bb7728fddd1d57fe46b4801ca6100d49b27ca", "message": "Collect TaskInfo for Presto on Spark tasks", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "44fddb1f7712a67af1083eed9166767f4af57e29", "url": "https://github.com/prestodb/presto/commit/44fddb1f7712a67af1083eed9166767f4af57e29", "message": "Implement QueryMonitor callbacks for Presto on Spark", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "a5bf15d92aeabfd8fc76e362f320bb776bf08bc8", "url": "https://github.com/prestodb/presto/commit/a5bf15d92aeabfd8fc76e362f320bb776bf08bc8", "message": "Add ability to register event listener in Presto on Spark", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "220dfd7233f2d81bc81d7e3a339355ffb9d72117", "url": "https://github.com/prestodb/presto/commit/220dfd7233f2d81bc81d7e3a339355ffb9d72117", "message": "Allow query info to be stored in a file upon query finish\n\nThis will allow to retrieve query id, stack trace and potentially\nother debug information upon query completition", "committedDate": "2020-07-14T14:45:01Z", "type": "commit"}, {"oid": "220dfd7233f2d81bc81d7e3a339355ffb9d72117", "url": "https://github.com/prestodb/presto/commit/220dfd7233f2d81bc81d7e3a339355ffb9d72117", "message": "Allow query info to be stored in a file upon query finish\n\nThis will allow to retrieve query id, stack trace and potentially\nother debug information upon query completition", "committedDate": "2020-07-14T14:45:01Z", "type": "forcePushed"}]}