{"pr_number": 1281, "pr_title": "Reflection serde", "pr_createdAt": "2020-01-07T23:32:14Z", "pr_url": "https://github.com/confluentinc/schema-registry/pull/1281", "timeline": [{"oid": "b85001a281aebd27e84e59c1e03996987929457d", "url": "https://github.com/confluentinc/schema-registry/commit/b85001a281aebd27e84e59c1e03996987929457d", "message": "enabled default constructor\n\nDefault constructor allows the SerDe to be used as default serde in KStreams config.", "committedDate": "2020-01-07T23:12:36Z", "type": "commit"}, {"oid": "642d3f73f277a4c3b7f898df1312db175a3cd32d", "url": "https://github.com/confluentinc/schema-registry/commit/642d3f73f277a4c3b7f898df1312db175a3cd32d", "message": "added logic to resolve the reflection schema when it is not provided during construction", "committedDate": "2020-01-07T23:25:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA0MjMwNw==", "url": "https://github.com/confluentinc/schema-registry/pull/1281#discussion_r364042307", "bodyText": "nit: The build is complaining that whitespace is needed around !=", "author": "rayokota", "createdAt": "2020-01-08T02:37:07Z", "path": "avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java", "diffHunk": "@@ -173,58 +173,91 @@ protected GenericContainerWithVersion deserializeWithSchemaAndVersion(\n   }\n \n   protected DatumReader<?> getDatumReader(Schema writerSchema, Schema readerSchema) {\n+    // normalize reader schema\n+    readerSchema = getReaderSchema(writerSchema, readerSchema);\n     boolean writerSchemaIsPrimitive =\n         AvroSchemaUtils.getPrimitiveSchemas().values().contains(writerSchema);\n-    // do not use SpecificDatumReader if writerSchema is a primitive\n-    if (useSchemaReflection && !writerSchemaIsPrimitive) {\n-      if (readerSchema == null) {\n-        throw new SerializationException(\n-            \"Reader schema cannot be null when using Avro schema reflection\");\n-      }\n+    if (writerSchemaIsPrimitive) {\n+      return new GenericDatumReader<>(writerSchema, readerSchema);\n+    } else if (useSchemaReflection) {\n       return new ReflectDatumReader<>(writerSchema, readerSchema);\n-    } else if (useSpecificAvroReader && !writerSchemaIsPrimitive) {\n-      if (readerSchema == null) {\n-        readerSchema = getReaderSchema(writerSchema);\n-      }\n+    } else if (useSpecificAvroReader) {\n       return new SpecificDatumReader<>(writerSchema, readerSchema);\n     } else {\n-      if (readerSchema == null) {\n-        return new GenericDatumReader<>(writerSchema);\n-      }\n       return new GenericDatumReader<>(writerSchema, readerSchema);\n     }\n   }\n \n-  @SuppressWarnings(\"unchecked\")\n-  private Schema getReaderSchema(Schema writerSchema) {\n-    Schema readerSchema = readerSchemaCache.get(writerSchema.getFullName());\n-    if (readerSchema == null) {\n-      Class<SpecificRecord> readerClass = SpecificData.get().getClass(writerSchema);\n-      if (readerClass != null) {\n-        try {\n-          readerSchema = readerClass.newInstance().getSchema();\n-        } catch (InstantiationException e) {\n-          throw new SerializationException(writerSchema.getFullName()\n-                                           + \" specified by the \"\n-                                           + \"writers schema could not be instantiated to \"\n-                                           + \"find the readers schema.\");\n-        } catch (IllegalAccessException e) {\n-          throw new SerializationException(writerSchema.getFullName()\n-                                           + \" specified by the \"\n-                                           + \"writers schema is not allowed to be instantiated \"\n-                                           + \"to find the readers schema.\");\n-        }\n-        readerSchemaCache.put(writerSchema.getFullName(), readerSchema);\n-      } else {\n-        throw new SerializationException(\"Could not find class \"\n-                                         + writerSchema.getFullName()\n-                                         + \" specified in writer's schema whilst finding reader's \"\n-                                         + \"schema for a SpecificRecord.\");\n-      }\n+  /**\n+   * Normalizes the reader schema, puts the resolved schema into the cache. \n+   * <li>\n+   * <ul>if the reader schema is provided, use the provided one</ul>\n+   * <ul>if the reader schema is cached for the writer schema full name, use the cached value</ul>\n+   * <ul>if the writer schema is primitive, use the writer one</ul>\n+   * <ul>if schema reflection is used, generate one from the class referred by writer schema</ul>\n+   * <ul>if generated classes are used, query the class referred by writer schema</ul>\n+   * <ul>otherwise use the writer schema</ul>\n+   * </li>\n+   */\n+  private Schema getReaderSchema(Schema writerSchema, Schema readerSchema) {\n+    if (readerSchema!=null) {", "originalCommit": "642d3f73f277a4c3b7f898df1312db175a3cd32d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "99eea98abed0947c170434e25f7e8dbdb2b64cd9", "chunk": "diff --git a/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java b/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java\nindex 803cfc486..b46eca376 100644\n--- a/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java\n+++ b/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java\n\n@@ -200,11 +200,11 @@ public abstract class AbstractKafkaAvroDeserializer extends AbstractKafkaAvroSer\n    * </li>\n    */\n   private Schema getReaderSchema(Schema writerSchema, Schema readerSchema) {\n-    if (readerSchema!=null) {\n+    if (readerSchema != null) {\n       return readerSchema;\n     }\n     readerSchema = readerSchemaCache.get(writerSchema.getFullName());\n-    if (readerSchema!=null) {\n+    if (readerSchema != null) {\n       return readerSchema;\n     }\n     boolean writerSchemaIsPrimitive =\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA0MjM1MQ==", "url": "https://github.com/confluentinc/schema-registry/pull/1281#discussion_r364042351", "bodyText": "nit: The build is complaining that whitespace is needed around !=", "author": "rayokota", "createdAt": "2020-01-08T02:37:22Z", "path": "avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java", "diffHunk": "@@ -173,58 +173,91 @@ protected GenericContainerWithVersion deserializeWithSchemaAndVersion(\n   }\n \n   protected DatumReader<?> getDatumReader(Schema writerSchema, Schema readerSchema) {\n+    // normalize reader schema\n+    readerSchema = getReaderSchema(writerSchema, readerSchema);\n     boolean writerSchemaIsPrimitive =\n         AvroSchemaUtils.getPrimitiveSchemas().values().contains(writerSchema);\n-    // do not use SpecificDatumReader if writerSchema is a primitive\n-    if (useSchemaReflection && !writerSchemaIsPrimitive) {\n-      if (readerSchema == null) {\n-        throw new SerializationException(\n-            \"Reader schema cannot be null when using Avro schema reflection\");\n-      }\n+    if (writerSchemaIsPrimitive) {\n+      return new GenericDatumReader<>(writerSchema, readerSchema);\n+    } else if (useSchemaReflection) {\n       return new ReflectDatumReader<>(writerSchema, readerSchema);\n-    } else if (useSpecificAvroReader && !writerSchemaIsPrimitive) {\n-      if (readerSchema == null) {\n-        readerSchema = getReaderSchema(writerSchema);\n-      }\n+    } else if (useSpecificAvroReader) {\n       return new SpecificDatumReader<>(writerSchema, readerSchema);\n     } else {\n-      if (readerSchema == null) {\n-        return new GenericDatumReader<>(writerSchema);\n-      }\n       return new GenericDatumReader<>(writerSchema, readerSchema);\n     }\n   }\n \n-  @SuppressWarnings(\"unchecked\")\n-  private Schema getReaderSchema(Schema writerSchema) {\n-    Schema readerSchema = readerSchemaCache.get(writerSchema.getFullName());\n-    if (readerSchema == null) {\n-      Class<SpecificRecord> readerClass = SpecificData.get().getClass(writerSchema);\n-      if (readerClass != null) {\n-        try {\n-          readerSchema = readerClass.newInstance().getSchema();\n-        } catch (InstantiationException e) {\n-          throw new SerializationException(writerSchema.getFullName()\n-                                           + \" specified by the \"\n-                                           + \"writers schema could not be instantiated to \"\n-                                           + \"find the readers schema.\");\n-        } catch (IllegalAccessException e) {\n-          throw new SerializationException(writerSchema.getFullName()\n-                                           + \" specified by the \"\n-                                           + \"writers schema is not allowed to be instantiated \"\n-                                           + \"to find the readers schema.\");\n-        }\n-        readerSchemaCache.put(writerSchema.getFullName(), readerSchema);\n-      } else {\n-        throw new SerializationException(\"Could not find class \"\n-                                         + writerSchema.getFullName()\n-                                         + \" specified in writer's schema whilst finding reader's \"\n-                                         + \"schema for a SpecificRecord.\");\n-      }\n+  /**\n+   * Normalizes the reader schema, puts the resolved schema into the cache. \n+   * <li>\n+   * <ul>if the reader schema is provided, use the provided one</ul>\n+   * <ul>if the reader schema is cached for the writer schema full name, use the cached value</ul>\n+   * <ul>if the writer schema is primitive, use the writer one</ul>\n+   * <ul>if schema reflection is used, generate one from the class referred by writer schema</ul>\n+   * <ul>if generated classes are used, query the class referred by writer schema</ul>\n+   * <ul>otherwise use the writer schema</ul>\n+   * </li>\n+   */\n+  private Schema getReaderSchema(Schema writerSchema, Schema readerSchema) {\n+    if (readerSchema!=null) {\n+      return readerSchema;\n+    }\n+    readerSchema = readerSchemaCache.get(writerSchema.getFullName());\n+    if (readerSchema!=null) {", "originalCommit": "642d3f73f277a4c3b7f898df1312db175a3cd32d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "99eea98abed0947c170434e25f7e8dbdb2b64cd9", "chunk": "diff --git a/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java b/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java\nindex 803cfc486..b46eca376 100644\n--- a/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java\n+++ b/avro-serializer/src/main/java/io/confluent/kafka/serializers/AbstractKafkaAvroDeserializer.java\n\n@@ -200,11 +200,11 @@ public abstract class AbstractKafkaAvroDeserializer extends AbstractKafkaAvroSer\n    * </li>\n    */\n   private Schema getReaderSchema(Schema writerSchema, Schema readerSchema) {\n-    if (readerSchema!=null) {\n+    if (readerSchema != null) {\n       return readerSchema;\n     }\n     readerSchema = readerSchemaCache.get(writerSchema.getFullName());\n-    if (readerSchema!=null) {\n+    if (readerSchema != null) {\n       return readerSchema;\n     }\n     boolean writerSchemaIsPrimitive =\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA0MjYzNw==", "url": "https://github.com/confluentinc/schema-registry/pull/1281#discussion_r364042637", "bodyText": "Are there tests that use this?", "author": "rayokota", "createdAt": "2020-01-08T02:38:52Z", "path": "avro-serde/src/main/java/io/confluent/kafka/streams/serdes/avro/ReflectionAvroDeserializer.java", "diffHunk": "@@ -40,11 +40,24 @@\n   private final KafkaAvroDeserializer inner;\n   private final Schema schema;\n \n+  public ReflectionAvroDeserializer() {", "originalCommit": "642d3f73f277a4c3b7f898df1312db175a3cd32d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDA0MjY2NQ==", "url": "https://github.com/confluentinc/schema-registry/pull/1281#discussion_r364042665", "bodyText": "Are there tests that use this?", "author": "rayokota", "createdAt": "2020-01-08T02:39:01Z", "path": "avro-serde/src/main/java/io/confluent/kafka/streams/serdes/avro/ReflectionAvroDeserializer.java", "diffHunk": "@@ -40,11 +40,24 @@\n   private final KafkaAvroDeserializer inner;\n   private final Schema schema;\n \n+  public ReflectionAvroDeserializer() {\n+    this.schema = null;\n+    this.inner = new KafkaAvroDeserializer();\n+  }\n+\n   public ReflectionAvroDeserializer(Class<T> type) {\n     this.schema = ReflectData.get().getSchema(type);\n     this.inner = new KafkaAvroDeserializer();\n   }\n \n+  /**\n+   * For testing purposes only.\n+   */\n+  ReflectionAvroDeserializer(final SchemaRegistryClient client) {", "originalCommit": "642d3f73f277a4c3b7f898df1312db175a3cd32d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "99eea98abed0947c170434e25f7e8dbdb2b64cd9", "url": "https://github.com/confluentinc/schema-registry/commit/99eea98abed0947c170434e25f7e8dbdb2b64cd9", "message": "fixed whitespace warning", "committedDate": "2020-01-08T10:00:07Z", "type": "commit"}, {"oid": "17a3989a3bd2f19d4f40a6ab85c9b2e050a538ad", "url": "https://github.com/confluentinc/schema-registry/commit/17a3989a3bd2f19d4f40a6ab85c9b2e050a538ad", "message": "added missing constructors", "committedDate": "2020-01-08T13:42:01Z", "type": "commit"}, {"oid": "d113ffeed42dbb18352783a2157a220bdf3bf72b", "url": "https://github.com/confluentinc/schema-registry/commit/d113ffeed42dbb18352783a2157a220bdf3bf72b", "message": "cloned the original test case to support dynamic type recognition", "committedDate": "2020-01-08T13:43:00Z", "type": "commit"}, {"oid": "7fed48e8e000103c346c511194e13643a21dd911", "url": "https://github.com/confluentinc/schema-registry/commit/7fed48e8e000103c346c511194e13643a21dd911", "message": "cache only generated schemas\n\nThe failure in testVersionMaintained was caused by caching the schema for given name. In case\nof GenericDatumReader the schema is as it comes from the serialized record. This means\nif the schema evolves, there could be multiple representations of the same avro record.", "committedDate": "2020-01-13T14:10:19Z", "type": "commit"}]}