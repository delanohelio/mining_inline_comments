{"pr_number": 6409, "pr_title": "feat: Add support for IN clause to pull queries", "pr_createdAt": "2020-10-12T21:29:39Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6409", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NDgzNw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503594837", "bodyText": "The pullQueryContext is the same, the only thing that changes are the keys right?You could avoid creating a new object and just set the keys in each iteration.", "author": "vpapavas", "createdAt": "2020-10-12T23:58:40Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n+          whereInfo.keysBound.stream()\n+              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+              .collect(Collectors.toList()));\n+\n+      for (List<Struct> keys : keysByLocation) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(", "originalCommit": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0MDI0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503640241", "bodyText": "PullQueryContext is threadsafe because it's immutable.  Dealing with small immutable objects is fairly efficient in the JVM and is considered worth doing to make things threadsafe and easy to understand.", "author": "AlanConfluent", "createdAt": "2020-10-13T03:04:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NDgzNw=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex 7c5f2598d9..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -230,18 +229,13 @@ public final class PullQueryExecutor {\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n-      final List<List<?>> tableRows = new ArrayList<>();\n-      final List<LogicalSchema> schemas = new ArrayList<>();\n-      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n-      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n-          whereInfo.keysBound.stream()\n-              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n-              .collect(Collectors.toList()));\n+      List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      List<List<?>> tableRows = new ArrayList<>();\n+      for (Object keyBound : whereInfo.keysBound) {\n+        final Struct key = asKeyStruct(keyBound, query.getPhysicalSchema());\n \n-      for (List<Struct> keys : keysByLocation) {\n         final PullQueryContext pullQueryContext = new PullQueryContext(\n-            keys,\n+            key,\n             mat,\n             analysis,\n             whereInfo,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTQxMw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503595413", "bodyText": "Why don't you return besides they keys also the active, standby per group? This way you wouldn't need to do locate twice basically.", "author": "vpapavas", "createdAt": "2020-10-13T00:00:58Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(", "originalCommit": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5ODE3MA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503598170", "bodyText": "Actually, I think currently the routing is wrong and you have to return the <active,standby> per group", "author": "vpapavas", "createdAt": "2020-10-13T00:11:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzODY1Nw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503638657", "bodyText": "Yeah, I had thought that a given set of partitions were grouped together at each active and standby, but I think you're right this isn't the case.  I'll change it to groupByActiveStandyList or something similar.  In practice, there aren't too many standbys, so this is likely to be a lot better than grouping by partition or just fetching by key.", "author": "AlanConfluent", "createdAt": "2020-10-13T02:58:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTQxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIwODMwMg==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r504208302", "bodyText": "I reworked this so that it now groups key together only if they share the same list of nodes, including active and all standbys.  Most of the time if there's 1 or 2 standbys and lots of keys fetched, this will hopefully reduce unnecessary calls.", "author": "AlanConfluent", "createdAt": "2020-10-13T19:37:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTQxMw=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex 7c5f2598d9..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -230,18 +229,13 @@ public final class PullQueryExecutor {\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n-      final List<List<?>> tableRows = new ArrayList<>();\n-      final List<LogicalSchema> schemas = new ArrayList<>();\n-      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n-      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n-          whereInfo.keysBound.stream()\n-              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n-              .collect(Collectors.toList()));\n+      List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      List<List<?>> tableRows = new ArrayList<>();\n+      for (Object keyBound : whereInfo.keysBound) {\n+        final Struct key = asKeyStruct(keyBound, query.getPhysicalSchema());\n \n-      for (List<Struct> keys : keysByLocation) {\n         final PullQueryContext pullQueryContext = new PullQueryContext(\n-            keys,\n+            key,\n             mat,\n             analysis,\n             whereInfo,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTcyNQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503595725", "bodyText": "It seems that you assume that all keys in the group are routed to the same standby but that's not the case, since they might belong to different partitions.", "author": "vpapavas", "createdAt": "2020-10-13T00:02:17Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -271,8 +308,9 @@ private PullQueryResult handlePullQuery(\n   ) {\n     // Get active and standby nodes for this key\n     final Locator locator = pullQueryContext.mat.locator();\n+    final Struct key = Iterables.getLast(pullQueryContext.keys);\n     final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n+        key,", "originalCommit": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzODc0NA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503638744", "bodyText": "I had thought that a given set of partitions were grouped together at each active and standby, but I think you're right this isn't the case.  I'll rework this.", "author": "AlanConfluent", "createdAt": "2020-10-13T02:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTcyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex 7c5f2598d9..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -308,9 +285,8 @@ public final class PullQueryExecutor {\n   ) {\n     // Get active and standby nodes for this key\n     final Locator locator = pullQueryContext.mat.locator();\n-    final Struct key = Iterables.getLast(pullQueryContext.keys);\n     final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        key,\n+        pullQueryContext.key,\n         routingOptions,\n         routingFilterFactory\n     );\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NzczNA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503597734", "bodyText": "Here you group keys based on the node that hosts the active partition. However, the keys may belong to different partitions and hence the standby may be different for keys in the same group. I think you should group them per <active, standby> combination else when we do the routing, we cannot assume that all keys go to the same standby  (when active dead)", "author": "vpapavas", "createdAt": "2020-10-13T00:09:56Z", "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -118,6 +123,21 @@\n     return filteredHosts;\n   }\n \n+  @Override\n+  public List<List<Struct>> groupByLocation(final List<Struct> keys) {\n+    final Map<String, List<Struct>> groups = new HashMap<>();\n+    for (Struct key : keys) {", "originalCommit": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY0MDczNA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503640734", "bodyText": "Yeah, I think either grouping by partition or <active, standby> list would be best.  I think in the normal case where you don't have many standbys, the latter is a good method.", "author": "AlanConfluent", "createdAt": "2020-10-13T03:06:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NzczNA=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\nindex d36df2e015..7a1273fa0c 100644\n--- a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n+++ b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n\n@@ -123,21 +118,6 @@ final class KsLocator implements Locator {\n     return filteredHosts;\n   }\n \n-  @Override\n-  public List<List<Struct>> groupByLocation(final List<Struct> keys) {\n-    final Map<String, List<Struct>> groups = new HashMap<>();\n-    for (Struct key : keys) {\n-      final KeyQueryMetadata metadata = kafkaStreams\n-          .queryMetadataForKey(stateStoreName, key, keySerializer);\n-      groups.computeIfAbsent(metadata.activeHost().toString(), active -> new ArrayList<>());\n-      groups.get(metadata.activeHost().toString()).add(key);\n-    }\n-    return groups.entrySet().stream()\n-        .sorted(Comparator.comparing(Entry::getKey))\n-        .map(Entry::getValue)\n-        .collect(Collectors.toList());\n-  }\n-\n   @VisibleForTesting\n   KsqlHostInfo asKsqlHost(final HostInfo hostInfo) {\n     return new KsqlHostInfo(hostInfo.host(), hostInfo.port());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5OTkyMw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503599923", "bodyText": "What's the benefit of having this class versus adding one more entry in the ComparisonTarget? Seems a lot of work for achieving the same functionality?", "author": "vpapavas", "createdAt": "2020-10-13T00:18:32Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -761,19 +827,78 @@ private static Instant asInstant(final Expression other) {\n   }\n \n   private enum ComparisonTarget {\n-    KEYCOL,\n     WINDOWSTART,\n     WINDOWEND\n   }\n \n-  private static Map<ComparisonTarget, List<ComparisonExpression>> extractComparisons(\n+  private static class KeyAndWindowBounds {", "originalCommit": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzOTcxOQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503639719", "bodyText": "InPredicate isn't a ComparisonExpression.  Here, I can have a different type for each target type.\nAlternatively, I could have change the map to point to an expression and casted back to the subtype, but that's not a great practice.", "author": "AlanConfluent", "createdAt": "2020-10-13T03:02:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5OTkyMw=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex 7c5f2598d9..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -826,79 +800,67 @@ public final class PullQueryExecutor {\n     );\n   }\n \n-  private enum ComparisonTarget {\n-    WINDOWSTART,\n-    WINDOWEND\n-  }\n-\n-  private static class KeyAndWindowBounds {\n-    private List<ComparisonExpression> keyColExpression = new ArrayList<>();\n-    private List<ComparisonExpression> windowStartExpression = new ArrayList<>();\n-    private List<ComparisonExpression> windowEndExpression = new ArrayList<>();\n-    private List<InPredicate> inPredicate = new ArrayList<>();\n-\n-    KeyAndWindowBounds() {\n-    }\n-\n-    public KeyAndWindowBounds addKeyColExpression(final ComparisonExpression keyColExpression) {\n-      this.keyColExpression.add(keyColExpression);\n-      return this;\n+  private static Optional<InPredicate> extractInPredicate(\n+      final Expression exp,\n+      final PersistentQueryMetadata query\n+  ) {\n+    if (exp instanceof InPredicate) {\n+      final InPredicate inPredicate = (InPredicate) exp;\n+      extractWhereClauseTarget(inPredicate, query);\n+      return Optional.of(inPredicate);\n     }\n \n-    public KeyAndWindowBounds addWindowStartExpression(\n-        final ComparisonExpression windowStartExpression) {\n-      this.windowStartExpression.add(windowStartExpression);\n-      return this;\n-    }\n+    if (exp instanceof LogicalBinaryExpression) {\n+      final LogicalBinaryExpression binary = (LogicalBinaryExpression) exp;\n+      if (binary.getType() != LogicalBinaryExpression.Type.AND) {\n+        throw invalidWhereClauseException(\"Only AND expressions are supported: \" + exp, false);\n+      }\n \n-    public KeyAndWindowBounds addWindowEndExpression(\n-        final ComparisonExpression windowEndExpression) {\n-      this.windowEndExpression.add(windowEndExpression);\n-      return this;\n-    }\n+      final Optional<InPredicate> left =\n+          extractInPredicate(binary.getLeft(), query);\n \n-    public KeyAndWindowBounds addInPredicate(final InPredicate inPredicate) {\n-      this.inPredicate.add(inPredicate);\n-      return this;\n-    }\n+      final Optional<InPredicate> right =\n+          extractInPredicate(binary.getRight(), query);\n \n-    public KeyAndWindowBounds merge(final KeyAndWindowBounds other) {\n-      keyColExpression.addAll(other.keyColExpression);\n-      windowStartExpression.addAll(other.windowStartExpression);\n-      windowEndExpression.addAll(other.windowEndExpression);\n-      inPredicate.addAll(other.inPredicate);\n-      return this;\n+      if (left.isPresent() && right.isPresent()) {\n+        throw invalidWhereClauseException(\"Only one IN expression allowed:\" + exp, false);\n+      }\n+      return left.isPresent() ? left : right;\n     }\n \n-    public List<ComparisonExpression> getKeyColExpression() {\n-      return keyColExpression;\n-    }\n+    return Optional.empty();\n+  }\n \n-    public List<ComparisonExpression> getWindowStartExpression() {\n-      return windowStartExpression;\n+  private static void extractWhereClauseTarget(\n+      final InPredicate inPredicate,\n+      final PersistentQueryMetadata query\n+  ) {\n+    UnqualifiedColumnReferenceExp column = (UnqualifiedColumnReferenceExp) inPredicate.getValue();\n+    final ColumnName keyColumn = Iterables.getOnlyElement(query.getLogicalSchema().key()).name();\n+    if (column.getColumnName().equals(keyColumn)) {\n+      return;\n     }\n \n-    public List<ComparisonExpression> getWindowEndExpression() {\n-      return windowEndExpression;\n-    }\n+    throw invalidWhereClauseException(\n+        \"WHERE clause on unsupported column: \" + column.getColumnName().text(),\n+        false\n+    );\n+  }\n \n-    public List<InPredicate> getInPredicate() {\n-      return inPredicate;\n-    }\n+  private enum ComparisonTarget {\n+    KEYCOL,\n+    WINDOWSTART,\n+    WINDOWEND\n   }\n \n-  private static KeyAndWindowBounds extractComparisons(\n+  private static Map<ComparisonTarget, List<ComparisonExpression>> extractComparisons(\n       final Expression exp,\n       final PersistentQueryMetadata query\n   ) {\n     if (exp instanceof ComparisonExpression) {\n       final ComparisonExpression comparison = (ComparisonExpression) exp;\n-      return extractWhereClauseTarget(comparison, query);\n-    }\n-\n-    if (exp instanceof InPredicate) {\n-      final InPredicate inPredicate = (InPredicate) exp;\n-      return extractWhereClauseTarget(inPredicate, query);\n+      final ComparisonTarget target = extractWhereClauseTarget(comparison, query);\n+      return ImmutableMap.of(target, ImmutableList.of(comparison));\n     }\n \n     if (exp instanceof LogicalBinaryExpression) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjYzNw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503602637", "bodyText": "Shouldn't there be some error handling here? What happens if a thread dies due to an uncaught exception? We would like to fail the entire query and not return partial results, right? Maybe handle something like this:\n        try {\n            future.get();\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        } catch (ExecutionException e) {\n            // Extract the actual exception from its wrapper\n            Throwable t = e.getCause();\n            System.err.println(\"Uncaught exception is detected! \" + t\n                    + \" st: \" + Arrays.toString(t.getStackTrace()));\n            // ... Handle the exception\n        }", "author": "vpapavas", "createdAt": "2020-10-13T00:29:17Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n+          whereInfo.keysBound.stream()\n+              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+              .collect(Collectors.toList()));\n+\n+      for (List<Struct> keys : keysByLocation) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(\n+            keys,\n+            mat,\n+            analysis,\n+            whereInfo,\n+            queryId,\n+            contextStacker,\n+            pullQueryMetrics);\n+\n+        futures.add(executorService.submit(() -> handlePullQuery(\n+            statement,\n+            executionContext,\n+            serviceContext,\n+            pullQueryContext,\n+            routingOptions\n+        )));\n \n-      final PullQueryContext pullQueryContext = new PullQueryContext(\n-          key,\n-          mat,\n-          analysis,\n-          whereInfo,\n-          queryId,\n-          contextStacker,\n-          pullQueryMetrics);\n+      }\n+      for (Future<PullQueryResult> future : futures) {\n+        final PullQueryResult result = future.get();", "originalCommit": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIwNzYwNQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r504207605", "bodyText": "Yeah, I agree that we don't want partial results, so I wouldn't want to catch each individual future.\nAlso, calling interrupt is what causes the InterruptedException and it sends that exception to other threads.  To have the current thread have it thrown, all we have to do is not catch it.\nI pretty much just let the existing handler catch Exception in the wider scope.  I added a small special case to unwrap ExecutionException so we get the same error message.", "author": "AlanConfluent", "createdAt": "2020-10-13T19:36:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1MzM0Ng==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505053346", "bodyText": "calling interrupt is what causes the InterruptedException\n\nI think you probably meant this, but just a small clarification here - Thread.currentThread().interrupt() does not directly cause an InterruptedException. It just sets an interrupt flag on the thread's state, and then any blocking code is expected to check that flag and raise an InterruptedException when it notices that flag. There is no guarantee that calling interupt will actually do anything (especially if there's misbehaving client code). It's a cooperative strategy.", "author": "agavra", "createdAt": "2020-10-14T23:10:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjYzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg1MjMwNA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505852304", "bodyText": "Yeah, you're right that a thread may have to explicitly check for being interrupted if it's doing a lot of computation.  If it's sleeping in some manner, there's a good chance that it will be thrown for the thread, e.g. Thread.sleep.", "author": "AlanConfluent", "createdAt": "2020-10-15T21:07:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjYzNw=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex 7c5f2598d9..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -230,18 +229,13 @@ public final class PullQueryExecutor {\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n-      final List<List<?>> tableRows = new ArrayList<>();\n-      final List<LogicalSchema> schemas = new ArrayList<>();\n-      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n-      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n-          whereInfo.keysBound.stream()\n-              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n-              .collect(Collectors.toList()));\n+      List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      List<List<?>> tableRows = new ArrayList<>();\n+      for (Object keyBound : whereInfo.keysBound) {\n+        final Struct key = asKeyStruct(keyBound, query.getPhysicalSchema());\n \n-      for (List<Struct> keys : keysByLocation) {\n         final PullQueryContext pullQueryContext = new PullQueryContext(\n-            keys,\n+            key,\n             mat,\n             analysis,\n             whereInfo,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0NjE3MA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505046170", "bodyText": "very soon we're going to support all expression types as keys (including structs) and we already support DECIMAL keys. I'm not entirely sure that this approach will work then since it's not always possible to take a java object and convert it into an expression as the inverse conversion is lossy. Is it possible to extract the original expression when we construct the List<Struct> keys instead of mapping it to Java objects?", "author": "agavra", "createdAt": "2020-10-14T23:00:18Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/rewrite/PullQueryKeyUpdater.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine.rewrite;\n+\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.engine.rewrite.ExpressionTreeRewriter.Context;\n+import io.confluent.ksql.execution.expression.tree.DoubleLiteral;\n+import io.confluent.ksql.execution.expression.tree.Expression;\n+import io.confluent.ksql.execution.expression.tree.InListExpression;\n+import io.confluent.ksql.execution.expression.tree.InPredicate;\n+import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n+import io.confluent.ksql.execution.expression.tree.LongLiteral;\n+import io.confluent.ksql.execution.expression.tree.StringLiteral;\n+import io.confluent.ksql.execution.expression.tree.VisitParentExpressionVisitor;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Statement;\n+import io.confluent.ksql.util.KsqlException;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Schema;\n+import org.apache.kafka.connect.data.Struct;\n+\n+/**\n+ * Takes a configured statement and rewrites it to update the keys requested.  This only works if\n+ * the query uses the IN keyword.\n+ * This is required because when fetching multiple keys using the IN keyword, a given host may be\n+ * the active for one partition and standby for another partition, and if you issue a query\n+ * requesting keys from both partitions while using ksql.query.pull.enable.standby.reads=true,\n+ * you'll fetch stale values unintentionally.\n+ */\n+public final class PullQueryKeyUpdater {\n+\n+  private PullQueryKeyUpdater() {}\n+\n+  /**\n+   * Returns a Statement with the IN expression updated to include only the given keys.\n+   * @param statement the original statement.\n+   * @param keys the keys to include\n+   * @return The updated statement\n+   */\n+  public static Statement update(\n+      final Query statement,\n+      final List<Struct> keys) {\n+    final BiFunction<Expression, Void, Expression> expressionRewriter =\n+        (e, v) -> ExpressionTreeRewriter.rewriteWith(\n+            new ExpressionRewriterPlugin(keys)::process, e, v);\n+    return (Statement) new StatementRewriter<>(expressionRewriter, (n, c) -> Optional.empty())\n+        .rewrite(statement, null);\n+  }\n+\n+  private static final class ExpressionRewriterPlugin extends\n+      VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n+\n+    private final List<Struct> keys;\n+\n+    ExpressionRewriterPlugin(final List<Struct> keys) {\n+      super(Optional.empty());\n+      this.keys = keys;\n+    }\n+\n+    @Override\n+    public Optional<Expression> visitInPredicate(final InPredicate node, final Context<Void> ctx) {\n+      final List<Expression> values = keys.stream().map(k -> {\n+        final Field field = Iterables.getOnlyElement(k.schema().fields());\n+        return convertToExpression(field.schema(), k.get(field));\n+      }).collect(Collectors.toList());\n+      final InListExpression inList\n+          = new InListExpression(node.getValueList().getLocation(), values);\n+      return Optional.of(new InPredicate(node.getLocation(), node.getValue(), inList));\n+    }\n+\n+    private Expression convertToExpression(final Schema schema, final Object value) {\n+      switch (schema.type()) {\n+        case STRING:\n+          return new StringLiteral((String) value);\n+        case INT8:\n+        case INT16:\n+        case INT32:\n+          return new IntegerLiteral((int) value);\n+        case INT64:\n+          return new LongLiteral((long) value);\n+        case FLOAT32:\n+        case FLOAT64:\n+          return new DoubleLiteral((double) value);\n+        default:\n+          throw new KsqlException(\"Unknown key type \" + schema.type());", "originalCommit": "beb105b8f097b92482913ba27b540d137ed01a33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0MTkzMg==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505841932", "bodyText": "As we mentioned elsewhere, I entirely got rid of this rewriter and instead use partitions to ensure I only read the correct data rather than the keys only.  I also added partition to the read calls on streams so that it enforces this both for this change and when range queries are soon implemented.", "author": "AlanConfluent", "createdAt": "2020-10-15T20:55:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0NjE3MA=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/rewrite/PullQueryKeyUpdater.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/rewrite/PullQueryKeyUpdater.java\ndeleted file mode 100644\nindex 5501520e20..0000000000\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/rewrite/PullQueryKeyUpdater.java\n+++ /dev/null\n\n@@ -1,106 +0,0 @@\n-/*\n- * Copyright 2020 Confluent Inc.\n- *\n- * Licensed under the Confluent Community License (the \"License\"); you may not use\n- * this file except in compliance with the License.  You may obtain a copy of the\n- * License at\n- *\n- * http://www.confluent.io/confluent-community-license\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n- * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations under the License.\n- */\n-\n-package io.confluent.ksql.engine.rewrite;\n-\n-import com.google.common.collect.Iterables;\n-import io.confluent.ksql.engine.rewrite.ExpressionTreeRewriter.Context;\n-import io.confluent.ksql.execution.expression.tree.DoubleLiteral;\n-import io.confluent.ksql.execution.expression.tree.Expression;\n-import io.confluent.ksql.execution.expression.tree.InListExpression;\n-import io.confluent.ksql.execution.expression.tree.InPredicate;\n-import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n-import io.confluent.ksql.execution.expression.tree.LongLiteral;\n-import io.confluent.ksql.execution.expression.tree.StringLiteral;\n-import io.confluent.ksql.execution.expression.tree.VisitParentExpressionVisitor;\n-import io.confluent.ksql.parser.tree.Query;\n-import io.confluent.ksql.parser.tree.Statement;\n-import io.confluent.ksql.util.KsqlException;\n-import java.util.List;\n-import java.util.Optional;\n-import java.util.function.BiFunction;\n-import java.util.stream.Collectors;\n-import org.apache.kafka.connect.data.Field;\n-import org.apache.kafka.connect.data.Schema;\n-import org.apache.kafka.connect.data.Struct;\n-\n-/**\n- * Takes a configured statement and rewrites it to update the keys requested.  This only works if\n- * the query uses the IN keyword.\n- * This is required because when fetching multiple keys using the IN keyword, a given host may be\n- * the active for one partition and standby for another partition, and if you issue a query\n- * requesting keys from both partitions while using ksql.query.pull.enable.standby.reads=true,\n- * you'll fetch stale values unintentionally.\n- */\n-public final class PullQueryKeyUpdater {\n-\n-  private PullQueryKeyUpdater() {}\n-\n-  /**\n-   * Returns a Statement with the IN expression updated to include only the given keys.\n-   * @param statement the original statement.\n-   * @param keys the keys to include\n-   * @return The updated statement\n-   */\n-  public static Statement update(\n-      final Query statement,\n-      final List<Struct> keys) {\n-    final BiFunction<Expression, Void, Expression> expressionRewriter =\n-        (e, v) -> ExpressionTreeRewriter.rewriteWith(\n-            new ExpressionRewriterPlugin(keys)::process, e, v);\n-    return (Statement) new StatementRewriter<>(expressionRewriter, (n, c) -> Optional.empty())\n-        .rewrite(statement, null);\n-  }\n-\n-  private static final class ExpressionRewriterPlugin extends\n-      VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n-\n-    private final List<Struct> keys;\n-\n-    ExpressionRewriterPlugin(final List<Struct> keys) {\n-      super(Optional.empty());\n-      this.keys = keys;\n-    }\n-\n-    @Override\n-    public Optional<Expression> visitInPredicate(final InPredicate node, final Context<Void> ctx) {\n-      final List<Expression> values = keys.stream().map(k -> {\n-        final Field field = Iterables.getOnlyElement(k.schema().fields());\n-        return convertToExpression(field.schema(), k.get(field));\n-      }).collect(Collectors.toList());\n-      final InListExpression inList\n-          = new InListExpression(node.getValueList().getLocation(), values);\n-      return Optional.of(new InPredicate(node.getLocation(), node.getValue(), inList));\n-    }\n-\n-    private Expression convertToExpression(final Schema schema, final Object value) {\n-      switch (schema.type()) {\n-        case STRING:\n-          return new StringLiteral((String) value);\n-        case INT8:\n-        case INT16:\n-        case INT32:\n-          return new IntegerLiteral((int) value);\n-        case INT64:\n-          return new LongLiteral((long) value);\n-        case FLOAT32:\n-        case FLOAT64:\n-          return new DoubleLiteral((double) value);\n-        default:\n-          throw new KsqlException(\"Unknown key type \" + schema.type());\n-      }\n-    }\n-  }\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1MDY4OA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505050688", "bodyText": "is there any requirement that the pull query result is reproducible? it seems like we add rows to the result based on the order of the nodes that we request, but those nodes can host different partitions at different times. I think it's reasonable to not guarantee ordering, but food for thought (and probably should be documented)", "author": "agavra", "createdAt": "2020-10-14T23:07:03Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,36 +234,73 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<Struct> keys = whereInfo.keysBound.stream()\n+          .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+          .collect(ImmutableList.toImmutableList());\n+      final List<KsqlNodeList> nodeLists = mat.locator().locate(\n+          keys,\n+          routingOptions,\n+          routingFilterFactory\n+      );\n \n-      final PullQueryContext pullQueryContext = new PullQueryContext(\n-          key,\n-          mat,\n-          analysis,\n-          whereInfo,\n-          queryId,\n-          contextStacker,\n-          pullQueryMetrics);\n+      for (KsqlNodeList ksqlNodeList : nodeLists) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(\n+            ksqlNodeList.getKeys(),\n+            mat,\n+            analysis,\n+            whereInfo,\n+            queryId,\n+            contextStacker,\n+            pullQueryMetrics);\n+\n+        futures.add(executorService.submit(() -> handlePullQuery(\n+            statement,\n+            executionContext,\n+            serviceContext,\n+            pullQueryContext,\n+            ksqlNodeList.getNodes(),\n+            routingOptions\n+        )));\n \n-      final PullQueryResult result = handlePullQuery(\n-          statement,\n-          executionContext,\n-          serviceContext,\n-          pullQueryContext,\n-          routingOptions\n-      );\n+      }\n+      for (Future<PullQueryResult> future : futures) {", "originalCommit": "beb105b8f097b92482913ba27b540d137ed01a33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0NTkwNw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505845907", "bodyText": "Yes, you're right that there are no guarantees about ordering.  I'll document that in the code and consider documenting elsewhere as well.", "author": "AlanConfluent", "createdAt": "2020-10-15T21:00:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1MDY4OA=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex bed9d55797..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -234,22 +229,13 @@ public final class PullQueryExecutor {\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n-      final List<List<?>> tableRows = new ArrayList<>();\n-      final List<LogicalSchema> schemas = new ArrayList<>();\n-      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n-      final List<Struct> keys = whereInfo.keysBound.stream()\n-          .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n-          .collect(ImmutableList.toImmutableList());\n-      final List<KsqlNodeList> nodeLists = mat.locator().locate(\n-          keys,\n-          routingOptions,\n-          routingFilterFactory\n-      );\n+      List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      List<List<?>> tableRows = new ArrayList<>();\n+      for (Object keyBound : whereInfo.keysBound) {\n+        final Struct key = asKeyStruct(keyBound, query.getPhysicalSchema());\n \n-      for (KsqlNodeList ksqlNodeList : nodeLists) {\n         final PullQueryContext pullQueryContext = new PullQueryContext(\n-            ksqlNodeList.getKeys(),\n+            key,\n             mat,\n             analysis,\n             whereInfo,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1NzI0Ng==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505057246", "bodyText": "nit: probably makes sense to make this Optional<List<KsqlNode>> instead of List<Optional<KsqlNode>> to prevent creating a list of empty optionals in the non-debug case. And then you can also use Collections#nCopies to make it a little more readable", "author": "agavra", "createdAt": "2020-10-14T23:16:28Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -289,11 +329,14 @@ private PullQueryResult handlePullQuery(\n     // increasing order of lag.\n     for (KsqlNode node : filteredAndOrderedNodes) {\n       try {\n+        final TableRows rows\n+            = routeQuery(node, statement, executionContext, serviceContext, pullQueryContext);\n         final Optional<KsqlNode> debugNode = Optional.ofNullable(\n             routingOptions.isDebugRequest() ? node : null);\n-        return new PullQueryResult(\n-            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n-            debugNode);\n+        final List<Optional<KsqlNode>> debugNodes = rows.getRows().stream()", "originalCommit": "beb105b8f097b92482913ba27b540d137ed01a33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg1NTU4OQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505855589", "bodyText": "I had been thinking that maybe this was necessary because different machines can have different configs, but I now remember that this is a request config, so it should always work.  Ok, made it Optional<List<KsqlNode>>", "author": "AlanConfluent", "createdAt": "2020-10-15T21:12:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1NzI0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex bed9d55797..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -329,14 +303,11 @@ public final class PullQueryExecutor {\n     // increasing order of lag.\n     for (KsqlNode node : filteredAndOrderedNodes) {\n       try {\n-        final TableRows rows\n-            = routeQuery(node, statement, executionContext, serviceContext, pullQueryContext);\n         final Optional<KsqlNode> debugNode = Optional.ofNullable(\n             routingOptions.isDebugRequest() ? node : null);\n-        final List<Optional<KsqlNode>> debugNodes = rows.getRows().stream()\n-            .map(r -> debugNode)\n-            .collect(Collectors.toList());\n-        return new PullQueryResult(rows, debugNodes);\n+        return new PullQueryResult(\n+            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n+            debugNode);\n       } catch (Exception t) {\n         LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n                   statement.getStatementText(), node, System.currentTimeMillis(), t);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2MjI2MA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505062260", "bodyText": "I'm worried this approach doesn't scale well for things other than IN queries (not to mention that it feels hacky). Instead, it probably makes sense to have a way to specify that a pull query (internally routed only) should only read from certain partitions. Otherwise, how would we handle things like range queries? I can't \"rewrite\" the range query and avoid the risk of reading standby data.\nGenerally, I think it might make sense to think about communicating pull queries internally using something other than just the SQL statement.", "author": "agavra", "createdAt": "2020-10-14T23:23:53Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -389,8 +438,14 @@ private static TableRows queryRowsLocally(\n   private static TableRows forwardTo(\n       final KsqlNode owner,\n       final ConfiguredStatement<Query> statement,\n-      final ServiceContext serviceContext\n+      final ServiceContext serviceContext,\n+      final PullQueryContext pullQueryContext\n   ) {\n+    // Rewrite the expression to only query for the particular keys we care about for this node.\n+    // Otherwise, we'll risk reading standby data for other partitions.", "originalCommit": "beb105b8f097b92482913ba27b540d137ed01a33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA5MzE1OQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505093159", "bodyText": "Yeah, that's fair.  We actually were discussing range queries as well and it's probably easier to use a unified approach.  I think that it should be sufficient to specify partition when reading from the table (to ensure you're only reading from the actives and standbys you intend) and also on the second hop, avoid reading keys that are not hosted on this machine or that don't agree with those specified partitions.  That same approach will work on range queries as well.", "author": "AlanConfluent", "createdAt": "2020-10-15T00:19:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2MjI2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg2ODQyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505868429", "bodyText": "Ok, implemented that other approach where partition is specified.  No rewriting necessary.", "author": "AlanConfluent", "createdAt": "2020-10-15T21:27:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2MjI2MA=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex bed9d55797..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -438,14 +403,8 @@ public final class PullQueryExecutor {\n   private static TableRows forwardTo(\n       final KsqlNode owner,\n       final ConfiguredStatement<Query> statement,\n-      final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext\n+      final ServiceContext serviceContext\n   ) {\n-    // Rewrite the expression to only query for the particular keys we care about for this node.\n-    // Otherwise, we'll risk reading standby data for other partitions.\n-    final Statement rewrittenStatement = PullQueryKeyUpdater.update(statement.getStatement(),\n-        pullQueryContext.keys);\n-    final String rewrittenSql = SqlFormatter.formatSql(rewrittenStatement) + \";\";\n     // Add skip forward flag to properties\n     final Map<String, Object> requestProperties = ImmutableMap.of(\n         KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2NDk1OQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505064959", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    throw new KsqlException(\"Ony comparison to literals is currently supported: \"\n          \n          \n            \n                    throw new KsqlException(\"Only comparison to literals is currently supported: \"", "author": "agavra", "createdAt": "2020-10-14T23:27:58Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -535,44 +590,65 @@ private static WhereInfo extractWhereInfo(\n     final Expression where = analysis.getWhereExpression()\n         .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n \n-    final Map<ComparisonTarget, List<ComparisonExpression>> comparisons =\n-        extractComparisons(where, query);\n-\n-    final List<ComparisonExpression> keyComparison = comparisons.get(ComparisonTarget.KEYCOL);\n-    if (keyComparison == null) {\n+    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n+    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n+    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n+    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n       throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n+    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n+      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n     }\n \n-    final Object key = extractKeyWhereClause(\n-        keyComparison,\n-        windowed,\n-        query.getLogicalSchema()\n-    );\n+    final List<Object> keys;\n+    if (keyComparison.size() > 0) {\n+      keys = ImmutableList.of(\n+          extractKeyWhereClause(keyComparison, windowed, query.getLogicalSchema()));\n+    } else {\n+      keys = extractKeysFromInPredicate(inPredicate, windowed, query.getLogicalSchema());\n+    }\n \n     if (!windowed) {\n-      if (comparisons.size() > 1) {\n+      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n+          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n         throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n       }\n \n-      return new WhereInfo(key, Optional.empty());\n+      return new WhereInfo(keys, Optional.empty());\n     }\n \n     final WindowBounds windowBounds =\n-        extractWhereClauseWindowBounds(comparisons);\n+        extractWhereClauseWindowBounds(keyAndWindowBounds);\n \n-    return new WhereInfo(key, Optional.of(windowBounds));\n+    return new WhereInfo(keys, Optional.of(windowBounds));\n   }\n \n-  private static Object extractKeyWhereClause(\n-      final List<ComparisonExpression> comparisons,\n+  private static List<Object> extractKeysFromInPredicate(\n+      final List<InPredicate> inPredicates,\n       final boolean windowed,\n       final LogicalSchema schema\n   ) {\n-    if (comparisons.size() != 1) {\n-      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n+    final InPredicate inPredicate = Iterables.getLast(inPredicates);\n+    final List<Object> result = new ArrayList<>();\n+    for (Expression expression : inPredicate.getValueList().getValues()) {\n+      if (!(expression instanceof Literal)) {\n+        throw new KsqlException(\"Ony comparison to literals is currently supported: \"", "originalCommit": "beb105b8f097b92482913ba27b540d137ed01a33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0NTAyNw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505845027", "bodyText": "Done", "author": "AlanConfluent", "createdAt": "2020-10-15T20:59:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2NDk1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex bed9d55797..6e026ff40b 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -590,53 +549,54 @@ public final class PullQueryExecutor {\n     final Expression where = analysis.getWhereExpression()\n         .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n \n-    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n-    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n-    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n-    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n-      throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n-    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n-      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n-    }\n+    final Map<ComparisonTarget, List<ComparisonExpression>> comparisons =\n+        extractComparisons(where, query);\n+    if (comparisons.size() > 0) {\n+      final List<ComparisonExpression> keyComparison = comparisons.get(ComparisonTarget.KEYCOL);\n+      if (keyComparison == null) {\n+        throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n+      }\n \n-    final List<Object> keys;\n-    if (keyComparison.size() > 0) {\n-      keys = ImmutableList.of(\n-          extractKeyWhereClause(keyComparison, windowed, query.getLogicalSchema()));\n-    } else {\n-      keys = extractKeysFromInPredicate(inPredicate, windowed, query.getLogicalSchema());\n-    }\n+      final Object key = extractKeyWhereClause(\n+          keyComparison,\n+          windowed,\n+          query.getLogicalSchema()\n+      );\n+\n+      if (!windowed) {\n+        if (comparisons.size() > 1) {\n+          throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n+        }\n \n-    if (!windowed) {\n-      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n-          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n-        throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n+        return new WhereInfo(ImmutableList.of(key), Optional.empty());\n       }\n \n-      return new WhereInfo(keys, Optional.empty());\n-    }\n+      final WindowBounds windowBounds =\n+          extractWhereClauseWindowBounds(comparisons);\n \n-    final WindowBounds windowBounds =\n-        extractWhereClauseWindowBounds(keyAndWindowBounds);\n+      return new WhereInfo(ImmutableList.of(key), Optional.of(windowBounds));\n+    }\n+    Optional<InPredicate> inPredicate = extractInPredicate(where, query);\n+    if (inPredicate.isPresent()) {\n+      List<Object> keyValues = extractKeysFromInPredicate(inPredicate.get(), windowed,\n+          query.getLogicalSchema());\n \n-    return new WhereInfo(keys, Optional.of(windowBounds));\n+      return new WhereInfo(keyValues, Optional.empty());\n+    }\n+    throw invalidWhereClauseException(\"Unsupported expression: \" + where, false);\n   }\n \n   private static List<Object> extractKeysFromInPredicate(\n-      final List<InPredicate> inPredicates,\n+      final InPredicate inPredicate,\n       final boolean windowed,\n       final LogicalSchema schema\n   ) {\n-    final InPredicate inPredicate = Iterables.getLast(inPredicates);\n-    final List<Object> result = new ArrayList<>();\n+    List<Object> result = new ArrayList<>();\n     for (Expression expression : inPredicate.getValueList().getValues()) {\n       if (!(expression instanceof Literal)) {\n         throw new KsqlException(\"Ony comparison to literals is currently supported: \"\n             + inPredicate);\n       }\n-      if (expression instanceof NullLiteral) {\n-        throw new KsqlException(\"Primary key columns can not be NULL: \" + inPredicate);\n-      }\n       final Object value = ((Literal) expression).getValue();\n       result.add(coerceKey(schema, value, windowed));\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA3NjU4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505076582", "bodyText": "nit: computeIfAbsent returns the result of the compute, so you could just\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>());\n          \n          \n            \n                  groups.get(filteredHosts).add(key);\n          \n          \n            \n                  groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>()).add(key);", "author": "agavra", "createdAt": "2020-10-14T23:45:02Z", "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -68,54 +74,61 @@\n   }\n \n   @Override\n-  public List<KsqlNode> locate(\n-      final Struct key,\n+  public List<KsqlNodeList> locate(\n+      final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final KeyQueryMetadata metadata = kafkaStreams\n-        .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-    // Fail fast if Streams not ready. Let client handle it\n-    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-                stateStoreName, key);\n-      throw new MaterializationException(String.format(\n-          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-    }\n+    final Map<ImmutableList<KsqlNode>, List<Struct>> groups = new HashMap<>();\n+    for (Struct key : keys) {\n+      final KeyQueryMetadata metadata = kafkaStreams\n+          .queryMetadataForKey(stateStoreName, key, keySerializer);\n+\n+      // Fail fast if Streams not ready. Let client handle it\n+      if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n+        LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n+            stateStoreName, key);\n+        throw new MaterializationException(String.format(\n+            \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n+      }\n \n-    LOG.debug(\"Handling pull query for key {} in partition {} of state store {}.\",\n-              key, metadata.partition(), stateStoreName);\n-    \n-    final HostInfo activeHost = metadata.activeHost();\n-    final Set<HostInfo> standByHosts = metadata.standbyHosts();\n-\n-    // If the lookup is for a forwarded request, only filter localhost\n-    List<KsqlHostInfo> allHosts = null;\n-    if (routingOptions.skipForwardRequest()) {\n-      LOG.debug(\"Before filtering: Local host {} \", localHost);\n-      allHosts = ImmutableList.of(new KsqlHostInfo(localHost.getHost(), localHost.getPort()));\n-    } else {\n-      LOG.debug(\"Before filtering: Active host {} , standby hosts {}\", activeHost, standByHosts);\n-      allHosts = Stream.concat(Stream.of(activeHost), standByHosts.stream())\n-          .map(this::asKsqlHost)\n-          .collect(Collectors.toList());\n+      LOG.debug(\"Handling pull query for key {} in partition {} of state store {}.\",\n+          key, metadata.partition(), stateStoreName);\n+      final HostInfo activeHost = metadata.activeHost();\n+      final Set<HostInfo> standByHosts = metadata.standbyHosts();\n+\n+      // If the lookup is for a forwarded request, only filter localhost\n+      List<KsqlHostInfo> allHosts = null;\n+      if (routingOptions.skipForwardRequest()) {\n+        LOG.debug(\"Before filtering: Local host {} \", localHost);\n+        allHosts = ImmutableList.of(new KsqlHostInfo(localHost.getHost(), localHost.getPort()));\n+      } else {\n+        LOG.debug(\"Before filtering: Active host {} , standby hosts {}\", activeHost, standByHosts);\n+        allHosts = Stream.concat(Stream.of(activeHost), standByHosts.stream())\n+            .map(this::asKsqlHost)\n+            .collect(Collectors.toList());\n+      }\n+      final RoutingFilter routingFilter = routingFilterFactory.createRoutingFilter(routingOptions,\n+          allHosts, activeHost, applicationId, stateStoreName, metadata.partition());\n+\n+      // Filter out hosts based on active, liveness and max lag filters.\n+      // The list is ordered by routing preference: active node is first, then standby nodes.\n+      // If heartbeat is not enabled, all hosts are considered alive.\n+      // If the request is forwarded internally from another ksql server, only the max lag filter\n+      // is applied.\n+      final ImmutableList<KsqlNode> filteredHosts = allHosts.stream()\n+          .filter(routingFilter::filter)\n+          .map(this::asNode)\n+          .collect(ImmutableList.toImmutableList());\n+\n+      LOG.debug(\"Filtered and ordered hosts: {}\", filteredHosts);\n+\n+      groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>());\n+      groups.get(filteredHosts).add(key);", "originalCommit": "beb105b8f097b92482913ba27b540d137ed01a33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0NDA4NQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505844085", "bodyText": "This code hanged a lot, but I used this trick elsewhere.", "author": "AlanConfluent", "createdAt": "2020-10-15T20:58:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA3NjU4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "74f95f8286ada5c7ce51aee10b03615a086f3065", "chunk": "diff --git a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\nindex 3bfb8a707e..7a1273fa0c 100644\n--- a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n+++ b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n\n@@ -74,61 +68,54 @@ final class KsLocator implements Locator {\n   }\n \n   @Override\n-  public List<KsqlNodeList> locate(\n-      final List<Struct> keys,\n+  public List<KsqlNode> locate(\n+      final Struct key,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final Map<ImmutableList<KsqlNode>, List<Struct>> groups = new HashMap<>();\n-    for (Struct key : keys) {\n-      final KeyQueryMetadata metadata = kafkaStreams\n-          .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-      // Fail fast if Streams not ready. Let client handle it\n-      if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-        LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-            stateStoreName, key);\n-        throw new MaterializationException(String.format(\n-            \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-      }\n+    final KeyQueryMetadata metadata = kafkaStreams\n+        .queryMetadataForKey(stateStoreName, key, keySerializer);\n+\n+    // Fail fast if Streams not ready. Let client handle it\n+    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n+      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n+                stateStoreName, key);\n+      throw new MaterializationException(String.format(\n+          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n+    }\n \n-      LOG.debug(\"Handling pull query for key {} in partition {} of state store {}.\",\n-          key, metadata.partition(), stateStoreName);\n-      final HostInfo activeHost = metadata.activeHost();\n-      final Set<HostInfo> standByHosts = metadata.standbyHosts();\n-\n-      // If the lookup is for a forwarded request, only filter localhost\n-      List<KsqlHostInfo> allHosts = null;\n-      if (routingOptions.skipForwardRequest()) {\n-        LOG.debug(\"Before filtering: Local host {} \", localHost);\n-        allHosts = ImmutableList.of(new KsqlHostInfo(localHost.getHost(), localHost.getPort()));\n-      } else {\n-        LOG.debug(\"Before filtering: Active host {} , standby hosts {}\", activeHost, standByHosts);\n-        allHosts = Stream.concat(Stream.of(activeHost), standByHosts.stream())\n-            .map(this::asKsqlHost)\n-            .collect(Collectors.toList());\n-      }\n-      final RoutingFilter routingFilter = routingFilterFactory.createRoutingFilter(routingOptions,\n-          allHosts, activeHost, applicationId, stateStoreName, metadata.partition());\n-\n-      // Filter out hosts based on active, liveness and max lag filters.\n-      // The list is ordered by routing preference: active node is first, then standby nodes.\n-      // If heartbeat is not enabled, all hosts are considered alive.\n-      // If the request is forwarded internally from another ksql server, only the max lag filter\n-      // is applied.\n-      final ImmutableList<KsqlNode> filteredHosts = allHosts.stream()\n-          .filter(routingFilter::filter)\n-          .map(this::asNode)\n-          .collect(ImmutableList.toImmutableList());\n-\n-      LOG.debug(\"Filtered and ordered hosts: {}\", filteredHosts);\n-\n-      groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>());\n-      groups.get(filteredHosts).add(key);\n+    LOG.debug(\"Handling pull query for key {} in partition {} of state store {}.\",\n+              key, metadata.partition(), stateStoreName);\n+    \n+    final HostInfo activeHost = metadata.activeHost();\n+    final Set<HostInfo> standByHosts = metadata.standbyHosts();\n+\n+    // If the lookup is for a forwarded request, only filter localhost\n+    List<KsqlHostInfo> allHosts = null;\n+    if (routingOptions.skipForwardRequest()) {\n+      LOG.debug(\"Before filtering: Local host {} \", localHost);\n+      allHosts = ImmutableList.of(new KsqlHostInfo(localHost.getHost(), localHost.getPort()));\n+    } else {\n+      LOG.debug(\"Before filtering: Active host {} , standby hosts {}\", activeHost, standByHosts);\n+      allHosts = Stream.concat(Stream.of(activeHost), standByHosts.stream())\n+          .map(this::asKsqlHost)\n+          .collect(Collectors.toList());\n     }\n-    return groups.entrySet().stream()\n-        .map(e -> new NodeList(e.getValue(), e.getKey()))\n-        .collect(ImmutableList.toImmutableList());\n+    final RoutingFilter routingFilter = routingFilterFactory.createRoutingFilter(routingOptions,\n+        allHosts, activeHost, applicationId, stateStoreName, metadata.partition());\n+\n+    // Filter out hosts based on active, liveness and max lag filters.\n+    // The list is ordered by routing preference: active node is first, then standby nodes.\n+    // If heartbeat is not enabled, all hosts are considered alive.\n+    // If the request is forwarded internally from another ksql server, only the max lag filter\n+    // is applied.\n+    final List<KsqlNode> filteredHosts = allHosts.stream()\n+        .filter(routingFilter::filter)\n+        .map(this::asNode)\n+        .collect(Collectors.toList());\n+\n+    LOG.debug(\"Filtered and ordered hosts: {}\", filteredHosts);\n+    return filteredHosts;\n   }\n \n   @VisibleForTesting\n"}}, {"oid": "74f95f8286ada5c7ce51aee10b03615a086f3065", "url": "https://github.com/confluentinc/ksql/commit/74f95f8286ada5c7ce51aee10b03615a086f3065", "message": "Basic version", "committedDate": "2020-10-16T22:02:37Z", "type": "commit"}, {"oid": "332017dcb31ee51be6991679b834e8a2cdf46925", "url": "https://github.com/confluentinc/ksql/commit/332017dcb31ee51be6991679b834e8a2cdf46925", "message": "Groups queries by location", "committedDate": "2020-10-16T22:02:37Z", "type": "commit"}, {"oid": "6b8970512b59b4b5249f80b041b7f06545bfa235", "url": "https://github.com/confluentinc/ksql/commit/6b8970512b59b4b5249f80b041b7f06545bfa235", "message": "Makes it multithreaded", "committedDate": "2020-10-16T22:02:37Z", "type": "commit"}, {"oid": "db742d1981f69fe2cac152d64093eba66e7a3d95", "url": "https://github.com/confluentinc/ksql/commit/db742d1981f69fe2cac152d64093eba66e7a3d95", "message": "Reworked to work with window functions", "committedDate": "2020-10-16T22:02:37Z", "type": "commit"}, {"oid": "e02ab188ed3b4f1f0eaf09768585bf4b56c10dc7", "url": "https://github.com/confluentinc/ksql/commit/e02ab188ed3b4f1f0eaf09768585bf4b56c10dc7", "message": "Gets tests working", "committedDate": "2020-10-16T22:02:37Z", "type": "commit"}, {"oid": "41f34c1a8c14713ab3df1320e63087c224c4f757", "url": "https://github.com/confluentinc/ksql/commit/41f34c1a8c14713ab3df1320e63087c224c4f757", "message": "mvn validate", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "40ee19af6560f097a2959358fa21ddb0f37baba9", "url": "https://github.com/confluentinc/ksql/commit/40ee19af6560f097a2959358fa21ddb0f37baba9", "message": "Adds rest query validation tests", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "cd573e08a7ca45d4072ac4bbc3f838ae0ad3d9c7", "url": "https://github.com/confluentinc/ksql/commit/cd573e08a7ca45d4072ac4bbc3f838ae0ad3d9c7", "message": "Fixes test", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "f505f71f657b1c7351864c67ea8870f119b45406", "url": "https://github.com/confluentinc/ksql/commit/f505f71f657b1c7351864c67ea8870f119b45406", "message": "Feedback", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "4b662c8c3a32b2562a9532836000dea955cc162d", "url": "https://github.com/confluentinc/ksql/commit/4b662c8c3a32b2562a9532836000dea955cc162d", "message": "Revert change to RestQueryTranslationTest", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "fb493c2dde16c2238003ad95e6dbed5459059659", "url": "https://github.com/confluentinc/ksql/commit/fb493c2dde16c2238003ad95e6dbed5459059659", "message": "Changes to reorganize by host each time", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "1a55d1f807dcff3631edb2fbb3a8e949481b2cc2", "url": "https://github.com/confluentinc/ksql/commit/1a55d1f807dcff3631edb2fbb3a8e949481b2cc2", "message": "Changed to using partition rather than rewriting keys", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "c13a9c8b9790b986fc81f35c05546d3cb798a652", "url": "https://github.com/confluentinc/ksql/commit/c13a9c8b9790b986fc81f35c05546d3cb798a652", "message": "Removes key dups", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "4888c5752f3fc7a22bf8d2078cacefbd2eb8be31", "url": "https://github.com/confluentinc/ksql/commit/4888c5752f3fc7a22bf8d2078cacefbd2eb8be31", "message": "Uncomments KsLocatorTest.java and adds a case", "committedDate": "2020-10-16T22:02:38Z", "type": "commit"}, {"oid": "54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "url": "https://github.com/confluentinc/ksql/commit/54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "message": "Ups threads to 100", "committedDate": "2020-10-16T22:05:34Z", "type": "commit"}, {"oid": "54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "url": "https://github.com/confluentinc/ksql/commit/54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "message": "Ups threads to 100", "committedDate": "2020-10-16T22:05:34Z", "type": "forcePushed"}, {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "url": "https://github.com/confluentinc/ksql/commit/f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "message": "Fixes RestQueryTranslationTest", "committedDate": "2020-10-19T21:38:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc0MjY0Mw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508742643", "bodyText": "We really need to add some comments in the code. I am having a hard time following and trying to understand what it does, and I already know what it is supposed to do :-P", "author": "vpapavas", "createdAt": "2020-10-20T18:20:32Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -265,45 +294,104 @@ void checkRateLimit() {\n     }\n   }\n \n-  private PullQueryResult handlePullQuery(\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    TableRows routeQuery(\n+        KsqlNode node,\n+        ConfiguredStatement<Query> statement,\n+        KsqlExecutionContext executionContext,\n+        ServiceContext serviceContext,\n+        PullQueryContext pullQueryContext\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  static PullQueryResult handlePullQuery(\n       final ConfiguredStatement<Query> statement,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext,\n-      final RoutingOptions routingOptions\n-  ) {\n-    // Get active and standby nodes for this key\n-    final Locator locator = pullQueryContext.mat.locator();\n-    final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n-        routingOptions,\n-        routingFilterFactory\n-    );\n-\n-    if (filteredAndOrderedNodes.isEmpty()) {\n+      final RoutingOptions routingOptions,\n+      final Function<List<KsqlLocation>, PullQueryContext> contextFactory,\n+      final QueryId queryId,\n+      final List<KsqlLocation> locations,\n+      final ExecutorService executorService,\n+      final RouteQuery routeQuery\n+  ) throws InterruptedException {\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n       LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-                statement.getStatementText());\n+          statement.getStatementText());\n       throw new MaterializationException(String.format(\n           \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n           statement.getStatementText()));\n     }\n \n-    // Nodes are ordered by preference: active is first if alive then standby nodes in\n-    // increasing order of lag.\n-    for (KsqlNode node : filteredAndOrderedNodes) {\n-      try {\n-        final Optional<KsqlNode> debugNode = Optional.ofNullable(\n-            routingOptions.isDebugRequest() ? node : null);\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();", "originalCommit": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgwODgxMw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508808813", "bodyText": "I agree.  I added a lot of comments for the newer code I wrote.  Tell me if anything is unclear.", "author": "AlanConfluent", "createdAt": "2020-10-20T20:12:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc0MjY0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "09a06dd90822b7aa3cf52550fddb5240df513111", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex ab733aef70..e050b38e01 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -327,14 +327,31 @@ public final class PullQueryExecutor {\n           statement.getStatementText()));\n     }\n \n+    // The source nodes associated with each of the rows\n     final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n     final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n     final List<LogicalSchema> schemas = new ArrayList<>();\n     List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n     for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n       final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n           = groupByHost(statement, remainingLocations, round);\n \n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n       final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n       for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n         final KsqlNode node = entry.getKey();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc0MzI1NQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508743255", "bodyText": "Consider adding a more descriptive error message so that we know at which point in the code the query failed and why.", "author": "vpapavas", "createdAt": "2020-10-20T18:21:32Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -265,45 +294,104 @@ void checkRateLimit() {\n     }\n   }\n \n-  private PullQueryResult handlePullQuery(\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    TableRows routeQuery(\n+        KsqlNode node,\n+        ConfiguredStatement<Query> statement,\n+        KsqlExecutionContext executionContext,\n+        ServiceContext serviceContext,\n+        PullQueryContext pullQueryContext\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  static PullQueryResult handlePullQuery(\n       final ConfiguredStatement<Query> statement,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext,\n-      final RoutingOptions routingOptions\n-  ) {\n-    // Get active and standby nodes for this key\n-    final Locator locator = pullQueryContext.mat.locator();\n-    final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n-        routingOptions,\n-        routingFilterFactory\n-    );\n-\n-    if (filteredAndOrderedNodes.isEmpty()) {\n+      final RoutingOptions routingOptions,\n+      final Function<List<KsqlLocation>, PullQueryContext> contextFactory,\n+      final QueryId queryId,\n+      final List<KsqlLocation> locations,\n+      final ExecutorService executorService,\n+      final RouteQuery routeQuery\n+  ) throws InterruptedException {\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n       LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-                statement.getStatementText());\n+          statement.getStatementText());\n       throw new MaterializationException(String.format(\n           \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n           statement.getStatementText()));\n     }\n \n-    // Nodes are ordered by preference: active is first if alive then standby nodes in\n-    // increasing order of lag.\n-    for (KsqlNode node : filteredAndOrderedNodes) {\n-      try {\n-        final Optional<KsqlNode> debugNode = Optional.ofNullable(\n-            routingOptions.isDebugRequest() ? node : null);\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    for (int round = 0; ; round++) {\n+      final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        final PullQueryContext pullQueryContext = contextFactory.apply(entry.getValue());\n+\n+        futures.put(node, executorService.submit(() ->  {\n+          final TableRows rows = routeQuery.routeQuery(\n+              node, statement, executionContext, serviceContext, pullQueryContext);\n+          final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+              routingOptions.isDebugRequest()\n+                  ? Collections.nCopies(rows.getRows().size(), node) : null);\n+          return new PullQueryResult(rows, debugNodes);\n+        }));\n+      }\n+\n+      final ImmutableList.Builder<KsqlLocation> nextRoundRemaining = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>>  entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getTableRows().getSchema());\n+          tableRows.addAll(result.getTableRows().getRows());\n+        } catch (ExecutionException e) {\n+          LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+              statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n         return new PullQueryResult(\n-            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n-            debugNode);\n-      } catch (Exception t) {\n-        LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n-                  statement.getStatementText(), node, System.currentTimeMillis(), t);\n+            new TableRows(statement.getStatementText(), queryId, Iterables.getLast(schemas),\n+                tableRows),\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes));\n       }\n     }\n-    throw new MaterializationException(String.format(\n-        \"Unable to execute pull query: %s\", statement.getStatementText()));\n+  }\n+\n+  private static Map<KsqlNode, List<KsqlLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s\", statement.getStatementText()));", "originalCommit": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgxNjQyOA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508816428", "bodyText": "Ok, changed it to \"Unable to execute pull query: %s. Exhausted standby hosts to try.\"", "author": "AlanConfluent", "createdAt": "2020-10-20T20:25:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc0MzI1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "09a06dd90822b7aa3cf52550fddb5240df513111", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex ab733aef70..e050b38e01 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -327,14 +327,31 @@ public final class PullQueryExecutor {\n           statement.getStatementText()));\n     }\n \n+    // The source nodes associated with each of the rows\n     final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n     final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n     final List<LogicalSchema> schemas = new ArrayList<>();\n     List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n     for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n       final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n           = groupByHost(statement, remainingLocations, round);\n \n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n       final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n       for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n         final KsqlNode node = entry.getKey();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc3MjkwMA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508772900", "bodyText": "What this method does, is group all locations per the same host, which if round=0, will be the active. So, all locations (all keys) that have the same host as active will we grouped together. Then, in the second round, for any keys that the active failed, we will get the standby that is second in ordering.", "author": "vpapavas", "createdAt": "2020-10-20T19:07:12Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -265,45 +294,104 @@ void checkRateLimit() {\n     }\n   }\n \n-  private PullQueryResult handlePullQuery(\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    TableRows routeQuery(\n+        KsqlNode node,\n+        ConfiguredStatement<Query> statement,\n+        KsqlExecutionContext executionContext,\n+        ServiceContext serviceContext,\n+        PullQueryContext pullQueryContext\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  static PullQueryResult handlePullQuery(\n       final ConfiguredStatement<Query> statement,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext,\n-      final RoutingOptions routingOptions\n-  ) {\n-    // Get active and standby nodes for this key\n-    final Locator locator = pullQueryContext.mat.locator();\n-    final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n-        routingOptions,\n-        routingFilterFactory\n-    );\n-\n-    if (filteredAndOrderedNodes.isEmpty()) {\n+      final RoutingOptions routingOptions,\n+      final Function<List<KsqlLocation>, PullQueryContext> contextFactory,\n+      final QueryId queryId,\n+      final List<KsqlLocation> locations,\n+      final ExecutorService executorService,\n+      final RouteQuery routeQuery\n+  ) throws InterruptedException {\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n       LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-                statement.getStatementText());\n+          statement.getStatementText());\n       throw new MaterializationException(String.format(\n           \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n           statement.getStatementText()));\n     }\n \n-    // Nodes are ordered by preference: active is first if alive then standby nodes in\n-    // increasing order of lag.\n-    for (KsqlNode node : filteredAndOrderedNodes) {\n-      try {\n-        final Optional<KsqlNode> debugNode = Optional.ofNullable(\n-            routingOptions.isDebugRequest() ? node : null);\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    for (int round = 0; ; round++) {\n+      final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        final PullQueryContext pullQueryContext = contextFactory.apply(entry.getValue());\n+\n+        futures.put(node, executorService.submit(() ->  {\n+          final TableRows rows = routeQuery.routeQuery(\n+              node, statement, executionContext, serviceContext, pullQueryContext);\n+          final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+              routingOptions.isDebugRequest()\n+                  ? Collections.nCopies(rows.getRows().size(), node) : null);\n+          return new PullQueryResult(rows, debugNodes);\n+        }));\n+      }\n+\n+      final ImmutableList.Builder<KsqlLocation> nextRoundRemaining = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>>  entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getTableRows().getSchema());\n+          tableRows.addAll(result.getTableRows().getRows());\n+        } catch (ExecutionException e) {\n+          LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+              statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n         return new PullQueryResult(\n-            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n-            debugNode);\n-      } catch (Exception t) {\n-        LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n-                  statement.getStatementText(), node, System.currentTimeMillis(), t);\n+            new TableRows(statement.getStatementText(), queryId, Iterables.getLast(schemas),\n+                tableRows),\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes));\n       }\n     }\n-    throw new MaterializationException(String.format(\n-        \"Unable to execute pull query: %s\", statement.getStatementText()));\n+  }\n+\n+  private static Map<KsqlNode, List<KsqlLocation>> groupByHost(", "originalCommit": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgxNDQxNg==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508814416", "bodyText": "That's correct. I added this example to make it clearer:\n    // For example, locations might be:\n    // [ Partition 0 <Host 1, Host 2>,\n    //   Partition 1 <Host 2, Host 1>,\n    //   Partition 2 <Host 1, Host 2> ]\n    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].", "author": "AlanConfluent", "createdAt": "2020-10-20T20:23:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc3MjkwMA=="}], "type": "inlineReview", "revised_code": {"commit": "09a06dd90822b7aa3cf52550fddb5240df513111", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\nindex ab733aef70..e050b38e01 100644\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n\n@@ -327,14 +327,31 @@ public final class PullQueryExecutor {\n           statement.getStatementText()));\n     }\n \n+    // The source nodes associated with each of the rows\n     final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n     final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n     final List<LogicalSchema> schemas = new ArrayList<>();\n     List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n     for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n       final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n           = groupByHost(statement, remainingLocations, round);\n \n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n       final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n       for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n         final KsqlNode node = entry.getKey();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5MTEwNg==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508791106", "bodyText": "Why do you need to know the partitions here? Is it because you don't know which partitions are active and which standbys? If so, we can get this information with KafkaStreams.allMetadata().  If we know what each partition is, then for a forwarded request, we know we need to access the standby partitions whereas for a non-forwarded only the active ones. This could avoid sending the partitions over the network causing overhead.", "author": "vpapavas", "createdAt": "2020-10-20T19:40:46Z", "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -68,28 +73,64 @@\n   }\n \n   @Override\n-  public List<KsqlNode> locate(\n-      final Struct key,\n+  public List<KsqlLocation> locate(\n+      final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final KeyQueryMetadata metadata = kafkaStreams\n-        .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-    // Fail fast if Streams not ready. Let client handle it\n-    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-                stateStoreName, key);\n-      throw new MaterializationException(String.format(\n-          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-    }\n+    // Maintain request order for reproducibility by using a LinkedHashMap, even though it's\n+    // not a guarantee of the API.\n+    final Map<Integer, List<KsqlNode>> locationsByPartition = new LinkedHashMap<>();\n+    final Map<Integer, Set<Struct>> keysByPartition = new HashMap<>();\n+    final Set<Integer> filterPartitions = routingOptions.getPartitions();", "originalCommit": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg1Mzk5NA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508853994", "bodyText": "We need to know the partitions that are intended to be fetched because the forwarding node is orchestrating this round by round traversal through the prioritized node lists.  The real issue is that I'm always sending all keys to all nodes, regardless of whether I'm intending on fetching just the active partitions or standby ones.\nAs an example, let's say we have a Host 0 receiving the request:\n Key A -> Partition 0 <Host 1, Host 2>\n Key B -> Partition 1 <Host 2, Host 1>\n Key C -> Partition 2 <Host 1, Host 2>\n\nIn round 0, we go to Host 2, sending Keys A, B, and C.  Host 2 is the active for Partition 1, but the standby for Partitions 0 and 2.  Should Host 2 return Key B (as if it's being called for round 0) or Keys A and C (as if it's being called for round 1)?  If we know nothing else, we can't know.  Returning both would intermix the rounds and create duplicates of active and standby data.\nOne method I used to disambiguate things was to rewrite the query to modify the keys requested to indicate which it was interested in.  This was frowned upon, so I instead specified which partitions it was interested in, which accomplishes the same thing. We could specify \"round\" instead and rely on the local host's metadata to figure out what it should return, but I wanted as consistent a snapshot dictated by the orchestrating node.\nIn the above example, Host 0 receives the request and forwards it on to all others, both active and standby, so we can't rely on the status of forwarding to know which partitions we should go for.  Also, if there are multiple standbys, it matters whether we forward it on to the first or second in the list because the first might have lower lag.  So, even among local standby partitions, the orchestrator really may want some subset at a given time.\nAlso, as a last note, the partitions fetched are a comma-separated list of unique partition numbers, so even for 128 partitions, it's not a lot of data.", "author": "AlanConfluent", "createdAt": "2020-10-20T21:34:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5MTEwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkyOTUxNA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508929514", "bodyText": "I was thinking that you can be sure if it is a forwarded request, you need to access the standby partitions. And if you can know which partitions are active and which standby, then you can answer the question which partitions should be used to lookup keys. A request that is not forwarded always looksup active partitions whereas a forwarded request always looks up standby partitions.", "author": "vpapavas", "createdAt": "2020-10-21T01:07:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5MTEwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTcyNDkyMg==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r509724922", "bodyText": "Discussed offline. The reason we need the partitions is that we need to know also which standby we want since they are ordered so we cannot rely only on the round number", "author": "vpapavas", "createdAt": "2020-10-21T21:43:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5MTEwNg=="}], "type": "inlineReview", "revised_code": {"commit": "d59cdfbc39aa1314995eeeaf5503c9f66dd04158", "chunk": "diff --git a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\nindex cd414881f8..e4878dc11a 100644\n--- a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n+++ b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n\n@@ -73,7 +73,7 @@ final class KsLocator implements Locator {\n   }\n \n   @Override\n-  public List<KsqlLocation> locate(\n+  public List<KsqlPartitionLocation> locate(\n       final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5OTk3OA==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508799978", "bodyText": "Can we make this loop cheaper for forwarded requests if we do send the partitions in the request?", "author": "vpapavas", "createdAt": "2020-10-20T19:56:26Z", "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -68,28 +73,64 @@\n   }\n \n   @Override\n-  public List<KsqlNode> locate(\n-      final Struct key,\n+  public List<KsqlLocation> locate(\n+      final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final KeyQueryMetadata metadata = kafkaStreams\n-        .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-    // Fail fast if Streams not ready. Let client handle it\n-    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-                stateStoreName, key);\n-      throw new MaterializationException(String.format(\n-          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-    }\n+    // Maintain request order for reproducibility by using a LinkedHashMap, even though it's\n+    // not a guarantee of the API.\n+    final Map<Integer, List<KsqlNode>> locationsByPartition = new LinkedHashMap<>();\n+    final Map<Integer, Set<Struct>> keysByPartition = new HashMap<>();\n+    final Set<Integer> filterPartitions = routingOptions.getPartitions();\n+    for (Struct key : keys) {", "originalCommit": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg5MTcwMw==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508891703", "bodyText": "The only issue is that we still need to find which keys belong to which partitions to figure out which we should query for locally so we don't try them unnecessarily on rocksdb, which would also be expensive.  I could try to expose the info necessary to create a DefaultStreamPartitioner, but this seems a bit complex.  This may be a little wasteful, but it's not too bad.", "author": "AlanConfluent", "createdAt": "2020-10-20T23:07:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5OTk3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkyOTgwOQ==", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508929809", "bodyText": "No it's ok. I also realized that there is not much to do that is a low hanging fruit. Just wanted to pick your brain if you had anything in mind. But it's not necessary to do now.", "author": "vpapavas", "createdAt": "2020-10-21T01:08:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5OTk3OA=="}], "type": "inlineReview", "revised_code": {"commit": "d59cdfbc39aa1314995eeeaf5503c9f66dd04158", "chunk": "diff --git a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\nindex cd414881f8..e4878dc11a 100644\n--- a/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n+++ b/ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java\n\n@@ -73,7 +73,7 @@ final class KsLocator implements Locator {\n   }\n \n   @Override\n-  public List<KsqlLocation> locate(\n+  public List<KsqlPartitionLocation> locate(\n       final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n"}}, {"oid": "09a06dd90822b7aa3cf52550fddb5240df513111", "url": "https://github.com/confluentinc/ksql/commit/09a06dd90822b7aa3cf52550fddb5240df513111", "message": "Adds Comments", "committedDate": "2020-10-20T23:10:25Z", "type": "commit"}, {"oid": "d59cdfbc39aa1314995eeeaf5503c9f66dd04158", "url": "https://github.com/confluentinc/ksql/commit/d59cdfbc39aa1314995eeeaf5503c9f66dd04158", "message": "Renames KsqlLocation to KsqlPartitionLocation", "committedDate": "2020-10-21T20:45:08Z", "type": "commit"}]}