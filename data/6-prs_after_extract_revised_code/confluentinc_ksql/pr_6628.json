{"pr_number": 6628, "pr_title": "chore: support complex key pull queries", "pr_createdAt": "2020-11-17T01:28:26Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6628", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3NDg0OQ==", "url": "https://github.com/confluentinc/ksql/pull/6628#discussion_r525574849", "bodyText": "This is just done because GenericExpressionResolver isn't as low overhead right?", "author": "AlanConfluent", "createdAt": "2020-11-17T22:44:25Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -778,31 +798,40 @@ private static Object extractKeyWhereClause(\n     }\n \n     final Expression other = getNonColumnRefSide(comparison);\n-    if (!(other instanceof Literal)) {\n-      throw new KsqlException(\"Ony comparison to literals is currently supported: \" + comparison);\n-    }\n-\n-    if (other instanceof NullLiteral) {\n-      throw new KsqlException(\"Primary key columns can not be NULL: \" + comparison);\n-    }\n-\n-    final Object right = ((Literal) other).getValue();\n-    return coerceKey(schema, right, windowed);\n+    final Column keyColumn = schema.key().get(0);\n+    return resolveKey(other, keyColumn, executionContext, config, comparison);\n   }\n \n-  private static Object coerceKey(\n-      final LogicalSchema schema,\n-      final Object right,\n-      final boolean windowed\n+  private static Object resolveKey(\n+      final Expression exp,\n+      final Column keyColumn,\n+      final KsqlExecutionContext executionContext,\n+      final KsqlConfig config,\n+      final Expression errorMessageHint\n   ) {\n-    if (schema.key().size() != 1) {\n-      throw invalidWhereClauseException(\"Only single KEY column supported\", windowed);\n+    final Object obj;\n+    if (exp instanceof NullLiteral) {\n+      obj = null;\n+    } else if (exp instanceof Literal) {\n+      // skip the GenericExpressionResolver because this is", "originalCommit": "d48b3b6d96d97676a0d7dfc1284cef242b727746", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4MDYzNw==", "url": "https://github.com/confluentinc/ksql/pull/6628#discussion_r525580637", "bodyText": "yup, that was exactly the idea", "author": "agavra", "createdAt": "2020-11-17T22:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3NDg0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "5dd79121d58e310f4cac749c0dbfa5a1f53fec48", "chunk": "diff --git a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java b/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\ndeleted file mode 100644\nindex 7b46990a62..0000000000\n--- a/ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java\n+++ /dev/null\n\n@@ -1,1431 +0,0 @@\n-/*\n- * Copyright 2019 Confluent Inc.\n- *\n- * Licensed under the Confluent Community License (the \"License\"); you may not use\n- * this file except in compliance with the License.  You may obtain a copy of the\n- * License at\n- *\n- * http://www.confluent.io/confluent-community-license\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n- * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations under the License.\n- */\n-\n-package io.confluent.ksql.rest.server.execution;\n-\n-import static java.util.Objects.requireNonNull;\n-\n-import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.collect.BoundType;\n-import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.ImmutableMap;\n-import com.google.common.collect.ImmutableSet;\n-import com.google.common.collect.Iterables;\n-import com.google.common.collect.Range;\n-import com.google.common.collect.Sets;\n-import com.google.common.collect.Sets.SetView;\n-import com.google.common.util.concurrent.RateLimiter;\n-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n-import io.confluent.ksql.GenericRow;\n-import io.confluent.ksql.KsqlExecutionContext;\n-import io.confluent.ksql.analyzer.ImmutableAnalysis;\n-import io.confluent.ksql.analyzer.PullQueryValidator;\n-import io.confluent.ksql.analyzer.QueryAnalyzer;\n-import io.confluent.ksql.analyzer.RewrittenAnalysis;\n-import io.confluent.ksql.config.SessionConfig;\n-import io.confluent.ksql.engine.generic.GenericExpressionResolver;\n-import io.confluent.ksql.engine.rewrite.ExpressionTreeRewriter.Context;\n-import io.confluent.ksql.execution.context.QueryContext;\n-import io.confluent.ksql.execution.context.QueryContext.Stacker;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil;\n-import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n-import io.confluent.ksql.execution.expression.tree.ComparisonExpression;\n-import io.confluent.ksql.execution.expression.tree.ComparisonExpression.Type;\n-import io.confluent.ksql.execution.expression.tree.Expression;\n-import io.confluent.ksql.execution.expression.tree.InPredicate;\n-import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n-import io.confluent.ksql.execution.expression.tree.Literal;\n-import io.confluent.ksql.execution.expression.tree.LogicalBinaryExpression;\n-import io.confluent.ksql.execution.expression.tree.LongLiteral;\n-import io.confluent.ksql.execution.expression.tree.NullLiteral;\n-import io.confluent.ksql.execution.expression.tree.QualifiedColumnReferenceExp;\n-import io.confluent.ksql.execution.expression.tree.StringLiteral;\n-import io.confluent.ksql.execution.expression.tree.UnqualifiedColumnReferenceExp;\n-import io.confluent.ksql.execution.expression.tree.VisitParentExpressionVisitor;\n-import io.confluent.ksql.execution.plan.SelectExpression;\n-import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n-import io.confluent.ksql.execution.streams.RoutingOptions;\n-import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n-import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n-import io.confluent.ksql.execution.streams.materialization.Materialization;\n-import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n-import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n-import io.confluent.ksql.execution.streams.materialization.TableRow;\n-import io.confluent.ksql.execution.transform.KsqlTransformer;\n-import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n-import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n-import io.confluent.ksql.execution.util.ExpressionTypeManager;\n-import io.confluent.ksql.logging.processing.ProcessingLogger;\n-import io.confluent.ksql.metastore.model.DataSource;\n-import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n-import io.confluent.ksql.model.WindowType;\n-import io.confluent.ksql.name.ColumnName;\n-import io.confluent.ksql.name.SourceName;\n-import io.confluent.ksql.parser.tree.AllColumns;\n-import io.confluent.ksql.parser.tree.Query;\n-import io.confluent.ksql.parser.tree.Select;\n-import io.confluent.ksql.parser.tree.SingleColumn;\n-import io.confluent.ksql.query.QueryId;\n-import io.confluent.ksql.rest.Errors;\n-import io.confluent.ksql.rest.SessionProperties;\n-import io.confluent.ksql.rest.client.RestResponse;\n-import io.confluent.ksql.rest.entity.StreamedRow;\n-import io.confluent.ksql.rest.entity.StreamedRow.Header;\n-import io.confluent.ksql.rest.entity.TableRows;\n-import io.confluent.ksql.rest.entity.TableRowsFactory;\n-import io.confluent.ksql.rest.server.resources.KsqlRestException;\n-import io.confluent.ksql.schema.ksql.Column;\n-import io.confluent.ksql.schema.ksql.DefaultSqlValueCoercer;\n-import io.confluent.ksql.schema.ksql.LogicalSchema;\n-import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n-import io.confluent.ksql.schema.ksql.PhysicalSchema;\n-import io.confluent.ksql.schema.ksql.SystemColumns;\n-import io.confluent.ksql.schema.ksql.types.SqlType;\n-import io.confluent.ksql.schema.utils.FormatOptions;\n-import io.confluent.ksql.serde.connect.ConnectSchemas;\n-import io.confluent.ksql.services.ServiceContext;\n-import io.confluent.ksql.statement.ConfiguredStatement;\n-import io.confluent.ksql.util.GrammaticalJoiner;\n-import io.confluent.ksql.util.KsqlConfig;\n-import io.confluent.ksql.util.KsqlException;\n-import io.confluent.ksql.util.KsqlRequestConfig;\n-import io.confluent.ksql.util.KsqlServerException;\n-import io.confluent.ksql.util.KsqlStatementException;\n-import io.confluent.ksql.util.PersistentQueryMetadata;\n-import io.confluent.ksql.util.timestamp.PartialStringToTimestampParser;\n-import java.time.Duration;\n-import java.time.Instant;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.LinkedHashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Map.Entry;\n-import java.util.Objects;\n-import java.util.Optional;\n-import java.util.Set;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-import java.util.concurrent.TimeUnit;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n-import org.apache.kafka.connect.data.ConnectSchema;\n-import org.apache.kafka.connect.data.Field;\n-import org.apache.kafka.connect.data.Struct;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n-@SuppressWarnings(\"UnstableApiUsage\")\n-public final class PullQueryExecutor {\n-  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n-\n-  private static final Logger LOG = LoggerFactory.getLogger(PullQueryExecutor.class);\n-\n-  private static final Set<Type> VALID_WINDOW_BOUNDS_TYPES = ImmutableSet.of(\n-      Type.EQUAL,\n-      Type.GREATER_THAN,\n-      Type.GREATER_THAN_OR_EQUAL,\n-      Type.LESS_THAN,\n-      Type.LESS_THAN_OR_EQUAL\n-  );\n-\n-  private static final String VALID_WINDOW_BOUNDS_COLUMNS =\n-      GrammaticalJoiner.and().join(SystemColumns.windowBoundsColumnNames());\n-\n-  private static final String VALID_WINDOW_BOUNDS_TYPES_STRING =\n-      GrammaticalJoiner.and().join(VALID_WINDOW_BOUNDS_TYPES);\n-\n-  private final KsqlExecutionContext executionContext;\n-  private final RoutingFilterFactory routingFilterFactory;\n-  private final RateLimiter rateLimiter;\n-  private final ExecutorService executorService;\n-\n-  public PullQueryExecutor(\n-      final KsqlExecutionContext executionContext,\n-      final RoutingFilterFactory routingFilterFactory,\n-      final KsqlConfig ksqlConfig\n-  ) {\n-    this(\n-        executionContext,\n-        routingFilterFactory,\n-        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG),\n-        Executors.newFixedThreadPool(\n-            ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n-        )\n-    );\n-  }\n-\n-  @VisibleForTesting\n-  PullQueryExecutor(\n-      final KsqlExecutionContext executionContext,\n-      final RoutingFilterFactory routingFilterFactory,\n-      final int maxQps, final ExecutorService executorService\n-  ) {\n-    this.executionContext = requireNonNull(executionContext, \"executionContext\");\n-    this.routingFilterFactory = requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n-    this.rateLimiter = RateLimiter.create(maxQps);\n-    this.executorService = requireNonNull(executorService, \"executorService\");\n-  }\n-\n-  @SuppressWarnings(\"unused\") // Needs to match validator API.\n-  public static void validate(\n-      final ConfiguredStatement<Query> statement,\n-      final SessionProperties sessionProperties,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext\n-  ) {\n-    throw new KsqlRestException(Errors.queryEndpoint(statement.getStatementText()));\n-  }\n-\n-  @SuppressFBWarnings(\"REC_CATCH_EXCEPTION\")\n-  public PullQueryResult execute(\n-      final ConfiguredStatement<Query> statement,\n-      final Map<String, Object> requestProperties,\n-      final ServiceContext serviceContext,\n-      final Optional<Boolean> isInternalRequest,\n-      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n-  ) {\n-    if (!statement.getStatement().isPullQuery()) {\n-      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n-    }\n-\n-    final SessionConfig sessionConfig = statement.getSessionConfig();\n-\n-    if (!sessionConfig.getConfig(false)\n-        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n-      throw new KsqlStatementException(\n-          \"Pull queries are disabled.\"\n-              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-              + System.lineSeparator()\n-              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n-              + \"this feature.\",\n-          statement.getStatementText());\n-    }\n-\n-    try {\n-      // Not using session.getConfig(true) due to performance issues,\n-      // see: https://github.com/confluentinc/ksql/issues/6407\n-      final RoutingOptions routingOptions = new ConfigRoutingOptions(\n-          sessionConfig.getConfig(false),\n-          statement.getSessionConfig().getOverrides(),\n-          requestProperties\n-      );\n-\n-      // If internal listeners are in use, we require the request to come from that listener to\n-      // treat it as having been forwarded.\n-      final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n-          // Trust the forward request option if isInternalRequest isn't available.\n-          && isInternalRequest.orElse(true);\n-\n-      // Only check the rate limit at the forwarding host\n-      if (!isAlreadyForwarded) {\n-        checkRateLimit();\n-      }\n-\n-      final ImmutableAnalysis analysis = new RewrittenAnalysis(\n-          analyze(statement, executionContext),\n-          new ColumnReferenceRewriter()::process\n-      );\n-\n-      final List<Column> key = analysis.getFrom().getDataSource().getSchema().key();\n-      if (key.size() > 1) {\n-        throw new KsqlException(\"Pull queries are not supported on sources with \"\n-            + \"more than one key column: \" + key);\n-      }\n-\n-      final PersistentQueryMetadata query = findMaterializingQuery(executionContext, analysis);\n-\n-      final WhereInfo whereInfo = extractWhereInfo(\n-          analysis,\n-          query,\n-          executionContext,\n-          statement.getSessionConfig().getConfig(false));\n-\n-      final QueryId queryId = uniqueQueryId();\n-\n-      final QueryContext.Stacker contextStacker = new Stacker();\n-\n-      final Materialization mat = query\n-          .getMaterialization(queryId, contextStacker)\n-          .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n-\n-      final List<Struct> keys = whereInfo.keysBound.stream()\n-          .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n-          .collect(ImmutableList.toImmutableList());\n-\n-      final List<KsqlPartitionLocation> locations = mat.locator().locate(\n-          keys,\n-          routingOptions,\n-          routingFilterFactory\n-      );\n-\n-      final Function<List<KsqlPartitionLocation>, PullQueryContext> contextFactory\n-          = (locationsForHost) ->\n-          new PullQueryContext(\n-              locationsForHost,\n-              mat,\n-              analysis,\n-              whereInfo,\n-              queryId,\n-              contextStacker,\n-              pullQueryMetrics);\n-\n-      return handlePullQuery(\n-          statement,\n-          executionContext,\n-          serviceContext,\n-          routingOptions,\n-          contextFactory,\n-          queryId,\n-          locations,\n-          executorService,\n-          PullQueryExecutor::routeQuery);\n-\n-    } catch (final Exception e) {\n-      pullQueryMetrics.ifPresent(metrics -> metrics.recordErrorRate(1));\n-      throw new KsqlStatementException(\n-          e.getMessage() == null ? \"Server Error\" : e.getMessage(),\n-          statement.getStatementText(),\n-          e\n-      );\n-    }\n-  }\n-\n-  public void close(final Duration timeout) {\n-    try {\n-      executorService.shutdown();\n-      executorService.awaitTermination(timeout.toMillis(), TimeUnit.MILLISECONDS);\n-    } catch (final InterruptedException e) {\n-      Thread.currentThread().interrupt();\n-    }\n-  }\n-\n-  private static void validateSchemas(final List<LogicalSchema> schemas) {\n-    final LogicalSchema schema = Iterables.getLast(schemas);\n-    for (LogicalSchema s : schemas) {\n-      if (!schema.equals(s)) {\n-        throw new KsqlException(\"Schemas from different hosts should be identical\");\n-      }\n-    }\n-  }\n-\n-  @VisibleForTesting\n-  void checkRateLimit() {\n-    if (!rateLimiter.tryAcquire()) {\n-      throw new KsqlException(\"Host is at rate limit for pull queries. Currently set to \"\n-          + rateLimiter.getRate() + \" qps.\");\n-    }\n-  }\n-\n-  @VisibleForTesting\n-  interface RouteQuery {\n-    TableRows routeQuery(\n-        KsqlNode node,\n-        ConfiguredStatement<Query> statement,\n-        KsqlExecutionContext executionContext,\n-        ServiceContext serviceContext,\n-        PullQueryContext pullQueryContext\n-    );\n-  }\n-\n-  @VisibleForTesting\n-  static PullQueryResult handlePullQuery(\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext,\n-      final RoutingOptions routingOptions,\n-      final Function<List<KsqlPartitionLocation>, PullQueryContext> contextFactory,\n-      final QueryId queryId,\n-      final List<KsqlPartitionLocation> locations,\n-      final ExecutorService executorService,\n-      final RouteQuery routeQuery\n-  ) throws InterruptedException {\n-    final boolean anyPartitionsEmpty = locations.stream()\n-        .anyMatch(location -> location.getNodes().isEmpty());\n-    if (anyPartitionsEmpty) {\n-      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-          statement.getStatementText());\n-      throw new MaterializationException(String.format(\n-          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n-          statement.getStatementText()));\n-    }\n-\n-    // The source nodes associated with each of the rows\n-    final List<KsqlNode> sourceNodes = new ArrayList<>();\n-    // Each of the table rows returned, aggregated across nodes\n-    final List<List<?>> tableRows = new ArrayList<>();\n-    // Each of the schemas returned, aggregated across nodes\n-    final List<LogicalSchema> schemas = new ArrayList<>();\n-    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n-    // For each round, each set of partition location objects is grouped by host, and all\n-    // keys associated with that host are batched together. For any requests that fail,\n-    // the partition location objects will be added to remainingLocations, and the next round\n-    // will attempt to fetch them from the next node in their prioritized list.\n-    // For example, locations might be:\n-    // [ Partition 0 <Host 1, Host 2>,\n-    //   Partition 1 <Host 2, Host 1>,\n-    //   Partition 2 <Host 1, Host 2> ]\n-    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n-    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n-    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n-    for (int round = 0; ; round++) {\n-      // Group all partition location objects by their nth round node\n-      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n-          = groupByHost(statement, remainingLocations, round);\n-\n-      // Make requests to each host, specifying the partitions we're interested in from\n-      // this host.\n-      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n-      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n-        final KsqlNode node = entry.getKey();\n-        final PullQueryContext pullQueryContext = contextFactory.apply(entry.getValue());\n-\n-        futures.put(node, executorService.submit(() ->  {\n-          final TableRows rows = routeQuery.routeQuery(\n-              node, statement, executionContext, serviceContext, pullQueryContext);\n-          final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n-              routingOptions.isDebugRequest()\n-                  ? Collections.nCopies(rows.getRows().size(), node) : null);\n-          return new PullQueryResult(rows, debugNodes);\n-        }));\n-      }\n-\n-      // Go through all of the results of the requests, either aggregating rows or adding\n-      // the locations to the nextRoundRemaining list.\n-      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n-          = ImmutableList.builder();\n-      for (Map.Entry<KsqlNode, Future<PullQueryResult>>  entry : futures.entrySet()) {\n-        final Future<PullQueryResult> future = entry.getValue();\n-        final KsqlNode node = entry.getKey();\n-        try {\n-          final PullQueryResult result = future.get();\n-          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n-          schemas.add(result.getTableRows().getSchema());\n-          tableRows.addAll(result.getTableRows().getRows());\n-        } catch (ExecutionException e) {\n-          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n-              statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n-          nextRoundRemaining.addAll(groupedByHost.get(node));\n-        }\n-      }\n-      remainingLocations = nextRoundRemaining.build();\n-\n-      // If there are no partition locations remaining, then we're done.\n-      if (remainingLocations.size() == 0) {\n-        validateSchemas(schemas);\n-        return new PullQueryResult(\n-            new TableRows(statement.getStatementText(), queryId, Iterables.getLast(schemas),\n-                tableRows),\n-            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes));\n-      }\n-    }\n-  }\n-\n-  /**\n-   * Groups all of the partition locations by the round-th entry in their prioritized list\n-   * of host nodes.\n-   * @param statement the statement from which this request came\n-   * @param locations the list of partition locations to parse\n-   * @param round which round this is\n-   * @return A map of node to list of partition locations\n-   */\n-  private static Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n-      final ConfiguredStatement<Query> statement,\n-      final List<KsqlPartitionLocation> locations,\n-      final int round) {\n-    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n-    for (KsqlPartitionLocation location : locations) {\n-      // If one of the partitions required is out of nodes, then we cannot continue.\n-      if (round >= location.getNodes().size()) {\n-        throw new MaterializationException(String.format(\n-            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n-            statement.getStatementText()));\n-      }\n-      final KsqlNode nextHost = location.getNodes().get(round);\n-      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n-    }\n-    return groupedByHost;\n-  }\n-\n-  private static TableRows routeQuery(\n-      final KsqlNode node,\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext\n-  ) {\n-    if (node.isLocal()) {\n-      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n-               statement.getStatementText(), node.location(), System.currentTimeMillis());\n-      pullQueryContext.pullQueryMetrics\n-          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n-      return queryRowsLocally(\n-          statement,\n-          executionContext,\n-          pullQueryContext);\n-    } else {\n-      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n-                statement.getStatementText(), node.location(), System.currentTimeMillis());\n-      pullQueryContext.pullQueryMetrics\n-          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n-      return forwardTo(node, statement, serviceContext, pullQueryContext);\n-    }\n-  }\n-\n-  private static TableRows queryRowsLocally(\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final PullQueryContext pullQueryContext\n-  ) {\n-    final Result result;\n-    if (pullQueryContext.whereInfo.windowBounds.isPresent()) {\n-      final WindowBounds windowBounds = pullQueryContext.whereInfo.windowBounds.get();\n-\n-      final ImmutableList.Builder<TableRow> allRows = ImmutableList.builder();\n-      for (KsqlPartitionLocation location : pullQueryContext.locations) {\n-        if (!location.getKeys().isPresent()) {\n-          throw new IllegalStateException(\"Window queries should be done with keys\");\n-        }\n-        for (Struct key : location.getKeys().get()) {\n-          final List<? extends TableRow> rows = pullQueryContext.mat.windowed()\n-              .get(key, location.getPartition(), windowBounds.start,\n-                  windowBounds.end);\n-          allRows.addAll(rows);\n-        }\n-      }\n-      result = new Result(pullQueryContext.mat.schema(), allRows.build());\n-    } else {\n-      final ImmutableList.Builder<TableRow> allRows = ImmutableList.builder();\n-      for (KsqlPartitionLocation location : pullQueryContext.locations) {\n-        if (!location.getKeys().isPresent()) {\n-          throw new IllegalStateException(\"Window queries should be done with keys\");\n-        }\n-        for (Struct key : location.getKeys().get()) {\n-          final List<? extends TableRow> rows = pullQueryContext.mat.nonWindowed()\n-              .get(key, location.getPartition())\n-              .map(ImmutableList::of)\n-              .orElse(ImmutableList.of());\n-          allRows.addAll(rows);\n-        }\n-      }\n-      result = new Result(pullQueryContext.mat.schema(), allRows.build());\n-    }\n-\n-    final LogicalSchema outputSchema;\n-    final List<List<?>> rows;\n-    if (isSelectStar(statement.getStatement().getSelect())) {\n-      outputSchema = TableRowsFactory.buildSchema(\n-          result.schema, pullQueryContext.mat.windowType().isPresent());\n-      rows = TableRowsFactory.createRows(result.rows);\n-    } else {\n-      final List<SelectExpression> projection = pullQueryContext.analysis.getSelectItems().stream()\n-          .map(SingleColumn.class::cast)\n-          .map(si -> SelectExpression\n-              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n-          .collect(Collectors.toList());\n-\n-      outputSchema = selectOutputSchema(\n-          result, executionContext, projection, pullQueryContext.mat.windowType());\n-\n-      rows = handleSelects(\n-          result,\n-          statement,\n-          executionContext,\n-          pullQueryContext.analysis,\n-          outputSchema,\n-          projection,\n-          pullQueryContext.mat.windowType(),\n-          pullQueryContext.queryId,\n-          pullQueryContext.contextStacker\n-      );\n-    }\n-    return new TableRows(\n-        statement.getStatementText(),\n-        pullQueryContext.queryId,\n-        outputSchema,\n-        rows\n-    );\n-  }\n-\n-  private static TableRows forwardTo(\n-      final KsqlNode owner,\n-      final ConfiguredStatement<Query> statement,\n-      final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext\n-  ) {\n-    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n-    // standby data when we are reading active for example.\n-    final String partitions = pullQueryContext.locations.stream()\n-        .map(location -> Integer.toString(location.getPartition()))\n-        .collect(Collectors.joining(\",\"));\n-    // Add skip forward flag to properties\n-    final Map<String, Object> requestProperties = ImmutableMap.of(\n-        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n-        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n-        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n-    final RestResponse<List<StreamedRow>> response = serviceContext\n-        .getKsqlClient()\n-        .makeQueryRequest(\n-            owner.location(),\n-            statement.getStatementText(),\n-            statement.getSessionConfig().getOverrides(),\n-            requestProperties\n-        );\n-\n-    if (response.isErroneous()) {\n-      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n-    }\n-\n-    final List<StreamedRow> streamedRows = response.getResponse();\n-    if (streamedRows.isEmpty()) {\n-      throw new KsqlServerException(\"Invalid empty response from forwarding call\");\n-    }\n-\n-    final Header header = streamedRows.get(0).getHeader()\n-        .orElseThrow(() -> new KsqlServerException(\"Expected header in first row\"));\n-\n-    final ImmutableList.Builder<List<?>> rows = ImmutableList.builder();\n-\n-    for (final StreamedRow row : streamedRows.subList(1, streamedRows.size())) {\n-      if (row.getErrorMessage().isPresent()) {\n-        throw new KsqlStatementException(\n-            row.getErrorMessage().get().getMessage(),\n-            statement.getStatementText()\n-        );\n-      }\n-\n-      if (!row.getRow().isPresent()) {\n-        throw new KsqlServerException(\"Unexpected forwarding response\");\n-      }\n-\n-      rows.add(row.getRow().get().getColumns());\n-    }\n-\n-    return new TableRows(\n-        statement.getStatementText(),\n-        header.getQueryId(),\n-        header.getSchema(),\n-        rows.build()\n-    );\n-  }\n-\n-  private static QueryId uniqueQueryId() {\n-    return new QueryId(\"query_\" + System.currentTimeMillis());\n-  }\n-\n-  private static ImmutableAnalysis analyze(\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext\n-  ) {\n-    final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(executionContext.getMetaStore(), \"\");\n-\n-    return queryAnalyzer.analyze(statement.getStatement(), Optional.empty());\n-  }\n-\n-  static final class PullQueryContext {\n-\n-    private final List<KsqlPartitionLocation> locations;\n-    private final Materialization mat;\n-    private final ImmutableAnalysis analysis;\n-    private final WhereInfo whereInfo;\n-    private final QueryId queryId;\n-    private final QueryContext.Stacker contextStacker;\n-    private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n-\n-    private PullQueryContext(\n-        final List<KsqlPartitionLocation> locations,\n-        final Materialization mat,\n-        final ImmutableAnalysis analysis,\n-        final WhereInfo whereInfo,\n-        final QueryId queryId,\n-        final QueryContext.Stacker contextStacker,\n-        final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n-    ) {\n-      this.locations = Objects.requireNonNull(locations, \"locations\");\n-      this.mat = Objects.requireNonNull(mat, \"materialization\");\n-      this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n-      this.whereInfo = Objects.requireNonNull(whereInfo, \"whereInfo\");\n-      this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n-      this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n-      this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n-    }\n-  }\n-\n-  private static final class WindowBounds {\n-\n-    private final Range<Instant> start;\n-    private final Range<Instant> end;\n-\n-    private WindowBounds(\n-        final Range<Instant> start,\n-        final Range<Instant> end\n-    ) {\n-      this.start = Objects.requireNonNull(start, \"startBounds\");\n-      this.end = Objects.requireNonNull(end, \"endBounds\");\n-    }\n-  }\n-\n-  private static final class WhereInfo {\n-\n-    private final List<Object> keysBound;\n-    private final Optional<WindowBounds> windowBounds;\n-\n-    private WhereInfo(\n-        final List<Object> keysBound,\n-        final Optional<WindowBounds> windowBounds\n-    ) {\n-      this.keysBound = keysBound;\n-      this.windowBounds = Objects.requireNonNull(windowBounds);\n-    }\n-  }\n-\n-  private static final class Result {\n-\n-    private final LogicalSchema schema;\n-    private final List<? extends TableRow> rows;\n-\n-    private Result(\n-        final LogicalSchema schema,\n-        final List<? extends TableRow> rows\n-    ) {\n-      this.schema = Objects.requireNonNull(schema, \"schema\");\n-      this.rows = Objects.requireNonNull(rows, \"rows\");\n-    }\n-  }\n-\n-  private static WhereInfo extractWhereInfo(\n-      final ImmutableAnalysis analysis,\n-      final PersistentQueryMetadata query,\n-      final KsqlExecutionContext executionContext,\n-      final KsqlConfig config\n-  ) {\n-    final boolean windowed = query.getResultTopic().getKeyFormat().isWindowed();\n-\n-    final Expression where = analysis.getWhereExpression()\n-        .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n-\n-    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n-    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n-    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n-    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n-      throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n-    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n-      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n-    }\n-\n-    final List<Object> keys;\n-    if (keyComparison.size() > 0) {\n-      keys = ImmutableList.of(\n-          extractKeyWhereClause(\n-              keyComparison,\n-              windowed,\n-              query.getLogicalSchema(),\n-              executionContext,\n-              config)\n-      );\n-    } else {\n-      keys = extractKeysFromInPredicate(\n-          inPredicate,\n-          windowed,\n-          query.getLogicalSchema(),\n-          executionContext,\n-          config\n-      );\n-    }\n-\n-    if (!windowed) {\n-      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n-          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n-        throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n-      }\n-\n-      return new WhereInfo(keys, Optional.empty());\n-    }\n-\n-    final WindowBounds windowBounds =\n-        extractWhereClauseWindowBounds(keyAndWindowBounds);\n-\n-    return new WhereInfo(keys, Optional.of(windowBounds));\n-  }\n-\n-  private static List<Object> extractKeysFromInPredicate(\n-      final List<InPredicate> inPredicates,\n-      final boolean windowed,\n-      final LogicalSchema schema,\n-      final KsqlExecutionContext executionContext,\n-      final KsqlConfig config\n-  ) {\n-    final InPredicate inPredicate = Iterables.getLast(inPredicates);\n-    if (schema.key().size() != 1) {\n-      throw invalidWhereClauseException(\"Only single KEY column supported\", windowed);\n-    }\n-\n-    final Column keyColumn = schema.key().get(0);\n-    return inPredicate.getValueList()\n-        .getValues()\n-        .stream()\n-        .map(expression -> resolveKey(expression, keyColumn, executionContext, config, inPredicate))\n-        .collect(Collectors.toList());\n-  }\n-\n-  private static Object extractKeyWhereClause(\n-      final List<ComparisonExpression> comparisons,\n-      final boolean windowed,\n-      final LogicalSchema schema,\n-      final KsqlExecutionContext executionContext,\n-      final KsqlConfig config\n-  ) {\n-    final ComparisonExpression comparison = Iterables.getLast(comparisons);\n-    if (comparison.getType() != Type.EQUAL) {\n-      final ColumnName keyColumn = Iterables.getOnlyElement(schema.key()).name();\n-      throw invalidWhereClauseException(\"Bound on '\" + keyColumn.text()\n-          + \"' must currently be '='\", windowed);\n-    }\n-\n-    final Expression other = getNonColumnRefSide(comparison);\n-    final Column keyColumn = schema.key().get(0);\n-    return resolveKey(other, keyColumn, executionContext, config, comparison);\n-  }\n-\n-  private static Object resolveKey(\n-      final Expression exp,\n-      final Column keyColumn,\n-      final KsqlExecutionContext executionContext,\n-      final KsqlConfig config,\n-      final Expression errorMessageHint\n-  ) {\n-    final Object obj;\n-    if (exp instanceof NullLiteral) {\n-      obj = null;\n-    } else if (exp instanceof Literal) {\n-      // skip the GenericExpressionResolver because this is\n-      // a critical code path executed once-per-query\n-      obj = ((Literal) exp).getValue();\n-    } else {\n-      obj = new GenericExpressionResolver(\n-          keyColumn.type(),\n-          keyColumn.name(),\n-          executionContext.getMetaStore(),\n-          config,\n-          \"pull query\"\n-      ).resolve(exp);\n-    }\n-\n-    if (obj == null) {\n-      throw new KsqlException(\"Primary key columns can not be NULL: \" + errorMessageHint);\n-    }\n-\n-    return DefaultSqlValueCoercer.STRICT.coerce(obj, keyColumn.type())\n-        .orElseThrow(() -> new KsqlException(\"'\" + obj + \"' can not be converted \"\n-            + \"to the type of the key column: \" + keyColumn.toString(FormatOptions.noEscape())))\n-        .orElse(null);\n-  }\n-\n-  private static WindowBounds extractWhereClauseWindowBounds(\n-      final KeyAndWindowBounds keyAndWindowBounds\n-  ) {\n-    return new WindowBounds(\n-        extractWhereClauseWindowBounds(ComparisonTarget.WINDOWSTART,\n-            keyAndWindowBounds.getWindowStartExpression()),\n-        extractWhereClauseWindowBounds(ComparisonTarget.WINDOWEND,\n-            keyAndWindowBounds.getWindowEndExpression())\n-    );\n-  }\n-\n-  private static Range<Instant> extractWhereClauseWindowBounds(\n-      final ComparisonTarget windowType,\n-      final List<ComparisonExpression> comparisons\n-  ) {\n-    if (comparisons.isEmpty()) {\n-      return Range.all();\n-    }\n-\n-    final Map<Type, List<ComparisonExpression>> byType = comparisons.stream()\n-        .collect(Collectors.groupingBy(PullQueryExecutor::getSimplifiedBoundType));\n-\n-    final SetView<Type> unsupported = Sets.difference(byType.keySet(), VALID_WINDOW_BOUNDS_TYPES);\n-    if (!unsupported.isEmpty()) {\n-      throw invalidWhereClauseException(\n-          \"Unsupported \" + windowType + \" bounds: \" + unsupported, true);\n-    }\n-\n-    final String duplicates = byType.entrySet().stream()\n-        .filter(e -> e.getValue().size() > 1)\n-        .map(e -> e.getKey() + \": \" + e.getValue())\n-        .collect(Collectors.joining(System.lineSeparator()));\n-\n-    if (!duplicates.isEmpty()) {\n-      throw invalidWhereClauseException(\n-          \"Duplicate \" + windowType + \" bounds on: \" + duplicates, true);\n-    }\n-\n-    final Map<Type, ComparisonExpression> singles = byType.entrySet().stream()\n-        .collect(Collectors.toMap(Entry::getKey, e -> e.getValue().get(0)));\n-\n-    final ComparisonExpression equals = singles.get(Type.EQUAL);\n-    if (equals != null) {\n-      if (byType.size() > 1) {\n-        throw invalidWhereClauseException(\n-            \"`\" + equals + \"` cannot be combined with other \" + windowType + \" bounds\",\n-            true\n-        );\n-      }\n-\n-      return Range.singleton(asInstant(getNonColumnRefSide(equals)));\n-    }\n-\n-    final Optional<ComparisonExpression> upper =\n-        Optional.ofNullable(singles.get(Type.LESS_THAN));\n-\n-    final Optional<ComparisonExpression> lower =\n-        Optional.ofNullable(singles.get(Type.GREATER_THAN));\n-\n-    return extractWindowBound(lower, upper);\n-  }\n-\n-  private static Type getSimplifiedBoundType(final ComparisonExpression comparison) {\n-    final Type type = comparison.getType();\n-    final boolean inverted = comparison.getRight() instanceof UnqualifiedColumnReferenceExp;\n-\n-    switch (type) {\n-      case LESS_THAN:\n-      case LESS_THAN_OR_EQUAL:\n-        return inverted ? Type.GREATER_THAN : Type.LESS_THAN;\n-      case GREATER_THAN:\n-      case GREATER_THAN_OR_EQUAL:\n-        return inverted ? Type.LESS_THAN : Type.GREATER_THAN;\n-      default:\n-        return type;\n-    }\n-  }\n-\n-  private static Range<Instant> extractWindowBound(\n-      final Optional<ComparisonExpression> lowerComparison,\n-      final Optional<ComparisonExpression> upperComparison\n-  ) {\n-    if (!lowerComparison.isPresent() && !upperComparison.isPresent()) {\n-      return Range.all();\n-    }\n-\n-    if (!lowerComparison.isPresent()) {\n-      final Instant upper = asInstant(getNonColumnRefSide(upperComparison.get()));\n-      final BoundType upperType = getRangeBoundType(upperComparison.get());\n-      return Range.upTo(upper, upperType);\n-    }\n-\n-    if (!upperComparison.isPresent()) {\n-      final Instant lower = asInstant(getNonColumnRefSide(lowerComparison.get()));\n-      final BoundType lowerType = getRangeBoundType(lowerComparison.get());\n-      return Range.downTo(lower, lowerType);\n-    }\n-\n-    final Instant lower = asInstant(getNonColumnRefSide(lowerComparison.get()));\n-    final BoundType lowerType = getRangeBoundType(lowerComparison.get());\n-\n-    final Instant upper = asInstant(getNonColumnRefSide(upperComparison.get()));\n-    final BoundType upperType = getRangeBoundType(upperComparison.get());\n-\n-    return Range.range(lower, lowerType, upper, upperType);\n-  }\n-\n-  private static BoundType getRangeBoundType(final ComparisonExpression lowerComparison) {\n-    final boolean openBound = lowerComparison.getType() == Type.LESS_THAN\n-        || lowerComparison.getType() == Type.GREATER_THAN;\n-\n-    return openBound\n-        ? BoundType.OPEN\n-        : BoundType.CLOSED;\n-  }\n-\n-  private static Expression getNonColumnRefSide(final ComparisonExpression comparison) {\n-    return comparison.getRight() instanceof UnqualifiedColumnReferenceExp\n-        ? comparison.getLeft()\n-        : comparison.getRight();\n-  }\n-\n-  private static Instant asInstant(final Expression other) {\n-    if (other instanceof IntegerLiteral) {\n-      return Instant.ofEpochMilli(((IntegerLiteral) other).getValue());\n-    }\n-\n-    if (other instanceof LongLiteral) {\n-      return Instant.ofEpochMilli(((LongLiteral) other).getValue());\n-    }\n-\n-    if (other instanceof StringLiteral) {\n-      final String text = ((StringLiteral) other).getValue();\n-      try {\n-        final long timestamp = new PartialStringToTimestampParser()\n-            .parse(text);\n-\n-        return Instant.ofEpochMilli(timestamp);\n-      } catch (final Exception e) {\n-        throw invalidWhereClauseException(\"Failed to parse datetime: \" + text, true);\n-      }\n-    }\n-\n-    throw invalidWhereClauseException(\n-        \"Window bounds must be an INT, BIGINT or STRING containing a datetime.\",\n-        true\n-    );\n-  }\n-\n-  private enum ComparisonTarget {\n-    WINDOWSTART,\n-    WINDOWEND\n-  }\n-\n-  private static class KeyAndWindowBounds {\n-    private List<ComparisonExpression> keyColExpression = new ArrayList<>();\n-    private List<ComparisonExpression> windowStartExpression = new ArrayList<>();\n-    private List<ComparisonExpression> windowEndExpression = new ArrayList<>();\n-    private List<InPredicate> inPredicate = new ArrayList<>();\n-\n-    KeyAndWindowBounds() {\n-    }\n-\n-    public KeyAndWindowBounds addKeyColExpression(final ComparisonExpression keyColExpression) {\n-      this.keyColExpression.add(keyColExpression);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds addWindowStartExpression(\n-        final ComparisonExpression windowStartExpression) {\n-      this.windowStartExpression.add(windowStartExpression);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds addWindowEndExpression(\n-        final ComparisonExpression windowEndExpression) {\n-      this.windowEndExpression.add(windowEndExpression);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds addInPredicate(final InPredicate inPredicate) {\n-      this.inPredicate.add(inPredicate);\n-      return this;\n-    }\n-\n-    public KeyAndWindowBounds merge(final KeyAndWindowBounds other) {\n-      keyColExpression.addAll(other.keyColExpression);\n-      windowStartExpression.addAll(other.windowStartExpression);\n-      windowEndExpression.addAll(other.windowEndExpression);\n-      inPredicate.addAll(other.inPredicate);\n-      return this;\n-    }\n-\n-    public List<ComparisonExpression> getKeyColExpression() {\n-      return keyColExpression;\n-    }\n-\n-    public List<ComparisonExpression> getWindowStartExpression() {\n-      return windowStartExpression;\n-    }\n-\n-    public List<ComparisonExpression> getWindowEndExpression() {\n-      return windowEndExpression;\n-    }\n-\n-    public List<InPredicate> getInPredicate() {\n-      return inPredicate;\n-    }\n-  }\n-\n-  private static KeyAndWindowBounds extractComparisons(\n-      final Expression exp,\n-      final PersistentQueryMetadata query\n-  ) {\n-    if (exp instanceof ComparisonExpression) {\n-      final ComparisonExpression comparison = (ComparisonExpression) exp;\n-      return extractWhereClauseTarget(comparison, query);\n-    }\n-\n-    if (exp instanceof InPredicate) {\n-      final InPredicate inPredicate = (InPredicate) exp;\n-      return extractWhereClauseTarget(inPredicate, query);\n-    }\n-\n-    if (exp instanceof LogicalBinaryExpression) {\n-      final LogicalBinaryExpression binary = (LogicalBinaryExpression) exp;\n-      if (binary.getType() != LogicalBinaryExpression.Type.AND) {\n-        throw invalidWhereClauseException(\"Only AND expressions are supported: \" + exp, false);\n-      }\n-\n-      final KeyAndWindowBounds left = extractComparisons(binary.getLeft(), query);\n-      final KeyAndWindowBounds right = extractComparisons(binary.getRight(), query);\n-      return left.merge(right);\n-    }\n-\n-    throw invalidWhereClauseException(\"Unsupported expression: \" + exp, false);\n-  }\n-\n-  private static KeyAndWindowBounds extractWhereClauseTarget(\n-      final ComparisonExpression comparison,\n-      final PersistentQueryMetadata query\n-  ) {\n-    final UnqualifiedColumnReferenceExp column;\n-    if (comparison.getRight() instanceof UnqualifiedColumnReferenceExp) {\n-      column = (UnqualifiedColumnReferenceExp) comparison.getRight();\n-    } else if (comparison.getLeft() instanceof UnqualifiedColumnReferenceExp) {\n-      column = (UnqualifiedColumnReferenceExp) comparison.getLeft();\n-    } else {\n-      throw invalidWhereClauseException(\"Invalid WHERE clause: \" + comparison, false);\n-    }\n-\n-    final ColumnName columnName = column.getColumnName();\n-    if (columnName.equals(SystemColumns.WINDOWSTART_NAME)) {\n-      return new KeyAndWindowBounds().addWindowStartExpression(comparison);\n-    }\n-\n-    if (columnName.equals(SystemColumns.WINDOWEND_NAME)) {\n-      return new KeyAndWindowBounds().addWindowEndExpression(comparison);\n-    }\n-\n-    final ColumnName keyColumn = Iterables.getOnlyElement(query.getLogicalSchema().key()).name();\n-    if (columnName.equals(keyColumn)) {\n-      return new KeyAndWindowBounds().addKeyColExpression(comparison);\n-    }\n-\n-    throw invalidWhereClauseException(\n-        \"WHERE clause on unsupported column: \" + columnName.text(),\n-        false\n-    );\n-  }\n-\n-  private static KeyAndWindowBounds extractWhereClauseTarget(\n-      final InPredicate inPredicate,\n-      final PersistentQueryMetadata query\n-  ) {\n-    final UnqualifiedColumnReferenceExp column\n-        = (UnqualifiedColumnReferenceExp) inPredicate.getValue();\n-    final ColumnName keyColumn = Iterables.getOnlyElement(query.getLogicalSchema().key()).name();\n-    if (column.getColumnName().equals(keyColumn)) {\n-      return new KeyAndWindowBounds().addInPredicate(inPredicate);\n-    }\n-\n-    throw invalidWhereClauseException(\n-        \"IN expression on unsupported column: \" + column.getColumnName().text(),\n-        false\n-    );\n-  }\n-\n-  private static boolean isSelectStar(final Select select) {\n-    final boolean someStars = select.getSelectItems().stream()\n-        .anyMatch(s -> s instanceof AllColumns);\n-\n-    if (someStars && select.getSelectItems().size() != 1) {\n-      throw new KsqlException(\"Pull queries only support wildcards in the projects \"\n-          + \"if they are the only expression\");\n-    }\n-\n-    return someStars;\n-  }\n-\n-  private static List<List<?>> handleSelects(\n-      final Result input,\n-      final ConfiguredStatement<Query> statement,\n-      final KsqlExecutionContext executionContext,\n-      final ImmutableAnalysis analysis,\n-      final LogicalSchema outputSchema,\n-      final List<SelectExpression> projection,\n-      final Optional<WindowType> windowType,\n-      final QueryId queryId,\n-      final Stacker contextStacker\n-  ) {\n-    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n-        .noneMatch(SystemColumns::isSystemColumn);\n-\n-    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n-        .noneMatch(input.schema::isKeyColumn);\n-\n-    final LogicalSchema intermediateSchema;\n-    final Function<TableRow, GenericRow> preSelectTransform;\n-    if (noSystemColumns && noKeyColumns) {\n-      intermediateSchema = input.schema;\n-      preSelectTransform = TableRow::value;\n-    } else {\n-      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n-      final boolean windowed = windowType.isPresent();\n-\n-      intermediateSchema = input.schema\n-          .withPseudoAndKeyColsInValue(windowed);\n-\n-      preSelectTransform = row -> {\n-        final Struct key = row.key();\n-        final GenericRow value = row.value();\n-\n-        final List<Object> keyFields = key.schema().fields().stream()\n-            .map(key::get)\n-            .collect(Collectors.toList());\n-\n-        value.ensureAdditionalCapacity(\n-            1 // ROWTIME\n-            + keyFields.size()\n-            + row.window().map(w -> 2).orElse(0)\n-        );\n-\n-        value.append(row.rowTime());\n-        value.appendAll(keyFields);\n-\n-        row.window().ifPresent(window -> {\n-          value.append(window.start().toEpochMilli());\n-          value.append(window.end().toEpochMilli());\n-        });\n-\n-        return value;\n-      };\n-    }\n-\n-    final KsqlConfig ksqlConfig = statement.getSessionConfig().getConfig(true);\n-\n-    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n-        projection,\n-        intermediateSchema,\n-        ksqlConfig,\n-        executionContext.getMetaStore()\n-    );\n-\n-    final ProcessingLogger logger = executionContext\n-        .getProcessingLogContext()\n-        .getLoggerFactory()\n-        .getLogger(\n-            QueryLoggerUtil.queryLoggerName(\n-                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n-        );\n-\n-    final KsqlTransformer<Object, GenericRow> transformer = select\n-        .getTransformer(logger);\n-\n-    final ImmutableList.Builder<List<?>> output = ImmutableList.builder();\n-    input.rows.forEach(r -> {\n-      final GenericRow intermediate = preSelectTransform.apply(r);\n-\n-      final GenericRow mapped = transformer.transform(\n-          r.key(),\n-          intermediate,\n-          new PullProcessingContext(r.rowTime())\n-      );\n-      validateProjection(mapped, outputSchema);\n-      output.add(mapped.values());\n-    });\n-\n-    return output.build();\n-  }\n-\n-  private static void validateProjection(\n-      final GenericRow fullRow,\n-      final LogicalSchema schema\n-  ) {\n-    final int actual = fullRow.size();\n-    final int expected = schema.columns().size();\n-    if (actual != expected) {\n-      throw new IllegalStateException(\"Row column count mismatch.\"\n-          + \" expected:\" + expected\n-          + \", got:\" + actual\n-      );\n-    }\n-  }\n-\n-  private static LogicalSchema selectOutputSchema(\n-      final Result input,\n-      final KsqlExecutionContext executionContext,\n-      final List<SelectExpression> selectExpressions,\n-      final Optional<WindowType> windowType\n-  ) {\n-    final Builder schemaBuilder = LogicalSchema.builder();\n-\n-    // Copy meta & key columns into the value schema as SelectValueMapper expects it:\n-    final LogicalSchema schema = input.schema\n-        .withPseudoAndKeyColsInValue(windowType.isPresent());\n-\n-    final ExpressionTypeManager expressionTypeManager =\n-        new ExpressionTypeManager(schema, executionContext.getMetaStore());\n-\n-    for (final SelectExpression select : selectExpressions) {\n-      final SqlType type = expressionTypeManager.getExpressionSqlType(select.getExpression());\n-\n-      if (input.schema.isKeyColumn(select.getAlias())\n-          || select.getAlias().equals(SystemColumns.WINDOWSTART_NAME)\n-          || select.getAlias().equals(SystemColumns.WINDOWEND_NAME)\n-      ) {\n-        schemaBuilder.keyColumn(select.getAlias(), type);\n-      } else {\n-        schemaBuilder.valueColumn(select.getAlias(), type);\n-      }\n-    }\n-    return schemaBuilder.build();\n-  }\n-\n-  private static PersistentQueryMetadata findMaterializingQuery(\n-      final KsqlExecutionContext executionContext,\n-      final ImmutableAnalysis analysis\n-  ) {\n-    final SourceName sourceName = getSourceName(analysis);\n-\n-    final Set<QueryId> queries = executionContext.getQueriesWithSink(sourceName);\n-    if (queries.isEmpty()) {\n-      throw notMaterializedException(sourceName);\n-    }\n-    if (queries.size() > 1) {\n-      throw new KsqlException(\"Multiple queries currently materialize '\" + sourceName + \"'.\"\n-          + \" KSQL currently only supports pull queries when the table has only been\"\n-          + \" materialized once.\");\n-    }\n-\n-    final QueryId queryId = Iterables.getOnlyElement(queries);\n-\n-    final PersistentQueryMetadata query = executionContext\n-        .getPersistentQuery(queryId)\n-        .orElseThrow(() -> new KsqlException(\"Materializing query has been stopped\"));\n-\n-    if (query.getDataSourceType() != DataSourceType.KTABLE) {\n-      throw new KsqlException(\"Pull queries are not supported on streams.\");\n-    }\n-\n-    return query;\n-  }\n-\n-  private static SourceName getSourceName(final ImmutableAnalysis analysis) {\n-    final DataSource source = analysis.getFrom().getDataSource();\n-    return source.getName();\n-  }\n-\n-  private static KsqlException notMaterializedException(final SourceName sourceTable) {\n-    return new KsqlException(\n-        \"Can't pull from \" + sourceTable + \" as it's not a materialized table.\"\n-        + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-    );\n-  }\n-\n-  private static KsqlException invalidWhereClauseException(\n-      final String msg,\n-      final boolean windowed\n-  ) {\n-    final String additional = !windowed\n-        ? \"\"\n-        : System.lineSeparator()\n-            + \" - (optionally) limits the time bounds of the windowed table.\"\n-            + System.lineSeparator()\n-            + \"\\t Bounds on \" + VALID_WINDOW_BOUNDS_COLUMNS + \" are supported\"\n-            + System.lineSeparator()\n-            + \"\\t Supported operators are \" + VALID_WINDOW_BOUNDS_TYPES_STRING;\n-\n-    return new KsqlException(msg + \". \"\n-        + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n-        + System.lineSeparator()\n-        + \"Pull queries require a WHERE clause that:\"\n-        + System.lineSeparator()\n-        + \" - limits the query to a single key, e.g. `SELECT * FROM X WHERE <key-column>=Y;`.\"\n-        + additional\n-    );\n-  }\n-\n-  private static Struct asKeyStruct(final Object keyValue, final PhysicalSchema physicalSchema) {\n-    final ConnectSchema keySchema = ConnectSchemas\n-        .columnsToConnectSchema(physicalSchema.keySchema().columns());\n-\n-    final Field keyField = Iterables.getOnlyElement(keySchema.fields());\n-\n-    final Struct key = new Struct(keySchema);\n-    key.put(keyField, keyValue);\n-    return key;\n-  }\n-\n-  private static final class ColumnReferenceRewriter\n-      extends VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n-\n-    private ColumnReferenceRewriter() {\n-      super(Optional.empty());\n-    }\n-\n-    @Override\n-    public Optional<Expression> visitQualifiedColumnReference(\n-        final QualifiedColumnReferenceExp node,\n-        final Context<Void> ctx\n-    ) {\n-      return Optional.of(new UnqualifiedColumnReferenceExp(node.getColumnName()));\n-    }\n-  }\n-\n-  private static final class ConfigRoutingOptions implements RoutingOptions {\n-\n-    private final KsqlConfig ksqlConfig;\n-    private final Map<String, ?> configOverrides;\n-    private final Map<String, ?> requestProperties;\n-\n-    ConfigRoutingOptions(\n-        final KsqlConfig ksqlConfig,\n-        final Map<String, ?> configOverrides,\n-        final Map<String, ?> requestProperties\n-    ) {\n-      this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n-      this.configOverrides = configOverrides;\n-      this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n-    }\n-\n-    private long getLong(final String key) {\n-      if (configOverrides.containsKey(key)) {\n-        return (Long) configOverrides.get(key);\n-      }\n-      return ksqlConfig.getLong(key);\n-    }\n-\n-    private boolean getForwardedFlag(final String key) {\n-      if (requestProperties.containsKey(key)) {\n-        return (Boolean) requestProperties.get(key);\n-      }\n-      return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n-    }\n-\n-    public boolean isDebugRequest() {\n-      if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n-        return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n-      }\n-      return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n-    }\n-\n-    @Override\n-    public Set<Integer> getPartitions() {\n-      if (requestProperties.containsKey(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS)) {\n-        @SuppressWarnings(\"unchecked\")\n-        final List<String> partitions = (List<String>) requestProperties.get(\n-            KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS);\n-        return partitions.stream()\n-            .map(partition -> {\n-              try {\n-                return Integer.parseInt(partition);\n-              } catch (NumberFormatException e) {\n-                throw new IllegalStateException(\"Internal request got a bad partition \"\n-                    + partition);\n-              }\n-            }).collect(Collectors.toSet());\n-      }\n-      return Collections.emptySet();\n-    }\n-\n-    @Override\n-    public long getOffsetLagAllowed() {\n-      return getLong(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG);\n-    }\n-\n-    @Override\n-    public boolean skipForwardRequest() {\n-      return getForwardedFlag(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING);\n-    }\n-  }\n-}\n\\ No newline at end of file\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3ODYyMw==", "url": "https://github.com/confluentinc/ksql/pull/6628#discussion_r525578623", "bodyText": "Just curious, how much overhead is it to compile the java into bytecode, load the bytecode, and then run it.  It makes a lot of sense when you compile once and then run many times, but in this case, there's a 1:1 relationship.  In general, it seems like interpreting the expression would be lower overhead and possibly faster.  Do we do it this way because this is the main method that currently exists for \"evaluating a sql expression\"?\nI'd be curious to run a benchmark doing just expression lookups (rather than literals).", "author": "AlanConfluent", "createdAt": "2020-11-17T22:52:08Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/generic/GenericExpressionResolver.java", "diffHunk": "@@ -76,11 +83,12 @@ public Object resolve(final Expression expression) {\n \n     @Override\n     protected Object visitExpression(final Expression expression, final Void context) {\n+      new EnsureNoColReferences(expression).process(expression, context);\n       final ExpressionMetadata metadata =\n           CodeGenRunner.compileExpression(", "originalCommit": "d48b3b6d96d97676a0d7dfc1284cef242b727746", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzMTE5MA==", "url": "https://github.com/confluentinc/ksql/pull/6628#discussion_r525631190", "bodyText": "Talked offline about this, we'll look into running specialized benchmarks to see how much the overhead is. Given that this is just \"new\" functionality, we won't block the PR on this and we'll run those benchmarks going forward.", "author": "agavra", "createdAt": "2020-11-18T01:15:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU3ODYyMw=="}], "type": "inlineReview", "revised_code": {"commit": "5dd79121d58e310f4cac749c0dbfa5a1f53fec48", "chunk": "diff --git a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/generic/GenericExpressionResolver.java b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/generic/GenericExpressionResolver.java\nindex a860ba8954..d3125541a4 100644\n--- a/ksqldb-engine/src/main/java/io/confluent/ksql/engine/generic/GenericExpressionResolver.java\n+++ b/ksqldb-engine/src/main/java/io/confluent/ksql/engine/generic/GenericExpressionResolver.java\n\n@@ -83,11 +77,10 @@ public class GenericExpressionResolver {\n \n     @Override\n     protected Object visitExpression(final Expression expression, final Void context) {\n-      new EnsureNoColReferences(expression).process(expression, context);\n       final ExpressionMetadata metadata =\n           CodeGenRunner.compileExpression(\n               expression,\n-              operation,\n+              \"insert value\",\n               NO_COLUMNS,\n               config,\n               functionRegistry\n"}}, {"oid": "5dd79121d58e310f4cac749c0dbfa5a1f53fec48", "url": "https://github.com/confluentinc/ksql/commit/5dd79121d58e310f4cac749c0dbfa5a1f53fec48", "message": "chore: support complex key pull queries", "committedDate": "2020-11-19T00:29:33Z", "type": "commit"}, {"oid": "a4b4c4cd82f4549cd198a5ce358b1432e9311161", "url": "https://github.com/confluentinc/ksql/commit/a4b4c4cd82f4549cd198a5ce358b1432e9311161", "message": "chore: update to better error message", "committedDate": "2020-11-19T00:29:51Z", "type": "commit"}, {"oid": "5cb93e548b265cd4e09e1993f47d6be469394405", "url": "https://github.com/confluentinc/ksql/commit/5cb93e548b265cd4e09e1993f47d6be469394405", "message": "test: update test case for multiple IN statements", "committedDate": "2020-11-19T00:29:53Z", "type": "commit"}, {"oid": "2756cfb722218ff67e9f48ef70661da751b988f8", "url": "https://github.com/confluentinc/ksql/commit/2756cfb722218ff67e9f48ef70661da751b988f8", "message": "chore: rebase with master", "committedDate": "2020-11-19T00:58:12Z", "type": "commit"}, {"oid": "2756cfb722218ff67e9f48ef70661da751b988f8", "url": "https://github.com/confluentinc/ksql/commit/2756cfb722218ff67e9f48ef70661da751b988f8", "message": "chore: rebase with master", "committedDate": "2020-11-19T00:58:12Z", "type": "forcePushed"}, {"oid": "28c43d43dd2ff72c27ccde079ff6da375a9a4c75", "url": "https://github.com/confluentinc/ksql/commit/28c43d43dd2ff72c27ccde079ff6da375a9a4c75", "message": "chore: fix checkstyle", "committedDate": "2020-11-19T01:24:34Z", "type": "commit"}]}